[{"id": "1805.00063", "submitter": "Igor Melnyk", "authors": "Pierre L. Dognin, Igor Melnyk, Youssef Mroueh, Jarret Ross, and Tom\n  Sercu (IBM Research, USA)", "title": "Adversarial Semantic Alignment for Improved Image Captions", "comments": "Authors Equal Contribution, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study image captioning as a conditional GAN training,\nproposing both a context-aware LSTM captioner and co-attentive discriminator,\nwhich enforces semantic alignment between images and captions. We empirically\nfocus on the viability of two training methods: Self-critical Sequence Training\n(SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more\nstable gradient behavior and improved results over Gumbel ST, even without\naccessing discriminator gradients directly. We also address the problem of\nautomatic evaluation for captioning models and introduce a new semantic score,\nand show its correlation to human judgement. As an evaluation paradigm, we\nargue that an important criterion for a captioner is the ability to generalize\nto compositions of objects that do not usually co-occur together. To this end,\nwe introduce a small captioned Out of Context (OOC) test set. The OOC set,\ncombined with our semantic score, are the proposed new diagnosis tools for the\ncaptioning community. When evaluated on OOC and MS-COCO benchmarks, we show\nthat SCST-based training has a strong performance in both semantic score and\nhuman evaluation, promising to be a valuable new approach for efficient\ndiscrete GAN training.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 19:10:43 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 17:43:25 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 18:41:03 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Dognin", "Pierre L.", "", "IBM Research, USA"], ["Melnyk", "Igor", "", "IBM Research, USA"], ["Mroueh", "Youssef", "", "IBM Research, USA"], ["Ross", "Jarret", "", "IBM Research, USA"], ["Sercu", "Tom", "", "IBM Research, USA"]]}, {"id": "1805.00065", "submitter": "Aman Agarwal", "authors": "Aman Agarwal, Kenta Takatsu, Ivan Zaitsev, Thorsten Joachims", "title": "A General Framework for Counterfactual Learning-to-Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit feedback (e.g., click, dwell time) is an attractive source of\ntraining data for Learning-to-Rank, but its naive use leads to learning results\nthat are distorted by presentation bias. For the special case of optimizing\naverage rank for linear ranking functions, however, the recently developed\nSVM-PropRank method has shown that counterfactual inference techniques can be\nused to provably overcome the distorting effect of presentation bias. Going\nbeyond this special case, this paper provides a general and theoretically\nrigorous framework for counterfactual learning-to-rank that enables unbiased\ntraining for a broad class of additive ranking metrics (e.g., Discounted\nCumulative Gain (DCG)) as well as a broad class of models (e.g., deep\nnetworks). Specifically, we derive a relaxation for propensity-weighted\nrank-based metrics which is subdifferentiable and thus suitable for\ngradient-based optimization. We demonstrate the effectiveness of this general\napproach by instantiating two new learning methods. One is a new type of\nunbiased SVM that optimizes DCG -- called SVM PropDCG --, and we show how the\nresulting optimization problem can be solved via the Convex Concave Procedure\n(CCP). The other is Deep PropDCG, where the ranking function can be an\narbitrary deep network. In addition to the theoretical support, we empirically\nfind that SVM PropDCG significantly outperforms existing linear rankers in\nterms of DCG. Moreover, the ability to train non-linear ranking functions via\nDeep PropDCG further improves performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 19:12:37 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 03:32:49 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 13:58:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Agarwal", "Aman", ""], ["Takatsu", "Kenta", ""], ["Zaitsev", "Ivan", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1805.00071", "submitter": "Maximilian Baust", "authors": "Maximilian Baust, Florian Ludwig, Christian Rupprecht, Matthias Kohl,\n  Stefan Braunewell", "title": "Understanding Regularization to Visualize Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational methods for revealing visual concepts learned by convolutional\nneural networks have gained significant attention during the last years. Being\nbased on noisy gradients obtained via back-propagation such methods require the\napplication of regularization strategies. We present a mathematical framework\nunifying previously employed regularization methods. Within this framework, we\npropose a novel technique based on Sobolev gradients which can be implemented\nvia convolutions and does not require specialized numerical treatment, such as\ntotal variation regularization. The experiments performed on feature inversion\nand activation maximization demonstrate the benefit of a unified approach to\nregularization, such as sharper reconstructions via the proposed Sobolev\nfilters and a better control over reconstructed scales.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:09:34 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Baust", "Maximilian", ""], ["Ludwig", "Florian", ""], ["Rupprecht", "Christian", ""], ["Kohl", "Matthias", ""], ["Braunewell", "Stefan", ""]]}, {"id": "1805.00089", "submitter": "Youcheng Sun", "authors": "Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska,\n  and Daniel Kroening", "title": "Concolic Testing for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concolic testing combines program execution and symbolic analysis to explore\nthe execution paths of a software program. This paper presents the first\nconcolic testing approach for Deep Neural Networks (DNNs). More specifically,\nwe formalise coverage criteria for DNNs that have been studied in the\nliterature, and then develop a coherent method for performing concolic testing\nto increase test coverage. Our experimental results show the effectiveness of\nthe concolic testing approach in both achieving high coverage and finding\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 20:34:16 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 13:37:51 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Sun", "Youcheng", ""], ["Wu", "Min", ""], ["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""], ["Kwiatkowska", "Marta", ""], ["Kroening", "Daniel", ""]]}, {"id": "1805.00108", "submitter": "Seokho Kang", "authors": "Seokho Kang, Kyunghyun Cho", "title": "Conditional molecular design with deep generative models", "comments": "25 pages, 6 figures", "journal-ref": "Journal of Chemical Information and Modeling 59(1): 43-52, 2019", "doi": "10.1021/acs.jcim.8b00263", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although machine learning has been successfully used to propose novel\nmolecules that satisfy desired properties, it is still challenging to explore a\nlarge chemical space efficiently. In this paper, we present a conditional\nmolecular design method that facilitates generating new molecules with desired\nproperties. The proposed model, which simultaneously performs both property\nprediction and molecule generation, is built as a semi-supervised variational\nautoencoder trained on a set of existing molecules with only a partial\nannotation. We generate new molecules with desired properties by sampling from\nthe generative distribution estimated by the model. We demonstrate the\neffectiveness of the proposed model by evaluating it on drug-like molecules.\nThe model improves the performance of property prediction by exploiting\nunlabeled molecules, and efficiently generates novel molecules fulfilling\nvarious target conditions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 21:36:05 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 19:15:20 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 17:07:44 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kang", "Seokho", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1805.00119", "submitter": "Constantine Vitt", "authors": "Constantine Vitt, Darinka Dentcheva, Hui Xiong", "title": "Risk-Averse Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new approach to solving classification problems, which is bases\non the theory of coherent measures of risk and risk sharing ideas. The proposed\napproach aims at designing a risk-averse classifier. The new approach allows\nfor associating distinct risk functional to each classes. The risk may be\nmeasured by different (non-linear in probability) measures,\n  We analyze the structure of the new classifier design problem and establish\nits theoretical relation to known risk-neutral design problems. In particular,\nwe show that the risk-sharing classification problem is equivalent to an\nimplicitly defined optimization problem with unequal, implicitly defined but\nunknown, weights for each data point. We implement our methodology in a binary\nclassification scenario on several different data sets and carry out numerical\ncomparison with classifiers which are obtained using the Huber loss function\nand other loss functions known in the literature. We formulate specific\nrisk-averse support vector machines in order to demonstrate the viability of\nour method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 22:29:18 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 19:41:06 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Vitt", "Constantine", ""], ["Dentcheva", "Darinka", ""], ["Xiong", "Hui", ""]]}, {"id": "1805.00121", "submitter": "Juan Duque Rodriguez", "authors": "Juan Ar\\'evalo, Juan Ram\\'on Duque, Marco Creatura", "title": "A Missing Information Loss function for implicit feedback datasets", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models for Recommender Systems with implicit feedback typically\ntreat unobserved user-item interactions (i.e. missing information) as negative\nfeedback. This is frequently done either through negative sampling (point--wise\nloss) or with a ranking loss function (pair-- or list--wise estimation). Since\na zero preference recommendation is a valid solution for most common objective\nfunctions, regarding unknown values as actual zeros results in users having a\nzero preference recommendation for most of the available items. In this paper\nwe propose a novel objective function, the \\emph{Missing Information Loss}\n(MIL), that explicitly forbids treating unobserved user-item interactions as\npositive or negative feedback. We apply this loss to both traditional Matrix\nFactorization and user--based Denoising Autoencoder, and compare it with other\nestablished objective functions such as cross-entropy (both point- and\npair-wise) or the recently proposed multinomial log-likelihood. MIL achieves\ncompetitive performance in ranking-aware metrics when applied to three\ndatasets. Furthermore, we show that such a relevance in the recommendation is\nobtained while displaying popular items less frequently (up to a $20 \\%$\ndecrease with respect to the best competing method). This debiasing from the\nrecommendation of popular items favours the appearance of infrequent items (up\nto a $50 \\%$ increase of long-tail recommendations), a valuable feature for\nRecommender Systems with a large catalogue of products.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 22:38:05 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 08:16:50 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Ar\u00e9valo", "Juan", ""], ["Duque", "Juan Ram\u00f3n", ""], ["Creatura", "Marco", ""]]}, {"id": "1805.00165", "submitter": "Fernando Gama", "authors": "Fernando Gama and Antonio G. Marques and Geert Leus and Alejandro\n  Ribeiro", "title": "Convolutional Neural Network Architectures for Signals Supported on\n  Graphs", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2018.2887403", "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two architectures that generalize convolutional neural networks (CNNs) for\nthe processing of signals supported on graphs are introduced. We start with the\nselection graph neural network (GNN), which replaces linear time invariant\nfilters with linear shift invariant graph filters to generate convolutional\nfeatures and reinterprets pooling as a possibly nonlinear subsampling stage\nwhere nearby nodes pool their information in a set of preselected sample nodes.\nA key component of the architecture is to remember the position of sampled\nnodes to permit computation of convolutional features at deeper layers. The\nsecond architecture, dubbed aggregation GNN, diffuses the signal through the\ngraph and stores the sequence of diffused components observed by a designated\nnode. This procedure effectively aggregates all components into a stream of\ninformation having temporal structure to which the convolution and pooling\nstages of regular CNNs can be applied. A multinode version of aggregation GNNs\nis further introduced for operation in large scale graphs. An important\nproperty of selection and aggregation GNNs is that they reduce to conventional\nCNNs when particularized to time signals reinterpreted as graph signals in a\ncirculant graph. Comparative numerical analyses are performed in a source\nlocalization application over synthetic and real-world networks. Performance is\nalso evaluated for an authorship attribution problem and text category\nclassification. Multinode aggregation GNNs are consistently the best performing\nGNN architecture.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 03:04:31 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 01:17:25 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Leus", "Geert", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1805.00169", "submitter": "Rodrigo de Lamare", "authors": "S. F. B. Pinto and R. C. de Lamare", "title": "Multi-Step Knowledge-Aided Iterative ESPRIT for Direction Finding", "comments": "7 figures. arXiv admin note: text overlap with arXiv:1703.10523", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a subspace-based algorithm for DOA estimation which\niteratively reduces the disturbance factors of the estimated data covariance\nmatrix and incorporates prior knowledge which is gradually obtained on line. An\nanalysis of the MSE of the reshaped data covariance matrix is carried out along\nwith comparisons between computational complexities of the proposed and\nexisting algorithms. Simulations focusing on closely-spaced sources, where they\nare uncorrelated and correlated, illustrate the improvements achieved.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 03:12:16 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Pinto", "S. F. B.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1805.00184", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Carlos Guestrin, Sameer Singh", "title": "Compact Factorization of Matrices Using Generalized Round-Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is a well-studied task in machine learning for compactly\nrepresenting large, noisy data. In our approach, instead of using the\ntraditional concept of matrix rank, we define a new notion of link-rank based\non a non-linear link function used within factorization. In particular, by\napplying the round function on a factorization to obtain ordinal-valued\nmatrices, we introduce generalized round-rank (GRR). We show that not only are\nthere many full-rank matrices that are low GRR, but further, that these\nmatrices cannot be approximated well by low-rank linear factorization. We\nprovide uniqueness conditions of this formulation and provide gradient\ndescent-based algorithms. Finally, we present experiments on real-world\ndatasets to demonstrate that the GRR-based factorization is significantly more\naccurate than linear factorization, while converging faster and using lower\nrank representations.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 04:41:58 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Guestrin", "Carlos", ""], ["Singh", "Sameer", ""]]}, {"id": "1805.00200", "submitter": "Yoriyuki Yamagata", "authors": "Takumi Akazaki, Shuang Liu, Yoriyuki Yamagata, Yihai Duan, Jianye Hao", "title": "Falsification of Cyber-Physical Systems Using Deep Reinforcement\n  Learning", "comments": "9 pages, 1 figure, to be presented at FM2018", "journal-ref": "Formal Methods. FM 2018. Lecture Notes in Computer Science, vol\n  10951. Springer, Cham", "doi": "10.1007/978-3-319-95582-7_27", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of software and distributed computing,\nCyber-Physical Systems (CPS) are widely adopted in many application areas,\ne.g., smart grid, autonomous automobile. It is difficult to detect defects in\nCPS models due to the complexities involved in the software and physical\nsystems. To find defects in CPS models efficiently, robustness guided\nfalsification of CPS is introduced. Existing methods use several optimization\ntechniques to generate counterexamples, which falsify the given properties of a\nCPS. However those methods may require a large number of simulation runs to\nfind the counterexample and is far from practical. In this work, we explore\nstate-of-the-art Deep Reinforcement Learning (DRL) techniques to reduce the\nnumber of simulation runs required to find such counterexamples. We report our\nmethod and the preliminary evaluation results.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 06:22:54 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Akazaki", "Takumi", ""], ["Liu", "Shuang", ""], ["Yamagata", "Yoriyuki", ""], ["Duan", "Yihai", ""], ["Hao", "Jianye", ""]]}, {"id": "1805.00215", "submitter": "Shun Yi", "authors": "Shun Yi", "title": "Internal node bagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel view to understand how dropout works as an inexplicit\nensemble learning method, which doesn't point out how many and which nodes to\nlearn a certain feature. We propose a new training method named internal node\nbagging, it explicitly forces a group of nodes to learn a certain feature in\ntraining time, and combine those nodes to be one node in inference time. It\nmeans we can use much more parameters to improve model's fitting ability in\ntraining time while keeping model small in inference time. We test our method\non several benchmark datasets and find it performs significantly better than\ndropout on small models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 07:16:24 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 14:28:04 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 13:12:49 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2018 03:00:08 GMT"}, {"version": "v5", "created": "Fri, 21 Sep 2018 01:50:44 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Yi", "Shun", ""]]}, {"id": "1805.00216", "submitter": "Gautam Kamath", "authors": "Gautam Kamath, Jerry Li, Vikrant Singhal, Jonathan Ullman", "title": "Privately Learning High-Dimensional Distributions", "comments": "To appear in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel, computationally efficient, and differentially private\nalgorithms for two fundamental high-dimensional learning problems: learning a\nmultivariate Gaussian and learning a product distribution over the Boolean\nhypercube in total variation distance. The sample complexity of our algorithms\nnearly matches the sample complexity of the optimal non-private learners for\nthese tasks in a wide range of parameters, showing that privacy comes\nessentially for free for these problems. In particular, in contrast to previous\napproaches, our algorithm for learning Gaussians does not require strong a\npriori bounds on the range of the parameters. Our algorithms introduce a novel\ntechnical approach to reducing the sensitivity of the estimation procedure that\nwe call recursive private preconditioning.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 07:20:46 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 17:38:53 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 04:23:31 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Kamath", "Gautam", ""], ["Li", "Jerry", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1805.00250", "submitter": "Hongyu Lin", "authors": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on detection tasks in information extraction, where\npositive instances are sparsely distributed and models are usually evaluated\nusing F-measure on positive classes. These characteristics often result in\ndeficient performance of neural network based detection models. In this paper,\nwe propose adaptive scaling, an algorithm which can handle the positive\nsparsity problem and directly optimize over F-measure via dynamic\ncost-sensitive learning. To this end, we borrow the idea of marginal utility\nfrom economics and propose a theoretical framework for instance importance\nmeasuring without introducing any additional hyper-parameters. Experiments show\nthat our algorithm leads to a more effective and stable training of neural\nnetwork based detection models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:21:34 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 06:39:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lin", "Hongyu", ""], ["Lu", "Yaojie", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "1805.00254", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Benjamin Roth and Hinrich Sch\\\"utze", "title": "Joint Bootstrapping Machines for High Confidence Relation Extraction", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised bootstrapping techniques for relationship extraction from\ntext iteratively expand a set of initial seed instances. Due to the lack of\nlabeled data, a key challenge in bootstrapping is semantic drift: if a false\npositive instance is added during an iteration, then all following iterations\nare contaminated. We introduce BREX, a new bootstrapping method that protects\nagainst such contamination by highly effective confidence assessment. This is\nachieved by using entity and template seeds jointly (as opposed to just one as\nin previous work), by expanding entities and templates in parallel and in a\nmutually constraining fashion in each iteration and by introducing\nhigherquality similarity measures for templates. Experimental results show that\nBREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the\nart for four relationships.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:39:19 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1805.00309", "submitter": "Ning Ma", "authors": "Ning Ma, Alexey Volkov, Aleksandr Livshits, Pawel Pietrusinski,\n  Houdong Hu, Mark Bolin", "title": "An Universal Image Attractiveness Ranking Framework", "comments": "Accepted by 2019 Winter Conference on Application of Computer Vision\n  (WACV)", "journal-ref": "2019 IEEE Winter Conference on Applications of Computer Vision\n  (WACV)", "doi": "10.1109/WACV.2019.00075", "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework to rank image attractiveness using a novel\npairwise deep network trained with a large set of side-by-side multi-labeled\nimage pairs from a web image index. The judges only provide relative ranking\nbetween two images without the need to directly assign an absolute score, or\nrate any predefined image attribute, thus making the rating more intuitive and\naccurate. We investigate a deep attractiveness rank net (DARN), a combination\nof deep convolutional neural network and rank net, to directly learn an\nattractiveness score mean and variance for each image and the underlying\ncriteria the judges use to label each pair. The extension of this model\n(DARN-V2) is able to adapt to individual judge's personal preference. We also\nshow the attractiveness of search results are significantly improved by using\nthis attractiveness information in a real commercial search engine. We evaluate\nour model against other state-of-the-art models on our side-by-side web test\ndata and another public aesthetic data set. With much less judgments (1M vs\n50M), our model outperforms on side-by-side labeled data, and is comparable on\ndata labeled by absolute score.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 21:10:37 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 06:27:01 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 06:34:48 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Ma", "Ning", ""], ["Volkov", "Alexey", ""], ["Livshits", "Aleksandr", ""], ["Pietrusinski", "Pawel", ""], ["Hu", "Houdong", ""], ["Bolin", "Mark", ""]]}, {"id": "1805.00310", "submitter": "Pin-Yu Chen", "authors": "Pei-Hsuan Lu, Pin-Yu Chen, Kang-Cheng Chen, Chia-Mu Yu", "title": "On the Limitation of MagNet Defense against $L_1$-based Adversarial\n  Examples", "comments": "Accepted to IEEE/IFIP International Conference on Dependable and\n  Systems and Networks (DSN) 2018 Workshop on Dependable and Secure Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, defending adversarial perturbations to natural examples in\norder to build robust machine learning models trained by deep neural networks\n(DNNs) has become an emerging research field in the conjunction of deep\nlearning and security. In particular, MagNet consisting of an adversary\ndetector and a data reformer is by far one of the strongest defenses in the\nblack-box oblivious attack setting, where the attacker aims to craft\ntransferable adversarial examples from an undefended DNN model to bypass an\nunknown defense module deployed on the same DNN model. Under this setting,\nMagNet can successfully defend a variety of attacks in DNNs, including the\nhigh-confidence adversarial examples generated by the Carlini and Wagner's\nattack based on the $L_2$ distortion metric. However, in this paper, under the\nsame attack setting we show that adversarial examples crafted based on the\n$L_1$ distortion metric can easily bypass MagNet and mislead the target DNN\nimage classifiers on MNIST and CIFAR-10. We also provide explanations on why\nthe considered approach can yield adversarial examples with superior attack\nperformance and conduct extensive experiments on variants of MagNet to verify\nits lack of robustness to $L_1$ distortion based attacks. Notably, our results\nsubstantially weaken the assumption of effective threat models on MagNet that\nrequire knowing the deployed defense technique when attacking DNNs (i.e., the\ngray-box attack setting).\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 05:44:51 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 15:37:54 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Lu", "Pei-Hsuan", ""], ["Chen", "Pin-Yu", ""], ["Chen", "Kang-Cheng", ""], ["Yu", "Chia-Mu", ""]]}, {"id": "1805.00311", "submitter": "Yinheng Zhu", "authors": "Yinheng Zhu, Wanli Chen, Xun Zhan, Zonglin Guo, Hongjian Shi, Ian G.\n  Harris", "title": "Head Mounted Pupil Tracking Using Convolutional Neural Network", "comments": "It's out of date and not STOA any more", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pupil tracking is an important branch of object tracking which require high\nprecision. We investigate head mounted pupil tracking which is often more\nconvenient and precise than remote pupil tracking, but also more challenging.\nWhen pupil tracking suffers from noise like bad illumination, detection\nprecision dramatically decreases. Due to the appearance of head mounted\nrecording device and public benchmark image datasets, head mounted tracking\nalgorithms have become easier to design and evaluate. In this paper, we propose\na robust head mounted pupil detection algorithm which uses a Convolutional\nNeural Network (CNN) to combine different features of pupil. Here we consider\nthree features of pupil. Firstly, we use three pupil feature-based algorithms\nto find pupil center independently. Secondly, we use a CNN to evaluate the\nquality of each result. Finally, we select the best result as output. The\nexperimental results show that our proposed algorithm performs better than the\npresent state-of-art.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 04:48:16 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 01:44:01 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Zhu", "Yinheng", ""], ["Chen", "Wanli", ""], ["Zhan", "Xun", ""], ["Guo", "Zonglin", ""], ["Shi", "Hongjian", ""], ["Harris", "Ian G.", ""]]}, {"id": "1805.00316", "submitter": "Shabab Bazrafkan", "authors": "Shabab Bazrafkan, Hossein Javidnia, Peter Corcoran", "title": "Versatile Auxiliary Classifier with Generative Adversarial Network\n  (VAC+GAN)", "comments": "This paper will be uploaded as two separate manuscripts", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most interesting challenges in Artificial Intelligence is to train\nconditional generators which are able to provide labeled adversarial samples\ndrawn from a specific distribution. In this work, a new framework is presented\nto train a deep conditional generator by placing a classifier in parallel with\nthe discriminator and back propagate the classification error through the\ngenerator network. The method is versatile and is applicable to any variations\nof Generative Adversarial Network (GAN) implementation, and also gives superior\nresults compared to similar methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 13:17:39 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 17:26:41 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 23:47:57 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Bazrafkan", "Shabab", ""], ["Javidnia", "Hossein", ""], ["Corcoran", "Peter", ""]]}, {"id": "1805.00322", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Thomas Lu, Edward Chow", "title": "Occluded object reconstruction for first responders with augmented\n  reality glasses using conditional generative adversarial networks", "comments": "SPIE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firefighters suffer a variety of life-threatening risks, including\nline-of-duty deaths, injuries, and exposures to hazardous substances. Support\nfor reducing these risks is important. We built a partially occluded object\nreconstruction method on augmented reality glasses for first responders. We\nused a deep learning based on conditional generative adversarial networks to\ntrain associations between the various images of flammable and hazardous\nobjects and their partially occluded counterparts. Our system then\nreconstructed an image of a new flammable object. Finally, the reconstructed\nimage was superimposed on the input image to provide \"transparency\". The system\nimitates human learning about the laws of physics through experience by\nlearning the shape of flammable objects and the flame characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 23:56:10 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Yun", "Kyongsik", ""], ["Lu", "Thomas", ""], ["Chow", "Edward", ""]]}, {"id": "1805.00327", "submitter": "Ying Ma", "authors": "Ying Ma, Jose Principe", "title": "A Taxonomy for Neural Memory Networks", "comments": null, "journal-ref": "Published in: IEEE Transactions on Neural Networks and Learning\n  Systems ( Volume: 31, Issue: 6, June 2020)", "doi": "10.1109/TNNLS.2019.2926466", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a taxonomy for memory networks is proposed based on their\nmemory organization. The taxonomy includes all the popular memory networks:\nvanilla recurrent neural network (RNN), long short term memory (LSTM ), neural\nstack and neural Turing machine and their variants. The taxonomy puts all these\nnetworks under a single umbrella and shows their relative expressive power ,\ni.e. vanilla RNN <=LSTM<=neural stack<=neural RAM. The differences and\ncommonality between these networks are analyzed. These differences are also\nconnected to the requirements of different tasks which can give the user\ninstructions of how to choose or design an appropriate memory network for a\nspecific task. As a conceptual simplified class of problems, four tasks of\nsynthetic symbol sequences: counting, counting with interference, reversing and\nrepeat counting are developed and tested to verify our arguments. And we use\ntwo natural language processing problems to discuss how this taxonomy helps\nchoosing the appropriate neural memory networks for real world problem.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 13:37:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ma", "Ying", ""], ["Principe", "Jose", ""]]}, {"id": "1805.00348", "submitter": "Dongrui Wu", "authors": "Yuqi Cui, Xiao Zhang, Yang Wang, Chenfeng Guo, Dongrui Wu", "title": "OMG - Emotion Challenge Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper describes our solution to the 2018 IEEE World Congress on\nComputational Intelligence One-Minute Gradual-Emotional Behavior Challenge,\nwhose goal was to estimate continuous arousal and valence values from short\nvideos. We designed four base regression models using visual and audio\nfeatures, and then used a spectral approach to fuse them to obtain improved\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 10:50:30 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Cui", "Yuqi", ""], ["Zhang", "Xiao", ""], ["Wang", "Yang", ""], ["Guo", "Chenfeng", ""], ["Wu", "Dongrui", ""]]}, {"id": "1805.00352", "submitter": "Marina Sokolova", "authors": "Qufei Chen, Marina Sokolova", "title": "Word2Vec and Doc2Vec in Unsupervised Sentiment Analysis of Clinical\n  Discharge Summaries", "comments": "23 pages, 3 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we explored application of Word2Vec and Doc2Vec for sentiment\nanalysis of clinical discharge summaries. We applied unsupervised learning\nsince the data sets did not have sentiment annotations. Note that unsupervised\nlearning is a more realistic scenario than supervised learning which requires\nan access to a training set of sentiment-annotated data. We aim to detect if\nthere exists any underlying bias towards or against a certain disease. We used\nSentiWordNet to establish a gold sentiment standard for the data sets and\nevaluate performance of Word2Vec and Doc2Vec methods. We have shown that the\nWord2vec and Doc2Vec methods complement each other results in sentiment\nanalysis of the data sets.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 14:07:44 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Chen", "Qufei", ""], ["Sokolova", "Marina", ""]]}, {"id": "1805.00355", "submitter": "Debasmit Das", "authors": "Debasmit Das, C.S. George Lee", "title": "Sample-to-Sample Correspondence for Unsupervised Domain Adaptation", "comments": "Final version appeared in Engineering Applications of Artificial\n  Intelligence. Mostly, the related work in this version is different from the\n  published version", "journal-ref": null, "doi": "10.1016/j.engappai.2018.05.001", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assumption that training and testing samples are generated from the same\ndistribution does not always hold for real-world machine-learning applications.\nThe procedure of tackling this discrepancy between the training (source) and\ntesting (target) domains is known as domain adaptation. We propose an\nunsupervised version of domain adaptation that considers the presence of only\nunlabelled data in the target domain. Our approach centers on finding\ncorrespondences between samples of each domain. The correspondences are\nobtained by treating the source and target samples as graphs and using a convex\ncriterion to match them. The criteria used are first-order and second-order\nsimilarities between the graphs as well as a class-based regularization. We\nhave also developed a computationally efficient routine for the convex\noptimization, thus allowing the proposed method to be used widely. To verify\nthe effectiveness of the proposed method, computer simulations were conducted\non synthetic, image classification and sentiment classification datasets.\nResults validated that the proposed local sample-to-sample matching method\nout-performs traditional moment-matching methods and is competitive with\nrespect to current local domain-adaptation methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 14:12:57 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 16:48:03 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 06:27:40 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "1805.00356", "submitter": "Jill-J\\^enn Vie", "authors": "Jill-J\\^enn Vie", "title": "Deep Factorization Machines for Knowledge Tracing", "comments": "4 pages, 1 table, accepted at the 13th BEA workshop, co-located with\n  NAACL HLT 2018 conference in New Orleans on June 5, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces our solution to the 2018 Duolingo Shared Task on Second\nLanguage Acquisition Modeling (SLAM). We used deep factorization machines, a\nwide and deep learning model of pairwise relationships between users, items,\nskills, and other entities considered. Our solution (AUC 0.815) hopefully\nmanaged to beat the logistic regression baseline (AUC 0.774) but not the top\nperforming model (AUC 0.861) and reveals interesting strategies to build upon\nitem response theory models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 14:13:56 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Vie", "Jill-J\u00eann", ""]]}, {"id": "1805.00357", "submitter": "Markus Degel", "authors": "Markus A. Degel, Nassir Navab, Shadi Albarqouni", "title": "Domain and Geometry Agnostic CNNs for Left Atrium Segmentation in 3D\n  Ultrasound", "comments": null, "journal-ref": "Medical Image Computing and Computer Assisted Intervention (MICCAI\n  2018)", "doi": "10.1007/978-3-030-00937-3_72", "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of the left atrium and deriving its size can help to predict and\ndetect various cardiovascular conditions. Automation of this process in 3D\nUltrasound image data is desirable, since manual delineations are\ntime-consuming, challenging and observer-dependent. Convolutional neural\nnetworks have made improvements in computer vision and in medical image\nanalysis. They have successfully been applied to segmentation tasks and were\nextended to work on volumetric data. In this paper we introduce a combined\ndeep-learning based approach on volumetric segmentation in Ultrasound\nacquisitions with incorporation of prior knowledge about left atrial shape and\nimaging device. The results show, that including a shape prior helps the domain\nadaptation and the accuracy of segmentation is further increased with\nadversarial learning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 09:22:50 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Degel", "Markus A.", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "1805.00361", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Patrick Dong, Wenhan Zhang, Jason Dong, Charles\n  Young", "title": "Ultra Power-Efficient CNN Domain Specific Accelerator with 9.3TOPS/Watt\n  for Mobile and Embedded Applications", "comments": "9 pages, 10 Figures. Accepted by CVPR 2018 Efficient Deep Learning\n  for Computer Vision workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision performances have been significantly improved in recent years\nby Convolutional Neural Networks(CNN). Currently, applications using CNN\nalgorithms are deployed mainly on general purpose hardwares, such as CPUs, GPUs\nor FPGAs. However, power consumption, speed, accuracy, memory footprint, and\ndie size should all be taken into consideration for mobile and embedded\napplications. Domain Specific Architecture (DSA) for CNN is the efficient and\npractical solution for CNN deployment and implementation. We designed and\nproduced a 28nm Two-Dimensional CNN-DSA accelerator with an ultra\npower-efficient performance of 9.3TOPS/Watt and with all processing done in the\ninternal memory instead of outside DRAM. It classifies 224x224 RGB image inputs\nat more than 140fps with peak power consumption at less than 300mW and an\naccuracy comparable to the VGG benchmark. The CNN-DSA accelerator is\nreconfigurable to support CNN model coefficients of various layer sizes and\nlayer types, including convolution, depth-wise convolution, short-cut\nconnections, max pooling, and ReLU. Furthermore, in order to better support\nreal-world deployment for various application scenarios, especially with\nlow-end mobile and embedded platforms and MCUs (Microcontroller Units), we also\ndesigned algorithms to fully utilize the CNN-DSA accelerator efficiently by\nreducing the dependency on external accelerator computation resources,\nincluding implementation of Fully-Connected (FC) layers within the accelerator\nand compression of extracted features from the CNN-DSA accelerator. Live demos\nwith our CNN-DSA accelerator on mobile and embedded systems show its\ncapabilities to be widely and practically applied in the real world.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 17:36:14 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Dong", "Patrick", ""], ["Zhang", "Wenhan", ""], ["Dong", "Jason", ""], ["Young", "Charles", ""]]}, {"id": "1805.00367", "submitter": "Chong Zhang", "authors": "Chong Zhang, Geok Soon Hong, Jun-Hong Zhou, Kay Chen Tan, Haizhou Li,\n  Huan Xu, Jihoon Hong, and Hian-Leng Chan", "title": "A Multi-State Diagnosis and Prognosis Framework with Feature Learning\n  for Tool Condition Monitoring", "comments": "14 pages, 12 figures, 10 tables, submitted to IEEE Transactions on\n  Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a multi-state diagnosis and prognosis (MDP) framework is\nproposed for tool condition monitoring via a deep belief network based\nmulti-state approach (DBNMS). For fault diagnosis, a cost-sensitive deep belief\nnetwork (namely ECS-DBN) is applied to deal with the imbalanced data problem\nfor tool state estimation. An appropriate prognostic degradation model is then\napplied for tool wear estimation based on the different tool states. The\nproposed framework has the advantage of automatic feature representation\nlearning and shows better performance in accuracy and robustness. The\neffectiveness of the proposed DBNMS is validated using a real-world dataset\nobtained from the gun drilling process. This dataset contains a large amount of\nmeasured signals involving different tool geometries under various operating\nconditions. The DBNMS is examined for both the tool state estimation and tool\nwear estimation tasks. In the experimental studies, the prediction results are\nevaluated and compared with popular machine learning approaches, which show the\nsuperior performance of the proposed DBNMS approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 04:43:25 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Zhang", "Chong", ""], ["Hong", "Geok Soon", ""], ["Zhou", "Jun-Hong", ""], ["Tan", "Kay Chen", ""], ["Li", "Haizhou", ""], ["Xu", "Huan", ""], ["Hong", "Jihoon", ""], ["Chan", "Hian-Leng", ""]]}, {"id": "1805.00432", "submitter": "Duc Le", "authors": "V.Duc Le, Sang Kyun Cha", "title": "Real-time Air Pollution prediction model based on Spatiotemporal Big\n  data", "comments": "6 pages", "journal-ref": "The International Conference on Big data, IoT, and Cloud Computing\n  (BIC 2018)", "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air pollution is one of the most concerns for urban areas. Many countries\nhave constructed monitoring stations to hourly collect pollution values.\nRecently, there is a research in Daegu city, Korea for real-time air quality\nmonitoring via sensors installed on taxis running across the whole city. The\ncollected data is huge (1-second interval) and in both Spatial and Temporal\nformat. In this paper, based on this spatiotemporal Big data, we propose a\nreal-time air pollution prediction model based on Convolutional Neural Network\n(CNN) algorithm for image-like Spatial distribution of air pollution. Regarding\nto Temporal information in the data, we introduce a combination of a Long\nShort-Term Memory (LSTM) unit for time series data and a Neural Network model\nfor other air pollution impact factors such as weather conditions to build a\nhybrid prediction model. This model is simple in architecture but still brings\ngood prediction ability.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:36:12 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 00:55:20 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 02:35:34 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Le", "V. Duc", ""], ["Cha", "Sang Kyun", ""]]}, {"id": "1805.00500", "submitter": "Jeremiah Johnson", "authors": "Jeremiah W. Johnson", "title": "Adapting Mask-RCNN for Automatic Nucleus Segmentation", "comments": "7 pages, 3 figures", "journal-ref": "Proceedings of the 2019 Computer Vision Conference, Vol. 2", "doi": "10.1007/978-3-030-17798-0", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation of microscopy images is an important task in medical\nimage processing and analysis. Nucleus detection is an important example of\nthis task. Mask-RCNN is a recently proposed state-of-the-art algorithm for\nobject detection, object localization, and object instance segmentation of\nnatural images. In this paper we demonstrate that Mask-RCNN can be used to\nperform highly effective and efficient automatic segmentations of a wide range\nof microscopy images of cell nuclei, for a variety of cells acquired under a\nvariety of conditions.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 18:11:38 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Johnson", "Jeremiah W.", ""]]}, {"id": "1805.00503", "submitter": "Jessica Lee", "authors": "Xinyu Guan, Jessica Lee, Peter Wu, Yue Wu", "title": "Machine Learning for Exam Triage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we extend the state-of-the-art CheXNet (Rajpurkar et al.\n[2017]) by making use of the additional non-image features in the dataset. Our\nmodel produced better AUROC scores than the original CheXNet.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 03:49:22 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Guan", "Xinyu", ""], ["Lee", "Jessica", ""], ["Wu", "Peter", ""], ["Wu", "Yue", ""]]}, {"id": "1805.00521", "submitter": "Jingzhao Zhang", "authors": "Jingzhao Zhang, Aryan Mokhtari, Suvrit Sra, Ali Jadbabaie", "title": "Direct Runge-Kutta Discretization Achieves Acceleration", "comments": "24 pages. 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study gradient-based optimization methods obtained by directly\ndiscretizing a second-order ordinary differential equation (ODE) related to the\ncontinuous limit of Nesterov's accelerated gradient method. When the function\nis smooth enough, we show that acceleration can be achieved by a stable\ndiscretization of this ODE using standard Runge-Kutta integrators.\nSpecifically, we prove that under Lipschitz-gradient, convexity and\norder-$(s+2)$ differentiability assumptions, the sequence of iterates generated\nby discretizing the proposed second-order ODE converges to the optimal solution\nat a rate of $\\mathcal{O}({N^{-2\\frac{s}{s+1}}})$, where $s$ is the order of\nthe Runge-Kutta numerical integrator. Furthermore, we introduce a new local\nflatness condition on the objective, under which rates even faster than\n$\\mathcal{O}(N^{-2})$ can be achieved with low-order integrators and only\ngradient information. Notably, this flatness condition is satisfied by several\nstandard loss functions used in machine learning. We provide numerical\nexperiments that verify the theoretical rates predicted by our results.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 19:12:46 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 01:06:05 GMT"}, {"version": "v3", "created": "Sat, 19 May 2018 23:51:27 GMT"}, {"version": "v4", "created": "Fri, 14 Sep 2018 00:12:18 GMT"}, {"version": "v5", "created": "Wed, 28 Nov 2018 01:02:35 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Zhang", "Jingzhao", ""], ["Mokhtari", "Aryan", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1805.00528", "submitter": "Yu Li", "authors": "Yu Li, Hu Wang, Kangjia Mo, Tao Zeng", "title": "Reconstruction of Simulation-Based Physical Field by Reconstruction\n  Neural Network Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of modeling techniques have been developed in the past decade to\nreduce the computational expense and improve the accuracy of modeling. In this\nstudy, a new framework of modeling is suggested. Compared with other popular\nmethods, a distinctive characteristic is \"from image based model to analysis\nbased model (e.g. stress, strain, and deformation)\". In such a framework, a\nreconstruction neural network (ReConNN) model designed for simulation-based\nphysical field's reconstruction is proposed. The ReConNN contains two submodels\nthat are convolutional neural network (CNN) and generative adversarial net-work\n(GAN). The CNN is employed to construct the mapping between contour images of\nphysical field and objective function. Subsequently, the GAN is utilized to\ngenerate more images which are similar to the existing contour images. Finally,\nLagrange polynomial is applied to complete the reconstruction. However, the\nexisting CNN models are commonly applied to the classification tasks, which\nseem to be difficult to handle with regression tasks of images. Meanwhile, the\nexisting GAN architectures are insufficient to generate high-accuracy \"pseudo\ncontour images\". Therefore, a ReConNN model based on a Convolution in\nConvolution (CIC) and a Convolutional AutoEncoder based on Wasserstein\nGenerative Adversarial Network (WGAN-CAE) is suggested. To evaluate the\nperformance of the proposed model representatively, a classical topology\noptimization procedure is considered. Then the ReConNN is utilized to the\nreconstruction of heat transfer process of a pin fin heat sink. It demonstrates\nthat the proposed ReConNN model is proved to be a potential capability to\nreconstruct physical field for multidisciplinary, such as structural\noptimization.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 08:17:08 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 00:57:23 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 02:32:12 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Li", "Yu", ""], ["Wang", "Hu", ""], ["Mo", "Kangjia", ""], ["Zeng", "Tao", ""]]}, {"id": "1805.00533", "submitter": "Ping Li", "authors": "Ping Li", "title": "Sign-Full Random Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of 1-bit (\"sign-sign\") random projections has been a popular tool\nfor efficient search and machine learning on large datasets. Given two $D$-dim\ndata vectors $u$, $v\\in\\mathbb{R}^D$, one can generate $x = \\sum_{i=1}^D u_i\nr_i$, and $y = \\sum_{i=1}^D v_i r_i$, where $r_i\\sim N(0,1)$ iid. The\n\"collision probability\" is ${Pr}\\left(sgn(x)=sgn(y)\\right) =\n1-\\frac{\\cos^{-1}\\rho}{\\pi}$, where $\\rho = \\rho(u,v)$ is the cosine\nsimilarity.\n  We develop \"sign-full\" random projections by estimating $\\rho$ from (e.g.,)\nthe expectation $E(sgn(x)y)=\\sqrt{\\frac{2}{\\pi}} \\rho$, which can be further\nsubstantially improved by normalizing $y$. For nonnegative data, we recommend\nan interesting estimator based on $E\\left(y_- 1_{x\\geq 0} + y_+ 1_{x<0}\\right)$\nand its normalized version. The recommended estimator almost matches the\naccuracy of the (computationally expensive) maximum likelihood estimator. At\nhigh similarity ($\\rho\\rightarrow1$), the asymptotic variance of recommended\nestimator is only $\\frac{4}{3\\pi} \\approx 0.4$ of the estimator for sign-sign\nprojections. At small $k$ and high similarity, the improvement would be even\nmuch more substantial.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 08:41:21 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "1805.00559", "submitter": "Qunwei Li", "authors": "Baocheng Geng and Qunwei Li and Pramod K. Varshney", "title": "Decision Tree Design for Classification in Crowdsourcing Systems", "comments": "two columns, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel sequential paradigm for classification in\ncrowdsourcing systems. Considering that workers are unreliable and they perform\nthe tests with errors, we study the construction of decision trees so as to\nminimize the probability of mis-classification. By exploiting the connection\nbetween probability of mis-classification and entropy at each level of the\ndecision tree, we propose two algorithms for decision tree design. Furthermore,\nthe worker assignment problem is studied when workers can be assigned to\ndifferent tests of the decision tree to provide a trade-off between\nclassification cost and resulting error performance. Numerical results are\npresented for illustration.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 21:31:08 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Geng", "Baocheng", ""], ["Li", "Qunwei", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1805.00571", "submitter": "Matthew Hirn", "authors": "Michael Eickenberg, Georgios Exarchakis, Matthew Hirn, St\\'ephane\n  Mallat, Louis Thiry", "title": "Solid Harmonic Wavelet Scattering for Predictions of Molecule Properties", "comments": "Keywords: wavelets, electronic structure calculations, solid\n  harmonics, invariants, multilinear regression", "journal-ref": "J. Chem. Phys. 148, 241732 (2018)", "doi": "10.1063/1.5023798", "report-no": null, "categories": "physics.chem-ph cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning algorithm for the prediction of molecule\nproperties inspired by ideas from density functional theory. Using\nGaussian-type orbital functions, we create surrogate electronic densities of\nthe molecule from which we compute invariant \"solid harmonic scattering\ncoefficients\" that account for different types of interactions at different\nscales. Multi-linear regressions of various physical properties of molecules\nare computed from these invariant coefficients. Numerical experiments show that\nthese regressions have near state of the art performance, even with relatively\nfew training examples. Predictions over small sets of scattering coefficients\ncan reach a DFT precision while being interpretable.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 22:23:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Eickenberg", "Michael", ""], ["Exarchakis", "Georgios", ""], ["Hirn", "Matthew", ""], ["Mallat", "St\u00e9phane", ""], ["Thiry", "Louis", ""]]}, {"id": "1805.00579", "submitter": "Han Zhao", "authors": "Han Zhao, Shuayb Zarar, Ivan Tashev, Chin-Hui Lee", "title": "Convolutional-Recurrent Neural Networks for Speech Enhancement", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end model based on convolutional and recurrent neural\nnetworks for speech enhancement. Our model is purely data-driven and does not\nmake any assumptions about the type or the stationarity of the noise. In\ncontrast to existing methods that use multilayer perceptrons (MLPs), we employ\nboth convolutional and recurrent neural network architectures. Thus, our\napproach allows us to exploit local structures in both the frequency and\ntemporal domains. By incorporating prior knowledge of speech signals into the\ndesign of model structures, we build a model that is more data-efficient and\nachieves better generalization on both seen and unseen noise. Based on\nexperiments with synthetic data, we demonstrate that our model outperforms\nexisting methods, improving PESQ by up to 0.6 on seen noise and 0.64 on unseen\nnoise.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 00:06:53 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Zhao", "Han", ""], ["Zarar", "Shuayb", ""], ["Tashev", "Ivan", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "1805.00616", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Zhi-Hua Zhou", "title": "$\\ell_1$-regression with Heavy-tailed Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of linear regression with heavy-tailed\ndistributions. Different from previous studies that use the squared loss to\nmeasure the performance, we choose the absolute loss, which is capable of\nestimating the conditional median. To address the challenge that both the input\nand output could be heavy-tailed, we propose a truncated minimization problem,\nand demonstrate that it enjoys an $\\widetilde{O}(\\sqrt{d/n})$ excess risk,\nwhere $d$ is the dimensionality and $n$ is the number of samples. Compared with\ntraditional work on $\\ell_1$-regression, the main advantage of our result is\nthat we achieve a high-probability risk bound without exponential moment\nconditions on the input and output. Furthermore, if the input is bounded, we\nshow that the classical empirical risk minimization is competent for\n$\\ell_1$-regression even when the output is heavy-tailed.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 04:05:19 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 03:59:46 GMT"}, {"version": "v3", "created": "Mon, 4 Jun 2018 13:14:42 GMT"}, {"version": "v4", "created": "Thu, 25 Oct 2018 10:18:52 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Zhang", "Lijun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1805.00692", "submitter": "Flavio Teixeira", "authors": "Karin Schnass and Flavio Teixeira", "title": "Compressed Dictionary Learning", "comments": "5 figure, 4.6 pages per figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that the computational complexity of the Iterative\nThresholding and K-residual-Means (ITKrM) algorithm for dictionary learning can\nbe significantly reduced by using dimensionality-reduction techniques based on\nthe Johnson-Lindenstrauss lemma. The dimensionality reduction is efficiently\ncarried out with the fast Fourier transform. We introduce the Iterative\ncompressed-Thresholding and K-Means (IcTKM) algorithm for fast dictionary\nlearning and study its convergence properties. We show that IcTKM can locally\nrecover an incoherent, overcomplete generating dictionary of $K$ atoms from\ntraining signals of sparsity level $S$ with high probability. Fast dictionary\nlearning is achieved by embedding the training data and the dictionary into $m\n< d$ dimensions, and recovery is shown to be locally stable with an embedding\ndimension which scales as low as $m = O(S \\log^4 S \\log^3 K)$. The compression\neffectively shatters the data dimension bottleneck in the computational cost of\nITKrM, reducing it by a factor $O(m/d)$. Our theoretical results are\ncomplemented with numerical simulations which demonstrate that IcTKM is a\npowerful, low-cost algorithm for learning dictionaries from high-dimensional\ndata sets.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 09:27:49 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 20:24:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Schnass", "Karin", ""], ["Teixeira", "Flavio", ""]]}, {"id": "1805.00702", "submitter": "Bijay Neupane", "authors": "Bijay Neupane, Torben Bach Pedersen, and Bo Thiesson", "title": "Utilizing Device-level Demand Forecasting for Flexibility Markets - Full\n  Version", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uncertainty in the power supply due to fluctuating Renewable Energy\nSources (RES) has severe (financial and other) implications for energy market\nplayers. In this paper, we present a device-level Demand Response (DR) scheme\nthat captures the atomic (all available) flexibilities in energy demand and\nprovides the largest possible solution space to generate demand/supply\nschedules that minimize market imbalances. We evaluate the effectiveness and\nfeasibility of widely used forecasting models for device-level flexibility\nanalysis. In a typical device-level flexibility forecast, a market player is\nmore concerned with the \\textit{utility} that the demand flexibility brings to\nthe market, rather than the intrinsic forecast accuracy. In this regard, we\nprovide comprehensive predictive modeling and scheduling of demand flexibility\nfrom household appliances to demonstrate the (financial and otherwise)\nviability of introducing flexibility-based DR in the Danish/Nordic market.\nFurther, we investigate the correlation between the potential utility and the\naccuracy of the demand forecast model. Furthermore, we perform a number of\nexperiments to determine the data granularity that provides the best financial\nreward to market players for adopting the proposed DR scheme. A cost-benefit\nanalysis of forecast results shows that even with somewhat low forecast\naccuracy, market players can achieve regulation cost savings of 54% of the\ntheoretically optimal.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 09:55:57 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Neupane", "Bijay", ""], ["Pedersen", "Torben Bach", ""], ["Thiesson", "Bo", ""]]}, {"id": "1805.00705", "submitter": "Elham Jebal Barezi Sarbijan Ms", "authors": "Onno Kampman, Elham J. Barezi, Dario Bertero, Pascale Fung", "title": "Investigating Audio, Visual, and Text Fusion Methods for End-to-End\n  Automatic Personality Prediction", "comments": "Accepted at ACL2018 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tri-modal architecture to predict Big Five personality trait\nscores from video clips with different channels for audio, text, and video\ndata. For each channel, stacked Convolutional Neural Networks are employed. The\nchannels are fused both on decision-level and by concatenating their respective\nfully connected layers. It is shown that a multimodal fusion approach\noutperforms each single modality channel, with an improvement of 9.4\\% over the\nbest individual modality (video). Full backpropagation is also shown to be\nbetter than a linear combination of modalities, meaning complex interactions\nbetween modalities can be leveraged to build better models. Furthermore, we can\nsee the prediction relevance of each modality for each trait. The described\nmodel can be used to increase the emotional intelligence of virtual agents.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:03:13 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 07:20:31 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Kampman", "Onno", ""], ["Barezi", "Elham J.", ""], ["Bertero", "Dario", ""], ["Fung", "Pascale", ""]]}, {"id": "1805.00778", "submitter": "Bo Zhang", "authors": "Bo Zhang, Wei Li, Jie Hao, Xiao-Li Li and Meng Zhang", "title": "Adversarial adaptive 1-D convolutional neural networks for bearing fault\n  diagnosis under varying working condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional intelligent fault diagnosis of rolling bearings work well only\nunder a common assumption that the labeled training data (source domain) and\nunlabeled testing data (target domain) are drawn from the same distribution.\nHowever, in many real-world applications, this assumption does not hold,\nespecially when the working condition varies. In this paper, a new adversarial\nadaptive 1-D CNN called A2CNN is proposed to address this problem. A2CNN\nconsists of four parts, namely, a source feature extractor, a target feature\nextractor, a label classifier and a domain discriminator. The layers between\nthe source and target feature extractor are partially untied during the\ntraining stage to take both training efficiency and domain adaptation into\nconsideration. Experiments show that A2CNN has strong fault-discriminative and\ndomain-invariant capacity, and therefore can achieve high accuracy under\ndifferent working conditions. We also visualize the learned features and the\nnetworks to explore the reasons behind the high performance of our proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 13:15:24 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 02:51:16 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 07:13:32 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhang", "Bo", ""], ["Li", "Wei", ""], ["Hao", "Jie", ""], ["Li", "Xiao-Li", ""], ["Zhang", "Meng", ""]]}, {"id": "1805.00779", "submitter": "Toon Van Craenendonck", "authors": "Toon Van Craenendonck, Wannes Meert, Sebastijan Dumancic, Hendrik\n  Blockeel", "title": "COBRAS-TS: A new approach to Semi-Supervised Clustering of Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is ubiquitous in data analysis, including analysis of time series.\nIt is inherently subjective: different users may prefer different clusterings\nfor a particular dataset. Semi-supervised clustering addresses this by allowing\nthe user to provide examples of instances that should (not) be in the same\ncluster. This paper studies semi-supervised clustering in the context of time\nseries. We show that COBRAS, a state-of-the-art semi-supervised clustering\nmethod, can be adapted to this setting. We refer to this approach as COBRAS-TS.\nAn extensive experimental evaluation supports the following claims: (1)\nCOBRAS-TS far outperforms the current state of the art in semi-supervised\nclustering for time series, and thus presents a new baseline for the field; (2)\nCOBRAS-TS can identify clusters with separated components; (3) COBRAS-TS can\nidentify clusters that are characterized by small local patterns; (4) a small\namount of semi-supervision can greatly improve clustering quality for time\nseries; (5) the choice of the clustering algorithm matters (contrary to earlier\nclaims in the literature).\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 13:06:58 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Van Craenendonck", "Toon", ""], ["Meert", "Wannes", ""], ["Dumancic", "Sebastijan", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1805.00784", "submitter": "Maren Awiszus", "authors": "Maren Awiszus, Bodo Rosenhahn", "title": "Markov Chain Neural Networks", "comments": "Accepted for CVPR 2018 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a modified neural network model which is capable to\nsimulate Markov Chains. We show how to express and train such a network, how to\nensure given statistical properties reflected in the training data and we\ndemonstrate several applications where the network produces non-deterministic\noutcomes. One example is a random walker model, e.g. useful for simulation of\nBrownian motions or a natural Tic-Tac-Toe network which ensures\nnon-deterministic game behavior.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 13:19:11 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Awiszus", "Maren", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1805.00787", "submitter": "Jack Hall", "authors": "Jack Hall", "title": "Cognition in Dynamical Systems, Second Edition", "comments": "50 pages including references. Base file is `cognition.tex`. All\n  figures are generated by TikZ. This is a revised version of my doctoral\n  thesis, which was published under the name of John Wendell Hall since The\n  University of Texas at Austin required my full name. All of this work is\n  unpublished aside from the UT library, where the first edition is stored as\n  my dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognition is the process of knowing. As carried out by a dynamical system, it\nis the process by which the system absorbs information into its state. A\ncomplex network of agents cognizes knowledge about its environment, internal\ndynamics and initial state by forming emergent, macro-level patterns. Such\npatterns require each agent to find its place while partially aware of the\nwhole pattern. Such partial awareness can be achieved by separating the system\ndynamics into two parts by timescale: the propagation dynamics and the pattern\ndynamics. The fast propagation dynamics describe the spread of signals across\nthe network. If they converge to a fixed point for any quasi-static state of\nthe slow pattern dynamics, that fixed point represents an aggregate of\nmacro-level information. On longer timescales, agents coordinate via positive\nfeedback to form patterns, which are defined using closed walks in the graph of\nagents. Patterns can be coherent, in that every part of the pattern depends on\nevery other part for context. Coherent patterns are acausal, in that (a) they\ncannot be predicted and (b) no part of the stored knowledge can be mapped to\nany part of the pattern, or vice versa. A cognitive network's knowledge is\nencoded or embodied by the selection of patterns which emerge. The theory of\ncognition summarized here can model autocatalytic reaction-diffusion systems,\nartificial neural networks, market economies and ant colony optimization, among\nmany other real and virtual systems. This theory suggests a new understanding\nof complexity as a lattice of contexts rather than a single measure.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:12:08 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Hall", "Jack", ""]]}, {"id": "1805.00794", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Shayan Fazeli, and Majid Sarrafzadeh", "title": "ECG Heartbeat Classification: A Deep Transferable Representation", "comments": null, "journal-ref": null, "doi": "10.1109/ICHI.2018.00092", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) can be reliably used as a measure to monitor the\nfunctionality of the cardiovascular system. Recently, there has been a great\nattention towards accurate categorization of heartbeats. While there are many\ncommonalities between different ECG conditions, the focus of most studies has\nbeen classifying a set of conditions on a dataset annotated for that task\nrather than learning and employing a transferable knowledge between different\ntasks. In this paper, we propose a method based on deep convolutional neural\nnetworks for the classification of heartbeats which is able to accurately\nclassify five different arrhythmias in accordance with the AAMI EC57 standard.\nFurthermore, we suggest a method for transferring the knowledge acquired on\nthis task to the myocardial infarction (MI) classification task. We evaluated\nthe proposed method on PhysionNet's MIT-BIH and PTB Diagnostics datasets.\nAccording to the results, the suggested method is able to make predictions with\nthe average accuracies of 93.4% and 95.9% on arrhythmia classification and MI\nclassification, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 23:59:39 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 05:00:21 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Fazeli", "Shayan", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1805.00801", "submitter": "Anahita Namvar", "authors": "Anahita Namvar, Mohammad Siami, Fethi Rabhi, Mohsen Naderpour", "title": "Credit risk prediction in an imbalanced social lending environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit risk prediction is an effective way of evaluating whether a potential\nborrower will repay a loan, particularly in peer-to-peer lending where class\nimbalance problems are prevalent. However, few credit risk prediction models\nfor social lending consider imbalanced data and, further, the best resampling\ntechnique to use with imbalanced data is still controversial. In an attempt to\naddress these problems, this paper presents an empirical comparison of various\ncombinations of classifiers and resampling techniques within a novel risk\nassessment methodology that incorporates imbalanced data. The credit\npredictions from each combination are evaluated with a G-mean measure to avoid\nbias towards the majority class, which has not been considered in similar\nstudies. The results reveal that combining random forest and random\nunder-sampling may be an effective strategy for calculating the credit risk\nassociated with loan applicants in social lending markets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 12:54:40 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Namvar", "Anahita", ""], ["Siami", "Mohammad", ""], ["Rabhi", "Fethi", ""], ["Naderpour", "Mohsen", ""]]}, {"id": "1805.00811", "submitter": "Victoria Hodge", "authors": "Victoria J. Hodge and Jim Austin", "title": "An Evaluation of Classification and Outlier Detection Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper evaluates algorithms for classification and outlier detection\naccuracies in temporal data. We focus on algorithms that train and classify\nrapidly and can be used for systems that need to incorporate new data\nregularly. Hence, we compare the accuracy of six fast algorithms using a range\nof well-known time-series datasets. The analyses demonstrate that the choice of\nalgorithm is task and data specific but that we can derive heuristics for\nchoosing. Gradient Boosting Machines are generally best for classification but\nthere is no single winner for outlier detection though Gradient Boosting\nMachines (again) and Random Forest are better. Hence, we recommend running\nevaluations of a number of algorithms using our heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 13:50:15 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Hodge", "Victoria J.", ""], ["Austin", "Jim", ""]]}, {"id": "1805.00861", "submitter": "Oscar Claveria", "authors": "Oscar Claveria, Enric Monte, Salvador Torra", "title": "Modelling cross-dependencies between Spain's regional tourism markets\n  with an extension of the Gaussian process regression model", "comments": "17 pages 2 figures, 3 tables", "journal-ref": "Claveria, O., Monte, E., and Torra, S. (2016): Modelling\n  cross-dependencies between Spain's regional tourism markets with an extension\n  of the Gaussian process regression model. SERIEs, 7 (3), 341-357", "doi": "10.1007/s13209-016-0144-7", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents an extension of the Gaussian process regression model for\nmultiple-input multiple-output forecasting. This approach allows modelling the\ncross-dependencies between a given set of input variables and generating a\nvectorial prediction. Making use of the existing correlations in international\ntourism demand to all seventeen regions of Spain, the performance of the\nproposed model is assessed in a multiple-step-ahead forecasting comparison. The\nresults of the experiment in a multivariate setting show that the Gaussian\nprocess regression model significantly improves the forecasting accuracy of a\nmulti-layer perceptron neural network used as a benchmark. The results reveal\nthat incorporating the connections between different markets in the modelling\nprocess may prove very useful to refine predictions at a regional level.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 15:16:43 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Claveria", "Oscar", ""], ["Monte", "Enric", ""], ["Torra", "Salvador", ""]]}, {"id": "1805.00868", "submitter": "Zeren Tan", "authors": "Zeren Tan and Ruimin Li", "title": "A Dynamic Model for Traffic Flow Prediction Using Improved DRN", "comments": "15 pages, 11 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Real-time traffic flow prediction can not only provide travelers with\nreliable traffic information so that it can save people's time, but also assist\nthe traffic management agency to manage traffic system. It can greatly improve\nthe efficiency of the transportation system. Traditional traffic flow\nprediction approaches usually need a large amount of data but still give poor\nperformances. With the development of deep learning, researchers begin to pay\nattention to artificial neural networks (ANNs) such as RNN and LSTM. However,\nthese ANNs are very time-consuming. In our research, we improve the Deep\nResidual Network and build a dynamic model which previous researchers hardly\nuse. We firstly integrate the input and output of the $i^{th}$ layer to the\ninput of the $i+1^{th}$ layer and prove that each layer will fit a simpler\nfunction so that the error rate will be much smaller. Then, we use the concept\nof online learning in our model to update pre-trained model during prediction.\nOur result shows that our model has higher accuracy than some state-of-the-art\nmodels. In addition, our dynamic model can perform better in practical\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 15:35:52 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 07:57:12 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 15:50:43 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 17:25:59 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Tan", "Zeren", ""], ["Li", "Ruimin", ""]]}, {"id": "1805.00869", "submitter": "Yann Ollivier", "authors": "Yann Ollivier", "title": "Approximate Temporal Difference Learning is a Gradient Descent for\n  Reversible Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, temporal difference (TD) is the most direct\nalgorithm to learn the value function of a policy. For large or infinite state\nspaces, exact representations of the value function are usually not available,\nand it must be approximated by a function in some parametric family.\n  However, with \\emph{nonlinear} parametric approximations (such as neural\nnetworks), TD is not guaranteed to converge to a good approximation of the true\nvalue function within the family, and is known to diverge even in relatively\nsimple cases. TD lacks an interpretation as a stochastic gradient descent of an\nerror between the true and approximate value functions, which would provide\nsuch guarantees.\n  We prove that approximate TD is a gradient descent provided the current\npolicy is \\emph{reversible}. This holds even with nonlinear approximations.\n  A policy with transition probabilities $P(s,s')$ between states is reversible\nif there exists a function $\\mu$ over states such that\n$\\frac{P(s,s')}{P(s',s)}=\\frac{\\mu(s')}{\\mu(s)}$. In particular, every move can\nbe undone with some probability. This condition is restrictive; it is\nsatisfied, for instance, for a navigation problem in any unoriented graph.\n  In this case, approximate TD is exactly a gradient descent of the\n\\emph{Dirichlet norm}, the norm of the difference of \\emph{gradients} between\nthe true and approximate value functions. The Dirichlet norm also controls the\nbias of approximate policy gradient. These results hold even with no decay\nfactor ($\\gamma=1$) and do not rely on contractivity of the Bellman operator,\nthus proving stability of TD even with $\\gamma=1$ for reversible policies.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 15:40:24 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Ollivier", "Yann", ""]]}, {"id": "1805.00878", "submitter": "Oscar Claveria", "authors": "Oscar Claveria, Enric Monte, Salvador Torra", "title": "Modelling tourism demand to Spain with machine learning techniques. The\n  impact of forecast horizon on model selection", "comments": "24 pages, 3 figures, 6 tables", "journal-ref": "Claveria, O., Monte, E., and Torra, S. (2016): Modelling tourism\n  demand to Spain with machine learning techniques. The impact of forecast\n  horizon on model selection. Revista de Economia Aplicada, 24 (72), 109-132", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study assesses the influence of the forecast horizon on the forecasting\nperformance of several machine learning techniques. We compare the fo recast\naccuracy of Support Vector Regression (SVR) to Neural Network (NN) models,\nusing a linear model as a benchmark. We focus on international tourism demand\nto all seventeen regions of Spain. The SVR with a Gaussian radial basis\nfunction kernel outperforms the rest of the models for the longest forecast\nhorizons. We also find that machine learning methods improve their forecasting\naccuracy with respect to linear models as forecast horizons increase. This\nresult shows the suitability of SVR for medium and long term forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 15:48:11 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Claveria", "Oscar", ""], ["Monte", "Enric", ""], ["Torra", "Salvador", ""]]}, {"id": "1805.00899", "submitter": "Geoffrey Irving", "authors": "Geoffrey Irving, Paul Christiano, Dario Amodei", "title": "AI safety via debate", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make AI systems broadly useful for challenging real-world tasks, we need\nthem to learn complex human goals and preferences. One approach to specifying\ncomplex goals asks humans to judge during training which agent behaviors are\nsafe and useful, but this approach can fail if the task is too complicated for\na human to directly judge. To help address this concern, we propose training\nagents via self play on a zero sum debate game. Given a question or proposed\naction, two agents take turns making short statements up to a limit, then a\nhuman judges which of the agents gave the most true, useful information. In an\nanalogy to complexity theory, debate with optimal play can answer any question\nin PSPACE given polynomial time judges (direct judging answers only NP\nquestions). In practice, whether debate works involves empirical questions\nabout humans and the tasks we want AIs to perform, plus theoretical questions\nabout the meaning of AI alignment. We report results on an initial MNIST\nexperiment where agents compete to convince a sparse classifier, boosting the\nclassifier's accuracy from 59.4% to 88.9% given 6 pixels and from 48.2% to\n85.2% given 4 pixels. Finally, we discuss theoretical and practical aspects of\nthe debate model, focusing on potential weaknesses as the model scales up, and\nwe propose future human and computer experiments to test these properties.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 16:27:32 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 17:36:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Irving", "Geoffrey", ""], ["Christiano", "Paul", ""], ["Amodei", "Dario", ""]]}, {"id": "1805.00909", "submitter": "Sergey Levine", "authors": "Sergey Levine", "title": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial\n  and Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of reinforcement learning or optimal control provides a\nmathematical formalization of intelligent decision making that is powerful and\nbroadly applicable. While the general form of the reinforcement learning\nproblem enables effective reasoning about uncertainty, the connection between\nreinforcement learning and inference in probabilistic models is not immediately\nobvious. However, such a connection has considerable value when it comes to\nalgorithm design: formalizing a problem as probabilistic inference in principle\nallows us to bring to bear a wide array of approximate inference tools, extend\nthe model in flexible and powerful ways, and reason about compositionality and\npartial observability. In this article, we will discuss how a generalization of\nthe reinforcement learning or optimal control problem, which is sometimes\ntermed maximum entropy reinforcement learning, is equivalent to exact\nprobabilistic inference in the case of deterministic dynamics, and variational\ninference in the case of stochastic dynamics. We will present a detailed\nderivation of this framework, overview prior work that has drawn on this and\nrelated ideas to propose new reinforcement learning and control algorithms, and\ndescribe perspectives on future research.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:11:20 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 16:14:58 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 20:03:59 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Levine", "Sergey", ""]]}, {"id": "1805.00915", "submitter": "Grant Rotskoff", "authors": "Grant M. Rotskoff and Eric Vanden-Eijnden", "title": "Trainability and Accuracy of Neural Networks: An Interacting Particle\n  System Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks, a central tool in machine learning, have demonstrated\nremarkable, high fidelity performance on image recognition and classification\ntasks. These successes evince an ability to accurately represent high\ndimensional functions, but rigorous results about the approximation error of\nneural networks after training are few. Here we establish conditions for global\nconvergence of the standard optimization algorithm used in machine learning\napplications, stochastic gradient descent (SGD), and quantify the scaling of\nits error with the size of the network. This is done by reinterpreting SGD as\nthe evolution of a particle system with interactions governed by a potential\nrelated to the objective or \"loss\" function used to train the network. We show\nthat, when the number $n$ of units is large, the empirical distribution of the\nparticles descends on a convex landscape towards the global minimum at a rate\nindependent of $n$, with a resulting approximation error that universally\nscales as $O(n^{-1})$. These properties are established in the form of a Law of\nLarge Numbers and a Central Limit Theorem for the empirical distribution. Our\nanalysis also quantifies the scale and nature of the noise introduced by SGD\nand provides guidelines for the step size and batch size to use when training a\nneural network. We illustrate our findings on examples in which we train neural\nnetworks to learn the energy function of the continuous 3-spin model on the\nsphere. The approximation error scales as our analysis predicts in as high a\ndimension as $d=25$.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:23:42 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 15:03:44 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 14:20:51 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Rotskoff", "Grant M.", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "1805.00917", "submitter": "Michael Gensheimer", "authors": "Michael F. Gensheimer, Balasubramanian Narasimhan", "title": "A Scalable Discrete-Time Survival Model for Neural Networks", "comments": null, "journal-ref": null, "doi": "10.7717/peerj.6257", "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is currently great interest in applying neural networks to prediction\ntasks in medicine. It is important for predictive models to be able to use\nsurvival data, where each patient has a known follow-up time and\nevent/censoring indicator. This avoids information loss when training the model\nand enables generation of predicted survival curves. In this paper, we describe\na discrete-time survival model that is designed to be used with neural\nnetworks, which we refer to as Nnet-survival. The model is trained with the\nmaximum likelihood method using minibatch stochastic gradient descent (SGD).\nThe use of SGD enables rapid convergence and application to large datasets that\ndo not fit in memory. The model is flexible, so that the baseline hazard rate\nand the effect of the input data on hazard probability can vary with follow-up\ntime. It has been implemented in the Keras deep learning framework, and source\ncode for the model and several examples is available online. We demonstrate the\nperformance of the model on both simulated and real data and compare it to\nexisting models Cox-nnet and Deepsurv.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:26:09 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 02:40:07 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 22:57:54 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Gensheimer", "Michael F.", ""], ["Narasimhan", "Balasubramanian", ""]]}, {"id": "1805.00928", "submitter": "Erol Cromwell", "authors": "Erol Cromwell, Donna Flynn", "title": "Lidar Cloud Detection with Fully Convolutional Networks", "comments": "Updated for full version of paper. 10 pages, submitted to NIPS 2018\n  Conference (in review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we present a novel approach for segmenting laser radar\n(lidar) imagery into geometric time-height cloud locations with a fully\nconvolutional network (FCN). We describe a semi-supervised learning method to\ntrain the FCN by: pre-training the classification layers of the FCN with\nimage-level annotations, pre-training the entire FCN with the cloud locations\nof the MPLCMASK cloud mask algorithm, and fully supervised learning with\nhand-labeled cloud locations. We show the model achieves higher levels of cloud\nidentification compared to the cloud mask algorithm implementation.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:46:42 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 23:39:33 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Cromwell", "Erol", ""], ["Flynn", "Donna", ""]]}, {"id": "1805.00979", "submitter": "Tivadar Danka", "authors": "Tivadar Danka, Peter Horvath", "title": "modAL: A modular active learning framework for Python", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  modAL is a modular active learning framework for Python, aimed to make active\nlearning research and practice simpler. Its distinguishing features are (i)\nclear and modular object oriented design (ii) full compatibility with\nscikit-learn models and workflows. These features make fast prototyping and\neasy extensibility possible, aiding the development of real-life active\nlearning pipelines and novel algorithms as well. modAL is fully open source,\nhosted on GitHub at https://github.com/cosmic-cortex/modAL. To assure code\nquality, extensive unit tests are provided and continuous integration is\napplied. In addition, a detailed documentation with several tutorials are also\navailable for ease of use. The framework is available in PyPI and distributed\nunder the MIT license.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 18:52:09 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 08:03:23 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Danka", "Tivadar", ""], ["Horvath", "Peter", ""]]}, {"id": "1805.00980", "submitter": "Safa Cicek", "authors": "Safa Cicek, Alhussein Fawzi and Stefano Soatto", "title": "SaaS: Speed as a Supervisor for Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the SaaS Algorithm for semi-supervised learning, which uses\nlearning speed during stochastic gradient descent in a deep neural network to\nmeasure the quality of an iterative estimate of the posterior probability of\nunknown labels. Training speed in supervised learning correlates strongly with\nthe percentage of correct labels, so we use it as an inference criterion for\nthe unknown labels, without attempting to infer the model parameters at first.\nDespite its simplicity, SaaS achieves state-of-the-art results in\nsemi-supervised learning benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 18:52:18 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Cicek", "Safa", ""], ["Fawzi", "Alhussein", ""], ["Soatto", "Stefano", ""]]}, {"id": "1805.00982", "submitter": "Anant Raj", "authors": "Anant Raj, Sebastian U. Stich", "title": "k-SVRG: Variance Reduction for Large Scale Optimization", "comments": "The title of the previous version of the manuscript was \"SVRG meets\n  SAGA: k-SVRG A Tale of Limited Memory\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduced stochastic gradient (SGD) methods converge significantly\nfaster than the vanilla SGD counterpart. However, these methods are not very\npractical on large scale problems, as they either i) require frequent passes\nover the full data to recompute gradients---without making any progress during\nthis time (like for SVRG), or ii)~they require additional memory that can\nsurpass the size of the input problem (like for SAGA). In this work, we propose\n$k$-SVRG that addresses these issues by making best use of the \\emph{available}\nmemory and minimizes the stalling phases without progress. We prove linear\nconvergence of $k$-SVRG on strongly convex problems and convergence to\nstationary points on non-convex problems. Numerical experiments show the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 19:01:22 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 12:42:13 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Raj", "Anant", ""], ["Stich", "Sebastian U.", ""]]}, {"id": "1805.00987", "submitter": "Laurynas Karazija", "authors": "Laurynas Karazija, Petar Veli\\v{c}kovi\\'c, and Pietro Li\\`o", "title": "Automatic Inference of Cross-modal Connection Topologies for X-CNNs", "comments": "10 pages, 3 figures, 2 tables, to appear in ISNN 2018", "journal-ref": null, "doi": "10.1007/978-3-319-92537-0_7", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a way to learn cross-modal convolutional neural network\n(X-CNN) architectures from a base convolutional network (CNN) and the training\ndata to reduce the design cost and enable applying cross-modal networks in\nsparse data environments. Two approaches for building X-CNNs are presented. The\nbase approach learns the topology in a data-driven manner, by using\nmeasurements performed on the base CNN and supplied data. The iterative\napproach performs further optimisation of the topology through a combined\nlearning procedure, simultaneously learning the topology and training the\nnetwork. The approaches were evaluated agains examples of hand-designed X-CNNs\nand their base variants, showing superior performance and, in some cases,\ngaining an additional 9% of accuracy. From further considerations, we conclude\nthat the presented methodology takes less time than any manual approach would,\nwhilst also significantly reducing the design complexity. The application of\nthe methods is fully automated and implemented in Xsertion library.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 19:16:17 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Karazija", "Laurynas", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1805.01033", "submitter": "Qun Liu", "authors": "Qun Liu, Supratik Mukhopadhyay", "title": "Unsupervised Learning using Pretrained CNN and Associative Memory Bank", "comments": "Paper was accepted at the 2018 International Joint Conference on\n  Neural Networks (IJCNN 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional features extracted from a comprehensive labeled dataset,\ncontain substantial representations which could be effectively used in a new\ndomain. Despite the fact that generic features achieved good results in many\nvisual tasks, fine-tuning is required for pretrained deep CNN models to be more\neffective and provide state-of-the-art performance. Fine tuning using the\nbackpropagation algorithm in a supervised setting, is a time and resource\nconsuming process. In this paper, we present a new architecture and an approach\nfor unsupervised object recognition that addresses the above mentioned problem\nwith fine tuning associated with pretrained CNN-based supervised deep learning\napproaches while allowing automated feature extraction. Unlike existing works,\nour approach is applicable to general object recognition tasks. It uses a\npretrained (on a related domain) CNN model for automated feature extraction\npipelined with a Hopfield network based associative memory bank for storing\npatterns for classification purposes. The use of associative memory bank in our\nframework allows eliminating backpropagation while providing competitive\nperformance on an unseen dataset.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 21:32:08 GMT"}], "update_date": "2018-05-06", "authors_parsed": [["Liu", "Qun", ""], ["Mukhopadhyay", "Supratik", ""]]}, {"id": "1805.01044", "submitter": "Haider Raza", "authors": "Haider Raza, Dheeraj Rathee, ShangMing Zhou, Hubert Cecotti, Girijesh\n  Prasad", "title": "Covariate Shift Estimation based Adaptive Ensemble Learning for Handling\n  Non-Stationarity in Motor Imagery related EEG-based Brain-Computer Interface", "comments": "28 Pages, 3 figures, Neurocomputing", "journal-ref": "Neurocomputing 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-stationary nature of electroencephalography (EEG) signals makes an\nEEG-based brain-computer interface (BCI) a dynamic system, thus improving its\nperformance is a challenging task. In addition, it is well-known that due to\nnon-stationarity based covariate shifts, the input data distributions of\nEEG-based BCI systems change during inter- and intra-session transitions, which\nposes great difficulty for developments of online adaptive data-driven systems.\nEnsemble learning approaches have been used previously to tackle this\nchallenge. However, passive scheme based implementation leads to poor\nefficiency while increasing high computational cost. This paper presents a\nnovel integration of covariate shift estimation and unsupervised adaptive\nensemble learning (CSE-UAEL) to tackle non-stationarity in motor-imagery (MI)\nrelated EEG classification. The proposed method first employs an exponentially\nweighted moving average model to detect the covariate shifts in the common\nspatial pattern features extracted from MI related brain responses. Then, a\nclassifier ensemble was created and updated over time to account for changes in\nstreaming input data distribution wherein new classifiers are added to the\nensemble in accordance with estimated shifts. Furthermore, using two publicly\navailable BCI-related EEG datasets, the proposed method was extensively\ncompared with the state-of-the-art single-classifier based passive scheme,\nsingle-classifier based active scheme and ensemble based passive schemes. The\nexperimental results show that the proposed active scheme based ensemble\nlearning algorithm significantly enhances the BCI performance in MI\nclassifications.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 22:21:38 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Raza", "Haider", ""], ["Rathee", "Dheeraj", ""], ["Zhou", "ShangMing", ""], ["Cecotti", "Hubert", ""], ["Prasad", "Girijesh", ""]]}, {"id": "1805.01045", "submitter": "Jean-Baptiste Regli", "authors": "Jean-Baptiste Regli, Ricardo Silva", "title": "Alpha-Beta Divergence For Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a variational approximation framework using direct\noptimization of what is known as the {\\it scale invariant Alpha-Beta\ndivergence} (sAB divergence). This new objective encompasses most variational\nobjectives that use the Kullback-Leibler, the R{\\'e}nyi or the gamma\ndivergences. It also gives access to objective functions never exploited before\nin the context of variational inference. This is achieved via two easy to\ninterpret control parameters, which allow for a smooth interpolation over the\ndivergence space while trading-off properties such as mass-covering of a target\ndistribution and robustness to outliers in the data. Furthermore, the sAB\nvariational objective can be optimized directly by repurposing existing methods\nfor Monte Carlo computation of complex variational objectives, leading to\nestimates of the divergence instead of variational lower bounds. We show the\nadvantages of this objective on Bayesian models for regression problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 22:22:07 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 18:56:16 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Regli", "Jean-Baptiste", ""], ["Silva", "Ricardo", ""]]}, {"id": "1805.01049", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Dong Guo, Cauligi S. Raghavendra, Paul Thompson", "title": "Large-Scale Unsupervised Deep Representation Learning for Brain\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is increasingly being used for computer aided diagnosis\nof brain related disorders based on structural magnetic resonance imaging (MRI)\ndata. Most of such work employs biologically and medically meaningful\nhand-crafted features calculated from different regions of the brain. The\nconstruction of such highly specialized features requires a considerable amount\nof time, manual oversight and careful quality control to ensure the absence of\nerrors in the computational process. Recent advances in Deep Representation\nLearning have shown great promise in extracting highly non-linear and\ninformation-rich features from data. In this paper, we present a novel\nlarge-scale deep unsupervised approach to learn generic feature representations\nof structural brain MRI scans, which requires no specialized domain knowledge\nor manual intervention. Our method produces low-dimensional representations of\nbrain structure, which can be used to reconstruct brain images with very low\nerror and exhibit performance comparable to FreeSurfer features on various\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 22:51:34 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Guo", "Dong", ""], ["Raghavendra", "Cauligi S.", ""], ["Thompson", "Paul", ""]]}, {"id": "1805.01078", "submitter": "Zhaoqi Li", "authors": "Zhaoqi Li, Yu Ma, Catalina Vajiac, Yunkai Zhang", "title": "Exploration of Numerical Precision in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced numerical precision is a common technique to reduce computational\ncost in many Deep Neural Networks (DNNs). While it has been observed that DNNs\nare resilient to small errors and noise, no general result exists that is\ncapable of predicting a given DNN system architecture's sensitivity to reduced\nprecision. In this project, we emulate arbitrary bit-width using a specified\nfloating-point representation with a truncation method, which is applied to the\nneural network after each batch. We explore the impact of several model\nparameters on the network's training accuracy and show results on the MNIST\ndataset. We then present a preliminary theoretical investigation of the error\nscaling in both forward and backward propagations. We end with a discussion of\nthe implications of these results as well as the potential for generalization\nto other network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 01:39:30 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Li", "Zhaoqi", ""], ["Ma", "Yu", ""], ["Vajiac", "Catalina", ""], ["Zhang", "Yunkai", ""]]}, {"id": "1805.01087", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma, Zecong Hu, Jingzhou Liu, Nanyun Peng, Graham Neubig, Eduard\n  Hovy", "title": "Stack-Pointer Networks for Dependency Parsing", "comments": "Accepted by ACL-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel architecture for dependency parsing: \\emph{stack-pointer\nnetworks} (\\textbf{\\textsc{StackPtr}}). Combining pointer\nnetworks~\\citep{vinyals2015pointer} with an internal stack, the proposed model\nfirst reads and encodes the whole sentence, then builds the dependency tree\ntop-down (from root-to-leaf) in a depth-first fashion. The stack tracks the\nstatus of the depth-first search and the pointer networks select one child for\nthe word at the top of the stack at each step. The \\textsc{StackPtr} parser\nbenefits from the information of the whole sentence and all previously derived\nsubtree structures, and removes the left-to-right restriction in classical\ntransition-based parsers. Yet, the number of steps for building any (including\nnon-projective) parse tree is linear in the length of the sentence just as\nother transition-based parsers, yielding an efficient decoding algorithm with\n$O(n^2)$ time complexity. We evaluate our model on 29 treebanks spanning 20\nlanguages and different dependency annotation schemas, and achieve\nstate-of-the-art performance on 21 of them.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 02:23:28 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Ma", "Xuezhe", ""], ["Hu", "Zecong", ""], ["Liu", "Jingzhou", ""], ["Peng", "Nanyun", ""], ["Neubig", "Graham", ""], ["Hovy", "Eduard", ""]]}, {"id": "1805.01089", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Junyang Lin, Xuancheng Ren", "title": "A Hierarchical End-to-End Model for Jointly Improving Text Summarization\n  and Sentiment Classification", "comments": "accepted by IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization and sentiment classification both aim to capture the main\nideas of the text but at different levels. Text summarization is to describe\nthe text within a few sentences, while sentiment classification can be regarded\nas a special type of summarization which \"summarizes\" the text into a even more\nabstract fashion, i.e., a sentiment class. Based on this idea, we propose a\nhierarchical end-to-end model for joint learning of text summarization and\nsentiment classification, where the sentiment classification label is treated\nas the further \"summarization\" of the text summarization output. Hence, the\nsentiment classification layer is put upon the text summarization layer, and a\nhierarchical structure is derived. Experimental results on Amazon online\nreviews datasets show that our model achieves better performance than the\nstrong baseline systems on both abstractive summarization and sentiment\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 02:30:07 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 03:30:35 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Lin", "Junyang", ""], ["Ren", "Xuancheng", ""]]}, {"id": "1805.01128", "submitter": "Hojung Lee", "authors": "Hojung Lee, Jong-seok Lee", "title": "Local Critic Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach to train deep neural networks by\nunlocking the layer-wise dependency of backpropagation training. The approach\nemploys additional modules called local critic networks besides the main\nnetwork model to be trained, which are used to obtain error gradients without\ncomplete feedforward and backward propagation processes. We propose a cascaded\nlearning strategy for these local networks. In addition, the approach is also\nuseful from multi-model perspectives, including structural optimization of\nneural networks, computationally efficient progressive inference, and ensemble\nclassification for performance improvement. Experimental results show the\neffectiveness of the proposed approach and suggest guidelines for determining\nappropriate algorithm parameters.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 05:56:23 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 04:47:43 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Lee", "Hojung", ""], ["Lee", "Jong-seok", ""]]}, {"id": "1805.01136", "submitter": "Ningyuan Chen", "authors": "Ningyuan Chen, Guillermo Gallego", "title": "Nonparametric Pricing Analytics with Customer Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized pricing analytics is becoming an essential tool in retailing.\nUpon observing the personalized information of each arriving customer, the firm\nneeds to set a price accordingly based on the covariates such as income,\neducation background, past purchasing history to extract more revenue. For new\nentrants of the business, the lack of historical data may severely limit the\npower and profitability of personalized pricing. We propose a nonparametric\npricing policy to simultaneously learn the preference of customers based on the\ncovariates and maximize the expected revenue over a finite horizon. The policy\ndoes not depend on any prior assumptions on how the personalized information\naffects consumers' preferences (such as linear models). It is adaptively splits\nthe covariate space into smaller bins (hyper-rectangles) and clusters customers\nbased on their covariates and preferences, offering similar prices for\ncustomers who belong to the same cluster trading off granularity and accuracy.\nWe show that the algorithm achieves a regret of order $O(\\log(T)^2\nT^{(2+d)/(4+d)})$, where $T$ is the length of the horizon and $d$ is the\ndimension of the covariate. It improves the current regret in the literature\n\\citep{slivkins2014contextual}, under mild technical conditions in the pricing\ncontext (smoothness and local concavity). We also prove that no policy can\nachieve a regret less than $O(T^{(2+d)/(4+d)})$ for a particular instance and\nthus demonstrate the near optimality of the proposed policy.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 06:42:27 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 02:14:33 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 03:16:36 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chen", "Ningyuan", ""], ["Gallego", "Guillermo", ""]]}, {"id": "1805.01156", "submitter": "Ville Vestman", "authors": "Ville Vestman and Tomi Kinnunen", "title": "Supervector Compression Strategies to Speed up I-Vector System\n  Development", "comments": "To appear in Speaker Odyssey 2018: The Speaker and Language\n  Recognition Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The front-end factor analysis (FEFA), an extension of principal component\nanalysis (PPCA) tailored to be used with Gaussian mixture models (GMMs), is\ncurrently the prevalent approach to extract compact utterance-level features\n(i-vectors) for automatic speaker verification (ASV) systems. Little research\nhas been conducted comparing FEFA to the conventional PPCA applied to maximum a\nposteriori (MAP) adapted GMM supervectors. We study several alternative\nmethods, including PPCA, factor analysis (FA), and two supervised approaches,\nsupervised PPCA (SPPCA) and the recently proposed probabilistic partial least\nsquares (PPLS), to compress MAP-adapted GMM supervectors. The resulting\ni-vectors are used in ASV tasks with a probabilistic linear discriminant\nanalysis (PLDA) back-end. We experiment on two different datasets, on the\ntelephone condition of NIST SRE 2010 and on the recent VoxCeleb corpus\ncollected from YouTube videos containing celebrity interviews recorded in\nvarious acoustical and technical conditions. The results suggest that, in terms\nof ASV accuracy, the supervector compression approaches are on a par with FEFA.\nThe supervised approaches did not result in improved performance. In comparison\nto FEFA, we obtained more than hundred-fold (100x) speedups in the total\nvariability model (TVM) training using the PPCA and FA supervector compression\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 08:12:39 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Vestman", "Ville", ""], ["Kinnunen", "Tomi", ""]]}, {"id": "1805.01157", "submitter": "Jiaxu Cui", "authors": "Jiaxu Cui and Bo Yang", "title": "Graph Bayesian Optimization: Algorithms, Evaluations and Applications", "comments": "This work is in progress, and contains 27 pages, 14 figures, an\n  appendix, the contrast algorithm in last experiment ( see Figure 11)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network structure optimization is a fundamental task in complex network\nanalysis. However, almost all the research on Bayesian optimization is aimed at\noptimizing the objective functions with vectorial inputs. In this work, we\nfirst present a flexible framework, denoted graph Bayesian optimization, to\nhandle arbitrary graphs in the Bayesian optimization community. By combining\nthe proposed framework with graph kernels, it can take full advantage of\nimplicit graph structural features to supplement explicit features guessed\naccording to the experience, such as tags of nodes and any attributes of\ngraphs. The proposed framework can identify which features are more important\nduring the optimization process. We apply the framework to solve four problems\nincluding two evaluations and two applications to demonstrate its efficacy and\npotential applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 08:13:48 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 13:49:41 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 08:45:29 GMT"}, {"version": "v4", "created": "Tue, 6 Nov 2018 06:49:13 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Cui", "Jiaxu", ""], ["Yang", "Bo", ""]]}, {"id": "1805.01162", "submitter": "Qun Liu", "authors": "Qun Liu, Suman Kumar, Vijay Mago", "title": "SafeRNet: Safe Transportation Routing in the era of Internet of Vehicles\n  and Mobile Crowd Sensing", "comments": "Paper was accepted at the 14th IEEE Consumer Communications &\n  Networking Conference (CCNC 2017)", "journal-ref": null, "doi": "10.1109/CCNC.2017.7983123", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World wide road traffic fatality and accident rates are high, and this is\ntrue even in technologically advanced countries like the USA. Despite the\nadvances in Intelligent Transportation Systems, safe transportation routing\ni.e., finding safest routes is largely an overlooked paradigm. In recent years,\nlarge amount of traffic data has been produced by people, Internet of Vehicles\nand Internet of Things (IoT). Also, thanks to advances in cloud computing and\nproliferation of mobile communication technologies, it is now possible to\nperform analysis on vast amount of generated data (crowd sourced) and deliver\nthe result back to users in real time. This paper proposes SafeRNet, a safe\nroute computation framework which takes advantage of these technologies to\nanalyze streaming traffic data and historical data to effectively infer safe\nroutes and deliver them back to users in real time. SafeRNet utilizes Bayesian\nnetwork to formulate safe route model. Furthermore, a case study is presented\nto demonstrate the effectiveness of our approach using real traffic data.\nSafeRNet intends to improve drivers safety in a modern technology rich\ntransportation system.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 08:22:27 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Liu", "Qun", ""], ["Kumar", "Suman", ""], ["Mago", "Vijay", ""]]}, {"id": "1805.01174", "submitter": "Benjamin Donnot", "authors": "Benjamin Donnot (TAU, LRI), Isabelle Guyon (TAU, LRI, UP11), Antoine\n  Marot, Marc Schoenauer (LRI, TAU), Patrick Panciatici", "title": "Optimization of computational budget for power system risk assessment", "comments": null, "journal-ref": "2018 IEEE PES Innovative Smart Grid Technologies Conference\n  Europe, Oct 2018, Sarajevo, Bosnia and Herzegovina. 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of maintaining high voltage power transmission\nnetworks in security at all time, namely anticipating exceeding of thermal\nlimit for eventual single line disconnection (whatever its cause may be) by\nrunning slow, but accurate, physical grid simulators. New conceptual frameworks\nare calling for a probabilistic risk-based security criterion. However, these\napproaches suffer from high requirements in terms of tractability. Here, we\npropose a new method to assess the risk. This method uses both machine learning\ntechniques (artificial neural networks) and more standard simulators based on\nphysical laws. More specifically we train neural networks to estimate the\noverall dangerousness of a grid state. A classical benchmark problem (manpower\n118 buses test case) is used to show the strengths of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 09:02:34 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Donnot", "Benjamin", "", "TAU, LRI"], ["Guyon", "Isabelle", "", "TAU, LRI, UP11"], ["Marot", "Antoine", "", "LRI, TAU"], ["Schoenauer", "Marc", "", "LRI, TAU"], ["Panciatici", "Patrick", ""]]}, {"id": "1805.01216", "submitter": "Dinesh Raghu", "authors": "Dinesh Raghu, Nikhil Gupta and Mausam", "title": "Disentangling Language and Knowledge in Task-Oriented Dialogs", "comments": "Published in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Knowledge Base (KB) used for real-world applications, such as booking a\nmovie or restaurant reservation, keeps changing over time. End-to-end neural\nnetworks trained for these task-oriented dialogs are expected to be immune to\nany changes in the KB. However, existing approaches breakdown when asked to\nhandle such changes. We propose an encoder-decoder architecture (BoSsNet) with\na novel Bag-of-Sequences (BoSs) memory, which facilitates the disentangled\nlearning of the response's language model and its knowledge incorporation.\nConsequently, the KB can be modified with new knowledge without a drop in\ninterpretability. We find that BoSsNet outperforms state-of-the-art models,\nwith considerable improvements (> 10\\%) on bAbI OOV test sets and other\nhuman-human datasets. We also systematically modify existing datasets to\nmeasure disentanglement and show BoSsNet to be robust to KB modifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 10:52:26 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 17:50:13 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 17:24:32 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Raghu", "Dinesh", ""], ["Gupta", "Nikhil", ""], ["Mausam", "", ""]]}, {"id": "1805.01222", "submitter": "Hesam Sagha", "authors": "Andreas Triantafyllopoulos, Hesam Sagha, Florian Eyben, Bj\\\"orn\n  Schuller", "title": "audEERING's approach to the One-Minute-Gradual Emotion Challenge", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes audEERING's submissions as well as additional\nevaluations for the One-Minute-Gradual (OMG) emotion recognition challenge. We\nprovide the results for audio and video processing on subject (in)dependent\nevaluations. On the provided Development set, we achieved 0.343 Concordance\nCorrelation Coefficient (CCC) for arousal (from audio) and .401 for valence\n(from video).\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 11:06:23 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Triantafyllopoulos", "Andreas", ""], ["Sagha", "Hesam", ""], ["Eyben", "Florian", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1805.01237", "submitter": "Hyeong Soo Chang", "authors": "Hyeong Soo Chang", "title": "An Asymptotically Optimal Strategy for Constrained Multi-armed Bandit\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the stochastic multi-armed bandit (MAB) problem from a constrained model\nthat generalizes the classical one, we show that an asymptotic optimality is\nachievable by a simple strategy extended from the $\\epsilon_t$-greedy strategy.\nWe provide a finite-time lower bound on the probability of correct selection of\nan optimal near-feasible arm that holds for all time steps. Under some\nconditions, the bound approaches one as time $t$ goes to infinity. A particular\nexample sequence of $\\{\\epsilon_t\\}$ having the asymptotic convergence rate in\nthe order of $(1-\\frac{1}{t})^4$ that holds from a sufficiently large $t$ is\nalso discussed.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 11:43:26 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Chang", "Hyeong Soo", ""]]}, {"id": "1805.01252", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence and Stefan Riezler", "title": "Improving a Neural Semantic Parser by Counterfactual Learning from Human\n  Bandit Feedback", "comments": "Conference of the Association for Computational Linguistics (ACL),\n  2018, Melbourne, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning from human bandit feedback describes a scenario where\nuser feedback on the quality of outputs of a historic system is logged and used\nto improve a target system. We show how to apply this learning framework to\nneural semantic parsing. From a machine learning perspective, the key challenge\nlies in a proper reweighting of the estimator so as to avoid known degeneracies\nin counterfactual learning, while still being applicable to stochastic gradient\noptimization. To conduct experiments with human users, we devise an easy-to-use\ninterface to collect human feedback on semantic parses. Our work is the first\nto show that semantic parsers can be improved significantly by counterfactual\nlearning from logged human feedback data.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 12:24:39 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 07:04:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Lawrence", "Carolin", ""], ["Riezler", "Stefan", ""]]}, {"id": "1805.01278", "submitter": "Ga\\\"etan Caillaut", "authors": "Ga\\\"etan Caillaut, Guillaume Cleuziou", "title": "Learning Pretopological Spaces to Model Complex Propagation Phenomena: A\n  Multiple Instance Learning Approach Based on a Logical Modeling", "comments": "36 pages 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning the concept of \"propagation\" in\nthe pretopology theoretical formalism. Our proposal is first to define the\npseudo-closure operator (modeling the propagation concept) as a logical\ncombination of neighborhoods. We show that learning such an operator lapses\ninto the Multiple Instance (MI) framework, where the learning process is\nperformed on bags of instances instead of individual instances. Though this\nframework is well suited for this task, its use for learning a pretopological\nspace leads to a set of bags exponential in size. To overcome this issue we\nthus propose a learning method based on a low estimation of the bags covered by\na concept under construction. As an experiment, percolation processes (forest\nfires typically) are simulated and the corresponding propagation models are\nlearned based on a subset of observations. It reveals that the proposed MI\napproach is significantly more efficient on the task of propagation model\nrecognition than existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 13:10:57 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Caillaut", "Ga\u00ebtan", ""], ["Cleuziou", "Guillaume", ""]]}, {"id": "1805.01288", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "Semantic Channel and Shannon's Channel Mutually Match for Multi-Label\n  Classification", "comments": "11 pages, 5 figures, submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A group of transition probability functions form a Shannon's channel whereas\na group of truth functions form a semantic channel. Label learning is to let\nsemantic channels match Shannon's channels and label selection is to let\nShannon's channels match semantic channels. The Channel Matching (CM) algorithm\nis provided for multi-label classification. This algorithm adheres to maximum\nsemantic information criterion which is compatible with maximum likelihood\ncriterion and regularized least squares criterion. If samples are very large,\nwe can directly convert Shannon's channels into semantic channels by the third\nkind of Bayes' theorem; otherwise, we can train truth functions with parameters\nby sampling distributions. A label may be a Boolean function of some atomic\nlabels. For simplifying learning, we may only obtain the truth functions of\nsome atomic label. For a given label, instances are divided into three kinds\n(positive, negative, and unclear) instead of two kinds as in popular studies so\nthat the problem with binary relevance is avoided. For each instance, the\nclassifier selects a compound label with most semantic information or richest\nconnotation. As a predictive model, the semantic channel does not change with\nthe prior probability distribution (source) of instances. It still works when\nthe source is changed. The classifier changes with the source, and hence can\novercome class-imbalance problem. It is shown that the old population's\nincreasing will change the classifier for label \"Old\" and has been impelling\nthe semantic evolution of \"Old\". The CM iteration algorithm for unseen instance\nclassification is introduced.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 03:55:10 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1805.01352", "submitter": "Yangfan Hu", "authors": "Yangfan Hu, Huajin Tang, Gang Pan", "title": "Spiking Deep Residual Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have received significant attention for their\nbiological plausibility. SNNs theoretically have at least the same\ncomputational power as traditional artificial neural networks (ANNs). They\npossess potential of achieving energy-efficiency while keeping comparable\nperformance to deep neural networks (DNNs). However, it is still a big\nchallenge to train a very deep SNN. In this paper, we propose an efficient\napproach to build a spiking version of deep residual network (ResNet). ResNet\nis considered as a kind of the state-of-the-art convolutional neural networks\n(CNNs). We employ the idea of converting a trained ResNet to a network of\nspiking neurons, named Spiking ResNet (S-ResNet). We propose a shortcut\nconversion model to appropriately scale continuous-valued activations to match\nfiring rates in SNN, and a compensation mechanism to reduce the error caused by\ndiscretisation. Experimental results demonstrate that, compared with the\nstate-of-the-art SNN approaches, the proposed Spiking ResNet achieves the best\nperformance on CIFAR-10, CIFAR-100, and ImageNet 2012. Our work is the first\ntime to build a SNN deeper than 40, with comparable performance to ANNs on a\nlarge-scale dataset.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 06:44:13 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 16:55:37 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Hu", "Yangfan", ""], ["Tang", "Huajin", ""], ["Pan", "Gang", ""]]}, {"id": "1805.01357", "submitter": "Bin Liu", "authors": "Bin Liu, Shuai Nie, Yaping Zhang, Dengfeng Ke, Shan Liang, Wenju Liu1", "title": "Boosting Noise Robustness of Acoustic Model via Deep Adversarial\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In realistic environments, speech is usually interfered by various noise and\nreverberation, which dramatically degrades the performance of automatic speech\nrecognition (ASR) systems. To alleviate this issue, the commonest way is to use\na well-designed speech enhancement approach as the front-end of ASR. However,\nmore complex pipelines, more computations and even higher hardware costs\n(microphone array) are additionally consumed for this kind of methods. In\naddition, speech enhancement would result in speech distortions and mismatches\nto training. In this paper, we propose an adversarial training method to\ndirectly boost noise robustness of acoustic model. Specifically, a jointly\ncompositional scheme of generative adversarial net (GAN) and neural\nnetwork-based acoustic model (AM) is used in the training phase. GAN is used to\ngenerate clean feature representations from noisy features by the guidance of a\ndiscriminator that tries to distinguish between the true clean signals and\ngenerated signals. The joint optimization of generator, discriminator and AM\nconcentrates the strengths of both GAN and AM for speech recognition.\nSystematic experiments on CHiME-4 show that the proposed method significantly\nimproves the noise robustness of AM and achieves the average relative error\nrate reduction of 23.38% and 11.54% on the development and test set,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 06:06:24 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Liu", "Bin", ""], ["Nie", "Shuai", ""], ["Zhang", "Yaping", ""], ["Ke", "Dengfeng", ""], ["Liang", "Shan", ""], ["Liu1", "Wenju", ""]]}, {"id": "1805.01360", "submitter": "Daniele Zambon", "authors": "Daniele Zambon, Lorenzo Livi, Cesare Alippi", "title": "Anomaly and Change Detection in Graph Streams through Constant-Curvature\n  Manifold Embeddings", "comments": "To be published in IEEE IJCNN 2018", "journal-ref": "2018 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2018.8489762", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping complex input data into suitable lower dimensional manifolds is a\ncommon procedure in machine learning. This step is beneficial mainly for two\nreasons: (1) it reduces the data dimensionality and (2) it provides a new data\nrepresentation possibly characterised by convenient geometric properties.\nEuclidean spaces are by far the most widely used embedding spaces, thanks to\ntheir well-understood structure and large availability of consolidated\ninference methods. However, recent research demonstrated that many types of\ncomplex data (e.g., those represented as graphs) are actually better described\nby non-Euclidean geometries. Here, we investigate how embedding graphs on\nconstant-curvature manifolds (hyper-spherical and hyperbolic manifolds) impacts\non the ability to detect changes in sequences of attributed graphs. The\nproposed methodology consists in embedding graphs into a geometric space and\nperform change detection there by means of conventional methods for numerical\nstreams. The curvature of the space is a parameter that we learn to reproduce\nthe geometry of the original application-dependent graph space. Preliminary\nexperimental results show the potential capability of representing graphs by\nmeans of curved manifold, in particular for change and anomaly detection\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:12:46 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zambon", "Daniele", ""], ["Livi", "Lorenzo", ""], ["Alippi", "Cesare", ""]]}, {"id": "1805.01367", "submitter": "Erwan Lecarpentier", "authors": "Erwan Lecarpentier, Guillaume Infantes, Charles Lesire, Emmanuel\n  Rachelson", "title": "Open Loop Execution of Tree-Search Algorithms, extended version", "comments": "10 pages, 10 figures", "journal-ref": "27th International Joint Conference on Artificial Intelligence\n  (IJCAI 2018)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of tree-search stochastic planning algorithms where a\ngenerative model is available, we consider on-line planning algorithms building\ntrees in order to recommend an action. We investigate the question of avoiding\nre-planning in subsequent decision steps by directly using sub-trees as action\nrecommender. Firstly, we propose a method for open loop control via a new\nalgorithm taking the decision of re-planning or not at each time step based on\nan analysis of the statistics of the sub-tree. Secondly, we show that the\nprobability of selecting a suboptimal action at any depth of the tree can be\nupper bounded and converges towards zero. Moreover, this upper bound decays in\na logarithmic way between subsequent depths. This leads to a distinction\nbetween node-wise optimality and state-wise optimality. Finally, we empirically\ndemonstrate that our method achieves a compromise between loss of performance\nand computational gain.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:20:10 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 21:42:21 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Lecarpentier", "Erwan", ""], ["Infantes", "Guillaume", ""], ["Lesire", "Charles", ""], ["Rachelson", "Emmanuel", ""]]}, {"id": "1805.01431", "submitter": "Mandar Kulkarni Mr.", "authors": "Mandar Kulkarni, Aria Abubakar", "title": "Siamese networks for generating adversarial examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples. An adversary\nmodifies the input data such that humans still assign the same label, however,\nmachine learning models misclassify it. Previous approaches in the literature\ndemonstrated that adversarial examples can even be generated for the remotely\nhosted model. In this paper, we propose a Siamese network based approach to\ngenerate adversarial examples for a multiclass target CNN. We assume that the\nadversary do not possess any knowledge of the target data distribution, and we\nuse an unlabeled mismatched dataset to query the target, e.g., for the\nResNet-50 target, we use the Food-101 dataset as the query. Initially, the\ntarget model assigns labels to the query dataset, and a Siamese network is\ntrained on the image pairs derived from these multiclass labels. We learn the\n\\emph{adversarial perturbations} for the Siamese model and show that these\nperturbations are also adversarial w.r.t. the target model. In experimental\nresults, we demonstrate effectiveness of our approach on MNIST, CIFAR-10 and\nImageNet targets with TinyImageNet/Food-101 query datasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 17:11:18 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Kulkarni", "Mandar", ""], ["Abubakar", "Aria", ""]]}, {"id": "1805.01500", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Rajesh Ranganath, Jaan Altosaar, David M. Blei", "title": "Noisin: Unbiased Regularization for Recurrent Neural Networks", "comments": "In Proceedings of the International Conference on Machine Learning,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful models of sequential data. They\nhave been successfully used in domains such as text and speech. However, RNNs\nare susceptible to overfitting; regularization is important. In this paper we\ndevelop Noisin, a new method for regularizing RNNs. Noisin injects random noise\ninto the hidden states of the RNN and then maximizes the corresponding marginal\nlikelihood of the data. We show how Noisin applies to any RNN and we study many\ndifferent types of noise. Noisin is unbiased--it preserves the underlying RNN\non average. We characterize how Noisin regularizes its RNN both theoretically\nand empirically. On language modeling benchmarks, Noisin improves over dropout\nby as much as 12.2% on the Penn Treebank and 9.4% on the Wikitext-2 dataset. We\nalso compared the state-of-the-art language model of Yang et al. 2017, both\nwith and without Noisin. On the Penn Treebank, the method with Noisin more\nquickly reaches state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 18:34:52 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 00:08:47 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Dieng", "Adji B.", ""], ["Ranganath", "Rajesh", ""], ["Altosaar", "Jaan", ""], ["Blei", "David M.", ""]]}, {"id": "1805.01509", "submitter": "Saba Al-Sayouri", "authors": "Saba A. Al-Sayouri, Danai Koutra, Evangelos E. Papalexakis, Sarah S.\n  Lam", "title": "RECS: Robust Graph Embedding Using Connection Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of graph embeddings or node representation learning in a variety\nof downstream tasks, such as node classification, link prediction, and\nrecommendation systems, has led to their popularity in recent years.\nRepresentation learning algorithms aim to preserve local and global network\nstructure by identifying node neighborhood notions. However, many existing\nalgorithms generate embeddings that fail to properly preserve the network\nstructure, or lead to unstable representations due to random processes (e.g.,\nrandom walks to generate context) and, thus, cannot generate to multi-graph\nproblems. In this paper, we propose RECS, a novel, stable graph embedding\nalgorithmic framework. RECS learns graph representations using connection\nsubgraphs by employing the analogy of graphs with electrical circuits. It\npreserves both local and global connectivity patterns, and addresses the issue\nof high-degree nodes. Further, it exploits the strength of weak ties and\nmeta-data that have been neglected by baselines. The experiments show that RECS\noutperforms state-of-the-art algorithms by up to 36.85% on multi-label\nclassification problem. Further, in contrast to baselines, RECS, being\ndeterministic, is completely stable.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 18:47:43 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 04:17:46 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 22:18:21 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Al-Sayouri", "Saba A.", ""], ["Koutra", "Danai", ""], ["Papalexakis", "Evangelos E.", ""], ["Lam", "Sarah S.", ""]]}, {"id": "1805.01516", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, E.M. Mirkes, I.Y. Tyukin", "title": "How deep should be the depth of convolutional neural networks: a\n  backyard dog case study", "comments": "Edited and extended version with more detailed description of\n  numerical experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The work concerns the problem of reducing a pre-trained deep neuronal network\nto a smaller network, with just few layers, whilst retaining the network's\nfunctionality on a given task\n  The proposed approach is motivated by the observation that the aim to deliver\nthe highest accuracy possible in the broadest range of operational conditions,\nwhich many deep neural networks models strive to achieve, may not necessarily\nbe always needed, desired, or even achievable due to the lack of data or\ntechnical constraints. In relation to the face recognition problem, we\nformulated an example of such a usecase, the `backyard dog' problem. The\n`backyard dog', implemented by a lean network, should correctly identify\nmembers from a limited group of individuals, a `family', and should distinguish\nbetween them. At the same time, the network must produce an alarm to an image\nof an individual who is not in a member of the family. To produce such a\nnetwork, we propose a shallowing algorithm. The algorithm takes an existing\ndeep learning model on its input and outputs a shallowed version of it. The\nalgorithm is non-iterative and is based on the Advanced Supervised Principal\nComponent Analysis. Performance of the algorithm is assessed in exhaustive\nnumerical experiments. In the above usecase, the `backyard dog' problem, the\nmethod is capable of drastically reducing the depth of deep learning neural\nnetworks, albeit at the cost of mild performance deterioration.\n  We developed a simple non-iterative method for shallowing down pre-trained\ndeep networks. The method is generic in the sense that it applies to a broad\nclass of feed-forward networks, and is based on the Advanced Supervise\nPrincipal Component Analysis. The method enables generation of families of\nsmaller-size shallower specialized networks tuned for specific operational\nconditions and tasks from a single larger and more universal legacy network.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:37:54 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 06:06:19 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 17:43:12 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Gorban", "A. N.", ""], ["Mirkes", "E. M.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1805.01532", "submitter": "Geoffrey Negiar", "authors": "Armin Askari, Geoffrey Negiar, Rajiv Sambharya, Laurent El Ghaoui", "title": "Lifted Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We describe a novel family of models of multi- layer feedforward neural\nnetworks in which the activation functions are encoded via penalties in the\ntraining problem. Our approach is based on representing a non-decreasing\nactivation function as the argmin of an appropriate convex optimiza- tion\nproblem. The new framework allows for algo- rithms such as block-coordinate\ndescent methods to be applied, in which each step is composed of a simple (no\nhidden layer) supervised learning problem that is parallelizable across data\npoints and/or layers. Experiments indicate that the pro- posed models provide\nexcellent initial guesses for weights for standard neural networks. In addi-\ntion, the model provides avenues for interesting extensions, such as robustness\nagainst noisy in- puts and optimizing over parameters in activation functions.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 20:56:31 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 01:48:34 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Askari", "Armin", ""], ["Negiar", "Geoffrey", ""], ["Sambharya", "Rajiv", ""], ["Ghaoui", "Laurent El", ""]]}, {"id": "1805.01554", "submitter": "Toan Nguyen", "authors": "Minh Nguyen, Toan Nguyen, Thien Huu Nguyen", "title": "A Deep Learning Model with Hierarchical LSTMs and Supervised Attention\n  for Anti-Phishing", "comments": "In: R. Verma, A. Das. (eds.): Proceedings of the 1st Anti-Phishing\n  Shared Pilot at 4th ACM International Workshop on Security and Privacy\n  Analytics (IWSPA 2018), Tempe, Arizona, USA, 21-03-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-phishing aims to detect phishing content/documents in a pool of textual\ndata. This is an important problem in cybersecurity that can help to guard\nusers from fraudulent information. Natural language processing (NLP) offers a\nnatural solution for this problem as it is capable of analyzing the textual\ncontent to perform intelligent recognition. In this work, we investigate\nstate-of-the-art techniques for text categorization in NLP to address the\nproblem of anti-phishing for emails (i.e, predicting if an email is phishing or\nnot). These techniques are based on deep learning models that have attracted\nmuch attention from the community recently. In particular, we present a\nframework with hierarchical long short-term memory networks (H-LSTMs) and\nattention mechanisms to model the emails simultaneously at the word and the\nsentence level. Our expectation is to produce an effective model for\nanti-phishing and demonstrate the effectiveness of deep learning for problems\nin cybersecurity.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 21:53:09 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Nguyen", "Minh", ""], ["Nguyen", "Toan", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1805.01618", "submitter": "Nikit Gawande", "authors": "Kumarjit Pathak, Jitin Kapila, Aasheesh Barvey, Nikit Gawande", "title": "Distribution Assertive Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression modelling approach, the main step is to fit the regression line\nas close as possible to the target variable. In this process most algorithms\ntry to fit all of the data in a single line and hence fitting all parts of\ntarget variable in one go. It was observed that the error between predicted and\ntarget variable usually have a varying behavior across the various quantiles of\nthe dependent variable and hence single point diagnostic like MAPE has its\nlimitation to signify the level of fitness across the distribution of\nY(dependent variable). To address this problem, a novel approach is proposed in\nthe paper to deal with regression fitting over various quantiles of target\nvariable. Using this approach we have significantly improved the eccentric\nbehavior of the distance (error) between predicted and actual value of\nregression. Our proposed solution is based on understanding the segmented\nbehavior of the data with respect to the internal segments within the data and\napproach for retrospectively fitting the data based on each quantile behavior.\nWe believe exploring and using this approach would help in achieving better and\nmore explainable results in most settings of real world data modelling\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 06:16:30 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""], ["Barvey", "Aasheesh", ""], ["Gawande", "Nikit", ""]]}, {"id": "1805.01626", "submitter": "Weihao Kong", "authors": "Weihao Kong, Gregory Valiant", "title": "Estimating Learnability in the Sublinear Data Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating how well a model class is capable of\nfitting a distribution of labeled data. We show that it is often possible to\naccurately estimate this \"learnability\" even when given an amount of data that\nis too small to reliably learn any accurate model. Our first result applies to\nthe setting where the data is drawn from a $d$-dimensional distribution with\nisotropic covariance (or known covariance), and the label of each datapoint is\nan arbitrary noisy function of the datapoint. In this setting, we show that\nwith $O(\\sqrt{d})$ samples, one can accurately estimate the fraction of the\nvariance of the label that can be explained via the best linear function of the\ndata. In contrast to this sublinear sample size, finding an approximation of\nthe best-fit linear function requires on the order of $d$ samples. Our\nsublinear sample results and approach also extend to the non-isotropic setting,\nwhere the data distribution has an (unknown) arbitrary covariance matrix: we\nshow that, if the label $y$ of point $x$ is a linear function with independent\nnoise, $y = \\langle x , \\beta \\rangle + noise$ with $\\|\\beta \\|$ bounded, the\nvariance of the noise can be estimated to error $\\epsilon$ with\n$O(d^{1-1/\\log{1/\\epsilon}})$ if the covariance matrix has bounded condition\nnumber, or $O(d^{1-\\sqrt{\\epsilon}})$ if there are no bounds on the condition\nnumber. We also establish that these sample complexities are optimal, to\nconstant factors. Finally, we extend these techniques to the setting of binary\nclassification, where we obtain analogous sample complexities for the problem\nof estimating the prediction error of the best linear classifier, in a natural\nmodel of binary labeled data. We demonstrate the practical viability of our\napproaches on several real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 06:57:19 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 06:06:03 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 04:47:51 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Kong", "Weihao", ""], ["Valiant", "Gregory", ""]]}, {"id": "1805.01627", "submitter": "Debabrota Basu", "authors": "Debabrota Basu, Pierre Senellart and St\\'ephane Bressan", "title": "BelMan: Bayesian Bandits on the Belief--Reward Manifold", "comments": "36 pages, 14 figures, accepted in ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a generic, Bayesian, information geometric approach to the\nexploration--exploitation trade-off in multi-armed bandit problems. Our\napproach, BelMan, uniformly supports pure exploration,\nexploration--exploitation, and two-phase bandit problems. The knowledge on\nbandit arms and their reward distributions is summarised by the barycentre of\nthe joint distributions of beliefs and rewards of the arms, the\n\\emph{pseudobelief-reward}, within the beliefs-rewards manifold. BelMan\nalternates \\emph{information projection} and \\emph{reverse information\nprojection}, i.e., projection of the pseudobelief-reward onto beliefs-rewards\nto choose the arm to play, and projection of the resulting beliefs-rewards onto\nthe pseudobelief-reward. It introduces a mechanism that infuses an exploitative\nbias by means of a \\emph{focal distribution}, i.e., a reward distribution that\ngradually concentrates on higher rewards. Comparative performance evaluation\nwith state-of-the-art algorithms shows that BelMan is not only competitive but\ncan also outperform other approaches in specific setups, for instance involving\nmany arms and continuous rewards.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 07:11:53 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:25:16 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Basu", "Debabrota", ""], ["Senellart", "Pierre", ""], ["Bressan", "St\u00e9phane", ""]]}, {"id": "1805.01648", "submitter": "Niladri Chatterji", "authors": "Xiang Cheng, Niladri S. Chatterji, Yasin Abbasi-Yadkori, Peter L.\n  Bartlett, Michael I. Jordan", "title": "Sharp convergence rates for Langevin dynamics in the nonconvex setting", "comments": "78 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling from a distribution $p^*(x) \\propto\n\\exp\\left(-U(x)\\right)$, where the function $U$ is $L$-smooth everywhere and\n$m$-strongly convex outside a ball of radius $R$, but potentially nonconvex\ninside this ball. We study both overdamped and underdamped Langevin MCMC and\nestablish upper bounds on the number of steps required to obtain a sample from\na distribution that is within $\\epsilon$ of $p^*$ in $1$-Wasserstein distance.\nFor the first-order method (overdamped Langevin MCMC), the iteration complexity\nis $\\tilde{\\mathcal{O}}\\left(e^{cLR^2}d/\\epsilon^2\\right)$, where $d$ is the\ndimension of the underlying space. For the second-order method (underdamped\nLangevin MCMC), the iteration complexity is\n$\\tilde{\\mathcal{O}}\\left(e^{cLR^2}\\sqrt{d}/\\epsilon\\right)$ for an explicit\npositive constant $c$. Surprisingly, the iteration complexity for both these\nalgorithms is only polynomial in the dimension $d$ and the target accuracy\n$\\epsilon$. It is exponential, however, in the problem parameter $LR^2$, which\nis a measure of non-log-concavity of the target distribution.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 08:16:00 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 15:34:27 GMT"}, {"version": "v3", "created": "Sun, 3 Feb 2019 02:09:14 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 06:49:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Cheng", "Xiang", ""], ["Chatterji", "Niladri S.", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1805.01667", "submitter": "Martin V\\\"olker", "authors": "Martin V\\\"olker, Ji\\v{r}\\'i Hammer, Robin T. Schirrmeister, Joos\n  Behncke, Lukas D.J. Fiederer, Andreas Schulze-Bonhage, Petr Marusi\\v{c},\n  Wolfram Burgard, Tonio Ball", "title": "Intracranial Error Detection via Deep Learning", "comments": "8 pages, 6 figures. Accepted at the 2018 IEEE International\n  Conference on Systems, Man, and Cybernetics (SMC2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have revolutionized the field of machine learning\nand were recently successfully applied to various classification problems in\nnoninvasive electroencephalography (EEG). However, these methods were so far\nonly rarely evaluated for use in intracranial EEG. We employed convolutional\nneural networks (CNNs) to classify and characterize the error-related brain\nresponse as measured in 24 intracranial EEG recordings. Decoding accuracies of\nCNNs were significantly higher than those of a regularized linear discriminant\nanalysis. Using time-resolved deep decoding, it was possible to classify errors\nin various regions in the human brain, and further to decode errors over 200 ms\nbefore the actual erroneous button press, e.g., in the precentral gyrus.\nMoreover, deeper networks performed better than shallower networks in\ndistinguishing correct from error trials in all-channel decoding. In single\nrecordings, up to 100 % decoding accuracy was achieved. Visualization of the\nnetworks' learned features indicated that multivariate decoding on an ensemble\nof channels yields related, albeit non-redundant information compared to\nsingle-channel decoding. In summary, here we show the usefulness of deep\nlearning for both intracranial error decoding and mapping of the\nspatio-temporal structure of the human error processing network.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 08:53:03 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 13:15:38 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 10:57:22 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["V\u00f6lker", "Martin", ""], ["Hammer", "Ji\u0159\u00ed", ""], ["Schirrmeister", "Robin T.", ""], ["Behncke", "Joos", ""], ["Fiederer", "Lukas D. J.", ""], ["Schulze-Bonhage", "Andreas", ""], ["Marusi\u010d", "Petr", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1805.01685", "submitter": "Weiran Huang", "authors": "Weiran Huang and Jungseul Ok and Liang Li and Wei Chen", "title": "Combinatorial Pure Exploration with Continuous and Separable Reward\n  Functions and Its Applications (Extended Version)", "comments": "conference version accepted by IJCAI-ECAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Combinatorial Pure Exploration problem with Continuous and\nSeparable reward functions (CPE-CS) in the stochastic multi-armed bandit\nsetting. In a CPE-CS instance, we are given several stochastic arms with\nunknown distributions, as well as a collection of possible decisions. Each\ndecision has a reward according to the distributions of arms. The goal is to\nidentify the decision with the maximum reward, using as few arm samples as\npossible. The problem generalizes the combinatorial pure exploration problem\nwith linear rewards, which has attracted significant attention in recent years.\nIn this paper, we propose an adaptive learning algorithm for the CPE-CS\nproblem, and analyze its sample complexity. In particular, we introduce a new\nhardness measure called the consistent optimality hardness, and give both the\nupper and lower bounds of sample complexity. Moreover, we give examples to\ndemonstrate that our solution has the capacity to deal with non-linear reward\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 09:41:15 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Huang", "Weiran", ""], ["Ok", "Jungseul", ""], ["Li", "Liang", ""], ["Chen", "Wei", ""]]}, {"id": "1805.01702", "submitter": "Kun Chen", "authors": "Kun Chen, Kechao Cai, Longbo Huang, John C.S. Lui", "title": "Beyond the Click-Through Rate: Web Link Selection with Multi-level\n  Feedback", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web link selection problem is to select a small subset of web links from\na large web link pool, and to place the selected links on a web page that can\nonly accommodate a limited number of links, e.g., advertisements,\nrecommendations, or news feeds. Despite the long concerned click-through rate\nwhich reflects the attractiveness of the link itself, the revenue can only be\nobtained from user actions after clicks, e.g., purchasing after being directed\nto the product pages by recommendation links. Thus, the web links have an\nintrinsic \\emph{multi-level feedback structure}. With this observation, we\nconsider the context-free web link selection problem, where the objective is to\nmaximize revenue while ensuring that the attractiveness is no less than a\npreset threshold. The key challenge of the problem is that each link's\nmulti-level feedbacks are stochastic, and unobservable unless the link is\nselected. We model this problem with a constrained stochastic multi-armed\nbandit formulation, and design an efficient link selection algorithm, called\nConstrained Upper Confidence Bound algorithm (\\textbf{Con-UCB}), and prove\n$O(\\sqrt{T\\ln T})$ bounds on both the regret and the violation of the\nattractiveness constraint. We conduct extensive experiments on three real-world\ndatasets, and show that \\textbf{Con-UCB} outperforms state-of-the-art\ncontext-free bandit algorithms concerning the multi-level feedback structure.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 10:37:27 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Chen", "Kun", ""], ["Cai", "Kechao", ""], ["Huang", "Longbo", ""], ["Lui", "John C. S.", ""]]}, {"id": "1805.01745", "submitter": "Xin Ma", "authors": "Xin Ma", "title": "A brief introduction to the Grey Machine Learning", "comments": "Awarded by the Joint Conference of 2018 International Congress of\n  Grey Systems and Uncertainty Analysis (GSUA) and 32nd Workshop of Grey System\n  Society of China (GSSC) as the Excellent Paper", "journal-ref": "Journal of Grey System, 2019, vol 31, no. 1, pp. 1-12", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a brief introduction to the key points of the Grey\nMachine Learning (GML) based on the kernels. The general formulation of the\ngrey system models have been firstly summarized, and then the nonlinear\nextension of the grey models have been developed also with general\nformulations. The kernel implicit mapping is used to estimate the nonlinear\nfunction of the GML model, by extending the nonparametric formulation of the\nLSSVM, the estimation of the nonlinear function of the GML model can also be\nexpressed by the kernels. A short discussion on the priority of this new\nframework to the existing grey models and LSSVM have also been discussed in\nthis paper. And the perspectives and future orientations of this framework have\nalso been presented.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 12:53:05 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 03:42:37 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Ma", "Xin", ""]]}, {"id": "1805.01772", "submitter": "Peter Hawkins", "authors": "Yuan Yu, Mart\\'in Abadi, Paul Barham, Eugene Brevdo, Mike Burrows,\n  Andy Davis, Jeff Dean, Sanjay Ghemawat, Tim Harley, Peter Hawkins, Michael\n  Isard, Manjunath Kudlur, Rajat Monga, Derek Murray, Xiaoqiang Zheng", "title": "Dynamic Control Flow in Large-Scale Machine Learning", "comments": "Appeared in EuroSys 2018. 14 pages, 16 figures", "journal-ref": "EuroSys 2018: Thirteenth EuroSys Conference, April 23-26, 2018,\n  Porto, Portugal. ACM, New York, NY, USA", "doi": "10.1145/3190508.3190551", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent machine learning models rely on fine-grained dynamic control flow\nfor training and inference. In particular, models based on recurrent neural\nnetworks and on reinforcement learning depend on recurrence relations,\ndata-dependent conditional execution, and other features that call for dynamic\ncontrol flow. These applications benefit from the ability to make rapid\ncontrol-flow decisions across a set of computing devices in a distributed\nsystem. For performance, scalability, and expressiveness, a machine learning\nsystem must support dynamic control flow in distributed and heterogeneous\nenvironments.\n  This paper presents a programming model for distributed machine learning that\nsupports dynamic control flow. We describe the design of the programming model,\nand its implementation in TensorFlow, a distributed machine learning system.\nOur approach extends the use of dataflow graphs to represent machine learning\nmodels, offering several distinctive features. First, the branches of\nconditionals and bodies of loops can be partitioned across many machines to run\non a set of heterogeneous devices, including CPUs, GPUs, and custom ASICs.\nSecond, programs written in our model support automatic differentiation and\ndistributed gradient computations, which are necessary for training machine\nlearning models that use control flow. Third, our choice of non-strict\nsemantics enables multiple loop iterations to execute in parallel across\nmachines, and to overlap compute and I/O operations.\n  We have done our work in the context of TensorFlow, and it has been used\nextensively in research and production. We evaluate it using several real-world\napplications, and demonstrate its performance and scalability.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 13:40:07 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Yu", "Yuan", ""], ["Abadi", "Mart\u00edn", ""], ["Barham", "Paul", ""], ["Brevdo", "Eugene", ""], ["Burrows", "Mike", ""], ["Davis", "Andy", ""], ["Dean", "Jeff", ""], ["Ghemawat", "Sanjay", ""], ["Harley", "Tim", ""], ["Hawkins", "Peter", ""], ["Isard", "Michael", ""], ["Kudlur", "Manjunath", ""], ["Monga", "Rajat", ""], ["Murray", "Derek", ""], ["Zheng", "Xiaoqiang", ""]]}, {"id": "1805.01837", "submitter": "Mathias Niepert", "authors": "Mathias Niepert and Alberto Garcia-Duran", "title": "Towards a Spectrum of Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our ongoing work on understanding the limitations of graph\nconvolutional networks (GCNs) as well as our work on generalizations of graph\nconvolutions for representing more complex node attribute dependencies. Based\non an analysis of GCNs with the help of the corresponding computation graphs,\nwe propose a generalization of existing GCNs where the aggregation operations\nare (a) determined by structural properties of the local neighborhood graphs\nand (b) not restricted to weighted averages. We show that the proposed approach\nis strictly more expressive while requiring only a modest increase in the\nnumber of parameters and computations. We also show that the proposed\ngeneralization is identical to standard convolutional layers when applied to\nregular grid graphs.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 16:13:36 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Niepert", "Mathias", ""], ["Garcia-Duran", "Alberto", ""]]}, {"id": "1805.01852", "submitter": "David R\\\"ugamer", "authors": "David R\\\"ugamer, Sonja Greven", "title": "Inference for $L_2$-Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical inference framework for the component-wise\nfunctional gradient descent algorithm (CFGD) under normality assumption for\nmodel errors, also known as $L_2$-Boosting. The CFGD is one of the most\nversatile tools to analyze data, because it scales well to high-dimensional\ndata sets, allows for a very flexible definition of additive regression models\nand incorporates inbuilt variable selection. Due to the variable selection, we\nbuild on recent proposals for post-selection inference. However, the iterative\nnature of component-wise boosting, which can repeatedly select the same\ncomponent to update, necessitates adaptations and extensions to existing\napproaches. We propose tests and confidence intervals for linear, grouped and\npenalized additive model components selected by $L_2$-Boosting. Our concepts\nalso transfer to slow-learning algorithms more generally, and to other\nselection techniques which restrict the response space to more complex sets\nthan polyhedra. We apply our framework to an additive model for sales prices of\nresidential apartments and investigate the properties of our concepts in\nsimulation studies.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 16:51:38 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 10:00:44 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 14:44:10 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 20:17:26 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["R\u00fcgamer", "David", ""], ["Greven", "Sonja", ""]]}, {"id": "1805.01867", "submitter": "Jie Yang", "authors": "Jie Yang, Diego Klabjan", "title": "Bayesian active learning for choice models with deep Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an active learning algorithm and models which can\ngradually learn individual's preference through pairwise comparisons. The\nactive learning scheme aims at finding individual's most preferred choice with\nminimized number of pairwise comparisons. The pairwise comparisons are encoded\ninto probabilistic models based on assumptions of choice models and deep\nGaussian processes. The next-to-compare decision is determined by a novel\nacquisition function. We benchmark the proposed algorithm and models using\nfunctions with multiple local optima and one public airline itinerary dataset.\nThe experiments indicate the effectiveness of our active learning algorithm and\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 17:22:39 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Yang", "Jie", ""], ["Klabjan", "Diego", ""]]}, {"id": "1805.01889", "submitter": "Saba Al-Sayouri", "authors": "Saba A. Al-Sayouri, Ekta Gujral, Danai Koutra, Evangelos E.\n  Papalexakis, Sarah S. Lam", "title": "t-PINE: Tensor-based Predictable and Interpretable Node Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representations have increasingly grown in popularity during the last\nyears. Existing representation learning approaches explicitly encode network\nstructure. Despite their good performance in downstream processes (e.g., node\nclassification, link prediction), there is still room for improvement in\ndifferent aspects, like efficacy, visualization, and interpretability. In this\npaper, we propose, t-PINE, a method that addresses these limitations. Contrary\nto baseline methods, which generally learn explicit graph representations by\nsolely using an adjacency matrix, t-PINE avails a multi-view information graph,\nthe adjacency matrix represents the first view, and a nearest neighbor\nadjacency, computed over the node features, is the second view, in order to\nlearn explicit and implicit node representations, using the Canonical Polyadic\n(a.k.a. CP) decomposition. We argue that the implicit and the explicit mapping\nfrom a higher-dimensional to a lower-dimensional vector space is the key to\nlearn more useful, highly predictable, and gracefully interpretable\nrepresentations. Having good interpretable representations provides a good\nguidance to understand how each view contributes to the representation learning\nprocess. In addition, it helps us to exclude unrelated dimensions. Extensive\nexperiments show that t-PINE drastically outperforms baseline methods by up to\n158.6% with respect to Micro-F1, in several multi-label classification\nproblems, while it has high visualization and interpretability utility.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:33:07 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Al-Sayouri", "Saba A.", ""], ["Gujral", "Ekta", ""], ["Koutra", "Danai", ""], ["Papalexakis", "Evangelos E.", ""], ["Lam", "Sarah S.", ""]]}, {"id": "1805.01890", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Mojtaba Heidarysafa, Donald E. Brown, Kiana Jafari\n  Meimandi, Laura E. Barnes", "title": "RMDL: Random Multimodel Deep Learning for Classification", "comments": "Best Paper award ACM ICISDM", "journal-ref": null, "doi": "10.1145/3206098.3206111", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continually increasing number of complex datasets each year necessitates\never improving machine learning methods for robust and accurate categorization\nof these data. This paper introduces Random Multimodel Deep Learning (RMDL): a\nnew ensemble, deep learning approach for classification. Deep learning models\nhave achieved state-of-the-art results across many domains. RMDL solves the\nproblem of finding the best deep learning structure and architecture while\nsimultaneously improving robustness and accuracy through ensembles of deep\nlearning architectures. RDML can accept as input a variety data to include\ntext, video, images, and symbolic. This paper describes RMDL and shows test\nresults for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,\nand 20newsgroup. These test results show that RDML produces consistently better\nperformance than standard methods over a broad range of data types and\nclassification problems.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:36:43 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 16:08:33 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Kowsari", "Kamran", ""], ["Heidarysafa", "Mojtaba", ""], ["Brown", "Donald E.", ""], ["Meimandi", "Kiana Jafari", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1805.01891", "submitter": "Lu Hou", "authors": "Lu Hou, James T. Kwok", "title": "Power Law in Sparsified Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power law has been observed in the degree distributions of many\nbiological neural networks. Sparse deep neural networks, which learn an\neconomical representation from the data, resemble biological neural networks in\nmany ways. In this paper, we study if these artificial networks also exhibit\nproperties of the power law. Experimental results on two popular deep learning\nmodels, namely, multilayer perceptrons and convolutional neural networks, are\naffirmative. The power law is also naturally related to preferential\nattachment. To study the dynamical properties of deep networks in continual\nlearning, we propose an internal preferential attachment model to explain how\nthe network topology evolves. Experimental results show that with the arrival\nof a new task, the new connections made follow this preferential attachment\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 07:51:00 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Hou", "Lu", ""], ["Kwok", "James T.", ""]]}, {"id": "1805.01907", "submitter": "Yunhao Tang", "authors": "Yunhao Tang and Shipra Agrawal", "title": "Exploration by Distributional Reinforcement Learning", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework based on distributional reinforcement learning and\nrecent attempts to combine Bayesian parameter updates with deep reinforcement\nlearning. We show that our proposed framework conceptually unifies multiple\nprevious methods in exploration. We also derive a practical algorithm that\nachieves efficient exploration on challenging control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 18:07:21 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 16:57:32 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Tang", "Yunhao", ""], ["Agrawal", "Shipra", ""]]}, {"id": "1805.01930", "submitter": "Brian Bartoldson", "authors": "Brian Bartoldson, Adrian Barbu, Gordon Erlebacher", "title": "Enhancing the Regularization Effect of Weight Pruning in Artificial\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) may not be worth their computational/memory\ncosts when used in mobile phones or embedded devices. Parameter-pruning\nalgorithms combat these costs, with some algorithms capable of removing over\n90% of an ANN's weights without harming the ANN's performance. Removing weights\nfrom an ANN is a form of regularization, but existing pruning algorithms do not\nsignificantly improve generalization error. We show that pruning ANNs can\nimprove generalization if pruning targets large weights instead of small\nweights. Applying our pruning algorithm to an ANN leads to a higher image\nclassification accuracy on CIFAR-10 data than applying the popular regularizer\ndropout. The pruning couples this higher accuracy with an 85% reduction of the\nANN's parameter count.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 20:39:31 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Bartoldson", "Brian", ""], ["Barbu", "Adrian", ""], ["Erlebacher", "Gordon", ""]]}, {"id": "1805.01934", "submitter": "Qifeng Chen", "authors": "Chen Chen, Qifeng Chen, Jia Xu, and Vladlen Koltun", "title": "Learning to See in the Dark", "comments": "Published at the Conference on Computer Vision and Pattern\n  Recognition (CVPR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging in low light is challenging due to low photon count and low SNR.\nShort-exposure images suffer from noise, while long exposure can induce blur\nand is often impractical. A variety of denoising, deblurring, and enhancement\ntechniques have been proposed, but their effectiveness is limited in extreme\nconditions, such as video-rate imaging at night. To support the development of\nlearning-based pipelines for low-light image processing, we introduce a dataset\nof raw short-exposure low-light images, with corresponding long-exposure\nreference images. Using the presented dataset, we develop a pipeline for\nprocessing low-light images, based on end-to-end training of a\nfully-convolutional network. The network operates directly on raw sensor data\nand replaces much of the traditional image processing pipeline, which tends to\nperform poorly on such data. We report promising results on the new dataset,\nanalyze factors that affect performance, and highlight opportunities for future\nwork. The results are shown in the supplementary video at\nhttps://youtu.be/qWKUFK7MWvg\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 21:03:12 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Chen", "Chen", ""], ["Chen", "Qifeng", ""], ["Xu", "Jia", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1805.01955", "submitter": "Buu Phan", "authors": "Buu Phan", "title": "Improve Uncertainty Estimation for Unknown Classes in Bayesian Neural\n  Networks with Semi-Supervised /One Set Classification", "comments": "Major updates for current version required, especially on section 3\n  and format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural network (DNN) has achieved many state-of-the-art\nresults, estimating the uncertainty presented in the DNN model and the data is\na challenging task. Problems related to uncertainty such as classifying unknown\nclasses (class which does not appear in the training data) data as known class\nwith high confidence, is critically concerned in the safety domain area (e.g,\nautonomous driving, medical diagnosis). In this paper, we show that applying\ncurrent Bayesian Neural Network (BNN) techniques alone does not effectively\ncapture the uncertainty. To tackle this problem, we introduce a simple way to\nimprove the BNN by using one class classification (in this paper, we use the\nterm \"set classification\" instead). We empirically show the result of our\nmethod on an experiment which involves three datasets: MNIST, notMNIST and\nFMNIST.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 22:43:19 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 16:48:17 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Phan", "Buu", ""]]}, {"id": "1805.01956", "submitter": "Michael Everett", "authors": "Michael Everett, Yu Fan Chen, Jonathan P. How", "title": "Motion Planning Among Dynamic, Decision-Making Agents with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots that navigate among pedestrians use collision avoidance algorithms to\nenable safe and efficient operation. Recent works present deep reinforcement\nlearning as a framework to model the complex interactions and cooperation.\nHowever, they are implemented using key assumptions about other agents'\nbehavior that deviate from reality as the number of agents in the environment\nincreases. This work extends our previous approach to develop an algorithm that\nlearns collision avoidance among a variety of types of dynamic agents without\nassuming they follow any particular behavior rules. This work also introduces a\nstrategy using LSTM that enables the algorithm to use observations of an\narbitrary number of other agents, instead of previous methods that have a fixed\nobservation size. The proposed algorithm outperforms our previous approach in\nsimulation as the number of agents increases, and the algorithm is demonstrated\non a fully autonomous robotic vehicle traveling at human walking speed, without\nthe use of a 3D Lidar.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 22:45:08 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Everett", "Michael", ""], ["Chen", "Yu Fan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1805.01978", "submitter": "Zhirong Wu", "authors": "Zhirong Wu, Yuanjun Xiong, Stella Yu, Dahua Lin", "title": "Unsupervised Feature Learning via Non-Parametric Instance-level\n  Discrimination", "comments": "CVPR 2018 spotlight paper. Code:\n  https://github.com/zhirongw/lemniscate.pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural net classifiers trained on data with annotated class labels can also\ncapture apparent visual similarity among categories without being directed to\ndo so. We study whether this observation can be extended beyond the\nconventional domain of supervised learning: Can we learn a good feature\nrepresentation that captures apparent similarity among instances, instead of\nclasses, by merely asking the feature to be discriminative of individual\ninstances? We formulate this intuition as a non-parametric classification\nproblem at the instance-level, and use noise-contrastive estimation to tackle\nthe computational challenges imposed by the large number of instance classes.\nOur experimental results demonstrate that, under unsupervised learning\nsettings, our method surpasses the state-of-the-art on ImageNet classification\nby a large margin. Our method is also remarkable for consistently improving\ntest performance with more training data and better network architectures. By\nfine-tuning the learned feature, we further obtain competitive results for\nsemi-supervised learning and object detection tasks. Our non-parametric model\nis highly compact: With 128 features per image, our method requires only 600MB\nstorage for a million images, enabling fast nearest neighbour retrieval at the\nrun time.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 00:47:01 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Wu", "Zhirong", ""], ["Xiong", "Yuanjun", ""], ["Yu", "Stella", ""], ["Lin", "Dahua", ""]]}, {"id": "1805.02043", "submitter": "Jaehun Kim", "authors": "Jaehun Kim, Minz Won, Xavier Serra, Cynthia C. S. Liem", "title": "Transfer Learning of Artist Group Factors to Musical Genre\n  Classification", "comments": "The Web Conference 2018", "journal-ref": null, "doi": "10.1145/3184558.3191823", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automated recognition of music genres from audio information is a\nchallenging problem, as genre labels are subjective and noisy. Artist labels\nare less subjective and less noisy, while certain artists may relate more\nstrongly to certain genres. At the same time, at prediction time, it is not\nguaranteed that artist labels are available for a given audio segment.\nTherefore, in this work, we propose to apply the transfer learning framework,\nlearning artist-related information which will be used at inference time for\ngenre classification. We consider different types of artist-related\ninformation, expressed through artist group factors, which will allow for more\nefficient learning and stronger robustness to potential label noise.\nFurthermore, we investigate how to achieve the highest validation accuracy on\nthe given FMA dataset, by experimenting with various kinds of transfer methods,\nincluding single-task transfer, multi-task transfer and finally multi-task\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 11:17:49 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 00:25:53 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Kim", "Jaehun", ""], ["Won", "Minz", ""], ["Serra", "Xavier", ""], ["Liem", "Cynthia C. S.", ""]]}, {"id": "1805.02070", "submitter": "Yu-Jhe Li", "authors": "Yu-Jhe Li, Hsin-Yu Chang, Yu-Jing Lin, Po-Wei Wu, and Yu-Chiang Frank\n  Wang", "title": "Deep Reinforcement Learning for Playing 2.5D Fighting Games", "comments": "ICIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has shown its success in game playing. However,\n2.5D fighting games would be a challenging task to handle due to ambiguity in\nvisual appearances like height or depth of the characters. Moreover, actions in\nsuch games typically involve particular sequential action orders, which also\nmakes the network design very difficult. Based on the network of Asynchronous\nAdvantage Actor-Critic (A3C), we create an OpenAI-gym-like gaming environment\nwith the game of Little Fighter 2 (LF2), and present a novel A3C+ network for\nlearning RL agents. The introduced model includes a Recurrent Info network,\nwhich utilizes game-related info features with recurrent layers to observe\ncombo skills for fighting. In the experiments, we consider LF2 in different\nsettings, which successfully demonstrates the use of our proposed model for\nlearning 2.5D fighting games.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 15:34:03 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Li", "Yu-Jhe", ""], ["Chang", "Hsin-Yu", ""], ["Lin", "Yu-Jing", ""], ["Wu", "Po-Wei", ""], ["Wang", "Yu-Chiang Frank", ""]]}, {"id": "1805.02087", "submitter": "Eric Strobl", "authors": "Eric V. Strobl", "title": "A Constraint-Based Algorithm For Causal Discovery with Cycles, Latent\n  Variables and Selection Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal processes in nature may contain cycles, and real datasets may violate\ncausal sufficiency as well as contain selection bias. No constraint-based\ncausal discovery algorithm can currently handle cycles, latent variables and\nselection bias (CLS) simultaneously. I therefore introduce an algorithm called\nCyclic Causal Inference (CCI) that makes sound inferences with a conditional\nindependence oracle under CLS, provided that we can represent the cyclic causal\nprocess as a non-recursive linear structural equation model with independent\nerrors. Empirical results show that CCI outperforms CCD in the cyclic case as\nwell as rivals FCI and RFCI in the acyclic case.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 17:12:10 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Strobl", "Eric V.", ""]]}, {"id": "1805.02103", "submitter": "Ana Stanescu", "authors": "Ana Stanescu and Gaurav Pandey", "title": "Developing parsimonious ensembles using ensemble diversity within a\n  reinforcement learning framework", "comments": "Previously this version appeared as arXiv:2102.07344 which was\n  submitted as a new work by accident", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous ensembles built from the predictions of a wide variety and\nlarge number of diverse base predictors represent a potent approach to building\npredictive models for problems where the ideal base/individual predictor may\nnot be obvious. Ensemble selection is an especially promising approach here,\nnot only for improving prediction performance, but also because of its ability\nto select a collectively predictive subset, often a relatively small one, of\nthe base predictors. In this paper, we present a set of algorithms that\nexplicitly incorporate ensemble diversity, a known factor influencing\npredictive performance of ensembles, into a reinforcement learning framework\nfor ensemble selection. We rigorously tested these approaches on several\nchallenging problems and associated data sets, yielding that several of them\nproduced more accurate ensembles than those that don't explicitly consider\ndiversity. More importantly, these diversity-incorporating ensembles were much\nsmaller in size, i.e., more parsimonious, than the latter types of ensembles.\nThis can eventually aid the interpretation or reverse engineering of predictive\nmodels assimilated into the resultant ensemble(s).\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 18:53:32 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 23:39:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Stanescu", "Ana", ""], ["Pandey", "Gaurav", ""]]}, {"id": "1805.02123", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Population Anomaly Detection through Deep Gaussianization", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithmic method for population anomaly detection based on\ngaussianization through an adversarial autoencoder. This method is applicable\nto detection of `soft' anomalies in arbitrarily distributed highly-dimensional\ndata.\n  A soft, or population, anomaly is characterized by a shift in the\ndistribution of the data set, where certain elements appear with higher\nprobability than anticipated. Such anomalies must be detected by considering a\nsufficiently large sample set rather than a single sample.\n  Applications include, but not limited to, payment fraud trends, data\nexfiltration, disease clusters and epidemics, and social unrests. We evaluate\nthe method on several domains and obtain both quantitative results and\nqualitative insights.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 22:51:35 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1805.02136", "submitter": "Zhi Xu", "authors": "John N. Tsitsiklis, Kuang Xu, Zhi Xu", "title": "Private Sequential Learning", "comments": "Accepted for presentation at COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a private learning model to study an intrinsic tradeoff between\nprivacy and query complexity in sequential learning. Our model involves a\nlearner who aims to determine a scalar value, $v^*$, by sequentially querying\nan external database and receiving binary responses. In the meantime, an\nadversary observes the learner's queries, though not the responses, and tries\nto infer from them the value of $v^*$. The objective of the learner is to\nobtain an accurate estimate of $v^*$ using only a small number of queries,\nwhile simultaneously protecting her privacy by making $v^*$ provably difficult\nto learn for the adversary. Our main results provide tight upper and lower\nbounds on the learner's query complexity as a function of desired levels of\nprivacy and estimation accuracy. We also construct explicit query strategies\nwhose complexity is optimal up to an additive constant.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 02:16:31 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 05:11:40 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 15:13:56 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tsitsiklis", "John N.", ""], ["Xu", "Kuang", ""], ["Xu", "Zhi", ""]]}, {"id": "1805.02146", "submitter": "John Clemens", "authors": "John Clemens", "title": "Automatic Classification of Object Code Using Machine Learning", "comments": "Presented/Published at Digital Forensics Workshop (DFRWS) 2015", "journal-ref": null, "doi": "10.1016/j.diin.2015.05.007", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has repeatedly shown that machine learning techniques can be\napplied to either whole files or file fragments to classify them for analysis.\nWe build upon these techniques to show that for samples of un-labeled compiled\ncomputer object code, one can apply the same type of analysis to classify\nimportant aspects of the code, such as its target architecture and endianess.\nWe show that using simple byte-value histograms we retain enough information\nabout the opcodes within a sample to classify the target architecture with high\naccuracy, and then discuss heuristic-based features that exploit information\nwithin the operands to determine endianess. We introduce a dataset with over\n16000 code samples from 20 architectures and experimentally show that by using\nour features, classifiers can achieve very high accuracy with relatively small\nsample sizes.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 03:49:48 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Clemens", "John", ""]]}, {"id": "1805.02161", "submitter": "Makito Oku", "authors": "Makito Oku", "title": "Branching embedding: A heuristic dimensionality reduction algorithm\n  based on hierarchical clustering", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a new dimensionality reduction algorithm named branching\nembedding (BE). It converts a dendrogram to a two-dimensional scatter plot, and\nvisualizes the inherent structures of the original high-dimensional data. Since\nthe conversion part is not computationally demanding, the BE algorithm would be\nbeneficial for the case where hierarchical clustering is already performed.\nNumerical experiments revealed that the outputs of the algorithm moderately\npreserve the original hierarchical structures.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 07:07:42 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Oku", "Makito", ""]]}, {"id": "1805.02176", "submitter": "Mahdi Bazarghan", "authors": "Ehsan Rahmatizad KhajePasha, Mahdi Bazarghan, Hamidreza Kheiri\n  Manjili, Ramin Mohammadkhani and Ruhallah Amandi", "title": "Predicting clinical significance of BRCA1 and BRCA2 single nucleotide\n  substitution variants with unknown clinical significance using probabilistic\n  neural network and deep neural network-stacked autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-synonymous single nucleotide polymorphisms (nsSNPs) are single nucleotide\nsubstitution occurring in the coding region of a gene and leads to a change in\namino-acid sequence of protein. The studies have shown these variations may be\nassociated with disease. Thus, investigating the effects of nsSNPs on protein\nfunction will give a greater insight on how nsSNPs can lead into disease.\nBreast cancer is the most common cancer among women causing highest cancer\ndeath every year. BRCA1 and BRCA2 tumor suppressor genes are two main\ncandidates of which, mutations in them can increase the risk of developing\nbreast cancer. For prediction and detection of the cancer one can use\nexperimental or computational methods, but the experimental method is very\ncostly and time consuming in comparison with the computational method. The\ncomputer and computational methods have been used for more than 30 years. Here\nwe try to predict the clinical significance of BRCA1 and BRCA2 nsSNPs as well\nas the unknown clinical significances. Nearly 500 BRCA1 and BRCA2 nsSNPs with\nknown clinical significances retrieved from NCBI database. Based on\nhydrophobicity or hydrophilicity and their role in proteins' second structure,\nthey are divided into 6 groups, each assigned with scores. The data are\nprepared in the acceptable form to the automated prediction mechanisms,\nProbabilistic Neural Network (PNN) and Deep Neural NetworkStacked AutoEncoder\n(DNN). With Jackknife cross validation we show that the prediction accuracy\nachieved for BRCA1 and BRCA2 using PNN are 87.97% and 82.17% respectively,\nwhile 95.41% and 92.80% accuracies achieved using DNN. The total required\nprocessing time for the training and testing the PNN is 0.9 second and DNN\nrequires about 7 hours of training and it can predict instantly. both methods\nshow great improvement in accuracy and speed compared to previous attempts.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 09:38:02 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["KhajePasha", "Ehsan Rahmatizad", ""], ["Bazarghan", "Mahdi", ""], ["Manjili", "Hamidreza Kheiri", ""], ["Mohammadkhani", "Ramin", ""], ["Amandi", "Ruhallah", ""]]}, {"id": "1805.02214", "submitter": "Marek Rei", "authors": "Marek Rei, Anders S{\\o}gaard", "title": "Zero-shot Sequence Labeling: Transferring Knowledge from Sentences to\n  Tokens", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can attention- or gradient-based visualization techniques be used to infer\ntoken-level labels for binary sequence tagging problems, using networks trained\nonly on sentence-level labels? We construct a neural network architecture based\non soft attention, train it as a binary sentence classifier and evaluate\nagainst token-level annotation on four different datasets. Inferring token\nlabels from a network provides a method for quantitatively evaluating what the\nmodel is learning, along with generating useful feedback in assistance systems.\nOur results indicate that attention-based methods are able to predict\ntoken-level labels more accurately, compared to gradient-based methods,\nsometimes even rivaling the supervised oracle network.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 13:53:50 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Rei", "Marek", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1805.02232", "submitter": "Han Liu", "authors": "Han Liu, Xiangnan He, Fuli Feng, Liqiang Nie, Rui Liu, Hanwang Zhang", "title": "Discrete Factorization Machines for Fast Feature-based Recommendation", "comments": "Appeared in IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User and item features of side information are crucial for accurate\nrecommendation. However, the large number of feature dimensions, e.g., usually\nlarger than 10^7, results in expensive storage and computational cost. This\nprohibits fast recommendation especially on mobile applications where the\ncomputational resource is very limited. In this paper, we develop a generic\nfeature-based recommendation model, called Discrete Factorization Machine\n(DFM), for fast and accurate recommendation. DFM binarizes the real-valued\nmodel parameters (e.g., float32) of every feature embedding into binary codes\n(e.g., boolean), and thus supports efficient storage and fast user-item score\ncomputation. To avoid the severe quantization loss of the binarization, we\npropose a convergent updating rule that resolves the challenging discrete\noptimization of DFM. Through extensive experiments on two real-world datasets,\nwe show that 1) DFM consistently outperforms state-of-the-art binarized\nrecommendation models, and 2) DFM shows very competitive performance compared\nto its real-valued version (FM), demonstrating the minimized quantization loss.\nThis work is accepted by IJCAI 2018.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 15:24:54 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 09:08:36 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 08:56:16 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Liu", "Han", ""], ["He", "Xiangnan", ""], ["Feng", "Fuli", ""], ["Nie", "Liqiang", ""], ["Liu", "Rui", ""], ["Zhang", "Hanwang", ""]]}, {"id": "1805.02242", "submitter": "Wenjie Ruan", "authors": "Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska", "title": "Reachability Analysis of Deep Neural Networks with Provable Guarantees", "comments": "This is the long version of the conference paper accepted in\n  IJCAI-2018. Github: https://github.com/TrustAI/DeepGO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying correctness of deep neural networks (DNNs) is challenging. We study\na generic reachability problem for feed-forward DNNs which, for a given set of\ninputs to the network and a Lipschitz-continuous function over its outputs,\ncomputes the lower and upper bound on the function values. Because the network\nand the function are Lipschitz continuous, all values in the interval between\nthe lower and upper bound are reachable. We show how to obtain the safety\nverification problem, the output range analysis problem and a robustness\nmeasure by instantiating the reachability problem. We present a novel algorithm\nbased on adaptive nested optimisation to solve the reachability problem. The\ntechnique has been implemented and evaluated on a range of DNNs, demonstrating\nits efficiency, scalability and ability to handle a broader class of networks\nthan state-of-the-art verification approaches.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 16:33:52 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1805.02257", "submitter": "Lingrui Gan", "authors": "Lingrui Gan, Naveen N. Narisetty, Feng Liang", "title": "Bayesian Regularization for Graphical Models with Unequal Shrinkage", "comments": "To appear in Journal of the American Statistical Association (Theory\n  & Methods)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Bayesian framework for estimating a high-dimensional sparse\nprecision matrix, in which adaptive shrinkage and sparsity are induced by a\nmixture of Laplace priors. Besides discussing our formulation from the Bayesian\nstandpoint, we investigate the MAP (maximum a posteriori) estimator from a\npenalized likelihood perspective that gives rise to a new non-convex penalty\napproximating the $\\ell_0$ penalty. Optimal error rates for estimation\nconsistency in terms of various matrix norms along with selection consistency\nfor sparse structure recovery are shown for the unique MAP estimator under mild\nconditions. For fast and efficient computation, an EM algorithm is proposed to\ncompute the MAP estimator of the precision matrix and (approximate) posterior\nprobabilities on the edges of the underlying sparse structure. Through\nextensive simulation studies and a real application to a call center data, we\nhave demonstrated the fine performance of our method compared with existing\nalternatives.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 18:16:21 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 18:31:59 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Gan", "Lingrui", ""], ["Narisetty", "Naveen N.", ""], ["Liang", "Feng", ""]]}, {"id": "1805.02269", "submitter": "Shubhranshu Shekhar", "authors": "Shubhranshu Shekhar and Leman Akoglu", "title": "Incorporating Privileged Information to Unsupervised Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new unsupervised anomaly detection ensemble called SPI which\ncan harness privileged information - data available only for training examples\nbut not for (future) test examples. Our ideas build on the Learning Using\nPrivileged Information (LUPI) paradigm pioneered by Vapnik et al. [19,17],\nwhich we extend to unsupervised learning and in particular to anomaly\ndetection. SPI (for Spotting anomalies with Privileged Information) constructs\na number of frames/fragments of knowledge (i.e., density estimates) in the\nprivileged space and transfers them to the anomaly scoring space through\n\"imitation\" functions that use only the partial information available for test\nexamples. Our generalization of the LUPI paradigm to unsupervised anomaly\ndetection shepherds the field in several key directions, including (i) domain\nknowledge-augmented detection using expert annotations as PI, (ii) fast\ndetection using computationally-demanding data as PI, and (iii) early detection\nusing \"historical future\" data as PI. Through extensive experiments on\nsimulated and real datasets, we show that augmenting privileged information to\nanomaly detection significantly improves detection performance. We also\ndemonstrate the promise of SPI under all three settings (i-iii); with PI\ncapturing expert knowledge, computationally expensive features, and future data\non three real world detection tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 19:53:45 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 05:58:08 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Shekhar", "Shubhranshu", ""], ["Akoglu", "Leman", ""]]}, {"id": "1805.02279", "submitter": "Naji Khosravan", "authors": "Naji Khosravan and Ulas Bagci", "title": "S4ND: Single-Shot Single-Scale Lung Nodule Detection", "comments": "Accepted for publication at MICCAI 2018 (21st International\n  Conference on Medical Image Computing and Computer Assisted Intervention)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art lung nodule detection studies rely on computationally\nexpensive multi-stage frameworks to detect nodules from CT scans. To address\nthis computational challenge and provide better performance, in this paper we\npropose S4ND, a new deep learning based method for lung nodule detection. Our\napproach uses a single feed forward pass of a single network for detection and\nprovides better performance when compared to the current literature. The whole\ndetection pipeline is designed as a single $3D$ Convolutional Neural Network\n(CNN) with dense connections, trained in an end-to-end manner. S4ND does not\nrequire any further post-processing or user guidance to refine detection\nresults. Experimentally, we compared our network with the current\nstate-of-the-art object detection network (SSD) in computer vision as well as\nthe state-of-the-art published method for lung nodule detection (3D DCNN). We\nused publically available $888$ CT scans from LUNA challenge dataset and showed\nthat the proposed method outperforms the current literature both in terms of\nefficiency and accuracy by achieving an average FROC-score of $0.897$. We also\nprovide an in-depth analysis of our proposed network to shed light on the\nunclear paradigms of tiny object detection.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 21:32:14 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 18:26:28 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Khosravan", "Naji", ""], ["Bagci", "Ulas", ""]]}, {"id": "1805.02285", "submitter": "Yen-Yun Yu", "authors": "Yen-Yun Yu, Shireen Y. Elhabian, Ross T. Whitaker", "title": "Clustering With Pairwise Relationships: A Generative Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) has become important in current data analysis\napplications, where the amount of unlabeled data is growing exponentially and\nuser input remains limited by logistics and expense. Constrained clustering, as\na subclass of SSL, makes use of user input in the form of relationships between\ndata points (e.g., pairs of data points belonging to the same class or\ndifferent classes) and can remarkably improve the performance of unsupervised\nclustering in order to reflect user-defined knowledge of the relationships\nbetween particular data points. Existing algorithms incorporate such user\ninput, heuristically, as either hard constraints or soft penalties, which are\nseparate from any generative or statistical aspect of the clustering model;\nthis results in formulations that are suboptimal and not sufficiently general.\nIn this paper, we propose a principled, generative approach to\nprobabilistically model, without ad hoc penalties, the joint distribution given\nby user-defined pairwise relations. The proposed model accounts for general\nunderlying distributions without assuming a specific form and relies on\nexpectation-maximization for model fitting. For distributions in a standard\nform, the proposed approach results in a closed-form solution for updated\nparameters.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 22:33:24 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Yu", "Yen-Yun", ""], ["Elhabian", "Shireen Y.", ""], ["Whitaker", "Ross T.", ""]]}, {"id": "1805.02294", "submitter": "Stephen Notley", "authors": "Stephen Notley, Malik Magdon-Ismail", "title": "Examining the Use of Neural Networks for Feature Extraction: A\n  Comparative Analysis using Deep Learning, Support Vector Machines, and\n  K-Nearest Neighbor Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks in many varieties are touted as very powerful machine\nlearning tools because of their ability to distill large amounts of information\nfrom different forms of data, extracting complex features and enabling powerful\nclassification abilities. In this study, we use neural networks to extract\nfeatures from both images and numeric data and use these extracted features as\ninputs for other machine learning models, namely support vector machines (SVMs)\nand k-nearest neighbor classifiers (KNNs), in order to see if\nneural-network-extracted features enhance the capabilities of these models. We\ntested 7 different neural network architectures in this manner, 4 for images\nand 3 for numeric data, training each for varying lengths of time and then\ncomparing the results of the neural network independently to those of an SVM\nand KNN on the data, and finally comparing these results to models of SVM and\nKNN trained using features extracted via the neural network architecture. This\nprocess was repeated on 3 different image datasets and 2 different numeric\ndatasets. The results show that, in many cases, the features extracted using\nthe neural network significantly improve the capabilities of SVMs and KNNs\ncompared to running these algorithms on the raw features, and in some cases\nalso surpass the performance of the neural network alone. This in turn suggests\nthat it may be a reasonable practice to use neural networks as a means to\nextract features for classification by other machine learning models for some\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 23:41:18 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 13:11:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Notley", "Stephen", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1805.02296", "submitter": "Sara Bahaadini", "authors": "Sara Bahaadini, Vahid Noroozi, Neda Rohani, Scott Coughlin, Michael\n  Zevin, and Aggelos K. Katsaggelos", "title": "DIRECT: Deep Discriminative Embedding for Clustering of LIGO Data", "comments": "This work has been accepted to be presented in the 25th IEEE\n  International Conference on Image Processing (ICIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, benefiting from the strong ability of deep neural network in\nestimating non-linear functions, we propose a discriminative embedding function\nto be used as a feature extractor for clustering tasks. The trained embedding\nfunction transfers knowledge from the domain of a labeled set of\nmorphologically-distinct images, known as classes, to a new domain within which\nnew classes can potentially be isolated and identified. Our target application\nin this paper is the Gravity Spy Project, which is an effort to characterize\ntransient, non-Gaussian noise present in data from the Advanced Laser\nInterferometer Gravitational-wave Observatory, or LIGO. Accumulating large,\nlabeled sets of noise features and identifying of new classes of noise lead to\na better understanding of their origin, which makes their removal from the data\nand/or detectors possible.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 00:13:30 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Bahaadini", "Sara", ""], ["Noroozi", "Vahid", ""], ["Rohani", "Neda", ""], ["Coughlin", "Scott", ""], ["Zevin", "Michael", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "1805.02306", "submitter": "Ruoqing Zhu", "authors": "Jack Yutong Li, Ruoqing Zhu, Annie Qu, Han Ye, Zhankun Sun", "title": "Semi-orthogonal Non-negative Matrix Factorization with an Application in\n  Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency Department (ED) crowding is a worldwide issue that affects the\nefficiency of hospital management and the quality of patient care. This occurs\nwhen the request for an admit ward-bed to receive a patient is delayed until an\nadmission decision is made by a doctor. To reduce the overcrowding and waiting\ntime of ED, we build a classifier to predict the disposition of patients using\nmanually-typed nurse notes collected during triage, thereby allowing hospital\nstaff to begin necessary preparation beforehand. However, these triage notes\ninvolve high dimensional, noisy, and also sparse text data which makes model\nfitting and interpretation difficult. To address this issue, we propose the\nsemi-orthogonal non-negative matrix factorization (SONMF) for both continuous\nand binary design matrices to first bi-cluster the patients and words into a\nreduced number of topics. The subjects can then be interpreted as a\nnon-subtractive linear combination of orthogonal basis topic vectors. These\ngenerated topic vectors provide the hospital with a direct understanding of the\ncause of admission. We show that by using a transformation of basis, the\nclassification accuracy can be further increased compared to the conventional\nbag-of-words model and alternative matrix factorization approaches. Through\nsimulated data experiments, we also demonstrate that the proposed method\noutperforms other non-negative matrix factorization (NMF) methods in terms of\nfactorization accuracy, rate of convergence, and degree of orthogonality.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 01:12:12 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 19:12:37 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 15:46:21 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Li", "Jack Yutong", ""], ["Zhu", "Ruoqing", ""], ["Qu", "Annie", ""], ["Ye", "Han", ""], ["Sun", "Zhankun", ""]]}, {"id": "1805.02338", "submitter": "Yingkai Li", "authors": "Yingkai Li, Huidong Liu", "title": "Implementation of Stochastic Quasi-Newton's Method in PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we implement the Stochastic Damped LBFGS (SdLBFGS) for\nstochastic non-convex optimization. We make two important modifications to the\noriginal SdLBFGS algorithm. First, by initializing the Hessian at each step\nusing an identity matrix, the algorithm converges better than original\nalgorithm. Second, by performing direction normalization we could gain stable\noptimization procedure without line search. Experiments on minimizing a 2D\nnon-convex function shows that our improved algorithm converges better than\noriginal algorithm, and experiments on the CIFAR10 and MNIST datasets show that\nour improved algorithm works stably and gives comparable or even better testing\naccuracies than first order optimizers SGD, Adagrad, and second order\noptimizers LBFGS in PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 04:13:26 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Li", "Yingkai", ""], ["Liu", "Huidong", ""]]}, {"id": "1805.02349", "submitter": "Tselil Schramm", "authors": "Boaz Barak, Chi-Ning Chou, Zhixian Lei, Tselil Schramm, Yueqi Sheng", "title": "(Nearly) Efficient Algorithms for the Graph Matching Problem on\n  Correlated Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a quasipolynomial time algorithm for the graph matching problem (also\nknown as noisy or robust graph isomorphism) on correlated random graphs.\nSpecifically, for every $\\gamma>0$, we give a $n^{O(\\log n)}$ time algorithm\nthat given a pair of $\\gamma$-correlated $G(n,p)$ graphs $G_0,G_1$ with average\ndegree between $n^{\\varepsilon}$ and $n^{1/153}$ for $\\varepsilon = o(1)$,\nrecovers the \"ground truth\" permutation $\\pi\\in S_n$ that matches the vertices\nof $G_0$ to the vertices of $G_n$ in the way that minimizes the number of\nmismatched edges. We also give a recovery algorithm for a denser regime, and a\npolynomial-time algorithm for distinguishing between correlated and\nuncorrelated graphs.\n  Prior work showed that recovery is information-theoretically possible in this\nmodel as long the average degree was at least $\\log n$, but sub-exponential\ntime algorithms were only known in the dense case (i.e., for $p > n^{-o(1)}$).\nMoreover, \"Percolation Graph Matching\", which is the most common heuristic for\nthis problem, has been shown to require knowledge of $n^{\\Omega(1)}$ \"seeds\"\n(i.e., input/output pairs of the permutation $\\pi$) to succeed in this regime.\nIn contrast our algorithms require no seed and succeed for $p$ which is as low\nas $n^{o(1)-1}$.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 05:38:41 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 23:32:37 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Barak", "Boaz", ""], ["Chou", "Chi-Ning", ""], ["Lei", "Zhixian", ""], ["Schramm", "Tselil", ""], ["Sheng", "Yueqi", ""]]}, {"id": "1805.02350", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang", "title": "Efficient active learning of sparse halfspaces", "comments": "To appear at COLT 2018; corrected a few typos in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficient PAC active learning of homogeneous linear\nclassifiers (halfspaces) in $\\mathbb{R}^d$, where the goal is to learn a\nhalfspace with low error using as few label queries as possible. Under the\nextra assumption that there is a $t$-sparse halfspace that performs well on the\ndata ($t \\ll d$), we would like our active learning algorithm to be {\\em\nattribute efficient}, i.e. to have label requirements sublinear in $d$. In this\npaper, we provide a computationally efficient algorithm that achieves this\ngoal. Under certain distributional assumptions on the data, our algorithm\nachieves a label complexity of $O(t \\cdot \\mathrm{polylog}(d, \\frac 1\n\\epsilon))$. In contrast, existing algorithms in this setting are either\ncomputationally inefficient, or subject to label requirements polynomial in $d$\nor $\\frac 1 \\epsilon$.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 05:49:20 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 16:27:28 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Zhang", "Chicheng", ""]]}, {"id": "1805.02396", "submitter": "Ziwei Zhang", "authors": "Ziwei Zhang, Peng Cui, Haoyang Li, Xiao Wang and Wenwu Zhu", "title": "Billion-scale Network Embedding with Iterative Random Projection", "comments": "Accepted by ICDM 2018. 10 pages, 8 figures, 2018 IEEE International\n  Conference on Data Mining (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding, which learns low-dimensional vector representation for\nnodes in the network, has attracted considerable research attention recently.\nHowever, the existing methods are incapable of handling billion-scale networks,\nbecause they are computationally expensive and, at the same time, difficult to\nbe accelerated by distributed computing schemes. To address these problems, we\npropose RandNE (Iterative Random Projection Network Embedding), a novel and\nsimple billion-scale network embedding method. Specifically, we propose a\nGaussian random projection approach to map the network into a low-dimensional\nembedding space while preserving the high-order proximities between nodes. To\nreduce the time complexity, we design an iterative projection procedure to\navoid the explicit calculation of the high-order proximities. Theoretical\nanalysis shows that our method is extremely efficient, and friendly to\ndistributed computing schemes without any communication cost in the\ncalculation. We also design a dynamic updating procedure which can efficiently\nincorporate the dynamic changes of the networks without error aggregation.\nExtensive experimental results demonstrate the efficiency and efficacy of\nRandNE over state-of-the-art methods in several tasks including network\nreconstruction, link prediction and node classification on multiple datasets\nwith different scales, ranging from thousands to billions of nodes and edges.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:28:45 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 12:26:57 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Ziwei", ""], ["Cui", "Peng", ""], ["Li", "Haoyang", ""], ["Wang", "Xiao", ""], ["Zhu", "Wenwu", ""]]}, {"id": "1805.02399", "submitter": "Nilavra Bhattacharya", "authors": "Nilavra Bhattacharya, Jacek Gwizdka", "title": "Relating Eye-Tracking Measures With Changes In Knowledge on Search Tasks", "comments": "ACM Symposium on Eye Tracking Research and Applications (ETRA), June\n  14-17, 2018, Warsaw, Poland", "journal-ref": "Proceedings of the 2018 ACM Symposium on Eye Tracking Research &\n  Applications", "doi": "10.1145/3204493.3204579", "report-no": null, "categories": "cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conducted an eye-tracking study where 30 participants performed searches\non the web. We measured their topical knowledge before and after each task.\nTheir eye-fixations were labelled as \"reading\" or \"scanning\". The series of\nreading fixations in a line, called \"reading-sequences\" were characterized by\ntheir length in pixels, fixation duration, and the number of fixations making\nup the sequence. We hypothesize that differences in knowledge-change of\nparticipants are reflected in their eye-tracking measures related to reading.\nOur results show that the participants with higher change in knowledge differ\nsignificantly in terms of their total reading-sequence-length,\nreading-sequence-duration, and number of reading fixations, when compared to\nparticipants with lower knowledge-change.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:33:59 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bhattacharya", "Nilavra", ""], ["Gwizdka", "Jacek", ""]]}, {"id": "1805.02411", "submitter": "Marinka Zitnik", "authors": "Marinka Zitnik and Rok Sosic and Jure Leskovec", "title": "Prioritizing network communities", "comments": null, "journal-ref": "Nature Communications, 9:2544, 2018", "doi": "10.1038/s41467-018-04948-5", "report-no": null, "categories": "cs.SI cs.LG q-bio.MN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncovering modular structure in networks is fundamental for systems in\nbiology, physics, and engineering. Community detection identifies candidate\nmodules as hypotheses, which then need to be validated through experiments,\nsuch as mutagenesis in a biological laboratory. Only a few communities can\ntypically be validated, and it is thus important to prioritize which\ncommunities to select for downstream experimentation. Here we develop CRank, a\nmathematically principled approach for prioritizing network communities. CRank\nefficiently evaluates robustness and magnitude of structural features of each\ncommunity and then combines these features into the community prioritization.\nCRank can be used with any community detection method. It needs only\ninformation provided by the network structure and does not require any\nadditional metadata or labels. However, when available, CRank can incorporate\ndomain-specific information to further boost performance. Experiments on many\nlarge networks show that CRank effectively prioritizes communities, yielding a\nnearly 50-fold improvement in community prioritization.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 09:30:34 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 18:36:42 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Zitnik", "Marinka", ""], ["Sosic", "Rok", ""], ["Leskovec", "Jure", ""]]}, {"id": "1805.02474", "submitter": "Linfeng Song", "authors": "Yue Zhang, Qi Liu and Linfeng Song", "title": "Sentence-State LSTM for Text Representation", "comments": "ACL 18 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bi-directional LSTMs are a powerful tool for text representation. On the\nother hand, they have been shown to suffer various limitations due to their\nsequential nature. We investigate an alternative LSTM structure for encoding\ntext, which consists of a parallel state for each word. Recurrent steps are\nused to perform local and global information exchange between words\nsimultaneously, rather than incremental reading of a sequence of words. Results\non various classification and sequence labelling benchmarks show that the\nproposed model has strong representation power, giving highly competitive\nperformances compared to stacked BiLSTM models with similar parameter numbers.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 12:36:54 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zhang", "Yue", ""], ["Liu", "Qi", ""], ["Song", "Linfeng", ""]]}, {"id": "1805.02483", "submitter": "Alexander Jung", "authors": "Henrik Ambos, Nguyen Tran, Alexander Jung", "title": "The Logistic Network Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the network Lasso to solve binary classification and clustering\nproblems for network-structured data. To this end, we generalize ordinary\nlogistic regression to non-Euclidean data with an intrinsic network structure.\nThe resulting \"logistic network Lasso\" amounts to solving a non-smooth convex\nregularized empirical risk minimization. The risk is measured using the\nlogistic loss incurred over a small set of labeled nodes. For the\nregularization, we propose to use the total variation of the classifier\nrequiring it to conform to the underlying network structure. A scalable\nimplementation of the learning method is obtained using an inexact variant of\nthe alternating direction methods of multipliers which results in a scalable\nlearning algorithm\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 12:50:36 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 12:39:33 GMT"}, {"version": "v3", "created": "Sat, 4 Aug 2018 15:15:07 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 17:46:39 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Ambos", "Henrik", ""], ["Tran", "Nguyen", ""], ["Jung", "Alexander", ""]]}, {"id": "1805.02489", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck", "title": "Transformer for Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the UMONS solution for the OMG-Emotion Challenge. We\nexplore a context-dependent architecture where the arousal and valence of an\nutterance are predicted according to its surrounding context (i.e. the\npreceding and following utterances of the video). We report an improvement when\ntaking into account context for both unimodal and multimodal predictions.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:42:57 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 13:03:59 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""]]}, {"id": "1805.02536", "submitter": "Francisco Cruz", "authors": "Francisco Cruz, Oriol Ramos Terrades", "title": "A probabilistic framework for handwritten text line segmentation", "comments": "47 pages, 23 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We successfully combine Expectation-Maximization algorithm and variational\napproaches for parameter learning and computing inference on Markov random\nfelds. This is a general method that can be applied to many computer vision\ntasks. In this paper, we apply it to handwritten text line segmentation. We\nconduct several experiments that demonstrate that our method deal with common\nissues of this task, such as complex document layout or non-latin scripts. The\nobtained results prove that our method achieve state-of-the-art performance on\ndifferent benchmark datasets without any particular fine tuning step.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 14:10:20 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 08:50:13 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Cruz", "Francisco", ""], ["Terrades", "Oriol Ramos", ""]]}, {"id": "1805.02566", "submitter": "Hyoukjun Kwon", "authors": "Hyoukjun Kwon, Prasanth Chatarasi, Michael Pellauer, Angshuman\n  Parashar, Vivek Sarkar, Tushar Krishna", "title": "Understanding Reuse, Performance, and Hardware Cost of DNN Dataflows: A\n  Data-Centric Approach Using MAESTRO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data partitioning and scheduling strategies used by DNN accelerators to\nleverage reuse and perform staging are known as dataflow, and they directly\nimpact the performance and energy efficiency of DNN accelerator designs. An\naccelerator microarchitecture dictates the dataflow(s) that can be employed to\nexecute a layer or network. Selecting an optimal dataflow for a layer shape can\nhave a large impact on utilization and energy efficiency, but there is a lack\nof understanding on the choices and consequences of dataflows, and of tools and\nmethodologies to help architects explore the co-optimization design space. In\nthis work, we first introduce a set of data-centric directives to concisely\nspecify the space of DNN dataflows in a compilerfriendly form. We then show how\nthese directives can be analyzed to infer various forms of reuse and to exploit\nthem using hardware capabilities. We codify this analysis into an analytical\ncost model, MAESTRO (Modeling Accelerator Efficiency via Spatio-Temporal Reuse\nand Occupancy), that estimates various cost-benefit tradeoffs of a dataflow\nincluding execution time and energy efficiency for a DNN model and hardware\nconfiguration. We demonstrate the use of MAESTRO to drive a hardware design\nspace exploration (DSE) experiment, which searches across 480M designs to\nidentify 2.5M valid designs at an average rate of 0.17M designs per second,\nincluding Pareto-optimal throughput- and energy-optimized design points.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 15:36:44 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 17:09:00 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 17:53:17 GMT"}, {"version": "v4", "created": "Sun, 8 Sep 2019 01:02:40 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 23:41:20 GMT"}, {"version": "v6", "created": "Mon, 11 May 2020 17:08:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kwon", "Hyoukjun", ""], ["Chatarasi", "Prasanth", ""], ["Pellauer", "Michael", ""], ["Parashar", "Angshuman", ""], ["Sarkar", "Vivek", ""], ["Krishna", "Tushar", ""]]}, {"id": "1805.02587", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski", "title": "Sharp Analysis of a Simple Model for Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests have become an important tool for improving accuracy in\nregression and classification problems since their inception by Leo Breiman in\n2001. In this paper, we revisit a historically important random forest model\noriginally proposed by Breiman in 2004 and later studied by G\\'erard Biau in\n2012, where a feature is selected at random and the splits occurs at the\nmidpoint of the node along the chosen feature. If the regression function is\nLipschitz and depends only on a small subset of $ S $ out of $ d $ features, we\nshow that, given access to $ n $ observations and properly tuned split\nprobabilities, the mean-squared prediction error is $ O((n(\\log\nn)^{(S-1)/2})^{-\\frac{1}{S\\log2+1}}) $. This positively answers an outstanding\nquestion of Biau about whether the rate of convergence for this random forest\nmodel could be improved. Furthermore, by a refined analysis of the\napproximation and estimation errors for linear models, we show that this rate\ncannot be improved in general. Finally, we generalize our analysis and improve\nextant prediction error bounds for another random forest model in which each\ntree is constructed from subsampled data and the splits are performed at the\nempirical median along a chosen feature.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 15:52:48 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 21:52:46 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 00:38:32 GMT"}, {"version": "v4", "created": "Tue, 26 Jun 2018 18:40:29 GMT"}, {"version": "v5", "created": "Fri, 21 Sep 2018 04:32:56 GMT"}, {"version": "v6", "created": "Mon, 17 Jun 2019 01:08:34 GMT"}, {"version": "v7", "created": "Mon, 22 Jun 2020 22:46:20 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Klusowski", "Jason M.", ""]]}, {"id": "1805.02590", "submitter": "Alejandro Frery", "authors": "J. M. Scavuzzo and F. Trucco and M. Espinosa and C. B. Tauro and M.\n  Abril and C. M. Scavuzzo and A. C. Frery", "title": "Modeling Dengue Vector Population Using Remotely Sensed Data and Machine\n  Learning", "comments": "Accepted for publication in Acta Tropica", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mosquitoes are vectors of many human diseases. In particular, Aedes \\ae gypti\n(Linnaeus) is the main vector for Chikungunya, Dengue, and Zika viruses in\nLatin America and it represents a global threat. Public health policies that\naim at combating this vector require dependable and timely information, which\nis usually expensive to obtain with field campaigns. For this reason, several\nefforts have been done to use remote sensing due to its reduced cost. The\npresent work includes the temporal modeling of the oviposition activity\n(measured weekly on 50 ovitraps in a north Argentinean city) of Aedes \\ae gypti\n(Linnaeus), based on time series of data extracted from operational earth\nobservation satellite images. We use are NDVI, NDWI, LST night, LST day and\nTRMM-GPM rain from 2012 to 2016 as predictive variables. In contrast to\nprevious works which use linear models, we employ Machine Learning techniques\nusing completely accessible open source toolkits. These models have the\nadvantages of being non-parametric and capable of describing nonlinear\nrelationships between variables. Specifically, in addition to two linear\napproaches, we assess a Support Vector Machine, an Artificial Neural Networks,\na K-nearest neighbors and a Decision Tree Regressor. Considerations are made on\nparameter tuning and the validation and training approach. The results are\ncompared to linear models used in previous works with similar data sets for\ngenerating temporal predictive models. These new tools perform better than\nlinear approaches, in particular Nearest Neighbor Regression (KNNR) performs\nthe best. These results provide better alternatives to be implemented\noperatively on the Argentine geospatial Risk system that is running since 2012.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 16:43:34 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Scavuzzo", "J. M.", ""], ["Trucco", "F.", ""], ["Espinosa", "M.", ""], ["Tauro", "C. B.", ""], ["Abril", "M.", ""], ["Scavuzzo", "C. M.", ""], ["Frery", "A. C.", ""]]}, {"id": "1805.02627", "submitter": "Rodrigo Fernandes de Mello", "authors": "Rodrigo Fernandes de Mello, Moacir Antonelli Ponti, Carlos Henrique\n  Grossi Ferreira", "title": "Computing the Shattering Coefficient of Supervised Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Statistical Learning Theory (SLT) provides the theoretical guarantees for\nsupervised machine learning based on the Empirical Risk Minimization Principle\n(ERMP). Such principle defines an upper bound to ensure the uniform convergence\nof the empirical risk Remp(f), i.e., the error measured on a given data sample,\nto the expected value of risk R(f) (a.k.a. actual risk), which depends on the\nJoint Probability Distribution P(X x Y) mapping input examples x in X to class\nlabels y in Y. The uniform convergence is only ensured when the Shattering\ncoefficient N(F,2n) has a polynomial growing behavior. This paper proves the\nShattering coefficient for any Hilbert space H containing the input space X and\ndiscusses its effects in terms of learning guarantees for supervised machine\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 17:22:55 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 11:06:06 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 17:32:20 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 13:02:27 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["de Mello", "Rodrigo Fernandes", ""], ["Ponti", "Moacir Antonelli", ""], ["Ferreira", "Carlos Henrique Grossi", ""]]}, {"id": "1805.02642", "submitter": "Oren Elisha", "authors": "Shai Dekel, Oren Elisha, Ohad Morgan", "title": "Wavelet Decomposition of Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a significant improvement to the popular\ntree-based Stochastic Gradient Boosting algorithm using a wavelet decomposition\nof the trees. This approach is based on harmonic analysis and approximation\ntheoretical elements, and as we show through extensive experimentation, our\nwavelet based method generally outperforms existing methods, particularly in\ndifficult scenarios of class unbalance and mislabeling in the training data.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 17:52:44 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 13:23:49 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Dekel", "Shai", ""], ["Elisha", "Oren", ""], ["Morgan", "Ohad", ""]]}, {"id": "1805.02677", "submitter": "Santosh Vempala", "authors": "Santosh Vempala and John Wilmes", "title": "Gradient Descent for One-Hidden-Layer Neural Networks: Polynomial\n  Convergence and SQ Lower Bounds", "comments": "Revised version now includes matching lower bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of training neural network models with one hidden\nnonlinear activation layer and an output weighted sum layer. We analyze\nGradient Descent applied to learning a bounded target function on $n$\nreal-valued inputs. We give an agnostic learning guarantee for GD: starting\nfrom a randomly initialized network, it converges in mean squared loss to the\nminimum error (in $2$-norm) of the best approximation of the target function\nusing a polynomial of degree at most $k$. Moreover, for any $k$, the size of\nthe network and number of iterations needed are both bounded by\n$n^{O(k)}\\log(1/\\epsilon)$. In particular, this applies to training networks of\nunbiased sigmoids and ReLUs. We also rigorously explain the empirical finding\nthat gradient descent discovers lower frequency Fourier components before\nhigher frequency components.\n  We complement this result with nearly matching lower bounds in the\nStatistical Query model. GD fits well in the SQ framework since each training\nstep is determined by an expectation over the input distribution. We show that\nany SQ algorithm that achieves significant improvement over a constant function\nwith queries of tolerance some inverse polynomial in the input dimensionality\n$n$ must use $n^{\\Omega(k)}$ queries even when the target functions are\nrestricted to a set of $n^{O(k)}$ degree-$k$ polynomials, and the input\ndistribution is uniform over the unit sphere; for this class the\ninformation-theoretic lower bound is only $\\Theta(k \\log n)$.\n  Our approach for both parts is based on spherical harmonics. We view gradient\ndescent as an operator on the space of functions, and study its dynamics. An\nessential tool is the Funk-Hecke theorem, which explains the eigenfunctions of\nthis operator in the case of the mean squared loss.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 18:07:19 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 11:15:17 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 17:30:12 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Vempala", "Santosh", ""], ["Wilmes", "John", ""]]}, {"id": "1805.02686", "submitter": "Evangelos Pournaras", "authors": "Evangelos Pournaras, Srivatsan Yadhunathan, Ada Diaconescu", "title": "Holarchic Structures for Decentralized Deep Learning - A Performance\n  Analysis", "comments": null, "journal-ref": null, "doi": "10.1007/s10586-019-02906-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure plays a key role in learning performance. In centralized\ncomputational systems, hyperparameter optimization and regularization\ntechniques such as dropout are computational means to enhance learning\nperformance by adjusting the deep hierarchical structure. However, in\ndecentralized deep learning by the Internet of Things, the structure is an\nactual network of autonomous interconnected devices such as smart phones that\ninteract via complex network protocols. Self-adaptation of the learning\nstructure is a challenge. Uncertainties such as network latency, node and link\nfailures or even bottlenecks by limited processing capacity and energy\navailability can signif- icantly downgrade learning performance. Network\nself-organization and self-management is complex, while it requires additional\ncomputational and network resources that hinder the feasibility of\ndecentralized deep learning. In contrast, this paper introduces a self-adaptive\nlearning approach based on holarchic learning structures for exploring,\nmitigating and boosting learning performance in distributed environments with\nuncertainties. A large-scale performance analysis with 864000 experiments fed\nwith synthetic and real-world data from smart grid and smart city pilot\nprojects confirm the cost-effectiveness of holarchic structures for\ndecentralized deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 18:33:43 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 21:51:57 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Pournaras", "Evangelos", ""], ["Yadhunathan", "Srivatsan", ""], ["Diaconescu", "Ada", ""]]}, {"id": "1805.02716", "submitter": "Eliu Huerta", "authors": "E. A. Huerta, Daniel George, Zhizhen Zhao and Gabrielle Allen", "title": "Real-time regression analysis with deep convolutional neural networks", "comments": "3 pages. Position Paper accepted to SciML2018: DOE ASCR Workshop on\n  Scientific Machine Learning. North Bethesda, MD, United States, January\n  30-February 1, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the development of novel deep learning algorithms to enable\nreal-time regression analysis for time series data. We showcase the application\nof this new method with a timely case study, and then discuss the applicability\nof this approach to tackle similar challenges across science domains.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 19:43:26 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Huerta", "E. A.", ""], ["George", "Daniel", ""], ["Zhao", "Zhizhen", ""], ["Allen", "Gabrielle", ""]]}, {"id": "1805.02722", "submitter": "Noah Apthorpe", "authors": "Daniel Hahn, Noah Apthorpe, Nick Feamster", "title": "Detecting Compressed Cleartext Traffic from Consumer Internet of Things\n  Devices", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data encryption is the primary method of protecting the privacy of consumer\ndevice Internet communications from network observers. The ability to\nautomatically detect unencrypted data in network traffic is therefore an\nessential tool for auditing Internet-connected devices. Existing methods\nidentify network packets containing cleartext but cannot differentiate packets\ncontaining encrypted data from packets containing compressed unencrypted data,\nwhich can be easily recovered by reversing the compression algorithm. This\nmakes it difficult for consumer protection advocates to identify devices that\nrisk user privacy by sending sensitive data in a compressed unencrypted format.\nHere, we present the first technique to automatically distinguish encrypted\nfrom compressed unencrypted network transmissions on a per-packet basis. We\napply three machine learning models and achieve a maximum 66.9% accuracy with a\nconvolutional neural network trained on raw packet data. This result is a\nbaseline for this previously unstudied machine learning problem, which we hope\nwill motivate further attention and accuracy improvements. To facilitate\ncontinuing research on this topic, we have made our training and test datasets\navailable to the public.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 19:56:47 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Hahn", "Daniel", ""], ["Apthorpe", "Noah", ""], ["Feamster", "Nick", ""]]}, {"id": "1805.02730", "submitter": "Ken C. L. Wong", "authors": "Ken C. L. Wong, Alexandros Karargyris, Tanveer Syeda-Mahmood, Mehdi\n  Moradi", "title": "Building Disease Detection Algorithms with Very Small Numbers of\n  Positive Samples", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-66179-7_54", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning can provide promising results in medical image\nanalysis, the lack of very large annotated datasets confines its full\npotential. Furthermore, limited positive samples also create unbalanced\ndatasets which limit the true positive rates of trained models. As unbalanced\ndatasets are mostly unavoidable, it is greatly beneficial if we can extract\nuseful knowledge from negative samples to improve classification accuracy on\nlimited positive samples. To this end, we propose a new strategy for building\nmedical image analysis pipelines that target disease detection. We train a\ndiscriminative segmentation model only on normal images to provide a source of\nknowledge to be transferred to a disease detection classifier. We show that\nusing the feature maps of a trained segmentation network, deviations from\nnormal anatomy can be learned by a two-class classification network on an\nextremely unbalanced training dataset with as little as one positive for 17\nnegative samples. We demonstrate that even though the segmentation network is\nonly trained on normal cardiac computed tomography images, the resulting\nfeature maps can be used to detect pericardial effusion and cardiac septal\ndefects with two-class convolutional classification networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 20:26:14 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Wong", "Ken C. L.", ""], ["Karargyris", "Alexandros", ""], ["Syeda-Mahmood", "Tanveer", ""], ["Moradi", "Mehdi", ""]]}, {"id": "1805.02777", "submitter": "Chun Kai Ling", "authors": "Chun Kai Ling, Fei Fang, J. Zico Kolter", "title": "What game are we playing? End-to-end learning in normal and extensive\n  form games", "comments": "Fixed typos and updated experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent work in AI has made great progress in solving large,\nzero-sum, extensive-form games, the underlying assumption in most past work is\nthat the parameters of the game itself are known to the agents. This paper\ndeals with the relatively under-explored but equally important \"inverse\"\nsetting, where the parameters of the underlying game are not known to all\nagents, but must be learned through observations. We propose a differentiable,\nend-to-end learning framework for addressing this task. In particular, we\nconsider a regularized version of the game, equivalent to a particular form of\nquantal response equilibrium, and develop 1) a primal-dual Newton method for\nfinding such equilibrium points in both normal and extensive form games; and 2)\na backpropagation method that lets us analytically compute gradients of all\nrelevant game parameters through the solution itself. This ultimately lets us\nlearn the game by training in an end-to-end fashion, effectively by integrating\na \"differentiable game solver\" into the loop of larger deep network\narchitectures. We demonstrate the effectiveness of the learning method in\nseveral settings including poker and security game tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 23:17:18 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 21:57:09 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1805.02785", "submitter": "Joshua Bertram", "authors": "Joshua R. Bertram, Xuxi Yang, and Peng Wei", "title": "Fast Online Exact Solutions for Deterministic MDPs with Sparse Rewards", "comments": "Submitted to NIPS 2018; preprint version posted here. 8 pages\n  content, appendices include pseudocode and proof for algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Decision Processes (MDPs) are a mathematical framework for modeling\nsequential decision making under uncertainty. The classical approaches for\nsolving MDPs are well known and have been widely studied, some of which rely on\napproximation techniques to solve MDPs with large state space and/or action\nspace. However, most of these classical solution approaches and their\napproximation techniques still take much computation time to converge and\nusually must be re-computed if the reward function is changed. This paper\nintroduces a novel alternative approach for exactly and efficiently solving\ndeterministic, continuous MDPs with sparse reward sources. When the environment\nis such that the \"distance\" between states can be determined in constant time,\ne.g. grid world, our algorithm offers $O( |R|^2 \\times |A|^2 \\times |S|)$,\nwhere $|R|$ is the number of reward sources, $|A|$ is the number of actions,\nand $|S|$ is the number of states. Memory complexity for the algorithm is $O(\n|S| + |R| \\times |A|)$. This new approach opens new avenues for boosting\ncomputational performance for certain classes of MDPs and is of tremendous\nvalue for MDP applications such as robotics and unmanned systems. This paper\ndescribes the algorithm and presents numerical experiment results to\ndemonstrate its powerful computational performance. We also provide rigorous\nmathematical description of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 00:12:43 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 12:48:00 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 15:55:27 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bertram", "Joshua R.", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "1805.02788", "submitter": "Mathieu Ravaut", "authors": "Aparna Balagopalan, Satya Gorti, Mathieu Ravaut, Raeid Saqur", "title": "ReGAN: RE[LAX|BAR|INFORCE] based Sequence Generation using GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have seen steep ascension to the peak\nof ML research zeitgeist in recent years. Mostly catalyzed by its success in\nthe domain of image generation, the technique has seen wide range of adoption\nin a variety of other problem domains. Although GANs have had a lot of success\nin producing more realistic images than other approaches, they have only seen\nlimited use for text sequences. Generation of longer sequences compounds this\nproblem. Most recently, SeqGAN (Yu et al., 2017) has shown improvements in\nadversarial evaluation and results with human evaluation compared to a MLE\nbased trained baseline. The main contributions of this paper are three-fold: 1.\nWe show results for sequence generation using a GAN architecture with efficient\npolicy gradient estimators, 2. We attain improved training stability, and 3. We\nperform a comparative study of recent unbiased low variance gradient estimation\ntechniques such as REBAR (Tucker et al., 2017), RELAX (Grathwohl et al., 2018)\nand REINFORCE (Williams, 1992). Using a simple grammar on synthetic datasets\nwith varying length, we indicate the quality of sequences generated by the\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 00:37:42 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Gorti", "Satya", ""], ["Ravaut", "Mathieu", ""], ["Saqur", "Raeid", ""]]}, {"id": "1805.02830", "submitter": "Ping Li", "authors": "Ping Li", "title": "Several Tunable GMM Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While tree methods have been popular in practice, researchers and\npractitioners are also looking for simple algorithms which can reach similar\naccuracy of trees. In 2010, (Ping Li UAI'10) developed the method of\n\"abc-robust-logitboost\" and compared it with other supervised learning methods\non datasets used by the deep learning literature. In this study, we propose a\nseries of \"tunable GMM kernels\" which are simple and perform largely comparably\nto tree methods on the same datasets. Note that \"abc-robust-logitboost\"\nsubstantially improved the original \"GDBT\" in that (a) it developed a\ntree-split formula based on second-order information of the derivatives of the\nloss function; (b) it developed a new set of derivatives for multi-class\nclassification formulation.\n  In the prior study in 2017, the \"generalized min-max\" (GMM) kernel was shown\nto have good performance compared to the \"radial-basis function\" (RBF) kernel.\nHowever, as demonstrated in this paper, the original GMM kernel is often not as\ncompetitive as tree methods on the datasets used in the deep learning\nliterature. Since the original GMM kernel has no parameters, we propose tunable\nGMM kernels by adding tuning parameters in various ways. Three basic (i.e.,\nwith only one parameter) GMM kernels are the \"$e$GMM kernel\", \"$p$GMM kernel\",\nand \"$\\gamma$GMM kernel\", respectively. Extensive experiments show that they\nare able to produce good results for a large number of classification tasks.\nFurthermore, the basic kernels can be combined to boost the performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 04:51:14 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "1805.02840", "submitter": "Maria Jofre", "authors": "Maria Jofre and Richard Gerlach", "title": "Fighting Accounting Fraud Through Forensic Data Analytics", "comments": "Working Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accounting fraud is a global concern representing a significant threat to the\nfinancial system stability due to the resulting diminishing of the market\nconfidence and trust of regulatory authorities. Several tricks can be used to\ncommit accounting fraud, hence the need for non-static regulatory interventions\nthat take into account different fraudulent patterns. Accordingly, this study\naims to improve the detection of accounting fraud via the implementation of\nseveral machine learning methods to better differentiate between fraud and\nnon-fraud companies, and to further assist the task of examination within the\nriskier firms by evaluating relevant financial indicators. Out-of-sample\nresults suggest there is a great potential in detecting falsified financial\nstatements through statistical modelling and analysis of publicly available\naccounting information. The proposed methodology can be of assistance to public\nauditors and regulatory agencies as it facilitates auditing processes, and\nsupports more targeted and effective examinations of accounting reports.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 05:31:49 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Jofre", "Maria", ""], ["Gerlach", "Richard", ""]]}, {"id": "1805.02848", "submitter": "Gunwoong Park", "authors": "Gunwoong Park, Hyewon Park", "title": "Identifiability of Generalized Hypergeometric Distribution (GHD)\n  Directed Acyclic Graphical Models", "comments": "24 pages, 7 figures, 2 tables. The 22nd International Conference on\n  Artificial Intelligence and Statistics. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of identifiable DAG models where the conditional\ndistribution of each node given its parents belongs to a family of generalized\nhypergeometric distributions (GHD). A family of generalized hypergeometric\ndistributions includes a lot of discrete distributions such as the binomial,\nBeta-binomial, negative binomial, Poisson, hyper-Poisson, and many more. We\nprove that if the data drawn from the new class of DAG models, one can fully\nidentify the graph structure. We further present a reliable and polynomial-time\nalgorithm that recovers the graph from finitely many data. We show through\ntheoretical results and numerical experiments that our algorithm is\nstatistically consistent in high-dimensional settings (p>n) if the indegree of\nthe graph is bounded, and out-performs state-of-the-art DAG learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 06:03:49 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 12:03:03 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 08:59:17 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Park", "Gunwoong", ""], ["Park", "Hyewon", ""]]}, {"id": "1805.02855", "submitter": "Neal Jean", "authors": "Neal Jean, Sherrie Wang, Anshul Samar, George Azzari, David Lobell,\n  Stefano Ermon", "title": "Tile2Vec: Unsupervised representation learning for spatially distributed\n  data", "comments": "8 pages, 4 figures in main text; 9 pages, 11 figures in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geospatial analysis lacks methods like the word vector representations and\npre-trained networks that significantly boost performance across a wide range\nof natural language and computer vision tasks. To fill this gap, we introduce\nTile2Vec, an unsupervised representation learning algorithm that extends the\ndistributional hypothesis from natural language -- words appearing in similar\ncontexts tend to have similar meanings -- to spatially distributed data. We\ndemonstrate empirically that Tile2Vec learns semantically meaningful\nrepresentations on three datasets. Our learned representations significantly\nimprove performance in downstream classification tasks and, similar to word\nvectors, visual analogies can be obtained via simple arithmetic in the latent\nspace.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 06:40:40 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 09:26:16 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Jean", "Neal", ""], ["Wang", "Sherrie", ""], ["Samar", "Anshul", ""], ["Azzari", "George", ""], ["Lobell", "David", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.02896", "submitter": "Ilya Verenich", "authors": "Ilya Verenich, Marlon Dumas, Marcello La Rosa, Fabrizio Maggi, Irene\n  Teinemaa", "title": "Survey and cross-benchmark comparison of remaining time prediction\n  methods in business process monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring methods exploit historical process\nexecution logs to generate predictions about running instances (called cases)\nof a business process, such as the prediction of the outcome, next activity or\nremaining cycle time of a given process case. These insights could be used to\nsupport operational managers in taking remedial actions as business processes\nunfold, e.g. shifting resources from one case onto another to ensure this\nlatter is completed on time. A number of methods to tackle the remaining cycle\ntime prediction problem have been proposed in the literature. However, due to\ndifferences in their experimental setup, choice of datasets, evaluation\nmeasures and baselines, the relative merits of each method remain unclear. This\narticle presents a systematic literature review and taxonomy of methods for\nremaining time prediction in the context of business processes, as well as a\ncross-benchmark comparison of 16 such methods based on 16 real-life datasets\noriginating from different industry domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 08:38:58 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 21:56:51 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Verenich", "Ilya", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Maggi", "Fabrizio", ""], ["Teinemaa", "Irene", ""]]}, {"id": "1805.02908", "submitter": "Mastane Achab", "authors": "Mastane Achab, Stephan Cl\\'emen\\c{c}on, Aur\\'elien Garivier", "title": "Profitable Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Originally motivated by default risk management applications, this paper\ninvestigates a novel problem, referred to as the profitable bandit problem\nhere. At each step, an agent chooses a subset of the K possible actions. For\neach action chosen, she then receives the sum of a random number of rewards.\nHer objective is to maximize her cumulated earnings. We adapt and study three\nwell-known strategies in this purpose, that were proved to be most efficient in\nother settings: kl-UCB, Bayes-UCB and Thompson Sampling. For each of them, we\nprove a finite time regret bound which, together with a lower bound we obtain\nas well, establishes asymptotic optimality. Our goal is also to compare these\nthree strategies from a theoretical and empirical perspective both at the same\ntime. We give simple, self-contained proofs that emphasize their similarities,\nas well as their differences. While both Bayesian strategies are automatically\nadapted to the geometry of information, the numerical experiments carried out\nshow a slight advantage for Thompson Sampling in practice.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:08:38 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Achab", "Mastane", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""], ["Garivier", "Aur\u00e9lien", ""]]}, {"id": "1805.02917", "submitter": "Motoki Sato", "authors": "Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto", "title": "Interpretable Adversarial Perturbation in Input Embedding Space for Text", "comments": "8 pages, 4 figures", "journal-ref": "IJCAI-ECAI-2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following great success in the image processing field, the idea of\nadversarial training has been applied to tasks in the natural language\nprocessing (NLP) field. One promising approach directly applies adversarial\ntraining developed in the image processing field to the input word embedding\nspace instead of the discrete input space of texts. However, this approach\nabandons such interpretability as generating adversarial texts to significantly\nimprove the performance of NLP tasks. This paper restores interpretability to\nsuch methods by restricting the directions of perturbations toward the existing\nwords in the input embedding space. As a result, we can straightforwardly\nreconstruct each input with perturbations to an actual text by considering the\nperturbations to be the replacement of words in the sentence while maintaining\nor even improving the task performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:27:46 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Sato", "Motoki", ""], ["Suzuki", "Jun", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1805.02971", "submitter": "Nan Li", "authors": "Mingdong Ou, Nan Li, Shenghuo Zhu, Rong Jin", "title": "Multinomial Logit Bandit with Linear Utility Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multinomial logit bandit is a sequential subset selection problem which\narises in many applications. In each round, the player selects a\n$K$-cardinality subset from $N$ candidate items, and receives a reward which is\ngoverned by a {\\it multinomial logit} (MNL) choice model considering both item\nutility and substitution property among items. The player's objective is to\ndynamically learn the parameters of MNL model and maximize cumulative reward\nover a finite horizon $T$. This problem faces the exploration-exploitation\ndilemma, and the involved combinatorial nature makes it non-trivial. In recent\nyears, there have developed some algorithms by exploiting specific\ncharacteristics of the MNL model, but all of them estimate the parameters of\nMNL model separately and incur a regret no better than\n$\\tilde{O}\\big(\\sqrt{NT}\\big)$ which is not preferred for large candidate set\nsize $N$. In this paper, we consider the {\\it linear utility} MNL choice model\nwhose item utilities are represented as linear functions of $d$-dimension item\nfeatures, and propose an algorithm, titled {\\bf LUMB}, to exploit the\nunderlying structure. It is proven that the proposed algorithm achieves\n$\\tilde{O}\\big(dK\\sqrt{T}\\big)$ regret which is free of candidate set size.\nExperiments show the superiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 12:23:54 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 08:04:16 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Ou", "Mingdong", ""], ["Li", "Nan", ""], ["Zhu", "Shenghuo", ""], ["Jin", "Rong", ""]]}, {"id": "1805.02983", "submitter": "Younghun Song", "authors": "Younghun Song, Jae-Gil Lee", "title": "Augmenting Recurrent Neural Networks with High-Order User-Contextual\n  Preference for Session-Based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent adoption of recurrent neural networks (RNNs) for session modeling\nhas yielded substantial performance gains compared to previous approaches. In\nterms of context-aware session modeling, however, the existing RNN-based models\nare limited in that they are not designed to explicitly model rich static\nuser-side contexts (e.g., age, gender, location). Therefore, in this paper, we\nexplore the utility of explicit user-side context modeling for RNN session\nmodels. Specifically, we propose an augmented RNN (ARNN) model that extracts\nhigh-order user-contextual preference using the product-based neural network\n(PNN) in order to augment any existing RNN session model. Evaluation results\nshow that our proposed model outperforms the baseline RNN session model by a\nlarge margin when rich user-side contexts are available.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 12:44:12 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Song", "Younghun", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1805.02991", "submitter": "Li He", "authors": "Li He, Qi Meng, Wei Chen, Zhi-Ming Ma, Tie-Yan Liu", "title": "Differential Equations for Modeling Asynchronous Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous stochastic gradient descent (ASGD) is a popular parallel\noptimization algorithm in machine learning. Most theoretical analysis on ASGD\ntake a discrete view and prove upper bounds for their convergence rates.\nHowever, the discrete view has its intrinsic limitations: there is no\ncharacterization of the optimization path and the proof techniques are\ninduction-based and thus usually complicated. Inspired by the recent successful\nadoptions of stochastic differential equations (SDE) to the theoretical\nanalysis of SGD, in this paper, we study the continuous approximation of ASGD\nby using stochastic differential delay equations (SDDE). We introduce the\napproximation method and study the approximation error. Then we conduct\ntheoretical analysis on the convergence rates of ASGD algorithm based on the\ncontinuous approximation. There are two methods: moment estimation and energy\nfunction minimization can be used to analyze the convergence rates. Moment\nestimation depends on the specific form of the loss function, while energy\nfunction minimization only leverages the convex property of the loss function,\nand does not depend on its specific form. In addition to the convergence\nanalysis, the continuous view also helps us derive better convergence rates.\nAll of this clearly shows the advantage of taking the continuous view in\ngradient descent algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 13:06:26 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["He", "Li", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1805.03006", "submitter": "Xijun Liang", "authors": "Xijun Liang, Zhonghang Xia, Yongxiang Wang, Ling Jian, Xinnan Niu,\n  Andrew Link", "title": "Efficient online learning for large-scale peptide identification", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Post-database searching is a key procedure in peptide\ndentification with tandem mass spectrometry (MS/MS) strategies for refining\npeptide-spectrum matches (PSMs) generated by database search engines. Although\nmany statistical and machine learning-based methods have been developed to\nimprove the accuracy of peptide identification, the challenge remains on\nlarge-scale datasets and datasets with an extremely large proportion of false\npositives (hard datasets). A more efficient learning strategy is required for\nimproving the performance of peptide identification on challenging datasets.\n  Results: In this work, we present an online learning method to conquer the\nchallenges remained for exiting peptide identification algorithms. We propose a\ncost-sensitive learning model by using different loss functions for decoy and\ntarget PSMs respectively. A larger penalty for wrongly selecting decoy PSMs\nthan that for target PSMs, and thus the new model can reduce its false\ndiscovery rate on hard datasets. Also, we design an online learning algorithm,\nOLCS-Ranker, to solve the proposed learning model. Rather than taking all\ntraining data samples all at once, OLCS-Ranker iteratively feeds in only one\ntraining sample into the learning model at each round. As a result, the memory\nrequirement is significantly reduced for large-scale problems. Experimental\nstudies show that OLCS-Ranker outperforms benchmark methods, such as CRanker\nand Batch-CS-Ranker, in terms of accuracy and stability. Furthermore,\nOLCS-Ranker is 15--85 times faster than CRanker method on large datasets.\n  Availability and implementation: OLCS-Ranker software is available at no\ncharge for non-commercial use at https://github.com/Isaac-QiXing/CRanker.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 13:32:40 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Liang", "Xijun", ""], ["Xia", "Zhonghang", ""], ["Wang", "Yongxiang", ""], ["Jian", "Ling", ""], ["Niu", "Xinnan", ""], ["Link", "Andrew", ""]]}, {"id": "1805.03033", "submitter": "Bogdan Penkovsky", "authors": "Bogdan Penkovsky, Laurent Larger, Daniel Brunner", "title": "Efficient Design of Hardware-Enabled Reservoir Computing in FPGAs", "comments": null, "journal-ref": null, "doi": "10.1063/1.5039826", "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new approach towards the efficient optimization\nand implementation of reservoir computing hardware reducing the required domain\nexpert knowledge and optimization effort. First, we adapt the reservoir input\nmask to the structure of the data via linear autoencoders. We therefore\nincorporate the advantages of dimensionality reduction and dimensionality\nexpansion achieved by conventional algorithmically efficient linear algebra\nprocedures of principal component analysis. Second, we employ\nevolutionary-inspired genetic algorithm techniques resulting in a highly\nefficient optimization of reservoir dynamics with dramatically reduced number\nof evaluations comparing to exhaustive search. We illustrate the method on the\nso-called single-node reservoir computing architecture, especially suitable for\nimplementation in ultrahigh-speed hardware. The combination of both methods and\nthe resulting reduction of time required for performance optimization of a\nhardware system establish a strategy towards machine learning hardware capable\nof self-adaption to optimally solve specific problems. We confirm the validity\nof those principles building reservoir computing hardware based on a\nfield-programmable gate array.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 07:40:59 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 16:59:14 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Penkovsky", "Bogdan", ""], ["Larger", "Laurent", ""], ["Brunner", "Daniel", ""]]}, {"id": "1805.03096", "submitter": "Tewodros Habtegebrial", "authors": "Christian Bailer, Tewodros Habtegebrial, Kiran varanasi, Didier\n  Stricker", "title": "Fast Feature Extraction with CNNs with Pooling Layers", "comments": "Accepted at BMVC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, many publications showed that convolutional neural network\nbased features can have a superior performance to engineered features. However,\nnot much effort was taken so far to extract local features efficiently for a\nwhole image. In this paper, we present an approach to compute patch-based local\nfeature descriptors efficiently in presence of pooling and striding layers for\nwhole images at once. Our approach is generic and can be applied to nearly all\nexisting network architectures. This includes networks for all local feature\nextraction tasks like camera calibration, Patchmatching, optical flow\nestimation and stereo matching. In addition, our approach can be applied to\nother patch-based approaches like sliding window object detection and\nrecognition. We complete our paper with a speed benchmark of popular CNN based\nfeature extraction approaches applied on a whole image, with and without our\nspeedup, and example code (for Torch) that shows how an arbitrary CNN\narchitecture can be easily converted by our approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:14:20 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Bailer", "Christian", ""], ["Habtegebrial", "Tewodros", ""], ["varanasi", "Kiran", ""], ["Stricker", "Didier", ""]]}, {"id": "1805.03117", "submitter": "M.C. David Marsh", "authors": "Theodor Bjorkmo and M.C. David Marsh", "title": "Local, algebraic simplifications of Gaussian random fields", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1475-7516/2018/12/022", "report-no": null, "categories": "astro-ph.CO cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of Gaussian random fields and Gaussian random processes are\nlimited by the computational complexity of evaluating the probability density\nfunction, which involves inverting the relevant covariance matrix. In this\nwork, we show how that problem can be completely circumvented for the local\nTaylor coefficients of a Gaussian random field with a Gaussian (or `square\nexponential') covariance function. Our results hold for any dimension of the\nfield and to any order in the Taylor expansion. We present two applications.\nFirst, we show that this method can be used to explicitly generate non-trivial\npotential energy landscapes with many fields. This application is particularly\nuseful when one is concerned with the field locally around special points\n(e.g.~maxima or minima), as we exemplify by the problem of cosmic `manyfield'\ninflation in the early universe. Second, we show that this method has\napplications in machine learning, and greatly simplifies the regression problem\nof determining the hyperparameters of the covariance function given a training\ndata set consisting of local Taylor coefficients at single point. An\naccompanying Mathematica notebook is available at\nhttps://doi.org/10.17863/CAM.22859 .\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:43:54 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Bjorkmo", "Theodor", ""], ["Marsh", "M. C. David", ""]]}, {"id": "1805.03162", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "Polite Dialogue Generation Without Parallel Data", "comments": "To Appear in TACL Journal (16 pages) (first submission cycle: Oct1\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylistic dialogue response generation, with valuable applications in\npersonality-based conversational agents, is a challenging task because the\nresponse needs to be fluent, contextually-relevant, as well as\nparalinguistically accurate. Moreover, parallel datasets for\nregular-to-stylistic pairs are usually unavailable. We present three\nweakly-supervised models that can generate diverse polite (or rude) dialogue\nresponses without parallel data. Our late fusion model (Fusion) merges the\ndecoder of an encoder-attention-decoder dialogue model with a language model\ntrained on stand-alone polite utterances. Our label-fine-tuning (LFT) model\nprepends to each source sequence a politeness-score scaled label (predicted by\nour state-of-the-art politeness classifier) during training, and at test time\nis able to generate polite, neutral, and rude responses by simply scaling the\nlabel embedding by the corresponding score. Our reinforcement learning model\n(Polite-RL) encourages politeness generation by assigning rewards proportional\nto the politeness classifier score of the sampled response. We also present two\nretrieval-based polite dialogue model baselines. Human evaluation validates\nthat while the Fusion and the retrieval-based models achieve politeness with\npoorer context-relevance, the LFT and Polite-RL models can produce\nsignificantly more polite responses without sacrificing dialogue quality.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 16:56:15 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.03278", "submitter": "Thomas Schlegl", "authors": "Thomas Schlegl (1 and 2), Hrvoje Bogunovic (2), Sophie Klimscha (2),\n  Philipp Seeb\\\"ock (1 and 2), Amir Sadeghipour (2), Bianca Gerendas (2),\n  Sebastian M. Waldstein (2), Georg Langs (1), Ursula Schmidt-Erfurth (2) ((1)\n  Department of Biomedical Imaging and Image-guided Therapy, Computational\n  Imaging Research Lab, Medical University Vienna, Austria, (2) Christian\n  Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology\n  and Optometry, Medical University Vienna, Austria)", "title": "Fully Automated Segmentation of Hyperreflective Foci in Optical\n  Coherence Tomography Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of disease related entities in retinal imaging data\nis relevant for disease- and treatment monitoring. It enables the quantitative\nassessment of large amounts of data and the corresponding study of disease\ncharacteristics. The presence of hyperreflective foci (HRF) is related to\ndisease progression in various retinal diseases. Manual identification of HRF\nin spectral-domain optical coherence tomography (SD-OCT) scans is error-prone\nand tedious. We present a fully automated machine learning approach for\nsegmenting HRF in SD-OCT scans. Evaluation on annotated OCT images of the\nretina demonstrates that a residual U-Net allows to segment HRF with high\naccuracy. As our dataset comprised data from different retinal diseases\nincluding age-related macular degeneration, diabetic macular edema and retinal\nvein occlusion, the algorithm can safely be applied in all of them though\ndifferent pathophysiological origins are known.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 20:49:57 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Schlegl", "Thomas", "", "1 and 2"], ["Bogunovic", "Hrvoje", "", "1 and 2"], ["Klimscha", "Sophie", "", "1 and 2"], ["Seeb\u00f6ck", "Philipp", "", "1 and 2"], ["Sadeghipour", "Amir", ""], ["Gerendas", "Bianca", ""], ["Waldstein", "Sebastian M.", ""], ["Langs", "Georg", ""], ["Schmidt-Erfurth", "Ursula", ""]]}, {"id": "1805.03294", "submitter": "Albert Zeyer", "authors": "Albert Zeyer, and Kazuki Irie, and Ralf Schl\\\"uter, and Hermann Ney", "title": "Improved training of end-to-end attention models for speech recognition", "comments": "submitted to Interspeech 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-1616", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence attention-based models on subword units allow simple\nopen-vocabulary end-to-end speech recognition. In this work, we show that such\nmodels can achieve competitive results on the Switchboard 300h and LibriSpeech\n1000h tasks. In particular, we report the state-of-the-art word error rates\n(WER) of 3.54% on the dev-clean and 3.82% on the test-clean evaluation subsets\nof LibriSpeech. We introduce a new pretraining scheme by starting with a high\ntime reduction factor and lowering it during training, which is crucial both\nfor convergence and final performance. In some experiments, we also use an\nauxiliary CTC loss function to help the convergence. In addition, we train long\nshort-term memory (LSTM) language models on subword units. By shallow fusion,\nwe report up to 27% relative improvements in WER over the attention baseline\nwithout a language model.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 21:27:04 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zeyer", "Albert", ""], ["Irie", "Kazuki", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1805.03305", "submitter": "Zheng Xu", "authors": "Zheng Xu, Xitong Yang, Xue Li, Xiaoshuai Sun", "title": "The Effectiveness of Instance Normalization: a Strong Baseline for\n  Single Image Dehazing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep neural network architecture for the challenging\nproblem of single image dehazing, which aims to recover the clear image from a\ndegraded hazy image. Instead of relying on hand-crafted image priors or\nexplicitly estimating the components of the widely used atmospheric scattering\nmodel, our end-to-end system directly generates the clear image from an input\nhazy image. The proposed network has an encoder-decoder architecture with skip\nconnections and instance normalization. We adopt the convolutional layers of\nthe pre-trained VGG network as encoder to exploit the representation power of\ndeep features, and demonstrate the effectiveness of instance normalization for\nimage dehazing. Our simple yet effective network outperforms the\nstate-of-the-art methods by a large margin on the benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 22:08:35 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Xu", "Zheng", ""], ["Yang", "Xitong", ""], ["Li", "Xue", ""], ["Sun", "Xiaoshuai", ""]]}, {"id": "1805.03327", "submitter": "Marinka Zitnik", "authors": "Bo Wang, Armin Pourshafeie, Marinka Zitnik, Junjie Zhu, Carlos D.\n  Bustamante, Serafim Batzoglou, and Jure Leskovec", "title": "Network Enhancement: a general method to denoise weighted biological\n  networks", "comments": null, "journal-ref": "Nature Communications, 9:3108, 2018", "doi": "10.1038/s41467-018-05469-x", "report-no": null, "categories": "q-bio.MN cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are ubiquitous in biology where they encode connectivity patterns at\nall scales of organization, from molecular to the biome. However, biological\nnetworks are noisy due to the limitations of measurement technology and\ninherent natural variation, which can hamper discovery of network patterns and\ndynamics. We propose Network Enhancement (NE), a method for improving the\nsignal-to-noise ratio of undirected, weighted networks. NE uses a doubly\nstochastic matrix operator that induces sparsity and provides a closed-form\nsolution that increases spectral eigengap of the input network. As a result, NE\nremoves weak edges, enhances real connections, and leads to better downstream\nperformance. Experiments show that NE improves gene function prediction by\ndenoising tissue-specific interaction networks, alleviates interpretation of\nnoisy Hi-C contact maps from the human genome, and boosts fine-grained\nidentification accuracy of species. Our results indicate that NE is widely\napplicable for denoising biological networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 00:22:03 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 21:28:54 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Wang", "Bo", ""], ["Pourshafeie", "Armin", ""], ["Zitnik", "Marinka", ""], ["Zhu", "Junjie", ""], ["Bustamante", "Carlos D.", ""], ["Batzoglou", "Serafim", ""], ["Leskovec", "Jure", ""]]}, {"id": "1805.03359", "submitter": "Peter Henderson", "authors": "Joshua Romoff, Peter Henderson, Alexandre Pich\\'e, Vincent\n  Francois-Lavet, Joelle Pineau", "title": "Reward Estimation for Variance Reduction in Deep Reinforcement Learning", "comments": "Version 1 as appears in the International Conference on Learning\n  Representations (ICLR) 2018 Workshop Track; Version 2 as appears in the\n  Proceedings of The 2nd Conference on Robot Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) agents require the specification of a reward\nsignal for learning behaviours. However, introduction of corrupt or stochastic\nrewards can yield high variance in learning. Such corruption may be a direct\nresult of goal misspecification, randomness in the reward signal, or\ncorrelation of the reward with external factors that are not known to the\nagent. Corruption or stochasticity of the reward signal can be especially\nproblematic in robotics, where goal specification can be particularly difficult\nfor complex tasks. While many variance reduction techniques have been studied\nto improve the robustness of the RL process, handling such stochastic or\ncorrupted reward structures remains difficult. As an alternative for handling\nthis scenario in model-free RL methods, we suggest using an estimator for both\nrewards and value functions. We demonstrate that this improves performance\nunder corrupted stochastic rewards in both the tabular and non-linear function\napproximation settings for a variety of noise types and environments. The use\nof reward estimation is a robust and easy-to-implement improvement for handling\ncorrupted reward signals in model-free RL.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 03:11:29 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 20:36:53 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Romoff", "Joshua", ""], ["Henderson", "Peter", ""], ["Pich\u00e9", "Alexandre", ""], ["Francois-Lavet", "Vincent", ""], ["Pineau", "Joelle", ""]]}, {"id": "1805.03364", "submitter": "Andy Shih", "authors": "Andy Shih, Arthur Choi, Adnan Darwiche", "title": "A Symbolic Approach to Explaining Bayesian Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach for explaining Bayesian network classifiers, which is\nbased on compiling such classifiers into decision functions that have a\ntractable and symbolic form. We introduce two types of explanations for why a\nclassifier may have classified an instance positively or negatively and suggest\nalgorithms for computing these explanations. The first type of explanation\nidentifies a minimal set of the currently active features that is responsible\nfor the current classification, while the second type of explanation identifies\na minimal set of features whose current state (active or not) is sufficient for\nthe classification. We consider in particular the compilation of Naive and\nLatent-Tree Bayesian network classifiers into Ordered Decision Diagrams (ODDs),\nproviding a context for evaluating our proposal using case studies and\nexperiments based on classifiers from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 03:56:24 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Shih", "Andy", ""], ["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1805.03379", "submitter": "Manqing Dong", "authors": "Manqing Dong, Lina Yao, Xianzhi Wang, Boualem Benatallah, Chaoran\n  Huang, Xiaodong Ning", "title": "Opinion Fraud Detection via Neural Autoencoder Decision Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews play an important role in influencing buyers' daily purchase\ndecisions. However, fake and meaningless reviews, which cannot reflect users'\ngenuine purchase experience and opinions, widely exist on the Web and pose\ngreat challenges for users to make right choices. Therefore,it is desirable to\nbuild a fair model that evaluates the quality of products by distinguishing\nspamming reviews. We present an end-to-end trainable unified model to leverage\nthe appealing properties from Autoencoder and random forest. A stochastic\ndecision tree model is implemented to guide the global parameter learning\nprocess. Extensive experiments were conducted on a large Amazon review dataset.\nThe proposed model consistently outperforms a series of compared methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 05:44:19 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Dong", "Manqing", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Benatallah", "Boualem", ""], ["Huang", "Chaoran", ""], ["Ning", "Xiaodong", ""]]}, {"id": "1805.03409", "submitter": "Yair Meidan", "authors": "Yair Meidan, Michael Bohadana, Yael Mathov, Yisroel Mirsky, Dominik\n  Breitenbacher, Asaf Shabtai, Yuval Elovici", "title": "N-BaIoT: Network-based Detection of IoT Botnet Attacks Using Deep\n  Autoencoders", "comments": "Accepted for publication in July September issue of IEEE Pervasive\n  Computing", "journal-ref": null, "doi": "10.1109/MPRV.2018.03367731", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The proliferation of IoT devices which can be more easily compromised than\ndesktop computers has led to an increase in the occurrence of IoT based botnet\nattacks. In order to mitigate this new threat there is a need to develop new\nmethods for detecting attacks launched from compromised IoT devices and\ndifferentiate between hour and millisecond long IoTbased attacks. In this paper\nwe propose and empirically evaluate a novel network based anomaly detection\nmethod which extracts behavior snapshots of the network and uses deep\nautoencoders to detect anomalous network traffic emanating from compromised IoT\ndevices. To evaluate our method, we infected nine commercial IoT devices in our\nlab with two of the most widely known IoT based botnets, Mirai and BASHLITE.\nOur evaluation results demonstrated our proposed method's ability to accurately\nand instantly detect the attacks as they were being launched from the\ncompromised IoT devices which were part of a botnet.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 08:26:40 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Meidan", "Yair", ""], ["Bohadana", "Michael", ""], ["Mathov", "Yael", ""], ["Mirsky", "Yisroel", ""], ["Breitenbacher", "Dominik", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "1805.03435", "submitter": "Dan Busbridge", "authors": "Vitalii Zhelezniak, Dan Busbridge, April Shen, Samuel L. Smith and\n  Nils Y. Hammerla", "title": "Decoding Decoders: Finding Optimal Representation Spaces for\n  Unsupervised Similarity Tasks", "comments": "ICLR 2018 Workshop Track, 15 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evidence indicates that simple models outperform complex deep\nnetworks on many unsupervised similarity tasks. We provide a simple yet\nrigorous explanation for this behaviour by introducing the concept of an\noptimal representation space, in which semantically close symbols are mapped to\nrepresentations that are close under a similarity measure induced by the\nmodel's objective function. In addition, we present a straightforward procedure\nthat, without any retraining or architectural modifications, allows deep\nrecurrent models to perform equally well (and sometimes better) when compared\nto shallow models. To validate our analysis, we conduct a set of consistent\nempirical evaluations and introduce several new sentence embedding models in\nthe process. Even though this work is presented within the context of natural\nlanguage processing, the insights are readily applicable to other domains that\nrely on distributed representations for transfer tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 09:41:51 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Busbridge", "Dan", ""], ["Shen", "April", ""], ["Smith", "Samuel L.", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1805.03441", "submitter": "Zheng Wang", "authors": "Zheng Wang and Michael O'Boyle", "title": "Machine Learning in Compiler Optimisation", "comments": "Accepted to be published at Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, machine learning based compilation has moved from an an\nobscure research niche to a mainstream activity. In this article, we describe\nthe relationship between machine learning and compiler optimisation and\nintroduce the main concepts of features, models, training and deployment. We\nthen provide a comprehensive survey and provide a road map for the wide variety\nof different research areas. We conclude with a discussion on open issues in\nthe area and potential research directions. This paper provides both an\naccessible introduction to the fast moving area of machine learning based\ncompilation and a detailed bibliography of its main achievements.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 10:04:28 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Wang", "Zheng", ""], ["O'Boyle", "Michael", ""]]}, {"id": "1805.03444", "submitter": "Woohyung Chun", "authors": "Woohyung Chun, Sung-Min Hong, Junho Huh and Inyup Kang", "title": "Controlling the privacy loss with the input feature maps of the layers\n  in convolutional neural networks", "comments": "9 pages (8 pages for contents) and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the method to sanitize the privacy of the IFM(Input Feature Map)s\nthat are fed into the layers of CNN(Convolutional Neural Network)s. The method\nintroduces the degree of the sanitization that makes the application using a\nCNN be able to control the privacy loss represented as the ratio of the\nprobabilistic accuracies for original IFM and sanitized IFM. For the\nsanitization of an IFM, the sample-and-hold based approximation scheme is\ndevised to satisfy an application-specific degree of the sanitization. The\nscheme approximates an IFM by replacing all the samples in a window with the\nnon-zero sample closest to the mean of the sampling window. It also removes the\ndependency on CNN configuration by unfolding multi-dimensional IFM tensors into\none-dimensional streams to be approximated.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 10:12:31 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 10:48:13 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 10:31:56 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 12:03:32 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chun", "Woohyung", ""], ["Hong", "Sung-Min", ""], ["Huh", "Junho", ""], ["Kang", "Inyup", ""]]}, {"id": "1805.03463", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an and Daniel Hern\\'andez-Lobato", "title": "Dealing with Categorical and Integer-valued Variables in Bayesian\n  Optimization with Gaussian Processes", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.004", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) methods are useful for optimizing functions that\nare expen- sive to evaluate, lack an analytical expression and whose\nevaluations can be contaminated by noise. These methods rely on a probabilistic\nmodel of the objective function, typically a Gaussian process (GP), upon which\nan acquisition function is built. The acquisition function guides the\noptimization process and measures the expected utility of performing an\nevaluation of the objective at a new point. GPs assume continous input\nvariables. When this is not the case, for example when some of the input\nvariables take categorical or integer values, one has to introduce extra\napproximations. Consider a suggested input location taking values in the real\nline. Before doing the evaluation of the objective, a common approach is to use\na one hot encoding approximation for categorical variables, or to round to the\nclosest integer, in the case of integer-valued variables. We show that this can\nlead to problems in the optimization process and describe a more principled\napproach to account for input variables that are categorical or integer-valued.\nWe illustrate in both synthetic and a real experiments the utility of our\napproach, which significantly improves the results of standard BO methods using\nGaussian processes on problems with categorical or integer-valued variables.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 11:51:52 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 16:06:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "1805.03504", "submitter": "Minglong Lei", "authors": "Yong Shi, Minglong Lei, Peng Zhang, Lingfeng Niu", "title": "Diffusion Based Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In network embedding, random walks play a fundamental role in preserving\nnetwork structures. However, random walk based embedding methods have two\nlimitations. First, random walk methods are fragile when the sampling frequency\nor the number of node sequences changes. Second, in disequilibrium networks\nsuch as highly biases networks, random walk methods often perform poorly due to\nthe lack of global network information. In order to solve the limitations, we\npropose in this paper a network diffusion based embedding method. To solve the\nfirst limitation, our method employs a diffusion driven process to capture both\ndepth information and breadth information. The time dimension is also attached\nto node sequences that can strengthen information preserving. To solve the\nsecond limitation, our method uses the network inference technique based on\ncascades to capture the global network information. To verify the performance,\nwe conduct experiments on node classification tasks using the learned\nrepresentations. Results show that compared with random walk based methods,\ndiffusion based models are more robust when samplings under each node is rare.\nWe also conduct experiments on a highly imbalanced network. Results shows that\nthe proposed model are more robust under the biased network structure.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 13:23:24 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 06:04:38 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Shi", "Yong", ""], ["Lei", "Minglong", ""], ["Zhang", "Peng", ""], ["Niu", "Lingfeng", ""]]}, {"id": "1805.03551", "submitter": "Yujian Li", "authors": "Yujian Li, Chuanhui Shan", "title": "A Unified Framework of Deep Neural Networks by Capsules", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of deep learning, how to describe deep neural networks\nunifiedly is becoming an important issue. We first formalize neural networks\nmathematically with their directed graph representations, and prove a\ngeneration theorem about the induced networks of connected directed acyclic\ngraphs. Then, we set up a unified framework for deep learning with capsule\nnetworks. This capsule framework could simplify the description of existing\ndeep neural networks, and provide a theoretical basis of graphic designing and\nprogramming techniques for deep learning models, thus would be of great\nsignificance to the advancement of deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 14:23:17 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 03:56:38 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Li", "Yujian", ""], ["Shan", "Chuanhui", ""]]}, {"id": "1805.03553", "submitter": "Abdullah Al-Dujaili", "authors": "Alex Huang, Abdullah Al-Dujaili, Erik Hemberg, Una-May O'Reilly", "title": "On Visual Hallmarks of Robustness to Adversarial Malware", "comments": "Submitted to the IReDLiA workshop at the Federated Artificial\n  Intelligence Meeting (FAIM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge of adversarial learning is to interpret the resulting\nhardened model. In this contribution, we ask how robust generalization can be\nvisually discerned and whether a concise view of the interactions between a\nhardened decision map and input samples is possible. We first provide a means\nof visually comparing a hardened model's loss behavior with respect to the\nadversarial variants generated during training versus loss behavior with\nrespect to adversarial variants generated from other sources. This allows us to\nconfirm that the association of observed flatness of a loss landscape with\ngeneralization that is seen with naturally trained models extends to\nadversarially hardened models and robust generalization. To complement these\nmeans of interpreting model parameter robustness we also use self-organizing\nmaps to provide a visual means of superimposing adversarial and natural\nvariants on a model's decision space, thus allowing the model's global\nrobustness to be comprehensively examined.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 14:28:42 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Huang", "Alex", ""], ["Al-Dujaili", "Abdullah", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1805.03586", "submitter": "Baoxiang Wang", "authors": "Jiajin Li, Baoxiang Wang", "title": "Policy Optimization with Second-Order Advantage Information", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization on high-dimensional continuous control tasks exhibits its\ndifficulty caused by the large variance of the policy gradient estimators. We\npresent the action subspace dependent gradient (ASDG) estimator which\nincorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a\nunified framework to reduce the variance. To invoke RB, our proposed algorithm\n(POSA) learns the underlying factorization structure among the action space\nbased on the second-order advantage information. POSA captures the quadratic\ninformation explicitly and efficiently by utilizing the wide & deep\narchitecture. Empirical studies show that our proposed approach demonstrates\nthe performance improvements on high-dimensional synthetic settings and OpenAI\nGym's MuJoCo continuous control tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 15:23:58 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 09:47:11 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Li", "Jiajin", ""], ["Wang", "Baoxiang", ""]]}, {"id": "1805.03591", "submitter": "Bingcong Li", "authors": "Bingcong Li, Tianyi Chen, and Georgios B. Giannakis", "title": "Secure Mobile Edge Computing in IoT via Collaborative Online Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2949504", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accommodate heterogeneous tasks in Internet of Things (IoT), a new\ncommunication and computing paradigm termed mobile edge computing emerges that\nextends computing services from the cloud to edge, but at the same time exposes\nnew challenges on security. The present paper studies online security-aware\nedge computing under jamming attacks. Leveraging online learning tools, novel\nalgorithms abbreviated as SAVE-S and SAVE-A are developed to cope with the\nstochastic and adversarial forms of jamming, respectively. Without utilizing\nextra resources such as spectrum and transmission power to evade jamming\nattacks, SAVE-S and SAVE-A can select the most reliable server to offload\ncomputing tasks with minimal privacy and security concerns. It is analytically\nestablished that without any prior information on future jamming and server\nsecurity risks, the proposed schemes can achieve ${\\cal O}\\big(\\sqrt{T}\\big)$\nregret. Information sharing among devices can accelerate the security-aware\ncomputing tasks. Incorporating the information shared by other devices, SAVE-S\nand SAVE-A offer impressive improvements on the sublinear regret, which is\nguaranteed by what is termed \"value of cooperation.\" Effectiveness of the\nproposed schemes is tested on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 15:39:17 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Li", "Bingcong", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1805.03616", "submitter": "Yunzhe Tao", "authors": "Li Wang, Junlin Yao, Yunzhe Tao, Li Zhong, Wei Liu, Qiang Du", "title": "A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for\n  Abstractive Text Summarization", "comments": "International Joint Conference on Artificial Intelligence and\n  European Conference on Artificial Intelligence (IJCAI-ECAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning approach to tackle the automatic\nsummarization tasks by incorporating topic information into the convolutional\nsequence-to-sequence (ConvS2S) model and using self-critical sequence training\n(SCST) for optimization. Through jointly attending to topics and word-level\nalignment, our approach can improve coherence, diversity, and informativeness\nof generated summaries via a biased probability generation mechanism. On the\nother hand, reinforcement training, like SCST, directly optimizes the proposed\nmodel with respect to the non-differentiable metric ROUGE, which also avoids\nthe exposure bias during inference. We carry out the experimental evaluation\nwith state-of-the-art methods over the Gigaword, DUC-2004, and LCSTS datasets.\nThe empirical results demonstrate the superiority of our proposed method in the\nabstractive summarization.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 16:56:41 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 14:51:32 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 06:42:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Wang", "Li", ""], ["Yao", "Junlin", ""], ["Tao", "Yunzhe", ""], ["Zhong", "Li", ""], ["Liu", "Wei", ""], ["Du", "Qiang", ""]]}, {"id": "1805.03620", "submitter": "Sebastian Ruder", "authors": "Anders S{\\o}gaard, Sebastian Ruder, Ivan Vuli\\'c", "title": "On the Limitations of Unsupervised Bilingual Dictionary Induction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised machine translation---i.e., not assuming any cross-lingual\nsupervision signal, whether a dictionary, translations, or comparable\ncorpora---seems impossible, but nevertheless, Lample et al. (2018) recently\nproposed a fully unsupervised machine translation (MT) model. The model relies\nheavily on an adversarial, unsupervised alignment of word embedding spaces for\nbilingual dictionary induction (Conneau et al., 2018), which we examine here.\nOur results identify the limitations of current unsupervised MT: unsupervised\nbilingual dictionary induction performs much worse on morphologically rich\nlanguages that are not dependent marking, when monolingual corpora from\ndifferent domains or different embedding algorithms are used. We show that a\nsimple trick, exploiting a weak supervision signal from identical words,\nenables more robust induction, and establish a near-perfect correlation between\nunsupervised bilingual dictionary induction performance and a previously\nunexplored graph similarity metric.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 17:08:03 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["S\u00f8gaard", "Anders", ""], ["Ruder", "Sebastian", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.03642", "submitter": "Yanshuai Cao", "authors": "Avishek Joey Bose, Huan Ling, Yanshuai Cao", "title": "Adversarial Contrastive Estimation", "comments": "Association for Computational Linguistics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning by contrasting positive and negative samples is a general strategy\nadopted by many methods. Noise contrastive estimation (NCE) for word embeddings\nand translating embeddings for knowledge graphs are examples in NLP employing\nthis approach. In this work, we view contrastive learning as an abstraction of\nall such methods and augment the negative sampler into a mixture distribution\ncontaining an adversarially learned sampler. The resulting adaptive sampler\nfinds harder negative examples, which forces the main model to learn a better\nrepresentation of the data. We evaluate our proposal on learning word\nembeddings, order embeddings and knowledge graph embeddings and observe both\nfaster convergence and improved results on multiple metrics.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 04:06:30 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 20:20:39 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 20:34:14 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Ling", "Huan", ""], ["Cao", "Yanshuai", ""]]}, {"id": "1805.03643", "submitter": "Fei Tian", "authors": "Yang Fan, Fei Tian, Tao Qin, Xiang-Yang Li, Tie-Yan Liu", "title": "Learning to Teach", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching plays a very important role in our society, by spreading human\nknowledge and educating our next generations. A good teacher will select\nappropriate teaching materials, impact suitable methodologies, and set up\ntargeted examinations, according to the learning behaviors of the students. In\nthe field of artificial intelligence, however, one has not fully explored the\nrole of teaching, and pays most attention to machine \\emph{learning}. In this\npaper, we argue that equal attention, if not more, should be paid to teaching,\nand furthermore, an optimization framework (instead of heuristics) should be\nused to obtain good teaching strategies. We call this approach `learning to\nteach'. In the approach, two intelligent agents interact with each other: a\nstudent model (which corresponds to the learner in traditional machine learning\nalgorithms), and a teacher model (which determines the appropriate data, loss\nfunction, and hypothesis space to facilitate the training of the student\nmodel). The teacher model leverages the feedback from the student model to\noptimize its own teaching strategies by means of reinforcement learning, so as\nto achieve teacher-student co-evolution. To demonstrate the practical value of\nour proposed approach, we take the training of deep neural networks (DNN) as an\nexample, and show that by using the learning to teach techniques, we are able\nto use much less training data and fewer iterations to achieve almost the same\naccuracy for different kinds of DNN models (e.g., multi-layer perceptron,\nconvolutional neural networks and recurrent neural networks) under various\nmachine learning tasks (e.g., image classification and text understanding).\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 04:41:26 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Fan", "Yang", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Li", "Xiang-Yang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1805.03644", "submitter": "Yanshuai Cao", "authors": "Yanshuai Cao, Gavin Weiguang Ding, Kry Yik-Chau Lui, Ruitong Huang", "title": "Improving GAN Training via Binarized Representation Entropy (BRE)\n  Regularization", "comments": "Published as a conference paper at the 6th International Conference\n  on Learning Representations (ICLR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel regularizer to improve the training of Generative\nAdversarial Networks (GANs). The motivation is that when the discriminator D\nspreads out its model capacity in the right way, the learning signals given to\nthe generator G are more informative and diverse. These in turn help G to\nexplore better and discover the real data manifold while avoiding large\nunstable jumps due to the erroneous extrapolation made by D. Our regularizer\nguides the rectifier discriminator D to better allocate its model capacity, by\nencouraging the binary activation patterns on selected internal layers of D to\nhave a high joint entropy. Experimental results on both synthetic data and real\ndatasets demonstrate improvements in stability and convergence speed of the GAN\ntraining, as well as higher sample quality. The approach also leads to higher\nclassification accuracies in semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 06:31:24 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cao", "Yanshuai", ""], ["Ding", "Gavin Weiguang", ""], ["Lui", "Kry Yik-Chau", ""], ["Huang", "Ruitong", ""]]}, {"id": "1805.03647", "submitter": "Emre Cakir", "authors": "Emre \\c{C}ak{\\i}r and Tuomas Virtanen", "title": "End-to-End Polyphonic Sound Event Detection Using Convolutional\n  Recurrent Neural Networks with Learned Time-Frequency Representation Input", "comments": "accepted to IJCNN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound event detection systems typically consist of two stages: extracting\nhand-crafted features from the raw audio waveform, and learning a mapping\nbetween these features and the target sound events using a classifier.\nRecently, the focus of sound event detection research has been mostly shifted\nto the latter stage using standard features such as mel spectrogram as the\ninput for classifiers such as deep neural networks. In this work, we utilize\nend-to-end approach and propose to combine these two stages in a single deep\nneural network classifier. The feature extraction over the raw waveform is\nconducted by a feedforward layer block, whose parameters are initialized to\nextract the time-frequency representations. The feature extraction parameters\nare updated during training, resulting with a representation that is optimized\nfor the specific task. This feature extraction block is followed by (and\njointly trained with) a convolutional recurrent network, which has recently\ngiven state-of-the-art results in many sound recognition tasks. The proposed\nsystem does not outperform a convolutional recurrent network with fixed\nhand-crafted features. The final magnitude spectrum characteristics of the\nfeature extraction block parameters indicate that the most relevant information\nfor the given task is contained in 0 - 3 kHz frequency range, and this is also\nsupported by the empirical results on the SED performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 15:10:57 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["\u00c7ak\u0131r", "Emre", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1805.03687", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Statistical Analysis on E-Commerce Reviews, with Sentiment\n  Classification using Bidirectional Recurrent Neural Network (RNN)", "comments": "21 pages, 29 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding customer sentiments is of paramount importance in marketing\nstrategies today. Not only will it give companies an insight as to how\ncustomers perceive their products and/or services, but it will also give them\nan idea on how to improve their offers. This paper attempts to understand the\ncorrelation of different variables in customer reviews on a women clothing\ne-commerce, and to classify each review whether it recommends the reviewed\nproduct or not and whether it consists of positive, negative, or neutral\nsentiment. To achieve these goals, we employed univariate and multivariate\nanalyses on dataset features except for review titles and review texts, and we\nimplemented a bidirectional recurrent neural network (RNN) with long-short term\nmemory unit (LSTM) for recommendation and sentiment classification. Results\nhave shown that a recommendation is a strong indicator of a positive sentiment\nscore, and vice-versa. On the other hand, ratings in product reviews are fuzzy\nindicators of sentiment scores. We also found out that the bidirectional LSTM\nwas able to reach an F1-score of 0.88 for recommendation classification, and\n0.93 for sentiment classification.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 11:58:20 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:10:51 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1805.03714", "submitter": "Zelda Mariet", "authors": "Vitaly Kuznetsov and Zelda Mariet", "title": "Foundations of Sequence-to-Sequence Modeling for Time Series", "comments": "To appear at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The availability of large amounts of time series data, paired with the\nperformance of deep-learning algorithms on a broad class of problems, has\nrecently led to significant interest in the use of sequence-to-sequence models\nfor time series forecasting. We provide the first theoretical analysis of this\ntime series forecasting framework. We include a comparison of\nsequence-to-sequence modeling to classical time series models, and as such our\ntheory can serve as a quantitative guide for practitioners choosing between\ndifferent modeling methodologies.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:03:37 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 15:55:15 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Kuznetsov", "Vitaly", ""], ["Mariet", "Zelda", ""]]}, {"id": "1805.03716", "submitter": "Omer Levy", "authors": "Omer Levy, Kenton Lee, Nicholas FitzGerald, Luke Zettlemoyer", "title": "Long Short-Term Memory as a Dynamically Computed Element-wise Weighted\n  Sum", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs were introduced to combat vanishing gradients in simple RNNs by\naugmenting them with gated additive recurrent connections. We present an\nalternative view to explain the success of LSTMs: the gates themselves are\nversatile recurrent models that provide more representational power than\npreviously appreciated. We do this by decoupling the LSTM's gates from the\nembedded simple RNN, producing a new class of RNNs where the recurrence\ncomputes an element-wise weighted sum of context-independent functions of the\ninput. Ablations on a range of problems demonstrate that the gating mechanism\nalone performs as well as an LSTM in most settings, strongly suggesting that\nthe gates are doing much more in practice than just alleviating vanishing\ngradients.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:05:58 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Levy", "Omer", ""], ["Lee", "Kenton", ""], ["FitzGerald", "Nicholas", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.03735", "submitter": "Benajmin Radford J", "authors": "Benjamin J. Radford and Bartley D. Richardson and Shawn E. Davis", "title": "Sequence Aggregation Rules for Anomaly Detection in Computer Network\n  Traffic", "comments": "Prepared for the American Statistical Associations Symposium on Data\n  Science and Statistics 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate methods for applying unsupervised anomaly detection to\ncybersecurity applications on computer network traffic data, or flow. We borrow\nfrom the natural language processing literature and conceptualize flow as a\nsort of \"language\" spoken between machines. Five sequence aggregation rules are\nevaluated for their efficacy in flagging multiple attack types in a labeled\nflow dataset, CICIDS2017. For sequence modeling, we rely on long short-term\nmemory (LSTM) recurrent neural networks (RNN). Additionally, a simple\nfrequency-based model is described and its performance with respect to attack\ndetection is compared to the LSTM models. We conclude that the frequency-based\nmodel tends to perform as well as or better than the LSTM models for the tasks\nat hand, with a few notable exceptions.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 21:14:17 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 14:37:54 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Radford", "Benjamin J.", ""], ["Richardson", "Bartley D.", ""], ["Davis", "Shawn E.", ""]]}, {"id": "1805.03737", "submitter": "Amanda Prorok", "authors": "Amanda Prorok", "title": "Graph Neural Networks for Learning Robot Team Coordination", "comments": "Presented at the Federated AI for Robotics Workshop,\n  IJCAI-ECAI/ICML/AAMAS 2018", "journal-ref": "Federated AI for Robotics Workshop, IJCAI-ECAI/ICML/AAMAS 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how Graph Neural Networks can be used for learning\ndistributed coordination mechanisms in connected teams of robots. We capture\nthe relational aspect of robot coordination by modeling the robot team as a\ngraph, where each robot is a node, and edges represent communication links.\nDuring training, robots learn how to pass messages and update internal states,\nso that a target behavior is reached. As a proxy for more complex problems,\nthis short paper considers the problem where each robot must locally estimate\nthe algebraic connectivity of the team's network topology.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 21:24:50 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 13:42:51 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Prorok", "Amanda", ""]]}, {"id": "1805.03779", "submitter": "Jong Chul Ye", "authors": "Yoseob Han, Leonard Sunwoo, and Jong Chul Ye", "title": "k-Space Deep Learning for Accelerated MRI", "comments": "Accepted to IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The annihilating filter-based low-rank Hankel matrix approach (ALOHA) is one\nof the state-of-the-art compressed sensing approaches that directly\ninterpolates the missing k-space data using low-rank Hankel matrix completion.\nThe success of ALOHA is due to the concise signal representation in the k-space\ndomain thanks to the duality between structured low-rankness in the k-space\ndomain and the image domain sparsity. Inspired by the recent mathematical\ndiscovery that links convolutional neural networks to Hankel matrix\ndecomposition using data-driven framelet basis, here we propose a fully\ndata-driven deep learning algorithm for k-space interpolation. Our network can\nbe also easily applied to non-Cartesian k-space trajectories by simply adding\nan additional regridding layer. Extensive numerical experiments show that the\nproposed deep learning method consistently outperforms the existing\nimage-domain deep learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 01:43:19 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 05:56:47 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 15:44:52 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Han", "Yoseob", ""], ["Sunwoo", "Leonard", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1805.03887", "submitter": "Luca Venturini", "authors": "Luca Venturini, Elena Baralis, Paolo Garza", "title": "Scaling associative classification for very large datasets", "comments": null, "journal-ref": "J Big Data (2017) 4: 44", "doi": "10.1186/s40537-017-0107-2", "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised learning algorithms are nowadays successfully scaling up to\ndatasets that are very large in volume, leveraging the potential of in-memory\ncluster-computing Big Data frameworks. Still, massive datasets with a number of\nlarge-domain categorical features are a difficult challenge for any classifier.\nMost off-the-shelf solutions cannot cope with this problem. In this work we\nintroduce DAC, a Distributed Associative Classifier. DAC exploits ensemble\nlearning to distribute the training of an associative classifier among parallel\nworkers and improve the final quality of the model. Furthermore, it adopts\nseveral novel techniques to reach high scalability without sacrificing quality,\namong which a preventive pruning of classification rules in the extraction\nphase based on Gini impurity. We ran experiments on Apache Spark, on a real\nlarge-scale dataset with more than 4 billion records and 800 million distinct\ncategories. The results showed that DAC improves on a state-of-the-art solution\nin both prediction quality and execution time. Since the generated model is\nhuman-readable, it can not only classify new records, but also allow\nunderstanding both the logic behind the prediction and the properties of the\nmodel, becoming a useful aid for decision makers.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:41:55 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Venturini", "Luca", ""], ["Baralis", "Elena", ""], ["Garza", "Paolo", ""]]}, {"id": "1805.03901", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, Stephen J. Roberts, Yarin Gal", "title": "Loss-Calibrated Approximate Inference in Bayesian Neural Networks", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches in approximate inference for Bayesian neural networks\nminimise the Kullback-Leibler divergence to approximate the true posterior over\nthe weights. However, this approximation is without knowledge of the final\napplication, and therefore cannot guarantee optimal predictions for a given\ntask. To make more suitable task-specific approximations, we introduce a new\nloss-calibrated evidence lower bound for Bayesian neural networks in the\ncontext of supervised learning, informed by Bayesian decision theory. By\nintroducing a lower bound that depends on a utility function, we ensure that\nour approximation achieves higher utility than traditional methods for\napplications that have asymmetric utility functions. Furthermore, in using\ndropout inference, we highlight that our new objective is identical to that of\nstandard dropout neural networks, with an additional utility-dependent penalty\nterm. We demonstrate our new loss-calibrated model with an illustrative medical\nexample and a restricted model capacity experiment, and highlight failure modes\nof the comparable weighted cross entropy approach. Lastly, we demonstrate the\nscalability of our method to real world applications with per-pixel semantic\nsegmentation on an autonomous driving data set.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:26:03 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cobb", "Adam D.", ""], ["Roberts", "Stephen J.", ""], ["Gal", "Yarin", ""]]}, {"id": "1805.03908", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, Santiago Pascual, Alexandros Karatzoglou", "title": "Towards a universal neural network encoder for time series", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of a time series encoder to learn representations that are\nuseful on data set types with which it has not been trained on. The encoder is\nformed of a convolutional neural network whose temporal output is summarized by\na convolutional attention mechanism. This way, we obtain a compact,\nfixed-length representation from longer, variable-length time series. We\nevaluate the performance of the proposed approach on a well-known time series\nclassification benchmark, considering full adaptation, partial adaptation, and\nno adaptation of the encoder to the new data type. Results show that such\nstrategies are competitive with the state-of-the-art, often outperforming\nconceptually-matching approaches. Besides accuracy scores, the facility of\nadaptation and the efficiency of pre-trained encoders make them an appealing\noption for the processing of scarcely- or non-labeled time series.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:46:45 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Pascual", "Santiago", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1805.03911", "submitter": "Imanol Perez Arribas", "authors": "Terry Lyons and Imanol Perez Arribas", "title": "Labelling as an unsupervised learning problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unravelling hidden patterns in datasets is a classical problem with many\npotential applications. In this paper, we present a challenge whose objective\nis to discover nonlinear relationships in noisy cloud of points. If a set of\npoint satisfies a nonlinear relationship that is unlikely to be due to\nrandomness, we will label the set with this relationship. Since points can\nsatisfy one, many or no such nonlinear relationships, cloud of points will\ntypically have one, multiple or no labels at all. This introduces the labelling\nproblem that will be studied in this paper.\n  The objective of this paper is to develop a framework for the labelling\nproblem. We introduce a precise notion of a label, and we propose an algorithm\nto discover such labels in a given dataset, which is then tested in synthetic\ndatasets. We also analyse, using tools from random matrix theory, the problem\nof discovering false labels in the dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 10:04:27 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 08:36:20 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Lyons", "Terry", ""], ["Arribas", "Imanol Perez", ""]]}, {"id": "1805.03963", "submitter": "Veit Elser", "authors": "Veit Elser, Dan Schmidt, Jonathan Yedidia", "title": "Monotone Learning with Rectified Wire Networks", "comments": "41 pages, 21 figures, new experimental results, various improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new neural network model, together with a tractable and\nmonotone online learning algorithm. Our model describes feed-forward networks\nfor classification, with one output node for each class. The only nonlinear\noperation is rectification using a ReLU function with a bias. However, there is\na rectifier on every edge rather than at the nodes of the network. There are\nalso weights, but these are positive, static, and associated with the nodes.\nOur \"rectified wire\" networks are able to represent arbitrary Boolean\nfunctions. Only the bias parameters, on the edges of the network, are learned.\nAnother departure in our approach, from standard neural networks, is that the\nloss function is replaced by a constraint. This constraint is simply that the\nvalue of the output node associated with the correct class should be zero. Our\nmodel has the property that the exact norm-minimizing parameter update,\nrequired to correctly classify a training item, is the solution to a quadratic\nprogram that can be computed with a few passes through the network. We\ndemonstrate a training algorithm using this update, called sequential\ndeactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a\nnatural choice for the nodal weights, SDA has no hyperparameters other than\nthose describing the network structure. Our experiments explore behavior with\nrespect to network size and depth in a family of sparse expander networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 13:24:34 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 20:49:16 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2018 17:09:49 GMT"}, {"version": "v4", "created": "Mon, 14 Jan 2019 01:08:30 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Elser", "Veit", ""], ["Schmidt", "Dan", ""], ["Yedidia", "Jonathan", ""]]}, {"id": "1805.03989", "submitter": "Junyang Lin", "authors": "Junyang Lin, Xu Sun, Shuming Ma and Qi Su", "title": "Global Encoding for Abstractive Summarization", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural abstractive summarization, the conventional sequence-to-sequence\n(seq2seq) model often suffers from repetition and semantic irrelevance. To\ntackle the problem, we propose a global encoding framework, which controls the\ninformation flow from the encoder to the decoder based on the global\ninformation of the source context. It consists of a convolutional gated unit to\nperform global encoding to improve the representations of the source-side\ninformation. Evaluations on the LCSTS and the English Gigaword both demonstrate\nthat our model outperforms the baseline models, and the analysis shows that our\nmodel is capable of reducing repetition.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 14:11:51 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:29:18 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Lin", "Junyang", ""], ["Sun", "Xu", ""], ["Ma", "Shuming", ""], ["Su", "Qi", ""]]}, {"id": "1805.04018", "submitter": "Mert Al", "authors": "Mert Al, Thee Chanyaswad, Sun-Yuan Kung", "title": "Supervising Nystr\\\"om Methods via Negative Margin Support Vector\n  Selection", "comments": "10 pages, 3 figures, 1 table for the main paper. 4 pages, 2 figures,\n  1 table for the appendix. Submitted to the Thirty-second Annual Conference on\n  Neural Information Processing Systems (NIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nystr\\\"om methods have been popular techniques for scalable kernel based\nlearning. They approximate explicit, low-dimensional feature mappings for\nkernel functions from the pairwise comparisons with the training data. However,\nNystr\\\"om methods are generally applied without the supervision provided by the\ntraining labels in the classification/regression problems. This leads to\npairwise comparisons with randomly chosen training samples in the model.\nConversely, this work studies a supervised Nystr\\\"om method that chooses the\ncritical subsets of samples for the success of the Machine Learning model.\nParticularly, we select the Nystr\\\"om support vectors via the negative margin\ncriterion, and create explicit feature maps that are more suitable for the\nclassification task on the data. Experimental results on six datasets show\nthat, without increasing the complexity over unsupervised techniques, our\nmethod can significantly improve the classification performance achieved via\nkernel approximation methods and reduce the number of features needed to reach\nor exceed the performance of the full-dimensional kernel machines.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:14:15 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 02:18:35 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Al", "Mert", ""], ["Chanyaswad", "Thee", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "1805.04025", "submitter": "Chenxi Liu", "authors": "Alan L. Yuille, Chenxi Liu", "title": "Deep Nets: What have they ever done for Vision?", "comments": "To appear in IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an opinion paper about the strengths and weaknesses of Deep Nets for\nvision. They are at the heart of the enormous recent progress in artificial\nintelligence and are of growing importance in cognitive science and\nneuroscience. They have had many successes but also have several limitations\nand there is limited understanding of their inner workings. At present Deep\nNets perform very well on specific visual tasks with benchmark datasets but\nthey are much less general purpose, flexible, and adaptive than the human\nvisual system. We argue that Deep Nets in their current form are unlikely to be\nable to overcome the fundamental problem of computer vision, namely how to deal\nwith the combinatorial explosion, caused by the enormous complexity of natural\nimages, and obtain the rich understanding of visual scenes that the human\nvisual achieves. We argue that this combinatorial explosion takes us into a\nregime where \"big data is not enough\" and where we need to rethink our methods\nfor benchmarking performance and evaluating vision algorithms. We stress that,\nas vision algorithms are increasingly used in real world applications, that\nperformance evaluation is not merely an academic exercise but has important\nconsequences in the real world. It is impractical to review the entire Deep Net\nliterature so we restrict ourselves to a limited range of topics and references\nwhich are intended as entry points into the literature. The views expressed in\nthis paper are our own and do not necessarily represent those of anybody else\nin the computer vision community.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:43:44 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 01:47:35 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 19:52:59 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 15:34:56 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yuille", "Alan L.", ""], ["Liu", "Chenxi", ""]]}, {"id": "1805.04132", "submitter": "Pan He", "authors": "Xiaoyu Yue, Zhanghui Kuang, Zhaoyang Zhang, Zhenfang Chen, Pan He, Yu\n  Qiao, Wei Zhang", "title": "Boosting up Scene Text Detectors with Guided CNN", "comments": "Submitted to British Machine Vision Conference (BMVC), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep CNNs have achieved great success in text detection. Most of existing\nmethods attempt to improve accuracy with sophisticated network design, while\npaying less attention on speed. In this paper, we propose a general framework\nfor text detection called Guided CNN to achieve the two goals simultaneously.\nThe proposed model consists of one guidance subnetwork, where a guidance mask\nis learned from the input image itself, and one primary text detector, where\nevery convolution and non-linear operation are conducted only in the guidance\nmask. On the one hand, the guidance subnetwork filters out non-text regions\ncoarsely, greatly reduces the computation complexity. On the other hand, the\nprimary text detector focuses on distinguishing between text and hard non-text\nregions and regressing text bounding boxes, achieves a better detection\naccuracy. A training strategy, called background-aware block-wise random\nsynthesis, is proposed to further boost up the performance. We demonstrate that\nthe proposed Guided CNN is not only effective but also efficient with two\nstate-of-the-art methods, CTPN and EAST, as backbones. On the challenging\nbenchmark ICDAR 2013, it speeds up CTPN by 2.9 times on average, while\nimproving the F-measure by 1.5%. On ICDAR 2015, it speeds up EAST by 2.0 times\nwhile improving the F-measure by 1.0%.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 18:51:19 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 03:38:25 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Yue", "Xiaoyu", ""], ["Kuang", "Zhanghui", ""], ["Zhang", "Zhaoyang", ""], ["Chen", "Zhenfang", ""], ["He", "Pan", ""], ["Qiao", "Yu", ""], ["Zhang", "Wei", ""]]}, {"id": "1805.04170", "submitter": "Minjie Wang", "authors": "Minjie Wang, Chien-chin Huang and Jinyang Li", "title": "Unifying Data, Model and Hybrid Parallelism in Deep Learning via Tensor\n  Tiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning systems have become vital tools across many fields, but the\nincreasing model sizes mean that training must be accelerated to maintain such\nsystems' utility. Current systems like Tensorflow and MXNet focus on one\nspecific parallelization strategy, data parallelism, which requires large\ntraining batch sizes in order to scale. We cast the problem of finding the best\nparallelization strategy as the problem of finding the best tiling to partition\ntensors with the least overall communication. We propose an algorithm that can\nfind the optimal tiling. Our resulting parallelization solution is a hybrid of\ndata parallelism and model parallelism. We build the SoyBean system that\nperforms automatic parallelization. SoyBean automatically transforms a serial\ndataflow graph captured by an existing deep learning system frontend into a\nparallel dataflow graph based on the optimal tiling it has found. Our\nevaluations show that SoyBean is 1.5x-4x faster than pure data parallelism for\nAlexNet and VGG. We present this automatic tiling in a new system, SoyBean,\nthat can act as a backend for Tensorflow, MXNet, and others.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:38:56 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Wang", "Minjie", ""], ["Huang", "Chien-chin", ""], ["Li", "Jinyang", ""]]}, {"id": "1805.04174", "submitter": "Guoyin Wang", "authors": "Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen,\n  Xinyuan Zhang, Ricardo Henao, Lawrence Carin", "title": "Joint Embedding of Words and Labels for Text Classification", "comments": "Published in ACL 2018; Code: https://github.com/guoyinwang/LEAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are effective intermediate representations for capturing\nsemantic regularities between words, when learning the representations of text\nsequences. We propose to view text classification as a label-word joint\nembedding problem: each label is embedded in the same space with the word\nvectors. We introduce an attention framework that measures the compatibility of\nembeddings between text sequences and labels. The attention is learned on a\ntraining set of labeled samples to ensure that, given a text sequence, the\nrelevant words are weighted higher than the irrelevant ones. Our method\nmaintains the interpretability of word embeddings, and enjoys a built-in\nability to leverage alternative sources of information, in addition to input\ntext sequences. Extensive results on the several large text datasets show that\nthe proposed framework outperforms the state-of-the-art methods by a large\nmargin, in terms of both accuracy and speed.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:42:52 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Wang", "Guoyin", ""], ["Li", "Chunyuan", ""], ["Wang", "Wenlin", ""], ["Zhang", "Yizhe", ""], ["Shen", "Dinghan", ""], ["Zhang", "Xinyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1805.04193", "submitter": "Cong Feng", "authors": "Cong Feng, Mingjian Cui, Bri-Mathias Hodge, Siyuan Lu, Hendrik F.\n  Hamann, and Jie Zhang", "title": "An Unsupervised Clustering-Based Short-Term Solar Forecasting\n  Methodology Using Multi-Model Machine Learning Blending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar forecasting accuracy is affected by weather conditions, and weather\nawareness forecasting models are expected to improve the performance. However,\nit may not be available and reliable to classify different forecasting tasks by\nusing only meteorological weather categorization. In this paper, an\nunsupervised clustering-based (UC-based) solar forecasting methodology is\ndeveloped for short-term (1-hour-ahead) global horizontal irradiance (GHI)\nforecasting. This methodology consists of three parts: GHI time series\nunsupervised clustering, pattern recognition, and UC-based forecasting. The\ndaily GHI time series is first clustered by an Optimized Cross-validated\nClUsteRing (OCCUR) method, which determines the optimal number of clusters and\nbest clustering results. Then, support vector machine pattern recognition\n(SVM-PR) is adopted to recognize the category of a certain day using the first\nfew hours' data in the forecasting stage. GHI forecasts are generated by the\nmost suitable models in different clusters, which are built by a two-layer\nMachine learning based Multi-Model (M3) forecasting framework. The developed\nUC-based methodology is validated by using 1-year of data with six solar\nfeatures. Numerical results show that (i) UC-based models outperform non-UC\n(all-in-one) models with the same M3 architecture by approximately 20%; (ii)\nM3-based models also outperform the single-algorithm machine learning (SAML)\nmodels by approximately 20%.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 22:17:51 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Feng", "Cong", ""], ["Cui", "Mingjian", ""], ["Hodge", "Bri-Mathias", ""], ["Lu", "Siyuan", ""], ["Hamann", "Hendrik F.", ""], ["Zhang", "Jie", ""]]}, {"id": "1805.04220", "submitter": "Matthew Gombolay", "authors": "Matthew Gombolay, Reed Jensen, Jessica Stigile, Toni Golen, Neel Shah,\n  Sung-Hyun Son, and Julie Shah", "title": "Human-Machine Collaborative Optimization via Apprenticeship Scheduling", "comments": "Portions of this paper were published in the Proceedings of the\n  International Joint Conference on Artificial Intelligence (IJCAI) in 2016 and\n  in the Proceedings of Robotics: Science and Systems (RSS) in 2016. The paper\n  consists of 50 pages with 11 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinating agents to complete a set of tasks with intercoupled temporal and\nresource constraints is computationally challenging, yet human domain experts\ncan solve these difficult scheduling problems using paradigms learned through\nyears of apprenticeship. A process for manually codifying this domain knowledge\nwithin a computational framework is necessary to scale beyond the\n``single-expert, single-trainee\" apprenticeship model. However, human domain\nexperts often have difficulty describing their decision-making processes,\ncausing the codification of this knowledge to become laborious. We propose a\nnew approach for capturing domain-expert heuristics through a pairwise ranking\nformulation. Our approach is model-free and does not require enumerating or\niterating through a large state space. We empirically demonstrate that this\napproach accurately learns multifaceted heuristics on a synthetic data set\nincorporating job-shop scheduling and vehicle routing problems, as well as on\ntwo real-world data sets consisting of demonstrations of experts solving a\nweapon-to-target assignment problem and a hospital resource allocation problem.\nWe also demonstrate that policies learned from human scheduling demonstration\nvia apprenticeship learning can substantially improve the efficiency of a\nbranch-and-bound search for an optimal schedule. We employ this human-machine\ncollaborative optimization technique on a variant of the weapon-to-target\nassignment problem. We demonstrate that this technique generates solutions\nsubstantially superior to those produced by human domain experts at a rate up\nto 9.5 times faster than an optimization approach and can be applied to\noptimally solve problems twice as complex as those solved by a human\ndemonstrator.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 01:53:05 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Gombolay", "Matthew", ""], ["Jensen", "Reed", ""], ["Stigile", "Jessica", ""], ["Golen", "Toni", ""], ["Shah", "Neel", ""], ["Son", "Sung-Hyun", ""], ["Shah", "Julie", ""]]}, {"id": "1805.04234", "submitter": "Ya-Lin Zhang", "authors": "Ya-Lin Zhang, Jun Zhou, Wenhao Zheng, Ji Feng, Longfei Li, Ziqi Liu,\n  Ming Li, Zhiqiang Zhang, Chaochao Chen, Xiaolong Li, Zhi-Hua Zhou, YUAN\n  (ALAN) QI", "title": "Distributed Deep Forest and its Application to Automatic Detection of\n  Cash-out Fraud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet companies are facing the need for handling large-scale machine\nlearning applications on a daily basis and distributed implementation of\nmachine learning algorithms which can handle extra-large scale tasks with great\nperformance is widely needed. Deep forest is a recently proposed deep learning\nframework which uses tree ensembles as its building blocks and it has achieved\nhighly competitive results on various domains of tasks. However, it has not\nbeen tested on extremely large scale tasks. In this work, based on our\nparameter server system, we developed the distributed version of deep forest.\nTo meet the need for real-world tasks, many improvements are introduced to the\noriginal deep forest model, including MART (Multiple Additive Regression Tree)\nas base learners for efficiency and effectiveness consideration, the cost-based\nmethod for handling prevalent class-imbalanced data, MART based feature\nselection for high dimension data and different evaluation metrics for\nautomatically determining of the cascade level. We tested the deep forest model\non an extra-large scale task, i.e., automatic detection of cash-out fraud, with\nmore than 100 millions of training samples. Experimental results showed that\nthe deep forest model has the best performance according to the evaluation\nmetrics from different perspectives even with very little effort for parameter\ntuning. This model can block fraud transactions in a large amount of money each\nday. Even compared with the best-deployed model, the deep forest model can\nadditionally bring into a significant decrease in economic loss each day.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 03:17:21 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 11:18:38 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 09:04:46 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Zhang", "Ya-Lin", "", "ALAN"], ["Zhou", "Jun", "", "ALAN"], ["Zheng", "Wenhao", "", "ALAN"], ["Feng", "Ji", "", "ALAN"], ["Li", "Longfei", "", "ALAN"], ["Liu", "Ziqi", "", "ALAN"], ["Li", "Ming", "", "ALAN"], ["Zhang", "Zhiqiang", "", "ALAN"], ["Chen", "Chaochao", "", "ALAN"], ["Li", "Xiaolong", "", "ALAN"], ["Zhou", "Zhi-Hua", "", "ALAN"], ["YUAN", "", "", "ALAN"], ["QI", "", ""]]}, {"id": "1805.04246", "submitter": "Tomohiko Mizutani", "authors": "Tomohiko Mizutani", "title": "Convex Programming Based Spectral Clustering", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental task in data analysis, and spectral clustering\nhas been recognized as a promising approach to it. Given a graph describing the\nrelationship between data, spectral clustering explores the underlying cluster\nstructure in two stages. The first stage embeds the nodes of the graph in real\nspace, and the second stage groups the embedded nodes into several clusters.\nThe use of the $k$-means method in the grouping stage is currently standard\npractice. We present a spectral clustering algorithm that uses convex\nprogramming in the grouping stage and study how well it works. This algorithm\nis designed based on the following observation. If a graph is well-clustered,\nthen the nodes with the largest degree in each cluster can be found by\ncomputing an enclosing ellipsoid of the nodes embedded in real space, and the\nclusters can be identified by using those nodes. We show that, for\nwell-clustered graphs, the algorithm can find clusters of nodes with minimal\nconductance. We also give an experimental assessment of the algorithm's\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 06:11:03 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 15:58:21 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 06:21:33 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mizutani", "Tomohiko", ""]]}, {"id": "1805.04252", "submitter": "Zheng Wang", "authors": "Ben Taylor, Vicent Sanz Marco, Willy Wolff, Yehia Elkhatib, Zheng Wang", "title": "Adaptive Selection of Deep Learning Models on Embedded Systems", "comments": "Accepted to be published at LCTES 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent ground-breaking advances in deep learning networks ( DNNs ) make\nthem attractive for embedded systems. However, it can take a long time for DNNs\nto make an inference on resource-limited embedded devices. Offloading the\ncomputation into the cloud is often infeasible due to privacy concerns, high\nlatency, or the lack of connectivity. As such, there is a critical need to find\na way to effectively execute the DNN models locally on the devices. This paper\npresents an adaptive scheme to determine which DNN model to use for a given\ninput, by considering the desired accuracy and inference time. Our approach\nemploys machine learning to develop a predictive model to quickly select a\npre-trained DNN to use for a given input and the optimization constraint. We\nachieve this by first training off-line a predictive model, and then use the\nlearnt model to select a DNN model to use for new, unseen inputs. We apply our\napproach to the image classification task and evaluate it on a Jetson TX2\nembedded deep learning platform using the ImageNet ILSVRC 2012 validation\ndataset. We consider a range of influential DNN models. Experimental results\nshow that our approach achieves a 7.52% improvement in inference accuracy, and\na 1.8x reduction in inference time over the most-capable single DNN model.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 06:53:59 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Taylor", "Ben", ""], ["Marco", "Vicent Sanz", ""], ["Wolff", "Willy", ""], ["Elkhatib", "Yehia", ""], ["Wang", "Zheng", ""]]}, {"id": "1805.04272", "submitter": "Hanqing Zhao", "authors": "Hanqing Zhao, Yuehan Luo", "title": "An $O(N)$ Sorting Algorithm: Machine Learning Sort", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an $O(N\\cdot M)$ sorting algorithm by Machine Learning method,\nwhich shows a huge potential sorting big data. This sorting algorithm can be\napplied to parallel sorting and is suitable for GPU or TPU acceleration.\nFurthermore, we discuss the application of this algorithm to sparse hash table.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 08:28:55 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 16:24:39 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Zhao", "Hanqing", ""], ["Luo", "Yuehan", ""]]}, {"id": "1805.04276", "submitter": "Rudy Bunel", "authors": "Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, Pushmeet\n  Kohli", "title": "Leveraging Grammar and Reinforcement Learning for Neural Program\n  Synthesis", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis is the task of automatically generating a program\nconsistent with a specification. Recent years have seen proposal of a number of\nneural approaches for program synthesis, many of which adopt a sequence\ngeneration paradigm similar to neural machine translation, in which\nsequence-to-sequence models are trained to maximize the likelihood of known\nreference programs. While achieving impressive results, this strategy has two\nkey limitations. First, it ignores Program Aliasing: the fact that many\ndifferent programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many\nsemantically correct programs, which can adversely affect the synthesizer\nperformance. Second, this strategy overlooks the fact that programs have a\nstrict syntax that can be efficiently checked. To address the first limitation,\nwe perform reinforcement learning on top of a supervised model with an\nobjective that explicitly maximizes the likelihood of generating semantically\ncorrect programs. For addressing the second limitation, we introduce a training\nprocedure that directly maximizes the probability of generating syntactically\ncorrect programs that fulfill the specification. We show that our contributions\nlead to improved accuracy of the models, especially in cases where the training\ndata is limited.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 08:45:24 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 10:23:39 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Bunel", "Rudy", ""], ["Hausknecht", "Matthew", ""], ["Devlin", "Jacob", ""], ["Singh", "Rishabh", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1805.04333", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Chung-Hao Huang, Hirotoshi Yasuoka", "title": "Quantitative Projection Coverage for Testing ML-enabled Autonomous\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematically testing models learned from neural networks remains a crucial\nunsolved barrier to successfully justify safety for autonomous vehicles\nengineered using data-driven approach. We propose quantitative k-projection\ncoverage as a metric to mediate combinatorial explosion while guiding the data\nsampling process. By assuming that domain experts propose largely independent\nenvironment conditions and by associating elements in each condition with\nweights, the product of these conditions forms scenarios, and one may interpret\nweights associated with each equivalence class as relative importance.\nAchieving full k-projection coverage requires that the data set, when being\nprojected to the hyperplane formed by arbitrarily selected k-conditions, covers\neach class with number of data points no less than the associated weight. For\nthe general case where scenario composition is constrained by rules, precisely\ncomputing k-projection coverage remains in NP. In terms of finding minimum test\ncases to achieve full coverage, we present theoretical complexity for important\nsub-cases and an encoding to 0-1 integer programming. We have implemented a\nresearch prototype that generates test cases for a visual object defection unit\nin automated driving, demonstrating the technological feasibility of our\nproposed coverage criterion.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 11:31:47 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Huang", "Chung-Hao", ""], ["Yasuoka", "Hirotoshi", ""]]}, {"id": "1805.04396", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere", "title": "A Sensorimotor Perspective on Grounding the Semantic of Simple Visual\n  Features", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning and Robotics, the semantic content of visual features is\nusually provided to the system by a human who interprets its content. On the\ncontrary, strictly unsupervised approaches have difficulties relating the\nstatistics of sensory inputs to their semantic content without also relying on\nprior knowledge introduced in the system. We proposed in this paper to tackle\nthis problem from a sensorimotor perspective. In line with the Sensorimotor\nContingencies Theory, we make the fundamental assumption that the semantic\ncontent of sensory inputs at least partially stems from the way an agent can\nactively transform it. We illustrate our approach by formalizing how simple\nvisual features can induce invariants in a naive agent's sensorimotor\nexperience, and evaluate it on a simple simulated visual system. Without any a\npriori knowledge about the way its sensorimotor information is encoded, we show\nhow an agent can characterize the uniformity and edge-ness of the visual\nfeatures it interacts with.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 13:41:54 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1805.04424", "submitter": "Dinesh Kumar Amara", "authors": "Amara Dinesh Kumar", "title": "Novel Deep Learning Model for Traffic Sign Detection Using Capsule\n  Networks", "comments": "5 pages,3 figures", "journal-ref": "International Journal of Pure and Applied Mathematics Volume 118\n  No. 20 2018, 4543-4548 ISSN: 1314-3395", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks are the most widely used deep learning\nalgorithms for traffic signal classification till date but they fail to capture\npose, view, orientation of the images because of the intrinsic inability of max\npooling layer.This paper proposes a novel method for Traffic sign detection\nusing deep learning architecture called capsule networks that achieves\noutstanding performance on the German traffic sign dataset.Capsule network\nconsists of capsules which are a group of neurons representing the\ninstantiating parameters of an object like the pose and orientation by using\nthe dynamic routing and route by agreement algorithms.unlike the previous\napproaches of manual feature extraction,multiple deep neural networks with many\nparameters,our method eliminates the manual effort and provides resistance to\nthe spatial variances.CNNs can be fooled easily using various adversary attacks\nand capsule networks can overcome such attacks from the intruders and can offer\nmore reliability in traffic sign detection for autonomous vehicles.Capsule\nnetwork have achieved the state-of-the-art accuracy of 97.6% on German Traffic\nSign Recognition Benchmark dataset (GTSRB).\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 14:34:15 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Kumar", "Amara Dinesh", ""]]}, {"id": "1805.04513", "submitter": "Sayeh Sharify", "authors": "Sayeh Sharify, Mostafa Mahmoud, Alberto Delmas Lascorz, Milos Nikolic,\n  Andreas Moshovos", "title": "Laconic Deep Learning Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate a method for transparently identifying ineffectual computations\nin unmodified Deep Learning models and without affecting accuracy.\nSpecifically, we show that if we decompose multiplications down to the bit\nlevel the amount of work performed during inference for image classification\nmodels can be consistently reduced by two orders of magnitude. In the best case\nstudied of a sparse variant of AlexNet, this approach can ideally reduce\ncomputation work by more than 500x. We present Laconic a hardware accelerator\nthat implements this approach to improve execution time, and energy efficiency\nfor inference with Deep Learning Networks. Laconic judiciously gives up some of\nthe work reduction potential to yield a low-cost, simple, and energy efficient\ndesign that outperforms other state-of-the-art accelerators. For example, a\nLaconic configuration that uses a weight memory interface with just 128 wires\noutperforms a conventional accelerator with a 2K-wire weight memory interface\nby 2.3x on average while being 2.13x more energy efficient on average. A\nLaconic configuration that uses a 1K-wire weight memory interface, outperforms\nthe 2K-wire conventional accelerator by 15.4x and is 1.95x more energy\nefficient. Laconic does not require but rewards advances in model design such\nas a reduction in precision, the use of alternate numeric representations that\nreduce the number of bits that are \"1\", or an increase in weight or activation\nsparsity.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 18:14:08 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Sharify", "Sayeh", ""], ["Mahmoud", "Mostafa", ""], ["Lascorz", "Alberto Delmas", ""], ["Nikolic", "Milos", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1805.04514", "submitter": "Kenneth Young", "authors": "Kenny Young, Baoxiang Wang, Matthew E. Taylor", "title": "Metatrace Actor-Critic: Online Step-size Tuning by Meta-gradient Descent\n  for Reinforcement Learning Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has had many successes in both \"deep\" and\n\"shallow\" settings. In both cases, significant hyperparameter tuning is often\nrequired to achieve good performance. Furthermore, when nonlinear function\napproximation is used, non-stationarity in the state representation can lead to\nlearning instability. A variety of techniques exist to combat this --- most\nnotably large experience replay buffers or the use of multiple parallel actors.\nThese techniques come at the cost of moving away from the online RL problem as\nit is traditionally formulated (i.e., a single agent learning online without\nmaintaining a large database of training examples). Meta-learning can\npotentially help with both these issues by tuning hyperparameters online and\nallowing the algorithm to more robustly adjust to non-stationarity in a\nproblem. This paper applies meta-gradient descent to derive a set of step-size\ntuning algorithms specifically for online RL control with eligibility traces.\nOur novel technique, Metatrace, makes use of an eligibility trace analogous to\nmethods like $TD(\\lambda)$. We explore tuning both a single scalar step-size\nand a separate step-size for each learned parameter. We evaluate Metatrace\nfirst for control with linear function approximation in the classic mountain\ncar problem and then in a noisy, non-stationary version. Finally, we apply\nMetatrace for control with nonlinear function approximation in 5 games in the\nArcade Learning Environment where we explore how it impacts learning speed and\nrobustness to initial step-size choice. Results show that the meta-step-size\nparameter of Metatrace is easy to set, Metatrace can speed learning, and\nMetatrace can allow an RL algorithm to deal with non-stationarity in the\nlearning task.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:00:50 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 17:40:08 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Young", "Kenny", ""], ["Wang", "Baoxiang", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1805.04567", "submitter": "Stevan Harnad", "authors": "Christian Th\\'eriault, Fernanda P\\'erez-Gay, Dan Rivas, Stevan Harnad", "title": "Learning-induced categorical perception in a neural network model", "comments": "20 pages, 16 figures, 26 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human cognition, the expansion of perceived between-category distances and\ncompression of within-category distances is known as categorical perception\n(CP). There are several hypotheses about the causes of CP (e.g., language,\nlearning, evolution) but no functional model. Whether CP is essential to\ncategorisation or simply a by-product of it is not yet clear, but evidence is\naccumulating that CP can be induced by category learning. We provide a model\nfor learning-induced CP as expansion and compression of distances in\nhidden-unit space in neural nets. Basic conditions from which the current model\npredicts CP are described, and clues as to how these conditions might\ngeneralize to more complex kinds of categorization begin to emerge.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 19:18:27 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Th\u00e9riault", "Christian", ""], ["P\u00e9rez-Gay", "Fernanda", ""], ["Rivas", "Dan", ""], ["Harnad", "Stevan", ""]]}, {"id": "1805.04577", "submitter": "Tianbao Yang", "authors": "Mingrui Liu, Xiaoxuan Zhang, Lijun Zhang, Rong Jin, Tianbao Yang", "title": "Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound\n  Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error bound conditions (EBC) are properties that characterize the growth of\nan objective function when a point is moved away from the optimal set. They\nhave recently received increasing attention in the field of optimization for\ndeveloping optimization algorithms with fast convergence. However, the studies\nof EBC in statistical learning are hitherto still limited. The main\ncontributions of this paper are two-fold. First, we develop fast and\nintermediate rates of empirical risk minimization (ERM) under EBC for risk\nminimization with Lipschitz continuous, and smooth convex random functions.\nSecond, we establish fast and intermediate rates of an efficient stochastic\napproximation (SA) algorithm for risk minimization with Lipschitz continuous\nrandom functions, which requires only one pass of $n$ samples and adapts to\nEBC. For both approaches, the convergence rates span a full spectrum between\n$\\widetilde O(1/\\sqrt{n})$ and $\\widetilde O(1/n)$ depending on the power\nconstant in EBC, and could be even faster than $O(1/n)$ in special cases for\nERM. Moreover, these convergence rates are automatically adaptive without using\nany knowledge of EBC. Overall, this work not only strengthens the understanding\nof ERM for statistical learning but also brings new fast stochastic algorithms\nfor solving a broad range of statistical learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 20:03:54 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Liu", "Mingrui", ""], ["Zhang", "Xiaoxuan", ""], ["Zhang", "Lijun", ""], ["Jin", "Rong", ""], ["Yang", "Tianbao", ""]]}, {"id": "1805.04582", "submitter": "Tammo Rukat", "authors": "Tammo Rukat, Chris C. Holmes, Christopher Yau", "title": "TensOrMachine: Probabilistic Boolean Tensor Decomposition", "comments": "To be published at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean tensor decomposition approximates data of multi-way binary\nrelationships as product of interpretable low-rank binary factors, following\nthe rules of Boolean algebra. Here, we present its first probabilistic\ntreatment. We facilitate scalable sampling-based posterior inference by\nexploitation of the combinatorial structure of the factor conditionals. Maximum\na posteriori decompositions feature higher accuracies than existing techniques\nthroughout a wide range of simulated conditions. Moreover, the probabilistic\napproach facilitates the treatment of missing data and enables model selection\nwith much greater accuracy. We investigate three real-world data-sets. First,\ntemporal interaction networks in a hospital ward and behavioural data of\nuniversity students demonstrate the inference of instructive latent patterns.\nNext, we decompose a tensor with more than 10 billion data points, indicating\nrelations of gene expression in cancer patients. Not only does this demonstrate\nscalability, it also provides an entirely novel perspective on relational\nproperties of continuous data and, in the present example, on the molecular\nheterogeneity of cancer. Our implementation is available on GitHub:\nhttps://github.com/TammoR/LogicalFactorisationMachines.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 20:23:35 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Rukat", "Tammo", ""], ["Holmes", "Chris C.", ""], ["Yau", "Christopher", ""]]}, {"id": "1805.04591", "submitter": "Travis Gibson", "authors": "Travis E. Gibson and Georg K. Gerber", "title": "Robust and Scalable Models of Microbiome Dynamics", "comments": "ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1763-1772, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microbes are everywhere, including in and on our bodies, and have been shown\nto play key roles in a variety of prevalent human diseases. Consequently, there\nhas been intense interest in the design of bacteriotherapies or \"bugs as\ndrugs,\" which are communities of bacteria administered to patients for specific\ntherapeutic applications. Central to the design of such therapeutics is an\nunderstanding of the causal microbial interaction network and the population\ndynamics of the organisms. In this work we present a Bayesian nonparametric\nmodel and associated efficient inference algorithm that addresses the key\nconceptual and practical challenges of learning microbial dynamics from time\nseries microbe abundance data. These challenges include high-dimensional (300+\nstrains of bacteria in the gut) but temporally sparse and non-uniformly sampled\ndata; high measurement noise; and, nonlinear and physically non-negative\ndynamics. Our contributions include a new type of dynamical systems model for\nmicrobial dynamics based on what we term interaction modules, or learned\nclusters of latent variables with redundant interaction structure (reducing the\nexpected number of interaction coefficients from $O(n^2)$ to $O((\\log n)^2)$);\na fully Bayesian formulation of the stochastic dynamical systems model that\npropagates measurement and latent state uncertainty throughout the model; and\nintroduction of a temporally varying auxiliary variable technique to enable\nefficient inference by relaxing the hard non-negativity constraint on states.\nWe apply our method to simulated and real data, and demonstrate the utility of\nour technique for system identification from limited data and gaining new\nbiological insights into bacteriotherapy design.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 21:13:11 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 00:31:20 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Gibson", "Travis E.", ""], ["Gerber", "Georg K.", ""]]}, {"id": "1805.04609", "submitter": "Jonathan Zarecki", "authors": "Jonathan Zarecki, Shaul Markovitch", "title": "Textual Membership Queries", "comments": "Accepted to IJCAI 2020. Code is available at\n  github.com/jonzarecki/textual-mqs . Additional material is available at\n  tinyurl.com/sup-textualmqs . SOLE copyright holder is IJCAI (International\n  Joint Conferences on Artificial Intelligence), all rights reserved", "journal-ref": null, "doi": "10.24963/ijcai.2020/369", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human labeling of data can be very time-consuming and expensive, yet, in many\ncases it is critical for the success of the learning process. In order to\nminimize human labeling efforts, we propose a novel active learning solution\nthat does not rely on existing sources of unlabeled data. It uses a small\namount of labeled data as the core set for the synthesis of useful membership\nqueries (MQs) - unlabeled instances generated by an algorithm for human\nlabeling. Our solution uses modification operators, functions that modify\ninstances to some extent. We apply the operators on a small set of instances\n(core set), creating a set of new membership queries. Using this framework, we\nlook at the instance space as a search space and apply search algorithms in\norder to generate new examples highly relevant to the learner. We implement\nthis framework in the textual domain and test it on several text classification\ntasks and show improved classifier performance as more MQs are labeled and\nincorporated into the training set. To the best of our knowledge, this is the\nfirst work on membership queries in the textual domain.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 22:40:59 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:58:06 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 14:03:52 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Zarecki", "Jonathan", ""], ["Markovitch", "Shaul", ""]]}, {"id": "1805.04612", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Bruno Cornelis,\n  Nikos Deligiannis", "title": "Twitter User Geolocation using Deep Multiview Learning", "comments": "Presented at IEEE International Conference on Acoustics, Speech and\n  Signal Processing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the geographical location of users on social networks like Twitter\nis an active research topic with plenty of methods proposed so far. Most of the\nexisting work follows either a content-based or a network-based approach. The\nformer is based on user-generated content while the latter exploits the\nstructure of the network of users. In this paper, we propose a more generic\napproach, which incorporates not only both content-based and network-based\nfeatures, but also other available information into a unified model. Our\napproach, named Multi-Entry Neural Network (MENET), leverages the latest\nadvances in deep learning and multiview learning. A realization of MENET with\ntextual, network and metadata features results in an effective method for\nTwitter user geolocation, achieving the state of the art on two well-known\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 22:47:53 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Do", "Tien Huu", ""], ["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Cornelis", "Bruno", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1805.04613", "submitter": "Yan Zhou", "authors": "Yan Zhou, Murat Kantarcioglu, Bowei Xi", "title": "Breaking Transferability of Adversarial Samples with Randomness", "comments": "19 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the role of transferability of adversarial attacks in the\nobserved vulnerabilities of Deep Neural Networks (DNNs). We demonstrate that\nintroducing randomness to the DNN models is sufficient to defeat adversarial\nattacks, given that the adversary does not have an unlimited attack budget.\nInstead of making one specific DNN model robust to perfect knowledge attacks\n(a.k.a, white box attacks), creating randomness within an army of DNNs\ncompletely eliminates the possibility of perfect knowledge acquisition,\nresulting in a significantly more robust DNN ensemble against the strongest\nform of attacks. We also show that when the adversary has an unlimited budget\nof data perturbation, all defensive techniques would eventually break down as\nthe budget increases. Therefore, it is important to understand the game saddle\npoint where the adversary would not further pursue this endeavor.\n  Furthermore, we explore the relationship between attack severity and decision\nboundary robustness in the version space. We empirically demonstrate that by\nsimply adding a small Gaussian random noise to the learned weights, a DNN model\ncan increase its resilience to adversarial attacks by as much as 74.2%. More\nimportantly, we show that by randomly activating/revealing a model from a pool\nof pre-trained DNNs at each query request, we can put a tremendous strain on\nthe adversary's attack strategies. We compare our randomization techniques to\nthe Ensemble Adversarial Training technique and show that our randomization\ntechniques are superior under different attack budget constraints.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 22:50:33 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 23:56:58 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Zhou", "Yan", ""], ["Kantarcioglu", "Murat", ""], ["Xi", "Bowei", ""]]}, {"id": "1805.04680", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang and Tushar Khot and Ashish Sabharwal and Eduard Hovy", "title": "AdvEntuRe: Adversarial Training for Textual Entailment with\n  Knowledge-Guided Examples", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning textual entailment models with limited\nsupervision (5K-10K training examples), and present two complementary\napproaches for it. First, we propose knowledge-guided adversarial example\ngenerators for incorporating large lexical resources in entailment models via\nonly a handful of rule templates. Second, to make the entailment model - a\ndiscriminator - more robust, we propose the first GAN-style approach for\ntraining it using a natural language example generator that iteratively adjusts\nbased on the discriminator's performance. We demonstrate effectiveness using\ntwo entailment datasets, where the proposed methods increase accuracy by 4.7%\non SciTail and by 2.8% on a 1% training sub-sample of SNLI. Notably, even a\nsingle hand-written rule, negate, improves the accuracy on the negation\nexamples in SNLI by 6.1%.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 07:52:59 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kang", "Dongyeop", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Hovy", "Eduard", ""]]}, {"id": "1805.04686", "submitter": "Xiaojian Ma", "authors": "Mingxuan Jing, Xiaojian Ma, Wenbing Huang, Fuchun Sun, Huaping Liu", "title": "Task Transfer by Preference-Based Cost Learning", "comments": "Accepted to AAAI 2019. Mingxuan Jing and Xiaojian Ma contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of task transfer in reinforcement learning is migrating the action\npolicy of an agent to the target task from the source task. Given their\nsuccesses on robotic action planning, current methods mostly rely on two\nrequirements: exactly-relevant expert demonstrations or the explicitly-coded\ncost function on target task, both of which, however, are inconvenient to\nobtain in practice. In this paper, we relax these two strong conditions by\ndeveloping a novel task transfer framework where the expert preference is\napplied as a guidance. In particular, we alternate the following two steps:\nFirstly, letting experts apply pre-defined preference rules to select related\nexpert demonstrates for the target task. Secondly, based on the selection\nresult, we learn the target cost function and trajectory distribution\nsimultaneously via enhanced Adversarial MaxEnt IRL and generate more\ntrajectories by the learned target distribution for the next preference\nselection. The theoretical analysis on the distribution learning and\nconvergence of the proposed algorithm are provided. Extensive simulations on\nseveral benchmarks have been conducted for further verifying the effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 09:08:14 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 15:02:41 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 14:59:00 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Jing", "Mingxuan", ""], ["Ma", "Xiaojian", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Liu", "Huaping", ""]]}, {"id": "1805.04688", "submitter": "Yanpeng Zhao", "authors": "Yanpeng Zhao, Liwen Zhang, Kewei Tu", "title": "Gaussian Mixture Latent Vector Grammars", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce Latent Vector Grammars (LVeGs), a new framework that extends\nlatent variable grammars such that each nonterminal symbol is associated with a\ncontinuous vector space representing the set of (infinitely many) subtypes of\nthe nonterminal. We show that previous models such as latent variable grammars\nand compositional vector grammars can be interpreted as special cases of LVeGs.\nWe then present Gaussian Mixture LVeGs (GM-LVeGs), a new special case of LVeGs\nthat uses Gaussian mixtures to formulate the weights of production rules over\nsubtypes of nonterminals. A major advantage of using Gaussian mixtures is that\nthe partition function and the expectations of subtype rules can be computed\nusing an extension of the inside-outside algorithm, which enables efficient\ninference and learning. We apply GM-LVeGs to part-of-speech tagging and\nconstituency parsing and show that GM-LVeGs can achieve competitive accuracies.\nOur code is available at https://github.com/zhaoyanpeng/lveg.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 09:27:53 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhao", "Yanpeng", ""], ["Zhang", "Liwen", ""], ["Tu", "Kewei", ""]]}, {"id": "1805.04720", "submitter": "Mingda Qiao", "authors": "Mingda Qiao", "title": "Do Outliers Ruin Collaboration?", "comments": "Accepted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a binary classifier from $n$ different\ndata sources, among which at most an $\\eta$ fraction are adversarial. The\noverhead is defined as the ratio between the sample complexity of learning in\nthis setting and that of learning the same hypothesis class on a single data\ndistribution. We present an algorithm that achieves an $O(\\eta n + \\ln n)$\noverhead, which is proved to be worst-case optimal. We also discuss the\npotential challenges to the design of a computationally efficient learning\nalgorithm with a small overhead.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 13:35:35 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Qiao", "Mingda", ""]]}, {"id": "1805.04735", "submitter": "Dongrui Wu", "authors": "Dongrui Wu", "title": "Pool-Based Sequential Active Learning for Regression", "comments": null, "journal-ref": "in IEEE Transactions on Neural Networks and Learning Systems, vol.\n  30, no. 5, pp. 1348-1359, May 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a machine learning approach for reducing the data labeling\neffort. Given a pool of unlabeled samples, it tries to select the most useful\nones to label so that a model built from them can achieve the best possible\nperformance. This paper focuses on pool-based sequential active learning for\nregression (ALR). We first propose three essential criteria that an ALR\napproach should consider in selecting the most useful unlabeled samples:\ninformativeness, representativeness, and diversity, and compare four existing\nALR approaches against them. We then propose a new ALR approach using passive\nsampling, which considers both the representativeness and the diversity in both\nthe initialization and subsequent iterations. Remarkably, this approach can\nalso be integrated with other existing ALR approaches in the literature to\nfurther improve the performance. Extensive experiments on 11 UCI, CMU StatLib,\nand UFL Media Core datasets from various domains verified the effectiveness of\nour proposed ALR approaches.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 15:17:12 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wu", "Dongrui", ""]]}, {"id": "1805.04737", "submitter": "Dongrui Wu", "authors": "Dongrui Wu, Vernon J. Lawhern, Stephen Gordon, Brent J. Lance,\n  Chin-Teng Lin", "title": "Offline EEG-Based Driver Drowsiness Estimation Using Enhanced Batch-Mode\n  Active Learning (EBMAL) for Regression", "comments": null, "journal-ref": "IEEE Int'l. Conf. on Systems, Man and Cybernetics, pp. 730-736,\n  Budapest, Hungary, 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many important regression problems in real-world brain-computer\ninterface (BCI) applications, e.g., driver drowsiness estimation from EEG\nsignals. This paper considers offline analysis: given a pool of unlabeled EEG\nepochs recorded during driving, how do we optimally select a small number of\nthem to label so that an accurate regression model can be built from them to\nlabel the rest? Active learning is a promising solution to this problem, but\ninterestingly, to our best knowledge, it has not been used for regression\nproblems in BCI so far. This paper proposes a novel enhanced batch-mode active\nlearning (EBMAL) approach for regression, which improves upon a baseline active\nlearning algorithm by increasing the reliability, representativeness and\ndiversity of the selected samples to achieve better regression performance. We\nvalidate its effectiveness using driver drowsiness estimation from EEG signals.\nHowever, EBMAL is a general approach that can also be applied to many other\noffline regression problems beyond BCI.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 15:36:05 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wu", "Dongrui", ""], ["Lawhern", "Vernon J.", ""], ["Gordon", "Stephen", ""], ["Lance", "Brent J.", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1805.04740", "submitter": "Dongrui Wu", "authors": "Dongrui Wu, Vernon J. Lawhern, Stephen Gordon, Brent J. Lance,\n  Chin-Teng Lin", "title": "Agreement Rate Initialized Maximum Likelihood Estimator for Ensemble\n  Classifier Aggregation and Its Application in Brain-Computer Interface", "comments": null, "journal-ref": "IEEE Int'l. Conf. on Systems, Man and Cybernetics, pp. 724-729,\n  Budapest, Hungary, 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a powerful approach to construct a strong learner from\nmultiple base learners. The most popular way to aggregate an ensemble of\nclassifiers is majority voting, which assigns a sample to the class that most\nbase classifiers vote for. However, improved performance can be obtained by\nassigning weights to the base classifiers according to their accuracy. This\npaper proposes an agreement rate initialized maximum likelihood estimator\n(ARIMLE) to optimally fuse the base classifiers. ARIMLE first uses a simplified\nagreement rate method to estimate the classification accuracy of each base\nclassifier from the unlabeled samples, then employs the accuracies to\ninitialize a maximum likelihood estimator (MLE), and finally uses the\nexpectation-maximization algorithm to refine the MLE. Extensive experiments on\nvisually evoked potential classification in a brain-computer interface\napplication show that ARIMLE outperforms majority voting, and also achieves\nbetter or comparable performance with several other state-of-the-art classifier\ncombination approaches.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 15:43:36 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Wu", "Dongrui", ""], ["Lawhern", "Vernon J.", ""], ["Gordon", "Stephen", ""], ["Lance", "Brent J.", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1805.04748", "submitter": "Juan Cruz Barsce", "authors": "Juan Cruz Barsce, Jorge A. Palombarini, Ernesto C. Mart\\'inez", "title": "Towards Autonomous Reinforcement Learning: Automatic Setting of\n  Hyper-parameters using Bayesian Optimization", "comments": "Paper submitted to CLEI Electronic Journal. This is an extended\n  version of the conference paper presented at Latin American Computer\n  Conference (CLEI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of machine learning usage by industries and scientific\ncommunities in a variety of tasks such as text mining, image recognition and\nself-driving cars, automatic setting of hyper-parameter in learning algorithms\nis a key factor for achieving satisfactory performance regardless of user\nexpertise in the inner workings of the techniques and methodologies. In\nparticular, for a reinforcement learning algorithm, the efficiency of an agent\nlearning a control policy in an uncertain environment is heavily dependent on\nthe hyper-parameters used to balance exploration with exploitation. In this\nwork, an autonomous learning framework that integrates Bayesian optimization\nwith Gaussian process regression to optimize the hyper-parameters of a\nreinforcement learning algorithm, is proposed. Also, a bandits-based approach\nto achieve a balance between computational costs and decreasing uncertainty\nabout the Q-values, is presented. A gridworld example is used to highlight how\nhyper-parameter configurations of a learning algorithm (SARSA) are iteratively\nimproved based on two performance functions.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 16:42:55 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Barsce", "Juan Cruz", ""], ["Palombarini", "Jorge A.", ""], ["Mart\u00ednez", "Ernesto C.", ""]]}, {"id": "1805.04754", "submitter": "Nikit Gawande", "authors": "Kumarjit Pathak, Prabhukiran G, Jitin Kapila, Nikit Gawande", "title": "Incremental Learning Framework Using Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High volume of data, perceived as either challenge or opportunity. Deep\nlearning architecture demands high volume of data to effectively back propagate\nand train the weights without bias. At the same time, large volume of data\ndemands higher capacity of the machine where it could be executed seamlessly.\nBudding data scientist along with many research professionals face frequent\ndisconnection issue with cloud computing framework (working without dedicated\nconnection) due to free subscription to the platform. Similar issues also\nvisible while working on local computer where computer may run out of resource\nor power sometimes and researcher has to start training the models all over\nagain. In this paper, we intend to provide a way to resolve this issue and\nprogressively training the neural network even after having frequent\ndisconnection or resource outage without loosing much of the progress\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 17:58:24 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Pathak", "Kumarjit", ""], ["G", "Prabhukiran", ""], ["Kapila", "Jitin", ""], ["Gawande", "Nikit", ""]]}, {"id": "1805.04755", "submitter": "Brandon Greenwell", "authors": "Brandon M. Greenwell, Bradley C. Boehmke, Andrew J. McCarthy", "title": "A Simple and Effective Model-Based Variable Importance Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of \"big data\", it is becoming more of a challenge to not only\nbuild state-of-the-art predictive models, but also gain an understanding of\nwhat's really going on in the data. For example, it is often of interest to\nknow which, if any, of the predictors in a fitted model are relatively\ninfluential on the predicted outcome. Some modern algorithms---like random\nforests and gradient boosted decision trees---have a natural way of quantifying\nthe importance or relative influence of each feature. Other algorithms---like\nnaive Bayes classifiers and support vector machines---are not capable of doing\nso and model-free approaches are generally used to measure each predictor's\nimportance. In this paper, we propose a standardized, model-based approach to\nmeasuring predictor importance across the growing spectrum of supervised\nlearning algorithms. Our proposed method is illustrated through both simulated\nand real data examples. The R code to reproduce all of the figures in this\npaper is available in the supplementary materials.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 18:05:28 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Greenwell", "Brandon M.", ""], ["Boehmke", "Bradley C.", ""], ["McCarthy", "Andrew J.", ""]]}, {"id": "1805.04756", "submitter": "Matias Valdenegro-Toro", "authors": "Diego Vergara, Sergio Hern\\'andez, Matias Valdenegro-Toro and Felipe\n  Jorquera", "title": "Improving Predictive Uncertainty Estimation using Dropout -- Hamiltonian\n  Monte Carlo", "comments": "26 Pages, 12 Figures, version 3, to appear in Soft Computing, Author\n  preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating predictive uncertainty is crucial for many computer vision tasks,\nfrom image classification to autonomous driving systems. Hamiltonian Monte\nCarlo (HMC) is an sampling method for performing Bayesian inference. On the\nother hand, Dropout regularization has been proposed as an approximate model\naveraging technique that tends to improve generalization in large scale models\nsuch as deep neural networks. Although, HMC provides convergence guarantees for\nmost standard Bayesian models, it does not handle discrete parameters arising\nfrom Dropout regularization. In this paper, we present a robust methodology for\nimproving predictive uncertainty in classification problems, based on Dropout\nand Hamiltonian Monte Carlo. Even though Dropout induces a non-smooth energy\nfunction with no such convergence guarantees, the resulting discretization of\nthe Hamiltonian proves empirical success. The proposed method allows to\neffectively estimate the predictive accuracy and to provide better\ngeneralization for difficult test examples.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 18:11:33 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 01:17:11 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 13:49:05 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Vergara", "Diego", ""], ["Hern\u00e1ndez", "Sergio", ""], ["Valdenegro-Toro", "Matias", ""], ["Jorquera", "Felipe", ""]]}, {"id": "1805.04770", "submitter": "Tommaso Furlanello", "authors": "Tommaso Furlanello, Zachary C. Lipton, Michael Tschannen, Laurent Itti\n  and Anima Anandkumar", "title": "Born Again Neural Networks", "comments": "Published @ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) consists of transferring knowledge from one\nmachine learning model (the teacher}) to another (the student). Commonly, the\nteacher is a high-capacity model with formidable performance, while the student\nis more compact. By transferring knowledge, one hopes to benefit from the\nstudent's compactness. %we desire a compact model with performance close to the\nteacher's. We study KD from a new perspective: rather than compressing models,\nwe train students parameterized identically to their teachers. Surprisingly,\nthese {Born-Again Networks (BANs), outperform their teachers significantly,\nboth on computer vision and language modeling tasks. Our experiments with BANs\nbased on DenseNets demonstrate state-of-the-art performance on the CIFAR-10\n(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional\nexperiments explore two distillation objectives: (i) Confidence-Weighted by\nTeacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).\nBoth methods elucidate the essential components of KD, demonstrating a role of\nthe teacher outputs on both predicted and non-predicted classes. We present\nexperiments with students of various capacities, focusing on the under-explored\ncase where students overpower teachers. Our experiments show significant\nadvantages from transferring knowledge between DenseNets and ResNets in either\ndirection.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 19:48:50 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 10:46:28 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Furlanello", "Tommaso", ""], ["Lipton", "Zachary C.", ""], ["Tschannen", "Michael", ""], ["Itti", "Laurent", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1805.04784", "submitter": "Jundong Liu", "authors": "Zhewei Wang, Bibo Shi, Charles D. Smith, Jundong Liu", "title": "Nonlinear Metric Learning through Geodesic Interpolation within Lie\n  Groups", "comments": "6 pages; accepted to ICPR'2018; Lie groups for metric learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a nonlinear distance metric learning scheme based\non the fusion of component linear metrics. Instead of merging displacements at\neach data point, our model calculates the velocities induced by the component\ntransformations, via a geodesic interpolation on a Lie transfor- mation group.\nSuch velocities are later summed up to produce a global transformation that is\nguaranteed to be diffeomorphic. Consequently, pair-wise distances computed this\nway conform to a smooth and spatially varying metric, which can greatly benefit\nk-NN classification. Experiments on synthetic and real datasets demonstrate the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 21:12:20 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 11:24:27 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 15:49:12 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Wang", "Zhewei", ""], ["Shi", "Bibo", ""], ["Smith", "Charles D.", ""], ["Liu", "Jundong", ""]]}, {"id": "1805.04785", "submitter": "Yining Wang", "authors": "Xi Chen, Yining Wang, Yuan Zhou", "title": "An Optimal Policy for Dynamic Assortment Planning Under Uncapacitated\n  Multinomial Logit Models", "comments": "29 pages, 1 figure, 1 table. Removed an additional $O(\\sqrt{\\log\\log\n  T})$ term in the regret upper bound from the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamic assortment planning problem, where for each arriving\ncustomer, the seller offers an assortment of substitutable products and\ncustomer makes the purchase among offered products according to an\nuncapacitated multinomial logit (MNL) model. Since all the utility parameters\nof MNL are unknown, the seller needs to simultaneously learn customers' choice\nbehavior and make dynamic decisions on assortments based on the current\nknowledge. The goal of the seller is to maximize the expected revenue, or\nequivalently, to minimize the expected regret. Although dynamic assortment\nplanning problem has received an increasing attention in revenue management,\nmost existing policies require the estimation of mean utility for each product\nand the final regret usually involves the number of products $N$. The optimal\nregret of the dynamic assortment planning problem under the most basic and\npopular choice model---MNL model is still open. By carefully analyzing a\nrevenue potential function, we develop a trisection based policy combined with\nadaptive confidence bound construction, which achieves an {item-independent}\nregret bound of $O(\\sqrt{T})$, where $T$ is the length of selling horizon. We\nfurther establish the matching lower bound result to show the optimality of our\npolicy. There are two major advantages of the proposed policy. First, the\nregret of all our policies has no dependence on $N$. Second, our policies are\nalmost assumption free: there is no assumption on mean utility nor any\n\"separability\" condition on the expected revenues for different assortments.\nOur result also extends the unimodal bandit literature.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 21:13:42 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 21:17:03 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Yining", ""], ["Zhou", "Yuan", ""]]}, {"id": "1805.04807", "submitter": "Chang Liu", "authors": "Qi-Zhi Cai, Min Du, Chang Liu, Dawn Song", "title": "Curriculum Adversarial Training", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has been applied to many security-sensitive\napplications, such as facial authentication. The existence of adversarial\nexamples hinders such applications. The state-of-the-art result on defense\nshows that adversarial training can be applied to train a robust model on MNIST\nagainst adversarial examples; but it fails to achieve a high empirical\nworst-case accuracy on a more complex task, such as CIFAR-10 and SVHN. In our\nwork, we propose curriculum adversarial training (CAT) to resolve this issue.\nThe basic idea is to develop a curriculum of adversarial examples generated by\nattacks with a wide range of strengths. With two techniques to mitigate the\nforgetting and the generalization issues, we demonstrate that CAT can improve\nthe prior art's empirical worst-case accuracy by a large margin of 25% on\nCIFAR-10 and 35% on SVHN. At the same, the model's performance on\nnon-adversarial inputs is comparable to the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 02:10:56 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Cai", "Qi-Zhi", ""], ["Du", "Min", ""], ["Liu", "Chang", ""], ["Song", "Dawn", ""]]}, {"id": "1805.04829", "submitter": "Alexander Amini", "authors": "Alexander Amini, Ava Soleimany, Sertac Karaman, Daniela Rus", "title": "Spatial Uncertainty Sampling for End-to-End Control", "comments": "Originally published in Neural Information Processing Systems (NIPS)\n  Workshop on Bayesian Deep Learning 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end trained neural networks (NNs) are a compelling approach to\nautonomous vehicle control because of their ability to learn complex tasks\nwithout manual engineering of rule-based decisions. However, challenging road\nconditions, ambiguous navigation situations, and safety considerations require\nreliable uncertainty estimation for the eventual adoption of full-scale\nautonomous vehicles. Bayesian deep learning approaches provide a way to\nestimate uncertainty by approximating the posterior distribution of weights\ngiven a set of training data. Dropout training in deep NNs approximates\nBayesian inference in a deep Gaussian process and can thus be used to estimate\nmodel uncertainty. In this paper, we propose a Bayesian NN for end-to-end\ncontrol that estimates uncertainty by exploiting feature map correlation during\ntraining. This approach achieves improved model fits, as well as tighter\nuncertainty estimates, than traditional element-wise dropout. We evaluate our\nalgorithms on a challenging dataset collected over many different road types,\ntimes of day, and weather conditions, and demonstrate how uncertainties can be\nused in conjunction with a human controller in a parallel autonomous setting.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 06:19:14 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:10:40 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Amini", "Alexander", ""], ["Soleimany", "Ava", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "1805.04874", "submitter": "Bogdan Mazoure", "authors": "Thang Doan, Bogdan Mazoure and Clare Lyle", "title": "GAN Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional reinforcement learning (distributional RL) has seen empirical\nsuccess in complex Markov Decision Processes (MDPs) in the setting of nonlinear\nfunction approximation. However, there are many different ways in which one can\nleverage the distributional approach to reinforcement learning. In this paper,\nwe propose GAN Q-learning, a novel distributional RL method based on generative\nadversarial networks (GANs) and analyze its performance in simple tabular\nenvironments, as well as OpenAI Gym. We empirically show that our algorithm\nleverages the flexibility and blackbox approach of deep learning models while\nproviding a viable alternative to traditional methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 12:41:53 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 20:00:50 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 22:22:53 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Doan", "Thang", ""], ["Mazoure", "Bogdan", ""], ["Lyle", "Clare", ""]]}, {"id": "1805.04908", "submitter": "Gail Weiss", "authors": "Gail Weiss, Yoav Goldberg, Eran Yahav", "title": "On the Practical Computational Power of Finite Precision RNNs for\n  Language Recognition", "comments": "Accepted as a short paper in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Recurrent Neural Networks (RNNs) are famously known to be Turing\ncomplete, this relies on infinite precision in the states and unbounded\ncomputation time. We consider the case of RNNs with finite precision whose\ncomputation time is linear in the input length. Under these limitations, we\nshow that different RNN variants have different computational power. In\nparticular, we show that the LSTM and the Elman-RNN with ReLU activation are\nstrictly stronger than the RNN with a squashing activation and the GRU. This is\nachieved because LSTMs and ReLU-RNNs can easily implement counting behavior. We\nshow empirically that the LSTM does indeed learn to effectively use the\ncounting mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 16:28:32 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Weiss", "Gail", ""], ["Goldberg", "Yoav", ""], ["Yahav", "Eran", ""]]}, {"id": "1805.04912", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen and Evaggelia Tsiligianni and Nikos Deligiannis", "title": "Extendable Neural Matrix Completion", "comments": "5 pages, 2 figures, ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is one of the key problems in signal processing and machine\nlearning, with applications ranging from image pro- cessing and data gathering\nto classification and recommender sys- tems. Recently, deep neural networks\nhave been proposed as la- tent factor models for matrix completion and have\nachieved state- of-the-art performance. Nevertheless, a major problem with\nexisting neural-network-based models is their limited capabilities to extend to\nsamples unavailable at the training stage. In this paper, we propose a deep\ntwo-branch neural network model for matrix completion. The proposed model not\nonly inherits the predictive power of neural net- works, but is also capable of\nextending to partially observed samples outside the training set, without the\nneed of retraining or fine-tuning. Experimental studies on popular movie rating\ndatasets prove the ef- fectiveness of our model compared to the state of the\nart, in terms of both accuracy and extendability.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 16:46:36 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1805.04927", "submitter": "Xiaogang (Steven) Wang", "authors": "Masoud Ataei, Shengyuan Chen and Xiaogang Wang", "title": "Lehmer Transform and its Theoretical Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of transforms that we call {\\it Lehmer Transform}\nwhich is motivated by the {\\it Lehmer mean function}. The proposed {\\it Lehmer\ntransform} decomposes a function of a sample into their constituting\nstatistical moments. Theoretical properties of the proposed transform are\npresented. This transform could be very useful to provide an alternative method\nin analyzing non-stationary signals such as brain wave EEG.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 19:04:25 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ataei", "Masoud", ""], ["Chen", "Shengyuan", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1805.04928", "submitter": "Panos Stinis", "authors": "Nathan O. Hodas, Panos Stinis", "title": "Doing the impossible: Why neural networks can be trained at all", "comments": "The material is based on a poster from the 15th Neural Computation\n  and Psychology Workshop \"Contemporary Neural Network Models: Machine\n  Learning, Artificial Intelligence, and Cognition\" August 8-9, 2016, Drexel\n  University, Philadelphia, PA, USA", "journal-ref": null, "doi": null, "report-no": "PNNL-SA-127608", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks grow in size, from thousands to millions to billions\nof weights, the performance of those networks becomes limited by our ability to\naccurately train them. A common naive question arises: if we have a system with\nbillions of degrees of freedom, don't we also need billions of samples to train\nit? Of course, the success of deep learning indicates that reliable models can\nbe learned with reasonable amounts of data. Similar questions arise in protein\nfolding, spin glasses and biological neural networks. With effectively infinite\npotential folding/spin/wiring configurations, how does the system find the\nprecise arrangement that leads to useful and robust results? Simple sampling of\nthe possible configurations until an optimal one is reached is not a viable\noption even if one waited for the age of the universe. On the contrary, there\nappears to be a mechanism in the above phenomena that forces them to achieve\nconfigurations that live on a low-dimensional manifold, avoiding the curse of\ndimensionality. In the current work we use the concept of mutual information\nbetween successive layers of a deep neural network to elucidate this mechanism\nand suggest possible ways of exploiting it to accelerate training. We show that\nadding structure to the neural network that enforces higher mutual information\nbetween layers speeds training and leads to more accurate results. High mutual\ninformation between layers implies that the effective number of free parameters\nis exponentially smaller than the raw number of tunable weights.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 19:04:50 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 01:44:12 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Hodas", "Nathan O.", ""], ["Stinis", "Panos", ""]]}, {"id": "1805.04933", "submitter": "Zhidong Han", "authors": "Zhidong Han", "title": "Dyna: A Method of Momentum for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is presented for momentum gradient descent optimization based on\nthe first-order differential equation of the Newtonian dynamics. The fictitious\nmass is introduced to the dynamics of momentum for regularizing the adaptive\nstepsize of each individual parameter. The dynamic relaxation is adapted for\nstochastic optimization of nonlinear objective functions through an explicit\ntime integration with varying damping ratio. The adaptive stepsize is optimized\nfor each individual neural network layer based on the number of inputs. The\nadaptive stepsize for every parameter over the entire neural network is\nuniformly optimized with one upper bound, independent of sparsity, for better\noverall convergence rate. The numerical implementation of the algorithm is\nsimilar to the Adam Optimizer, possessing computational efficiency, similar\nmemory requirements, etc. There are three hyper-parameters in the algorithm\nwith clear physical interpretation. Preliminary trials show promise in\nperformance and convergence.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 19:21:38 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Han", "Zhidong", ""]]}, {"id": "1805.04938", "submitter": "Zhihui Zhu", "authors": "Zhihui Zhu, Daniel Soudry, Yonina C. Eldar, Michael B. Wakin", "title": "The Global Optimization Geometry of Shallow Linear Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the squared error loss landscape of shallow linear neural\nnetworks. We show---with significantly milder assumptions than previous\nworks---that the corresponding optimization problems have benign geometric\nproperties: there are no spurious local minima and the Hessian at every saddle\npoint has at least one negative eigenvalue. This means that at every saddle\npoint there is a directional negative curvature which algorithms can utilize to\nfurther decrease the objective value. These geometric properties imply that\nmany local search algorithms (such as the gradient descent which is widely\nutilized for training neural networks) can provably solve the training problem\nwith global convergence.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 20:09:09 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 04:56:18 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zhu", "Zhihui", ""], ["Soudry", "Daniel", ""], ["Eldar", "Yonina C.", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1805.04955", "submitter": "Thomas Stepleton", "authors": "Thomas Stepleton, Razvan Pascanu, Will Dabney, Siddhant M. Jayakumar,\n  Hubert Soyer, Remi Munos", "title": "Low-pass Recurrent Neural Networks - A memory architecture for\n  longer-term correlation discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents performing complex tasks must be able to\nremember observations and actions across sizable time intervals. This is\nespecially true during the initial learning stages, when exploratory behaviour\ncan increase the delay between specific actions and their effects. Many new or\npopular approaches for learning these distant correlations employ\nbackpropagation through time (BPTT), but this technique requires storing\nobservation traces long enough to span the interval between cause and effect.\nBesides memory demands, learning dynamics like vanishing gradients and slow\nconvergence due to infrequent weight updates can reduce BPTT's practicality;\nmeanwhile, although online recurrent network learning is a developing topic,\nmost approaches are not efficient enough to use as replacements. We propose a\nsimple, effective memory strategy that can extend the window over which BPTT\ncan learn without requiring longer traces. We explore this approach empirically\non a few tasks and discuss its implications.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 21:35:08 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Stepleton", "Thomas", ""], ["Pascanu", "Razvan", ""], ["Dabney", "Will", ""], ["Jayakumar", "Siddhant M.", ""], ["Soyer", "Hubert", ""], ["Munos", "Remi", ""]]}, {"id": "1805.04958", "submitter": "Julian Yarkony", "authors": "Julian Yarkony, Shaofei Wang", "title": "Accelerating Message Passing for MAP with Benders Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel mechanism to tighten the local polytope relaxation for\nMAP inference in Markov random fields with low state space variables. We\nconsider a surjection of the variables to a set of hyper-variables and apply\nthe local polytope relaxation over these hyper-variables. The state space of\neach individual hyper-variable is constructed to be enumerable while the vector\nproduct of pairs is not easily enumerable making message passing inference\nintractable.\n  To circumvent the difficulty of enumerating the vector product of state\nspaces of hyper-variables we introduce a novel Benders decomposition approach.\nThis produces an upper envelope describing the message constructed from affine\nfunctions of the individual variables that compose the hyper-variable receiving\nthe message. The envelope is tight at the minimizers which are shared by the\ntrue message. Benders rows are constructed to be Pareto optimal and are\ngenerated using an efficient procedure targeted for binary problems.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 21:40:58 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Yarkony", "Julian", ""], ["Wang", "Shaofei", ""]]}, {"id": "1805.04982", "submitter": "Anthony Tompkins", "authors": "Anthony Tompkins and Fabio Ramos", "title": "Index Set Fourier Series Features for Approximating Multi-dimensional\n  Periodic Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Periodicity is often studied in timeseries modelling with autoregressive\nmethods but is less popular in the kernel literature, particularly for higher\ndimensional problems such as in textures, crystallography, and quantum\nmechanics. Large datasets often make modelling periodicity untenable for\notherwise powerful non-parametric methods like Gaussian Processes (GPs) which\ntypically incur an $\\mathcal{O}(N^3)$ computational burden and, consequently,\nare unable to scale to larger datasets. To this end we introduce a method\ntermed \\emph{Index Set Fourier Series Features} to tractably exploit\nmultivariate Fourier series and efficiently decompose periodic kernels on\nhigher-dimensional data into a series of basis functions. We show that our\napproximation produces significantly less predictive error than alternative\napproaches such as those based on random Fourier features and achieves better\ngeneralisation on regression problems with periodic data.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 01:52:02 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Tompkins", "Anthony", ""], ["Ramos", "Fabio", ""]]}, {"id": "1805.05010", "submitter": "Jingyi Wang Ph.D.", "authors": "Jingyi Wang and Jun Sun and Peixin Zhang and Xinyu Wang", "title": "Detecting Adversarial Samples for Deep Neural Networks through Mutation\n  Testing", "comments": "Sumitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been shown that deep neural networks (DNN) are subject to\nattacks through adversarial samples. Adversarial samples are often crafted\nthrough adversarial perturbation, i.e., manipulating the original sample with\nminor modifications so that the DNN model labels the sample incorrectly. Given\nthat it is almost impossible to train perfect DNN, adversarial samples are\nshown to be easy to generate. As DNN are increasingly used in safety-critical\nsystems like autonomous cars, it is crucial to develop techniques for defending\nsuch attacks. Existing defense mechanisms which aim to make adversarial\nperturbation challenging have been shown to be ineffective. In this work, we\npropose an alternative approach. We first observe that adversarial samples are\nmuch more sensitive to perturbations than normal samples. That is, if we impose\nrandom perturbations on a normal and an adversarial sample respectively, there\nis a significant difference between the ratio of label change due to the\nperturbations. Observing this, we design a statistical adversary detection\nalgorithm called nMutant (inspired by mutation testing from software\nengineering community). Our experiments show that nMutant effectively detects\nmost of the adversarial samples generated by recently proposed attacking\nmethods. Furthermore, we provide an error bound with certain statistical\nsignificance along with the detection.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 04:48:24 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 08:38:04 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Zhang", "Peixin", ""], ["Wang", "Xinyu", ""]]}, {"id": "1805.05021", "submitter": "Sarah Itani", "authors": "Sarah Itani and Fabian Lecron and Philippe Fortemps", "title": "A One-Class Classification Decision Tree Based on Kernel Density\n  Estimation", "comments": null, "journal-ref": "Applied Soft Computing, Vol. 91, June 2020, 106250", "doi": "10.1016/j.asoc.2020.106250", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class Classification (OCC) is an area of machine learning which addresses\nprediction based on unbalanced datasets. Basically, OCC algorithms achieve\ntraining by means of a single class sample, with potentially some additional\ncounter-examples. The current OCC models give satisfaction in terms of\nperformance, but there is an increasing need for the development of\ninterpretable models. In the present work, we propose a one-class model which\naddresses concerns of both performance and interpretability. Our hybrid OCC\nmethod relies on density estimation as part of a tree-based learning algorithm,\ncalled One-Class decision Tree (OC-Tree). Within a greedy and recursive\napproach, our proposal rests on kernel density estimation to split a data\nsubset on the basis of one or several intervals of interest. Thus, the OC-Tree\nencloses data within hyper-rectangles of interest which can be described by a\nset of rules. Against state-of-the-art methods such as Cluster Support Vector\nData Description (ClusterSVDD), One-Class Support Vector Machine (OCSVM) and\nisolation Forest (iForest), the OC-Tree performs favorably on a range of\nbenchmark datasets. Furthermore, we propose a real medical application for\nwhich the OC-Tree has demonstrated its effectiveness, through the ability to\ntackle interpretable diagnosis aid based on unbalanced datasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 06:26:59 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:48:17 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 07:13:01 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Itani", "Sarah", ""], ["Lecron", "Fabian", ""], ["Fortemps", "Philippe", ""]]}, {"id": "1805.05036", "submitter": "Martin L\\\"angkvist", "authors": "Martin L\\\"angkvist and Amy Loutfi", "title": "A Deep Learning Approach with an Attention Mechanism for Automatic Sleep\n  Stage Classification", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic sleep staging is a challenging problem and state-of-the-art\nalgorithms have not yet reached satisfactory performance to be used instead of\nmanual scoring by a sleep technician. Much research has been done to find good\nfeature representations that extract the useful information to correctly\nclassify each epoch into the correct sleep stage. While many useful features\nhave been discovered, the amount of features have grown to an extent that a\nfeature reduction step is necessary in order to avoid the curse of\ndimensionality. One reason for the need of such a large feature set is that\nmany features are good for discriminating only one of the sleep stages and are\nless informative during other stages. This paper explores how a second feature\nrepresentation over a large set of pre-defined features can be learned using an\nauto-encoder with a selective attention for the current sleep stage in the\ntraining batch. This selective attention allows the model to learn feature\nrepresentations that focuses on the more relevant inputs without having to\nperform any dimensionality reduction of the input data. The performance of the\nproposed algorithm is evaluated on a large data set of polysomnography (PSG)\nnight recordings of patients with sleep-disordered breathing. The performance\nof the auto-encoder with selective attention is compared with a regular\nauto-encoder and previous works using a deep belief network (DBN).\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 07:36:26 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["L\u00e4ngkvist", "Martin", ""], ["Loutfi", "Amy", ""]]}, {"id": "1805.05052", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "Machine Learning: Basic Principles", "comments": "Machine Learning, Artificial Intelligence, Deep Learning, Data\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial introduces some main concepts of machine learning (ML). From an\nengineering point of view, the field of ML revolves around developing software\nthat implements the scientific principle: (i) formulate a hypothesis (choose a\nmodel) about some phenomenon, (ii) collect data to test the hypothesis\n(validate the model) and (iii) refine the hypothesis (iterate). One important\nclass of algorithms based on this principle are gradient descent methods which\naim at iteratively refining a model which is parametrized by some (\"weight\")\nvector. A plethora of ML methods is obtained by combining different choices for\nthe hypothesis space (model), the quality measure (loss) and the computational\nimplementation of the model refinement (optimization method). %Many of the\ncurrent systems, which are considered as (artificially) intelligent, are based\non %combinations of few basic machine learning methods. After formalizing the\nmain building blocks of an ML problem, some popular algorithmic design patterns\nfor ML methods are discussed. This tutorial grew out of the lecture notes\ndeveloped for the courses \"Machine Learning: Basic Principles\" and \"Artificial\nIntelligence\", which I have co-taught since 2015 at Aalto University.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 08:08:33 GMT"}, {"version": "v10", "created": "Sun, 17 Mar 2019 17:52:27 GMT"}, {"version": "v11", "created": "Sun, 19 May 2019 17:55:22 GMT"}, {"version": "v12", "created": "Fri, 21 Aug 2020 12:20:38 GMT"}, {"version": "v13", "created": "Wed, 21 Oct 2020 14:48:31 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 16:44:51 GMT"}, {"version": "v3", "created": "Wed, 20 Jun 2018 17:30:45 GMT"}, {"version": "v4", "created": "Sun, 5 Aug 2018 14:22:18 GMT"}, {"version": "v5", "created": "Sun, 19 Aug 2018 07:00:46 GMT"}, {"version": "v6", "created": "Wed, 5 Sep 2018 12:43:31 GMT"}, {"version": "v7", "created": "Wed, 19 Sep 2018 14:42:55 GMT"}, {"version": "v8", "created": "Mon, 8 Oct 2018 06:20:08 GMT"}, {"version": "v9", "created": "Mon, 28 Jan 2019 06:58:45 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1805.05071", "submitter": "Gilles Stoltz", "authors": "Aur\\'elien Garivier, H\\'edi Hadiji, Pierre Menard, Gilles Stoltz", "title": "KL-UCB-switch: optimal regret bounds for stochastic bandits from both a\n  distribution-dependent and a distribution-free viewpoints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of K-armed stochastic bandits with distribution only assumed\nto be supported by [0,1], we introduce the first algorithm, called\nKL-UCB-switch, that enjoys simultaneously a distribution-free regret bound of\noptimal order $\\sqrt{KT}$ and a distribution-dependent regret bound of optimal\norder as well, that is, matching the $\\kappa\\ln T$ lower bound by Lai & Robbins\n(1985) and Burnetas & Katehakis (1996). This self-contained contribution\nsimultaneously presents state-of-the-art techniques for regret minimization in\nbandit models, and an elementary construction of non-asymptotic confidence\nbounds based on the empirical likelihood method for bounded distributions.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:05:10 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:13:40 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Garivier", "Aur\u00e9lien", ""], ["Hadiji", "H\u00e9di", ""], ["Menard", "Pierre", ""], ["Stoltz", "Gilles", ""]]}, {"id": "1805.05151", "submitter": "Firoj Alam", "authors": "Firoj Alam and Shafiq Joty and Muhammad Imran", "title": "Domain Adaptation with Adversarial Training and Graph Embeddings", "comments": "This is a pre-print of our paper accepted to appear in the\n  proceedings of the ACL, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep neural networks (DNNs) is heavily dependent on the\navailability of labeled data. However, obtaining labeled data is a big\nchallenge in many real-world problems. In such scenarios, a DNN model can\nleverage labeled and unlabeled data from a related domain, but it has to deal\nwith the shift in data distributions between the source and the target domains.\nIn this paper, we study the problem of classifying social media posts during a\ncrisis event (e.g., Earthquake). For that, we use labeled and unlabeled data\nfrom past similar events (e.g., Flood) and unlabeled data for the current\nevent. We propose a novel model that performs adversarial learning based domain\nadaptation to deal with distribution drifts and graph based semi-supervised\nlearning to leverage unlabeled data within a single unified deep learning\nframework. Our experiments with two real-world crisis datasets collected from\nTwitter demonstrate significant improvements over several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 12:54:47 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Alam", "Firoj", ""], ["Joty", "Shafiq", ""], ["Imran", "Muhammad", ""]]}, {"id": "1805.05185", "submitter": "Yan Zuo", "authors": "Yan Zuo, Gil Avraham and Tom Drummond", "title": "Generative Adversarial Forests for Better Conditioned Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, many of the breakthroughs in various vision-related tasks\nhave revolved around improving learning of deep models; these methods have\nranged from network architectural improvements such as Residual Networks, to\nvarious forms of regularisation such as Batch Normalisation. In essence, many\nof these techniques revolve around better conditioning, allowing for deeper and\ndeeper models to be successfully learned. In this paper, we look towards better\nconditioning Generative Adversarial Networks (GANs) in an unsupervised learning\nsetting. Our method embeds the powerful discriminating capabilities of a\ndecision forest into the discriminator of a GAN. This results in a better\nconditioned model which learns in an extremely stable way. We demonstrate\nempirical results which show both clear qualitative and quantitative evidence\nof the effectiveness of our approach, gaining significant performance\nimprovements over several popular GAN-based approaches on the Oxford Flowers\nand Aligned Celebrity Faces datasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 14:19:49 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zuo", "Yan", ""], ["Avraham", "Gil", ""], ["Drummond", "Tom", ""]]}, {"id": "1805.05189", "submitter": "Wenjie Huang", "authors": "Wenjie Huang", "title": "Randomized Smoothing SVRG for Large-scale Nonsmooth Convex Optimization", "comments": "10 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1103.4296, arXiv:1403.4699 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of minimizing the average of a large\nnumber of nonsmooth and convex functions. Such problems often arise in typical\nmachine learning problems as empirical risk minimization, but are\ncomputationally very challenging. We develop and analyze a new algorithm that\nachieves robust linear convergence rate, and both its time complexity and\ngradient complexity are superior than state-of-art nonsmooth algorithms and\nsubgradient-based schemes. Besides, our algorithm works without any extra error\nbound conditions on the objective function as well as the common\nstrongly-convex condition. We show that our algorithm has wide applications in\noptimization and machine learning problems, and demonstrate experimentally that\nit performs well on a large-scale ranking problem.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 04:05:34 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Huang", "Wenjie", ""]]}, {"id": "1805.05239", "submitter": "Hamid Tizhoosh", "authors": "Sara Ross-Howe, H.R. Tizhoosh", "title": "The Effects of Image Pre- and Post-Processing, Wavelet Decomposition,\n  and Local Binary Patterns on U-Nets for Skin Lesion Segmentation", "comments": "Accepted for publication in proceedings of the IEEE World Congress on\n  Computational Intelligence (IEEE WCCI), Rio de Janeiro, Brazil, 8-3 July,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is a widespread, global, and potentially deadly disease, which\nover the last three decades has afflicted more lives in the USA than all other\nforms of cancer combined. There have been a lot of promising recent works\nutilizing deep network architectures, such as FCNs, U-Nets, and ResNets, for\ndeveloping automated skin lesion segmentation. This paper investigates various\npre- and post-processing techniques for improving the performance of U-Nets as\nmeasured by the Jaccard Index. The dataset provided as part of the \"2017 ISBI\nChallenges on Skin Lesion Analysis Towards Melanoma Detection\" was used for\nthis evaluation and the performance of the finalist competitors was the\nstandard for comparison. The pre-processing techniques employed in the proposed\nsystem included contrast enhancement, artifact removal, and vignette\ncorrection. More advanced image transformations, such as local binary patterns\nand wavelet decomposition, were also employed to augment the raw grayscale\nimages used as network input features. While the performance of the proposed\nsystem fell short of the winners of the challenge, it was determined that using\nwavelet decomposition as an early transformation step improved the overall\nperformance of the system over pre- and post-processing steps alone.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 23:23:15 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ross-Howe", "Sara", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1805.05287", "submitter": "Zhibing Zhao", "authors": "Zhibing Zhao, Haoming Li, Junming Wang, Jeffrey Kephart, Nicholas\n  Mattei, Hui Su, Lirong Xia", "title": "A Cost-Effective Framework for Preference Elicitation and Aggregation", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cost-effective framework for preference elicitation and\naggregation under the Plackett-Luce model with features. Given a budget, our\nframework iteratively computes the most cost-effective elicitation questions in\norder to help the agents make a better group decision.\n  We illustrate the viability of the framework with experiments on Amazon\nMechanical Turk, which we use to estimate the cost of answering different types\nof elicitation questions. We compare the prediction accuracy of our framework\nwhen adopting various information criteria that evaluate the expected\ninformation gain from a question. Our experiments show carefully designed\ninformation criteria are much more efficient, i.e., they arrive at the correct\nanswer using fewer queries, than randomly asking questions given the budget\nconstraint.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 16:57:36 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 13:50:56 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Zhao", "Zhibing", ""], ["Li", "Haoming", ""], ["Wang", "Junming", ""], ["Kephart", "Jeffrey", ""], ["Mattei", "Nicholas", ""], ["Su", "Hui", ""], ["Xia", "Lirong", ""]]}, {"id": "1805.05324", "submitter": "Paolo Bientinesi", "authors": "Tina Raissi (1), Alessandro Tibo (2), Paolo Bientinesi (1), ((1) RWTH\n  Aachen University, (2) University of Florence)", "title": "Extended pipeline for content-based feature engineering in music genre\n  recognition", "comments": "ICASSP 2018", "journal-ref": null, "doi": "10.1109/ICASSP.2018.8461807", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a feature engineering pipeline for the construction of musical\nsignal characteristics, to be used for the design of a supervised model for\nmusical genre identification. The key idea is to extend the traditional\ntwo-step process of extraction and classification with additive stand-alone\nphases which are no longer organized in a waterfall scheme. The whole system is\nrealized by traversing backtrack arrows and cycles between various stages. In\norder to give a compact and effective representation of the features, the\nstandard early temporal integration is combined with other selection and\nextraction phases: on the one hand, the selection of the most meaningful\ncharacteristics based on information gain, and on the other hand, the inclusion\nof the nonlinear correlation between this subset of features, determined by an\nautoencoder. The results of the experiments conducted on GTZAN dataset reveal a\nnoticeable contribution of this methodology towards the model's performance in\nclassification task.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 16:47:01 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Raissi", "Tina", ""], ["Tibo", "Alessandro", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1805.05361", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa, Wenlin Wang, Guoyin\n  Wang, Lawrence Carin, Ricardo Henao", "title": "NASH: Toward End-to-End Neural Architecture for Generative Semantic\n  Hashing", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic hashing has become a powerful paradigm for fast similarity search in\nmany information retrieval systems. While fairly successful, previous\ntechniques generally require two-stage training, and the binary constraints are\nhandled ad-hoc. In this paper, we present an end-to-end Neural Architecture for\nSemantic Hashing (NASH), where the binary hashing codes are treated as\nBernoulli latent variables. A neural variational inference framework is\nproposed for training, where gradients are directly back-propagated through the\ndiscrete latent variable to optimize the hash function. We also draw\nconnections between proposed method and rate-distortion theory, which provides\na theoretical foundation for the effectiveness of the proposed framework.\nExperimental results on three public datasets demonstrate that our method\nsignificantly outperforms several state-of-the-art models on both unsupervised\nand supervised scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:04:28 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Shen", "Dinghan", ""], ["Su", "Qinliang", ""], ["Chapfuwa", "Paidamoyo", ""], ["Wang", "Wenlin", ""], ["Wang", "Guoyin", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "1805.05373", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Yeeleng S. Vang, Yufang Huang, Xiaohui Xie", "title": "DeepEM: Deep 3D ConvNets With EM For Weakly Supervised Pulmonary Nodule\n  Detection", "comments": "MICCAI2018 Early Accept, Code\n  https://github.com/uci-cbcl/DeepEM-for-Weakly-Supervised-Detection.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning has been witnessing widespread adoption in various\nmedical image applications. However, training complex deep neural nets requires\nlarge-scale datasets labeled with ground truth, which are often unavailable in\nmany medical image domains. For instance, to train a deep neural net to detect\npulmonary nodules in lung computed tomography (CT) images, current practice is\nto manually label nodule locations and sizes in many CT images to construct a\nsufficiently large training dataset, which is costly and difficult to scale. On\nthe other hand, electronic medical records (EMR) contain plenty of partial\ninformation on the content of each medical image. In this work, we explore how\nto tap this vast, but currently unexplored data source to improve pulmonary\nnodule detection. We propose DeepEM, a novel deep 3D ConvNet framework\naugmented with expectation-maximization (EM), to mine weakly supervised labels\nin EMRs for pulmonary nodule detection. Experimental results show that DeepEM\ncan lead to 1.5\\% and 3.9\\% average improvement in free-response receiver\noperating characteristic (FROC) scores on LUNA16 and Tianchi datasets,\nrespectively, demonstrating the utility of incomplete information in EMRs for\nimproving deep learning\nalgorithms.\\footnote{https://github.com/uci-cbcl/DeepEM-for-Weakly-Supervised-Detection.git}\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:31:11 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 04:45:49 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 16:41:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhu", "Wentao", ""], ["Vang", "Yeeleng S.", ""], ["Huang", "Yufang", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1805.05383", "submitter": "Jeremias Knoblauch", "authors": "Jeremias Knoblauch and Theodoros Damoulas", "title": "Spatio-temporal Bayesian On-line Changepoint Detection with Model\n  Selection", "comments": "10 pages, 7f figures, to appear in Proceedings of the 35th\n  International Conference on Machine Learning 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian On-line Changepoint Detection is extended to on-line model selection\nand non-stationary spatio-temporal processes. We propose spatially structured\nVector Autoregressions (VARs) for modelling the process between changepoints\n(CPs) and give an upper bound on the approximation error of such models. The\nresulting algorithm performs prediction, model selection and CP detection\non-line. Its time complexity is linear and its space complexity constant, and\nthus it is two orders of magnitudes faster than its closest competitor. In\naddition, it outperforms the state of the art for multivariate data.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:59:04 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 15:43:20 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Knoblauch", "Jeremias", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "1805.05396", "submitter": "Tongfei Chen", "authors": "Tongfei Chen, Ji\\v{r}\\'i Navr\\'atil, Vijay Iyengar, Karthikeyan\n  Shanmugam", "title": "Confidence Scoring Using Whitebox Meta-models with Linear Classifier\n  Probes", "comments": "Accepted at AISTATS 2019", "journal-ref": "Proceedings of Machine Learning Research, PMLR 89:1467-1475, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel confidence scoring mechanism for deep neural networks\nbased on a two-model paradigm involving a base model and a meta-model. The\nconfidence score is learned by the meta-model observing the base model\nsucceeding/failing at its task. As features to the meta-model, we investigate\nlinear classifier probes inserted between the various layers of the base model.\nOur experiments demonstrate that this approach outperforms various baselines in\na filtering task, i.e., task of rejecting samples with low confidence.\nExperimental results are presented using CIFAR-10 and CIFAR-100 dataset with\nand without added noise. We discuss the importance of confidence scoring to\nbridge the gap between experimental and real-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 19:23:51 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 00:53:06 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Chen", "Tongfei", ""], ["Navr\u00e1til", "Ji\u0159\u00ed", ""], ["Iyengar", "Vijay", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "1805.05408", "submitter": "Nikita Tomin", "authors": "Nikita Tomin, Victor Kurbatsky, Michael Negnevitsky", "title": "The Concept of the Deep Learning-Based System \"Artificial Dispatcher\" to\n  Power System Control and Dispatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Year by year control of normal and emergency conditions of up-to-date power\nsystems becomes an increasingly complicated problem. With the increasing\ncomplexity the existing control system of power system conditions which\nincludes operative actions of the dispatcher and work of special automatic\ndevices proves to be insufficiently effective more and more frequently, which\nraises risks of dangerous and emergency conditions in power systems. The paper\nis aimed at compensating for the shortcomings of man (a cognitive barrier,\nexposure to stresses and so on) and automatic devices by combining their strong\npoints, i.e. the dispatcher's intelligence and the speed of automatic devices\nby virtue of development of the intelligent system \"Artificial dispatcher\" on\nthe basis of deep machine learning technology. For realization of the system\n\"Artificial dispatcher\" in addition to deep learning it is planned to attract\nthe game theory approaches to formalize work of the up-to-date power system as\na game problem. The \"gain\" for \"Artificial dispatcher\" will consist in bringing\nin a power system in the normal steady-state or post-emergency conditions by\nmeans of the required control actions.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 07:21:42 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Tomin", "Nikita", ""], ["Kurbatsky", "Victor", ""], ["Negnevitsky", "Michael", ""]]}, {"id": "1805.05409", "submitter": "Jason Anastasopoulos", "authors": "L. Jason Anastasopoulos and Andrew B. Whitford", "title": "Machine Learning for Public Administration Research, with Application to\n  Organizational Reputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have gained a great deal of popularity in recent\nyears among public administration scholars and practitioners. These techniques\nopen the door to the analysis of text, image and other types of data that allow\nus to test foundational theories of public administration and to develop new\ntheories. Despite the excitement surrounding machine learning methods, clarity\nregarding their proper use and potential pitfalls is lacking. This paper\nattempts to fill this gap in the literature through providing a machine\nlearning \"guide to practice\" for public administration scholars and\npractitioners. Here, we take a foundational view of machine learning and\ndescribe how these methods can enrich public administration research and\npractice through their ability develop new measures, tap into new sources of\ndata and conduct statistical inference and causal inference in a principled\nmanner. We then turn our attention to the pitfalls of using these methods such\nas unvalidated measures and lack of interpretability. Finally, we demonstrate\nhow machine learning techniques can help us learn about organizational\nreputation in federal agencies through an illustrated example using tweets from\n13 executive federal agencies.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 14:30:30 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 15:32:10 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Anastasopoulos", "L. Jason", ""], ["Whitford", "Andrew B.", ""]]}, {"id": "1805.05431", "submitter": "Ian Schneider", "authors": "Elaheh Fata, Igor Kadota and Ian Schneider", "title": "Comparison of Classical and Nonlinear Models for Short-Term Electricity\n  Price Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity is bought and sold in wholesale markets at prices that fluctuate\nsignificantly. Short-term forecasting of electricity prices is an important\nendeavor because it helps electric utilities control risk and because it\ninfluences competitive strategy for generators. As the \"smart grid\" grows,\nshort-term price forecasts are becoming an important input to bidding and\ncontrol algorithms for battery operators and demand response aggregators. While\nthe statistics and machine learning literature offers many proposed methods for\nelectricity price prediction, there is no consensus supporting a single best\napproach. We test two contrasting machine learning approaches for predicting\nelectricity prices, regression decision trees and recurrent neural networks\n(RNNs), and compare them to a more traditional ARIMA implementation. We conduct\nthe analysis on a challenging dataset of electricity prices from ERCOT, in\nTexas, where price fluctuation is especially high. We find that regression\ndecision trees in particular achieves high performance compared to the other\nmethods, suggesting that regression trees should be more carefully considered\nfor electricity price forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 20:15:36 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Fata", "Elaheh", ""], ["Kadota", "Igor", ""], ["Schneider", "Ian", ""]]}, {"id": "1805.05452", "submitter": "Azra Bihorac", "authors": "Lasith Adhikari, Tezcan Ozrazgat-Baslanti, Paul Thottakkara, Ashkan\n  Ebadi, Amir Motaei, Parisa Rashidi, Xiaolin Li, Azra Bihorac", "title": "Improved Predictive Models for Acute Kidney Injury with IDEAs:\n  Intraoperative Data Embedded Analytics", "comments": "47 pages, 6 Figures, Journal", "journal-ref": null, "doi": "10.1371/journal.pone.0214904", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute kidney injury (AKI) is a common and serious complication after a\nsurgery which is associated with morbidity and mortality. The majority of\nexisting perioperative AKI risk score prediction models are limited in their\ngeneralizability and do not fully utilize the physiological intraoperative\ntime-series data. Thus, there is a need for intelligent, accurate, and robust\nsystems, able to leverage information from large-scale data to predict\npatient's risk of developing postoperative AKI. A retrospective single-center\ncohort of 2,911 adult patients who underwent surgery at the University of\nFlorida Health has been used for this study. We used machine learning and\nstatistical analysis techniques to develop perioperative models to predict the\nrisk of AKI (risk during the first 3 days, 7 days, and until the discharge day)\nbefore and after the surgery. In particular, we examined the improvement in\nrisk prediction by incorporating three intraoperative physiologic time series\ndata, i.e., mean arterial blood pressure, minimum alveolar concentration, and\nheart rate. For an individual patient, the preoperative model produces a\nprobabilistic AKI risk score, which will be enriched by integrating\nintraoperative statistical features through a machine learning stacking\napproach inside a random forest classifier. We compared the performance of our\nmodel based on the area under the receiver operating characteristics curve\n(AUROC), accuracy and net reclassification improvement (NRI). The predictive\nperformance of the proposed model is better than the preoperative data only\nmodel. For AKI-7day outcome: The AUC was 0.86 (accuracy was 0.78) in the\nproposed model, while the preoperative AUC was 0.84 (accuracy 0.76).\nFurthermore, with the integration of intraoperative features, we were able to\nclassify patients who were misclassified in the preoperative model.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 15:21:11 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Adhikari", "Lasith", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Thottakkara", "Paul", ""], ["Ebadi", "Ashkan", ""], ["Motaei", "Amir", ""], ["Rashidi", "Parisa", ""], ["Li", "Xiaolin", ""], ["Bihorac", "Azra", ""]]}, {"id": "1805.05456", "submitter": "Manish Sharma", "authors": "Manish Sharma, Akash Anand, Rupika Srivastava and Lakshmi Kaligounder", "title": "Wearable Audio and IMU Based Shot Detection in Racquet Sports", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearables like smartwatches which are embedded with sensors and powerful\nprocessors, provide a strong platform for development of analytics solutions in\nsports domain. To analyze players' games, while motion sensor based shot\ndetection has been extensively studied in sports like Tennis, Golf, Baseball;\nTable Tennis and Badminton are relatively less explored due to possible less\nintense hand motion during shots. In our paper, we propose a novel,\ncomputationally inexpensive and real-time system for shot detection in table\ntennis, based on fusion of Inertial Measurement Unit (IMU) and audio sensor\ndata embedded in a wrist-worn wearable. The system builds upon our presented\nmethodology for synchronizing IMU and audio sensor input in time using detected\nshots and achieves 95.6% accuracy. To our knowledge, it is the first\nfusion-based solution for sports analysis in wearables. Shot detectors for\nother racquet sports as well as further analytics to provide features like shot\nclassification, rally analysis and recommendations, can easily be built over\nour proposed solution.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 21:31:59 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Sharma", "Manish", ""], ["Anand", "Akash", ""], ["Srivastava", "Rupika", ""], ["Kaligounder", "Lakshmi", ""]]}, {"id": "1805.05502", "submitter": "Jia Chen", "authors": "Jia Chen, Gang Wang, and Georgios B. Giannakis", "title": "Nonlinear Dimensionality Reduction for Discriminative Analytics of\n  Multiple Datasets", "comments": "final version", "journal-ref": null, "doi": "10.1109/TSP.2018.2885478", "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is widely used for feature extraction and\ndimensionality reduction, with documented merits in diverse tasks involving\nhigh-dimensional data. Standard PCA copes with one dataset at a time, but it is\nchallenged when it comes to analyzing multiple datasets jointly. In certain\ndata science settings however, one is often interested in extracting the most\ndiscriminative information from one dataset of particular interest (a.k.a.\ntarget data) relative to the other(s) (a.k.a. background data). To this end,\nthis paper puts forth a novel approach, termed discriminative (d) PCA, for such\ndiscriminative analytics of multiple datasets. Under certain conditions, dPCA\nis proved to be least-squares optimal in recovering the component vector unique\nto the target data relative to background data. To account for nonlinear data\ncorrelations, (linear) dPCA models for one or multiple background datasets are\ngeneralized through kernel-based learning. Interestingly, all dPCA variants\nadmit an analytical solution obtainable with a single (generalized) eigenvalue\ndecomposition. Finally, corroborating dimensionality reduction tests using both\nsynthetic and real datasets are provided to validate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 00:24:43 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 03:58:12 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 17:42:22 GMT"}, {"version": "v4", "created": "Fri, 30 Nov 2018 01:55:03 GMT"}, {"version": "v5", "created": "Tue, 4 Dec 2018 20:26:48 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Chen", "Jia", ""], ["Wang", "Gang", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1805.05510", "submitter": "Wenbin Li", "authors": "Wenbin Li, Jing Huo, Yinghuan Shi, Yang Gao, Lei Wang and Jiebo Luo", "title": "Online Progressive Deep Metric Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning especially deep metric learning has been widely developed for\nlarge-scale image inputs data. However, in many real-world applications, we can\nonly have access to vectorized inputs data. Moreover, on one hand, well-labeled\ndata is usually limited due to the high annotation cost. On the other hand, the\nreal data is commonly streaming data, which requires to be processed online. In\nthese scenarios, the fashionable deep metric learning is not suitable anymore.\nTo this end, we reconsider the traditional shallow online metric learning and\nnewly develop an online progressive deep metric learning (ODML) framework to\nconstruct a metric-algorithm-based deep network. Specifically, we take an\nonline metric learning algorithm as a metric-algorithm-based layer (i.e.,\nmetric layer), followed by a nonlinear layer, and then stack these layers in a\nfashion similar to deep learning. Different from the shallow online metric\nlearning, which can only learn one metric space (feature transformation), the\nproposed ODML is able to learn multiple hierarchical metric spaces.\nFurthermore, in a progressively and nonlinearly learning way, ODML has a\nstronger learning ability than traditional shallow online metric learning in\nthe case of limited available training data. To make the learning process more\nexplainable and theoretically guaranteed, we also provide theoretical analysis.\nThe proposed ODML enjoys several nice properties and can indeed learn a metric\nprogressively and performs better on the benchmark datasets. Extensive\nexperiments with different settings have been conducted to verify these\nproperties of the proposed ODML.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 01:10:18 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 02:35:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Li", "Wenbin", ""], ["Huo", "Jing", ""], ["Shi", "Yinghuan", ""], ["Gao", "Yang", ""], ["Wang", "Lei", ""], ["Luo", "Jiebo", ""]]}, {"id": "1805.05532", "submitter": "Byeongho Heo", "authors": "Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi", "title": "Knowledge Distillation with Adversarial Samples Supporting Decision\n  Boundary", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works on knowledge distillation have provided ways to transfer\nthe knowledge of a trained network for improving the learning process of a new\none, but finding a good technique for knowledge distillation is still an open\nproblem. In this paper, we provide a new perspective based on a decision\nboundary, which is one of the most important component of a classifier. The\ngeneralization performance of a classifier is closely related to the adequacy\nof its decision boundary, so a good classifier bears a good decision boundary.\nTherefore, transferring information closely related to the decision boundary\ncan be a good attempt for knowledge distillation. To realize this goal, we\nutilize an adversarial attack to discover samples supporting a decision\nboundary. Based on this idea, to transfer more accurate information about the\ndecision boundary, the proposed algorithm trains a student classifier based on\nthe adversarial samples supporting the decision boundary. Experiments show that\nthe proposed method indeed improves knowledge distillation and achieves the\nstate-of-the-arts performance.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 02:42:40 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 05:19:06 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 03:53:54 GMT"}, {"version": "v4", "created": "Fri, 14 Dec 2018 15:20:19 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Heo", "Byeongho", ""], ["Lee", "Minsik", ""], ["Yun", "Sangdoo", ""], ["Choi", "Jin Young", ""]]}, {"id": "1805.05536", "submitter": "Tracy Wan", "authors": "Tracy Wan, Neil Xu", "title": "Advances in Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project combines recent advances in experience replay techniques,\nnamely, Combined Experience Replay (CER), Prioritized Experience Replay (PER),\nand Hindsight Experience Replay (HER). We show the results of combinations of\nthese techniques with DDPG and DQN methods. CER always adds the most recent\nexperience to the batch. PER chooses which experiences should be replayed based\non how beneficial they will be towards learning. HER learns from failure by\nsubstituting the desired goal with the achieved goal and recomputing the reward\nfunction. The effectiveness of combinations of these experience replay\ntechniques is tested in a variety of OpenAI gym environments.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 02:50:35 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Wan", "Tracy", ""], ["Xu", "Neil", ""]]}, {"id": "1805.05579", "submitter": "Sebasti\\'an Basterrech", "authors": "Emmanuel Sam and Sergey Yarushev and Sebasti\\'an Basterrech and Alexey\n  Averkin", "title": "Prediction of Facebook Post Metrics using Machine Learning", "comments": "This is a draft version of a manuscript accepted in the XXI\n  International Conference on Soft Computing and Measurement (SCM'2018), Saint\n  Petersburg, Russia, May 23 - 25, 2018 (http://scm.eltech.ru/. It contains 4\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, we evaluate the performance of three well-known Machine\nLearning techniques for predicting the impact of a post in Facebook. Social\nmedias have a huge influence in the social behaviour. Therefore to develop an\nautomatic model for predicting the impact of posts in social medias can be\nuseful to the society. In this article, we analyze the efficiency for\npredicting the post impact of three popular techniques: Support Vector\nRegression (SVR), Echo State Network (ESN) and Adaptive Network Fuzzy Inject\nSystem (ANFIS). The evaluation was done over a public and well-known benchmark\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 06:11:55 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Sam", "Emmanuel", ""], ["Yarushev", "Sergey", ""], ["Basterrech", "Sebasti\u00e1n", ""], ["Averkin", "Alexey", ""]]}, {"id": "1805.05703", "submitter": "Vincent Moens", "authors": "Vincent Moens", "title": "The Hierarchical Adaptive Forgetting Variational Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in Machine Learning and statistics consists in detecting\nwhether the current sample in a stream of data belongs to the same distribution\nas previous ones, is an isolated outlier or inaugurates a new distribution of\ndata. We present a hierarchical Bayesian algorithm that aims at learning a\ntime-specific approximate posterior distribution of the parameters describing\nthe distribution of the data observed. We derive the update equations of the\nvariational parameters of the approximate posterior at each time step for\nmodels from the exponential family, and show that these updates find\ninteresting correspondents in Reinforcement Learning (RL). In this perspective,\nour model can be seen as a hierarchical RL algorithm that learns a posterior\ndistribution according to a certain stability confidence that is, in turn,\nlearned according to its own stability confidence. Finally, we show some\napplications of our generic model, first in a RL context, next with an adaptive\nBayesian Autoregressive model, and finally in the context of Stochastic\nGradient Descent optimization.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 10:57:06 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Moens", "Vincent", ""]]}, {"id": "1805.05751", "submitter": "Leonard Adolphs", "authors": "Leonard Adolphs and Hadi Daneshmand and Aurelien Lucchi and Thomas\n  Hofmann", "title": "Local Saddle Point Optimization: A Curvature Exploitation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based optimization methods are the most popular choice for finding\nlocal optima for classical minimization and saddle point problems. Here, we\nhighlight a systemic issue of gradient dynamics that arise for saddle point\nproblems, namely the presence of undesired stable stationary points that are no\nlocal optima. We propose a novel optimization approach that exploits curvature\ninformation in order to escape from these undesired stationary points. We prove\nthat different optimization methods, including gradient method and Adagrad,\nequipped with curvature exploitation can escape non-optimal stationary points.\nWe also provide empirical results on common saddle point problems which confirm\nthe advantage of using curvature exploitation.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 13:22:45 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 19:17:35 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 12:58:52 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Adolphs", "Leonard", ""], ["Daneshmand", "Hadi", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1805.05769", "submitter": "Ariel Rosenfeld", "authors": "Ariel Rosenfeld, Moshe Cohen, Matthew E. Taylor, Sarit Kraus", "title": "Leveraging human knowledge in tabular reinforcement learning: A study of\n  human subjects", "comments": "To appear in the Knowledge Engineering Review (KER) journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) can be extremely effective in solving complex,\nreal-world problems. However, injecting human knowledge into an RL agent may\nrequire extensive effort and expertise on the human designer's part. To date,\nhuman factors are generally not considered in the development and evaluation of\npossible RL approaches. In this article, we set out to investigate how\ndifferent methods for injecting human knowledge are applied, in practice, by\nhuman designers of varying levels of knowledge and skill. We perform the first\nempirical evaluation of several methods, including a newly proposed method\nnamed SASS which is based on the notion of similarities in the agent's\nstate-action space. Through this human study, consisting of 51 human\nparticipants, we shed new light on the human factors that play a key role in\nRL. We find that the classical reward shaping technique seems to be the most\nnatural method for most designers, both expert and non-expert, to speed up RL.\nHowever, we further find that our proposed method SASS can be effectively and\nefficiently combined with reward shaping, and provides a beneficial alternative\nto using only a single speedup method with minimal human designer effort\noverhead.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 13:51:31 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Rosenfeld", "Ariel", ""], ["Cohen", "Moshe", ""], ["Taylor", "Matthew E.", ""], ["Kraus", "Sarit", ""]]}, {"id": "1805.05773", "submitter": "Vikram Mullachery", "authors": "Vikram Mullachery, Samarth Tiwari", "title": "Online Bandit Linear Optimization: A Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces the concepts around Online Bandit Linear Optimization\nand explores an efficient setup called SCRiBLe (Self-Concordant Regularization\nin Bandit Learning) created by Abernethy et. al.\\cite{abernethy}. The SCRiBLe\nsetup and algorithm yield a $O(\\sqrt{T})$ regret bound and polynomial run time\ncomplexity bound on the dimension of the input space. In this article we build\nup to the bandit linear optimization case and study SCRiBLe.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 18:12:19 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Mullachery", "Vikram", ""], ["Tiwari", "Samarth", ""]]}, {"id": "1805.05781", "submitter": "Dongrui Wu", "authors": "Dongrui Wu", "title": "Active Semi-supervised Transfer Learning (ASTL) for Offline BCI\n  Calibration", "comments": "IEEE Int'l. Conf. on Systems, Man and Cybernetics, Banff, Canada,\n  2017. arXiv admin note: substantial text overlap with arXiv:1702.02897", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-trial classification of event-related potentials in\nelectroencephalogram (EEG) signals is a very important paradigm of\nbrain-computer interface (BCI). Because of individual differences, usually some\nsubject-specific calibration data are required to tailor the classifier for\neach subject. Transfer learning has been extensively used to reduce such\ncalibration data requirement, by making use of auxiliary data from\nsimilar/relevant subjects/tasks. However, all previous research assumes that\nall auxiliary data have been labeled. This paper considers a more general\nscenario, in which part of the auxiliary data could be unlabeled. We propose\nactive semi-supervised transfer learning (ASTL) for offline BCI calibration,\nwhich integrates active learning, semi-supervised learning, and transfer\nlearning. Using a visual evoked potential oddball task and three different EEG\nheadsets, we demonstrate that ASTL can achieve consistently good performance\nacross subjects and headsets, and it outperforms some state-of-the-art\napproaches in the literature.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 15:27:23 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Wu", "Dongrui", ""]]}, {"id": "1805.05809", "submitter": "Hyun Oh Song", "authors": "Yeonwoo Jeong, Hyun Oh Song", "title": "Efficient end-to-end learning for quantizable representations", "comments": "Accepted and to appear at ICML 2018. Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding representation learning via neural networks is at the core\nfoundation of modern similarity based search. While much effort has been put in\ndeveloping algorithms for learning binary hamming code representations for\nsearch efficiency, this still requires a linear scan of the entire dataset per\neach query and trades off the search accuracy through binarization. To this\nend, we consider the problem of directly learning a quantizable embedding\nrepresentation and the sparse binary hash code end-to-end which can be used to\nconstruct an efficient hash table not only providing significant search\nreduction in the number of data but also achieving the state of the art search\naccuracy outperforming previous state of the art deep metric learning methods.\nWe also show that finding the optimal sparse binary hash code in a mini-batch\ncan be computed exactly in polynomial time by solving a minimum cost flow\nproblem. Our results on Cifar-100 and on ImageNet datasets show the state of\nthe art search accuracy in precision@k and NMI metrics while providing up to\n98X and 478X search speedup respectively over exhaustive linear search. The\nsource code is available at\nhttps://github.com/maestrojeong/Deep-Hash-Table-ICML18\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 14:32:31 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 01:22:14 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 03:11:59 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Jeong", "Yeonwoo", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1805.05814", "submitter": "Michael Blot", "authors": "Michael Blot, Thomas Robert, Nicolas Thome, Matthieu Cord", "title": "SHADE: Information-Based Regularization for Deep Learning", "comments": "IEEE International Conference on Image Processing (ICIP) 2018. arXiv\n  admin note: substantial text overlap with arXiv:1804.10988", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is a big issue for training deep neural networks. In this\npaper, we propose a new information-theory-based regularization scheme named\nSHADE for SHAnnon DEcay. The originality of the approach is to define a prior\nbased on conditional entropy, which explicitly decouples the learning of\ninvariant representations in the regularizer and the learning of correlations\nbetween inputs and labels in the data fitting term. Our second contribution is\nto derive a stochastic version of the regularizer compatible with deep\nlearning, resulting in a tractable training scheme. We empirically validate the\nefficiency of our approach to improve classification performances compared to\nstandard regularization schemes on several standard architectures.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 14:21:23 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Blot", "Michael", ""], ["Robert", "Thomas", ""], ["Thome", "Nicolas", ""], ["Cord", "Matthieu", ""]]}, {"id": "1805.05827", "submitter": "Oleksii Abramenko", "authors": "Oleksii Abramenko and Alexander Jung", "title": "Graph Signal Sampling via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the problem of sampling and recovering clustered graph signal as\na multi-armed bandit (MAB) problem. This formulation lends naturally to\nlearning sampling strategies using the well-known gradient MAB algorithm. In\nparticular, the sampling strategy is represented as a probability distribution\nover the individual arms of the MAB and optimized using gradient ascent. Some\nillustrative numerical experiments indicate that the sampling strategies based\non the gradient MAB algorithm outperform existing sampling methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 14:46:45 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Abramenko", "Oleksii", ""], ["Jung", "Alexander", ""]]}, {"id": "1805.05838", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Seong Joon Oh, Yang Zhang, Bernt Schiele, Mario\n  Fritz", "title": "Gradient-Leaks: Understanding and Controlling Deanonymization in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated Learning (FL) systems are gaining popularity as a solution to\ntraining Machine Learning (ML) models from large-scale user data collected on\npersonal devices (e.g., smartphones) without their raw data leaving the device.\nAt the core of FL is a network of anonymous user devices sharing training\ninformation (model parameter updates) computed locally on personal data.\nHowever, the type and degree to which user-specific information is encoded in\nthe model updates is poorly understood. In this paper, we identify model\nupdates encode subtle variations in which users capture and generate data. The\nvariations provide a strong statistical signal, allowing an adversary to\neffectively deanonymize participating devices using a limited set of auxiliary\ndata. We analyze resulting deanonymization attacks on diverse tasks on\nreal-world (anonymized) user-generated data across a range of closed- and\nopen-world scenarios. We study various strategies to mitigate the risks of\ndeanonymization. As random perturbation methods do not offer convincing\noperating points, we propose data-augmentation strategies which introduces\nadversarial biases in device data and thereby, offer substantial protection\nagainst deanonymization threats with little effect on utility.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 15:12:45 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 12:02:07 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 15:56:36 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Oh", "Seong Joon", ""], ["Zhang", "Yang", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1805.05935", "submitter": "Daniel R. Jiang", "authors": "Daniel R. Jiang, Emmanuel Ekwedike, Han Liu", "title": "Feedback-Based Tree Search for Reinforcement Learning", "comments": "19 pages, to be presented at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes of Monte-Carlo tree search (MCTS) in a number of\nartificial intelligence (AI) application domains, we propose a model-based\nreinforcement learning (RL) technique that iteratively applies MCTS on batches\nof small, finite-horizon versions of the original infinite-horizon Markov\ndecision process. The terminal condition of the finite-horizon problems, or the\nleaf-node evaluator of the decision tree generated by MCTS, is specified using\na combination of an estimated value function and an estimated policy function.\nThe recommendations generated by the MCTS procedure are then provided as\nfeedback in order to refine, through classification and regression, the\nleaf-node evaluator for the next iteration. We provide the first sample\ncomplexity bounds for a tree search-based RL algorithm. In addition, we show\nthat a deep neural network implementation of the technique can create a\ncompetitive AI agent for the popular multi-player online battle arena (MOBA)\ngame King of Glory.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 17:53:58 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Jiang", "Daniel R.", ""], ["Ekwedike", "Emmanuel", ""], ["Liu", "Han", ""]]}, {"id": "1805.06061", "submitter": "Roy Schwartz", "authors": "Roy Schwartz, Sam Thomson, and Noah A. Smith", "title": "SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines", "comments": "ACL 2018, 12 pages. Code available at\n  https://github.com/Noahs-ARK/soft_patterns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent and convolutional neural networks comprise two distinct families of\nmodels that have proven to be useful for encoding natural language utterances.\nIn this paper we present SoPa, a new model that aims to bridge these two\napproaches. SoPa combines neural representation learning with weighted\nfinite-state automata (WFSAs) to learn a soft version of traditional surface\npatterns. We show that SoPa is an extension of a one-layer CNN, and that such\nCNNs are equivalent to a restricted version of SoPa, and accordingly, to a\nrestricted form of WFSA. Empirically, on three text classification tasks, SoPa\nis comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline,\nand is particularly useful in small data settings.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 23:03:01 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Schwartz", "Roy", ""], ["Thomson", "Sam", ""], ["Smith", "Noah A.", ""]]}, {"id": "1805.06095", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Yanning Shen, and Georgios B. Giannakis", "title": "Semi-Blind Inference of Topologies and Dynamical Processes over Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2903025", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network science provides valuable insights across numerous disciplines\nincluding sociology, biology, neuroscience and engineering. A task of major\npractical importance in these application domains is inferring the network\nstructure from noisy observations at a subset of nodes. Available methods for\ntopology inference typically assume that the process over the network is\nobserved at all nodes. However, application-specific constraints may prevent\nacquiring network-wide observations. Alleviating the limited flexibility of\nexisting approaches, this work advocates structural models for graph processes\nand develops novel algorithms for joint inference of the network topology and\nprocesses from partial nodal observations. Structural equation models (SEMs)\nand structural vector autoregressive models (SVARMs) have well-documented\nmerits in identifying even directed topologies of complex graphs; while SEMs\ncapture contemporaneous causal dependencies among nodes, SVARMs further account\nfor time-lagged influences. This paper develops algorithms that iterate between\ninferring directed graphs that \"best\" fit the data, and estimating the network\nprocesses at reduced computational complexity by leveraging tools related to\nKalman smoothing. To further accommodate delay-sensitive applications, an\nonline joint inference approach is put forth that even tracks time-evolving\ntopologies. Furthermore, conditions for identifying the network topology given\npartial observations are specified. It is proved that the required number of\nobservations for unique identification reduces significantly when the network\nstructure is sparse. Numerical tests with synthetic as well as real datasets\ncorroborate the effectiveness of the novel approach.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 02:06:53 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Shen", "Yanning", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1805.06126", "submitter": "Igor Halperin", "authors": "Igor Halperin and Ilya Feldshteyn", "title": "Market Self-Learning of Signals, Impact and Optimal Trading: Invisible\n  Hand Inference with Free Energy", "comments": "56 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.LG nlin.AO q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple model of a non-equilibrium self-organizing market where\nasset prices are partially driven by investment decisions of a bounded-rational\nagent. The agent acts in a stochastic market environment driven by various\nexogenous \"alpha\" signals, agent's own actions (via market impact), and noise.\nUnlike traditional agent-based models, our agent aggregates all traders in the\nmarket, rather than being a representative agent. Therefore, it can be\nidentified with a bounded-rational component of the market itself, providing a\nparticular implementation of an Invisible Hand market mechanism. In such\nsetting, market dynamics are modeled as a fictitious self-play of such\nbounded-rational market-agent in its adversarial stochastic environment. As\nrewards obtained by such self-playing market agent are not observed from market\ndata, we formulate and solve a simple model of such market dynamics based on a\nneuroscience-inspired Bounded Rational Information Theoretic Inverse\nReinforcement Learning (BRIT-IRL). This results in effective asset price\ndynamics with a non-linear mean reversion - which in our model is generated\ndynamically, rather than being postulated. We argue that our model can be used\nin a similar way to the Black-Litterman model. In particular, it represents, in\na simple modeling framework, market views of common predictive signals, market\nimpacts and implied optimal dynamic portfolio allocations, and can be used to\nassess values of private signals. Moreover, it allows one to quantify a\n\"market-implied\" optimal investment strategy, along with a measure of market\nrationality. Our approach is numerically light, and can be implemented using\nstandard off-the-shelf software such as TensorFlow.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 04:37:01 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Halperin", "Igor", ""], ["Feldshteyn", "Ilya", ""]]}, {"id": "1805.06137", "submitter": "Li Shen", "authors": "Li Shen, Peng Sun, Yitong Wang, Wei Liu, Tong Zhang", "title": "An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal\n  Extra-Gradient Method", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithmic framework of Variable Metric Over-Relaxed\nHybrid Proximal Extra-gradient (VMOR-HPE) method with a global convergence\nguarantee for the maximal monotone operator inclusion problem. Its iteration\ncomplexities and local linear convergence rate are provided, which\ntheoretically demonstrate that a large over-relaxed step-size contributes to\naccelerating the proposed VMOR-HPE as a byproduct. Specifically, we find that a\nlarge class of primal and primal-dual operator splitting algorithms are all\nspecial cases of VMOR-HPE. Hence, the proposed framework offers a new insight\ninto these operator splitting algorithms. In addition, we apply VMOR-HPE to the\nKarush-Kuhn-Tucker (KKT) generalized equation of linear equality constrained\nmulti-block composite convex optimization, yielding a new algorithm, namely\nnonsymmetric Proximal Alternating Direction Method of Multipliers with a\npreconditioned Extra-gradient step in which the preconditioned metric is\ngenerated by a blockwise Barzilai-Borwein line search technique (PADMM-EBB). We\nalso establish iteration complexities of PADMM-EBB in terms of the KKT\nresidual. Finally, we apply PADMM-EBB to handle the nonnegative dual graph\nregularized low-rank representation problem. Promising results on synthetic and\nreal datasets corroborate the efficacy of PADMM-EBB.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 05:38:37 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 03:51:22 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Shen", "Li", ""], ["Sun", "Peng", ""], ["Wang", "Yitong", ""], ["Liu", "Wei", ""], ["Zhang", "Tong", ""]]}, {"id": "1805.06146", "submitter": "Xianfu Chen", "authors": "Xianfu Chen, Honggang Zhang, Celimuge Wu, Shiwen Mao, Yusheng Ji,\n  Mehdi Bennis", "title": "Optimized Computation Offloading Performance in Virtual Edge Computing\n  Systems via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the quality of computation experience for mobile devices,\nmobile-edge computing (MEC) is a promising paradigm by providing computing\ncapabilities in close proximity within a sliced radio access network (RAN),\nwhich supports both traditional communication and MEC services. Nevertheless,\nthe design of computation offloading policies for a virtual MEC system remains\nchallenging. Specifically, whether to execute a computation task at the mobile\ndevice or to offload it for MEC server execution should adapt to the\ntime-varying network dynamics. In this paper, we consider MEC for a\nrepresentative mobile user in an ultra-dense sliced RAN, where multiple base\nstations (BSs) are available to be selected for computation offloading. The\nproblem of solving an optimal computation offloading policy is modelled as a\nMarkov decision process, where our objective is to maximize the long-term\nutility performance whereby an offloading decision is made based on the task\nqueue state, the energy queue state as well as the channel qualities between MU\nand BSs. To break the curse of high dimensionality in state space, we first\npropose a double deep Q-network (DQN) based strategic computation offloading\nalgorithm to learn the optimal policy without knowing a priori knowledge of\nnetwork dynamics. Then motivated by the additive structure of the utility\nfunction, a Q-function decomposition technique is combined with the double DQN,\nwhich leads to novel learning algorithm for the solving of stochastic\ncomputation offloading. Numerical experiments show that our proposed learning\nalgorithms achieve a significant improvement in computation offloading\nperformance compared with the baseline policies.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:21:02 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Chen", "Xianfu", ""], ["Zhang", "Honggang", ""], ["Wu", "Celimuge", ""], ["Mao", "Shiwen", ""], ["Ji", "Yusheng", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1805.06150", "submitter": "Aleksandra Faust", "authors": "Pararth Shah, Marek Fiser, Aleksandra Faust, J. Chase Kew, and Dilek\n  Hakkani-Tur", "title": "FollowNet: Robot Navigation by Following Natural Language Directions\n  with Deep Reinforcement Learning", "comments": "7 pages, 8 figures", "journal-ref": "Third Workshop in Machine Learning in the Planning and Control of\n  Robot Motion at ICRA, 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and following directions provided by humans can enable robots\nto navigate effectively in unknown situations. We present FollowNet, an\nend-to-end differentiable neural architecture for learning multi-modal\nnavigation policies. FollowNet maps natural language instructions as well as\nvisual and depth inputs to locomotion primitives. FollowNet processes\ninstructions using an attention mechanism conditioned on its visual and depth\ninput to focus on the relevant parts of the command while performing the\nnavigation task. Deep reinforcement learning (RL) a sparse reward learns\nsimultaneously the state representation, the attention function, and control\npolicies. We evaluate our agent on a dataset of complex natural language\ndirections that guide the agent through a rich and realistic dataset of\nsimulated homes. We show that the FollowNet agent learns to execute previously\nunseen instructions described with a similar vocabulary, and successfully\nnavigates along paths not encountered during training. The agent shows 30%\nimprovement over a baseline model without the attention mechanism, with 52%\nsuccess rate at novel instructions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:29:18 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Shah", "Pararth", ""], ["Fiser", "Marek", ""], ["Faust", "Aleksandra", ""], ["Kew", "J. Chase", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1805.06201", "submitter": "Sosuke Kobayashi", "authors": "Sosuke Kobayashi", "title": "Contextual Augmentation: Data Augmentation by Words with Paradigmatic\n  Relations", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data augmentation for labeled sentences called contextual\naugmentation. We assume an invariance that sentences are natural even if the\nwords in the sentences are replaced with other words with paradigmatic\nrelations. We stochastically replace words with other words that are predicted\nby a bi-directional language model at the word positions. Words predicted\naccording to a context are numerous but appropriate for the augmentation of the\noriginal words. Furthermore, we retrofit a language model with a\nlabel-conditional architecture, which allows the model to augment sentences\nwithout breaking the label-compatibility. Through the experiments for six\nvarious different text classification tasks, we demonstrate that the proposed\nmethod improves classifiers based on the convolutional or recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 09:10:21 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Kobayashi", "Sosuke", ""]]}, {"id": "1805.06230", "submitter": "Jacob Kauffmann", "authors": "Jacob Kauffmann, Klaus-Robert M\\\"uller and Gr\\'egoire Montavon", "title": "Towards Explaining Anomalies: A Deep Taylor Decomposition of One-Class\n  Models", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2020.107198", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common machine learning task is to discriminate between normal and\nanomalous data points. In practice, it is not always sufficient to reach high\naccuracy at this task, one also would like to understand why a given data point\nhas been predicted in a certain way. We present a new principled approach for\none-class SVMs that decomposes outlier predictions in terms of input variables.\nThe method first recomposes the one-class model as a neural network with\ndistance functions and min-pooling, and then performs a deep Taylor\ndecomposition (DTD) of the model output. The proposed One-Class DTD is\napplicable to a number of common distance-based SVM kernels and is able to\nreliably explain a wide set of data anomalies. Furthermore, it outperforms\nbaselines such as sensitivity analysis, nearest neighbor, or simple edge\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:20:51 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kauffmann", "Jacob", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Montavon", "Gr\u00e9goire", ""]]}, {"id": "1805.06258", "submitter": "Magda Gregorova", "authors": "Magda Gregorov\\'a, Alexandros Kalousis, St\\'ephane Marchand-Maillet", "title": "Structured nonlinear variable selection", "comments": "Accepted to UAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate structured sparsity methods for variable selection in\nregression problems where the target depends nonlinearly on the inputs. We\nfocus on general nonlinear functions not limiting a priori the function space\nto additive models. We propose two new regularizers based on partial\nderivatives as nonlinear equivalents of group lasso and elastic net. We\nformulate the problem within the framework of learning in reproducing kernel\nHilbert spaces and show how the variational problem can be reformulated into a\nmore practical finite dimensional equivalent. We develop a new algorithm\nderived from the ADMM principles that relies solely on closed forms of the\nproximal operators. We explore the empirical properties of our new algorithm\nfor Nonlinear Variable Selection based on Derivatives (NVSD) on a set of\nexperiments and confirm favourable properties of our structured-sparsity models\nand the algorithm in terms of both prediction and variable selection accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 11:57:31 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Gregorov\u00e1", "Magda", ""], ["Kalousis", "Alexandros", ""], ["Marchand-Maillet", "St\u00e9phane", ""]]}, {"id": "1805.06297", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "A robust self-learning method for fully unsupervised cross-lingual\n  mappings of word embeddings", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has managed to learn cross-lingual word embeddings without\nparallel data by mapping monolingual embeddings to a shared space through\nadversarial training. However, their evaluation has focused on favorable\nconditions, using comparable corpora or closely-related languages, and we show\nthat they often fail in more realistic scenarios. This work proposes an\nalternative approach based on a fully unsupervised initialization that\nexplicitly exploits the structural similarity of the embeddings, and a robust\nself-learning algorithm that iteratively improves this solution. Our method\nsucceeds in all tested scenarios and obtains the best published results in\nstandard datasets, even surpassing previous supervised systems. Our\nimplementation is released as an open source project at\nhttps://github.com/artetxem/vecmap\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 13:23:48 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 17:21:53 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1805.06299", "submitter": "Daniele Grattarola", "authors": "Daniele Grattarola, Daniele Zambon, Cesare Alippi, Lorenzo Livi", "title": "Change Detection in Graph Streams by Learning Graph Embeddings on\n  Constant-Curvature Manifolds", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2019.2927301", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The space of graphs is often characterised by a non-trivial geometry, which\ncomplicates learning and inference in practical applications. A common approach\nis to use embedding techniques to represent graphs as points in a conventional\nEuclidean space, but non-Euclidean spaces have often been shown to be better\nsuited for embedding graphs. Among these, constant-curvature Riemannian\nmanifolds (CCMs) offer embedding spaces suitable for studying the statistical\nproperties of a graph distribution, as they provide ways to easily compute\nmetric geodesic distances. In this paper, we focus on the problem of detecting\nchanges in stationarity in a stream of attributed graphs. To this end, we\nintroduce a novel change detection framework based on neural networks and CCMs,\nthat takes into account the non-Euclidean nature of graphs. Our contribution in\nthis work is twofold. First, via a novel approach based on adversarial\nlearning, we compute graph embeddings by training an autoencoder to represent\ngraphs on CCMs. Second, we introduce two novel change detection tests operating\non CCMs. We perform experiments on synthetic data, as well as two real-world\napplication scenarios: the detection of epileptic seizures using functional\nconnectivity brain networks, and the detection of hostility between two\nsubjects, using human skeletal graphs. Results show that the proposed methods\nare able to detect even small changes in a graph-generating process,\nconsistently outperforming approaches based on Euclidean embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 13:25:56 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 14:16:07 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 17:14:17 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Grattarola", "Daniele", ""], ["Zambon", "Daniele", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1805.06334", "submitter": "Lukas Liebel", "authors": "Lukas Liebel and Marco K\\\"orner", "title": "Auxiliary Tasks in Multi-task Learning", "comments": "fixed minor typesetting issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task convolutional neural networks (CNNs) have shown impressive results\nfor certain combinations of tasks, such as single-image depth estimation (SIDE)\nand semantic segmentation. This is achieved by pushing the network towards\nlearning a robust representation that generalizes well to different atomic\ntasks. We extend this concept by adding auxiliary tasks, which are of minor\nrelevance for the application, to the set of learned tasks. As a kind of\nadditional regularization, they are expected to boost the performance of the\nultimately desired main tasks. To study the proposed approach, we picked\nvision-based road scene understanding (RSU) as an exemplary application. Since\nmulti-task learning requires specialized datasets, particularly when using\nextensive sets of tasks, we provide a multi-modal dataset for multi-task RSU,\ncalled synMT. More than 2.5 $\\cdot$ 10^5 synthetic images, annotated with 21\ndifferent labels, were acquired from the video game Grand Theft Auto V (GTA V).\nOur proposed deep multi-task CNN architecture was trained on various\ncombination of tasks using synMT. The experiments confirmed that auxiliary\ntasks can indeed boost network performance, both in terms of final results and\ntraining time.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 13:59:20 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 16:12:16 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Liebel", "Lukas", ""], ["K\u00f6rner", "Marco", ""]]}, {"id": "1805.06350", "submitter": "Timothy O'Shea", "authors": "Timothy J. O'Shea, Tamoghna Roy, Nathan West", "title": "Approximating the Void: Learning Stochastic Channel Models from\n  Observation with Variational Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel modeling is a critical topic when considering designing, learning, or\nevaluating the performance of any communications system. Most prior work in\ndesigning or learning new modulation schemes has focused on using highly\nsimplified analytic channel models such as additive white Gaussian noise\n(AWGN), Rayleigh fading channels or similar. Recently, we proposed the usage of\na generative adversarial networks (GANs) to jointly approximate a wireless\nchannel response model (e.g. from real black box measurements) and optimize for\nan efficient modulation scheme over it using machine learning. This approach\nworked to some degree, but was unable to produce accurate probability\ndistribution functions (PDFs) representing the stochastic channel response. In\nthis paper, we focus specifically on the problem of accurately learning a\nchannel PDF using a variational GAN, introducing an architecture and loss\nfunction which can accurately capture stochastic behavior. We illustrate where\nour prior method failed and share results capturing the performance of such as\nsystem over a range of realistic channel distributions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 14:43:33 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 19:26:49 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["O'Shea", "Timothy J.", ""], ["Roy", "Tamoghna", ""], ["West", "Nathan", ""]]}, {"id": "1805.06370", "submitter": "Jonathan Schwarz", "authors": "Jonathan Schwarz and Jelena Luketina and Wojciech M. Czarnecki and\n  Agnieszka Grabska-Barwinska and Yee Whye Teh and Razvan Pascanu and Raia\n  Hadsell", "title": "Progress & Compress: A scalable framework for continual learning", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a conceptually simple and scalable framework for continual\nlearning domains where tasks are learned sequentially. Our method is constant\nin the number of parameters and is designed to preserve performance on\npreviously encountered tasks while accelerating learning progress on subsequent\nproblems. This is achieved by training a network with two components: A\nknowledge base, capable of solving previously encountered problems, which is\nconnected to an active column that is employed to efficiently learn the current\ntask. After learning a new task, the active column is distilled into the\nknowledge base, taking care to protect any previously acquired skills. This\ncycle of active learning (progression) followed by consolidation (compression)\nrequires no architecture growth, no access to or storing of previous data or\ntasks, and no task-specific parameters. We demonstrate the progress & compress\napproach on sequential classification of handwritten alphabets as well as two\nreinforcement learning domains: Atari games and 3D maze navigation.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 15:32:28 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 15:56:13 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Schwarz", "Jonathan", ""], ["Luketina", "Jelena", ""], ["Czarnecki", "Wojciech M.", ""], ["Grabska-Barwinska", "Agnieszka", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""], ["Hadsell", "Raia", ""]]}, {"id": "1805.06386", "submitter": "Ken Nakanishi", "authors": "Ken Nakanishi, Shin-ichi Maeda, Takeru Miyato, Daisuke Okanohara", "title": "Neural Multi-scale Image Compression", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a new lossy image compression method that utilizes the\nmulti-scale features of natural images. Our model consists of two networks:\nmulti-scale lossy autoencoder and parallel multi-scale lossless coder. The\nmulti-scale lossy autoencoder extracts the multi-scale image features to\nquantized variables and the parallel multi-scale lossless coder enables rapid\nand accurate lossless coding of the quantized variables via encoding/decoding\nthe variables in parallel. Our proposed model achieves comparable performance\nto the state-of-the-art model on Kodak and RAISE-1k dataset images, and it\nencodes a PNG image of size $768 \\times 512$ in 70 ms with a single GPU and a\nsingle CPU process and decodes it into a high-fidelity image in approximately\n200 ms.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 16:00:01 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Nakanishi", "Ken", ""], ["Maeda", "Shin-ichi", ""], ["Miyato", "Takeru", ""], ["Okanohara", "Daisuke", ""]]}, {"id": "1805.06431", "submitter": "Sungjoon Choi", "authors": "Sungjoon Choi, Sanghoon Hong, Kyungjae Lee, Sungbin Lim", "title": "Task Agnostic Robust Learning on Corrupt Outputs by Correlation-Guided\n  Mixture Density Networks", "comments": "Accepted to Computer Vision and Pattern Recognition (CVPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on weakly supervised learning with noisy training\ndata for both classification and regression problems.We assume that the\ntraining outputs are collected from a mixture of a target and correlated noise\ndistributions.Our proposed method simultaneously estimates the target\ndistribution and the quality of each data which is defined as the correlation\nbetween the target and data generating distributions.The cornerstone of the\nproposed method is a Cholesky Block that enables modeling dependencies among\nmixture distributions in a differentiable manner where we maintain the\ndistribution over the network weights.We first provide illustrative examples in\nboth regression and classification tasks to show the effectiveness of the\nproposed method.Then, the proposed method is extensively evaluated in a number\nof experiments where we show that it constantly shows comparable or superior\nperformances compared to existing baseline methods in the handling of noisy\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 17:14:33 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 19:23:49 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 02:03:04 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 03:35:44 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Choi", "Sungjoon", ""], ["Hong", "Sanghoon", ""], ["Lee", "Kyungjae", ""], ["Lim", "Sungbin", ""]]}, {"id": "1805.06439", "submitter": "Matt Bonakdarpour", "authors": "Matt Bonakdarpour, Sabyasachi Chatterjee, Rina Foygel Barber, John\n  Lafferty", "title": "Prediction Rule Reshaping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two methods are proposed for high-dimensional shape-constrained regression\nand classification. These methods reshape pre-trained prediction rules to\nsatisfy shape constraints like monotonicity and convexity. The first method can\nbe applied to any pre-trained prediction rule, while the second method deals\nspecifically with random forests. In both cases, efficient algorithms are\ndeveloped for computing the estimators, and experiments are performed to\ndemonstrate their performance on four datasets. We find that reshaping methods\nenforce shape constraints without compromising predictive accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 17:36:47 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Bonakdarpour", "Matt", ""], ["Chatterjee", "Sabyasachi", ""], ["Barber", "Rina Foygel", ""], ["Lafferty", "John", ""]]}, {"id": "1805.06440", "submitter": "Ira Shavitt", "authors": "Ira Shavitt, Eran Segal", "title": "Regularization Learning Networks: Deep Learning for Tabular Datasets", "comments": "Accepted to the 32nd Conference on Neural Information Processing\n  Systems (NIPS 2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance, Deep Neural Networks (DNNs) typically\nunderperform Gradient Boosting Trees (GBTs) on many tabular-dataset learning\ntasks. We propose that applying a different regularization coefficient to each\nweight might boost the performance of DNNs by allowing them to make more use of\nthe more relevant inputs. However, this will lead to an intractable number of\nhyperparameters. Here, we introduce Regularization Learning Networks (RLNs),\nwhich overcome this challenge by introducing an efficient hyperparameter tuning\nscheme which minimizes a new Counterfactual Loss. Our results show that RLNs\nsignificantly improve DNNs on tabular datasets, and achieve comparable results\nto GBTs, with the best performance achieved with an ensemble that combines GBTs\nand RLNs. RLNs produce extremely sparse networks, eliminating up to 99.8% of\nthe network edges and 82% of the input features, thus providing more\ninterpretable models and reveal the importance that the network assigns to\ndifferent inputs. RLNs could efficiently learn a single network in datasets\nthat comprise both tabular and unstructured data, such as in the setting of\nmedical imaging accompanied by electronic health records. An open source\nimplementation of RLN can be found at\nhttps://github.com/irashavitt/regularization_learning_networks.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 17:43:20 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2018 12:26:26 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 19:35:32 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Shavitt", "Ira", ""], ["Segal", "Eran", ""]]}, {"id": "1805.06441", "submitter": "Youssef  Mroueh", "authors": "Youssef Mroueh", "title": "Regularized Finite Dimensional Kernel Sobolev Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show in this note that the Sobolev Discrepancy introduced in Mroueh et al\nin the context of generative adversarial networks, is actually the weighted\nnegative Sobolev norm $||.||_{\\dot{H}^{-1}(\\nu_q)}$, that is known to linearize\nthe Wasserstein $W_2$ distance and plays a fundamental role in the dynamic\nformulation of optimal transport of Benamou and Brenier. Given a Kernel with\nfinite dimensional feature map we show that the Sobolev discrepancy can be\napproximated from finite samples. Assuming this discrepancy is finite, the\nerror depends on the approximation error in the function space induced by the\nfinite dimensional feature space kernel and on a statistical error due to the\nfinite sample approximation.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 17:44:51 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Mroueh", "Youssef", ""]]}, {"id": "1805.06502", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Cezary Kaliszyk, Josef Urban", "title": "First Experiments with Neural Translation of Informal to Formal\n  Mathematics", "comments": "Submission to CICM'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our experiments to train deep neural networks that automatically\ntranslate informalized LaTeX-written Mizar texts into the formal Mizar\nlanguage. To the best of our knowledge, this is the first time when neural\nnetworks have been adopted in the formalization of mathematics. Using Luong et\nal.'s neural machine translation model (NMT), we tested our aligned\ninformal-formal corpora against various hyperparameters and evaluated their\nresults. Our experiments show that our best performing model configurations are\nable to generate correct Mizar statements on 65.73\\% of the inference data,\nwith the union of all models covering 79.17\\%. These results indicate that\nformalization through artificial neural network is a promising approach for\nautomated formalization of mathematics. We present several case studies to\nillustrate our results.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:11:43 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 10:02:22 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Qingxiang", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1805.06523", "submitter": "Samet Oymak", "authors": "Samet Oymak, Mahdi Soltanolkotabi", "title": "End-to-end Learning of a Convolutional Neural Network via Deep Tensor\n  Decomposition", "comments": "29 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of learning the weights of a deep\nconvolutional neural network. We consider a network where convolutions are\ncarried out over non-overlapping patches with a single kernel in each layer. We\ndevelop an algorithm for simultaneously learning all the kernels from the\ntraining data. Our approach dubbed Deep Tensor Decomposition (DeepTD) is based\non a rank-1 tensor decomposition. We theoretically investigate DeepTD under a\nrealizable model for the training data where the inputs are chosen i.i.d. from\na Gaussian distribution and the labels are generated according to planted\nconvolutional kernels. We show that DeepTD is data-efficient and provably works\nas soon as the sample size exceeds the total number of convolutional weights in\nthe network. We carry out a variety of numerical experiments to investigate the\neffectiveness of DeepTD and verify our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 20:53:21 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Oymak", "Samet", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1805.06524", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Hybrid Adaptive Fuzzy Extreme Learning Machine for text classification", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional ELM and its improved versions suffer from the problems of\noutliers or noises due to overfitting and imbalance due to distribution. We\npropose a novel hybrid adaptive fuzzy ELM(HA-FELM), which introduces a fuzzy\nmembership function to the traditional ELM method to deal with the above\nproblems. We define the fuzzy membership function not only basing on the\ndistance between each sample and the center of the class but also the density\namong samples which based on the quantum harmonic oscillator model. The\nproposed fuzzy membership function overcomes the shortcoming of the traditional\nfuzzy membership function and could make itself adjusted according to the\nspecific distribution of different samples adaptively. Experiments show the\nproposed HA-FELM can produce better performance than SVM, ELM, and RELM in text\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:11:27 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06525", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Text classification based on ensemble extreme learning machine", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach based on cost-sensitive ensemble\nweighted extreme learning machine; we call this approach AE1-WELM. We apply\nthis approach to text classification. AE1-WELM is an algorithm including\nbalanced and imbalanced multiclassification for text classification. Weighted\nELM assigning the different weights to the different samples improves the\nclassification accuracy to a certain extent, but weighted ELM considers the\ndifferences between samples in the different categories only and ignores the\ndifferences between samples within the same categories. We measure the\nimportance of the documents by the sample information entropy, and generate\ncost-sensitive matrix and factor based on the document importance, then embed\nthe cost-sensitive weighted ELM into the AdaBoost.M1 framework seamlessly.\nVector space model(VSM) text representation produces the high dimensions and\nsparse features which increase the burden of ELM. To overcome this problem, we\ndevelop a text classification framework combining the word vector and AE1-WELM.\nThe experimental results show that our method provides an accurate, reliable\nand effective solution for text classification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:10:46 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06530", "submitter": "Borja Balle", "authors": "Borja Balle, Yu-Xiang Wang", "title": "Improving the Gaussian Mechanism for Differential Privacy: Analytical\n  Calibration and Optimal Denoising", "comments": "To appear at the 35th International Conference on Machine Learning\n  (ICML), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian mechanism is an essential building block used in multitude of\ndifferentially private data analysis algorithms. In this paper we revisit the\nGaussian mechanism and show that the original analysis has several important\nlimitations. Our analysis reveals that the variance formula for the original\nmechanism is far from tight in the high privacy regime ($\\varepsilon \\to 0$)\nand it cannot be extended to the low privacy regime ($\\varepsilon \\to \\infty$).\nWe address these limitations by developing an optimal Gaussian mechanism whose\nvariance is calibrated directly using the Gaussian cumulative density function\ninstead of a tail bound approximation. We also propose to equip the Gaussian\nmechanism with a post-processing step based on adaptive estimation techniques\nby leveraging that the distribution of the perturbation is known. Our\nexperiments show that analytical calibration removes at least a third of the\nvariance of the noise compared to the classical Gaussian mechanism, and that\ndenoising dramatically improves the accuracy of the Gaussian mechanism in the\nhigh-dimensional regime.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 21:19:40 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 12:57:57 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Balle", "Borja", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1805.06546", "submitter": "Huy Phan", "authors": "Huy Phan, Fernando Andreotti, Navin Cooray, Oliver Y. Ch\\'en, Maarten\n  De Vos", "title": "Joint Classification and Prediction CNN Framework for Automatic Sleep\n  Stage Classification", "comments": "This article has been published in IEEE Transactions on Biomedical\n  Engineering", "journal-ref": null, "doi": "10.1109/TBME.2018.2872652", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly identifying sleep stages is important in diagnosing and treating\nsleep disorders. This work proposes a joint classification-and-prediction\nframework based on CNNs for automatic sleep staging, and, subsequently,\nintroduces a simple yet efficient CNN architecture to power the framework.\nGiven a single input epoch, the novel framework jointly determines its label\n(classification) and its neighboring epochs' labels (prediction) in the\ncontextual output. While the proposed framework is orthogonal to the widely\nadopted classification schemes, which take one or multiple epochs as contextual\ninputs and produce a single classification decision on the target epoch, we\ndemonstrate its advantages in several ways. First, it leverages the dependency\namong consecutive sleep epochs while surpassing the problems experienced with\nthe common classification schemes. Second, even with a single model, the\nframework has the capacity to produce multiple decisions, which are essential\nin obtaining a good performance as in ensemble-of-models methods, with very\nlittle induced computational overhead. Probabilistic aggregation techniques are\nthen proposed to leverage the availability of multiple decisions. We conducted\nexperiments on two public datasets: Sleep-EDF Expanded with 20 subjects, and\nMontreal Archive of Sleep Studies dataset with 200 subjects. The proposed\nframework yields an overall classification accuracy of 82.3% and 83.6%,\nrespectively. We also show that the proposed framework not only is superior to\nthe baselines based on the common classification schemes but also outperforms\nexisting deep-learning approaches. To our knowledge, this is the first work\ngoing beyond the standard single-output classification to consider multitask\nneural networks for automatic sleep staging. This framework provides avenues\nfor further studies of different neural-network architectures for automatic\nsleep staging.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 22:29:15 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 17:57:45 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 01:29:18 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Phan", "Huy", ""], ["Andreotti", "Fernando", ""], ["Cooray", "Navin", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["De Vos", "Maarten", ""]]}, {"id": "1805.06576", "submitter": "Randall Balestriero", "authors": "Randall Balestriero and Richard Baraniuk", "title": "Mad Max: Affine Spline Insights into Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a rigorous bridge between deep networks (DNs) and approximation\ntheory via spline functions and operators. Our key result is that a large class\nof DNs can be written as a composition of max-affine spline operators (MASOs),\nwhich provide a powerful portal through which to view and analyze their inner\nworkings. For instance, conditioned on the input signal, the output of a MASO\nDN can be written as a simple affine transformation of the input. This implies\nthat a DN constructs a set of signal-dependent, class-specific templates\nagainst which the signal is compared via a simple inner product; we explore the\nlinks to the classical theory of optimal classification via matched filters and\nthe effects of data memorization. Going further, we propose a simple penalty\nterm that can be added to the cost function of any DN learning algorithm to\nforce the templates to be orthogonal with each other; this leads to\nsignificantly improved classification performance and reduced overfitting with\nno change to the DN architecture. The spline partition of the input signal\nspace that is implicitly induced by a MASO directly links DNs to the theory of\nvector quantization (VQ) and $K$-means clustering, which opens up new geometric\navenue to study how DNs organize signals in a hierarchical fashion. To validate\nthe utility of the VQ interpretation, we develop and validate a new distance\nmetric for signals and images that quantifies the difference between their VQ\nencodings. (This paper is a significantly expanded version of A Spline Theory\nof Deep Learning from ICML 2018.)\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 02:04:54 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2018 09:45:33 GMT"}, {"version": "v3", "created": "Sat, 21 Jul 2018 11:32:05 GMT"}, {"version": "v4", "created": "Wed, 25 Jul 2018 19:34:14 GMT"}, {"version": "v5", "created": "Sun, 11 Nov 2018 23:01:58 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Balestriero", "Randall", ""], ["Baraniuk", "Richard", ""]]}, {"id": "1805.06591", "submitter": "Rongpeng Li", "authors": "Rongpeng Li, Zhifeng Zhao, Qi Sun, Chi-Lin I, Chenyang Yang, Xianfu\n  Chen, Minjian Zhao, Honggang Zhang", "title": "Deep Reinforcement Learning for Resource Management in Network Slicing", "comments": "The manuscript has been accepted by IEEE Access in Nov. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network slicing is born as an emerging business to operators, by allowing\nthem to sell the customized slices to various tenants at different prices. In\norder to provide better-performing and cost-efficient services, network slicing\ninvolves challenging technical issues and urgently looks forward to intelligent\ninnovations to make the resource management consistent with users' activities\nper slice. In that regard, deep reinforcement learning (DRL), which focuses on\nhow to interact with the environment by trying alternative actions and\nreinforcing the tendency actions producing more rewarding consequences, is\nassumed to be a promising solution. In this paper, after briefly reviewing the\nfundamental concepts of DRL, we investigate the application of DRL in solving\nsome typical resource management for network slicing scenarios, which include\nradio resource slicing and priority-based core network slicing, and demonstrate\nthe advantage of DRL over several competing schemes through extensive\nsimulations. Finally, we also discuss the possible challenges to apply DRL in\nnetwork slicing from a general perspective.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 03:21:53 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 08:11:51 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 02:34:15 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Sun", "Qi", ""], ["I", "Chi-Lin", ""], ["Yang", "Chenyang", ""], ["Chen", "Xianfu", ""], ["Zhao", "Minjian", ""], ["Zhang", "Honggang", ""]]}, {"id": "1805.06595", "submitter": "Kevin He", "authors": "Kevin He, Jian Kang, Hyokyoung Grace Hong, Ji Zhu, Yanming Li, Huazhen\n  Lin, Han Xu and Yi Li", "title": "Covariance-Insured Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern bio-technologies have produced a vast amount of high-throughput data\nwith the number of predictors far greater than the sample size. In order to\nidentify more novel biomarkers and understand biological mechanisms, it is\nvital to detect signals weakly associated with outcomes among\nultrahigh-dimensional predictors. However, existing screening methods, which\ntypically ignore correlation information, are likely to miss these weak\nsignals. By incorporating the inter-feature dependence, we propose a\ncovariance-insured screening methodology to identify predictors that are\njointly informative but only marginally weakly associated with outcomes. The\nvalidity of the method is examined via extensive simulations and real data\nstudies for selecting potential genetic factors related to the onset of cancer.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 03:58:37 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["He", "Kevin", ""], ["Kang", "Jian", ""], ["Hong", "Hyokyoung Grace", ""], ["Zhu", "Ji", ""], ["Li", "Yanming", ""], ["Lin", "Huazhen", ""], ["Xu", "Han", ""], ["Li", "Yi", ""]]}, {"id": "1805.06605", "submitter": "Maya Kabkab", "authors": "Pouya Samangouei, Maya Kabkab, Rama Chellappa", "title": "Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using\n  Generative Models", "comments": "Published as a conference paper at the Sixth International Conference\n  on Learning Representations (ICLR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural network approaches have been widely adopted for\nmachine learning tasks, including classification. However, they were shown to\nbe vulnerable to adversarial perturbations: carefully crafted small\nperturbations can cause misclassification of legitimate images. We propose\nDefense-GAN, a new framework leveraging the expressive capability of generative\nmodels to defend deep neural networks against such attacks. Defense-GAN is\ntrained to model the distribution of unperturbed images. At inference time, it\nfinds a close output to a given image which does not contain the adversarial\nchanges. This output is then fed to the classifier. Our proposed method can be\nused with any classification model and does not modify the classifier structure\nor training procedure. It can also be used as a defense against any attack as\nit does not assume knowledge of the process for generating the adversarial\nexamples. We empirically show that Defense-GAN is consistently effective\nagainst different attack methods and improves on existing defense strategies.\nOur code has been made publicly available at\nhttps://github.com/kabkabm/defensegan\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 05:38:55 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:20:52 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Samangouei", "Pouya", ""], ["Kabkab", "Maya", ""], ["Chellappa", "Rama", ""]]}, {"id": "1805.06619", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "Taxi demand forecasting: A HEDGE based tessellation strategy for\n  improved accuracy", "comments": "Under revision in Special Issue on Knowledge Discovery from Mobility\n  Data for Intelligent Transportation Systems (Transactions on ITS)", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems ( Volume:\n  19 , Issue: 11 , Nov. 2018 )", "doi": "10.1109/TITS.2018.2860925", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in location-based modeling and forecasting lies in identifying\nsuitable spatial and temporal resolutions. In particular, judicious spatial\npartitioning can play a significant role in enhancing the performance of\nlocation-based forecasting models. In this work, we investigate two widely used\ntessellation strategies for partitioning city space, in the context of\nreal-time taxi demand forecasting. Our study compares (i) Geohash tessellation,\nand (ii) Voronoi tessellation, using two distinct taxi demand datasets, over\nmultiple time scales. For the purpose of comparison, we employ classical\ntime-series tools to model the spatio-temporal demand. Our study finds that the\nperformance of each tessellation strategy is highly dependent on the city\ngeography, spatial distribution of the data, and the time of the day, and that\nneither strategy is found to perform optimally across the forecast horizon. We\npropose a hybrid tessellation algorithm that picks the best tessellation\nstrategy at each instant, based on their performance in the recent past. Our\nhybrid algorithm is a non-stationary variant of the well-known HEDGE algorithm\nfor choosing the best advice from multiple experts. We show that the hybrid\ntessellation strategy performs consistently better than either of the two\nstrategies across the data sets considered, at multiple time scales, and with\ndifferent performance metrics. We achieve an average accuracy of above 80% per\nkm^2 for both data sets considered at 60 minute aggregation levels.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 06:59:11 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 05:40:03 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1805.06621", "submitter": "Tom\\'as Angles", "authors": "Tom\\'as Angles and St\\'ephane Mallat", "title": "Generative networks as inverse problems with Scattering transforms", "comments": "International Conference on Learning Representations, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Nets (GANs) and Variational Auto-Encoders (VAEs)\nprovide impressive image generations from Gaussian white noise, but the\nunderlying mathematics are not well understood. We compute deep convolutional\nnetwork generators by inverting a fixed embedding operator. Therefore, they do\nnot require to be optimized with a discriminator or an encoder. The embedding\nis Lipschitz continuous to deformations so that generators transform linear\ninterpolations between input white noise vectors into deformations between\noutput images. This embedding is computed with a wavelet Scattering transform.\nNumerical experiments demonstrate that the resulting Scattering generators have\nsimilar properties as GANs or VAEs, without learning a discriminative network\nor an encoder.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:12:18 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Angles", "Tom\u00e1s", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1805.06627", "submitter": "Luke Vilnis", "authors": "Luke Vilnis, Xiang Li, Shikhar Murty, Andrew McCallum", "title": "Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures", "comments": "ACL 2018 camera-ready version, 14 pages including appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding methods which enforce a partial order or lattice structure over the\nconcept space, such as Order Embeddings (OE) (Vendrov et al., 2016), are a\nnatural way to model transitive relational data (e.g. entailment graphs).\nHowever, OE learns a deterministic knowledge base, limiting expressiveness of\nqueries and the ability to use uncertainty for both prediction and learning\n(e.g. learning from expectations). Probabilistic extensions of OE (Lai and\nHockenmaier, 2017) have provided the ability to somewhat calibrate these\ndenotational probabilities while retaining the consistency and inductive bias\nof ordered models, but lack the ability to model the negative correlations\nfound in real-world knowledge. In this work we show that a broad class of\nmodels that assign probability measures to OE can never capture negative\ncorrelation, which motivates our construction of a novel box lattice and\naccompanying probability measure to capture anticorrelation and even disjoint\nconcepts, while still providing the benefits of probabilistic modeling, such as\nthe ability to perform rich joint and conditional queries over arbitrary sets\nof concepts, and both learning from and predicting calibrated uncertainty. We\nshow improvements over previous approaches in modeling the Flickr and WordNet\nentailment graphs, and investigate the power of the model.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:20:35 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Vilnis", "Luke", ""], ["Li", "Xiang", ""], ["Murty", "Shikhar", ""], ["McCallum", "Andrew", ""]]}, {"id": "1805.06657", "submitter": "Haotian Cui", "authors": "Haotian Cui, Xianggen Liu, Yanhao Huang", "title": "Deep-learning Based Modeling of Fault Detachment Stability for Power\n  Grid", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The project intends to model the stability of power system with a deep\nlearning algorithm to the problem, aiming to delay the removal of the fault.\nThe so-called \"fail-delay cut-off\" refers to the occurrence of N-1 backup\nprotection action on the backbone network of the system, resulting in longer\ntime for the removal of the fault. In practice, through the analysis and\ncalculation of a large number of online data, we have found that the N-1\nfailure system of the main protection action will not be unstable, which is\nalso a guarantee of the operation mode arrangement. In the case of the N-1\nbackup protection action, there is an approximately 2.5% probability that the\nsystem will be destabilized. Therefore, research is needed to improve the\noperating arrangement.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 08:54:00 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Cui", "Haotian", ""], ["Liu", "Xianggen", ""], ["Huang", "Yanhao", ""]]}, {"id": "1805.06660", "submitter": "Yazhou Yang", "authors": "Yazhou Yang, Marco Loog", "title": "Single Shot Active Learning using Pseudo Annotators", "comments": "12 pages, 8 figure, submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard myopic active learning assumes that human annotations are always\nobtainable whenever new samples are selected. This, however, is unrealistic in\nmany real-world applications where human experts are not readily available at\nall times. In this paper, we consider the single shot setting: all the required\nsamples should be chosen in a single shot and no human annotation can be\nexploited during the selection process. We propose a new method, Active\nLearning through Random Labeling (ALRL), which substitutes single human\nannotator for multiple, what we will refer to as, pseudo annotators. These\npseudo annotators always provide uniform and random labels whenever new\nunlabeled samples are queried. This random labeling enables standard active\nlearning algorithms to also exhibit the exploratory behavior needed for single\nshot active learning. The exploratory behavior is further enhanced by selecting\nthe most representative sample via minimizing nearest neighbor distance between\nunlabeled samples and queried samples. Experiments on real-world datasets\ndemonstrate that the proposed method outperforms several state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 09:05:28 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Yang", "Yazhou", ""], ["Loog", "Marco", ""]]}, {"id": "1805.06753", "submitter": "Yitan Wang", "authors": "Guangzeng Xie, Yitan Wang, Shuchang Zhou, Zhihua Zhang", "title": "Interpolatron: Interpolation or Extrapolation Schemes to Accelerate\n  Optimization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we explore acceleration techniques for large scale nonconvex\noptimization problems with special focuses on deep neural networks. The\nextrapolation scheme is a classical approach for accelerating stochastic\ngradient descent for convex optimization, but it does not work well for\nnonconvex optimization typically. Alternatively, we propose an interpolation\nscheme to accelerate nonconvex optimization and call the method Interpolatron.\nWe explain motivation behind Interpolatron and conduct a thorough empirical\nanalysis. Empirical results on DNNs of great depths (e.g., 98-layer ResNet and\n200-layer ResNet) on CIFAR-10 and ImageNet show that Interpolatron can converge\nmuch faster than the state-of-the-art methods such as the SGD with momentum and\nAdam. Furthermore, Anderson's acceleration, in which mixing coefficients are\ncomputed by least-squares estimation, can also be used to improve the\nperformance. Both Interpolatron and Anderson's acceleration are easy to\nimplement and tune. We also show that Interpolatron has linear convergence rate\nunder certain regularity assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 13:29:33 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Xie", "Guangzeng", ""], ["Wang", "Yitan", ""], ["Zhou", "Shuchang", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1805.06792", "submitter": "Jun-Kun Wang", "authors": "Jacob Abernethy and Kevin A. Lai and Kfir Y. Levy and Jun-Kun Wang", "title": "Faster Rates for Convex-Concave Games", "comments": "COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of no-regret algorithms to compute equilibria for\nparticular classes of convex-concave games. While standard regret bounds would\nlead to convergence rates on the order of $O(T^{-1/2})$, recent work\n\\citep{RS13,SALS15} has established $O(1/T)$ rates by taking advantage of a\nparticular class of optimistic prediction algorithms. In this work we go\nfurther, showing that for a particular class of games one achieves a $O(1/T^2)$\nrate, and we show how this applies to the Frank-Wolfe method and recovers a\nsimilar bound \\citep{D15}. We also show that such no-regret techniques can even\nachieve a linear rate, $O(\\exp(-T))$, for equilibrium computation under\nadditional curvature assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 14:16:54 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Abernethy", "Jacob", ""], ["Lai", "Kevin A.", ""], ["Levy", "Kfir Y.", ""], ["Wang", "Jun-Kun", ""]]}, {"id": "1805.06822", "submitter": "Gilad Cohen", "authors": "Gilad Cohen, Guillermo Sapiro, Raja Giryes", "title": "DNN or k-NN: That is the Generalize vs. Memorize Question", "comments": "Poster presented in NIPS 2018 \"Integration of Deep Learning Theories\"\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the relationship between the classification performed by\ndeep neural networks (DNNs) and the decision of various classical classifiers,\nnamely k-nearest neighbours (k-NN), support vector machines (SVM) and logistic\nregression (LR), at various layers of the network. This comparison provides us\nwith new insights as to the ability of neural networks to both memorize the\ntraining data and generalize to new data at the same time, where k-NN serves as\nthe ideal estimator that perfectly memorizes the data. We show that\nmemorization of non-generalizing networks happens only at the last layers.\nMoreover, the behavior of DNNs compared to the linear classifiers SVM and LR is\nquite the same on the training and test data regardless of whether the network\ngeneralizes. On the other hand, the similarity to k-NN holds only at the\nabsence of overfitting. Our results suggests that k-NN behavior of the network\non new data is a sign of generalization. Moreover, it shows that memorization\nand generalization, which are traditionally considered to be contradicting to\neach other, are compatible and complementary.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 15:31:22 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 06:58:53 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 06:44:35 GMT"}, {"version": "v4", "created": "Wed, 19 Dec 2018 19:41:15 GMT"}, {"version": "v5", "created": "Wed, 6 Feb 2019 15:34:43 GMT"}, {"version": "v6", "created": "Sun, 10 Feb 2019 12:03:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Cohen", "Gilad", ""], ["Sapiro", "Guillermo", ""], ["Giryes", "Raja", ""]]}, {"id": "1805.06826", "submitter": "Yixin Wang", "authors": "Yixin Wang, David M. Blei", "title": "The Blessings of Multiple Causes", "comments": "72 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observational data often assumes \"ignorability,\" that\nall confounders are observed. This assumption is standard yet untestable.\nHowever, many scientific studies involve multiple causes, different variables\nwhose effects are simultaneously of interest. We propose the deconfounder, an\nalgorithm that combines unsupervised machine learning and predictive model\nchecking to perform causal inference in multiple-cause settings. The\ndeconfounder infers a latent variable as a substitute for unobserved\nconfounders and then uses that substitute to perform causal inference. We\ndevelop theory for the deconfounder, and show that it requires weaker\nassumptions than classical causal inference. We analyze its performance in\nthree types of studies: semi-simulated data around smoking and lung cancer,\nsemi-simulated data around genome-wide association studies, and a real dataset\nabout actors and movie revenue. The deconfounder provides a checkable approach\nto estimating closer-to-truth causal effects.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 15:39:17 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 16:24:28 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 03:37:55 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Wang", "Yixin", ""], ["Blei", "David M.", ""]]}, {"id": "1805.06834", "submitter": "Chuang Wang", "authors": "Chuang Wang, Yonina C. Eldar and Yue M. Lu", "title": "Subspace Estimation from Incomplete Observations: A High-Dimensional\n  Analysis", "comments": "26 pages, 6 figures", "journal-ref": null, "doi": "10.1109/JSTSP.2018.2877405", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a high-dimensional analysis of three popular algorithms, namely,\nOja's method, GROUSE and PETRELS, for subspace estimation from streaming and\nhighly incomplete observations. We show that, with proper time scaling, the\ntime-varying principal angles between the true subspace and its estimates given\nby the algorithms converge weakly to deterministic processes when the ambient\ndimension $n$ tends to infinity. Moreover, the limiting processes can be\nexactly characterized as the unique solutions of certain ordinary differential\nequations (ODEs). A finite sample bound is also given, showing that the rate of\nconvergence towards such limits is $\\mathcal{O}(1/\\sqrt{n})$. In addition to\nproviding asymptotically exact predictions of the dynamic performance of the\nalgorithms, our high-dimensional analysis yields several insights, including an\nasymptotic equivalence between Oja's method and GROUSE, and a precise scaling\nrelationship linking the amount of missing data to the signal-to-noise ratio.\nBy analyzing the solutions of the limiting ODEs, we also establish phase\ntransition phenomena associated with the steady-state performance of these\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 16:04:39 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 22:36:18 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 00:59:09 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Wang", "Chuang", ""], ["Eldar", "Yonina C.", ""], ["Lu", "Yue M.", ""]]}, {"id": "1805.06837", "submitter": "Marten Wegkamp", "authors": "Xin Bing, Florentina Bunea, Marten Wegkamp", "title": "A fast algorithm with minimax optimal guarantees for topic models with\n  an unknown number of topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method of estimation in topic models, that is not a\nvariation on the existing simplex finding algorithms, and that estimates the\nnumber of topics K from the observed data. We derive new finite sample minimax\nlower bounds for the estimation of A, as well as new upper bounds for our\nproposed estimator. We describe the scenarios where our estimator is minimax\nadaptive. Our finite sample analysis is valid for any number of documents (n),\nindividual document length (N_i), dictionary size (p) and number of topics (K),\nand both p and K are allowed to increase with n, a situation not handled well\nby previous analyses. We complement our theoretical results with a detailed\nsimulation study. We illustrate that the new algorithm is faster and more\naccurate than the current ones, although we start out with a computational and\ntheoretical disadvantage of not knowing the correct number of topics K, while\nwe provide the competing methods with the correct value in our simulations.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 16:07:32 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 22:06:15 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 21:58:35 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Bing", "Xin", ""], ["Bunea", "Florentina", ""], ["Wegkamp", "Marten", ""]]}, {"id": "1805.06846", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Qiang Qiu, Robert Calderbank and Guillermo Sapiro", "title": "RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant\n  Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explicit encoding of group actions in deep features makes it possible for\nconvolutional neural networks (CNNs) to handle global deformations of images,\nwhich is critical to success in many vision tasks. This paper proposes to\ndecompose the convolutional filters over joint steerable bases across the space\nand the group geometry simultaneously, namely a rotation-equivariant CNN with\ndecomposed convolutional filters (RotDCF). This decomposition facilitates\ncomputing the joint convolution, which is proved to be necessary for the group\nequivariance. It significantly reduces the model size and computational\ncomplexity while preserving performance, and truncation of the bases expansion\nserves implicitly to regularize the filters. On datasets involving in-plane and\nout-of-plane object rotations, RotDCF deep features demonstrate greater\nrobustness and interpretability than regular CNNs. The stability of the\nequivariant representation to input variations is also proved theoretically\nunder generic assumptions on the filters in the decomposed form. The RotDCF\nframework can be extended to groups other than rotations, providing a general\napproach which achieves both group equivariance and representation stability at\na reduced model size.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 16:24:51 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Qiu", "Qiang", ""], ["Calderbank", "Robert", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1805.06862", "submitter": "Jun Zhou", "authors": "Jun Zhou, Yuhang Lu, Kang Zheng, Karen Smith, Colin Wilder, Song Wang", "title": "Design Identification of Curve Patterns on Cultural Heritage Objects:\n  Combining Template Matching and CNN-based Re-Ranking", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surfaces of many cultural heritage objects were embellished with various\npatterns, especially curve patterns. In practice, most of the unearthed\ncultural heritage objects are highly fragmented, e.g., sherds of potteries or\nvessels, and each of them only shows a very small portion of the underlying\nfull design, with noise and deformations. The goal of this paper is to address\nthe challenging problem of automatically identifying the underlying full design\nof curve patterns from such a sherd. Specifically, we formulate this problem as\ntemplate matching: curve structure segmented from the sherd is matched to each\nlocation with each possible orientation of each known full design. In this\npaper, we propose a new two-stage matching algorithm, with a different matching\ncost in each stage. In Stage 1, we use a traditional template matching, which\nis highly computationally efficient, over the whole search space and identify a\nsmall set of candidate matchings. In Stage 2, we derive a new matching cost by\ntraining a dual-source Convolutional Neural Network (CNN) and apply it to\nre-rank the candidate matchings identified in Stage 1. We collect 600 pottery\nsherds with 98 full designs from the Woodland Period in Southeastern North\nAmerica for experiments and the performance of the proposed algorithm is very\ncompetitive.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:05:32 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Zhou", "Jun", ""], ["Lu", "Yuhang", ""], ["Zheng", "Kang", ""], ["Smith", "Karen", ""], ["Wilder", "Colin", ""], ["Wang", "Song", ""]]}, {"id": "1805.06879", "submitter": "James Bagrow", "authors": "James P. Bagrow and Daniel Berenberg and Joshua Bongard", "title": "Neural language representations predict outcomes of scientific research", "comments": "8 pages, 3 figures, plus supporting material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many research fields codify their findings in standard formats, often by\nreporting correlations between quantities of interest. But the space of all\ntestable correlates is far larger than scientific resources can currently\naddress, so the ability to accurately predict correlations would be useful to\nplan research and allocate resources. Using a dataset of approximately 170,000\ncorrelational findings extracted from leading social science journals, we show\nthat a trained neural network can accurately predict the reported correlations\nusing only the text descriptions of the correlates. Accurate predictive models\nsuch as these can guide scientists towards promising untested correlates,\nbetter quantify the information gained from new findings, and has implications\nfor moving artificial intelligence systems from predicting structures to\npredicting relationships in the real world.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:40:12 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bagrow", "James P.", ""], ["Berenberg", "Daniel", ""], ["Bongard", "Joshua", ""]]}, {"id": "1805.06951", "submitter": "Neal Lawton", "authors": "Neal Lawton, Aram Galstyan, Greg Ver Steeg", "title": "A Forest Mixture Bound for Block-Free Parallel Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinate ascent variational inference is an important algorithm for\ninference in probabilistic models, but it is slow because it updates only a\nsingle variable at a time. Block coordinate methods perform inference faster by\nupdating blocks of variables in parallel. However, the speed and stability of\nthese algorithms depends on how the variables are partitioned into blocks. In\nthis paper, we give a stable parallel algorithm for inference in deep\nexponential families that doesn't require the variables to be partitioned into\nblocks. We achieve this by lower bounding the ELBO by a new objective we call\nthe forest mixture bound (FM bound) that separates the inference problem for\nvariables within a hidden layer. We apply this to the simple case when all\nrandom variables are Gaussian and show empirically that the algorithm converges\nfaster for models that are inherently more forest-like.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 20:11:32 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Lawton", "Neal", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""]]}, {"id": "1805.06962", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Kurt Keutzer, Alberto\n  Sangiovanni-Vincentelli, Sanjit A. Seshia", "title": "Counterexample-Guided Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for augmenting data sets for machine learning\nbased on counterexamples. Counterexamples are misclassified examples that have\nimportant properties for retraining and improving the model. Key components of\nour framework include a counterexample generator, which produces data items\nthat are misclassified by the model and error tables, a novel data structure\nthat stores information pertaining to misclassifications. Error tables can be\nused to explain the model's vulnerabilities and are used to efficiently\ngenerate counterexamples for augmentation. We show the efficacy of the proposed\nframework by comparing it to classical augmentation techniques on a case study\nof object detection in autonomous driving based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 20:42:07 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Ghosh", "Shromona", ""], ["Yue", "Xiangyu", ""], ["Keutzer", "Kurt", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1805.07006", "submitter": "Momo Matsuda", "authors": "Momo Matsuda, Keiichi Morikuni, Tetsuya Sakurai", "title": "Spectral feature scaling method for supervised dimensionality reduction", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral dimensionality reduction methods enable linear separations of\ncomplex data with high-dimensional features in a reduced space. However, these\nmethods do not always give the desired results due to irregularities or\nuncertainties of the data. Thus, we consider aggressively modifying the scales\nof the features to obtain the desired classification. Using prior knowledge on\nthe labels of partial samples to specify the Fiedler vector, we formulate an\neigenvalue problem of a linear matrix pencil whose eigenvector has the feature\nscaling factors. The resulting factors can modify the features of entire\nsamples to form clusters in the reduced space, according to the known labels.\nIn this study, we propose new dimensionality reduction methods supervised using\nthe feature scaling associated with the spectral clustering. Numerical\nexperiments show that the proposed methods outperform well-established\nsupervised methods for toy problems with more samples than features, and are\nmore robust regarding clustering than existing methods. Also, the proposed\nmethods outperform existing methods regarding classification for real-world\nproblems with more features than samples of gene expression profiles of cancer\ndiseases. Furthermore, the feature scaling tends to improve the clustering and\nclassification accuracies of existing unsupervised methods, as the proportion\nof training data increases.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 00:56:40 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Matsuda", "Momo", ""], ["Morikuni", "Keiichi", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "1805.07010", "submitter": "Patrick Emami", "authors": "Patrick Emami, Sanjay Ranka", "title": "Learning Permutations with Sinkhorn Policy Gradient", "comments": "16 pages, under review for NIPS 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems at the intersection of combinatorics and computer science\nrequire solving for a permutation that optimally matches, ranks, or sorts some\ndata. These problems usually have a task-specific, often non-differentiable\nobjective function that data-driven algorithms can use as a learning signal. In\nthis paper, we propose the Sinkhorn Policy Gradient (SPG) algorithm for\nlearning policies on permutation matrices. The actor-critic neural network\narchitecture we introduce for SPG uniquely decouples representation learning of\nthe state space from the highly-structured action space of permutations with a\ntemperature-controlled Sinkhorn layer. The Sinkhorn layer produces continuous\nrelaxations of permutation matrices so that the actor-critic architecture can\nbe trained end-to-end. Our empirical results show that agents trained with SPG\ncan perform competitively on sorting, the Euclidean TSP, and matching tasks. We\nalso observe that SPG is significantly more data efficient at the matching task\nthan the baseline methods, which indicates that SPG is conducive to learning\nrepresentations that are useful for reasoning about permutations.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 01:10:09 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Emami", "Patrick", ""], ["Ranka", "Sanjay", ""]]}, {"id": "1805.07029", "submitter": "Jeongyeol Baek", "authors": "JeongYeol Baek, Ioana Veronica Chelu, Livia Iordache, Vlad Paunescu,\n  HyunJoo Ryu, Alexandru Ghiuta, Andrei Petreanu, YunSung Soh, Andrei Leica,\n  ByeongMoon Jeon", "title": "Scene Understanding Networks for Autonomous Driving based on Around View\n  Monitoring System", "comments": "Accepted by CVPR 2018 Workshop on Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern driver assistance systems rely on a wide range of sensors (RADAR,\nLIDAR, ultrasound and cameras) for scene understanding and prediction. These\nsensors are typically used for detecting traffic participants and scene\nelements required for navigation. In this paper we argue that relying on camera\nbased systems, specifically Around View Monitoring (AVM) system has great\npotential to achieve these goals in both parking and driving modes with\ndecreased costs. The contributions of this paper are as follows: we present a\nnew end-to-end solution for delimiting the safe drivable area for each frame by\nmeans of identifying the closest obstacle in each direction from the driving\nvehicle, we use this approach to calculate the distance to the nearest\nobstacles and we incorporate it into a unified end-to-end architecture capable\nof joint object detection, curb detection and safe drivable area detection.\nFurthermore, we describe the family of networks for both a high accuracy\nsolution and a low complexity solution. We also introduce further augmentation\nof the base architecture with 3D object detection.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 02:54:54 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Baek", "JeongYeol", ""], ["Chelu", "Ioana Veronica", ""], ["Iordache", "Livia", ""], ["Paunescu", "Vlad", ""], ["Ryu", "HyunJoo", ""], ["Ghiuta", "Alexandru", ""], ["Petreanu", "Andrei", ""], ["Soh", "YunSung", ""], ["Leica", "Andrei", ""], ["Jeon", "ByeongMoon", ""]]}, {"id": "1805.07051", "submitter": "Zehang Li", "authors": "Zehang Richard Li, Tyler H. McCormick, Samuel J. Clark", "title": "Bayesian Joint Spike-and-Slab Graphical Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a new class of priors for Bayesian inference with\nmultiple Gaussian graphical models. We introduce fully Bayesian treatments of\ntwo popular procedures, the group graphical lasso and the fused graphical\nlasso, and extend them to a continuous spike-and-slab framework to allow\nself-adaptive shrinkage and model selection simultaneously. We develop an EM\nalgorithm that performs fast and dynamic explorations of posterior modes. Our\napproach selects sparse models efficiently with substantially smaller bias than\nwould be induced by alternative regularization procedures. The performance of\nthe proposed methods are demonstrated through simulation and two real data\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 05:27:02 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:32:47 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Li", "Zehang Richard", ""], ["McCormick", "Tyler H.", ""], ["Clark", "Samuel J.", ""]]}, {"id": "1805.07072", "submitter": "Shane Barratt", "authors": "Shane Barratt, Rishi Sharma", "title": "Optimizing for Generalization in Machine Learning with Cross-Validation\n  Gradients", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-validation is the workhorse of modern applied statistics and machine\nlearning, as it provides a principled framework for selecting the model that\nmaximizes generalization performance. In this paper, we show that the\ncross-validation risk is differentiable with respect to the hyperparameters and\ntraining data for many common machine learning algorithms, including logistic\nregression, elastic-net regression, and support vector machines. Leveraging\nthis property of differentiability, we propose a cross-validation gradient\nmethod (CVGM) for hyperparameter optimization. Our method enables efficient\noptimization in high-dimensional hyperparameter spaces of the cross-validation\nrisk, the best surrogate of the true generalization ability of our learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 07:04:37 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Barratt", "Shane", ""], ["Sharma", "Rishi", ""]]}, {"id": "1805.07075", "submitter": "Shalini Ghosh", "authors": "Shalini Ghosh, Amaury Mercier, Dheeraj Pichapati, Susmit Jha, Vinod\n  Yegneswaran, Patrick Lincoln", "title": "Trusted Neural Networks for Safety-Constrained Autonomous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Trusted Neural Network (TNN) models, which are deep neural network\nmodels that satisfy safety constraints critical to the application domain. We\ninvestigate different mechanisms for incorporating rule-based knowledge in the\nform of first-order logic constraints into a TNN model, where rules that encode\nsafety are accompanied by weights indicating their relative importance. This\nframework allows the TNN model to learn from knowledge available in form of\ndata as well as logical rules. We propose multiple approaches for solving this\nproblem: (a) a multi-headed model structure that allows trade-off between\nsatisfying logical constraints and fitting training data in a unified training\nframework, and (b) creating a constrained optimization problem and solving it\nin dual formulation by posing a new constrained loss function and using a\nproximal gradient descent algorithm. We demonstrate the efficacy of our TNN\nframework through experiments using the open-source TORCS~\\cite{BernhardCAA15}\n3D simulator for self-driving cars. Experiments using our first approach of a\nmulti-headed TNN model, on a dataset generated by a customized version of\nTORCS, show that (1) adding safety constraints to a neural network model\nresults in increased performance and safety, and (2) the improvement increases\nwith increasing importance of the safety constraints. Experiments were also\nperformed using the second approach of proximal algorithm for constrained\noptimization --- they demonstrate how the proposed method ensures that (1) the\noverall TNN model satisfies the constraints even when the training data\nviolates some of the constraints, and (2) the proximal gradient descent\nalgorithm on the constrained objective converges faster than the unconstrained\nversion.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 07:17:15 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Ghosh", "Shalini", ""], ["Mercier", "Amaury", ""], ["Pichapati", "Dheeraj", ""], ["Jha", "Susmit", ""], ["Yegneswaran", "Vinod", ""], ["Lincoln", "Patrick", ""]]}, {"id": "1805.07091", "submitter": "Lek-Heng Lim", "authors": "Liwen Zhang, Gregory Naitzat, and Lek-Heng Lim", "title": "Tropical Geometry of Deep Neural Networks", "comments": "18 pages, 6 figures", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "cs.LG math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish, for the first time, connections between feedforward neural\nnetworks with ReLU activation and tropical geometry --- we show that the family\nof such neural networks is equivalent to the family of tropical rational maps.\nAmong other things, we deduce that feedforward ReLU neural networks with one\nhidden layer can be characterized by zonotopes, which serve as building blocks\nfor deeper networks; we relate decision boundaries of such neural networks to\ntropical hypersurfaces, a major object of study in tropical geometry; and we\nprove that linear regions of such neural networks correspond to vertices of\npolytopes associated with tropical rational functions. An insight from our\ntropical formulation is that a deeper network is exponentially more expressive\nthan a shallow network.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 08:30:50 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Zhang", "Liwen", ""], ["Naitzat", "Gregory", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "1805.07107", "submitter": "Stephen Pauwels", "authors": "Stephen Pauwels, Toon Calders", "title": "Extending Dynamic Bayesian Networks for Anomaly Detection in Complex\n  Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Checking various log files from different processes can be a tedious task as\nthese logs contain lots of events, each with a (possibly large) number of\nattributes. We developed a way to automatically model log files and detect\noutlier traces in the data. For that we extend Dynamic Bayesian Networks to\nmodel the normal behavior found in log files. We introduce a new algorithm that\nis able to learn a model of a log file starting from the data itself. The model\nis capable of scoring traces even when new values or new combinations of values\nappear in the log file.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 09:23:12 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 13:08:31 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Pauwels", "Stephen", ""], ["Calders", "Toon", ""]]}, {"id": "1805.07112", "submitter": "Chen Chen", "authors": "Chen Chen, Shuai Mu, Wanpeng Xiao, Zexiong Ye, Liesi Wu, Qi Ju", "title": "Improving Image Captioning with Conditional Generative Adversarial Nets", "comments": "12 pages; 33 figures; 36 refenences; Accepted by AAAI2019", "journal-ref": "AAAI2019", "doi": "10.1609/aaai.v33i01.33018142", "report-no": "Vol 33 No 01: AAAI-19, IAAI-19, EAAI-20", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel\nconditional-generative-adversarial-nets-based image captioning framework as an\nextension of traditional reinforcement-learning (RL)-based encoder-decoder\narchitecture. To deal with the inconsistent evaluation problem among different\nobjective language metrics, we are motivated to design some \"discriminator\"\nnetworks to automatically and progressively determine whether generated caption\nis human described or machine generated. Two kinds of discriminator\narchitectures (CNN and RNN-based structures) are introduced since each has its\nown advantages. The proposed algorithm is generic so that it can enhance any\nexisting RL-based image captioning framework and we show that the conventional\nRL training method is just a special case of our approach. Empirically, we show\nconsistent improvements over all language evaluation metrics for different\nstate-of-the-art image captioning models. In addition, the well-trained\ndiscriminators can also be viewed as objective image captioning evaluators\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 09:31:53 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 08:55:29 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 06:36:45 GMT"}, {"version": "v4", "created": "Wed, 13 Feb 2019 03:02:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Chen", "Chen", ""], ["Mu", "Shuai", ""], ["Xiao", "Wanpeng", ""], ["Ye", "Zexiong", ""], ["Wu", "Liesi", ""], ["Ju", "Qi", ""]]}, {"id": "1805.07113", "submitter": "Daniele Zambon", "authors": "Daniele Zambon, Cesare Alippi, Lorenzo Livi", "title": "Change Point Methods on a Sequence of Graphs", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing ( Volume: 67, Issue: 24,\n  Dec.15, 15 2019)", "doi": "10.1109/TSP.2019.2953596", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite sequence of graphs, e.g., coming from technological,\nbiological, and social networks, the paper proposes a methodology to identify\npossible changes in stationarity in the stochastic process generating the\ngraphs. In order to cover a large class of applications, we consider the\ngeneral family of attributed graphs where both topology (number of vertexes and\nedge configuration) and related attributes are allowed to change also in the\nstationary case. Novel Change Point Methods (CPMs) are proposed, that (i) map\ngraphs into a vector domain; (ii) apply a suitable statistical test in the\nvector space; (iii) detect the change --if any-- according to a confidence\nlevel and provide an estimate for its time occurrence. Two specific\nmultivariate CPMs have been designed: one that detects shifts in the\ndistribution mean, the other addressing generic changes affecting the\ndistribution. We ground our proposal with theoretical results showing how to\nrelate the inference attained in the numerical vector space to the graph\ndomain, and vice versa. We also show how to extend the methodology for handling\nmultiple change points in the same sequence. Finally, the proposed CPMs have\nbeen validated on real data sets coming from epileptic-seizure detection\nproblems and on labeled data sets for graph classification. Results show the\neffectiveness of what proposed in relevant application scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 09:45:59 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 11:05:05 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zambon", "Daniele", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1805.07123", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en", "title": "Tree Edit Distance Learning via Adaptive Symbol Embeddings:\n  Supplementary Materials and Results", "comments": "Supplementary Materials and additional Results for the ICML 2018\n  paper Tree Edit Distance Learning via Adaptive Symbol Embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning has the aim to improve classification accuracy by learning a\ndistance measure which brings data points from the same class closer together\nand pushes data points from different classes further apart. Recent research\nhas demonstrated that metric learning approaches can also be applied to trees,\nsuch as molecular structures, abstract syntax trees of computer programs, or\nsyntax trees of natural language, by learning the cost function of an edit\ndistance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.\nHowever, learning such costs directly may yield an edit distance which violates\nmetric axioms, is challenging to interpret, and may not generalize well. In\nthis contribution, we propose a novel metric learning approach for trees which\nlearns an edit distance indirectly by embedding the tree nodes as vectors, such\nthat the Euclidean distance between those vectors supports class\ndiscrimination. We learn such embeddings by reducing the distance to\nprototypical trees from the same class and increasing the distance to\nprototypical trees from different classes. In our experiments, we show that our\nproposed metric learning approach improves upon the state-of-the-art in metric\nlearning for trees on six benchmark data sets, ranging from computer science\nover biomedical data to a natural-language processing data set containing over\n300,000 nodes.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 10:09:41 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""]]}, {"id": "1805.07137", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Kaoru Hiramatsu, Kunio Kashino", "title": "Knowledge Discovery from Layered Neural Networks based on Non-negative\n  Task Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has become an important issue in the machine learning field,\nalong with the success of layered neural networks in various practical tasks.\nSince a trained layered neural network consists of a complex nonlinear\nrelationship between large number of parameters, we failed to understand how\nthey could achieve input-output mappings with a given data set. In this paper,\nwe propose the non-negative task decomposition method, which applies\nnon-negative matrix factorization to a trained layered neural network. This\nenables us to decompose the inference mechanism of a trained layered neural\nnetwork into multiple principal tasks of input-output mapping, and reveal the\nroles of hidden units in terms of their contribution to each principal task.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 10:55:21 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 02:23:39 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Hiramatsu", "Kaoru", ""], ["Kashino", "Kunio", ""]]}, {"id": "1805.07159", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Jamal Toutouh, Enrique Alba", "title": "Low-Cost Recurrent Neural Network Expected Performance Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a powerful tool, but they are very sensitive to\ntheir hyper-parameter configuration. Moreover, training properly a recurrent\nneural network is a tough task, therefore selecting an appropriate\nconfiguration is critical. Varied strategies have been proposed to tackle this\nissue. However, most of them are still impractical because of the\ntime/resources needed. In this study, we propose a low computational cost model\nto evaluate the expected performance of a given architecture based on the\ndistribution of the error of random samples of the weights. We empirically\nvalidate our proposal using three use cases. The results suggest that this is a\npromising alternative to reduce the cost of exploration for hyper-parameter\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 12:00:09 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 09:26:27 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Toutouh", "Jamal", ""], ["Alba", "Enrique", ""]]}, {"id": "1805.07179", "submitter": "Ingmar Schuster", "authors": "Ingmar Schuster and Ilja Klebanov", "title": "Markov Chain Importance Sampling -- a highly efficient estimator for\n  MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain (MC) algorithms are ubiquitous in machine learning and\nstatistics and many other disciplines. Typically, these algorithms can be\nformulated as acceptance rejection methods. In this work we present a novel\nestimator applicable to these methods, dubbed Markov chain importance sampling\n(MCIS), which efficiently makes use of rejected proposals. For the unadjusted\nLangevin algorithm, it provides a novel way of correcting the discretization\nerror. Our estimator satisfies a central limit theorem and improves on error\nper CPU cycle, often to a large extent. As a by-product it enables estimating\nthe normalizing constant, an important quantity in Bayesian machine learning\nand statistics.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 12:47:02 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 19:36:44 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 08:39:35 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 05:56:51 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Schuster", "Ingmar", ""], ["Klebanov", "Ilja", ""]]}, {"id": "1805.07193", "submitter": "Markus Braun", "authors": "Markus Braun, Sebastian Krebs, Fabian Flohr, and Dariu M. Gavrila", "title": "The EuroCity Persons Dataset: A Novel Benchmark for Object Detection", "comments": "Submitted to IEEE Trans. on Pattern Analysis and Machine Intelligence", "journal-ref": "Published in IEEE Trans. on Pattern Analysis and Machine\n  Intelligence, 2019", "doi": "10.1109/TPAMI.2019.2897684", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data has had a great share in the success of deep learning in computer\nvision. Recent works suggest that there is significant further potential to\nincrease object detection performance by utilizing even bigger datasets. In\nthis paper, we introduce the EuroCity Persons dataset, which provides a large\nnumber of highly diverse, accurate and detailed annotations of pedestrians,\ncyclists and other riders in urban traffic scenes. The images for this dataset\nwere collected on-board a moving vehicle in 31 cities of 12 European countries.\nWith over 238200 person instances manually labeled in over 47300 images,\nEuroCity Persons is nearly one order of magnitude larger than person datasets\nused previously for benchmarking. The dataset furthermore contains a large\nnumber of person orientation annotations (over 211200). We optimize four\nstate-of-the-art deep learning approaches (Faster R-CNN, R-FCN, SSD and YOLOv3)\nto serve as baselines for the new object detection benchmark. In experiments\nwith previous datasets we analyze the generalization capabilities of these\ndetectors when trained with the new dataset. We furthermore study the effect of\nthe training set size, the dataset diversity (day- vs. night-time, geographical\nregion), the dataset detail (i.e. availability of object orientation\ninformation) and the annotation quality on the detector performance. Finally,\nwe analyze error sources and discuss the road ahead.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 13:17:46 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 15:20:52 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Braun", "Markus", ""], ["Krebs", "Sebastian", ""], ["Flohr", "Fabian", ""], ["Gavrila", "Dariu M.", ""]]}, {"id": "1805.07206", "submitter": "Justin Bayer", "authors": "Atanas Mirchev, Baris Kayalibay, Maximilian Soelch, Patrick van der\n  Smagt, Justin Bayer", "title": "Approximate Bayesian inference in spatial environments", "comments": "Preprint of publication at RSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based approaches bear great promise for decision making of agents\ninteracting with the physical world. In the context of spatial environments,\ndifferent types of problems such as localisation, mapping, navigation or\nautonomous exploration are typically adressed with specialised methods, often\nrelying on detailed knowledge of the system at hand. We express these tasks as\nprobabilistic inference and planning under the umbrella of deep sequential\ngenerative models. Using the frameworks of variational inference and neural\nnetworks, our method inherits favourable properties such as flexibility,\nscalability and the ability to learn from data. The method performs comparably\nto specialised state-of-the-art methodology in two distinct simulated\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 13:47:30 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 10:14:40 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 13:50:34 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Mirchev", "Atanas", ""], ["Kayalibay", "Baris", ""], ["Soelch", "Maximilian", ""], ["van der Smagt", "Patrick", ""], ["Bayer", "Justin", ""]]}, {"id": "1805.07220", "submitter": "Joshua Bertram", "authors": "Joshua R. Bertram and Peng Wei", "title": "Memoryless Exact Solutions for Deterministic MDPs with Sparse Rewards", "comments": "Submitted to NIPS 2018. arXiv admin note: text overlap with\n  arXiv:1805.02785", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for deterministic continuous Markov Decision\nProcesses with sparse rewards that computes the optimal policy exactly with no\ndependency on the size of the state space. The algorithm has time complexity of\n$O( |R|^3 \\times |A|^2 )$ and memory complexity of $O( |R| \\times |A| )$, where\n$|R|$ is the number of reward sources and $|A|$ is the number of actions.\nFurthermore, we describe a companion algorithm that can follow the optimal\npolicy from any initial state without computing the entire value function,\ninstead computing on-demand the value of states as they are needed. The\nalgorithm to solve the MDP does not depend on the size of the state space for\neither time or memory complexity, and the ability to follow the optimal policy\nis linear in time and space with the path length of following the optimal\npolicy from the initial state. We demonstrate the algorithm operation side by\nside with value iteration on tractable MDPs.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 15:59:55 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Bertram", "Joshua R.", ""], ["Wei", "Peng", ""]]}, {"id": "1805.07226", "submitter": "George Papamakarios", "authors": "George Papamakarios, David C. Sterratt, Iain Murray", "title": "Sequential Neural Likelihood: Fast Likelihood-free Inference with\n  Autoregressive Flows", "comments": "Accepted for publication at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Sequential Neural Likelihood (SNL), a new method for Bayesian\ninference in simulator models, where the likelihood is intractable but\nsimulating data from the model is possible. SNL trains an autoregressive flow\non simulated data in order to learn a model of the likelihood in the region of\nhigh posterior density. A sequential training procedure guides simulations and\nreduces simulation cost by orders of magnitude. We show that SNL is more\nrobust, more accurate and requires less tuning than related neural-based\nmethods, and we discuss diagnostics for assessing calibration, convergence and\ngoodness-of-fit.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:06:23 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 17:27:21 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Papamakarios", "George", ""], ["Sterratt", "David C.", ""], ["Murray", "Iain", ""]]}, {"id": "1805.07233", "submitter": "Kaixuan Chen", "authors": "Kaixuan Chen, Lina Yao, Xianzhi Wang, Dalin Zhang, Tao Gu, Zhiwen Yu,\n  Zheng Yang", "title": "Interpretable Parallel Recurrent Neural Networks with Convolutional\n  Attentions for Multi-Modality Activity Modeling", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.07661", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal features play a key role in wearable sensor-based human activity\nrecognition (HAR). Selecting the most salient features adaptively is a\npromising way to maximize the effectiveness of multimodal sensor data. In this\nregard, we propose a \"collect fully and select wisely\" principle as well as an\ninterpretable parallel recurrent model with convolutional attentions to improve\nthe recognition performance. We first collect modality features and the\nrelations between each pair of features to generate activity frames, and then\nintroduce an attention mechanism to select the most prominent regions from\nactivity frames precisely. The selected frames not only maximize the\nutilization of valid features but also reduce the number of features to be\ncomputed effectively. We further analyze the accuracy and interpretability of\nthe proposed model based on extensive experiments. The results show that our\nmodel achieves competitive performance on two benchmarked datasets and works\nwell in real life scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 02:43:02 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Chen", "Kaixuan", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Zhang", "Dalin", ""], ["Gu", "Tao", ""], ["Yu", "Zhiwen", ""], ["Yang", "Zheng", ""]]}, {"id": "1805.07242", "submitter": "James O' Neill", "authors": "James O' Neill", "title": "Siamese Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capsule Networks have shown encouraging results on \\textit{defacto} benchmark\ncomputer vision datasets such as MNIST, CIFAR and smallNORB. Although, they are\nyet to be tested on tasks where (1) the entities detected inherently have more\ncomplex internal representations and (2) there are very few instances per class\nto learn from and (3) where point-wise classification is not suitable. Hence,\nthis paper carries out experiments on face verification in both controlled and\nuncontrolled settings that together address these points. In doing so we\nintroduce \\textit{Siamese Capsule Networks}, a new variant that can be used for\npairwise learning tasks. The model is trained using contrastive loss with\n$\\ell_2$-normalized capsule encoded pose features. We find that \\textit{Siamese\nCapsule Networks} perform well against strong baselines on both pairwise\nlearning datasets, yielding best results in the few-shot learning setting where\nimage pairs in the test set contain unseen subjects.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:39:01 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Neill", "James O'", ""]]}, {"id": "1805.07249", "submitter": "Shrihari Vasudevan", "authors": "Shrihari Vasudevan", "title": "Dynamic learning rate using Mutual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates dynamic hyper-parameter setting, for deep neural\nnetwork training, using Mutual Information (MI). The specific hyper-parameter\nstudied in this paper is the learning rate. MI between the output layer and\ntrue outcomes is used to dynamically set the learning rate of the network\nthrough the training cycle; the idea is also extended to layer-wise setting of\nlearning rate. Two approaches are demonstrated - tracking relative change in\nmutual information and, additionally tracking its value relative to a reference\nmeasure. The paper does not attempt to recommend a specific learning rate\npolicy. Experiments demonstrate that mutual information may be effectively used\nto dynamically set learning rate and achieve competitive to better outcomes in\ncompetitive to better time.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:46:20 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 07:34:51 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Vasudevan", "Shrihari", ""]]}, {"id": "1805.07252", "submitter": "Xiaojian Ma", "authors": "Mingxuan Jing, Xiaojian Ma, Fuchun Sun, Huaping Liu", "title": "Learning and Inferring Movement with Deep Generative Model", "comments": "Mingxuan Jing and Xiaojian Ma contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and inference movement is a very challenging problem due to its high\ndimensionality and dependency to varied environments or tasks. In this paper,\nwe propose an effective probabilistic method for learning and inference of\nbasic movements. The motion planning problem is formulated as learning on a\ndirected graphic model and deep generative model is used to perform learning\nand inference from demonstrations. An important characteristic of this method\nis that it flexibly incorporates the task descriptors and context information\nfor long-term planning and it can be combined with dynamic systems for robot\ncontrol. The experimental validations on robotic approaching path planning\ntasks show the advantages over the base methods with limited training data.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:50:26 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 01:25:57 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jing", "Mingxuan", ""], ["Ma", "Xiaojian", ""], ["Sun", "Fuchun", ""], ["Liu", "Huaping", ""]]}, {"id": "1805.07297", "submitter": "Shiyin Wei", "authors": "Shiyin Wei, Xiaowei Jin, Hui Li", "title": "General solutions for nonlinear differential equations: a rule-based\n  self-learning approach using deep reinforcement learning", "comments": null, "journal-ref": null, "doi": "10.1007/s00466-019-01715-1", "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A universal rule-based self-learning approach using deep reinforcement\nlearning (DRL) is proposed for the first time to solve nonlinear ordinary\ndifferential equations and partial differential equations. The solver consists\nof a deep neural network-structured actor that outputs candidate solutions, and\na critic derived only from physical rules (governing equations and boundary and\ninitial conditions). Solutions in discretized time are treated as multiple\ntasks sharing the same governing equation, and the current step parameters\nprovide an ideal initialization for the next owing to the temporal continuity\nof the solutions, which shows a transfer learning characteristic and indicates\nthat the DRL solver has captured the intrinsic nature of the equation. The\napproach is verified through solving the Schr\\\"odinger, Navier-Stokes,\nBurgers', Van der Pol, and Lorenz equations and an equation of motion. The\nresults indicate that the approach gives solutions with high accuracy, and the\nsolution process promises to get faster.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 15:16:47 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 14:16:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Wei", "Shiyin", ""], ["Jin", "Xiaowei", ""], ["Li", "Hui", ""]]}, {"id": "1805.07300", "submitter": "Leon Chlon", "authors": "Leon Chlon, Andrew Song, Sandya Subramanian, Hugo Soulat, John Tauber,\n  Demba Ba, Michael Prerau", "title": "Multitaper Spectral Estimation HDP-HMMs for EEG Sleep Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalographic (EEG) monitoring of neural activity is widely used\nfor sleep disorder diagnostics and research. The standard of care is to\nmanually classify 30-second epochs of EEG time-domain traces into 5 discrete\nsleep stages. Unfortunately, this scoring process is subjective and\ntime-consuming, and the defined stages do not capture the heterogeneous\nlandscape of healthy and clinical neural dynamics. This motivates the search\nfor a data-driven and principled way to identify the number and composition of\nsalient, reoccurring brain states present during sleep. To this end, we propose\na Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM), combined with\nwide-sense stationary (WSS) time series spectral estimation to construct a\ngenerative model for personalized subject sleep states. In addition, we employ\nmultitaper spectral estimation to further reduce the large variance of the\nspectral estimates inherent to finite-length EEG measurements. By applying our\nmethod to both simulated and human sleep data, we arrive at three main results:\n1) a Bayesian nonparametric automated algorithm that recovers general temporal\ndynamics of sleep, 2) identification of subject-specific \"microstates\" within\ncanonical sleep stages, and 3) discovery of stage-dependent sub-oscillations\nwith shared spectral signatures across subjects.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 15:44:15 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Chlon", "Leon", ""], ["Song", "Andrew", ""], ["Subramanian", "Sandya", ""], ["Soulat", "Hugo", ""], ["Tauber", "John", ""], ["Ba", "Demba", ""], ["Prerau", "Michael", ""]]}, {"id": "1805.07311", "submitter": "G\\'abor Braun", "authors": "G\\'abor Braun, Sebastian Pokutta, Dan Tu, Stephen Wright", "title": "Blended Conditional Gradients: the unconditioning of conditional\n  gradients", "comments": "33 pages + 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a blended conditional gradient approach for minimizing a smooth\nconvex function over a polytope P, combining the Frank--Wolfe algorithm (also\ncalled conditional gradient) with gradient-based steps, different from away\nsteps and pairwise steps, but still achieving linear convergence for strongly\nconvex functions, along with good practical performance. Our approach retains\nall favorable properties of conditional gradient algorithms, notably avoidance\nof projections onto P and maintenance of iterates as sparse convex combinations\nof a limited number of extreme points of P. The algorithm is lazy, making use\nof inexpensive inexact solutions of the linear programming subproblem that\ncharacterizes the conditional gradient approach. It decreases measures of\noptimality (primal and dual gaps) rapidly, both in the number of iterations and\nin wall-clock time, outperforming even the lazy conditional gradient algorithms\nof [arXiv:1410.8816]. We also present a streamlined version of the algorithm\nfor the probability simplex.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 16:21:02 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 17:14:44 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 14:20:34 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Braun", "G\u00e1bor", ""], ["Pokutta", "Sebastian", ""], ["Tu", "Dan", ""], ["Wright", "Stephen", ""]]}, {"id": "1805.07317", "submitter": "Huazheng Wang", "authors": "Huazheng Wang, Ramsey Langley, Sonwoo Kim, Eric McCord-Snook, Hongning\n  Wang", "title": "Efficient Exploration of Gradient Space for Online Learning to Rank", "comments": "To appear on SIGIR '18: The 41st International ACM SIGIR Conference\n  on Research & Development in Information Retrieval", "journal-ref": null, "doi": "10.1145/3209978.3210045", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning to rank (OL2R) optimizes the utility of returned search\nresults based on implicit feedback gathered directly from users. To improve the\nestimates, OL2R algorithms examine one or more exploratory gradient directions\nand update the current ranker if a proposed one is preferred by users via an\ninterleaved test. In this paper, we accelerate the online learning process by\nefficient exploration in the gradient space. Our algorithm, named as Null Space\nGradient Descent, reduces the exploration space to only the \\emph{null space}\nof recent poorly performing gradients. This prevents the algorithm from\nrepeatedly exploring directions that have been discouraged by the most recent\ninteractions with users. To improve sensitivity of the resulting interleaved\ntest, we selectively construct candidate rankers to maximize the chance that\nthey can be differentiated by candidate ranking documents in the current query;\nand we use historically difficult queries to identify the best ranker when tie\noccurs in comparing the rankers. Extensive experimental comparisons with the\nstate-of-the-art OL2R algorithms on several public benchmarks confirmed the\neffectiveness of our proposal algorithm, especially in its fast learning\nconvergence and promising ranking quality at an early stage.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 16:32:04 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wang", "Huazheng", ""], ["Langley", "Ramsey", ""], ["Kim", "Sonwoo", ""], ["McCord-Snook", "Eric", ""], ["Wang", "Hongning", ""]]}, {"id": "1805.07324", "submitter": "Xin Li", "authors": "Huiting Hong, Xin Li and Mingzhong Wang", "title": "GANE: A Generative Adversarial Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding has become a hot research topic recently which can provide\nlow-dimensional feature representations for many machine learning applications.\nCurrent work focuses on either (1) whether the embedding is designed as an\nunsupervised learning task by explicitly preserving the structural connectivity\nin the network, or (2) whether the embedding is a by-product during the\nsupervised learning of a specific discriminative task in a deep neural network.\nIn this paper, we focus on bridging the gap of the two lines of the research.\nWe propose to adapt the Generative Adversarial model to perform network\nembedding, in which the generator is trying to generate vertex pairs, while the\ndiscriminator tries to distinguish the generated vertex pairs from real\nconnections (edges) in the network. Wasserstein-1 distance is adopted to train\nthe generator to gain better stability. We develop three variations of models,\nincluding GANE which applies cosine similarity, GANE-O1 which preserves the\nfirst-order proximity, and GANE-O2 which tries to preserves the second-order\nproximity of the network in the low-dimensional embedded vector space. We later\nprove that GANE-O2 has the same objective function as GANE-O1 when negative\nsampling is applied to simplify the training process in GANE-O2. Experiments\nwith real-world network datasets demonstrate that our models constantly\noutperform state-of-the-art solutions with significant improvements on\nprecision in link prediction, as well as on visualizations and accuracy in\nclustering tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 16:54:44 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 14:27:33 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Hong", "Huiting", ""], ["Li", "Xin", ""], ["Wang", "Mingzhong", ""]]}, {"id": "1805.07331", "submitter": "Marco Frasca", "authors": "Marco Frasca and Nicol\\`o Cesa-Bianchi", "title": "Positive and Unlabeled Learning through Negative Selection and\n  Imbalance-aware Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in protein function prediction, we consider a\nchallenging supervised classification setting in which positive labels are\nscarce and there are no explicit negative labels. The learning algorithm must\nthus select which unlabeled examples to use as negative training points,\npossibly ending up with an unbalanced learning problem. We address these issues\nby proposing an algorithm that combines active learning (for selecting negative\nexamples) with imbalance-aware learning (for mitigating the label imbalance).\nIn our experiments we observe that these two techniques operate\nsynergistically, outperforming state-of-the-art methods on standard protein\nfunction prediction benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:14:23 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 10:55:46 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Frasca", "Marco", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""]]}, {"id": "1805.07337", "submitter": "Akiyoshi Sannai", "authors": "Akiyoshi Sannai", "title": "Reconstruction of training samples from loss functions", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new mathematical framework to analyze the loss\nfunctions of deep neural networks with ReLU functions. Furthermore, as as\napplication of this theory, we prove that the loss functions can reconstruct\nthe inputs of the training samples up to scalar multiplication (as vectors) and\ncan provide the number of layers and nodes of the deep neural network. Namely,\nif we have all input and output of a loss function (or equivalently all\npossible learning process), for all input of each training sample $x_i \\in\n\\mathbb{R}^n$, we can obtain vectors $x'_i\\in \\mathbb{R}^n$ satisfying\n$x_i=c_ix'_i$ for some $c_i \\neq 0$. To prove theorem, we introduce the notion\nof virtual polynomials, which are polynomials written as the output of a node\nin a deep neural network. Using virtual polynomials, we find an algebraic\nstructure for the loss surfaces, called semi-algebraic sets. We analyze these\nloss surfaces from the algebro-geometric point of view. Factorization of\npolynomials is one of the most standard ideas in algebra. Hence, we express the\nfactorization of the virtual polynomials in terms of their active paths. This\nframework can be applied to the leakage problem in the training of deep neural\nnetworks. The main theorem in this paper indicates that there are many risks\nassociated with the training of deep neural networks. For example, if we have N\n(the dimension of weight space) + 1 nonsmooth points on the loss surface, which\nare sufficiently close to each other, we can obtain the input of training\nsample up to scalar multiplication. We also point out that the structures of\nthe loss surfaces depend on the shape of the deep neural network and not on the\ntraining samples.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:39:46 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Sannai", "Akiyoshi", ""]]}, {"id": "1805.07340", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Improved Sentence Modeling using Suffix Bidirectional LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have become ubiquitous in computing representations\nof sequential data, especially textual data in natural language processing. In\nparticular, Bidirectional LSTMs are at the heart of several neural models\nachieving state-of-the-art performance in a wide variety of tasks in NLP.\nHowever, BiLSTMs are known to suffer from sequential bias - the contextual\nrepresentation of a token is heavily influenced by tokens close to it in a\nsentence. We propose a general and effective improvement to the BiLSTM model\nwhich encodes each suffix and prefix of a sequence of tokens in both forward\nand reverse directions. We call our model Suffix Bidirectional LSTM or\nSuBiLSTM. This introduces an alternate bias that favors long range\ndependencies. We apply SuBiLSTMs to several tasks that require sentence\nmodeling. We demonstrate that using SuBiLSTM instead of a BiLSTM in existing\nmodels leads to improvements in performance in learning general sentence\nrepresentations, text classification, textual entailment and paraphrase\ndetection. Using SuBiLSTM we achieve new state-of-the-art results for\nfine-grained sentiment classification and question classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:46:25 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 22:16:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1805.07346", "submitter": "Stijn De Waele", "authors": "Stijn de Waele", "title": "Accurate Kernel Learning for Linear Gaussian Markov Processes using a\n  Scalable Likelihood Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report an exact likelihood computation for Linear Gaussian Markov\nprocesses that is more scalable than existing algorithms for complex models and\nsparsely sampled signals. Better scaling is achieved through elimination of\nrepeated computations in the Kalman likelihood, and by using the diagonalized\nform of the state transition equation. Using this efficient computation, we\nstudy the accuracy of kernel learning using maximum likelihood and the\nposterior mean in a simulation experiment. The posterior mean with a reference\nprior is more accurate for complex models and sparse sampling. Because of its\nlower computation load, the maximum likelihood estimator is an attractive\noption for more densely sampled signals and lower order models. We confirm\nestimator behavior in experimental data through their application to speleothem\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:56:58 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["de Waele", "Stijn", ""]]}, {"id": "1805.07349", "submitter": "Amir Khoshaman", "authors": "Amir H. Khoshaman and Mohammad H. Amin", "title": "GumBolt: Extending Gumbel trick to Boltzmann priors", "comments": "10 pages, 2 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines (BMs) are appealing candidates for powerful priors in\nvariational autoencoders (VAEs), as they are capable of capturing nontrivial\nand multi-modal distributions over discrete variables. However,\nnon-differentiability of the discrete units prohibits using the\nreparameterization trick, essential for low-noise back propagation. The Gumbel\ntrick resolves this problem in a consistent way by relaxing the variables and\ndistributions, but it is incompatible with BM priors. Here, we propose the\nGumBolt, a model that extends the Gumbel trick to BM priors in VAEs. GumBolt is\nsignificantly simpler than the recently proposed methods with BM prior and\noutperforms them by a considerable margin. It achieves state-of-the-art\nperformance on permutation invariant MNIST and OMNIGLOT datasets in the scope\nof models with only discrete latent variables. Moreover, the performance can be\nfurther improved by allowing multi-sampled (importance-weighted) estimation of\nlog-likelihood in training, which was not possible with previous models.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:59:17 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 17:30:53 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Khoshaman", "Amir H.", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1805.07376", "submitter": "Daniel McDonald", "authors": "Arash Khodadadi, Daniel J McDonald", "title": "Algorithms for Estimating Trends in Global Temperature Volatility", "comments": "Published in AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trends in terrestrial temperature variability are perhaps more relevant for\nspecies viability than trends in mean temperature. In this paper, we develop\nmethodology for estimating such trends using multi-resolution climate data from\npolar orbiting weather satellites. We derive two novel algorithms for\ncomputation that are tailored for dense, gridded observations over both space\nand time. We evaluate our methods with a simulation that mimics these data's\nfeatures and on a large, publicly available, global temperature dataset with\nthe eventual goal of tracking trends in cloud reflectance temperature\nvariability.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 18:20:52 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 23:46:05 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Khodadadi", "Arash", ""], ["McDonald", "Daniel J", ""]]}, {"id": "1805.07405", "submitter": "Marek Smieja", "authors": "Marek Smieja, {\\L}ukasz Struski, Jacek Tabor, Bartosz Zieli\\'nski,\n  Przemys{\\l}aw Spurek", "title": "Processing of missing data by neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general, theoretically justified mechanism for processing\nmissing data by neural networks. Our idea is to replace typical neuron's\nresponse in the first hidden layer by its expected value. This approach can be\napplied for various types of networks at minimal cost in their modification.\nMoreover, in contrast to recent approaches, it does not require complete data\nfor training. Experimental results performed on different types of\narchitectures show that our method gives better results than typical imputation\nstrategies and other methods dedicated for incomplete data.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 19:18:41 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 04:55:22 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 18:43:51 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Smieja", "Marek", ""], ["Struski", "\u0141ukasz", ""], ["Tabor", "Jacek", ""], ["Zieli\u0144ski", "Bartosz", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "1805.07410", "submitter": "Martin Bertran", "authors": "Martin Bertran, Natalia Martinez, Afroditi Papadaki, Qiang Qiu, Miguel\n  Rodrigues, Guillermo Sapiro", "title": "Learning to Collaborate for User-Controlled Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is becoming increasingly clear that users should own and control their\ndata. Utility providers are also becoming more interested in guaranteeing data\nprivacy. As such, users and utility providers should collaborate in data\nprivacy, a paradigm that has not yet been developed in the privacy research\ncommunity. We introduce this concept and present explicit architectures where\nthe user controls what characteristics of the data she/he wants to share and\nwhat she/he wants to keep private. This is achieved by collaborative learning a\nsensitization function, either a deterministic or a stochastic one, that\nretains valuable information for the utility tasks but it also eliminates\nnecessary information for the privacy ones. As illustration examples, we\nimplement them using a plug-and-play approach, where no algorithm is changed at\nthe system provider end, and an adversarial approach, where minor re-training\nof the privacy inferring engine is allowed. In both cases the learned\nsanitization function keeps the data in the original domain, thereby allowing\nthe system to use the same algorithms it was using before for both original and\nprivatized data. We show how we can maintain utility while fully protecting\nprivate information if the user chooses to do so, even when the first is harder\nthan the second, as in the case here illustrated of identity detection while\nhiding gender.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 19:34:20 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Bertran", "Martin", ""], ["Martinez", "Natalia", ""], ["Papadaki", "Afroditi", ""], ["Qiu", "Qiang", ""], ["Rodrigues", "Miguel", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1805.07412", "submitter": "Sebastian Claici", "authors": "Sebastian Claici and Aude Genevay and Justin Solomon", "title": "Wasserstein Measure Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of large data sets and Bayesian inference techniques\nmotivates demand for better data sparsification. Coresets provide a principled\nway of summarizing a large dataset via a smaller one that is guaranteed to\nmatch the performance of the full data set on specific problems. Classical\ncoresets, however, neglect the underlying data distribution, which is often\ncontinuous. We address this oversight by introducing Wasserstein measure\ncoresets, an extension of coresets which by definition takes into account\ngeneralization. Our formulation of the problem, which essentially consists in\nminimizing the Wasserstein distance, is solvable via stochastic gradient\ndescent. This yields an algorithm which simply requires sample access to the\ndata distribution and is able to handle large data streams in an online manner.\nWe validate our construction for inference and clustering.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 19:41:03 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 22:06:00 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Claici", "Sebastian", ""], ["Genevay", "Aude", ""], ["Solomon", "Justin", ""]]}, {"id": "1805.07418", "submitter": "Benjamin Guedj", "authors": "Benjamin Guedj and Le Li", "title": "Sequential Learning of Principal Curves: Summarizing Data Streams on the\n  Fly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When confronted with massive data streams, summarizing data with dimension\nreduction methods such as PCA raises theoretical and algorithmic pitfalls.\nPrincipal curves act as a nonlinear generalization of PCA and the present paper\nproposes a novel algorithm to automatically and sequentially learn principal\ncurves from data streams. We show that our procedure is supported by regret\nbounds with optimal sublinear remainder terms. A greedy local search\nimplementation (called \\texttt{slpc}, for Sequential Learning Principal Curves)\nthat incorporates both sleeping experts and multi-armed bandit ingredients is\npresented, along with its regret computation and performance on synthetic and\nreal-life data.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 19:49:13 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 20:03:35 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Guedj", "Benjamin", ""], ["Li", "Le", ""]]}, {"id": "1805.07430", "submitter": "Chen-Yu Wei", "authors": "Haipeng Luo, Chen-Yu Wei, Kai Zheng", "title": "Efficient Online Portfolio with Logarithmic Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the decades-old problem of online portfolio management and propose\nthe first algorithm with logarithmic regret that is not based on Cover's\nUniversal Portfolio algorithm and admits much faster implementation.\nSpecifically Universal Portfolio enjoys optimal regret $\\mathcal{O}(N\\ln T)$\nfor $N$ financial instruments over $T$ rounds, but requires log-concave\nsampling and has a large polynomial running time. Our algorithm, on the other\nhand, ensures a slightly larger but still logarithmic regret of\n$\\mathcal{O}(N^2(\\ln T)^4)$, and is based on the well-studied Online Mirror\nDescent framework with a novel regularizer that can be implemented via standard\noptimization methods in time $\\mathcal{O}(TN^{2.5})$ per round. The regret of\nall other existing works is either polynomial in $T$ or has a potentially\nunbounded factor such as the inverse of the smallest price relative.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:29:02 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 00:39:47 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""], ["Zheng", "Kai", ""]]}, {"id": "1805.07431", "submitter": "Chai Wah Wu", "authors": "Chai Wah Wu", "title": "Can machine learning identify interesting mathematics? An exploration\n  using empirically observed laws", "comments": "9 pages, minor edits and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the possibility of using machine learning to identify interesting\nmathematical structures by using certain quantities that serve as fingerprints.\nIn particular, we extract features from integer sequences using two empirical\nlaws: Benford's law and Taylor's law and experiment with various classifiers to\nidentify whether a sequence is, for example, nice, important, multiplicative,\neasy to compute or related to primes or palindromes.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:32:03 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 22:17:07 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 01:45:24 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wu", "Chai Wah", ""]]}, {"id": "1805.07438", "submitter": "Alejandro Frery", "authors": "R. G. Negri and A. C. Frery and W. B. Silva and T. S. G. Mendes and L.\n  V. Dutra", "title": "Region-Based Classification of PolSAR Data Using Radial Basis Kernel\n  Functions With Stochastic Distances", "comments": "Accepted for publication in the International Journal of Digital\n  Earth", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Region-based classification of PolSAR data can be effectively performed by\nseeking for the assignment that minimizes a distance between prototypes and\nsegments. Silva et al (2013) used stochastic distances between complex\nmultivariate Wishart models which, differently from other measures, are\ncomputationally tractable. In this work we assess the robustness of such\napproach with respect to errors in the training stage, and propose an extension\nthat alleviates such problems. We introduce robustness in the process by\nincorporating a combination of radial basis kernel functions and stochastic\ndistances with Support Vector Machines (SVM). We consider several stochastic\ndistances between Wishart: Bhatacharyya, Kullback-Leibler, Chi-Square,\nR\\'{e}nyi, and Hellinger. We perform two case studies with PolSAR images, both\nsimulated and from actual sensors, and different classification scenarios to\ncompare the performance of Minimum Distance and SVM classification frameworks.\nWith this, we model the situation of imperfect training samples. We show that\nSVM with the proposed kernel functions achieves better performance with respect\nto Minimum Distance, at the expense of more computational resources and the\nneed of parameter tuning. Code and data are provided for reproducibility.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 19:23:07 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Negri", "R. G.", ""], ["Frery", "A. C.", ""], ["Silva", "W. B.", ""], ["Mendes", "T. S. G.", ""], ["Dutra", "L. V.", ""]]}, {"id": "1805.07440", "submitter": "Linnan Wang", "authors": "Linnan Wang, Yiyang Zhao, Yuu Jinnai, Yuandong Tian, Rodrigo Fonseca", "title": "Neural Architecture Search using Deep Neural Networks and Monte Carlo\n  Tree Search", "comments": "To appear in the Thirty-Fourth AAAI conference on Artificial\n  Intelligence (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has shown great success in automating the\ndesign of neural networks, but the prohibitive amount of computations behind\ncurrent NAS methods requires further investigations in improving the sample\nefficiency and the network evaluation cost to get better results in a shorter\ntime. In this paper, we present a novel scalable Monte Carlo Tree Search (MCTS)\nbased NAS agent, named AlphaX, to tackle these two aspects. AlphaX improves the\nsearch efficiency by adaptively balancing the exploration and exploitation at\nthe state level, and by a Meta-Deep Neural Network (DNN) to predict network\naccuracies for biasing the search toward a promising region. To amortize the\nnetwork evaluation cost, AlphaX accelerates MCTS rollouts with a distributed\ndesign and reduces the number of epochs in evaluating a network by transfer\nlearning, which is guided with the tree structure in MCTS. In 12 GPU days and\n1000 samples, AlphaX found an architecture that reaches 97.84\\% top-1 accuracy\non CIFAR-10, and 75.5\\% top-1 accuracy on ImageNet, exceeding SOTA NAS methods\nin both the accuracy and sampling efficiency. Particularly, we also evaluate\nAlphaX on NASBench-101, a large scale NAS dataset; AlphaX is 3x and 2.8x more\nsample efficient than Random Search and Regularized Evolution in finding the\nglobal optimum. Finally, we show the searched architecture improves a variety\nof vision applications from Neural Style Transfer, to Image Captioning and\nObject Detection.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:57:41 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 07:47:47 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 06:50:28 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 01:04:05 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 17:45:31 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wang", "Linnan", ""], ["Zhao", "Yiyang", ""], ["Jinnai", "Yuu", ""], ["Tian", "Yuandong", ""], ["Fonseca", "Rodrigo", ""]]}, {"id": "1805.07441", "submitter": "Shixian Wen", "authors": "Shixian Wen and Laurent Itti", "title": "Overcoming catastrophic forgetting problem by weight consolidation and\n  long-term memory", "comments": "for Conference on Neural Information Processing Systems 2018\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential learning of multiple tasks in artificial neural networks using\ngradient descent leads to catastrophic forgetting, whereby previously learned\nknowledge is erased during learning of new, disjoint knowledge. Here, we\npropose a new approach to sequential learning which leverages the recent\ndiscovery of adversarial examples. We use adversarial subspaces from previous\ntasks to enable learning of new tasks with less interference. We apply our\nmethod to sequentially learning to classify digits 0, 1, 2 (task 1), 4, 5, 6,\n(task 2), and 7, 8, 9 (task 3) in MNIST (disjoint MNIST task). We compare and\ncombine our Adversarial Direction (AD) method with the recently proposed\nElastic Weight Consolidation (EWC) method for sequential learning. We train\neach task for 20 epochs, which yields good initial performance (99.24% correct\ntask 1 performance). After training task 2, and then task 3, both plain\ngradient descent (PGD) and EWC largely forget task 1 (task 1 accuracy 32.95%\nfor PGD and 41.02% for EWC), while our combined approach (AD+EWC) still\nachieves 94.53% correct on task 1. We obtain similar results with a much more\ndifficult disjoint CIFAR10 task, which to our knowledge had not been attempted\nbefore (70.10% initial task 1 performance, 67.73% after learning tasks 2 and 3\nfor AD+EWC, while PGD and EWC both fall to chance level). Our results suggest\nthat AD+EWC can provide better sequential learning performance than either PGD\nor EWC.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:01:12 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Wen", "Shixian", ""], ["Itti", "Laurent", ""]]}, {"id": "1805.07443", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Multi-view Sentence Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning can provide self-supervision when different views are\navailable of the same data. The distributional hypothesis provides another form\nof useful self-supervision from adjacent sentences which are plentiful in large\nunlabelled corpora. Motivated by the asymmetry in the two hemispheres of the\nhuman brain as well as the observation that different learning architectures\ntend to emphasise different aspects of sentence meaning, we create a unified\nmulti-view sentence representation learning framework, in which, one view\nencodes the input sentence with a Recurrent Neural Network (RNN), and the other\nview encodes it with a simple linear model, and the training objective is to\nmaximise the agreement specified by the adjacent context information between\ntwo views. We show that, after training, the vectors produced from our\nmulti-view training provide improved representations over the single-view\ntraining, and the combination of different views gives further representational\nimprovement and demonstrates solid transferability on standard downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:04:08 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1805.07445", "submitter": "Arash Vahdat", "authors": "Arash Vahdat, Evgeny Andriyash, William G. Macready", "title": "DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors", "comments": "Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines are powerful distributions that have been shown to be an\neffective prior over binary latent variables in variational autoencoders\n(VAEs). However, previous methods for training discrete VAEs have used the\nevidence lower bound and not the tighter importance-weighted bound. We propose\ntwo approaches for relaxing Boltzmann machines to continuous distributions that\npermit training with importance-weighted bounds. These relaxations are based on\ngeneralized overlapping transformations and the Gaussian integral trick.\nExperiments on the MNIST and OMNIGLOT datasets show that these relaxations\noutperform previous discrete VAEs with Boltzmann priors. An implementation\nwhich reproduces these results is available at\nhttps://github.com/QuadrantAI/dvae .\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:11:58 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 23:56:38 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 17:25:51 GMT"}, {"version": "v4", "created": "Mon, 15 Oct 2018 18:16:27 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Vahdat", "Arash", ""], ["Andriyash", "Evgeny", ""], ["Macready", "William G.", ""]]}, {"id": "1805.07451", "submitter": "Yingzhou Li", "authors": "Yingzhou Li, Xiuyuan Cheng, Jianfeng Lu", "title": "Butterfly-Net: Optimal Function Representation Based on Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks, especially convolutional neural networks (CNNs), have been\nsuccessfully applied in various areas of machine learning as well as to\nchallenging problems in other scientific and engineering fields. This paper\nintroduces Butterfly-Net, a low-complexity CNN with structured and sparse\ncross-channel connections, together with a Butterfly initialization strategy\nfor a family of networks. Theoretical analysis of the approximation power of\nButterfly-Net to the Fourier representation of input data shows that the error\ndecays exponentially as the depth increases. Combining Butterfly-Net with a\nfully connected neural network, a large class of problems are proved to be well\napproximated with network complexity depending on the effective frequency\nbandwidth instead of the input dimension. Regular CNN is covered as a special\ncase in our analysis. Numerical experiments validate the analytical results on\nthe approximation of Fourier kernels and energy functionals of Poisson's\nequations. Moreover, all experiments support that training from Butterfly\ninitialization outperforms training from random initialization. Also, adding\nthe remaining cross-channel connections, although significantly increase the\nparameter number, does not much improve the post-training accuracy and is more\nsensitive to data distribution.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:36:25 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 02:49:05 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 14:41:21 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 21:28:04 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Li", "Yingzhou", ""], ["Cheng", "Xiuyuan", ""], ["Lu", "Jianfeng", ""]]}, {"id": "1805.07454", "submitter": "Song Liu Dr.", "authors": "Song Liu, Takafumi Kanamori, Wittawat Jitkrittum, Yu Chen", "title": "Fisher Efficient Inference of Intractable Models", "comments": "Fixed typos in the text. To appear in Neural Information Process 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Likelihood Estimators (MLE) has many good properties. For example,\nthe asymptotic variance of MLE solution attains equality of the asymptotic\nCram{\\'e}r-Rao lower bound (efficiency bound), which is the minimum possible\nvariance for an unbiased estimator. However, obtaining such MLE solution\nrequires calculating the likelihood function which may not be tractable due to\nthe normalization term of the density model. In this paper, we derive a\nDiscriminative Likelihood Estimator (DLE) from the Kullback-Leibler divergence\nminimization criterion implemented via density ratio estimation and a Stein\noperator. We study the problem of model inference using DLE. We prove its\nconsistency and show that the asymptotic variance of its solution can attain\nthe equality of the efficiency bound under mild regularity conditions. We also\npropose a dual formulation of DLE which can be easily optimized. Numerical\nstudies validate our asymptotic theorems and we give an example where DLE\nsuccessfully estimates an intractable model constructed using a pre-trained\ndeep neural network.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:48:35 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 00:19:52 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 14:06:21 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 09:13:20 GMT"}, {"version": "v5", "created": "Fri, 1 Nov 2019 18:47:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Song", ""], ["Kanamori", "Takafumi", ""], ["Jitkrittum", "Wittawat", ""], ["Chen", "Yu", ""]]}, {"id": "1805.07458", "submitter": "Bianca Dumitrascu", "authors": "Bianca Dumitrascu, Karen Feng, and Barbara E Engelhardt", "title": "PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of regret minimization in logistic contextual bandits,\nwhere a learner decides among sequential actions or arms given their respective\ncontexts to maximize binary rewards. Using a fast inference procedure with\nPolya-Gamma distributed augmentation variables, we propose an improved version\nof Thompson Sampling, a Bayesian formulation of contextual bandits with\nnear-optimal performance. Our approach, Polya-Gamma augmented Thompson Sampling\n(PG-TS), achieves state-of-the-art performance on simulated and real data.\nPG-TS explores the action space efficiently and exploits high-reward arms,\nquickly converging to solutions of low regret. Its explicit estimation of the\nposterior distribution of the context feature covariance leads to substantial\nempirical gains over approximate approaches. PG-TS is the first approach to\ndemonstrate the benefits of Polya-Gamma augmentation in bandits and to propose\nan efficient Gibbs sampler for approximating the analytically unsolvable\nintegral of logistic contextual bandits.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 22:06:38 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Dumitrascu", "Bianca", ""], ["Feng", "Karen", ""], ["Engelhardt", "Barbara E", ""]]}, {"id": "1805.07460", "submitter": "Cristian Guarnizo", "authors": "Cristian Guarnizo and Mauricio A. \\'Alvarez", "title": "Fast Kernel Approximations for Latent Force Models and Convolved\n  Multiple-Output Gaussian processes", "comments": "10 pages, 4 figures, corrected some typos", "journal-ref": "Conference on Uncertainty in Artificial Intelligence (UAI), 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A latent force model is a Gaussian process with a covariance function\ninspired by a differential operator. Such covariance function is obtained by\nperforming convolution integrals between Green's functions associated to the\ndifferential operators, and covariance functions associated to latent\nfunctions. In the classical formulation of latent force models, the covariance\nfunctions are obtained analytically by solving a double integral, leading to\nexpressions that involve numerical solutions of different types of error\nfunctions. In consequence, the covariance matrix calculation is considerably\nexpensive, because it requires the evaluation of one or more of these error\nfunctions. In this paper, we use random Fourier features to approximate the\nsolution of these double integrals obtaining simpler analytical expressions for\nsuch covariance functions. We show experimental results using ordinary\ndifferential operators and provide an extension to build general kernel\nfunctions for convolved multiple output Gaussian processes.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 22:31:40 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 03:10:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Guarnizo", "Cristian", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1805.07468", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Yu Yang, Yuchen Liu, Ying Nian Wu, Song-Chun Zhu", "title": "Unsupervised Learning of Neural Networks to Explain Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised method to learn a neural network, namely\nan explainer, to interpret a pre-trained convolutional neural network (CNN),\ni.e., explaining knowledge representations hidden in middle conv-layers of the\nCNN. Given feature maps of a certain conv-layer of the CNN, the explainer\nperforms like an auto-encoder, which first disentangles the feature maps into\nobject-part features and then inverts object-part features back to features of\nhigher conv-layers of the CNN. More specifically, the explainer contains\ninterpretable conv-layers, where each filter disentangles the representation of\na specific object part from chaotic input feature maps. As a paraphrase of CNN\nfeatures, the disentangled representations of object parts help people\nunderstand the logic inside the CNN. We also learn the explainer to use\nobject-part features to reconstruct features of higher CNN layers, in order to\nminimize loss of information during the feature disentanglement. More\ncrucially, we learn the explainer via network distillation without using any\nannotations of sample labels, object parts, or textures for supervision. We\nhave applied our method to different types of CNNs for evaluation, and\nexplainers have significantly boosted the interpretability of CNN features.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:02:14 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Quanshi", ""], ["Yang", "Yu", ""], ["Liu", "Yuchen", ""], ["Wu", "Ying Nian", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1805.07473", "submitter": "Yuhong Guo", "authors": "Meng Ye and Yuhong Guo", "title": "Progressive Ensemble Networks for Zero-Shot Recognition", "comments": "CVPR19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advancement of supervised image recognition algorithms, their\ndependence on the availability of labeled data and the rapid expansion of image\ncategories raise the significant challenge of zero-shot learning. Zero-shot\nlearning (ZSL) aims to transfer knowledge from labeled classes into unlabeled\nclasses to reduce human labeling effort. In this paper, we propose a novel\nprogressive ensemble network model with multiple projected label embeddings to\naddress zero-shot image recognition. The ensemble network is built by learning\nmultiple image classification functions with a shared feature extraction\nnetwork but different label embedding representations, which enhance the\ndiversity of the classifiers and facilitate information transfer to unlabeled\nclasses. A progressive training framework is then deployed to gradually label\nthe most confident images in each unlabeled class with predicted pseudo-labels\nand update the ensemble network with the training data augmented by the\npseudo-labels. The proposed model performs training on both labeled and\nunlabeled data. It can naturally bridge the domain shift problem in visual\nappearances and be extended to the generalized zero-shot learning scenario. We\nconduct experiments on multiple ZSL datasets and the empirical results\ndemonstrate the efficacy of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:24:12 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 22:07:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Ye", "Meng", ""], ["Guo", "Yuhong", ""]]}, {"id": "1805.07474", "submitter": "Lin Chen", "authors": "Lin Chen, Mingrui Zhang, Amin Karbasi", "title": "Projection-Free Bandit Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the first computationally efficient projection-free\nalgorithm for bandit convex optimization (BCO). We show that our algorithm\nachieves a sublinear regret of $O(nT^{4/5})$ (where $T$ is the horizon and $n$\nis the dimension) for any bounded convex functions with uniformly bounded\ngradients. We also evaluate the performance of our algorithm against baselines\non both synthetic and real data sets for quadratic programming, portfolio\nselection and matrix completion problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:29:24 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 00:24:32 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chen", "Lin", ""], ["Zhang", "Mingrui", ""], ["Karbasi", "Amin", ""]]}, {"id": "1805.07475", "submitter": "Jacob Harer", "authors": "Jacob Harer, Onur Ozdemir, Tomo Lazovich, Christopher P. Reale,\n  Rebecca L. Russell, Louis Y. Kim, Peter Chin", "title": "Learning to Repair Software Vulnerabilities with Generative Adversarial\n  Networks", "comments": "Presented at 32nd Conference on Neural Information Processing Systems\n  (nips 2018), Montreal Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of automated repair of software vulnerabilities, we\npropose an adversarial learning approach that maps from one discrete source\ndomain to another target domain without requiring paired labeled examples or\nsource and target domains to be bijections. We demonstrate that the proposed\nadversarial learning approach is an effective technique for repairing software\nvulnerabilities, performing close to seq2seq approaches that require labeled\npairs. The proposed Generative Adversarial Network approach is\napplication-agnostic in that it can be applied to other problems similar to\ncode repair, such as grammar correction or sentiment translation.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:31:03 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 16:09:33 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 18:22:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Harer", "Jacob", ""], ["Ozdemir", "Onur", ""], ["Lazovich", "Tomo", ""], ["Reale", "Christopher P.", ""], ["Russell", "Rebecca L.", ""], ["Kim", "Louis Y.", ""], ["Chin", "Peter", ""]]}, {"id": "1805.07476", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Huizhen Yu, Banafsheh Rafiee, Richard S. Sutton", "title": "Two geometric input transformation methods for fast online reinforcement\n  learning with neural nets", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply neural nets with ReLU gates in online reinforcement learning. Our\ngoal is to train these networks in an incremental manner, without the\ncomputationally expensive experience replay. By studying how individual neural\nnodes behave in online training, we recognize that the global nature of ReLU\ngates can cause undesirable learning interference in each node's learning\nbehavior. We propose reducing such interferences with two efficient input\ntransformation methods that are geometric in nature and match well the\ngeometric property of ReLU gates. The first one is tile coding, a classic\nbinary encoding scheme originally designed for local generalization based on\nthe topological structure of the input space. The second one (EmECS) is a new\nmethod we introduce; it is based on geometric properties of convex sets and\ntopological embedding of the input space into the boundary of a convex set. We\ndiscuss the behavior of the network when it operates on the transformed inputs.\nWe also compare it experimentally with some neural nets that do not use the\nsame input transformations, and with the classic algorithm of tile coding plus\na linear function approximator, and on several online reinforcement learning\ntasks, we show that the neural net with tile coding or EmECS can achieve not\nonly faster learning but also more accurate approximations. Our results\nstrongly suggest that geometric input transformation of this type can be\neffective for interference reduction and takes us a step closer to fully\nincremental reinforcement learning with neural nets.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:35:14 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 21:09:44 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ghiassian", "Sina", ""], ["Yu", "Huizhen", ""], ["Rafiee", "Banafsheh", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1805.07479", "submitter": "Cheng Ju", "authors": "Cheng Ju, James Li, Bram Wasti, Shengbo Guo", "title": "Semisupervised Learning on Heterogeneous Graphs and its Applications to\n  Facebook News Feed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based semi-supervised learning is a fundamental machine learning\nproblem, and has been well studied. Most studies focus on homogeneous networks\n(e.g. citation network, friend network). In the present paper, we propose the\nHeterogeneous Embedding Label Propagation (HELP) algorithm, a graph-based\nsemi-supervised deep learning algorithm, for graphs that are characterized by\nheterogeneous node types. Empirically, we demonstrate the effectiveness of this\nmethod in domain classification tasks with Facebook user-domain interaction\ngraph, and compare the performance of the proposed HELP algorithm with the\nstate of the art algorithms. We show that the HELP algorithm improves the\npredictive performance across multiple tasks, together with semantically\nmeaningful embedding that are discriminative for downstream classification or\nregression tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:58:07 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 02:20:50 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Ju", "Cheng", ""], ["Li", "James", ""], ["Wasti", "Bram", ""], ["Guo", "Shengbo", ""]]}, {"id": "1805.07482", "submitter": "Yatao An Bian", "authors": "An Bian, Joachim M. Buhmann, Andreas Krause", "title": "Optimal DR-Submodular Maximization and Applications to Provable Mean\n  Field Inference", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field inference in probabilistic models is generally a highly nonconvex\nproblem. Existing optimization methods, e.g., coordinate ascent algorithms, can\nonly generate local optima.\n  In this work we propose provable mean filed methods for probabilistic\nlog-submodular models and its posterior agreement (PA) with strong\napproximation guarantees. The main algorithmic technique is a new Double Greedy\nscheme, termed DR-DoubleGreedy, for continuous DR-submodular maximization with\nbox-constraints. It is a one-pass algorithm with linear time complexity,\nreaching the optimal 1/2 approximation ratio, which may be of independent\ninterest. We validate the superior performance of our algorithms against\nbaseline algorithms on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 00:22:10 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 20:55:42 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Bian", "An", ""], ["Buhmann", "Joachim M.", ""], ["Krause", "Andreas", ""]]}, {"id": "1805.07483", "submitter": "Julaiti Alafate", "authors": "Julaiti Alafate, Yoav Freund", "title": "Tell Me Something New: A New Framework for Asynchronous Parallel\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for parallel computation in the context of\nmachine learning that we call \"Tell Me Something New\" (TMSN). This approach\ninvolves a set of independent workers that use broadcast to update each other\nwhen they observe \"something new\". TMSN does not require synchronization or a\nhead node and is highly resilient against failing machines or laggards. We\ndemonstrate the utility of TMSN by applying it to learning boosted trees. We\nshow that our implementation is 10 times faster than XGBoost and LightGBM on\nthe splice-site prediction problem.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 00:36:04 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:51:32 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Alafate", "Julaiti", ""], ["Freund", "Yoav", ""]]}, {"id": "1805.07489", "submitter": "Alexandre Marques", "authors": "Alexandre N. Marques and Remi R. Lam and Karen E. Willcox", "title": "Contour location via entropy reduction leveraging multiple information\n  sources", "comments": null, "journal-ref": "NeurIPS 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.OC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm to locate contours of functions that are expensive\nto evaluate. The problem of locating contours arises in many applications,\nincluding classification, constrained optimization, and performance analysis of\nmechanical and dynamical systems (reliability, probability of failure,\nstability, etc.). Our algorithm locates contours using information from\nmultiple sources, which are available in the form of relatively inexpensive,\nbiased, and possibly noisy approximations to the original function. Considering\nmultiple information sources can lead to significant cost savings. We also\nintroduce the concept of contour entropy, a formal measure of uncertainty about\nthe location of the zero contour of a function approximated by a statistical\nsurrogate model. Our algorithm locates contours efficiently by maximizing the\nreduction of contour entropy per unit cost.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 01:36:43 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:41:15 GMT"}, {"version": "v3", "created": "Wed, 19 Dec 2018 15:08:49 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Marques", "Alexandre N.", ""], ["Lam", "Remi R.", ""], ["Willcox", "Karen E.", ""]]}, {"id": "1805.07500", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Fisher B. Gouza", "title": "GADAM: Genetic-Evolutionary ADAM for Deep Neural Network Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network learning can be formulated as a non-convex optimization\nproblem. Existing optimization algorithms, e.g., Adam, can learn the models\nfast, but may get stuck in local optima easily. In this paper, we introduce a\nnovel optimization algorithm, namely GADAM (Genetic-Evolutionary Adam). GADAM\nlearns deep neural network models based on a number of unit models generations\nby generations: it trains the unit models with Adam, and evolves them to the\nnew generations with genetic algorithm. We will show that GADAM can effectively\njump out of the local optima in the learning process to obtain better\nsolutions, and prove that GADAM can also achieve a very fast convergence.\nExtensive experiments have been done on various benchmark datasets, and the\nlearning results will demonstrate the effectiveness and efficiency of the GADAM\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:16:44 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 03:37:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Jiawei", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07502", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "On Deep Ensemble Learning from a Function Approximation Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to provide a general ensemble learning framework\nbased on deep learning models. Given a group of unit models, the proposed deep\nensemble learning framework will effectively combine their learning results via\na multilayered ensemble model. In the case when the unit model mathematical\nmappings are bounded, sigmoidal and discriminatory, we demonstrate that the\ndeep ensemble learning framework can achieve a universal approximation of any\nfunctions from the input space to the output space. Meanwhile, to achieve such\na performance, the deep ensemble learning framework also impose a strict\nconstraint on the number of involved unit models. According to the theoretic\nproof provided in this paper, given the input feature space of dimension d, the\nrequired unit model number will be 2d, if the ensemble model involves one\nsingle layer. Furthermore, as the ensemble component goes deeper, the number of\nrequired unit model is proved to be lowered down exponentially.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:25:30 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07504", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Deep Loopy Neural Network Model for Graph Structured Data Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep learning models may encounter great challenges in handling\ngraph structured data. In this paper, we introduce a new deep learning model\nfor graph data specifically, namely the deep loopy neural network.\nSignificantly different from the previous deep models, inside the deep loopy\nneural network, there exist a large number of loops created by the extensive\nconnections among nodes in the input graph data, which makes model learning an\ninfeasible task. To resolve such a problem, in this paper, we will introduce a\nnew learning algorithm for the deep loopy neural network specifically. Instead\nof learning the model variables based on the original model, in the proposed\nlearning algorithm, errors will be back-propagated through the edges in a group\nof extracted spanning trees. Extensive numerical experiments have been done on\nseveral real-world graph datasets, and the experimental results demonstrate the\neffectiveness of both the proposed model and the learning algorithm in handling\ngraph data.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:33:20 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 17:45:22 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1805.07507", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "Reconciled Polynomial Machine: A Unified Representation of Shallow and\n  Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at introducing a new machine learning model, namely\nreconciled polynomial machine, which can provide a unified representation of\nexisting shallow and deep machine learning models. Reconciled polynomial\nmachine predicts the output by computing the inner product of the feature\nkernel function and variable reconciling function. Analysis of several concrete\nmodels, including Linear Models, FM, MVM, Perceptron, MLP and Deep Neural\nNetworks, will be provided in this paper, which can all be reduced to the\nreconciled polynomial machine representations. Detailed analysis of the\nlearning error by these models will also be illustrated in this paper based on\ntheir reduced representations from the function approximation perspective.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:40:52 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07508", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "GEN Model: An Alternative Approach to Deep Neural Network Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.08631", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an alternative approach, namely GEN (Genetic\nEvolution Network) Model, to the deep learning models. Instead of building one\nsingle deep model, GEN adopts a genetic-evolutionary learning strategy to build\na group of unit models generations by generations. Significantly different from\nthe wellknown representation learning models with extremely deep structures,\nthe unit models covered in GEN are of a much shallower architecture. In the\ntraining process, from each generation, a subset of unit models will be\nselected based on their performance to evolve and generate the child models in\nthe next generation. GEN has significant advantages compared with existing deep\nrepresentation learning models in terms of both learning effectiveness,\nefficiency and interpretability of the learning process and learned results.\nExtensive experiments have been done on diverse benchmark datasets, and the\nexperimental results have demonstrated the outstanding performance of GEN\ncompared with the state-of-the-art baseline methods in both effectiveness of\nefficiency.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:48:26 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07513", "submitter": "Mo Yu", "authors": "Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng,\n  Gerald Tesauro, Haoyu Wang, Bowen Zhou", "title": "Diverse Few-Shot Text Classification with Multiple Metrics", "comments": "NAACL 2018. 11+5 pages. arXiv admin note: text overlap with\n  arXiv:1708.07918", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study few-shot learning in natural language domains. Compared to many\nexisting works that apply either metric-based or optimization-based\nmeta-learning to image domain with low inter-task variance, we consider a more\nrealistic setting, where tasks are diverse. However, it imposes tremendous\ndifficulties to existing state-of-the-art metric-based algorithms since a\nsingle metric is insufficient to capture complex task variations in natural\nlanguage domain. To alleviate the problem, we propose an adaptive metric\nlearning approach that automatically determines the best weighted combination\nfrom a set of metrics obtained from meta-training tasks for a newly seen\nfew-shot task. Extensive quantitative evaluations on real-world sentiment\nanalysis and dialog intent classification datasets demonstrate that the\nproposed method performs favorably against state-of-the-art few shot learning\nalgorithms in terms of predictive accuracy. We make our code and data available\nfor further study.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 04:45:04 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Yi", "Jinfeng", ""], ["Chang", "Shiyu", ""], ["Potdar", "Saloni", ""], ["Cheng", "Yu", ""], ["Tesauro", "Gerald", ""], ["Wang", "Haoyu", ""], ["Zhou", "Bowen", ""]]}, {"id": "1805.07516", "submitter": "Takeru Matsuda", "authors": "Takeru Matsuda and Aapo Hyvarinen", "title": "Estimation of Non-Normalized Mixture Models and Clustering Using Deep\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general method for estimating a finite mixture of non-normalized\nmodels. Here, a non-normalized model is defined to be a parametric distribution\nwith an intractable normalization constant. Existing methods for estimating\nnon-normalized models without computing the normalization constant are not\napplicable to mixture models because they contain more than one intractable\nnormalization constant. The proposed method is derived by extending noise\ncontrastive estimation (NCE), which estimates non-normalized models by\ndiscriminating between the observed data and some artificially generated noise.\nWe also propose an extension of NCE with multiple noise distributions. Then,\nbased on the observation that conventional classification learning with neural\nnetworks is implicitly assuming an exponential family as a generative model, we\nintroduce a method for clustering unlabeled data by estimating a finite mixture\nof distributions in an exponential family. Estimation of this mixture model is\nattained by the proposed extensions of NCE where the training data of neural\nnetworks are used as noise. Thus, the proposed method provides a\nprobabilistically principled clustering method that is able to utilize a deep\nrepresentation. Application to image clustering using a deep neural network\ngives promising results.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 05:15:12 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Matsuda", "Takeru", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1805.07517", "submitter": "Sho Sonoda Dr", "authors": "Sho Sonoda, Isao Ishikawa, Masahiro Ikeda, Kei Hagihara, Yoshihiro\n  Sawano, Takuo Matsubara, Noboru Murata", "title": "The global optimum of shallow neural network is attained by ridgelet\n  transform", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the global minimum of the backpropagation (BP) training problem\nof neural networks with an arbitrary nonlinear activation is given by the\nridgelet transform. A series of computational experiments show that there\nexists an interesting similarity between the scatter plot of hidden parameters\nin a shallow neural network after the BP training and the spectrum of the\nridgelet transform. By introducing a continuous model of neural networks, we\nreduce the training problem to a convex optimization in an infinite dimensional\nHilbert space, and obtain the explicit expression of the global optimizer via\nthe ridgelet transform.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 05:28:50 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 05:36:09 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 07:27:12 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Sonoda", "Sho", ""], ["Ishikawa", "Isao", ""], ["Ikeda", "Masahiro", ""], ["Hagihara", "Kei", ""], ["Sawano", "Yoshihiro", ""], ["Matsubara", "Takuo", ""], ["Murata", "Noboru", ""]]}, {"id": "1805.07541", "submitter": "Yu Zhang", "authors": "Yu Zhang, Ying Wei, Qiang Yang", "title": "Learning to Multitask", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning has shown promising performance in many applications and\nmany multitask models have been proposed. In order to identify an effective\nmultitask model for a given multitask problem, we propose a learning framework\ncalled learning to multitask (L2MT). To achieve the goal, L2MT exploits\nhistorical multitask experience which is organized as a training set consists\nof several tuples, each of which contains a multitask problem with multiple\ntasks, a multitask model, and the relative test error. Based on such training\nset, L2MT first uses a proposed layerwise graph neural network to learn task\nembeddings for all the tasks in a multitask problem and then learns an\nestimation function to estimate the relative test error based on task\nembeddings and the representation of the multitask model based on a unified\nformulation. Given a new multitask problem, the estimation function is used to\nidentify a suitable multitask model. Experiments on benchmark datasets show the\neffectiveness of the proposed L2MT framework.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 08:07:30 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Yu", ""], ["Wei", "Ying", ""], ["Yang", "Qiang", ""]]}, {"id": "1805.07544", "submitter": "Bo Kang", "authors": "Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "Conditional Network Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Embeddings (NEs) map the nodes of a given network into\n$d$-dimensional Euclidean space $\\mathbb{R}^d$. Ideally, this mapping is such\nthat `similar' nodes are mapped onto nearby points, such that the NE can be\nused for purposes such as link prediction (if `similar' means being `more\nlikely to be connected') or classification (if `similar' means `being more\nlikely to have the same label'). In recent years various methods for NE have\nbeen introduced, all following a similar strategy: defining a notion of\nsimilarity between nodes (typically some distance measure within the network),\na distance measure in the embedding space, and a loss function that penalizes\nlarge distances for similar nodes and small distances for dissimilar nodes.\n  A difficulty faced by existing methods is that certain networks are\nfundamentally hard to embed due to their structural properties: (approximate)\nmultipartiteness, certain degree distributions, assortativity, etc. To overcome\nthis, we introduce a conceptual innovation to the NE literature and propose to\ncreate \\emph{Conditional Network Embeddings} (CNEs); embeddings that maximally\nadd information with respect to given structural properties (e.g. node degrees,\nblock densities, etc.). We use a simple Bayesian approach to achieve this, and\npropose a block stochastic gradient descent algorithm for fitting it\nefficiently. We demonstrate that CNEs are superior for link prediction and\nmulti-label classification when compared to state-of-the-art methods, and this\nwithout adding significant mathematical or computational complexity. Finally,\nwe illustrate the potential of CNE for network visualization.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 08:12:29 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 08:36:26 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2018 15:18:21 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "1805.07557", "submitter": "Haiwen Huang", "authors": "Haiwen Huang, Chang Wang and Bin Dong", "title": "Nostalgic Adam: Weighting more of the past gradients when designing the\n  adaptive learning rate", "comments": "17 pages and 7 figures", "journal-ref": null, "doi": "10.24963/ijcai.2019/355", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order optimization algorithms have been proven prominent in deep\nlearning. In particular, algorithms such as RMSProp and Adam are extremely\npopular. However, recent works have pointed out the lack of ``long-term memory\"\nin Adam-like algorithms, which could hamper their performance and lead to\ndivergence. In our study, we observe that there are benefits of weighting more\nof the past gradients when designing the adaptive learning rate. We therefore\npropose an algorithm called the Nostalgic Adam (NosAdam) with theoretically\nguaranteed convergence at the best known convergence rate. NosAdam can be\nregarded as a fix to the non-convergence issue of Adam in alternative to the\nrecent work of [Reddi et al., 2018]. Our preliminary numerical experiments show\nthat NosAdam is a promising alternative algorithm to Adam. The proofs, code and\nother supplementary materials can be found in an anonymously shared link.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 09:37:05 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 06:56:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Huang", "Haiwen", ""], ["Wang", "Chang", ""], ["Dong", "Bin", ""]]}, {"id": "1805.07561", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili, Kayhan Behdin, Mohammad Amin Fakharian, Farokh\n  Marvasti", "title": "Transduction with Matrix Completion Using Smoothed Rank Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two new algorithms for transduction with Matrix\nCompletion (MC) problem. The joint MC and prediction tasks are addressed\nsimultaneously to enhance the accuracy, i.e., the label matrix is concatenated\nto the data matrix forming a stacked matrix. Assuming the data matrix is of low\nrank, we propose new recommendation methods by posing the problem as a\nconstrained minimization of the Smoothed Rank Function (SRF). We provide\nconvergence analysis for the proposed algorithms. The simulations are conducted\non real datasets in two different scenarios of randomly missing pattern with\nand without block loss. The results confirm that the accuracy of our proposed\nmethods outperforms those of state-of-the-art methods even up to 10% in low\nobservation rates for the scenario without block loss. Our accuracy in the\nlatter scenario, is comparable to state-of-the-art methods while the complexity\nof the proposed algorithms are reduced up to 4 times.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 09:50:16 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Behdin", "Kayhan", ""], ["Fakharian", "Mohammad Amin", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1805.07563", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Josef Urban, Henryk Michalewski, Mirek Ol\\v{s}\\'ak", "title": "Reinforcement Learning of Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theorem proving algorithm that uses practically no domain\nheuristics for guiding its connection-style proof search. Instead, it runs many\nMonte-Carlo simulations guided by reinforcement learning from previous proof\nattempts. We produce several versions of the prover, parameterized by different\nlearning and guiding algorithms. The strongest version of the system is trained\non a large corpus of mathematical problems and evaluated on previously unseen\nproblems. The trained system solves within the same number of inferences over\n40% more problems than a baseline prover, which is an unusually high\nimprovement in this hard AI domain. To our knowledge this is the first time\nreinforcement learning has been convincingly applied to solving general\nmathematical problems on a large scale.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 10:05:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Michalewski", "Henryk", ""], ["Ol\u0161\u00e1k", "Mirek", ""]]}, {"id": "1805.07569", "submitter": "Hannes Rapp", "authors": "Hannes Rapp, Martin Paul Nawrot, Merav Stern", "title": "Reliable counting of weakly labeled concepts by a single spiking neuron\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making an informed, correct and quick decision can be life-saving. It's\ncrucial for animals during an escape behaviour or for autonomous cars during\ndriving. The decision can be complex and may involve an assessment of the\namount of threats present and the nature of each threat. Thus, we should expect\nearly sensory processing to supply classification information fast and\naccurately, even before relying the information to higher brain areas or more\ncomplex system components downstream. Today, advanced convolutional artificial\nneural networks can successfully solve visual detection and classification\ntasks and are commonly used to build complex decision making systems. However,\nin order to perform well on these tasks they require increasingly complex,\n\"very deep\" model structure, which is costly in inference run-time, energy\nconsumption and number of training samples, only trainable on cloud-computing\nclusters. A single spiking neuron has been shown to be able to solve\nrecognition tasks for homogeneous Poisson input statistics, a commonly used\nmodel for spiking activity in the neocortex. When modeled as leaky integrate\nand fire with gradient decent learning algorithm it was shown to posses a\nvariety of complex computational capabilities. Here we improve its\nimplementation. We also account for more natural stimulus generated inputs that\ndeviate from this homogeneous Poisson spiking. The improved gradient-based\nlocal learning rule allows for significantly better and stable generalization.\nWe also show that with its improved capabilities it can count weakly labeled\nconcepts by applying our model to a problem of multiple instance learning (MIL)\nwith counting where labels are only available for collections of concepts. In\nthis counting MNIST task the neuron exploits the improved implementation and\noutperforms conventional ConvNet architecture under similar condtions.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 11:09:27 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 09:09:15 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Rapp", "Hannes", ""], ["Nawrot", "Martin Paul", ""], ["Stern", "Merav", ""]]}, {"id": "1805.07574", "submitter": "Scott Lee", "authors": "Scott H Lee, Drew Levin, Pat Finley, Charles M Heilig", "title": "Chief complaint classification with recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syndromic surveillance detects and monitors individual and population health\nindicators through sources such as emergency department records. Automated\nclassification of these records can improve outbreak detection speed and\ndiagnosis accuracy. Current syndromic systems rely on hand-coded keyword-based\nmethods to parse written fields and may benefit from the use of modern\nsupervised-learning classifier models. In this paper we implement two recurrent\nneural network models based on long short-term memory (LSTM) and gated\nrecurrent unit (GRU) cells and compare them to two traditional bag-of-words\nclassifiers: multinomial naive Bayes (MNB) and a support vector machine (SVM).\nThe MNB classifier is one of only two machine learning algorithms currently\nbeing used for syndromic surveillance. All four models are trained to predict\ndiagnostic code groups as defined by Clinical Classification Software, first to\npredict from discharge diagnosis, then from chief complaint fields. The\nclassifiers are trained on 3.6 million de-identified emergency department\nrecords from a single United States jurisdiction. We compare performance of\nthese models primarily using the F1 score. Using discharge diagnoses, the LSTM\nclassifier performs best, though all models exhibit an F1 score above 96.00.\nThe GRU performs best on chief complaints (F1=47.38), and MNB with bigrams\nperforms worst (F1=39.40). Certain syndrome types are easier to detect than\nothers. For examples, chief complaints using the GRU model predicts\nalcohol-related disorders well (F1=78.91) but predicts influenza poorly\n(F1=14.80). In all instances, the RNN models outperformed the bag-of-word\nclassifiers, suggesting deep learning models could substantially improve the\nautomatic classification of unstructured text for syndromic surveillance.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 11:54:43 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 15:04:22 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Lee", "Scott H", ""], ["Levin", "Drew", ""], ["Finley", "Pat", ""], ["Heilig", "Charles M", ""]]}, {"id": "1805.07575", "submitter": "Muhammad Naveed Tabassum", "authors": "Muhammad Naveed Tabassum and Esa Ollila", "title": "Sequential adaptive elastic net approach for single-snapshot source\n  localization", "comments": "12 pages, 5 figures, in the publication to the Journal of the\n  Acoustical Society of America", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG math.CV math.IT math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes efficient algorithms for accurate recovery of\ndirection-of-arrival (DoA) of sources from single-snapshot measurements using\ncompressed beamforming (CBF). In CBF, the conventional sensor array signal\nmodel is cast as an underdetermined complex-valued linear regression model and\nsparse signal recovery methods are used for solving the DoA finding problem. We\ndevelop a complex-valued pathwise weighted elastic net (c-PW-WEN) algorithm\nthat finds solutions at knots of penalty parameter values over a path (or grid)\nof EN tuning parameter values. c-PW-WEN also computes Lasso or weighted Lasso\nin its path. We then propose a sequential adaptive EN (SAEN) method that is\nbased on c-PW-WEN algorithm with adaptive weights that depend on the previous\nsolution. Extensive simulation studies illustrate that SAEN improves the\nprobability of exact recovery of true support compared to conventional sparse\nsignal recovery approaches such as Lasso, elastic net or orthogonal matching\npursuit in several challenging multiple target scenarios. The effectiveness of\nSAEN is more pronounced in the presence of high mutual coherence.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 11:57:54 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tabassum", "Muhammad Naveed", ""], ["Ollila", "Esa", ""]]}, {"id": "1805.07588", "submitter": "Qi Qian", "authors": "Qi Qian, Shenghuo Zhu, Jiasheng Tang, Rong Jin, Baigui Sun and Hao Li", "title": "Robust Optimization over Multiple Domains", "comments": "accepted by AAAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of learning a single model for multiple\ndomains. Unlike the conventional machine learning scenario where each domain\ncan have the corresponding model, multiple domains (i.e., applications/users)\nmay share the same machine learning model due to maintenance loads in cloud\ncomputing services. For example, a digit-recognition model should be applicable\nto hand-written digits, house numbers, car plates, etc. Therefore, an ideal\nmodel for cloud computing has to perform well at each applicable domain. To\naddress this new challenge from cloud computing, we develop a framework of\nrobust optimization over multiple domains. In lieu of minimizing the empirical\nrisk, we aim to learn a model optimized to the adversarial distribution over\nmultiple domains. Hence, we propose to learn the model and the adversarial\ndistribution simultaneously with the stochastic algorithm for efficiency.\nTheoretically, we analyze the convergence rate for convex and non-convex\nmodels. To our best knowledge, we first study the convergence rate of learning\na robust non-convex model with a practical algorithm. Furthermore, we\ndemonstrate that the robustness of the framework and the convergence rate can\nbe further enhanced by appropriate regularizers over the adversarial\ndistribution. The empirical study on real-world fine-grained visual\ncategorization and digits recognition tasks verifies the effectiveness and\nefficiency of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 13:19:44 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 19:13:28 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Qian", "Qi", ""], ["Zhu", "Shenghuo", ""], ["Tang", "Jiasheng", ""], ["Jin", "Rong", ""], ["Sun", "Baigui", ""], ["Li", "Hao", ""]]}, {"id": "1805.07592", "submitter": "Maryam Aziz", "authors": "Maryam Aziz, Jesse Anderton, Javed Aslam", "title": "Adaptively Pruning Features for Boosted Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosted decision trees enjoy popularity in a variety of applications;\nhowever, for large-scale datasets, the cost of training a decision tree in each\nround can be prohibitively expensive. Inspired by ideas from the multi-arm\nbandit literature, we develop a highly efficient algorithm for computing exact\ngreedy-optimal decision trees, outperforming the state-of-the-art Quick Boost\nmethod. We further develop a framework for deriving lower bounds on the problem\nthat applies to a wide family of conceivable algorithms for the task (including\nour algorithm and Quick Boost), and we demonstrate empirically on a wide\nvariety of data sets that our algorithm is near-optimal within this family of\nalgorithms. We also derive a lower bound applicable to any algorithm solving\nthe task, and we demonstrate that our algorithm empirically achieves\nperformance close to this best-achievable lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 13:44:57 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Aziz", "Maryam", ""], ["Anderton", "Jesse", ""], ["Aslam", "Javed", ""]]}, {"id": "1805.07594", "submitter": "Boris Muzellec", "authors": "Boris Muzellec and Marco Cuturi", "title": "Generalizing Point Embeddings using the Wasserstein Space of Elliptical\n  Distributions", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 31, pages\n  10258--10269, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding complex objects as vectors in low dimensional spaces is a\nlongstanding problem in machine learning. We propose in this work an extension\nof that approach, which consists in embedding objects as elliptical probability\ndistributions, namely distributions whose densities have elliptical level sets.\nWe endow these measures with the 2-Wasserstein metric, with two important\nbenefits: (i) For such measures, the squared 2-Wasserstein metric has a closed\nform, equal to a weighted sum of the squared Euclidean distance between means\nand the squared Bures metric between covariance matrices. The latter is a\nRiemannian metric between positive semi-definite matrices, which turns out to\nbe Euclidean on a suitable factor representation of such matrices, which is\nvalid on the entire geodesic between these matrices. (ii) The 2-Wasserstein\ndistance boils down to the usual Euclidean metric when comparing Diracs, and\ntherefore provides a natural framework to extend point embeddings. We show that\nfor these reasons Wasserstein elliptical embeddings are more intuitive and\nyield tools that are better behaved numerically than the alternative choice of\nGaussian embeddings with the Kullback-Leibler divergence. In particular, and\nunlike previous work based on the KL geometry, we learn elliptical\ndistributions that are not necessarily diagonal. We demonstrate the advantages\nof elliptical embeddings by using them for visualization, to compute embeddings\nof words, and to reflect entailment or hypernymy.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 13:51:34 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 16:53:17 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 11:53:24 GMT"}, {"version": "v4", "created": "Fri, 2 Nov 2018 17:59:23 GMT"}, {"version": "v5", "created": "Sun, 17 Feb 2019 08:48:08 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Muzellec", "Boris", ""], ["Cuturi", "Marco", ""]]}, {"id": "1805.07601", "submitter": "Luca Pasquali", "authors": "Hao Wu, Andreas Mardt, Luca Pasquali, Frank Noe", "title": "Deep Generative Markov State Models", "comments": null, "journal-ref": null, "doi": null, "report-no": "wu01", "categories": "stat.ML cs.LG math.DS math.PR physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep generative Markov State Model (DeepGenMSM) learning\nframework for inference of metastable dynamical systems and prediction of\ntrajectories. After unsupervised training on time series data, the model\ncontains (i) a probabilistic encoder that maps from high-dimensional\nconfiguration space to a small-sized vector indicating the membership to\nmetastable (long-lived) states, (ii) a Markov chain that governs the\ntransitions between metastable states and facilitates analysis of the long-time\ndynamics, and (iii) a generative part that samples the conditional distribution\nof configurations in the next time step. The model can be operated in a\nrecursive fashion to generate trajectories to predict the system evolution from\na defined starting state and propose new configurations. The DeepGenMSM is\ndemonstrated to provide accurate estimates of the long-time kinetics and\ngenerate valid distributions for molecular dynamics (MD) benchmark systems.\nRemarkably, we show that DeepGenMSMs are able to make long time-steps in\nmolecular configuration space and generate physically realistic structures in\nregions that were not seen in training data.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 14:30:56 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 10:50:56 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Wu", "Hao", ""], ["Mardt", "Andreas", ""], ["Pasquali", "Luca", ""], ["Noe", "Frank", ""]]}, {"id": "1805.07603", "submitter": "Zichuan Lin", "authors": "Zichuan Lin, Tianqi Zhao, Guangwen Yang, Lintao Zhang", "title": "Episodic Memory Deep Q-Networks", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have made huge progress in recent\nyears by leveraging the power of deep neural networks (DNN). Despite the\nsuccess, deep RL algorithms are known to be sample inefficient, often requiring\nmany rounds of interaction with the environments to obtain satisfactory\nperformance. Recently, episodic memory based RL has attracted attention due to\nits ability to latch on good actions quickly. In this paper, we present a\nsimple yet effective biologically inspired RL algorithm called Episodic Memory\nDeep Q-Networks (EMDQN), which leverages episodic memory to supervise an agent\nduring training. Experiments show that our proposed method can lead to better\nsample efficiency and is more likely to find good policies. It only requires\n1/5 of the interactions of DQN to achieve many state-of-the-art performances on\nAtari games, significantly outperforming regular DQN and other episodic memory\nbased RL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 14:33:00 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Lin", "Zichuan", ""], ["Zhao", "Tianqi", ""], ["Yang", "Guangwen", ""], ["Zhang", "Lintao", ""]]}, {"id": "1805.07616", "submitter": "Guillem Collell", "authors": "Guillem Collell and Marie-Francine Moens", "title": "Do Neural Network Cross-Modal Mappings Really Bridge Modalities?", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward networks are widely used in cross-modal applications to bridge\nmodalities by mapping distributed vectors of one modality to the other, or to a\nshared space. The predicted vectors are then used to perform e.g., retrieval or\nlabeling. Thus, the success of the whole system relies on the ability of the\nmapping to make the neighborhood structure (i.e., the pairwise similarities) of\nthe predicted vectors akin to that of the target vectors. However, whether this\nis achieved has not been investigated yet. Here, we propose a new similarity\nmeasure and two ad hoc experiments to shed light on this issue. In three\ncross-modal benchmarks we learn a large number of language-to-vision and\nvision-to-language neural network mappings (up to five layers) using a rich\ndiversity of image and text features and loss functions. Our results reveal\nthat, surprisingly, the neighborhood structure of the predicted vectors\nconsistently resembles more that of the input vectors than that of the target\nvectors. In a second experiment, we further show that untrained nets do not\nsignificantly disrupt the neighborhood (i.e., semantic) structure of the input\nvectors.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 15:51:43 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 16:16:37 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Collell", "Guillem", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1805.07624", "submitter": "Sotirios Chatzis", "authors": "Konstantinos P. Panousis, Sotirios Chatzis, Sergios Theodoridis", "title": "Nonparametric Bayesian Deep Networks with Local Competition", "comments": "Proc. ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to enable inference of deep networks that retain high\naccuracy for the least possible model complexity, with the latter deduced from\nthe data during inference. To this end, we revisit deep networks that comprise\ncompeting linear units, as opposed to nonlinear units that do not entail any\nform of (local) competition. In this context, our main technical innovation\nconsists in an inferential setup that leverages solid arguments from Bayesian\nnonparametrics. We infer both the needed set of connections or locally\ncompeting sets of units, as well as the required floating-point precision for\nstoring the network parameters. Specifically, we introduce auxiliary discrete\nlatent variables representing which initial network components are actually\nneeded for modeling the data at hand, and perform Bayesian inference over them\nby imposing appropriate stick-breaking priors. As we experimentally show using\nbenchmark datasets, our approach yields networks with less computational\nfootprint than the state-of-the-art, and with no compromises in predictive\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 17:15:53 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 19:34:06 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 12:10:22 GMT"}, {"version": "v4", "created": "Sun, 5 May 2019 19:50:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Panousis", "Konstantinos P.", ""], ["Chatzis", "Sotirios", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "1805.07631", "submitter": "Neev Samuel", "authors": "Neev Samuel, Tzvi Diskin, Ami Wiesel", "title": "Learning to Detect", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2899805", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider Multiple-Input-Multiple-Output (MIMO) detection\nusing deep neural networks. We introduce two different deep architectures: a\nstandard fully connected multi-layer network, and a Detection Network (DetNet)\nwhich is specifically designed for the task. The structure of DetNet is\nobtained by unfolding the iterations of a projected gradient descent algorithm\ninto a network. We compare the accuracy and runtime complexity of the purposed\napproaches and achieve state-of-the-art performance while maintaining low\ncomputational requirements. Furthermore, we manage to train a single network to\ndetect over an entire distribution of channels. Finally, we consider detection\nwith soft outputs and show that the networks can easily be modified to produce\nsoft decisions.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 18:04:18 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Samuel", "Neev", ""], ["Diskin", "Tzvi", ""], ["Wiesel", "Ami", ""]]}, {"id": "1805.07633", "submitter": "Pablo Moreno-Mu\\~noz", "authors": "Pablo Moreno-Mu\\~noz, Antonio Art\\'es-Rodr\\'iguez and Mauricio A.\n  \\'Alvarez", "title": "Heterogeneous Multi-output Gaussian Process Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel extension of multi-output Gaussian processes for handling\nheterogeneous outputs. We assume that each output has its own likelihood\nfunction and use a vector-valued Gaussian process prior to jointly model the\nparameters in all likelihoods as latent functions. Our multi-output Gaussian\nprocess uses a covariance function with a linear model of coregionalisation\nform. Assuming conditional independence across the underlying latent functions\ntogether with an inducing variable framework, we are able to obtain tractable\nvariational bounds amenable to stochastic variational inference. We illustrate\nthe performance of the model on synthetic data and two real datasets: a human\nbehavioral study and a demographic high-dimensional dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 18:17:59 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 23:37:39 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""], ["\u00c1lvarez", "Mauricio A.", ""]]}, {"id": "1805.07641", "submitter": "Yash Patel", "authors": "Yash Patel, Kashyap Chitta, Bhavan Jasani", "title": "Learning Sampling Policies for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of semi-supervised domain adaptation of classification\nalgorithms through deep Q-learning. The core idea is to consider the\npredictions of a source domain network on target domain data as noisy labels,\nand learn a policy to sample from this data so as to maximize classification\naccuracy on a small annotated reward partition of the target domain. Our\nexperiments show that learned sampling policies construct labeled sets that\nimprove accuracies of visual classifiers over baselines.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 19:09:18 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Patel", "Yash", ""], ["Chitta", "Kashyap", ""], ["Jasani", "Bhavan", ""]]}, {"id": "1805.07645", "submitter": "Jean Honorio", "authors": "Zitao Li and Jean Honorio", "title": "Regularized Loss Minimizers with Local Data Perturbation: Consistency\n  and Data Irrecoverability", "comments": null, "journal-ref": "IEEE International Symposium on Information Theory (ISIT), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new concept, data irrecoverability, and show that the\nwell-studied concept of data privacy is sufficient but not necessary for data\nirrecoverability. We show that there are several regularized loss minimization\nproblems that can use perturbed data with theoretical guarantees of\ngeneralization, i.e., loss consistency. Our results quantitatively connect the\nconvergence rates of the learning problems to the impossibility for any\nadversary for recovering the original data from perturbed observations. In\naddition, we show several examples where the convergence rates with perturbed\ndata only increase the convergence rates with original data within a constant\nfactor related to the amount of perturbation, i.e., noise.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 19:43:02 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 01:52:34 GMT"}, {"version": "v3", "created": "Sat, 20 Oct 2018 02:03:00 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 16:26:44 GMT"}, {"version": "v5", "created": "Tue, 29 Jan 2019 14:38:41 GMT"}, {"version": "v6", "created": "Tue, 27 Oct 2020 16:11:09 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Li", "Zitao", ""], ["Honorio", "Jean", ""]]}, {"id": "1805.07648", "submitter": "Vishvak Murahari", "authors": "Vishvak S Murahari, Thomas Ploetz", "title": "On Attention Models for Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most approaches that model time-series data in human activity recognition\nbased on body-worn sensing (HAR) use a fixed size temporal context to represent\ndifferent activities. This might, however, not be apt for sets of activities\nwith individ- ually varying durations. We introduce attention models into HAR\nresearch as a data driven approach for exploring relevant temporal context.\nAttention models learn a set of weights over input data, which we leverage to\nweight the temporal context being considered to model each sensor reading. We\nconstruct attention models for HAR by adding attention layers to a state-\nof-the-art deep learning HAR model (DeepConvLSTM) and evaluate our approach on\nbenchmark datasets achieving sig- nificant increase in performance. Finally, we\nvisualize the learned weights to better understand what constitutes relevant\ntemporal context.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 20:13:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Murahari", "Vishvak S", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1805.07654", "submitter": "Manuel Hau{\\ss}mann", "authors": "Manuel Haussmann, Fred A. Hamprecht, Melih Kandemir", "title": "Sampling-Free Variational Inference of Bayesian Neural Networks by\n  Variance Backpropagation", "comments": "Accepted at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Bayesian Neural Net formulation that affords variational\ninference for which the evidence lower bound is analytically tractable subject\nto a tight approximation. We achieve this tractability by (i) decomposing ReLU\nnonlinearities into the product of an identity and a Heaviside step function,\n(ii) introducing a separate path that decomposes the neural net expectation\nfrom its variance. We demonstrate formally that introducing separate latent\nbinary variables to the activations allows representing the neural network\nlikelihood as a chain of linear operations. Performing variational inference on\nthis construction enables a sampling-free computation of the evidence lower\nbound which is a more effective approximation than the widely applied Monte\nCarlo sampling and CLT related techniques. We evaluate the model on a range of\nregression and classification tasks against BNN inference alternatives, showing\ncompetitive or improved performance over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 21:00:44 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:23:37 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Haussmann", "Manuel", ""], ["Hamprecht", "Fred A.", ""], ["Kandemir", "Melih", ""]]}, {"id": "1805.07674", "submitter": "Chang Xiao", "authors": "Chang Xiao, Peilin Zhong, Changxi Zheng", "title": "BourGAN: Generative Networks with Metric Embeddings", "comments": "Neural Information Processing Systems, 2018", "journal-ref": "Advances in Neural Information Processing Systems 31, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the mode collapse for generative adversarial networks\n(GANs). We view modes as a geometric structure of data distribution in a metric\nspace. Under this geometric lens, we embed subsamples of the dataset from an\narbitrary metric space into the l2 space, while preserving their pairwise\ndistance distribution. Not only does this metric embedding determine the\ndimensionality of the latent space automatically, it also enables us to\nconstruct a mixture of Gaussians to draw latent space random vectors. We use\nthe Gaussian mixture model in tandem with a simple augmentation of the\nobjective function to train GANs. Every major step of our method is supported\nby theoretical analysis, and our experiments on real and synthetic data confirm\nthat the generator is able to produce samples spreading over most of the modes\nwhile avoiding unwanted samples, outperforming several recent GAN variants on a\nnumber of metrics and offering new features.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 23:17:18 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 00:48:02 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 01:43:24 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Xiao", "Chang", ""], ["Zhong", "Peilin", ""], ["Zheng", "Changxi", ""]]}, {"id": "1805.07683", "submitter": "Yu Jin", "authors": "Yu Jin, Joseph F. JaJa", "title": "Learning Graph-Level Representations with Recurrent Neural Networks", "comments": "Submit to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a variety of methods have been developed to encode graphs into\nlow-dimensional vectors that can be easily exploited by machine learning\nalgorithms. The majority of these methods start by embedding the graph nodes\ninto a low-dimensional vector space, followed by using some scheme to aggregate\nthe node embeddings. In this work, we develop a new approach to learn\ngraph-level representations, which includes a combination of unsupervised and\nsupervised learning components. We start by learning a set of node\nrepresentations in an unsupervised fashion. Graph nodes are mapped into node\nsequences sampled from random walk approaches approximated by the\nGumbel-Softmax distribution. Recurrent neural network (RNN) units are modified\nto accommodate both the node representations as well as their neighborhood\ninformation. Experiments on standard graph classification benchmarks\ndemonstrate that our proposed approach achieves superior or comparable\nperformance relative to the state-of-the-art algorithms in terms of convergence\nspeed and classification accuracy. We further illustrate the effectiveness of\nthe different components used by our approach.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 00:26:37 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 14:41:16 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 03:11:16 GMT"}, {"version": "v4", "created": "Tue, 11 Sep 2018 18:19:09 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jin", "Yu", ""], ["JaJa", "Joseph F.", ""]]}, {"id": "1805.07685", "submitter": "Cicero Nogueira Dos Santos", "authors": "Cicero Nogueira dos Santos, Igor Melnyk, Inkit Padhi", "title": "Fighting Offensive Language on Social Media with Unsupervised Text Style\n  Transfer", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to tackle the problem of offensive language in\nonline social media. Our approach uses unsupervised text style transfer to\ntranslate offensive sentences into non-offensive ones. We propose a new method\nfor training encoder-decoders using non-parallel data that combines a\ncollaborative classifier, attention and the cycle consistency loss.\nExperimental results on data from Twitter and Reddit show that our method\noutperforms a state-of-the-art text style transfer system in two out of three\nquantitative metrics and produces reliable non-offensive transferred sentences.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 00:57:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Santos", "Cicero Nogueira dos", ""], ["Melnyk", "Igor", ""], ["Padhi", "Inkit", ""]]}, {"id": "1805.07687", "submitter": "Daniel Brown", "authors": "Daniel S. Brown and Scott Niekum", "title": "Machine Teaching for Inverse Reinforcement Learning: Algorithms and\n  Applications", "comments": "In proceedings of the AAAI Conference on Artificial Intelligence,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) infers a reward function from\ndemonstrations, allowing for policy improvement and generalization. However,\ndespite much recent interest in IRL, little work has been done to understand\nthe minimum set of demonstrations needed to teach a specific sequential\ndecision-making task. We formalize the problem of finding maximally informative\ndemonstrations for IRL as a machine teaching problem where the goal is to find\nthe minimum number of demonstrations needed to specify the reward equivalence\nclass of the demonstrator. We extend previous work on algorithmic teaching for\nsequential decision-making tasks by showing a reduction to the set cover\nproblem which enables an efficient approximation algorithm for determining the\nset of maximally-informative demonstrations. We apply our proposed machine\nteaching algorithm to two novel applications: providing a lower bound on the\nnumber of queries needed to learn a policy using active IRL and developing a\nnovel IRL algorithm that can learn more efficiently from informative\ndemonstrations than a standard IRL approach.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 01:14:29 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 02:03:39 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 22:30:54 GMT"}, {"version": "v4", "created": "Thu, 10 Jan 2019 03:19:45 GMT"}, {"version": "v5", "created": "Mon, 11 Feb 2019 16:51:00 GMT"}, {"version": "v6", "created": "Tue, 5 Mar 2019 17:55:50 GMT"}, {"version": "v7", "created": "Fri, 16 Aug 2019 13:42:45 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Brown", "Daniel S.", ""], ["Niekum", "Scott", ""]]}, {"id": "1805.07702", "submitter": "Yu-Chiao Chiu", "authors": "Yu-Chiao Chiu, Hung-I Harry Chen, Tinghe Zhang, Songyao Zhang, Aparna\n  Gorthi, Li-Ju Wang, Yufei Huang, Yidong Chen", "title": "Predicting drug response of tumors from integrated genomic profiles by\n  deep neural networks", "comments": "Accepted for presentation in the International Conference on\n  Intelligent Biology and Medicine (ICIBM 2018) at Los Angeles, CA, USA.\n  Currently under consideration for publication in a Supplement Issue of BMC\n  Genomics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of high-throughput genomic profiles from a pharmacogenomics\nviewpoint has provided unprecedented insights into the oncogenic features\nmodulating drug response. A recent screening of ~1,000 cancer cell lines to a\ncollection of anti-cancer drugs illuminated the link between genotypes and\nvulnerability. However, due to essential differences between cell lines and\ntumors, the translation into predicting drug response in tumors remains\nchallenging. Here we proposed a DNN model to predict drug response based on\nmutation and expression profiles of a cancer cell or a tumor. The model\ncontains a mutation and an expression encoders pre-trained using a large\npan-cancer dataset to abstract core representations of high-dimension data,\nfollowed by a drug response predictor network. Given a pair of mutation and\nexpression profiles, the model predicts IC50 values of 265 drugs. We trained\nand tested the model on a dataset of 622 cancer cell lines and achieved an\noverall prediction performance of mean squared error at 1.96 (log-scale IC50\nvalues). The performance was superior in prediction error or stability than two\nclassical methods and four analog DNNs of our model. We then applied the model\nto predict drug response of 9,059 tumors of 33 cancer types. The model\npredicted both known, including EGFR inhibitors in non-small cell lung cancer\nand tamoxifen in ER+ breast cancer, and novel drug targets. The comprehensive\nanalysis further revealed the molecular mechanisms underlying the resistance to\na chemotherapeutic drug docetaxel in a pan-cancer setting and the anti-cancer\npotential of a novel agent, CX-5461, in treating gliomas and hematopoietic\nmalignancies. Overall, our model and findings improve the prediction of drug\nresponse and the identification of novel therapeutic options.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 04:27:09 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Chiu", "Yu-Chiao", ""], ["Chen", "Hung-I Harry", ""], ["Zhang", "Tinghe", ""], ["Zhang", "Songyao", ""], ["Gorthi", "Aparna", ""], ["Wang", "Li-Ju", ""], ["Huang", "Yufei", ""], ["Chen", "Yidong", ""]]}, {"id": "1805.07708", "submitter": "Yinlam Chow", "authors": "Yinlam Chow and Ofir Nachum and Edgar Duenez-Guzman and Mohammad\n  Ghavamzadeh", "title": "A Lyapunov-based Approach to Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world reinforcement learning (RL) problems, besides optimizing\nthe main objective function, an agent must concurrently avoid violating a\nnumber of constraints. In particular, besides optimizing performance it is\ncrucial to guarantee the safety of an agent during training as well as\ndeployment (e.g. a robot should avoid taking actions - exploratory or not -\nwhich irrevocably harm its hardware). To incorporate safety in RL, we derive\nalgorithms under the framework of constrained Markov decision problems (CMDPs),\nan extension of the standard Markov decision problems (MDPs) augmented with\nconstraints on expected cumulative costs. Our approach hinges on a novel\n\\emph{Lyapunov} method. We define and present a method for constructing\nLyapunov functions, which provide an effective way to guarantee the global\nsafety of a behavior policy during training via a set of local, linear\nconstraints. Leveraging these theoretical underpinnings, we show how to use the\nLyapunov approach to systematically transform dynamic programming (DP) and RL\nalgorithms into their safe counterparts. To illustrate their effectiveness, we\nevaluate these algorithms in several CMDP planning and decision-making tasks on\na safety benchmark domain. Our results show that our proposed method\nsignificantly outperforms existing baselines in balancing constraint\nsatisfaction and performance.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 05:12:04 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Chow", "Yinlam", ""], ["Nachum", "Ofir", ""], ["Duenez-Guzman", "Edgar", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1805.07722", "submitter": "Guo-Jun Qi", "authors": "Muhammad Abdullah Jamal, Guo-Jun Qi, Mubarak Shah", "title": "Task-Agnostic Meta-Learning for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning approaches have been proposed to tackle the few-shot learning\nproblem.Typically, a meta-learner is trained on a variety of tasks in the hopes\nof being generalizable to new tasks. However, the generalizability on new tasks\nof a meta-learner could be fragile when it is over-trained on existing tasks\nduring meta-training phase. In other words, the initial model of a meta-learner\ncould be too biased towards existing tasks to adapt to new tasks, especially\nwhen only very few examples are available to update the model. To avoid a\nbiased meta-learner and improve its generalizability, we propose a novel\nparadigm of Task-Agnostic Meta-Learning (TAML) algorithms. Specifically, we\npresent an entropy-based approach that meta-learns an unbiased initial model\nwith the largest uncertainty over the output labels by preventing it from\nover-performing in classification tasks. Alternatively, a more general\ninequality-minimization TAML is presented for more ubiquitous scenarios by\ndirectly minimizing the inequality of initial losses beyond the classification\ntasks wherever a suitable loss can be defined.Experiments on benchmarked\ndatasets demonstrate that the proposed approaches outperform compared\nmeta-learning algorithms in both few-shot classification and reinforcement\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 07:50:42 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Jamal", "Muhammad Abdullah", ""], ["Qi", "Guo-Jun", ""], ["Shah", "Mubarak", ""]]}, {"id": "1805.07723", "submitter": "Parameswaran Kamalaruban Dr.", "authors": "Parameswaran Kamalaruban and Robert C. Williamson", "title": "Minimax Lower Bounds for Cost Sensitive Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost-sensitive classification problem plays a crucial role in\nmission-critical machine learning applications, and differs with traditional\nclassification by taking the misclassification costs into consideration.\nAlthough being studied extensively in the literature, the fundamental limits of\nthis problem are still not well understood. We investigate the hardness of this\nproblem by extending the standard minimax lower bound of balanced binary\nclassification problem (due to \\cite{massart2006risk}), and emphasize the\nimpact of cost terms on the hardness.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 07:51:21 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kamalaruban", "Parameswaran", ""], ["Williamson", "Robert C.", ""]]}, {"id": "1805.07725", "submitter": "Kai Puolamaki", "authors": "Kai Puolam\\\"aki, Emilia Oikarinen, Buse Atli, Andreas Henelius", "title": "Human-guided data exploration using randomisation", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explorative data analysis system should be aware of what the user already\nknows and what the user wants to know of the data: otherwise the system cannot\nprovide the user with the most informative and useful views of the data. We\npropose a principled way to do exploratory data analysis, where the user's\nbackground knowledge is modeled by a distribution parametrised by subsets of\nrows and columns in the data, called tiles. The user can also use tiles to\ndescribe his or her interests concerning relations in the data. We provide a\ncomputationally efficient implementation of this concept based on constrained\nrandomisation. The implementation is used to model both the background\nknowledge and the user's information request and is a necessary prerequisite\nfor any interactive system. Furthermore, we describe a novel linear projection\npursuit method to find and show the views most informative to the user, which\nat the limit of no background knowledge and with generic objectives reduces to\nPCA. We show that our method is robust under noise and fast enough for\ninteractive use. We also show that the method gives understandable and useful\nresults when analysing real-world data sets. We will release an open source\nlibrary implementing the idea, including the experiments presented in this\npaper. We show that our method can outperform standard projection pursuit\nvisualisation methods in exploration tasks. Our framework makes it possible to\nconstruct human-guided data exploration systems which are fast, powerful, and\ngive results that are easy to comprehend.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 07:59:11 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 15:04:35 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Puolam\u00e4ki", "Kai", ""], ["Oikarinen", "Emilia", ""], ["Atli", "Buse", ""], ["Henelius", "Andreas", ""]]}, {"id": "1805.07732", "submitter": "Chao Qu", "authors": "Chao Qu, Shie Mannor, Huan Xu", "title": "Nonlinear Distributional Gradient Temporal-Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a distributional variant of gradient temporal-difference (TD)\nlearning. Distributional reinforcement learning has been demonstrated to\noutperform the regular one in the recent study\n\\citep{bellemare2017distributional}. In the policy evaluation setting, we\ndesign two new algorithms called distributional GTD2 and distributional TDC\nusing the Cram{\\'e}r distance on the distributional version of the Bellman\nerror objective function, which inherits advantages of both the nonlinear\ngradient TD algorithms and the distributional RL approach. In the control\nsetting, we propose the distributional Greedy-GQ using the similar derivation.\nWe prove the asymptotic almost-sure convergence of distributional GTD2 and TDC\nto a local optimal solution for general smooth function approximators, which\nincludes neural networks that have been widely used in recent study to solve\nthe real-life RL problems. In each step, the computational complexities of\nabove three algorithms are linear w.r.t.\\ the number of the parameters of the\nfunction approximator, thus can be implemented efficiently for neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 08:43:05 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 04:58:44 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 03:38:05 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Qu", "Chao", ""], ["Mannor", "Shie", ""], ["Xu", "Huan", ""]]}, {"id": "1805.07737", "submitter": "Parameswaran Kamalaruban Dr.", "authors": "Parameswaran Kamalaruban and Robert C. Williamson and Xinhua Zhang", "title": "Exp-Concavity of Proper Composite Losses", "comments": null, "journal-ref": "PMLR 40:1035-1065, 2015", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of online prediction with expert advice is to find a decision\nstrategy which will perform almost as well as the best expert in a given pool\nof experts, on any sequence of outcomes. This problem has been widely studied\nand $O(\\sqrt{T})$ and $O(\\log{T})$ regret bounds can be achieved for convex\nlosses (\\cite{zinkevich2003online}) and strictly convex losses with bounded\nfirst and second derivatives (\\cite{hazan2007logarithmic}) respectively. In\nspecial cases like the Aggregating Algorithm (\\cite{vovk1995game}) with mixable\nlosses and the Weighted Average Algorithm (\\cite{kivinen1999averaging}) with\nexp-concave losses, it is possible to achieve $O(1)$ regret bounds.\n\\cite{van2012exp} has argued that mixability and exp-concavity are roughly\nequivalent under certain conditions. Thus by understanding the underlying\nrelationship between these two notions we can gain the best of both algorithms\n(strong theoretical performance guarantees of the Aggregating Algorithm and the\ncomputational efficiency of the Weighted Average Algorithm). In this paper we\nprovide a complete characterization of the exp-concavity of any proper\ncomposite loss. Using this characterization and the mixability condition of\nproper losses (\\cite{van2012mixability}), we show that it is possible to\ntransform (re-parameterize) any $\\beta$-mixable binary proper loss into a\n$\\beta$-exp-concave composite loss with the same $\\beta$. In the multi-class\ncase, we propose an approximation approach for this transformation.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 08:53:48 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kamalaruban", "Parameswaran", ""], ["Williamson", "Robert C.", ""], ["Zhang", "Xinhua", ""]]}, {"id": "1805.07780", "submitter": "Vik Goel", "authors": "Vik Goel, Jameson Weng, Pascal Poupart", "title": "Unsupervised Video Object Segmentation for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new technique for deep reinforcement learning that automatically\ndetects moving objects and uses the relevant information for action selection.\nThe detection of moving objects is done in an unsupervised way by exploiting\nstructure from motion. Instead of directly learning a policy from raw images,\nthe agent first learns to detect and segment moving objects by exploiting flow\ninformation in video sequences. The learned representation is then used to\nfocus the policy of the agent on the moving objects. Over time, the agent\nidentifies which objects are critical for decision making and gradually builds\na policy based on relevant moving objects. This approach, which we call\nMotion-Oriented REinforcement Learning (MOREL), is demonstrated on a suite of\nAtari games where the ability to detect moving objects reduces the amount of\ninteraction needed with the environment to obtain a good policy. Furthermore,\nthe resulting policy is more interpretable than policies that directly map\nimages to actions or values with a black box neural network. We can gain\ninsight into the policy by inspecting the segmentation and motion of each\nobject detected by the agent. This allows practitioners to confirm whether a\npolicy is making decisions based on sensible information.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 15:45:03 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Goel", "Vik", ""], ["Weng", "Jameson", ""], ["Poupart", "Pascal", ""]]}, {"id": "1805.07782", "submitter": "Neel Guha", "authors": "Neel Guha, Virginia Smith", "title": "Model Aggregation via Good-Enough Model Spaces", "comments": "21 pages, 6 figures, 8 tablees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, the training data for a machine learning task is\npartitioned across multiple nodes, and aggregating this data may be infeasible\ndue to communication, privacy, or storage constraints. Existing distributed\noptimization methods for learning global models in these settings typically\naggregate local updates from each node in an iterative fashion. However, these\napproaches require many rounds of communication between nodes, and assume that\nupdates can be synchronously shared across a connected network. In this work,\nwe present Good-Enough Model Spaces (GEMS), a novel framework for learning a\nglobal model by carefully intersecting the sets of \"good-enough\" models across\neach node. Our approach utilizes minimal communication and does not require\nsharing of data between nodes. We present methods for learning both convex\nmodels and neural networks within this framework and discuss how small samples\nof held-out data can be used for post-learning fine-tuning. In experiments on\nimage and medical datasets, our approach on average improves upon other\nbaseline aggregation techniques such as ensembling or model averaging by as\nmuch as 15 points (accuracy).\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 15:58:14 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:47:06 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 18:34:56 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Guha", "Neel", ""], ["Smith", "Virginia", ""]]}, {"id": "1805.07785", "submitter": "Ga Wu", "authors": "Ga Wu, Justin Domke, Scott Sanner", "title": "Conditional Inference in Pre-trained Variational Autoencoders via\n  Cross-coding", "comments": "8 pages main content, 4 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) are a popular generative model, but one in\nwhich conditional inference can be challenging. If the decomposition into query\nand evidence variables is fixed, conditional VAEs provide an attractive\nsolution. To support arbitrary queries, one is generally reduced to Markov\nChain Monte Carlo sampling methods that can suffer from long mixing times. In\nthis paper, we propose an idea we term cross-coding to approximate the\ndistribution over the latent variables after conditioning on an evidence\nassignment to some subset of the variables. This allows generating query\nsamples without retraining the full VAE. We experimentally evaluate three\nvariations of cross-coding showing that (i) they can be quickly optimized for\ndifferent decompositions of evidence and query and (ii) they quantitatively and\nqualitatively outperform Hamiltonian Monte Carlo.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 16:13:09 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 18:31:02 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Wu", "Ga", ""], ["Domke", "Justin", ""], ["Sanner", "Scott", ""]]}, {"id": "1805.07798", "submitter": "Simon Du", "authors": "Simon S. Du, Surbhi Goel", "title": "Improved Learning of One-hidden-layer Convolutional Neural Networks with\n  Overlaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm to learn a one-hidden-layer convolutional neural\nnetwork where both the convolutional weights and the outputs weights are\nparameters to be learned. Our algorithm works for a general class of\n(potentially overlapping) patches, including commonly used structures for\ncomputer vision tasks. Our algorithm draws ideas from (1) isotonic regression\nfor learning neural networks and (2) landscape analysis of non-convex matrix\nfactorization problems. We believe these findings may inspire further\ndevelopment in designing provable algorithms for learning neural networks and\nother complex models.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:07:25 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 23:29:24 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Du", "Simon S.", ""], ["Goel", "Surbhi", ""]]}, {"id": "1805.07802", "submitter": "Dimche Kostadinov", "authors": "Dimche Kostadinov, Behrooz Razeghi, Sohrab Ferdowsi, Slava\n  Voloshynovskiy", "title": "Network Learning with Local Propagation", "comments": "preprint, a similar version submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a locally decoupled network parameter learning with local\npropagation. Three elements are taken into account: (i) sets of nonlinear\ntransforms that describe the representations at all nodes, (ii) a local\nobjective at each node related to the corresponding local representation goal,\nand (iii) a local propagation model that relates the nonlinear error vectors at\neach node with the goal error vectors from the directly connected nodes. The\nmodeling concepts (i), (ii) and (iii) offer several advantages, including (a) a\nunified learning principle for any network that is represented as a graph, (b)\nunderstanding and interpretation of the local and the global learning dynamics,\n(c) decoupled and parallel parameter learning, (d) a possibility for learning\nin infinitely long, multi-path and multi-goal networks. Numerical experiments\nvalidate the potential of the learning principle. The preliminary results show\nadvantages in comparison to the state-of-the-art methods, w.r.t. the learning\ntime and the network size while having comparable recognition accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:21:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Razeghi", "Behrooz", ""], ["Ferdowsi", "Sohrab", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1805.07805", "submitter": "Elad Sarafian", "authors": "Elad Sarafian, Aviv Tamar and Sarit Kraus", "title": "Constrained Policy Improvement for Safe and Efficient Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a policy improvement algorithm for Reinforcement Learning (RL)\nwhich is called Rerouted Behavior Improvement (RBI). RBI is designed to take\ninto account the evaluation errors of the Q-function. Such errors are common in\nRL when learning the $Q$-value from finite past experience data. Greedy\npolicies or even constrained policy optimization algorithms which ignore these\nerrors may suffer from an improvement penalty (i.e. a negative policy\nimprovement). To minimize the improvement penalty, the RBI idea is to attenuate\nrapid policy changes of low probability actions which were less frequently\nsampled. This approach is shown to avoid catastrophic performance degradation\nand reduce regret when learning from a batch of past experience. Through a\ntwo-armed bandit with Gaussian distributed rewards example, we show that it\nalso increases data efficiency when the optimal action has a high variance. We\nevaluate RBI in two tasks in the Atari Learning Environment: (1) learning from\nobservations of multiple behavior policies and (2) iterative RL. Our results\ndemonstrate the advantage of RBI over greedy policies and other constrained\npolicy optimization algorithms as a safe learning approach and as a general\ndata efficient learning algorithm. An anonymous Github repository of our RBI\nimplementation is found at https://github.com/eladsar/rbi.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:47:03 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 06:19:34 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 20:12:07 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sarafian", "Elad", ""], ["Tamar", "Aviv", ""], ["Kraus", "Sarit", ""]]}, {"id": "1805.07808", "submitter": "Chandan Gautam", "authors": "Chandan Gautam, Aruna Tiwari, Sundaram Suresh, Alexandros Iosifidis", "title": "Multi-layer Kernel Ridge Regression for One-class Classification", "comments": "19 Pages, 3 Figures and 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a multi-layer architecture (in a hierarchical fashion) by\nstacking various Kernel Ridge Regression (KRR) based Auto-Encoder for one-class\nclassification is proposed and is referred as MKOC. MKOC has many layers of\nAuto-Encoders to project the input features into new feature space and the last\nlayer was regression based one class classifier. The Auto-Encoders use an\nunsupervised approach of learning and the final layer uses semi-supervised\n(trained by only positive samples) approach of learning. The proposed MKOC is\nexperimentally evaluated on 15 publicly available benchmark datasets.\nExperimental results verify the effectiveness of the proposed approach over 11\nexisting state-of-the-art kernel-based one-class classifiers. Friedman test is\nalso performed to verify the statistical significance of the claim of the\nsuperiority of the proposed one-class classifiers over the existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:59:48 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 12:38:53 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Gautam", "Chandan", ""], ["Tiwari", "Aruna", ""], ["Suresh", "Sundaram", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1805.07810", "submitter": "Hippolyt Ritter", "authors": "Hippolyt Ritter, Aleksandar Botev, David Barber", "title": "Online Structured Laplace Approximations For Overcoming Catastrophic\n  Forgetting", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Kronecker factored online Laplace approximation for\novercoming catastrophic forgetting in neural networks. The method is grounded\nin a Bayesian online learning framework, where we recursively approximate the\nposterior after every task with a Gaussian, leading to a quadratic penalty on\nchanges to the weights. The Laplace approximation requires calculating the\nHessian around a mode, which is typically intractable for modern architectures.\nIn order to make our method scalable, we leverage recent block-diagonal\nKronecker factored approximations to the curvature. Our algorithm achieves over\n90% test accuracy across a sequence of 50 instantiations of the permuted MNIST\ndataset, substantially outperforming related methods for overcoming\ncatastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 18:26:23 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ritter", "Hippolyt", ""], ["Botev", "Aleksandar", ""], ["Barber", "David", ""]]}, {"id": "1805.07816", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Xi Wu, Vaibhav Rastogi, Yingyu Liang, Somesh Jha", "title": "Towards Understanding Limitations of Pixel Discretization Against\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide adoption of artificial neural networks in various domains has led to an\nincreasing interest in defending adversarial attacks against them.\nPreprocessing defense methods such as pixel discretization are particularly\nattractive in practice due to their simplicity, low computational overhead, and\napplicability to various systems. It is observed that such methods work well on\nsimple datasets like MNIST, but break on more complicated ones like ImageNet\nunder recently proposed strong white-box attacks. To understand the conditions\nfor success and potentials for improvement, we study the pixel discretization\ndefense method, including more sophisticated variants that take into account\nthe properties of the dataset being discretized. Our results again show poor\nresistance against the strong attacks. We analyze our results in a theoretical\nframework and offer strong evidence that pixel discretization is unlikely to\nwork on all but the simplest of the datasets. Furthermore, our arguments\npresent insights why some other preprocessing defenses may be insecure.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 19:37:54 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 02:46:43 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 18:30:38 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2019 02:02:16 GMT"}, {"version": "v5", "created": "Thu, 3 Oct 2019 15:43:21 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Chen", "Jiefeng", ""], ["Wu", "Xi", ""], ["Rastogi", "Vaibhav", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""]]}, {"id": "1805.07820", "submitter": "Amog Kamsetty", "authors": "Rohan Taori, Amog Kamsetty, Brenton Chu, Nikita Vemuri", "title": "Targeted Adversarial Examples for Black Box Audio Systems", "comments": "IEEE Deep Learning and Security Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep recurrent networks to audio transcription has led to\nimpressive gains in automatic speech recognition (ASR) systems. Many have\ndemonstrated that small adversarial perturbations can fool deep neural networks\ninto incorrectly predicting a specified target with high confidence. Current\nwork on fooling ASR systems have focused on white-box attacks, in which the\nmodel architecture and parameters are known. In this paper, we adopt a\nblack-box approach to adversarial generation, combining the approaches of both\ngenetic algorithms and gradient estimation to solve the task. We achieve a\n89.25% targeted attack similarity after 3000 generations while maintaining\n94.6% audio file similarity.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 20:04:09 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 03:34:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Taori", "Rohan", ""], ["Kamsetty", "Amog", ""], ["Chu", "Brenton", ""], ["Vemuri", "Nikita", ""]]}, {"id": "1805.07828", "submitter": "Ping Guo", "authors": "Ping Guo (School of Systems Science, Beijing Normal University,\n  Beijing, China)", "title": "A VEST of the Pseudoinverse Learning Algorithm", "comments": "ELM is another name of the PIL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we briefly review the basic scheme of the pseudoinverse\nlearning (PIL) algorithm and present some discussions on the PIL, as well as\nits variants. The PIL algorithm, first presented in 1995, is a non-gradient\ndescent and non-iterative learning algorithm for multi-layer neural networks\nand has several advantages compared with gradient descent based algorithms.\nSome new viewpoints to PIL algorithm are presented, and several common pitfalls\nin practical implementation of the neural network learning task are also\naddressed. In addition, we show that so called extreme learning machine is a\nVariant crEated by Simple name alTernation (VEST) of the PIL algorithm for\nsingle hidden layer feedforward neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 21:46:29 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:36:25 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Guo", "Ping", "", "School of Systems Science, Beijing Normal University,\n  Beijing, China"]]}, {"id": "1805.07833", "submitter": "Hicham Janati", "authors": "Hicham Janati and Marco Cuturi and Alexandre Gramfort", "title": "Wasserstein regularization for sparse multi-task regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus in this paper on high-dimensional regression problems where each\nregressor can be associated to a location in a physical space, or more\ngenerally a generic geometric space. Such problems often employ sparse priors,\nwhich promote models using a small subset of regressors. To increase\nstatistical power, the so-called multi-task techniques were proposed, which\nconsist in the simultaneous estimation of several related models. Combined with\nsparsity assumptions, it lead to models enforcing the active regressors to be\nshared across models, thanks to, for instance L1 / Lq norms. We argue in this\npaper that these techniques fail to leverage the spatial information associated\nto regressors. Indeed, while sparse priors enforce that only a small subset of\nvariables is used, the assumption that these regressors overlap across all\ntasks is overly simplistic given the spatial variability observed in real data.\nIn this paper, we propose a convex regularizer for multi-task regression that\nencodes a more flexible geometry. Our regularizer is based on unbalanced\noptimal transport (OT) theory, and can take into account a prior geometric\nknowledge on the regressor variables, without necessarily requiring overlapping\nsupports. We derive an efficient algorithm based on a regularized formulation\nof OT, which iterates through applications of Sinkhorn's algorithm along with\ncoordinate descent iterations. The performance of our model is demonstrated on\nregular grids with both synthetic and real datasets as well as complex\ntriangulated geometries of the cortex with an application in neuroimaging.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 22:50:18 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 15:12:05 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 12:43:43 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Janati", "Hicham", ""], ["Cuturi", "Marco", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1805.07836", "submitter": "Zhilu Zhang", "authors": "Zhilu Zhang and Mert R. Sabuncu", "title": "Generalized Cross Entropy Loss for Training Deep Neural Networks with\n  Noisy Labels", "comments": "32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved tremendous success in a variety of\napplications across many disciplines. Yet, their superior performance comes\nwith the expensive cost of requiring correctly annotated large-scale datasets.\nMoreover, due to DNNs' rich capacity, errors in training labels can hamper\nperformance. To combat this problem, mean absolute error (MAE) has recently\nbeen proposed as a noise-robust alternative to the commonly-used categorical\ncross entropy (CCE) loss. However, as we show in this paper, MAE can perform\npoorly with DNNs and challenging datasets. Here, we present a theoretically\ngrounded set of noise-robust loss functions that can be seen as a\ngeneralization of MAE and CCE. Proposed loss functions can be readily applied\nwith any existing DNN architecture and algorithm, while yielding good\nperformance in a wide range of noisy label scenarios. We report results from\nexperiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and\nsynthetically generated noisy labels.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 23:01:49 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 01:37:13 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 14:44:20 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 22:41:40 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Zhang", "Zhilu", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1805.07841", "submitter": "Yan  Li", "authors": "Yan Li, Chao Qu, Huan Xu", "title": "Communication-Efficient Projection-Free Algorithm for Distributed\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization has gained a surge of interest in recent years. In\nthis paper we propose a distributed projection free algorithm named Distributed\nConditional Gradient Sliding(DCGS). Compared to the state-of-the-art\ndistributed Frank-Wolfe algorithm, our algorithm attains the same communication\ncomplexity under much more realistic assumptions. In contrast to the consensus\nbased algorithm, DCGS is based on the primal-dual algorithm, yielding a modular\nanalysis that can be exploited to improve linear oracle complexity whenever\ncentralized Frank-Wolfe can be improved. We demonstrate this advantage and show\nthat the linear oracle complexity can be reduced to almost the same order of\nmagnitude as the communication complexity, when the feasible set is polyhedral.\nFinally we present experimental results on Lasso and matrix completion,\ndemonstrating significant performance improvement compared to the existing\ndistributed Frank-Wolfe algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 23:36:44 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Li", "Yan", ""], ["Qu", "Chao", ""], ["Xu", "Huan", ""]]}, {"id": "1805.07844", "submitter": "Yan  Li", "authors": "Yan Li, Chao Qu, Huan Xu", "title": "Projection-Free Algorithms in Statistical Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frank-Wolfe algorithm (FW) and its variants have gained a surge of interests\nin machine learning community due to its projection-free property. Recently\npeople have reduced the gradient evaluation complexity of FW algorithm to\n$\\log(\\frac{1}{\\epsilon})$ for the smooth and strongly convex objective. This\ncomplexity result is especially significant in learning problem, as the\noverwhelming data size makes a single evluation of gradient computational\nexpensive. However, in high-dimensional statistical estimation problems, the\nobjective is typically not strongly convex, and sometimes even non-convex. In\nthis paper, we extend the state-of-the-art FW type algorithms for the\nlarge-scale, high-dimensional estimation problem. We show that as long as the\nobjective satisfies {\\em restricted strong convexity}, and we are not\noptimizing over statistical limit of the model, the $\\log(\\frac{1}{\\epsilon})$\ngradient evaluation complexity could still be attained.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 23:49:25 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Li", "Yan", ""], ["Qu", "Chao", ""], ["Xu", "Huan", ""]]}, {"id": "1805.07848", "submitter": "Yaniv Taigman", "authors": "Noam Mor, Lior Wolf, Adam Polyak, Yaniv Taigman", "title": "A Universal Music Translation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for translating music across musical instruments, genres,\nand styles. This method is based on a multi-domain wavenet autoencoder, with a\nshared encoder and a disentangled latent space that is trained end-to-end on\nwaveforms. Employing a diverse training dataset and large net capacity, the\ndomain-independent encoder allows us to translate even from musical domains\nthat were not seen during training. The method is unsupervised and does not\nrely on supervision in the form of matched samples between domains or musical\ntranscriptions. We evaluate our method on NSynth, as well as on a dataset\ncollected from professional musicians, and achieve convincing translations,\neven when translating from whistling, potentially enabling the creation of\ninstrumental music by untrained humans.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 00:20:03 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 17:23:54 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Mor", "Noam", ""], ["Wolf", "Lior", ""], ["Polyak", "Adam", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1805.07852", "submitter": "Alistair Shilton", "authors": "Alistair Shilton, Sunil Gupta, Santu Rana, Pratibha Vellanki, Laurence\n  Park, Cheng Li, Svetha Venkatesh, Alessandra Sutti, David Rubin, Thomas\n  Dorin, Alireza Vahid, Murray Height, Teo Slezak", "title": "Accelerated Bayesian Optimization throughWeight-Prior Tuning", "comments": null, "journal-ref": "PMLR 108:635-645, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a widely-used method for optimizing expensive\n(to evaluate) problems. At the core of most BO methods is the modeling of the\nobjective function using a Gaussian Process (GP) whose covariance is selected\nfrom a set of standard covariance functions. From a weight-space view, this\nmodels the objective as a linear function in a feature space implied by the\ngiven covariance K, with an arbitrary Gaussian weight prior ${\\bf w} \\sim\n\\mathcal{N} ({\\bf 0}, {\\bf I})$. In many practical applications there is data\navailable that has a similar (covariance) structure to the objective, but\nwhich, having different form, cannot be used directly in standard transfer\nlearning. In this paper we show how such auxiliary data may be used to\nconstruct a GP covariance corresponding to a more appropriate weight prior for\nthe objective function. Building on this, we show that we may accelerate BO by\nmodeling the objective function using this (learned) weight prior, which we\ndemonstrate on both test functions and a practical application to short-polymer\nfibre manufacture.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 00:33:07 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 22:37:23 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Shilton", "Alistair", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Vellanki", "Pratibha", ""], ["Park", "Laurence", ""], ["Li", "Cheng", ""], ["Venkatesh", "Svetha", ""], ["Sutti", "Alessandra", ""], ["Rubin", "David", ""], ["Dorin", "Thomas", ""], ["Vahid", "Alireza", ""], ["Height", "Murray", ""], ["Slezak", "Teo", ""]]}, {"id": "1805.07857", "submitter": "Rongjie Lai", "authors": "Stefan C. Schonsheck, Bin Dong, Rongjie Lai", "title": "Parallel Transport Convolution: A New Tool for Convolutional Neural\n  Networks on Manifolds", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution has been playing a prominent role in various applications in\nscience and engineering for many years. It is the most important operation in\nconvolutional neural networks. There has been a recent growth of interests of\nresearch in generalizing convolutions on curved domains such as manifolds and\ngraphs. However, existing approaches cannot preserve all the desirable\nproperties of Euclidean convolutions, namely compactly supported filters,\ndirectionality, transferability across different manifolds. In this paper we\ndevelop a new generalization of the convolution operation, referred to as\nparallel transport convolution (PTC), on Riemannian manifolds and their\ndiscrete counterparts. PTC is designed based on the parallel transportation\nwhich is able to translate information along a manifold and to intrinsically\npreserve directionality. PTC allows for the construction of compactly supported\nfilters and is also robust to manifold deformations. This enables us to preform\nwavelet-like operations and to define deep convolutional neural networks on\ncurved domains.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 01:13:20 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 21:36:34 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Schonsheck", "Stefan C.", ""], ["Dong", "Bin", ""], ["Lai", "Rongjie", ""]]}, {"id": "1805.07862", "submitter": "Qingcan Wang", "authors": "Ruying Bao, Sihang Liang, Qingcan Wang", "title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially\n  Learned Semantic Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been demonstrated to be vulnerable to adversarial\nattacks, where small perturbations intentionally added to the original inputs\ncan fool the classifier. In this paper, we propose a defense method, Featurized\nBidirectional Generative Adversarial Networks (FBGAN), to extract the semantic\nfeatures of the input and filter the non-semantic perturbation. FBGAN is\npre-trained on the clean dataset in an unsupervised manner, adversarially\nlearning a bidirectional mapping between the high-dimensional data space and\nthe low-dimensional semantic space; also mutual information is applied to\ndisentangle the semantically meaningful features. After the bidirectional\nmapping, the adversarial data can be reconstructed to denoised data, which\ncould be fed into any pre-trained classifier. We empirically show the quality\nof reconstruction images and the effectiveness of defense.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 01:49:18 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 20:30:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bao", "Ruying", ""], ["Liang", "Sihang", ""], ["Wang", "Qingcan", ""]]}, {"id": "1805.07866", "submitter": "Yingyezhe Jin", "authors": "Yingyezhe Jin, Wenrui Zhang and Peng Li", "title": "Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking\n  Neural Networks", "comments": "11 pages, 5 figures. Published at NeurIPS (Neural Information\n  Processing System) 2018. Code available:\n  https://github.com/jinyyy666/mm-bp-snn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are positioned to enable spatio-temporal\ninformation processing and ultra-low power event-driven neuromorphic hardware.\nHowever, SNNs are yet to reach the same performances of conventional deep\nartificial neural networks (ANNs), a long-standing challenge due to complex\ndynamics and non-differentiable spike events encountered in training. The\nexisting SNN error backpropagation (BP) methods are limited in terms of\nscalability, lack of proper handling of spiking discontinuities, and/or\nmismatch between the rate-coded loss function and computed gradient. We present\na hybrid macro/micro level backpropagation (HM2-BP) algorithm for training\nmulti-layer SNNs. The temporal effects are precisely captured by the proposed\nspike-train level post-synaptic potential (S-PSP) at the microscopic level. The\nrate-coded errors are defined at the macroscopic level, computed and\nback-propagated across both macroscopic and microscopic levels. Different from\nexisting BP methods, HM2-BP directly computes the gradient of the rate-coded\nloss function w.r.t tunable parameters. We evaluate the proposed HM2-BP\nalgorithm by training deep fully connected and convolutional SNNs based on the\nstatic MNIST [14] and dynamic neuromorphic N-MNIST [26]. HM2-BP achieves an\naccuracy level of 99.49% and 98.88% for MNIST and N-MNIST, respectively,\noutperforming the best reported performances obtained from the existing SNN BP\nalgorithms. Furthermore, the HM2-BP produces the highest accuracies based on\nSNNs for the EMNIST [3] dataset, and leads to high recognition accuracy for the\n16-speaker spoken English letters of TI46 Corpus [16], a challenging\npatio-temporal speech recognition benchmark for which no prior success based on\nSNNs was reported. It also achieves competitive performances surpassing those\nof conventional deep learning models when dealing with asynchronous spiking\nstreams.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:04:30 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 05:32:05 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 06:34:07 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 03:47:02 GMT"}, {"version": "v5", "created": "Wed, 12 Dec 2018 04:44:45 GMT"}, {"version": "v6", "created": "Sat, 19 Jan 2019 16:43:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Jin", "Yingyezhe", ""], ["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "1805.07869", "submitter": "John Clemens", "authors": "John Clemens", "title": "Learning Device Models with Recurrent Neural Networks", "comments": "Under review for publication at IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489466", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful constructs capable of modeling\ncomplex systems, up to and including Turing Machines. However, learning such\ncomplex models from finite training sets can be difficult. In this paper we\nempirically show that RNNs can learn models of computer peripheral devices\nthrough input and output state observation. This enables automated development\nof functional software-only models of hardware devices. Such models are\napplicable to any number of tasks, including device validation, driver\ndevelopment, code de-obfuscation, and reverse engineering. We show that the\nsame RNN structure successfully models six different devices from simple test\ncircuits up to a 16550 UART serial port, and verify that these models are\ncapable of producing equivalent output to real hardware.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:23:49 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Clemens", "John", ""]]}, {"id": "1805.07871", "submitter": "Prashant Doshi", "authors": "Saurabh Arora and Prashant Doshi and Bikramjit Banerjee", "title": "A Framework and Method for Online Inverse Reinforcement Learning", "comments": null, "journal-ref": "Journal of Autonomous Agents and Multi-Agent Systems, Volume 35,\n  Article number: 4 (2021)", "doi": "10.1007/s10458-020-09485-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) is the problem of learning the\npreferences of an agent from the observations of its behavior on a task. While\nthis problem has been well investigated, the related problem of {\\em online}\nIRL---where the observations are incrementally accrued, yet the demands of the\napplication often prohibit a full rerun of an IRL method---has received\nrelatively less attention. We introduce the first formal framework for online\nIRL, called incremental IRL (I2RL), and a new method that advances maximum\nentropy IRL with hidden variables, to this setting. Our formal analysis shows\nthat the new method has a monotonically improving performance with more\ndemonstration data, as well as probabilistically bounded error, both under full\nand partial observability. Experiments in a simulated robotic application of\npenetrating a continuous patrol under occlusion shows the relatively improved\nperformance and speed up of the new method and validates the utility of online\nIRL.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:27:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Arora", "Saurabh", ""], ["Doshi", "Prashant", ""], ["Banerjee", "Bikramjit", ""]]}, {"id": "1805.07874", "submitter": "Yu-Chiao Chiu", "authors": "Hung-I Harry Chen, Yu-Chiao Chiu, Tinghe Zhang, Songyao Zhang, Yufei\n  Huang, Yidong Chen", "title": "GSAE: an autoencoder with embedded gene-set nodes for genomics\n  functional characterization", "comments": "Presented in the International Conference on Intelligent Biology and\n  Medicine (ICIBM 2018) at Los Angeles, CA, USA and published in BMC Systems\n  Biology 2018, 12(Suppl 8):142", "journal-ref": "BMC Systems Biology 2018, 12(Suppl 8):142", "doi": "10.1186/s12918-018-0642-2", "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bioinformatics tools have been developed to interpret gene expression data at\nthe gene set level, and these gene set based analyses improve the biologists'\ncapability to discover functional relevance of their experiment design. While\nelucidating gene set individually, inter gene sets association is rarely taken\ninto consideration. Deep learning, an emerging machine learning technique in\ncomputational biology, can be used to generate an unbiased combination of gene\nset, and to determine the biological relevance and analysis consistency of\nthese combining gene sets by leveraging large genomic data sets. In this study,\nwe proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model\nwith the incorporation of a priori defined gene sets that retain the crucial\nbiological features in the latent layer. We introduced the concept of the gene\nsuperset, an unbiased combination of gene sets with weights trained by the\nautoencoder, where each node in the latent layer is a superset. Trained with\ngenomic data from TCGA and evaluated with their accompanying clinical\nparameters, we showed gene supersets' ability of discriminating tumor subtypes\nand their prognostic capability. We further demonstrated the biological\nrelevance of the top component gene sets in the significant supersets. Using\nautoencoder model and gene superset at its latent layer, we demonstrated that\ngene supersets retain sufficient biological information with respect to tumor\nsubtypes and clinical prognostic significance. Superset also provides high\nreproducibility on survival analysis and accurate prediction for cancer\nsubtypes.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:37:54 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 20:53:26 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Chen", "Hung-I Harry", ""], ["Chiu", "Yu-Chiao", ""], ["Zhang", "Tinghe", ""], ["Zhang", "Songyao", ""], ["Huang", "Yufei", ""], ["Chen", "Yidong", ""]]}, {"id": "1805.07880", "submitter": "Yi Xu", "authors": "Yi Xu, Shenghuo Zhu, Sen Yang, Chi Zhang, Rong Jin, Tianbao Yang", "title": "Learning with Non-Convex Truncated Losses by SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with a {\\it convex loss} function has been a dominating paradigm for\nmany years. It remains an interesting question how non-convex loss functions\nhelp improve the generalization of learning with broad applicability. In this\npaper, we study a family of objective functions formed by truncating\ntraditional loss functions, which is applicable to both shallow learning and\ndeep learning. Truncating loss functions has potential to be less vulnerable\nand more robust to large noise in observations that could be adversarial. More\nimportantly, it is a generic technique without assuming the knowledge of noise\ndistribution. To justify non-convex learning with truncated losses, we\nestablish excess risk bounds of empirical risk minimization based on truncated\nlosses for heavy-tailed output, and statistical error of an approximate\nstationary point found by stochastic gradient descent (SGD) method. Our\nexperiments for shallow and deep learning for regression with outliers,\ncorrupted data and heavy-tailed noise further justify the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 03:41:37 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Xu", "Yi", ""], ["Zhu", "Shenghuo", ""], ["Yang", "Sen", ""], ["Zhang", "Chi", ""], ["Jin", "Rong", ""], ["Yang", "Tianbao", ""]]}, {"id": "1805.07883", "submitter": "Yining Wang", "authors": "Simon S. Du, Yining Wang, Xiyu Zhai, Sivaraman Balakrishnan, Ruslan\n  Salakhutdinov, Aarti Singh", "title": "How Many Samples are Needed to Estimate a Convolutional or Recurrent\n  Neural Network?", "comments": "Revised version, with new results on recurrent neural networks.\n  Preliminary version in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that the practical success of Convolutional Neural\nNetworks (CNNs) and Recurrent Neural Networks (RNNs) owes to the fact that CNNs\nand RNNs use a more compact parametric representation than their\nFully-Connected Neural Network (FNN) counterparts, and consequently require\nfewer training examples to accurately estimate their parameters. We initiate\nthe study of rigorously characterizing the sample-complexity of estimating CNNs\nand RNNs. We show that the sample-complexity to learn CNNs and RNNs scales\nlinearly with their intrinsic dimension and this sample-complexity is much\nsmaller than for their FNN counterparts. For both CNNs and RNNs, we also\npresent lower bounds showing our sample complexities are tight up to\nlogarithmic factors. Our main technical tools for deriving these results are a\nlocalized empirical process analysis and a new technical lemma characterizing\nthe convolutional and recurrent structure. We believe that these tools may\ninspire further developments in understanding CNNs and RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 03:56:17 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 04:18:24 GMT"}, {"version": "v3", "created": "Sun, 30 Jun 2019 00:24:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Du", "Simon S.", ""], ["Wang", "Yining", ""], ["Zhai", "Xiyu", ""], ["Balakrishnan", "Sivaraman", ""], ["Salakhutdinov", "Ruslan", ""], ["Singh", "Aarti", ""]]}, {"id": "1805.07891", "submitter": "Liang Luo", "authors": "Liang Luo, Jacob Nelson, Luis Ceze, Amar Phanishayee, Arvind\n  Krishnamurthy", "title": "Parameter Hub: a Rack-Scale Parameter Server for Distributed Deep Neural\n  Network Training", "comments": null, "journal-ref": null, "doi": "10.1145/3267809.3267840", "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed deep neural network (DDNN) training constitutes an increasingly\nimportant workload that frequently runs in the cloud. Larger DNN models and\nfaster compute engines are shifting DDNN training bottlenecks from computation\nto communication. This paper characterizes DDNN training to precisely pinpoint\nthese bottlenecks. We found that timely training requires high performance\nparameter servers (PSs) with optimized network stacks and gradient processing\npipelines, as well as server and network hardware with balanced computation and\ncommunication resources. We therefore propose PHub, a high performance\nmulti-tenant, rack-scale PS design. PHub co-designs the PS software and\nhardware to accelerate rack-level and hierarchical cross-rack parameter\nexchange, with an API compatible with many DDNN training frameworks. PHub\nprovides a performance improvement of up to 2.7x compared to state-of-the-art\ndistributed training techniques for cloud-based ImageNet workloads, with 25%\nbetter throughput per dollar.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 04:55:04 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 21:18:51 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Luo", "Liang", ""], ["Nelson", "Jacob", ""], ["Ceze", "Luis", ""], ["Phanishayee", "Amar", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1805.07892", "submitter": "Chandan Gautam", "authors": "Chandan Gautam, Ramesh Balaji, K Sudharsan, Aruna Tiwari, Kapil Ahuja", "title": "Localized Multiple Kernel Learning for Anomaly Detection: One-class\n  Classification", "comments": "21 pages, 9 Tables and 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-kernel learning has been well explored in the recent past and has\nexhibited promising outcomes for multi-class classification and regression\ntasks. In this paper, we present a multiple kernel learning approach for the\nOne-class Classification (OCC) task and employ it for anomaly detection.\nRecently, the basic multi-kernel approach has been proposed to solve the OCC\nproblem, which is simply a convex combination of different kernels with equal\nweights. This paper proposes a Localized Multiple Kernel learning approach for\nAnomaly Detection (LMKAD) using OCC, where the weight for each kernel is\nassigned locally. Proposed LMKAD approach adapts the weight for each kernel\nusing a gating function. The parameters of the gating function and one-class\nclassifier are optimized simultaneously through a two-step optimization\nprocess. We present the empirical results of the performance of LMKAD on 25\nbenchmark datasets from various disciplines. This performance is evaluated\nagainst existing Multi Kernel Anomaly Detection (MKAD) algorithm, and four\nother existing kernel-based one-class classifiers to showcase the credibility\nof our approach. Our algorithm achieves significantly better Gmean scores while\nusing a lesser number of support vectors compared to MKAD. Friedman test is\nalso performed to verify the statistical significance of the results claimed in\nthis paper.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 05:04:46 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 12:45:25 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 13:07:25 GMT"}, {"version": "v4", "created": "Tue, 17 Jul 2018 06:17:52 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Gautam", "Chandan", ""], ["Balaji", "Ramesh", ""], ["Sudharsan", "K", ""], ["Tiwari", "Aruna", ""], ["Ahuja", "Kapil", ""]]}, {"id": "1805.07894", "submitter": "Yang Song", "authors": "Yang Song, Rui Shu, Nate Kushman, Stefano Ermon", "title": "Constructing Unrestricted Adversarial Examples with Generative Models", "comments": "Neural Information Processing Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are typically constructed by perturbing an existing data\npoint within a small matrix norm, and current defense methods are focused on\nguarding against this type of attack. In this paper, we propose unrestricted\nadversarial examples, a new threat model where the attackers are not restricted\nto small norm-bounded perturbations. Different from perturbation-based attacks,\nwe propose to synthesize unrestricted adversarial examples entirely from\nscratch using conditional generative models. Specifically, we first train an\nAuxiliary Classifier Generative Adversarial Network (AC-GAN) to model the\nclass-conditional distribution over data samples. Then, conditioned on a\ndesired class, we search over the AC-GAN latent space to find images that are\nlikely under the generative model and are misclassified by a target classifier.\nWe demonstrate through human evaluation that unrestricted adversarial examples\ngenerated this way are legitimate and belong to the desired class. Our\nempirical results on the MNIST, SVHN, and CelebA datasets show that\nunrestricted adversarial examples can bypass strong adversarial training and\ncertified defense methods designed for traditional adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 05:19:08 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 03:55:54 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 05:46:09 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 22:18:56 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Song", "Yang", ""], ["Shu", "Rui", ""], ["Kushman", "Nate", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.07898", "submitter": "Wei Wen", "authors": "Wei Wen, Yandan Wang, Feng Yan, Cong Xu, Chunpeng Wu, Yiran Chen, Hai\n  Li", "title": "SmoothOut: Smoothing Out Sharp Minima to Improve Generalization in Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Deep Learning, Stochastic Gradient Descent (SGD) is usually selected as a\ntraining method because of its efficiency; however, recently, a problem in SGD\ngains research interest: sharp minima in Deep Neural Networks (DNNs) have poor\ngeneralization; especially, large-batch SGD tends to converge to sharp minima.\nIt becomes an open question whether escaping sharp minima can improve the\ngeneralization. To answer this question, we propose SmoothOut framework to\nsmooth out sharp minima in DNNs and thereby improve generalization. In a\nnutshell, SmoothOut perturbs multiple copies of the DNN by noise injection and\naverages these copies. Injecting noises to SGD is widely used in the\nliterature, but SmoothOut differs in lots of ways: (1) a de-noising process is\napplied before parameter updating; (2) noise strength is adapted to filter\nnorm; (3) an alternative interpretation on the advantage of noise injection,\nfrom the perspective of sharpness and generalization; (4) usage of uniform\nnoise instead of Gaussian noise. We prove that SmoothOut can eliminate sharp\nminima. Training multiple DNN copies is inefficient, we further propose an\nunbiased stochastic SmoothOut which only introduces the overhead of noise\ninjecting and de-noising per batch. An adaptive variant of SmoothOut,\nAdaSmoothOut, is also proposed to improve generalization. In a variety of\nexperiments, SmoothOut and AdaSmoothOut consistently improve generalization in\nboth small-batch and large-batch training on the top of state-of-the-art\nsolutions.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 05:28:22 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 20:44:05 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 15:20:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wen", "Wei", ""], ["Wang", "Yandan", ""], ["Yan", "Feng", ""], ["Xu", "Cong", ""], ["Wu", "Chunpeng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1805.07909", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Jennifer Jang, Samory Kpotufe", "title": "Quickshift++: Provably Good Initializations for Sample-Based Mean Shift", "comments": "ICML 2018. Code release: https://github.com/google/quickshift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide initial seedings to the Quick Shift clustering algorithm, which\napproximate the locally high-density regions of the data. Such seedings act as\nmore stable and expressive cluster-cores than the singleton modes found by\nQuick Shift. We establish statistical consistency guarantees for this\nmodification. We then show strong clustering performance on real datasets as\nwell as promising applications to image segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:42:30 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Jiang", "Heinrich", ""], ["Jang", "Jennifer", ""], ["Kpotufe", "Samory", ""]]}, {"id": "1805.07912", "submitter": "Futoshi Futami", "authors": "Futoshi Futami, Zhenghang Cui, Issei Sato, Masashi Sugiyama", "title": "Bayesian posterior approximation via greedy particle optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian inference, the posterior distributions are difficult to obtain\nanalytically for complex models such as neural networks. Variational inference\nusually uses a parametric distribution for approximation, from which we can\neasily draw samples. Recently discrete approximation by particles has attracted\nattention because of its high expression ability. An example is Stein\nvariational gradient descent (SVGD), which iteratively optimizes particles.\nAlthough SVGD has been shown to be computationally efficient empirically, its\ntheoretical properties have not been clarified yet and no finite sample bound\nof the convergence rate is known. Another example is the Stein points (SP)\nmethod, which minimizes kernelized Stein discrepancy directly. Although a\nfinite sample bound is assured theoretically, SP is computationally inefficient\nempirically, especially in high-dimensional problems. In this paper, we propose\na novel method named maximum mean discrepancy minimization by the Frank-Wolfe\nalgorithm (MMD-FW), which minimizes MMD in a greedy way by the FW algorithm.\nOur method is computationally efficient empirically and we show that its finite\nsample convergence bound is in a linear order in finite dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:43:56 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 19:47:34 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 18:54:23 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Futami", "Futoshi", ""], ["Cui", "Zhenghang", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1805.07914", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Himanshu Sahni, Yannick Schroecker, Charles L.\n  Isbell", "title": "Imitating Latent Policies from Observation", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a novel approach to imitation learning that infers\nlatent policies directly from state observations. We introduce a method that\ncharacterizes the causal effects of latent actions on observations while\nsimultaneously predicting their likelihood. We then outline an action alignment\nprocedure that leverages a small amount of environment interactions to\ndetermine a mapping between the latent and real-world actions. We show that\nthis corrected labeling can be used for imitating the observed behavior, even\nthough no expert actions are given. We evaluate our approach within classic\ncontrol environments and a platform game and demonstrate that it performs\nbetter than standard approaches. Code for this work is available at\nhttps://github.com/ashedwards/ILPO.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:49:57 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 06:40:13 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 07:13:07 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Sahni", "Himanshu", ""], ["Schroecker", "Yannick", ""], ["Isbell", "Charles L.", ""]]}, {"id": "1805.07917", "submitter": "Shauharda Khadka", "authors": "Shauharda Khadka and Kagan Tumer", "title": "Evolution-Guided Policy Gradient in Reinforcement Learning", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018),\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) algorithms have been successfully applied\nto a range of challenging control tasks. However, these methods typically\nsuffer from three core difficulties: temporal credit assignment with sparse\nrewards, lack of effective exploration, and brittle convergence properties that\nare extremely sensitive to hyperparameters. Collectively, these challenges\nseverely limit the applicability of these approaches to real-world problems.\nEvolutionary Algorithms (EAs), a class of black box optimization techniques\ninspired by natural evolution, are well suited to address each of these three\nchallenges. However, EAs typically suffer from high sample complexity and\nstruggle to solve problems that require optimization of a large number of\nparameters. In this paper, we introduce Evolutionary Reinforcement Learning\n(ERL), a hybrid algorithm that leverages the population of an EA to provide\ndiversified data to train an RL agent, and reinserts the RL agent into the EA\npopulation periodically to inject gradient information into the EA. ERL\ninherits EA's ability of temporal credit assignment with a fitness metric,\neffective exploration with a diverse set of policies, and stability of a\npopulation-based approach and complements it with off-policy DRL's ability to\nleverage gradients for higher sample efficiency and faster learning.\nExperiments in a range of challenging continuous control benchmarks demonstrate\nthat ERL significantly outperforms prior DRL and EA methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:55:58 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 17:23:26 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Khadka", "Shauharda", ""], ["Tumer", "Kagan", ""]]}, {"id": "1805.07932", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Jaehyun Jun, Byoung-Tak Zhang", "title": "Bilinear Attention Networks", "comments": "Accepted by NIPS 2018; Figure 1 was updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks in multimodal learning provide an efficient way to utilize\ngiven visual information selectively. However, the computational cost to learn\nattention distributions for every pair of multimodal input channels is\nprohibitively expensive. To solve this problem, co-attention builds two\nseparate attention distributions for each modality neglecting the interaction\nbetween multimodal inputs. In this paper, we propose bilinear attention\nnetworks (BAN) that find bilinear attention distributions to utilize given\nvision-language information seamlessly. BAN considers bilinear interactions\namong two groups of input channels, while low-rank bilinear pooling extracts\nthe joint representations for each pair of channels. Furthermore, we propose a\nvariant of multimodal residual networks to exploit eight-attention maps of the\nBAN efficiently. We quantitatively and qualitatively evaluate our model on\nvisual question answering (VQA 2.0) and Flickr30k Entities datasets, showing\nthat BAN significantly outperforms previous methods and achieves new\nstate-of-the-arts on both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 07:58:31 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 11:29:49 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Jun", "Jaehyun", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1805.07938", "submitter": "Mahito Sugiyama", "authors": "Mahito Sugiyama, Koji Tsuda, Hiroyuki Nakahara", "title": "Transductive Boltzmann Machines", "comments": "10 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present transductive Boltzmann machines (TBMs), which firstly achieve\ntransductive learning of the Gibbs distribution. While exact learning of the\nGibbs distribution is impossible by the family of existing Boltzmann machines\ndue to combinatorial explosion of the sample space, TBMs overcome the problem\nby adaptively constructing the minimum required sample space from data to avoid\nunnecessary generalization. We theoretically provide bias-variance\ndecomposition of the KL divergence in TBMs to analyze its learnability, and\nempirically demonstrate that TBMs are superior to the fully visible Boltzmann\nmachines and popularly used restricted Boltzmann machines in terms of\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:15:09 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Sugiyama", "Mahito", ""], ["Tsuda", "Koji", ""], ["Nakahara", "Hiroyuki", ""]]}, {"id": "1805.07941", "submitter": "Sean O. Settle", "authors": "Sean O. Settle, Manasa Bollavaram, Paolo D'Alberto, Elliott Delaye,\n  Oscar Fernandez, Nicholas Fraser, Aaron Ng, Ashish Sirasao, Michael Wu", "title": "Quantizing Convolutional Neural Networks for Low-Power High-Throughput\n  Inference Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning as a means to inferencing has proliferated thanks to its\nversatility and ability to approach or exceed human-level accuracy. These\ncomputational models have seemingly insatiable appetites for computational\nresources not only while training, but also when deployed at scales ranging\nfrom data centers all the way down to embedded devices. As such, increasing\nconsideration is being made to maximize the computational efficiency given\nlimited hardware and energy resources and, as a result, inferencing with\nreduced precision has emerged as a viable alternative to the IEEE 754 Standard\nfor Floating-Point Arithmetic. We propose a quantization scheme that allows\ninferencing to be carried out using arithmetic that is fundamentally more\nefficient when compared to even half-precision floating-point. Our quantization\nprocedure is significant in that we determine our quantization scheme\nparameters by calibrating against its reference floating-point model using a\nsingle inference batch rather than (re)training and achieve end-to-end post\nquantization accuracies comparable to the reference model.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:31:46 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Settle", "Sean O.", ""], ["Bollavaram", "Manasa", ""], ["D'Alberto", "Paolo", ""], ["Delaye", "Elliott", ""], ["Fernandez", "Oscar", ""], ["Fraser", "Nicholas", ""], ["Ng", "Aaron", ""], ["Sirasao", "Ashish", ""], ["Wu", "Michael", ""]]}, {"id": "1805.07943", "submitter": "Edouard Pauwels", "authors": "Edouard Pauwels, Francis Bach, Jean-Philippe Vert", "title": "Relating Leverage Scores and Density using Regularized Christoffel\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical leverage scores emerged as a fundamental tool for matrix\nsketching and column sampling with applications to low rank approximation,\nregression, random feature learning and quadrature. Yet, the very nature of\nthis quantity is barely understood. Borrowing ideas from the orthogonal\npolynomial literature, we introduce the regularized Christoffel function\nassociated to a positive definite kernel. This uncovers a variational\nformulation for leverage scores for kernel methods and allows to elucidate\ntheir relationships with the chosen kernel as well as population density. Our\nmain result quantitatively describes a decreasing relation between leverage\nscore and population density for a broad class of kernels on Euclidean spaces.\nNumerical simulations support our findings.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:35:26 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 09:51:09 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Pauwels", "Edouard", ""], ["Bach", "Francis", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1805.07956", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor", "title": "Multiple-Step Greedy Policies in Online and Approximate Reinforcement\n  Learning", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-step lookahead policies have demonstrated high empirical competence\nin Reinforcement Learning, via the use of Monte Carlo Tree Search or Model\nPredictive Control. In a recent work \\cite{efroni2018beyond}, multiple-step\ngreedy policies and their use in vanilla Policy Iteration algorithms were\nproposed and analyzed. In this work, we study multiple-step greedy algorithms\nin more practical setups. We begin by highlighting a counter-intuitive\ndifficulty, arising with soft-policy updates: even in the absence of\napproximations, and contrary to the 1-step-greedy case, monotonic policy\nimprovement is not guaranteed unless the update stepsize is sufficiently large.\nTaking particular care about this difficulty, we formulate and analyze online\nand approximate algorithms that use such a multi-step greedy operator.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 09:17:09 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 12:39:27 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Efroni", "Yonathan", ""], ["Dalal", "Gal", ""], ["Scherrer", "Bruno", ""], ["Mannor", "Shie", ""]]}, {"id": "1805.07960", "submitter": "Takayuki Kawashima", "authors": "Takayuki Kawashima and Hironori Fujisawa", "title": "Stochastic Gradient Descent for Stochastic Doubly-Nonconvex Composite\n  Optimization", "comments": "There is a mistake in the proof of Proposition 3.2. related to the\n  Euclidean projection with stochastic gradients", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient descent has been widely used for solving composite\noptimization problems in big data analyses. Many algorithms and convergence\nproperties have been developed. The composite functions were convex primarily\nand gradually nonconvex composite functions have been adopted to obtain more\ndesirable properties. The convergence properties have been investigated, but\nonly when either of composite functions is nonconvex. There is no convergence\nproperty when both composite functions are nonconvex, which is named the\n\\textit{doubly-nonconvex} case.To overcome this difficulty, we assume a simple\nand weak condition that the penalty function is \\textit{quasiconvex} and then\nwe obtain convergence properties for the stochastic doubly-nonconvex composite\noptimization problem.The convergence rate obtained here is of the same order as\nthe existing work.We deeply analyze the convergence rate with the constant step\nsize and mini-batch size and give the optimal convergence rate with appropriate\nsizes, which is superior to the existing work. Experimental results illustrate\nthat our method is superior to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 09:34:47 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 02:58:39 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kawashima", "Takayuki", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "1805.07978", "submitter": "Seongsik Park", "authors": "Seongsik Park, Jaehee Jang, Seijoon Kim, Sungroh Yoon", "title": "Energy-Efficient Inference Accelerator for Memory-Augmented Neural\n  Networks on an FPGA", "comments": "Accepted to DATE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-augmented neural networks (MANNs) are designed for question-answering\ntasks. It is difficult to run a MANN effectively on accelerators designed for\nother neural networks (NNs), in particular on mobile devices, because MANNs\nrequire recurrent data paths and various types of operations related to\nexternal memory access. We implement an accelerator for MANNs on a\nfield-programmable gate array (FPGA) based on a data flow architecture.\nInference times are also reduced by inference thresholding, which is a\ndata-based maximum inner-product search specialized for natural language tasks.\nMeasurements on the bAbI data show that the energy efficiency of the\naccelerator (FLOPS/kJ) was higher than that of an NVIDIA TITAN V GPU by a\nfactor of about 125, increasing to 140 with inference thresholding\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 10:34:22 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 05:00:30 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Park", "Seongsik", ""], ["Jang", "Jaehee", ""], ["Kim", "Seijoon", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1805.07979", "submitter": "Jieyun Huang", "authors": "Jieyun Huang, Yunjia Zhang, Jialai Zhang, Xi Zhang", "title": "A Tensor-Based Sub-Mode Coordinate Algorithm for Stock Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The investment on the stock market is prone to be affected by the Internet.\nFor the purpose of improving the prediction accuracy, we propose a multi-task\nstock prediction model that not only considers the stock correlations but also\nsupports multi-source data fusion. Our proposed model first utilizes tensor to\nintegrate the multi-sourced data, including financial Web news, investors'\nsentiments extracted from the social network and some quantitative data on\nstocks. In this way, the intrinsic relationships among different information\nsources can be captured, and meanwhile, multi-sourced information can be\ncomplemented to solve the data sparsity problem. Secondly, we propose an\nimproved sub-mode coordinate algorithm (SMC). SMC is based on the stock\nsimilarity, aiming to reduce the variance of their subspace in each dimension\nproduced by the tensor decomposition. The algorithm is able to improve the\nquality of the input features, and thus improves the prediction accuracy. And\nthe paper utilizes the Long Short-Term Memory (LSTM) neural network model to\npredict the stock fluctuation trends. Finally, the experiments on 78 A-share\nstocks in CSI 100 and thirteen popular HK stocks in the year 2015 and 2016 are\nconducted. The results demonstrate the improvement on the prediction accuracy\nand the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 10:36:46 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Huang", "Jieyun", ""], ["Zhang", "Yunjia", ""], ["Zhang", "Jialai", ""], ["Zhang", "Xi", ""]]}, {"id": "1805.07984", "submitter": "Daniel Z\\\"ugner", "authors": "Daniel Z\\\"ugner, Amir Akbarnejad and Stephan G\\\"unnemann", "title": "Adversarial Attacks on Neural Networks for Graph Data", "comments": "Accepted as a full paper at KDD 2018 on May 6, 2018", "journal-ref": "Proceedings of the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining, KDD 2018, pp. 2847-2856", "doi": "10.1145/3219819.3220078", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for graphs have achieved strong performance for the task\nof node classification. Despite their proliferation, currently there is no\nstudy of their robustness to adversarial attacks. Yet, in domains where they\nare likely to be used, e.g. the web, adversaries are common. Can deep learning\nmodels for graphs be easily fooled? In this work, we introduce the first study\nof adversarial attacks on attributed graphs, specifically focusing on models\nexploiting ideas of graph convolutions. In addition to attacks at test time, we\ntackle the more challenging class of poisoning/causative attacks, which focus\non the training phase of a machine learning model. We generate adversarial\nperturbations targeting the node's features and the graph structure, thus,\ntaking the dependencies between instances in account. Moreover, we ensure that\nthe perturbations remain unnoticeable by preserving important data\ncharacteristics. To cope with the underlying discrete domain we propose an\nefficient algorithm Nettack exploiting incremental computations. Our\nexperimental study shows that accuracy of node classification significantly\ndrops even when performing only few perturbations. Even more, our attacks are\ntransferable: the learned attacks generalize to other state-of-the-art node\nclassification models and unsupervised approaches, and likewise are successful\neven when only limited knowledge about the graph is given.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 10:58:10 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 18:40:36 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 14:07:08 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Z\u00fcgner", "Daniel", ""], ["Akbarnejad", "Amir", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1805.08000", "submitter": "Zhonghui You", "authors": "Zhonghui You, Jinmian Ye, Kunming Li, Zenglin Xu, Ping Wang", "title": "Adversarial Noise Layer: Regularize Neural Network By Adding Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel regularization method called Adversarial\nNoise Layer (ANL) and its efficient version called Class Adversarial Noise\nLayer (CANL), which are able to significantly improve CNN's generalization\nability by adding carefully crafted noise into the intermediate layer\nactivations. ANL and CANL can be easily implemented and integrated with most of\nthe mainstream CNN-based models. We compared the effects of the different types\nof noise and visually demonstrate that our proposed adversarial noise instruct\nCNN models to learn to extract cleaner feature maps, which further reduce the\nrisk of over-fitting. We also conclude that models trained with ANL or CANL are\nmore robust to the adversarial examples generated by FGSM than the traditional\nadversarial training approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 11:50:59 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 03:02:45 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["You", "Zhonghui", ""], ["Ye", "Jinmian", ""], ["Li", "Kunming", ""], ["Xu", "Zenglin", ""], ["Wang", "Ping", ""]]}, {"id": "1805.08006", "submitter": "Sidney Pontes-Filho", "authors": "Sidney Pontes-Filho and Marcus Liwicki", "title": "Bidirectional Learning for Robust Neural Networks", "comments": "8 pages, 4 figures, submitted to 2019 International Joint Conference\n  on Neural Networks", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852120", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multilayer perceptron can behave as a generative classifier by applying\nbidirectional learning (BL). It consists of training an undirected neural\nnetwork to map input to output and vice-versa; therefore it can produce a\nclassifier in one direction, and a generator in the opposite direction for the\nsame data. The learning process of BL tries to reproduce the neuroplasticity\nstated in Hebbian theory using only backward propagation of errors. In this\npaper, two novel learning techniques are introduced which use BL for improving\nrobustness to white noise static and adversarial examples. The first method is\nbidirectional propagation of errors, which the error propagation occurs in\nbackward and forward directions. Motivated by the fact that its generative\nmodel receives as input a constant vector per class, we introduce as a second\nmethod the hybrid adversarial networks (HAN). Its generative model receives a\nrandom vector as input and its training is based on generative adversarial\nnetworks (GAN). To assess the performance of BL, we perform experiments using\nseveral architectures with fully and convolutional layers, with and without\nbias. Experimental results show that both methods improve robustness to white\nnoise static and adversarial examples, and even increase accuracy, but have\ndifferent behavior depending on the architecture and task, being more\nbeneficial to use the one or the other. Nevertheless, HAN using a convolutional\narchitecture with batch normalization presents outstanding robustness, reaching\nstate-of-the-art accuracy on adversarial examples of hand-written digits.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 12:06:28 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 16:15:45 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Pontes-Filho", "Sidney", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1805.08010", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Anca D. Dragan, Sergey Levine", "title": "Where Do You Think You're Going?: Inferring Beliefs about Dynamics from\n  Behavior", "comments": "Accepted at Neural Information Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring intent from observed behavior has been studied extensively within\nthe frameworks of Bayesian inverse planning and inverse reinforcement learning.\nThese methods infer a goal or reward function that best explains the actions of\nthe observed agent, typically a human demonstrator. Another agent can use this\ninferred intent to predict, imitate, or assist the human user. However, a\ncentral assumption in inverse reinforcement learning is that the demonstrator\nis close to optimal. While models of suboptimal behavior exist, they typically\nassume that suboptimal actions are the result of some type of random noise or a\nknown cognitive bias, like temporal inconsistency. In this paper, we take an\nalternative approach, and model suboptimal behavior as the result of internal\nmodel misspecification: the reason that user actions might deviate from\nnear-optimal actions is that the user has an incorrect set of beliefs about the\nrules -- the dynamics -- governing how actions affect the environment. Our\ninsight is that while demonstrated actions may be suboptimal in the real world,\nthey may actually be near-optimal with respect to the user's internal model of\nthe dynamics. By estimating these internal beliefs from observed behavior, we\narrive at a new method for inferring intent. We demonstrate in simulation and\nin a user study with 12 participants that this approach enables us to more\naccurately model human intent, and can be used in a variety of applications,\nincluding offering assistance in a shared autonomy framework and inferring\nhuman preferences.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 12:15:34 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 22:32:49 GMT"}, {"version": "v3", "created": "Sat, 20 Oct 2018 23:55:27 GMT"}, {"version": "v4", "created": "Sat, 5 Jan 2019 18:30:29 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Reddy", "Siddharth", ""], ["Dragan", "Anca D.", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.08034", "submitter": "Lars Ruthotto", "authors": "Eldad Haber, Felix Lucka, Lars Ruthotto", "title": "Never look back - A modified EnKF method and its application to the\n  training of neural networks without back propagation", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new derivative-free optimization method and\ninvestigate its use for training neural networks. Our method is motivated by\nthe Ensemble Kalman Filter (EnKF), which has been used successfully for solving\noptimization problems that involve large-scale, highly nonlinear dynamical\nsystems. A key benefit of the EnKF method is that it requires only the\nevaluation of the forward propagation but not its derivatives. Hence, in the\ncontext of neural networks, it alleviates the need for back propagation and\nreduces the memory consumption dramatically. However, the method is not a pure\n\"black-box\" global optimization heuristic as it efficiently utilizes the\nstructure of typical learning problems. Promising first results of the EnKF for\ntraining deep neural networks have been presented recently by Kovachki and\nStuart. We propose an important modification of the EnKF that enables us to\nprove convergence of our method to the minimizer of a strongly convex function.\nOur method also bears similarity with implicit filtering and we demonstrate its\npotential for minimizing highly oscillatory functions using a simple example.\nFurther, we provide numerical examples that demonstrate the potential of our\nmethod for training deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:08:31 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 13:07:07 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Haber", "Eldad", ""], ["Lucka", "Felix", ""], ["Ruthotto", "Lars", ""]]}, {"id": "1805.08045", "submitter": "Shengxi Li", "authors": "Shengxi Li, Zeyang Yu, Danilo Mandic", "title": "A universal framework for learning the elliptical mixture model", "comments": "This work has been accepted to IEEE Transactions on Neural Networks\n  and Learning Systems with DOI:10.1109/TNNLS.2020.3010198. The abstract link\n  is https://ieeexplore.ieee.org/document/9153118", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3010198", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture modelling using elliptical distributions promises enhanced\nrobustness, flexibility and stability over the widely employed Gaussian mixture\nmodel (GMM). However, existing studies based on the elliptical mixture model\n(EMM) are restricted to several specific types of elliptical probability\ndensity functions, which are not supported by general solutions or systematic\nanalysis frameworks; this significantly limits the rigour and the power of EMMs\nin applications. To this end, we propose a novel general framework for\nestimating and analysing the EMMs, achieved through Riemannian manifold\noptimisation. First, we investigate the relationships between Riemannian\nmanifolds and elliptical distributions, and the so established connection\nbetween the original manifold and a reformulated one indicates a mismatch\nbetween those manifolds, the major cause of failure of the existing\noptimisation for solving general EMMs. We next propose a universal solver which\nis based on the optimisation of a re-designed cost and prove the existence of\nthe same optimum as in the original problem; this is achieved in a simple, fast\nand stable way. We further calculate the influence functions of the EMM as\ntheoretical bounds to quantify robustness to outliers. Comprehensive numerical\nresults demonstrate the ability of the proposed framework to accommodate EMMs\nwith different properties of individual functions in a stable way and with fast\nconvergence speed. Finally, the enhanced robustness and flexibility of the\nproposed framework over the standard GMM are demonstrated both analytically and\nthrough comprehensive simulations.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:39:22 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 11:16:32 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 20:09:50 GMT"}, {"version": "v4", "created": "Sun, 12 Jan 2020 13:45:46 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 22:13:07 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Li", "Shengxi", ""], ["Yu", "Zeyang", ""], ["Mandic", "Danilo", ""]]}, {"id": "1805.08052", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "Online Learning in Kernelized Markov Decision Processes", "comments": "22nd International Conference on Artificial Intelligence and\n  Statistics (AISTATS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning for minimizing regret in unknown, episodic Markov\ndecision processes (MDPs) with continuous states and actions. We develop\nvariants of the UCRL and posterior sampling algorithms that employ\nnonparametric Gaussian process priors to generalize across the state and action\nspaces. When the transition and reward functions of the true MDP are members of\nthe associated Reproducing Kernel Hilbert Spaces of functions induced by\nsymmetric psd kernels (frequentist setting), we show that the algorithms enjoy\nsublinear regret bounds. The bounds are in terms of explicit structural\nparameters of the kernels, namely a novel generalization of the information\ngain metric from kernelized bandit, and highlight the influence of transition\nand reward function structure on the learning performance. Our results are\napplicable to multidimensional state and action spaces with composite kernel\nstructures, and generalize results from the literature on kernelized bandits,\nand the adaptive control of parametric linear dynamical systems with quadratic\ncosts.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:44:10 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 03:30:24 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1805.08058", "submitter": "Alexander Keil", "authors": "Alexander P. Keil, Daniel Westreich, Jessie K Edwards, Stephen R Cole", "title": "Super learning in the SAS system", "comments": "7 pages, 1 table, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and objective: Stacking is an ensemble machine learning method\nthat averages predictions from multiple other algorithms, such as generalized\nlinear models and regression trees. An implementation of stacking, called super\nlearning, has been developed as a general approach to supervised learning and\nhas seen frequent usage, in part due to the availability of an R package. We\ndevelop super learning in the SAS software system using a new macro, and\ndemonstrate its performance relative to the R package.\n  Methods: Following previous work using the R SuperLearner package we assess\nthe performance of super learning in a number of domains. We compare the R\npackage with the new SAS macro in a small set of simulations assessing curve\nfitting in a predictive model as well in a set of 14 publicly available\ndatasets to assess cross-validated accuracy.\n  Results: Across the simulated data and the publicly available data, the SAS\nmacro performed similarly to the R package, despite a different set of\npotential algorithms available natively in R and SAS.\n  Conclusions: Our super learner macro performs as well as the R package at a\nnumber of tasks. Further, by extending the macro to include the use of R\npackages, the macro can leverage both the robust, enterprise oriented\nprocedures in SAS and the nimble, cutting edge packages in R. In the spirit of\nensemble learning, this macro extends the potential library of algorithms\nbeyond a single software system and provides a simple avenue into machine\nlearning in SAS.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:53:08 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 18:02:23 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 13:43:32 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Keil", "Alexander P.", ""], ["Westreich", "Daniel", ""], ["Edwards", "Jessie K", ""], ["Cole", "Stephen R", ""]]}, {"id": "1805.08061", "submitter": "Nicolas Keriven", "authors": "Nicolas Keriven, Damien Garreau, Iacopo Poli", "title": "NEWMA: a new method for scalable model-free online change-point\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting abrupt changes in the distribution of a\nmulti-dimensional time series, with limited computing power and memory. In this\npaper, we propose a new, simple method for model-free online change-point\ndetection that relies only on fast and light recursive statistics, inspired by\nthe classical Exponential Weighted Moving Average algorithm (EWMA). The\nproposed idea is to compute two EWMA statistics on the stream of data with\ndifferent forgetting factors, and to compare them. By doing so, we show that we\nimplicitly compare recent samples with older ones, without the need to\nexplicitly store them. Additionally, we leverage Random Features (RFs) to\nefficiently use the Maximum Mean Discrepancy as a distance between\ndistributions, furthermore exploiting recent optical hardware to compute\nhigh-dimensional RFs in near constant time. We show that our method is\nsignificantly faster than usual non-parametric methods for a given accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:03:46 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 08:02:51 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 09:52:52 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 14:25:54 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Keriven", "Nicolas", ""], ["Garreau", "Damien", ""], ["Poli", "Iacopo", ""]]}, {"id": "1805.08079", "submitter": "Menachem Adelman", "authors": "Menachem Adelman, Kfir Y. Levy, Ido Hakimi, Mark Silberstein", "title": "Faster Neural Network Training with Approximate Tensor Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel technique for faster DNN training which systematically\napplies sample-based approximation to the constituent tensor operations, i.e.,\nmatrix multiplications and convolutions. We introduce new sampling techniques,\nstudy their theoretical properties, and prove that they provide the same\nconvergence guarantees when applied to SGD DNN training. We apply approximate\ntensor operations to single and multi-node training of MLP and CNN networks on\nMNIST, CIFAR-10 and ImageNet datasets. We demonstrate up to 66% reduction in\nthe amount of computations and communication, and up to 1.37x faster training\ntime while maintaining negligible or no impact on the final test accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:14:14 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 14:37:43 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Adelman", "Menachem", ""], ["Levy", "Kfir Y.", ""], ["Hakimi", "Ido", ""], ["Silberstein", "Mark", ""]]}, {"id": "1805.08090", "submitter": "Saurabh Verma", "authors": "Saurabh Verma, Zhi-Li Zhang", "title": "Graph Capsule Convolutional Neural Networks", "comments": "Accepted at Joint ICML and IJCAI Workshop on Computational Biology,\n  Stockholm, Sweden, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Convolutional Neural Networks (GCNNs) are the most recent exciting\nadvancement in deep learning field and their applications are quickly spreading\nin multi-cross-domains including bioinformatics, chemoinformatics, social\nnetworks, natural language processing and computer vision. In this paper, we\nexpose and tackle some of the basic weaknesses of a GCNN model with a capsule\nidea presented in \\cite{hinton2011transforming} and propose our Graph Capsule\nNetwork (GCAPS-CNN) model. In addition, we design our GCAPS-CNN model to solve\nespecially graph classification problem which current GCNN models find\nchallenging. Through extensive experiments, we show that our proposed Graph\nCapsule Network can significantly outperforms both the existing state-of-art\ndeep learning methods and graph kernels on graph classification benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:38:31 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 20:51:00 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 14:25:12 GMT"}, {"version": "v4", "created": "Sun, 26 Aug 2018 00:13:38 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "1805.08094", "submitter": "Jun Liu", "authors": "Faqiang Wang, Haiyang Huang, Jun Liu", "title": "Variational based Mixed Noise Removal with CNN Deep Learning\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the traditional model based variational method and learning\nbased algorithms are naturally integrated to address mixed noise removal\nproblem. To be different from single type noise (e.g. Gaussian) removal, it is\na challenge problem to accurately discriminate noise types and levels for each\npixel. We propose a variational method to iteratively estimate the noise\nparameters, and then the algorithm can automatically classify the noise\naccording to the different statistical parameters. The proposed variational\nproblem can be separated into regularization, synthesis, parameter estimation\nand noise classification four steps with the operator splitting scheme. Each\nstep is related to an optimization subproblem. To enforce the regularization,\nthe deep learning method is employed to learn the natural images priori.\nCompared with some model based regularizations, the CNN regularizer can\nsignificantly improve the quality of the restored images. Compared with some\nlearning based methods, the synthesis step can produce better reconstructions\nby analyzing the recognized noise types and levels. In our method, the\nconvolution neutral network (CNN) can be regarded as an operator which\nassociated to a variational functional. From this viewpoint, the proposed\nmethod can be extended to many image reconstruction and inverse problems.\nNumerical experiments in the paper show that our method can achieve some\nstate-of-the-art results for mixed noise removal.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:52:06 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Wang", "Faqiang", ""], ["Huang", "Haiyang", ""], ["Liu", "Jun", ""]]}, {"id": "1805.08095", "submitter": "Jo\\~ao F. Henriques", "authors": "Jo\\~ao F. Henriques, Sebastien Ehrhardt, Samuel Albanie, Andrea\n  Vedaldi", "title": "Small steps and giant leaps: Minimal Newton solvers for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast second-order method that can be used as a drop-in\nreplacement for current deep learning solvers. Compared to stochastic gradient\ndescent (SGD), it only requires two additional forward-mode automatic\ndifferentiation operations per iteration, which has a computational cost\ncomparable to two standard forward passes and is easy to implement. Our method\naddresses long-standing issues with current second-order solvers, which invert\nan approximate Hessian matrix every iteration exactly or by conjugate-gradient\nmethods, a procedure that is both costly and sensitive to noise. Instead, we\npropose to keep a single estimate of the gradient projected by the inverse\nHessian matrix, and update it once per iteration. This estimate has the same\nsize and is similar to the momentum variable that is commonly used in SGD. No\nestimate of the Hessian is maintained. We first validate our method, called\nCurveBall, on small problems with known closed-form solutions (noisy Rosenbrock\nfunction and degenerate 2-layer linear networks), where current deep learning\nsolvers seem to struggle. We then train several large models on CIFAR and\nImageNet, including ResNet and VGG-f networks, where we demonstrate faster\nconvergence with no hyperparameter tuning. Code is available.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:54:28 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Henriques", "Jo\u00e3o F.", ""], ["Ehrhardt", "Sebastien", ""], ["Albanie", "Samuel", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1805.08096", "submitter": "Deyu Meng", "authors": "Shiqi Liu, Zilu Ma, Deyu Meng", "title": "Understanding Self-Paced Learning under Concave Conjugacy Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By simulating the easy-to-hard learning manners of humans/animals, the\nlearning regimes called curriculum learning~(CL) and self-paced learning~(SPL)\nhave been recently investigated and invoked broad interests. However, the\nintrinsic mechanism for analyzing why such learning regimes can work has not\nbeen comprehensively investigated. To this issue, this paper proposes a concave\nconjugacy theory for looking into the insight of CL/SPL. Specifically, by using\nthis theory, we prove the equivalence of the SPL regime and a latent concave\nobjective, which is closely related to the known non-convex regularized penalty\nwidely used in statistics and machine learning. Beyond the previous theory for\nexplaining CL/SPL insights, this new theoretical framework on one hand\nfacilitates two direct approaches for designing new SPL models for certain\ntasks, and on the other hand can help conduct the latent objective of\nself-paced curriculum learning, which is the advanced version of both CL/SPL\nand possess advantages of both learning regimes to a certain extent. This\nfurther facilitates a theoretical understanding for SPCL, instead of only\nCL/SPL as conventional. Under this theory, we attempt to attain intrinsic\nlatent objectives of two curriculum forms, the partial order and group\ncurriculums, which easily follow the theoretical understanding of the\ncorresponding SPCL regimes.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:55:25 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Liu", "Shiqi", ""], ["Ma", "Zilu", ""], ["Meng", "Deyu", ""]]}, {"id": "1805.08097", "submitter": "Ye Wang", "authors": "Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Invariant Representations from Adversarially Censored Autoencoders", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine conditional variational autoencoders (VAE) with adversarial\ncensoring in order to learn invariant representations that are disentangled\nfrom nuisance/sensitive variations. In this method, an adversarial network\nattempts to recover the nuisance variable from the representation, which the\nVAE is trained to prevent. Conditioning the decoder on the nuisance variable\nenables clean separation of the representation, since they are recombined for\nmodel learning and data reconstruction. We show this natural approach is\ntheoretically well-founded with information-theoretic arguments. Experiments\ndemonstrate that this method achieves invariance while preserving model\nlearning performance, and results in visually improved performance for style\ntransfer and generative sampling tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:56:02 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1805.08102", "submitter": "Jieren Xu", "authors": "Jieren Xu, Yitong Li, David Dunson, Ingrid Daubechies, Haizhao Yang", "title": "Non-Oscillatory Pattern Learning for Non-Stationary Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel non-oscillatory pattern (NOP) learning scheme for\nseveral oscillatory data analysis problems including signal decomposition,\nsuper-resolution, and signal sub-sampling. To the best of our knowledge, the\nproposed NOP is the first algorithm for these problems with fully\nnon-stationary oscillatory data with close and crossover frequencies, and\ngeneral oscillatory patterns. NOP is capable of handling complicated situations\nwhile existing algorithms fail; even in simple cases, e.g., stationary cases\nwith trigonometric patterns, numerical examples show that NOP admits\ncompetitive or better performance in terms of accuracy and robustness than\nseveral state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 15:00:40 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 23:16:50 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Xu", "Jieren", ""], ["Li", "Yitong", ""], ["Dunson", "David", ""], ["Daubechies", "Ingrid", ""], ["Yang", "Haizhao", ""]]}, {"id": "1805.08114", "submitter": "Xiaoyu Li", "authors": "Xiaoyu Li, Francesco Orabona", "title": "On the Convergence of Stochastic Gradient Descent with Adaptive\n  Stepsizes", "comments": "More discussion on related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent is the method of choice for large scale\noptimization of machine learning objective functions. Yet, its performance is\ngreatly variable and heavily depends on the choice of the stepsizes. This has\nmotivated a large body of research on adaptive stepsizes. However, there is\ncurrently a gap in our theoretical understanding of these methods, especially\nin the non-convex setting. In this paper, we start closing this gap: we\ntheoretically analyze in the convex and non-convex settings a generalized\nversion of the AdaGrad stepsizes. We show sufficient conditions for these\nstepsizes to achieve almost sure asymptotic convergence of the gradients to\nzero, proving the first guarantee for generalized AdaGrad stepsizes in the\nnon-convex setting. Moreover, we show that these stepsizes allow to\nautomatically adapt to the level of noise of the stochastic gradients in both\nthe convex and non-convex settings, interpolating between $O(1/T)$ and\n$O(1/\\sqrt{T})$, up to logarithmic terms.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 15:21:58 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 23:29:59 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 22:57:12 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Li", "Xiaoyu", ""], ["Orabona", "Francesco", ""]]}, {"id": "1805.08122", "submitter": "Yingdong Lu", "authors": "Yingdong Lu and Mark S. Squillante and Chai Wah Wu", "title": "A General Family of Robust Stochastic Operators for Reinforcement\n  Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a new family of operators for reinforcement learning with the\ngoal of alleviating the negative effects and becoming more robust to\napproximation or estimation errors. Various theoretical results are\nestablished, which include showing on a sample path basis that our family of\noperators preserve optimality and increase the action gap. Our empirical\nresults illustrate the strong benefits of our family of operators,\nsignificantly outperforming the classical Bellman operator and recently\nproposed operators.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 15:30:54 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 17:15:42 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Lu", "Yingdong", ""], ["Squillante", "Mark S.", ""], ["Wu", "Chai Wah", ""]]}, {"id": "1805.08134", "submitter": "Annie Liang", "authors": "Annie Liang and Xiaosheng Mu", "title": "Overabundant Information and Learning Traps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model of social learning from overabundant information:\nShort-lived agents sequentially choose from a large set of (flexibly\ncorrelated) information sources for prediction of an unknown state. Signal\nrealizations are public. We demonstrate two starkly different long-run\noutcomes: (1) efficient information aggregation, where the community eventually\nlearns as fast as possible; (2) \"learning traps,\" where the community gets\nstuck observing suboptimal sources and learns inefficiently. Our main results\nidentify a simple property of the signal correlation structure that separates\nthese outcomes. In both regimes, we characterize which sources are observed in\nthe long run and how often.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 15:43:17 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 01:19:57 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Liang", "Annie", ""], ["Mu", "Xiaosheng", ""]]}, {"id": "1805.08136", "submitter": "Luca Bertinetto", "authors": "Luca Bertinetto, Jo\\~ao F. Henriques, Philip H.S. Torr, Andrea Vedaldi", "title": "Meta-learning with differentiable closed-form solvers", "comments": "Published at ICLR'19. Code and data available at\n  http://www.robots.ox.ac.uk/~luca/r2d2.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapting deep networks to new concepts from a few examples is challenging,\ndue to the high computational requirements of standard fine-tuning procedures.\nMost work on few-shot learning has thus focused on simple learning techniques\nfor adaptation, such as nearest neighbours or gradient descent. Nonetheless,\nthe machine learning literature contains a wealth of methods that learn\nnon-deep models very efficiently. In this paper, we propose to use these fast\nconvergent methods as the main adaptation mechanism for few-shot learning. The\nmain idea is to teach a deep network to use standard machine learning tools,\nsuch as ridge regression, as part of its own internal model, enabling it to\nquickly adapt to novel data. This requires back-propagating errors through the\nsolver steps. While normally the cost of the matrix operations involved in such\na process would be significant, by using the Woodbury identity we can make the\nsmall number of examples work to our advantage. We propose both closed-form and\niterative solvers, based on ridge regression and logistic regression\ncomponents. Our methods constitute a simple and novel approach to the problem\nof few-shot learning and achieve performance competitive with or superior to\nthe state of the art on three benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 15:44:51 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 18:21:35 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 14:43:31 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Bertinetto", "Luca", ""], ["Henriques", "Jo\u00e3o F.", ""], ["Torr", "Philip H. S.", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1805.08140", "submitter": "Steve Hanneke", "authors": "Steve Hanneke, Aryeh Kontorovich", "title": "A New Lower Bound for Agnostic Learning with Sample Compression Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a tight characterization of the worst-case rates for the excess\nrisk of agnostic learning with sample compression schemes and for uniform\nconvergence for agnostic sample compression schemes. In particular, we find\nthat the optimal rates of convergence for size-$k$ agnostic sample compression\nschemes are of the form $\\sqrt{\\frac{k \\log(n/k)}{n}}$, which contrasts with\nagnostic learning with classes of VC dimension $k$, where the optimal rates are\nof the form $\\sqrt{\\frac{k}{n}}$.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 15:47:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "1805.08166", "submitter": "Tianqi Chen", "authors": "Tianqi Chen, Lianmin Zheng, Eddie Yan, Ziheng Jiang, Thierry Moreau,\n  Luis Ceze, Carlos Guestrin, Arvind Krishnamurthy", "title": "Learning to Optimize Tensor Programs", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a learning-based framework to optimize tensor programs for deep\nlearning workloads. Efficient implementations of tensor operators, such as\nmatrix multiplication and high dimensional convolution, are key enablers of\neffective deep learning systems. However, existing systems rely on manually\noptimized libraries such as cuDNN where only a narrow range of server class\nGPUs are well-supported. The reliance on hardware-specific operator libraries\nlimits the applicability of high-level graph optimizations and incurs\nsignificant engineering costs when deploying to new hardware targets. We use\nlearning to remove this engineering burden. We learn domain-specific\nstatistical cost models to guide the search of tensor operator implementations\nover billions of possible program variants. We further accelerate the search by\neffective model transfer across workloads. Experimental results show that our\nframework delivers performance competitive with state-of-the-art hand-tuned\nlibraries for low-power CPU, mobile GPU, and server-class GPU.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 16:38:12 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 02:48:41 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 18:31:27 GMT"}, {"version": "v4", "created": "Tue, 8 Jan 2019 23:35:15 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Chen", "Tianqi", ""], ["Zheng", "Lianmin", ""], ["Yan", "Eddie", ""], ["Jiang", "Ziheng", ""], ["Moreau", "Thierry", ""], ["Ceze", "Luis", ""], ["Guestrin", "Carlos", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1805.08169", "submitter": "Haochao Huang", "authors": "Haochao Huang", "title": "Cancer Research UK Drug Discovery Process Mining", "comments": "113 pages, 84 figures/tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. The Drug Discovery Unit (DDU) of Cancer Research UK (CRUK) is\nusing the software Dotmatics for storage and analysis of scientific data during\ndrug discovery process. Whilst the data include event logs, time stamps,\nactivities, and user information are mostly sitting in the database without\nfully utilising their potential value. Aims. This dissertation aims at\nextracting knowledge from event logs data which recorded during drug discovery\nprocess, to capture the operational business process of the DDU of Cancer\nResearch UK (CRUK) as it was being executed. It provides the evaluations and\nmethodologies of drawing the process mining panoramic models for the drug\ndiscovery process. Thus by enabling the DDU to maximise its efficiency in\nreviewing its resources and works allocations, patients will benefit from more\nnew treatments faster. Conclusion. Management of organisations can be benefit\nfrom the process mining methodologies. Disco is excellent for non-experts on\nmanagement purposes. ProM is great for expert on research purposes. However,\nthe process mining is not once and for all but is a regular operation\nmanagement process. Indeed, event logs needs to be understand more on the\ntarget organisational behaviours and organisational business process. The\nresearchers have to be aware that event logs data are the most important and\npriority elements in process mining.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:53:17 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Huang", "Haochao", ""]]}, {"id": "1805.08180", "submitter": "Andrew Levy", "authors": "Andrew Levy, Robert Platt, Kate Saenko", "title": "Hierarchical Reinforcement Learning with Hindsight", "comments": "Duplicate. See arXiv:1712.00948 \"Learning Multi-Level Hierarchies\n  with Hindsight\" for latest version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms can suffer from poor sample efficiency\nwhen rewards are delayed and sparse. We introduce a solution that enables\nagents to learn temporally extended actions at multiple levels of abstraction\nin a sample efficient and automated fashion. Our approach combines universal\nvalue functions and hindsight learning, allowing agents to learn policies\nbelonging to different time scales in parallel. We show that our method\nsignificantly accelerates learning in a variety of discrete and continuous\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:02:53 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 17:52:47 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Levy", "Andrew", ""], ["Platt", "Robert", ""], ["Saenko", "Kate", ""]]}, {"id": "1805.08182", "submitter": "Anastassia Kornilova", "authors": "Anastassia Kornilova, Daniel Argyle and Vlad Eidelman", "title": "Party Matters: Enhancing Legislative Embeddings with Author Attributes\n  for Vote Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting how Congressional legislators will vote is important for\nunderstanding their past and future behavior. However, previous work on\nroll-call prediction has been limited to single session settings, thus did not\nconsider generalization across sessions. In this paper, we show that metadata\nis crucial for modeling voting outcomes in new contexts, as changes between\nsessions lead to changes in the underlying data generation process. We show how\naugmenting bill text with the sponsors' ideologies in a neural network model\ncan achieve an average of a 4% boost in accuracy over the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:03:13 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kornilova", "Anastassia", ""], ["Argyle", "Daniel", ""], ["Eidelman", "Vlad", ""]]}, {"id": "1805.08191", "submitter": "Zhe Gan", "authors": "Qiuyuan Huang, Zhe Gan, Asli Celikyilmaz, Dapeng Wu, Jianfeng Wang,\n  Xiaodong He", "title": "Hierarchically Structured Reinforcement Learning for Topically Coherent\n  Visual Story Generation", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchically structured reinforcement learning approach to\naddress the challenges of planning for generating coherent multi-sentence\nstories for the visual storytelling task. Within our framework, the task of\ngenerating a story given a sequence of images is divided across a two-level\nhierarchical decoder. The high-level decoder constructs a plan by generating a\nsemantic concept (i.e., topic) for each image in sequence. The low-level\ndecoder generates a sentence for each image using a semantic compositional\nnetwork, which effectively grounds the sentence generation conditioned on the\ntopic. The two decoders are jointly trained end-to-end using reinforcement\nlearning. We evaluate our model on the visual storytelling (VIST) dataset.\nEmpirical results from both automatic and human evaluations demonstrate that\nthe proposed hierarchically structured reinforced training achieves\nsignificantly better performance compared to a strong flat deep reinforcement\nlearning baseline.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:23:31 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 20:11:56 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 07:58:43 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Gan", "Zhe", ""], ["Celikyilmaz", "Asli", ""], ["Wu", "Dapeng", ""], ["Wang", "Jianfeng", ""], ["He", "Xiaodong", ""]]}, {"id": "1805.08193", "submitter": "Bo Han", "authors": "Bo Han and Jiangchao Yao and Gang Niu and Mingyuan Zhou and Ivor Tsang\n  and Ya Zhang and Masashi Sugiyama", "title": "Masking: A New Perspective of Noisy Supervision", "comments": "NIPS 2018 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to learn various types of classifiers given training data\nwith noisy labels. Noisy labels, in the most popular noise model hitherto, are\ncorrupted from ground-truth labels by an unknown noise transition matrix. Thus,\nby estimating this matrix, classifiers can escape from overfitting those noisy\nlabels. However, such estimation is practically difficult, due to either the\nindirect nature of two-step approaches, or not big enough data to afford\nend-to-end approaches. In this paper, we propose a human-assisted approach\ncalled Masking that conveys human cognition of invalid class transitions and\nnaturally speculates the structure of the noise transition matrix. To this end,\nwe derive a structure-aware probabilistic model incorporating a structure\nprior, and solve the challenges from structure extraction and structure\nalignment. Thanks to Masking, we only estimate unmasked noise transition\nprobabilities and the burden of estimation is tremendously reduced. We conduct\nextensive experiments on CIFAR-10 and CIFAR-100 with three noise structures as\nwell as the industrial-level Clothing1M with agnostic noise structure, and the\nresults show that Masking can improve the robustness of classifiers\nsignificantly.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:24:42 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 05:37:09 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Han", "Bo", ""], ["Yao", "Jiangchao", ""], ["Niu", "Gang", ""], ["Zhou", "Mingyuan", ""], ["Tsang", "Ivor", ""], ["Zhang", "Ya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1805.08196", "submitter": "Asish Ghoshal", "authors": "Asish Ghoshal and Jean Honorio", "title": "Learning Maximum-A-Posteriori Perturbation Models for Structured\n  Prediction in Polynomial Time", "comments": "Accepted to ICML 2018", "journal-ref": "International Conference on Machine Learning (ICML), 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAP perturbation models have emerged as a powerful framework for inference in\nstructured prediction. Such models provide a way to efficiently sample from the\nGibbs distribution and facilitate predictions that are robust to random noise.\nIn this paper, we propose a provably polynomial time randomized algorithm for\nlearning the parameters of perturbed MAP predictors. Our approach is based on\nminimizing a novel Rademacher-based generalization bound on the expected loss\nof a perturbed MAP predictor, which can be computed in polynomial time. We\nobtain conditions under which our randomized learning algorithm can guarantee\ngeneralization to unseen examples.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:43:37 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ghoshal", "Asish", ""], ["Honorio", "Jean", ""]]}, {"id": "1805.08206", "submitter": "Yonatan Geifman", "authors": "Yonatan Geifman, Guy Uziel, Ran El-Yaniv", "title": "Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of uncertainty estimation in the context of\n(non-Bayesian) deep neural classification. In this context, all known methods\nare based on extracting uncertainty signals from a trained network optimized to\nsolve the classification problem at hand. We demonstrate that such techniques\ntend to introduce biased estimates for instances whose predictions are supposed\nto be highly confident. We argue that this deficiency is an artifact of the\ndynamics of training with SGD-like optimizers, and it has some properties\nsimilar to overfitting. Based on this observation, we develop an uncertainty\nestimation algorithm that selectively estimates the uncertainty of highly\nconfident points, using earlier snapshots of the trained model, before their\nestimates are jittered (and way before they are ready for actual\nclassification). We present extensive experiments indicating that the proposed\nalgorithm provides uncertainty estimates that are consistently better than all\nknown methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:59:59 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 05:10:28 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 11:19:55 GMT"}, {"version": "v4", "created": "Wed, 24 Apr 2019 13:00:42 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Geifman", "Yonatan", ""], ["Uziel", "Guy", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1805.08239", "submitter": "Joshua Glaser", "authors": "Joshua I. Glaser, Ari S. Benjamin, Roozbeh Farhoodi, Konrad P. Kording", "title": "The Roles of Supervised Machine Learning in Systems Neuroscience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the last several years, the use of machine learning (ML) in neuroscience\nhas been rapidly increasing. Here, we review ML's contributions, both realized\nand potential, across several areas of systems neuroscience. We describe four\nprimary roles of ML within neuroscience: 1) creating solutions to engineering\nproblems, 2) identifying predictive variables, 3) setting benchmarks for simple\nmodels of the brain, and 4) serving itself as a model for the brain. The\nbreadth and ease of its applicability suggests that machine learning should be\nin the toolbox of most systems neuroscientists.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:11:26 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 15:36:21 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Glaser", "Joshua I.", ""], ["Benjamin", "Ari S.", ""], ["Farhoodi", "Roozbeh", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1805.08244", "submitter": "Jing An", "authors": "Jing An, Jianfeng Lu, Lexing Ying", "title": "Stochastic modified equations for the asynchronous stochastic gradient\n  descent", "comments": "Final version. To appear in Information and Inference", "journal-ref": null, "doi": "10.1093/imaiai/iaz030", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic modified equations (SME) for modeling the\nasynchronous stochastic gradient descent (ASGD) algorithms. The resulting SME\nof Langevin type extracts more information about the ASGD dynamics and\nelucidates the relationship between different types of stochastic gradient\nalgorithms. We show the convergence of ASGD to the SME in the continuous time\nlimit, as well as the SME's precise prediction to the trajectories of ASGD with\nvarious forcing terms. As an application of the SME, we propose an optimal\nmini-batching strategy for ASGD via solving the optimal control problem of the\nassociated SME.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:24:20 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 16:28:31 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 20:08:55 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["An", "Jing", ""], ["Lu", "Jianfeng", ""], ["Ying", "Lexing", ""]]}, {"id": "1805.08249", "submitter": "Konrad Zolna", "authors": "Konrad Zolna and Krzysztof J. Geras and Kyunghyun Cho", "title": "Classifier-agnostic saliency map extraction", "comments": null, "journal-ref": "Computer Vision and Image Understanding, Volume 196, 2020, 102969,\n  ISSN 1077-3142", "doi": "10.1016/j.cviu.2020.102969", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently available methods for extracting saliency maps identify parts of\nthe input which are the most important to a specific fixed classifier. We show\nthat this strong dependence on a given classifier hinders their performance. To\naddress this problem, we propose classifier-agnostic saliency map extraction,\nwhich finds all parts of the image that any classifier could use, not just one\ngiven in advance. We observe that the proposed approach extracts higher quality\nsaliency maps than prior work while being conceptually simple and easy to\nimplement. The method sets the new state of the art result for localization\ntask on the ImageNet data, outperforming all existing weakly-supervised\nlocalization techniques, despite not using the ground truth labels at the\ninference time. The code reproducing the results is available at\nhttps://github.com/kondiz/casme .\n  The final version of this manuscript is published in Computer Vision and\nImage Understanding and is available online at\nhttps://doi.org/10.1016/j.cviu.2020.102969 .\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:36:52 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 19:14:19 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 16:56:49 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zolna", "Konrad", ""], ["Geras", "Krzysztof J.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1805.08254", "submitter": "Steve Hanneke", "authors": "Steve Hanneke, Aryeh Kontorovich, Menachem Sadigurschi", "title": "Sample Compression for Real-Valued Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithmically efficient version of the learner-to-compression\nscheme conversion in Moran and Yehudayoff (2016). In extending this technique\nto real-valued hypotheses, we also obtain an efficient regression-to-bounded\nsample compression converter. To our knowledge, this is the first general\ncompressed regression result (regardless of efficiency or boundedness)\nguaranteeing uniform approximate reconstruction. Along the way, we develop a\ngeneric procedure for constructing weak real-valued learners out of abstract\nregressors; this may be of independent interest. In particular, this result\nsheds new light on an open question of H. Simon (1997). We show applications to\ntwo regression problems: learning Lipschitz and bounded-variation functions.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:42:24 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""], ["Sadigurschi", "Menachem", ""]]}, {"id": "1805.08266", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Arnaud Doucet, Judith Rousseau", "title": "On the Selection of Initialization and Activation Function for Deep\n  Neural Networks", "comments": "8 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weight initialization and the activation function of deep neural networks\nhave a crucial impact on the performance of the training procedure. An\ninappropriate selection can lead to the loss of information of the input during\nforward propagation and the exponential vanishing/exploding of gradients during\nback-propagation. Understanding the theoretical properties of untrained random\nnetworks is key to identifying which deep networks may be trained successfully\nas recently demonstrated by Schoenholz et al. (2017) who showed that for deep\nfeedforward neural networks only a specific choice of hyperparameters known as\nthe `edge of chaos' can lead to good performance. We complete this analysis by\nproviding quantitative results showing that, for a class of ReLU-like\nactivation functions, the information propagates indeed deeper for an\ninitialization at the edge of chaos. By further extending this analysis, we\nidentify a class of activation functions that improve the information\npropagation over ReLU-like functions. This class includes the Swish activation,\n$\\phi_{swish}(x) = x \\cdot \\text{sigmoid}(x)$, used in Hendrycks & Gimpel\n(2016), Elfwing et al. (2017) and Ramachandran et al. (2017). This provides a\ntheoretical grounding for the excellent empirical performance of $\\phi_{swish}$\nobserved in these contributions. We complement those previous results by\nillustrating the benefit of using a random initialization on the edge of chaos\nin this context.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 19:23:39 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 18:20:25 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Hayou", "Soufiane", ""], ["Doucet", "Arnaud", ""], ["Rousseau", "Judith", ""]]}, {"id": "1805.08268", "submitter": "Alon Gonen", "authors": "Naman Agarwal and Alon Gonen", "title": "Optimal Sketching Bounds for Exp-concave Stochastic Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive optimal statistical and computational complexity bounds for\nexp-concave stochastic minimization in terms of the effective dimension. For\ncommon eigendecay patterns of the population covariance matrix, this quantity\nis significantly smaller than the ambient dimension. Our results reveal\ninteresting connections to sketching results in numerical linear algebra. In\nparticular, our statistical analysis highlights a novel and natural\nrelationship between algorithmic stability of empirical risk minimization and\nridge leverage scores, which play significant role in sketching-based methods.\nOur main computational result is a fast implementation of a\nsketch-to-precondition approach in the context of exp-concave empirical risk\nminimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 19:40:01 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 00:41:20 GMT"}, {"version": "v3", "created": "Fri, 22 Jun 2018 17:25:14 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 02:41:37 GMT"}, {"version": "v5", "created": "Tue, 29 Jan 2019 20:39:06 GMT"}, {"version": "v6", "created": "Fri, 7 Jun 2019 11:31:15 GMT"}, {"version": "v7", "created": "Fri, 20 Sep 2019 21:03:51 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Agarwal", "Naman", ""], ["Gonen", "Alon", ""]]}, {"id": "1805.08273", "submitter": "Adler Perotte", "authors": "Rajesh Ranganath, Adler Perotte", "title": "Multiple Causal Inference with Latent Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observational data requires assumptions. These\nassumptions range from measuring confounders to identifying instruments.\nTraditionally, causal inference assumptions have focused on estimation of\neffects for a single treatment. In this work, we construct techniques for\nestimation with multiple treatments in the presence of unobserved confounding.\nWe develop two assumptions based on shared confounding between treatments and\nindependence of treatments given the confounder. Together, these assumptions\nlead to a confounder estimator regularized by mutual information. For this\nestimator, we develop a tractable lower bound. To recover treatment effects, we\nuse the residual information in the treatments independent of the confounder.\nWe validate on simulations and an example from clinical medicine.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 20:01:52 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 14:29:39 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 18:49:17 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Ranganath", "Rajesh", ""], ["Perotte", "Adler", ""]]}, {"id": "1805.08289", "submitter": "Ari Benjamin", "authors": "Ari S. Benjamin, David Rolnick, Konrad Kording", "title": "Measuring and regularizing networks in function space", "comments": "Presented at ICLR 2019", "journal-ref": "International Conference on Learning Representations, 2019,\n  https://openreview.net/pdf?id=SkMwpiR9Y7", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To optimize a neural network one often thinks of optimizing its parameters,\nbut it is ultimately a matter of optimizing the function that maps inputs to\noutputs. Since a change in the parameters might serve as a poor proxy for the\nchange in the function, it is of some concern that primacy is given to\nparameters but that the correspondence has not been tested. Here, we show that\nit is simple and computationally feasible to calculate distances between\nfunctions in a $L^2$ Hilbert space. We examine how typical networks behave in\nthis space, and compare how parameter $\\ell^2$ distances compare to function\n$L^2$ distances between various points of an optimization trajectory. We find\nthat the two distances are nontrivially related. In particular, the\n$L^2/\\ell^2$ ratio decreases throughout optimization, reaching a steady value\naround when test error plateaus. We then investigate how the $L^2$ distance\ncould be applied directly to optimization. We first propose that in multitask\nlearning, one can avoid catastrophic forgetting by directly limiting how much\nthe input/output function changes between tasks. Secondly, we propose a new\nlearning rule that constrains the distance a network can travel through\n$L^2$-space in any one update. This allows new examples to be learned in a way\nthat minimally interferes with what has previously been learned. These\napplications demonstrate how one can measure and regularize function distances\ndirectly, without relying on parameters or local approximations like loss\ncurvature.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 21:03:21 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 22:17:51 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 19:04:34 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Benjamin", "Ari S.", ""], ["Rolnick", "David", ""], ["Kording", "Konrad", ""]]}, {"id": "1805.08296", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine", "title": "Data-Efficient Hierarchical Reinforcement Learning", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning (HRL) is a promising approach to extend\ntraditional reinforcement learning (RL) methods to solve more complex tasks.\nYet, the majority of current HRL methods require careful task-specific design\nand on-policy training, making them difficult to apply in real-world scenarios.\nIn this paper, we study how we can develop HRL algorithms that are general, in\nthat they do not make onerous additional assumptions beyond standard RL\nalgorithms, and efficient, in the sense that they can be used with modest\nnumbers of interaction samples, making them suitable for real-world problems\nsuch as robotic control. For generality, we develop a scheme where lower-level\ncontrollers are supervised with goals that are learned and proposed\nautomatically by the higher-level controllers. To address efficiency, we\npropose to use off-policy experience for both higher and lower-level training.\nThis poses a considerable challenge, since changes to the lower-level behaviors\nchange the action space for the higher-level policy, and we introduce an\noff-policy correction to remedy this challenge. This allows us to take\nadvantage of recent advances in off-policy model-free RL to learn both higher-\nand lower-level policies using substantially fewer environment interactions\nthan on-policy algorithms. We term the resulting HRL agent HIRO and find that\nit is generally applicable and highly sample-efficient. Our experiments show\nthat HIRO can be used to learn highly complex behaviors for simulated robots,\nsuch as pushing objects and utilizing them to reach target locations, learning\nfrom only a few million samples, equivalent to a few days of real-time\ninteraction. In comparisons with a number of prior HRL methods, we find that\nour approach substantially outperforms previous state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 21:33:44 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 07:53:39 GMT"}, {"version": "v3", "created": "Sat, 29 Sep 2018 02:36:13 GMT"}, {"version": "v4", "created": "Fri, 5 Oct 2018 12:39:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Nachum", "Ofir", ""], ["Gu", "Shixiang", ""], ["Lee", "Honglak", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.08303", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Compression of Deep Convolutional Neural Networks under Joint Sparsity\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization of deep convolutional neural networks (CNNs)\nsuch that they provide good performance while having reduced complexity if\ndeployed on either conventional systems utilizing spatial-domain convolution or\nlower complexity systems designed for Winograd convolution. Furthermore, we\nexplore the universal quantization and compression of these networks. In\nparticular, the proposed framework produces one compressed model whose\nconvolutional filters can be made sparse either in the spatial domain or in the\nWinograd domain. Hence, one compressed model can be deployed universally on any\nplatform, without need for re-training on the deployed platform, and the\nsparsity of its convolutional filters can be exploited for further complexity\nreduction in either domain. To get a better compression ratio, the sparse model\nis compressed in the spatial domain which has a less number of parameters. From\nour experiments, we obtain $24.2\\times$, $47.7\\times$ and $35.4\\times$\ncompressed models for ResNet-18, AlexNet and CT-SRCNN, while their\ncomputational cost is also reduced by $4.5\\times$, $5.1\\times$ and\n$23.5\\times$, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:00:21 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 02:18:12 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1805.08306", "submitter": "Saeed Saremi", "authors": "Saeed Saremi, Arash Mehrjou, Bernhard Sch\\\"olkopf, Aapo Hyv\\\"arinen", "title": "Deep Energy Estimator Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is a fundamental problem in statistical learning. This\nproblem is especially challenging for complex high-dimensional data due to the\ncurse of dimensionality. A promising solution to this problem is given here in\nan inference-free hierarchical framework that is built on score matching. We\nrevisit the Bayesian interpretation of the score function and the Parzen score\nmatching, and construct a multilayer perceptron with a scalable objective for\nlearning the energy (i.e. the unnormalized log-density), which is then\noptimized with stochastic gradient descent. In addition, the resulting deep\nenergy estimator network (DEEN) is designed as products of experts. We present\nthe utility of DEEN in learning the energy, the score function, and in\nsingle-step denoising experiments for synthetic and high-dimensional data. We\nalso diagnose stability problems in the direct estimation of the score function\nthat had been observed for denoising autoencoders.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:15:28 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Saremi", "Saeed", ""], ["Mehrjou", "Arash", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "1805.08308", "submitter": "Nina Miolane", "authors": "Nina Miolane, Johan Mathe, Claire Donnat, Mikael Jorda, Xavier Pennec", "title": "geomstats: a Python Package for Riemannian Geometry in Machine Learning", "comments": "Preprint NIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce geomstats, a python package that performs computations on\nmanifolds such as hyperspheres, hyperbolic spaces, spaces of symmetric positive\ndefinite matrices and Lie groups of transformations. We provide efficient and\nextensively unit-tested implementations of these manifolds, together with\nuseful Riemannian metrics and associated Exponential and Logarithm maps. The\ncorresponding geodesic distances provide a range of intuitive choices of\nMachine Learning loss functions. We also give the corresponding Riemannian\ngradients. The operations implemented in geomstats are available with different\ncomputing backends such as numpy, tensorflow and keras. We have enabled GPU\nimplementation and integrated geomstats manifold computations into keras deep\nlearning framework. This paper also presents a review of manifolds in machine\nlearning and an overview of the geomstats package with examples demonstrating\nits use for efficient and user-friendly Riemannian geometry.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:24:14 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 01:28:54 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Miolane", "Nina", ""], ["Mathe", "Johan", ""], ["Donnat", "Claire", ""], ["Jorda", "Mikael", ""], ["Pennec", "Xavier", ""]]}, {"id": "1805.08309", "submitter": "Xin He", "authors": "Xin He, Liu Ke, Wenyan Lu, Guihai Yan, Xuan Zhang", "title": "AxTrain: Hardware-Oriented Neural Network Training for Approximate\n  Inference", "comments": "In International Symposium on Low Power Electronics and Design\n  (ISLPED) 2018", "journal-ref": null, "doi": "10.1145/3218603.3218643", "report-no": null, "categories": "cs.LG cs.DC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intrinsic error tolerance of neural network (NN) makes approximate\ncomputing a promising technique to improve the energy efficiency of NN\ninference. Conventional approximate computing focuses on balancing the\nefficiency-accuracy trade-off for existing pre-trained networks, which can lead\nto suboptimal solutions. In this paper, we propose AxTrain, a hardware-oriented\ntraining framework to facilitate approximate computing for NN inference.\nSpecifically, AxTrain leverages the synergy between two orthogonal\nmethods---one actively searches for a network parameters distribution with high\nerror tolerance, and the other passively learns resilient weights by\nnumerically incorporating the noise distributions of the approximate hardware\nin the forward pass during the training phase. Experimental results from\nvarious datasets with near-threshold computing and approximation multiplication\nstrategies demonstrate AxTrain's ability to obtain resilient neural network\nparameters and system energy efficiency improvement.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:27:14 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["He", "Xin", ""], ["Ke", "Liu", ""], ["Lu", "Wenyan", ""], ["Yan", "Guihai", ""], ["Zhang", "Xuan", ""]]}, {"id": "1805.08311", "submitter": "Mohammad Ghasemzadeh", "authors": "Mohammad Ghasemzadeh, Fang Lin, Bita Darvish Rouhani, Farinaz\n  Koushanfar, Ke Huang", "title": "AgileNet: Lightweight Dictionary-based Few-shot Learning", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning models is heavily tied to the use of massive\namount of labeled data and excessively long training time. With the emergence\nof intelligent edge applications that use these models, the critical challenge\nis to obtain the same inference capability on a resource-constrained device\nwhile providing adaptability to cope with the dynamic changes in the data. We\npropose AgileNet, a novel lightweight dictionary-based few-shot learning\nmethodology which provides reduced complexity deep neural network for efficient\nexecution at the edge while enabling low-cost updates to capture the dynamics\nof the new data. Evaluations of state-of-the-art few-shot learning benchmarks\ndemonstrate the superior accuracy of AgileNet compared to prior arts.\nAdditionally, AgileNet is the first few-shot learning approach that prevents\nmodel updates by eliminating the knowledge obtained from the primary training.\nThis property is ensured through the dictionaries learned by our novel\nend-to-end structured decomposition, which also reduces the memory footprint\nand computation complexity to match the edge device constraints.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:36:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ghasemzadeh", "Mohammad", ""], ["Lin", "Fang", ""], ["Rouhani", "Bita Darvish", ""], ["Koushanfar", "Farinaz", ""], ["Huang", "Ke", ""]]}, {"id": "1805.08313", "submitter": "Jessie Huang", "authors": "Jessie Huang, Fa Wu, Doina Precup, Yang Cai", "title": "Learning Safe Policies with Expert Guidance", "comments": "Appears in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for ensuring safe behavior of a reinforcement learning\nagent when the reward function may be difficult to specify. In order to do\nthis, we rely on the existence of demonstrations from expert policies, and we\nprovide a theoretical framework for the agent to optimize in the space of\nrewards consistent with its existing knowledge. We propose two methods to solve\nthe resulting optimization: an exact ellipsoid-based method and a method in the\nspirit of the \"follow-the-perturbed-leader\" algorithm. Our experiments\ndemonstrate the behavior of our algorithm in both discrete and continuous\nproblems. The trained agent safely avoids states with potential negative\neffects while imitating the behavior of the expert in the other states.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:40:07 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 17:17:23 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Huang", "Jessie", ""], ["Wu", "Fa", ""], ["Precup", "Doina", ""], ["Cai", "Yang", ""]]}, {"id": "1805.08318", "submitter": "Augustus Odena", "authors": "Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena", "title": "Self-Attention Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Self-Attention Generative Adversarial Network\n(SAGAN) which allows attention-driven, long-range dependency modeling for image\ngeneration tasks. Traditional convolutional GANs generate high-resolution\ndetails as a function of only spatially local points in lower-resolution\nfeature maps. In SAGAN, details can be generated using cues from all feature\nlocations. Moreover, the discriminator can check that highly detailed features\nin distant portions of the image are consistent with each other. Furthermore,\nrecent work has shown that generator conditioning affects GAN performance.\nLeveraging this insight, we apply spectral normalization to the GAN generator\nand find that this improves training dynamics. The proposed SAGAN achieves the\nstate-of-the-art results, boosting the best published Inception score from 36.8\nto 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the\nchallenging ImageNet dataset. Visualization of the attention layers shows that\nthe generator leverages neighborhoods that correspond to object shapes rather\nthan local regions of fixed shape.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:10:35 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 18:20:10 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhang", "Han", ""], ["Goodfellow", "Ian", ""], ["Metaxas", "Dimitris", ""], ["Odena", "Augustus", ""]]}, {"id": "1805.08321", "submitter": "Tavor Baharav", "authors": "Vivek Bagaria, Tavor Z. Baharav, Govinda M. Kamath, David N. Tse", "title": "Bandit-Based Monte Carlo Optimization for Nearest Neighbors", "comments": "Accepted to the IEEE Journal on Selected Areas in Information Theory\n  (JSAIT) - Special Issue on Sequential, Active, and Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Monte Carlo method estimates an expensive-to-compute quantity\nby random sampling. Bandit-based Monte Carlo optimization is a general\ntechnique for computing the minimum of many such expensive-to-compute\nquantities by adaptive random sampling. The technique converts an optimization\nproblem into a statistical estimation problem which is then solved via\nmulti-armed bandits. We apply this technique to solve the problem of\nhigh-dimensional $k$-nearest neighbors, developing an algorithm which we prove\nis able to identify exact nearest neighbors with high probability. We show that\nunder regularity assumptions on a dataset of $n$ points in $d$-dimensional\nspace, the complexity of our algorithm scales logarithmically with the\ndimension of the data as $O\\left((n+d)\\log^2\n\\left(\\frac{nd}{\\delta}\\right)\\right)$ for error probability $\\delta$, rather\nthan linearly as in exact computation requiring $O(nd)$. We corroborate our\ntheoretical results with numerical simulations, showing that our algorithm\noutperforms both exact computation and state-of-the-art algorithms such as\nkGraph, NGT, and LSH on real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:28:30 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 00:26:39 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 23:10:15 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 21:10:05 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bagaria", "Vivek", ""], ["Baharav", "Tavor Z.", ""], ["Kamath", "Govinda M.", ""], ["Tse", "David N.", ""]]}, {"id": "1805.08322", "submitter": "Yuxin Chen", "authors": "Anette Hunziker, Yuxin Chen, Oisin Mac Aodha, Manuel Gomez Rodriguez,\n  Andreas Krause, Pietro Perona, Yisong Yue, Adish Singla", "title": "Teaching Multiple Concepts to a Forgetful Learner", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we help a forgetful learner learn multiple concepts within a limited\ntime frame? While there have been extensive studies in designing optimal\nschedules for teaching a single concept given a learner's memory model,\nexisting approaches for teaching multiple concepts are typically based on\nheuristic scheduling techniques without theoretical guarantees. In this paper,\nwe look at the problem from the perspective of discrete optimization and\nintroduce a novel algorithmic framework for teaching multiple concepts with\nstrong performance guarantees. Our framework is both generic, allowing the\ndesign of teaching schedules for different memory models, and also interactive,\nallowing the teacher to adapt the schedule to the underlying forgetting\nmechanisms of the learner. Furthermore, for a well-known memory model, we are\nable to identify a regime of model parameters where our framework is guaranteed\nto achieve high performance. We perform extensive evaluations using simulations\nalong with real user studies in two concrete applications: (i) an educational\napp for online vocabulary teaching; and (ii) an app for teaching novices how to\nrecognize animal species from images. Our results demonstrate the effectiveness\nof our algorithm compared to popular heuristic approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:34:11 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 16:20:41 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 16:25:03 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 17:07:54 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Hunziker", "Anette", ""], ["Chen", "Yuxin", ""], ["Mac Aodha", "Oisin", ""], ["Rodriguez", "Manuel Gomez", ""], ["Krause", "Andreas", ""], ["Perona", "Pietro", ""], ["Yue", "Yisong", ""], ["Singla", "Adish", ""]]}, {"id": "1805.08327", "submitter": "Arya Mazumdar", "authors": "Raj Kumar Maity, Ankit Singh Rawat and Arya Mazumdar", "title": "Robust Gradient Descent via Moment Encoding with LDPC Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of implementing large-scale gradient descent\nalgorithms in a distributed computing setting in the presence of {\\em\nstraggling} processors. To mitigate the effect of the stragglers, it has been\npreviously proposed to encode the data with an erasure-correcting code and\ndecode at the master server at the end of the computation. We, instead, propose\nto encode the second-moment of the data with a low density parity-check (LDPC)\ncode. The iterative decoding algorithms for LDPC codes have very low\ncomputational overhead and the number of decoding iterations can be made to\nautomatically adjust with the number of stragglers in the system. We show that\nfor a random model for stragglers, the proposed moment encoding based gradient\ndescent method can be viewed as the stochastic gradient descent method. This\nallows us to obtain convergence guarantees for the proposed solution.\nFurthermore, the proposed moment encoding based method is shown to outperform\nthe existing schemes in a real distributed computing setup.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:02:47 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 02:47:58 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Maity", "Raj Kumar", ""], ["Rawat", "Ankit Singh", ""], ["Mazumdar", "Arya", ""]]}, {"id": "1805.08328", "submitter": "Osbert Bastani", "authors": "Osbert Bastani and Yewen Pu and Armando Solar-Lezama", "title": "Verifiable Reinforcement Learning via Policy Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning has successfully solved many challenging\ncontrol tasks, its real-world applicability has been limited by the inability\nto ensure the safety of learned policies. We propose an approach to verifiable\nreinforcement learning by training decision tree policies, which can represent\ncomplex policies (since they are nonparametric), yet can be efficiently\nverified using existing techniques (since they are highly structured). The\nchallenge is that decision tree policies are difficult to train. We propose\nVIPER, an algorithm that combines ideas from model compression and imitation\nlearning to learn decision tree policies guided by a DNN policy (called the\noracle) and its Q-function, and show that it substantially outperforms two\nbaselines. We use VIPER to (i) learn a provably robust decision tree policy for\na variant of Atari Pong with a symbolic state space, (ii) learn a decision tree\npolicy for a toy game based on Pong that provably never loses, and (iii) learn\na provably stable decision tree policy for cart-pole. In each case, the\ndecision tree policy achieves performance equal to that of the original DNN\npolicy.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:14:32 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 02:53:31 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bastani", "Osbert", ""], ["Pu", "Yewen", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1805.08329", "submitter": "Haonan Yu", "authors": "Haonan Yu, Xiaochen Lian, Haichao Zhang, Wei Xu", "title": "Guided Feature Transformation (GFT): A Neural Language Grounding Module\n  for Embodied Agents", "comments": "CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a rising interest in training agents, embodied in\nvirtual environments, to perform language-directed tasks by deep reinforcement\nlearning. In this paper, we propose a simple but effective neural language\ngrounding module for embodied agents that can be trained end to end from\nscratch taking raw pixels, unstructured linguistic commands, and sparse rewards\nas the inputs. We model the language grounding process as a language-guided\ntransformation of visual features, where latent sentence embeddings are used as\nthe transformation matrices. In several language-directed navigation tasks that\nfeature challenging partial observability and require simple reasoning, our\nmodule significantly outperforms the state of the art. We also release\nXWorld3D, an easy-to-customize 3D environment that can potentially be modified\nto evaluate a variety of embodied agents.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:16:39 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 18:16:40 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Yu", "Haonan", ""], ["Lian", "Xiaochen", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1805.08331", "submitter": "Th\\'eo Lacombe", "authors": "Th\\'eo Lacombe and Marco Cuturi and Steve Oudot", "title": "Large Scale computation of Means and Clusters for Persistence Diagrams\n  using Optimal Transport", "comments": "17 pages, 9 figures (9 pages for the main content). To appear in NIPS\n  2018 proceedings. Version updated following reviewing process: correction of\n  typo, clarification of some details, addition of two illustrations (Fig.1 and\n  7 in this version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams (PDs) are now routinely used to summarize the underlying\ntopology of complex data. Despite several appealing properties, incorporating\nPDs in learning pipelines can be challenging because their natural geometry is\nnot Hilbertian. Indeed, this was recently exemplified in a string of papers\nwhich show that the simple task of averaging a few PDs can be computationally\nprohibitive. We propose in this article a tractable framework to carry out\nstandard tasks on PDs at scale, notably evaluating distances, estimating\nbarycenters and performing clustering. This framework builds upon a\nreformulation of PD metrics as optimal transport (OT) problems. Doing so, we\ncan exploit recent computational advances: the OT problem on a planar grid,\nwhen regularized with entropy, is convex can be solved in linear time using the\nSinkhorn algorithm and convolutions. This results in scalable computations that\ncan stream on GPUs. We demonstrate the efficiency of our approach by carrying\nout clustering with diagrams metrics on several thousands of PDs, a scale never\nseen before in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:23:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:08:33 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Lacombe", "Th\u00e9o", ""], ["Cuturi", "Marco", ""], ["Oudot", "Steve", ""]]}, {"id": "1805.08336", "submitter": "Kyungjae Lee", "authors": "Kyungjae Lee and Sungjoon Choi and Songhwai Oh", "title": "Maximum Causal Tsallis Entropy Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel maximum causal Tsallis entropy (MCTE)\nframework for imitation learning which can efficiently learn a sparse\nmulti-modal policy distribution from demonstrations. We provide the full\nmathematical analysis of the proposed framework. First, the optimal solution of\nan MCTE problem is shown to be a sparsemax distribution, whose supporting set\ncan be adjusted. The proposed method has advantages over a softmax distribution\nin that it can exclude unnecessary actions by assigning zero probability.\nSecond, we prove that an MCTE problem is equivalent to robust Bayes estimation\nin the sense of the Brier score. Third, we propose a maximum causal Tsallis\nentropy imitation learning (MCTEIL) algorithm with a sparse mixture density\nnetwork (sparse MDN) by modeling mixture weights using a sparsemax\ndistribution. In particular, we show that the causal Tsallis entropy of an MDN\nencourages exploration and efficient mixture utilization while Boltzmann Gibbs\nentropy is less effective. We validate the proposed method in two simulation\nstudies and MCTEIL outperforms existing imitation learning methods in terms of\naverage returns and learning multi-modal policies.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:49:47 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 04:24:06 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lee", "Kyungjae", ""], ["Choi", "Sungjoon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1805.08340", "submitter": "Tong Qin", "authors": "Tong Qin and Ling Zhou and Dongbin Xiu", "title": "Reducing Parameter Space for Neural Network Training", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For neural networks (NNs) with rectified linear unit (ReLU) or binary\nactivation functions, we show that their training can be accomplished in a\nreduced parameter space. Specifically, the weights in each neuron can be\ntrained on the unit sphere, as opposed to the entire space, and the threshold\ncan be trained in a bounded interval, as opposed to the real line. We show that\nthe NNs in the reduced parameter space are mathematically equivalent to the\nstandard NNs with parameters in the whole space. The reduced parameter space\nshall facilitate the optimization procedure for the network training, as the\nsearch space becomes (much) smaller. We demonstrate the improved training\nperformance using numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 01:08:40 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 17:13:01 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 18:10:43 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Qin", "Tong", ""], ["Zhou", "Ling", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1805.08349", "submitter": "Chuang Wang", "authors": "Chuang Wang, Hong Hu and Yue M. Lu", "title": "A Solvable High-Dimensional Model of GAN", "comments": "Accepted by 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical analysis of the training process for a single-layer\nGAN fed by high-dimensional input data. The training dynamics of the proposed\nmodel at both microscopic and macroscopic scales can be exactly analyzed in the\nhigh-dimensional limit. In particular, we prove that the macroscopic quantities\nmeasuring the quality of the training process converge to a deterministic\nprocess characterized by an ordinary differential equation (ODE), whereas the\nmicroscopic states containing all the detailed weights remain stochastic, whose\ndynamics can be described by a stochastic differential equation (SDE). This\nanalysis provides a new perspective different from recent analyses in the limit\nof small learning rate, where the microscopic state is always considered\ndeterministic, and the contribution of noise is ignored. From our analysis, we\nshow that the level of the background noise is essential to the convergence of\nthe training process: setting the noise level too strong leads to failure of\nfeature recovery, whereas setting the noise too weak causes oscillation.\nAlthough this work focuses on a simple copy model of GAN, we believe the\nanalysis methods and insights developed here would prove useful in the\ntheoretical understanding of other variants of GANs with more advanced training\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 01:57:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 13:51:21 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wang", "Chuang", ""], ["Hu", "Hong", ""], ["Lu", "Yue M.", ""]]}, {"id": "1805.08355", "submitter": "Dian Lei", "authors": "Dian Lei, Xiaoxiao Chen, Jianfei Zhao", "title": "Opening the black box of deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great success of deep learning shows that its technology contains\nprofound truth, and understanding its internal mechanism not only has important\nimplications for the development of its technology and effective application in\nvarious fields, but also provides meaningful insights into the understanding of\nhuman brain mechanism. At present, most of the theoretical research on deep\nlearning is based on mathematics. This dissertation proposes that the neural\nnetwork of deep learning is a physical system, examines deep learning from\nthree different perspectives: microscopic, macroscopic, and physical world\nviews, answers multiple theoretical puzzles in deep learning by using physics\nprinciples. For example, from the perspective of quantum mechanics and\nstatistical physics, this dissertation presents the calculation methods for\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\nMachine, as well as the selection of cost functions, explains why deep learning\nmust be deep, what characteristics are learned in deep learning, why\nConvolutional Neural Networks do not have to be trained layer by layer, and the\nlimitations of deep learning, etc., and proposes the theoretical direction and\nbasis for the further development of deep learning now and in the future. The\nbrilliance of physics flashes in deep learning, we try to establish the deep\nlearning technology based on the scientific theory of physics.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 02:12:33 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Lei", "Dian", ""], ["Chen", "Xiaoxiao", ""], ["Zhao", "Jianfei", ""]]}, {"id": "1805.08356", "submitter": "Lydia Zakynthinou", "authors": "Huy L. Nguyen, Lydia Zakynthinou", "title": "Improved Algorithms for Collaborative PAC Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a recent model of collaborative PAC learning where $k$ players with\n$k$ different tasks collaborate to learn a single classifier that works for all\ntasks. Previous work showed that when there is a classifier that has very small\nerror on all tasks, there is a collaborative algorithm that finds a single\nclassifier for all tasks and has $O((\\ln (k))^2)$ times the worst-case sample\ncomplexity for learning a single task. In this work, we design new algorithms\nfor both the realizable and the non-realizable setting, having sample\ncomplexity only $O(\\ln (k))$ times the worst-case sample complexity for\nlearning a single task. The sample complexity upper bounds of our algorithms\nmatch previous lower bounds and in some range of parameters are even better\nthan previous algorithms that are allowed to output different classifiers for\ndifferent tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 02:18:56 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 23:25:45 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Nguyen", "Huy L.", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "1805.08395", "submitter": "Yichen Wang", "authors": "Yichen Wang, Le Song, Hongyuan Zha", "title": "Learning to Optimize via Wasserstein Deep Inverse Optimal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the inverse optimal control problem in social sciences: we aim at\nlearning a user's true cost function from the observed temporal behavior. In\ncontrast to traditional phenomenological works that aim to learn a generative\nmodel to fit the behavioral data, we propose a novel variational principle and\ntreat user as a reinforcement learning algorithm, which acts by optimizing his\ncost function. We first propose a unified KL framework that generalizes\nexisting maximum entropy inverse optimal control methods. We further propose a\ntwo-step Wasserstein inverse optimal control framework. In the first step, we\ncompute the optimal measure with a novel mass transport equation. In the second\nstep, we formulate the learning problem as a generative adversarial network. In\ntwo real world experiments - recommender systems and social networks, we show\nthat our framework obtains significant performance gains over both existing\ninverse optimal control methods and point process based generative models.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 05:11:59 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Wang", "Yichen", ""], ["Song", "Le", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1805.08402", "submitter": "Tyler Scott", "authors": "Tyler R. Scott, Karl Ridgeway, Michael C. Mozer", "title": "Adapted Deep Embeddings: A Synthesis of Methods for $k$-Shot Inductive\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus in machine learning has branched beyond training classifiers on a\nsingle task to investigating how previously acquired knowledge in a source\ndomain can be leveraged to facilitate learning in a related target domain,\nknown as inductive transfer learning. Three active lines of research have\nindependently explored transfer learning using neural networks. In weight\ntransfer, a model trained on the source domain is used as an initialization\npoint for a network to be trained on the target domain. In deep metric\nlearning, the source domain is used to construct an embedding that captures\nclass structure in both the source and target domains. In few-shot learning,\nthe focus is on generalizing well in the target domain based on a limited\nnumber of labeled examples. We compare state-of-the-art methods from these\nthree paradigms and also explore hybrid adapted-embedding methods that use\nlimited target-domain data to fine tune embeddings constructed from\nsource-domain data. We conduct a systematic comparison of methods in a variety\nof domains, varying the number of labeled instances available in the target\ndomain ($k$), as well as the number of target-domain classes. We reach three\nprincipal conclusions: (1) Deep embeddings are far superior, compared to weight\ntransfer, as a starting point for inter-domain transfer or model re-use (2) Our\nhybrid methods robustly outperform every few-shot learning and every deep\nmetric learning method previously proposed, with a mean error reduction of 34%\nover state-of-the-art. (3) Among loss functions for discovering embeddings, the\nhistogram loss (Ustinova & Lempitsky, 2016) is most robust. We hope our results\nwill motivate a unification of research in weight transfer, deep metric\nlearning, and few-shot learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 05:29:13 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 18:03:48 GMT"}, {"version": "v3", "created": "Sat, 18 Aug 2018 19:43:52 GMT"}, {"version": "v4", "created": "Sat, 27 Oct 2018 15:55:16 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Scott", "Tyler R.", ""], ["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1805.08430", "submitter": "Ming Wu", "authors": "Jilong Xue, Youshan Miao, Cheng Chen, Ming Wu, Lintao Zhang, Lidong\n  Zhou", "title": "RPC Considered Harmful: Fast Distributed Deep Learning on RDMA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning emerges as an important new resource-intensive workload and has\nbeen successfully applied in computer vision, speech, natural language\nprocessing, and so on. Distributed deep learning is becoming a necessity to\ncope with growing data and model sizes. Its computation is typically\ncharacterized by a simple tensor data abstraction to model multi-dimensional\nmatrices, a data-flow graph to model computation, and iterative executions with\nrelatively frequent synchronizations, thereby making it substantially different\nfrom Map/Reduce style distributed big data computation.\n  RPC, commonly used as the communication primitive, has been adopted by\npopular deep learning frameworks such as TensorFlow, which uses gRPC. We show\nthat RPC is sub-optimal for distributed deep learning computation, especially\non an RDMA-capable network. The tensor abstraction and data-flow graph, coupled\nwith an RDMA network, offers the opportunity to reduce the unnecessary overhead\n(e.g., memory copy) without sacrificing programmability and generality. In\nparticular, from a data access point of view, a remote machine is abstracted\njust as a \"device\" on an RDMA channel, with a simple memory interface for\nallocating, reading, and writing memory regions. Our graph analyzer looks at\nboth the data flow graph and the tensors to optimize memory allocation and\nremote data access using this interface. The result is up to 25 times speedup\nin representative deep learning benchmarks against the standard gRPC in\nTensorFlow and up to 169% improvement even against an RPC implementation\noptimized for RDMA, leading to faster convergence in the training process.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 07:42:33 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Xue", "Jilong", ""], ["Miao", "Youshan", ""], ["Chen", "Cheng", ""], ["Wu", "Ming", ""], ["Zhang", "Lintao", ""], ["Zhou", "Lidong", ""]]}, {"id": "1805.08440", "submitter": "Philipp Oberdiek", "authors": "Philipp Oberdiek, Matthias Rottmann, Hanno Gottschalk", "title": "Classification Uncertainty of Deep Neural Networks Based on Gradient\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantification of uncertainty of Convolutional Neural Networks\n(CNNs) based on gradient metrics. Unlike the classical softmax entropy, such\nmetrics gather information from all layers of the CNN. We show for the EMNIST\ndigits data set that for several such metrics we achieve the same meta\nclassification accuracy -- i.e. the task of classifying predictions as correct\nor incorrect without knowing the actual label -- as for entropy thresholding.\nWe apply meta classification to unknown concepts (out-of-distribution samples)\n-- EMNIST/Omniglot letters, CIFAR10 and noise -- and demonstrate that meta\nclassification rates for unknown concepts can be increased when using entropy\ntogether with several gradient based metrics as input quantities for a meta\nclassifier. Meta classifiers only trained on the uncertainty metrics of known\nconcepts, i.e. EMNIST digits, usually do not perform equally well for all\nunknown concepts. If we however allow the meta classifier to be trained on\nuncertainty metrics for some out-of-distribution samples, meta classification\nfor concepts remote from EMNIST digits (then termed known unknowns) can be\nimproved considerably.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:07:14 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 10:37:11 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Oberdiek", "Philipp", ""], ["Rottmann", "Matthias", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1805.08462", "submitter": "Boyu Chen", "authors": "Boyu Chen, Wenlian Lu, Ernest Fokoue", "title": "Meta-Learning with Hessian-Free Approach in Deep Neural Nets Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is a promising method to achieve efficient training method\ntowards deep neural net and has been attracting increases interests in recent\nyears. But most of the current methods are still not capable to train complex\nneuron net model with long-time training process. In this paper, a novel\nsecond-order meta-optimizer, named Meta-learning with Hessian-Free(MLHF)\napproach, is proposed based on the Hessian-Free approach. Two recurrent neural\nnetworks are established to generate the damping and the precondition matrix of\nthis Hessian-Free framework. A series of techniques to meta-train the MLHF\ntowards stable and reinforce the meta-training of this optimizer, including the\ngradient calculation of $H$. Numerical experiments on deep convolution neural\nnets, including CUDA-convnet and ResNet18(v2), with datasets of CIFAR10 and\nILSVRC2012, indicate that the MLHF shows good and continuous training\nperformance during the whole long-time training process, i.e., both the\nrapid-decreasing early stage and the steadily-deceasing later stage, and so is\na promising meta-learning framework towards elevating the training efficiency\nin real-world deep neural nets.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 09:04:52 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 06:14:05 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chen", "Boyu", ""], ["Lu", "Wenlian", ""], ["Fokoue", "Ernest", ""]]}, {"id": "1805.08463", "submitter": "Ho Chung Leon Law", "authors": "Ho Chung Leon Law, Dino Sejdinovic, Ewan Cameron, Tim CD Lucas, Seth\n  Flaxman, Katherine Battle, Kenji Fukumizu", "title": "Variational Learning on Aggregate Outputs with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a typical supervised learning framework assumes that the inputs and the\noutputs are measured at the same levels of granularity, many applications,\nincluding global mapping of disease, only have access to outputs at a much\ncoarser level than that of the inputs. Aggregation of outputs makes\ngeneralization to new inputs much more difficult. We consider an approach to\nthis problem based on variational learning with a model of output aggregation\nand Gaussian processes, where aggregation leads to intractability of the\nstandard evidence lower bounds. We propose new bounds and tractable\napproximations, leading to improved prediction accuracy and scalability to\nlarge datasets, while explicitly taking uncertainty into account. We develop a\nframework which extends to several types of likelihoods, including the Poisson\nmodel for aggregated count data. We apply our framework to a challenging and\nimportant problem, the fine-scale spatial modelling of malaria incidence, with\nover 1 million observations.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 09:08:01 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Law", "Ho Chung Leon", ""], ["Sejdinovic", "Dino", ""], ["Cameron", "Ewan", ""], ["Lucas", "Tim CD", ""], ["Flaxman", "Seth", ""], ["Battle", "Katherine", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1805.08465", "submitter": "Chao Li", "authors": "Chao Li, Mohammad Emtiyaz Khan, Zhun Sun, Gang Niu, Bo Han, Shengli\n  Xie, Qibin Zhao", "title": "Beyond Unfolding: Exact Recovery of Latent Convex Tensor Decomposition\n  under Reshuffling", "comments": "AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact recovery of tensor decomposition (TD) methods is a desirable property\nin both unsupervised learning and scientific data analysis. The numerical\ndefects of TD methods, however, limit their practical applications on\nreal-world data. As an alternative, convex tensor decomposition (CTD) was\nproposed to alleviate these problems, but its exact-recovery property is not\nproperly addressed so far. To this end, we focus on latent convex tensor\ndecomposition (LCTD), a practically widely-used CTD model, and rigorously prove\na sufficient condition for its exact-recovery property. Furthermore, we show\nthat such property can be also achieved by a more general model than LCTD. In\nthe new model, we generalize the classic tensor (un-)folding into reshuffling\noperation, a more flexible mapping to relocate the entries of the matrix into a\ntensor. Armed with the reshuffling operations and exact-recovery property, we\nexplore a totally novel application for (generalized) LCTD, i.e., image\nsteganography. Experimental results on synthetic data validate our theory, and\nresults on image steganography show that our method outperforms the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 09:12:30 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 04:57:45 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 23:10:10 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Li", "Chao", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Sun", "Zhun", ""], ["Niu", "Gang", ""], ["Han", "Bo", ""], ["Xie", "Shengli", ""], ["Zhao", "Qibin", ""]]}, {"id": "1805.08468", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Chao Li, Danilo Mandic, Jianting Cao and Qibin Zhao", "title": "Rank Minimization on Tensor Ring: A New Paradigm in Scalable Tensor\n  Decomposition and Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-rank tensor completion tasks, due to the underlying multiple\nlarge-scale singular value decomposition (SVD) operations and rank selection\nproblem of the traditional methods, they suffer from high computational cost\nand high sensitivity of model complexity. In this paper, taking advantages of\nhigh compressibility of the recently proposed tensor ring (TR) decomposition,\nwe propose a new model for tensor completion problem. This is achieved through\nintroducing convex surrogates of tensor low-rank assumption on latent tensor\nring factors, which makes it possible for the Schatten norm regularization\nbased models to be solved at much smaller scale. We propose two algorithms\nwhich apply different structured Schatten norms on tensor ring factors\nrespectively. By the alternating direction method of multipliers (ADMM) scheme,\nthe tensor ring factors and the predicted tensor can be optimized\nsimultaneously. The experiments on synthetic data and real-world data show the\nhigh performance and efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 09:16:34 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Yuan", "Longhao", ""], ["Li", "Chao", ""], ["Mandic", "Danilo", ""], ["Cao", "Jianting", ""], ["Zhao", "Qibin", ""]]}, {"id": "1805.08469", "submitter": "Gilles Louppe", "authors": "Joeri Hermans, Gilles Louppe", "title": "Gradient Energy Matching for Distributed Asynchronous Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed asynchronous SGD has become widely used for deep learning in\nlarge-scale systems, but remains notorious for its instability when increasing\nthe number of workers. In this work, we study the dynamics of distributed\nasynchronous SGD under the lens of Lagrangian mechanics. Using this\ndescription, we introduce the concept of energy to describe the optimization\nprocess and derive a sufficient condition ensuring its stability as long as the\ncollective energy induced by the active workers remains below the energy of a\ntarget synchronous process. Making use of this criterion, we derive a stable\ndistributed asynchronous optimization procedure, GEM, that estimates and\nmaintains the energy of the asynchronous system below or equal to the energy of\nsequential SGD with momentum. Experimental results highlight the stability and\nspeedup of GEM compared to existing schemes, even when scaling to one hundred\nasynchronous workers. Results also indicate better generalization compared to\nthe targeted SGD with momentum.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 09:32:21 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Hermans", "Joeri", ""], ["Louppe", "Gilles", ""]]}, {"id": "1805.08490", "submitter": "Miltiadis Allamanis", "authors": "Marc Brockschmidt, Miltiadis Allamanis, Alexander L. Gaunt, Oleksandr\n  Polozov", "title": "Generative Code Modeling with Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for source code are an interesting structured prediction\nproblem, requiring to reason about both hard syntactic and semantic constraints\nas well as about natural, likely programs. We present a novel model for this\nproblem that uses a graph to represent the intermediate state of the generated\noutput. The generative procedure interleaves grammar-driven expansion steps\nwith graph augmentation and neural message passing steps. An experimental\nevaluation shows that our new model can generate semantically meaningful\nexpressions, outperforming a range of strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 10:38:41 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 21:56:13 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Brockschmidt", "Marc", ""], ["Allamanis", "Miltiadis", ""], ["Gaunt", "Alexander L.", ""], ["Polozov", "Oleksandr", ""]]}, {"id": "1805.08498", "submitter": "Michael Figurnov", "authors": "Michael Figurnov, Shakir Mohamed, Andriy Mnih", "title": "Implicit Reparameterization Gradients", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By providing a simple and efficient way of computing low-variance gradients\nof continuous random variables, the reparameterization trick has become the\ntechnique of choice for training a variety of latent variable models. However,\nit is not applicable to a number of important continuous distributions. We\nintroduce an alternative approach to computing reparameterization gradients\nbased on implicit differentiation and demonstrate its broader applicability by\napplying it to Gamma, Beta, Dirichlet, and von Mises distributions, which\ncannot be used with the classic reparameterization trick. Our experiments show\nthat the proposed approach is faster and more accurate than the existing\ngradient estimators for these distributions.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 11:00:19 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 12:38:04 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 17:49:12 GMT"}, {"version": "v4", "created": "Wed, 30 Jan 2019 15:24:42 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Figurnov", "Michael", ""], ["Mohamed", "Shakir", ""], ["Mnih", "Andriy", ""]]}, {"id": "1805.08522", "submitter": "Guillermo Valle-P\\'erez", "authors": "Guillermo Valle-P\\'erez, Chico Q. Camargo, Ard A. Louis", "title": "Deep learning generalizes because the parameter-function map is biased\n  towards simple functions", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime where classical\nlearning theory would instead predict that they would severely overfit. While\nmany proposals for some kind of implicit regularization have been made to\nrationalise this success, there is no consensus for the fundamental reason why\nDNNs do not strongly overfit. In this paper, we provide a new explanation. By\napplying a very general probability-complexity bound recently derived from\nalgorithmic information theory (AIT), we argue that the parameter-function map\nof many DNNs should be exponentially biased towards simple functions. We then\nprovide clear evidence for this strong simplicity bias in a model DNN for\nBoolean functions, as well as in much larger fully connected and convolutional\nnetworks applied to CIFAR10 and MNIST. As the target functions in many real\nproblems are expected to be highly structured, this intrinsic simplicity bias\nhelps explain why deep networks generalize well on real world problems. This\npicture also facilitates a novel PAC-Bayes approach where the prior is taken\nover the DNN input-output function space, rather than the more conventional\nprior over parameter space. If we assume that the training algorithm samples\nparameters close to uniformly within the zero-error region then the PAC-Bayes\ntheorem can be used to guarantee good expected generalization for target\nfunctions producing high-likelihood training sets. By exploiting recently\ndiscovered connections between DNNs and Gaussian processes to estimate the\nmarginal likelihood, we produce relatively tight generalization PAC-Bayes error\nbounds which correlate well with the true error on realistic datasets such as\nMNIST and CIFAR10 and for architectures including convolutional and fully\nconnected networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 11:51:36 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 10:55:36 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 18:22:18 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 23:40:35 GMT"}, {"version": "v5", "created": "Sun, 21 Apr 2019 10:16:54 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Valle-P\u00e9rez", "Guillermo", ""], ["Camargo", "Chico Q.", ""], ["Louis", "Ard A.", ""]]}, {"id": "1805.08527", "submitter": "Weizhong Zhang", "authors": "Weizhong Zhang, Bin Hong, Lin Ma, Wei Liu, and Tong Zhang", "title": "Safe Element Screening for Submodular Function Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are discrete analogs of convex functions, which have\napplications in various fields, including machine learning and computer vision.\nHowever, in large-scale applications, solving Submodular Function Minimization\n(SFM) problems remains challenging. In this paper, we make the first attempt to\nextend the emerging technique named screening in large-scale sparse learning to\nSFM for accelerating its optimization process. We first conduct a careful\nstudying of the relationships between SFM and the corresponding convex proximal\nproblems, as well as the accurate primal optimum estimation of the proximal\nproblems. Relying on this study, we subsequently propose a novel safe screening\nmethod to quickly identify the elements guaranteed to be included (we refer to\nthem as active) or excluded (inactive) in the final optimal solution of SFM\nduring the optimization process. By removing the inactive elements and fixing\nthe active ones, the problem size can be dramatically reduced, leading to great\nsavings in the computational cost without sacrificing any accuracy. To the best\nof our knowledge, the proposed method is the first screening method in the\nfields of SFM and even combinatorial optimization, thus pointing out a new\ndirection for accelerating SFM algorithms. Experiment results on both synthetic\nand real datasets demonstrate the significant speedups gained by our approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 11:58:11 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 11:35:54 GMT"}, {"version": "v3", "created": "Thu, 24 May 2018 05:52:55 GMT"}, {"version": "v4", "created": "Thu, 7 Jun 2018 03:32:56 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Zhang", "Weizhong", ""], ["Hong", "Bin", ""], ["Ma", "Lin", ""], ["Liu", "Wei", ""], ["Zhang", "Tong", ""]]}, {"id": "1805.08539", "submitter": "Lior Kamma", "authors": "Casper Benjamin Freksen, Lior Kamma, Kasper Green Larsen", "title": "Fully Understanding the Hashing Trick", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature hashing, also known as {\\em the hashing trick}, introduced by\nWeinberger et al. (2009), is one of the key techniques used in scaling-up\nmachine learning algorithms. Loosely speaking, feature hashing uses a random\nsparse projection matrix $A : \\mathbb{R}^n \\to \\mathbb{R}^m$ (where $m \\ll n$)\nin order to reduce the dimension of the data from $n$ to $m$ while\napproximately preserving the Euclidean norm. Every column of $A$ contains\nexactly one non-zero entry, equals to either $-1$ or $1$.\n  Weinberger et al. showed tail bounds on $\\|Ax\\|_2^2$. Specifically they\nshowed that for every $\\varepsilon, \\delta$, if $\\|x\\|_{\\infty} / \\|x\\|_2$ is\nsufficiently small, and $m$ is sufficiently large, then $$\\Pr[ \\; |\n\\;\\|Ax\\|_2^2 - \\|x\\|_2^2\\; | < \\varepsilon \\|x\\|_2^2 \\;] \\ge 1 - \\delta \\;.$$\nThese bounds were later extended by Dasgupta \\etal (2010) and most recently\nrefined by Dahlgaard et al. (2017), however, the true nature of the performance\nof this key technique, and specifically the correct tradeoff between the\npivotal parameters $\\|x\\|_{\\infty} / \\|x\\|_2, m, \\varepsilon, \\delta$ remained\nan open question.\n  We settle this question by giving tight asymptotic bounds on the exact\ntradeoff between the central parameters, thus providing a complete\nunderstanding of the performance of feature hashing. We complement the\nasymptotic bound with empirical data, which shows that the constants \"hiding\"\nin the asymptotic notation are, in fact, very close to $1$, thus further\nillustrating the tightness of the presented bounds in practice.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:23:47 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Freksen", "Casper Benjamin", ""], ["Kamma", "Lior", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "1805.08550", "submitter": "Laura Alessandretti", "authors": "Laura Alessandretti, Abeer ElBahrawy, Luca Maria Aiello, Andrea\n  Baronchelli", "title": "Anticipating cryptocurrency prices using machine learning", "comments": "Complexity, 2018", "journal-ref": null, "doi": "10.1155/2018/8983590", "report-no": null, "categories": "physics.soc-ph cs.LG q-fin.GN q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and AI-assisted trading have attracted growing interest for\nthe past few years. Here, we use this approach to test the hypothesis that the\ninefficiency of the cryptocurrency market can be exploited to generate abnormal\nprofits. We analyse daily data for $1,681$ cryptocurrencies for the period\nbetween Nov. 2015 and Apr. 2018. We show that simple trading strategies\nassisted by state-of-the-art machine learning algorithms outperform standard\nbenchmarks. Our results show that nontrivial, but ultimately simple,\nalgorithmic mechanisms can help anticipate the short-term evolution of the\ncryptocurrency market.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:45:54 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 13:49:41 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 12:33:33 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2018 09:05:02 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Alessandretti", "Laura", ""], ["ElBahrawy", "Abeer", ""], ["Aiello", "Luca Maria", ""], ["Baronchelli", "Andrea", ""]]}, {"id": "1805.08562", "submitter": "Vidya Muthukumar", "authors": "Vidya Muthukumar, Mitas Ray, Anant Sahai, Peter L. Bartlett", "title": "Best of many worlds: Robust model selection for online supervised\n  learning", "comments": "33 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce algorithms for online, full-information prediction that are\ncompetitive with contextual tree experts of unknown complexity, in both\nprobabilistic and adversarial settings. We show that by incorporating a\nprobabilistic framework of structural risk minimization into existing adaptive\nalgorithms, we can robustly learn not only the presence of stochastic structure\nwhen it exists (leading to constant as opposed to $\\mathcal{O}(\\sqrt{T})$\nregret), but also the correct model order. We thus obtain regret bounds that\nare competitive with the regret of an optimal algorithm that possesses strong\nside information about both the complexity of the optimal contextual tree\nexpert and whether the process generating the data is stochastic or\nadversarial. These are the first constructive guarantees on simultaneous\nadaptivity to the model and the presence of stochasticity.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 13:08:41 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Muthukumar", "Vidya", ""], ["Ray", "Mitas", ""], ["Sahai", "Anant", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1805.08565", "submitter": "Stefan Richthofer", "authors": "Stefan Richthofer, Laurenz Wiskott", "title": "Global Navigation Using Predictable and Slow Feature Analysis in\n  Multiroom Environments, Path Planning and Other Control Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended Predictable Feature Analysis (PFAx) [Richthofer and Wiskott, 2017]\nis an extension of PFA [Richthofer and Wiskott, 2015] that allows generating a\ngoal-directed control signal of an agent whose dynamics has previously been\nlearned during a training phase in an unsupervised manner. PFAx hardly requires\nassumptions or prior knowledge of the agent's sensor or control mechanics, or\nof the environment. It selects features from a high-dimensional input by\nintrinsic predictability and organizes them into a reasonably low-dimensional\nmodel.\n  While PFA obtains a well predictable model, PFAx yields a model ideally\nsuited for manipulations with predictable outcome. This allows for\ngoal-directed manipulation of an agent and thus for local navigation, i.e. for\nreaching states where intermediate actions can be chosen by a permanent descent\nof distance to the goal. The approach is limited when it comes to global\nnavigation, e.g. involving obstacles or multiple rooms.\n  In this article, we extend theoretical results from [Sprekeler and Wiskott,\n2008], enabling PFAx to perform stable global navigation. So far, the most\nwidely exploited characteristic of Slow Feature Analysis (SFA) was that\nslowness yields invariances. We focus on another fundamental characteristics of\nslow signals: They tend to yield monotonicity and one significant property of\nmonotonicity is that local optimization is sufficient to find a global optimum.\n  We present an SFA-based algorithm that structures an environment such that\nnavigation tasks hierarchically decompose into subgoals. Each of these can be\nefficiently achieved by PFAx, yielding an overall global solution of the task.\nThe algorithm needs to explore and process an environment only once and can\nthen perform all sorts of navigation tasks efficiently. We support this\nalgorithm by mathematical theory and apply it to different problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 13:18:01 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Richthofer", "Stefan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1805.08571", "submitter": "Chris Schwiegelshohn", "authors": "Alexander Munteanu and Chris Schwiegelshohn and Christian Sohler and\n  David P. Woodruff", "title": "On Coresets for Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coresets are one of the central methods to facilitate the analysis of large\ndata sets. We continue a recent line of research applying the theory of\ncoresets to logistic regression. First, we show a negative result, namely, that\nno strongly sublinear sized coresets exist for logistic regression. To deal\nwith intractable worst-case instances we introduce a complexity measure\n$\\mu(X)$, which quantifies the hardness of compressing a data set for logistic\nregression. $\\mu(X)$ has an intuitive statistical interpretation that may be of\nindependent interest. For data sets with bounded $\\mu(X)$-complexity, we show\nthat a novel sensitivity sampling scheme produces the first provably sublinear\n$(1\\pm\\varepsilon)$-coreset. We illustrate the performance of our method by\ncomparing to uniform sampling as well as to state of the art methods in the\narea. The experiments are conducted on real world benchmark data for logistic\nregression.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 13:33:22 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 12:30:00 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 16:25:50 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Munteanu", "Alexander", ""], ["Schwiegelshohn", "Chris", ""], ["Sohler", "Christian", ""], ["Woodruff", "David P.", ""]]}, {"id": "1805.08574", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Hujun Yin, John Keane, Mark Elliot", "title": "Breaking the Activation Function Bottleneck through Adaptive\n  Parameterization", "comments": "Published as a conference paper at NeurIPS (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard neural network architectures are non-linear only by virtue of a\nsimple element-wise activation function, making them both brittle and\nexcessively large. In this paper, we consider methods for making the\nfeed-forward layer more flexible while preserving its basic structure. We\ndevelop simple drop-in replacements that learn to adapt their parameterization\nconditional on the input, thereby increasing statistical efficiency\nsignificantly. We present an adaptive LSTM that advances the state of the art\nfor the Penn Treebank and WikiText-2 word-modeling tasks while using fewer\nparameters and converging in less than half as many iterations.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 13:35:08 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 06:37:30 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 10:13:09 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 13:57:14 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Yin", "Hujun", ""], ["Keane", "John", ""], ["Elliot", "Mark", ""]]}, {"id": "1805.08578", "submitter": "Stefano Teso", "authors": "Stefano Teso and Kristian Kersting", "title": "\"Why Should I Trust Interactive Learners?\" Explaining Interactive\n  Queries of Classifiers to Users", "comments": "Submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although interactive learning puts the user into the loop, the learner\nremains mostly a black box for the user. Understanding the reasons behind\nqueries and predictions is important when assessing how the learner works and,\nin turn, trust. Consequently, we propose the novel framework of explanatory\ninteractive learning: in each step, the learner explains its interactive query\nto the user, and she queries of any active classifier for visualizing\nexplanations of the corresponding predictions. We demonstrate that this can\nboost the predictive and explanatory powers of and the trust into the learned\nmodel, using text (e.g. SVMs) and image classification (e.g. neural networks)\nexperiments as well as a user study.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 13:46:59 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Teso", "Stefano", ""], ["Kersting", "Kristian", ""]]}, {"id": "1805.08588", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Li Wang, Zan Wang, Tim Baarslag, Jianye Hao", "title": "An Optimal Rewiring Strategy for Reinforcement Social Learning in\n  Cooperative Multiagent Systems", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent coordination in cooperative multiagent systems (MASs) has been\nwidely studied in both fixed-agent repeated interaction setting and the static\nsocial learning framework. However, two aspects of dynamics in real-world\nmultiagent scenarios are currently missing in existing works. First, the\nnetwork topologies can be dynamic where agents may change their connections\nthrough rewiring during the course of interactions. Second, the game matrix\nbetween each pair of agents may not be static and usually not known as a prior.\nBoth the network dynamic and game uncertainty increase the coordination\ndifficulty among agents. In this paper, we consider a multiagent dynamic social\nlearning environment in which each agent can choose to rewire potential\npartners and interact with randomly chosen neighbors in each round. We propose\nan optimal rewiring strategy for agents to select most beneficial peers to\ninteract with for the purpose of maximizing the accumulated payoff in repeated\ninteractions. We empirically demonstrate the effectiveness and robustness of\nour approach through comparing with benchmark strategies. The performance of\nthree representative learning strategies under our social learning framework\nwith our optimal rewiring is investigated as well.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 14:20:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Tang", "Hongyao", ""], ["Wang", "Li", ""], ["Wang", "Zan", ""], ["Baarslag", "Tim", ""], ["Hao", "Jianye", ""]]}, {"id": "1805.08593", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Angela Zhou", "title": "Confounding-Robust Policy Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning personalized decision policies from\nobservational data while accounting for possible unobserved confounding.\nPrevious approaches, which assume unconfoundedness, i.e., that no unobserved\nconfounders affect both the treatment assignment as well as outcome, can lead\nto policies that introduce harm rather than benefit when some unobserved\nconfounding is present, as is generally the case with observational data.\nInstead, since policy value and regret may not be point-identifiable, we study\na method that minimizes the worst-case estimated regret of a candidate policy\nagainst a baseline policy over an uncertainty set for propensity weights that\ncontrols the extent of unobserved confounding. We prove generalization\nguarantees that ensure our policy will be safe when applied in practice and\nwill in fact obtain the best-possible uniform control on the range of all\npossible population regrets that agree with the possible extent of confounding.\nWe develop efficient algorithmic solutions to compute this confounding-robust\npolicy. Finally, we assess and compare our methods on synthetic and\nsemi-synthetic data. In particular, we consider a case study on personalizing\nhormone replacement therapy based on observational data, where we validate our\nresults on a randomized experiment. We demonstrate that hidden confounding can\nhinder existing policy learning approaches and lead to unwarranted harm, while\nour robust approach guarantees safety and focuses on well-evidenced\nimprovement, a necessity for making personalized treatment policies learned\nfrom observational data reliable in practice.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:10:08 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 16:33:31 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 18:35:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "1805.08610", "submitter": "Mark McLeod", "authors": "Mark McLeod, Michael A. Osborne, Stephen J. Roberts", "title": "Optimization, fast and slow: optimally switching between local and\n  Bayesian optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the first Bayesian Optimization algorithm, BLOSSOM, which selects\nbetween multiple alternative acquisition functions and traditional local\noptimization at each step. This is combined with a novel stopping condition\nbased on expected regret. This pairing allows us to obtain the best\ncharacteristics of both local and Bayesian optimization, making efficient use\nof function evaluations while yielding superior convergence to the global\nminimum on a selection of optimization problems, and also halting optimization\nonce a principled and intuitive stopping condition has been fulfilled.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:27:17 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["McLeod", "Mark", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1805.08620", "submitter": "Shin Fujieda", "authors": "Shin Fujieda, Kohei Takayama, Toshiya Hachisuka", "title": "Wavelet Convolutional Neural Networks", "comments": "10 pages, 7 figures, 5 tables. arXiv admin note: substantial text\n  overlap with arXiv:1707.07394", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial and spectral approaches are two major approaches for image processing\ntasks such as image classification and object recognition. Among many such\nalgorithms, convolutional neural networks (CNNs) have recently achieved\nsignificant performance improvement in many challenging tasks. Since CNNs\nprocess images directly in the spatial domain, they are essentially spatial\napproaches. Given that spatial and spectral approaches are known to have\ndifferent characteristics, it will be interesting to incorporate a spectral\napproach into CNNs. We propose a novel CNN architecture, wavelet CNNs, which\ncombines a multiresolution analysis and CNNs into one model. Our insight is\nthat a CNN can be viewed as a limited form of a multiresolution analysis. Based\non this insight, we supplement missing parts of the multiresolution analysis\nvia wavelet transform and integrate them as additional components in the entire\narchitecture. Wavelet CNNs allow us to utilize spectral information which is\nmostly lost in conventional CNNs but useful in most image processing tasks. We\nevaluate the practical performance of wavelet CNNs on texture classification\nand image annotation. The experiments show that wavelet CNNs can achieve better\naccuracy in both tasks than existing models while having significantly fewer\nparameters than conventional CNNs.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 07:18:54 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Fujieda", "Shin", ""], ["Takayama", "Kohei", ""], ["Hachisuka", "Toshiya", ""]]}, {"id": "1805.08622", "submitter": "Parameswaran Kamalaruban Dr.", "authors": "Parameswaran Kamalaruban", "title": "Transitions, Losses, and Re-parameterizations: Elements of Prediction\n  Games", "comments": "PhD thesis, The Australian National University, 2018. arXiv admin\n  note: text overlap with arXiv:0901.0356 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents some geometric insights into three different types of\ntwo player prediction games -- namely general learning task, prediction with\nexpert advice, and online convex optimization. These games differ in the nature\nof the opponent (stochastic, adversarial, or intermediate), the order of the\nplayers' move, and the utility function. The insights shed some light on the\nunderstanding of the intrinsic barriers of the prediction problems and the\ndesign of computationally efficient learning algorithms with strong theoretical\nguarantees (such as generalizability, statistical consistency, and constant\nregret etc.).\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 09:18:03 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Kamalaruban", "Parameswaran", ""]]}, {"id": "1805.08638", "submitter": "Ruida Zhou", "authors": "Ruida Zhou, Chao Gan, Jing Yan, Cong Shen", "title": "Cost-aware Cascading Bandits", "comments": "11 pages, 2 figures, IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a cost-aware cascading bandits model, a new variant\nof multi-armed ban- dits with cascading feedback, by considering the random\ncost of pulling arms. In each step, the learning agent chooses an ordered list\nof items and examines them sequentially, until certain stopping condition is\nsatisfied. Our objective is then to max- imize the expected net reward in each\nstep, i.e., the reward obtained in each step minus the total cost in- curred in\nexamining the items, by deciding the or- dered list of items, as well as when\nto stop examina- tion. We study both the offline and online settings, depending\non whether the state and cost statistics of the items are known beforehand. For\nthe of- fline setting, we show that the Unit Cost Ranking with Threshold 1\n(UCR-T1) policy is optimal. For the online setting, we propose a Cost-aware\nCas- cading Upper Confidence Bound (CC-UCB) algo- rithm, and show that the\ncumulative regret scales in O(log T ). We also provide a lower bound for all\n{\\alpha}-consistent policies, which scales in {\\Omega}(log T ) and matches our\nupper bound. The performance of the CC-UCB algorithm is evaluated with both\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:39:30 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Zhou", "Ruida", ""], ["Gan", "Chao", ""], ["Yan", "Jing", ""], ["Shen", "Cong", ""]]}, {"id": "1805.08647", "submitter": "Prashant Singh", "authors": "Prashant Singh and Andreas Hellander", "title": "Multi-Statistic Approximate Bayesian Computation with Multi-Armed\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computation is an established and popular method for\nlikelihood-free inference with applications in many disciplines. The\neffectiveness of the method depends critically on the availability of well\nperforming summary statistics. Summary statistic selection relies heavily on\ndomain knowledge and carefully engineered features, and can be a laborious time\nconsuming process. Since the method is sensitive to data dimensionality, the\nprocess of selecting summary statistics must balance the need to include\ninformative statistics and the dimensionality of the feature vector. This paper\nproposes to treat the problem of dynamically selecting an appropriate summary\nstatistic from a given pool of candidate summary statistics as a multi-armed\nbandit problem. This allows approximate Bayesian computation rejection sampling\nto dynamically focus on a distribution over well performing summary statistics\nas opposed to a fixed set of statistics. The proposed method is unique in that\nit does not require any pre-processing and is scalable to a large number of\ncandidate statistics. This enables efficient use of a large library of possible\ntime series summary statistics without prior feature engineering. The proposed\napproach is compared to state-of-the-art methods for summary statistics\nselection using a challenging test problem from the systems biology literature.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:57:12 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Singh", "Prashant", ""], ["Hellander", "Andreas", ""]]}, {"id": "1805.08651", "submitter": "Aapo Hyvarinen", "authors": "Aapo Hyvarinen, Hiroaki Sasaki, Richard E. Turner", "title": "Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive\n  Learning", "comments": "Camera-ready version of article accepted for AISTATS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear ICA is a fundamental problem for unsupervised representation\nlearning, emphasizing the capacity to recover the underlying latent variables\ngenerating the data (i.e., identifiability). Recently, the very first\nidentifiability proofs for nonlinear ICA have been proposed, leveraging the\ntemporal structure of the independent components. Here, we propose a general\nframework for nonlinear ICA, which, as a special case, can make use of temporal\nstructure. It is based on augmenting the data by an auxiliary variable, such as\nthe time index, the history of the time series, or any other available\ninformation. We propose to learn nonlinear ICA by discriminating between true\naugmented data, or data in which the auxiliary variable has been randomized.\nThis enables the framework to be implemented algorithmically through logistic\nregression, possibly in a neural network. We provide a comprehensive proof of\nthe identifiability of the model as well as the consistency of our estimation\nmethod. The approach not only provides a general theoretical framework\ncombining and generalizing previously proposed nonlinear ICA models and\nalgorithms, but also brings practical advantages.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:01:22 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 13:09:54 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 15:17:01 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Hyvarinen", "Aapo", ""], ["Sasaki", "Hiroaki", ""], ["Turner", "Richard E.", ""]]}, {"id": "1805.08656", "submitter": "Ziming Zhang", "authors": "Ziming Zhang", "title": "LMKL-Net: A Fast Localized Multiple Kernel Learning Solver via Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose solving localized multiple kernel learning (LMKL)\nusing LMKL-Net, a feedforward deep neural network. In contrast to previous\nworks, as a learning principle we propose {\\em parameterizing} both the gating\nfunction for learning kernel combination weights and the multiclass classifier\nin LMKL using an attentional network (AN) and a multilayer perceptron (MLP),\nrespectively. In this way we can learn the (nonlinear) decision function in\nLMKL (approximately) by sequential applications of AN and MLP. Empirically on\nbenchmark datasets we demonstrate that overall LMKL-Net can not only outperform\nthe state-of-the-art MKL solvers in terms of accuracy, but also be trained\nabout {\\em two orders of magnitude} faster with much smaller memory footprint\nfor large-scale learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:12:38 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Zhang", "Ziming", ""]]}, {"id": "1805.08657", "submitter": "Grigorios Chrysos", "authors": "Grigorios G. Chrysos, Jean Kossaifi, Stefanos Zafeiriou", "title": "Robust Conditional Generative Adversarial Networks", "comments": "To appear in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative adversarial networks (cGAN) have led to large\nimprovements in the task of conditional image generation, which lies at the\nheart of computer vision. The major focus so far has been on performance\nimprovement, while there has been little effort in making cGAN more robust to\nnoise. The regression (of the generator) might lead to arbitrarily large errors\nin the output, which makes cGAN unreliable for real-world applications. In this\nwork, we introduce a novel conditional GAN model, called RoCGAN, which\nleverages structure in the target space of the model to address the issue. Our\nmodel augments the generator with an unsupervised pathway, which promotes the\noutputs of the generator to span the target manifold even in the presence of\nintense noise. We prove that RoCGAN share similar theoretical properties as GAN\nand experimentally verify that our model outperforms existing state-of-the-art\ncGAN architectures by a large margin in a variety of domains including images\nfrom natural scenes and faces.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:14:11 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 07:59:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chrysos", "Grigorios G.", ""], ["Kossaifi", "Jean", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1805.08665", "submitter": "Steven Atkinson", "authors": "Steven Atkinson and Nicholas Zabaras", "title": "Structured Bayesian Gaussian process latent variable model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian Gaussian process latent variable model that\nexplicitly captures spatial correlations in data using a parameterized spatial\nkernel and leveraging structure-exploiting algebra on the model covariance\nmatrices for computational tractability. Inference is made tractable through a\ncollapsed variational bound with similar computational complexity to that of\nthe traditional Bayesian GP-LVM. Inference over partially-observed test cases\nis achieved by optimizing a \"partially-collapsed\" bound. Modeling\nhigh-dimensional time series systems is enabled through use of a dynamical GP\nlatent variable prior. Examples imputing missing data on images and\nsuper-resolution imputation of missing video frames demonstrate the model.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:35:10 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Atkinson", "Steven", ""], ["Zabaras", "Nicholas", ""]]}, {"id": "1805.08671", "submitter": "Shiyu Liang", "authors": "Shiyu Liang, Ruoyu Sun, Jason D. Lee, R. Srikant", "title": "Adding One Neuron Can Eliminate All Bad Local Minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main difficulties in analyzing neural networks is the\nnon-convexity of the loss function which may have many bad local minima.\n  In this paper, we study the landscape of neural networks for binary\nclassification tasks. Under mild assumptions, we prove that after adding one\nspecial neuron with a skip connection to the output, or one special neuron per\nlayer, every local minimum is a global minimum.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:44:35 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Liang", "Shiyu", ""], ["Sun", "Ruoyu", ""], ["Lee", "Jason D.", ""], ["Srikant", "R.", ""]]}, {"id": "1805.08672", "submitter": "Romain Lopez", "authors": "Romain Lopez, Jeffrey Regier, Michael I. Jordan and Nir Yosef", "title": "Information Constraints on Auto-Encoding Variational Bayes", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 31 (2018)", "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parameterizing the approximate posterior of a generative model with neural\nnetworks has become a common theme in recent machine learning research. While\nproviding appealing flexibility, this approach makes it difficult to impose or\nassess structural constraints such as conditional independence. We propose a\nframework for learning representations that relies on Auto-Encoding Variational\nBayes and whose search space is constrained via kernel-based measures of\nindependence. In particular, our method employs the $d$-variable\nHilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between\nthe latent representations and arbitrary nuisance factors. We show how to apply\nthis method to a range of problems, including the problems of learning\ninvariant representations and the learning of interpretable representations. We\nalso present a full-fledged application to single-cell RNA sequencing\n(scRNA-seq). In this setting the biological signal is mixed in complex ways\nwith sequencing errors and sampling effects. We show that our method\nout-performs the state-of-the-art in this domain.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:45:14 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 00:16:45 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 00:41:02 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 02:40:15 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Lopez", "Romain", ""], ["Regier", "Jeffrey", ""], ["Jordan", "Michael I.", ""], ["Yosef", "Nir", ""]]}, {"id": "1805.08688", "submitter": "Xianzhi Du", "authors": "Xianzhi Du, Mostafa El-Khamy, Vlad I. Morariu, Jungwon Lee, Larry\n  Davis", "title": "Fused Deep Neural Networks for Efficient Pedestrian Detection", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient pedestrian detection system, designed\nby fusion of multiple deep neural network (DNN) systems. Pedestrian candidates\nare first generated by a single shot convolutional multi-box detector at\ndifferent locations with various scales and aspect ratios. The candidate\ngenerator is designed to provide the majority of ground truth pedestrian\nannotations at the cost of a large number of false positives. Then, a\nclassification system using the idea of ensemble learning is deployed to\nimprove the detection accuracy. The classification system further classifies\nthe generated candidates based on opinions of multiple deep verification\nnetworks and a fusion network which utilizes a novel soft-rejection fusion\nmethod to adjust the confidence in the detection results. To improve the\ntraining of the deep verification networks, a novel soft-label method is\ndevised to assign floating point labels to the generated pedestrian candidates.\nA deep context aggregation semantic segmentation network also provides\npixel-level classification of the scene and its results are softly fused with\nthe detection results by the single shot detector. Our pedestrian detector\ncompared favorably to state-of-art methods on all popular pedestrian detection\ndatasets. For example, our fused DNN has better detection accuracy on the\nCaltech Pedestrian dataset than all previous state of art methods, while also\nbeing the fastest. We significantly improved the log-average miss rate on the\nCaltech pedestrian dataset to 7.67% and achieved the new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 00:13:28 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Du", "Xianzhi", ""], ["El-Khamy", "Mostafa", ""], ["Morariu", "Vlad I.", ""], ["Lee", "Jungwon", ""], ["Davis", "Larry", ""]]}, {"id": "1805.08699", "submitter": "Sze Teng Liong", "authors": "Sze-Teng Liong, Y.S. Gan, Wei-Chuen Yau, Yen-Chang Huang, Tan Lit Ken", "title": "OFF-ApexNet on Micro-expression Recognition System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a person attempts to conceal an emotion, the genuine emotion is manifest\nas a micro-expression. Exploration of automatic facial micro-expression\nrecognition systems is relatively new in the computer vision domain. This is\ndue to the difficulty in implementing optimal feature extraction methods to\ncope with the subtlety and brief motion characteristics of the expression. Most\nof the existing approaches extract the subtle facial movements based on\nhand-crafted features. In this paper, we address the micro-expression\nrecognition task with a convolutional neural network (CNN) architecture, which\nwell integrates the features extracted from each video. A new feature\ndescriptor, Optical Flow Features from Apex frame Network (OFF-ApexNet) is\nintroduced. This feature descriptor combines the optical ow guided context with\nthe CNN. Firstly, we obtain the location of the apex frame from each video\nsequence as it portrays the highest intensity of facial motion among all\nframes. Then, the optical ow information are attained from the apex frame and a\nreference frame (i.e., onset frame). Finally, the optical flow features are fed\ninto a pre-designed CNN model for further feature enhancement as well as to\ncarry out the expression classification. To evaluate the effectiveness of\nOFF-ApexNet, comprehensive evaluations are conducted on three public\nspontaneous micro-expression datasets (i.e., SMIC, CASME II and SAMM). The\npromising recognition result suggests that the proposed method can optimally\ndescribe the significant micro-expression details. In particular, we report\nthat, in a multi-database with leave-one-subject-out cross-validation\nexperimental protocol, the recognition performance reaches 74.60% of\nrecognition accuracy and F-measure of 71.04%. We also note that this is the\nfirst work that performs cross-dataset validation on three databases in this\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 02:22:47 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Liong", "Sze-Teng", ""], ["Gan", "Y. S.", ""], ["Yau", "Wei-Chuen", ""], ["Huang", "Yen-Chang", ""], ["Ken", "Tan Lit", ""]]}, {"id": "1805.08704", "submitter": "Tian Han", "authors": "Tian Han, Jiawen Wu, and Ying Nian Wu", "title": "Replicating Active Appearance Model by Generator Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent Cell paper [Chang and Tsao, 2017] reports an interesting discovery.\nFor the face stimuli generated by a pre-trained active appearance model (AAM),\nthe responses of neurons in the areas of the primate brain that are responsible\nfor face recognition exhibit strong linear relationship with the shape\nvariables and appearance variables of the AAM that generates the face stimuli.\nIn this paper, we show that this behavior can be replicated by a deep\ngenerative model called the generator network, which assumes that the observed\nsignals are generated by latent random variables via a top-down convolutional\nneural network. Specifically, we learn the generator network from the face\nimages generated by a pre-trained AAM model using variational auto-encoder, and\nwe show that the inferred latent variables of the learned generator network\nhave strong linear relationship with the shape and appearance variables of the\nAAM model that generates the face images. Unlike the AAM model that has an\nexplicit shape model where the shape variables generate the control points or\nlandmarks, the generator network has no such shape model and shape variables.\nYet the generator network can learn the shape knowledge in the sense that some\nof the latent variables of the learned generator network capture the shape\nvariations in the face images generated by AAM.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 04:54:00 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Han", "Tian", ""], ["Wu", "Jiawen", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1805.08709", "submitter": "Emin Orhan", "authors": "A. Emin Orhan", "title": "A Simple Cache Model for Image Recognition", "comments": "Published as a conference paper at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large-scale image recognition models is computationally expensive.\nThis raises the question of whether there might be simple ways to improve the\ntest performance of an already trained model without having to re-train or\nfine-tune it with new data. Here, we show that, surprisingly, this is indeed\npossible. The key observation we make is that the layers of a deep network\nclose to the output layer contain independent, easily extractable\nclass-relevant information that is not contained in the output layer itself. We\npropose to extract this extra class-relevant information using a simple\nkey-value cache memory to improve the classification performance of the model\nat test time. Our cache memory is directly inspired by a similar cache model\npreviously proposed for language modeling (Grave et al., 2017). This cache\ncomponent does not require any training or fine-tuning; it can be applied to\nany pre-trained model and, by properly setting only two hyper-parameters, leads\nto significant improvements in its classification performance. Improvements are\nobserved across several architectures and datasets. In the cache component,\nusing features extracted from layers close to the output (but not from the\noutput layer itself) as keys leads to the largest improvements. Concatenating\nfeatures from multiple layers to form keys can further improve performance over\nusing single-layer features as keys. The cache component also has a\nregularizing effect, a simple consequence of which is that it substantially\nincreases the robustness of models against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:50:14 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 18:24:18 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Orhan", "A. Emin", ""]]}, {"id": "1805.08719", "submitter": "Mingyuan Zhou", "authors": "Mingyuan Zhou", "title": "Parsimonious Bayesian deep networks", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining Bayesian nonparametrics and a forward model selection strategy, we\nconstruct parsimonious Bayesian deep networks (PBDNs) that infer\ncapacity-regularized network architectures from the data and require neither\ncross-validation nor fine-tuning when training the model. One of the two\nessential components of a PBDN is the development of a special infinite-wide\nsingle-hidden-layer neural network, whose number of active hidden units can be\ninferred from the data. The other one is the construction of a greedy\nlayer-wise learning algorithm that uses a forward model selection criterion to\ndetermine when to stop adding another hidden layer. We develop both Gibbs\nsampling and stochastic gradient descent based maximum a posteriori inference\nfor PBDNs, providing state-of-the-art classification accuracy and interpretable\ndata subtypes near the decision boundaries, while maintaining low computational\ncomplexity for out-of-sample prediction.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:26:42 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 15:11:43 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 00:45:05 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhou", "Mingyuan", ""]]}, {"id": "1805.08720", "submitter": "Ugo Tanielian", "authors": "Ugo Tanielian, Mike Gartrell, Flavian Vasile", "title": "Adversarial Training of Word2Vec for Basket Completion", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the Word2Vec model trained with the Negative Sampling loss\nfunction has shown state-of-the-art results in a number of machine learning\ntasks, including language modeling tasks, such as word analogy and word\nsimilarity, and in recommendation tasks, through Prod2Vec, an extension that\napplies to modeling user shopping activity and user preferences. Several\nmethods that aim to improve upon the standard Negative Sampling loss have been\nproposed. In our paper we pursue more sophisticated Negative Sampling, by\nleveraging ideas from the field of Generative Adversarial Networks (GANs), and\npropose Adversarial Negative Sampling. We build upon the recent progress made\nin stabilizing the training objective of GANs in the discrete data setting, and\nintroduce a new GAN-Word2Vec model.We evaluate our model on the task of basket\ncompletion, and show significant improvements in performance over Word2Vec\ntrained using standard loss functions, including Noise Contrastive Estimation\nand Negative Sampling.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:26:50 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Tanielian", "Ugo", ""], ["Gartrell", "Mike", ""], ["Vasile", "Flavian", ""]]}, {"id": "1805.08727", "submitter": "Ningshan Zhang", "authors": "Judy Hoffman, Mehryar Mohri, Ningshan Zhang", "title": "Algorithms and Theory for Multiple-Source Adaptation", "comments": "arXiv admin note: text overlap with arXiv:1711.05037", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work includes a number of novel contributions for the multiple-source\nadaptation problem. We present new normalized solutions with strong theoretical\nguarantees for the cross-entropy loss and other similar losses. We also provide\nnew guarantees that hold in the case where the conditional probabilities for\nthe source domains are distinct. Moreover, we give new algorithms for\ndetermining the distribution-weighted combination solution for the\ncross-entropy loss and other losses. We report the results of a series of\nexperiments with real-world datasets. We find that our algorithm outperforms\ncompeting approaches by producing a single robust model that performs well on\nany target mixture distribution. Altogether, our theory, algorithms, and\nempirical results provide a full solution for the multiple-source adaptation\nproblem with very practical benefits.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 03:26:48 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Hoffman", "Judy", ""], ["Mohri", "Mehryar", ""], ["Zhang", "Ningshan", ""]]}, {"id": "1805.08728", "submitter": "Soumyadip Ghosh", "authors": "Soumyadip Ghosh, Mark Squillante and Ebisa Wollega", "title": "Efficient Stochastic Gradient Descent for Learning with Distributionally\n  Robust Optimization", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributionally robust optimization (DRO) problems are increasingly seen as\na viable method to train machine learning models for improved model\ngeneralization. These min-max formulations, however, are more difficult to\nsolve. We therefore provide a new stochastic gradient descent algorithm to\nefficiently solve this DRO formulation. Our approach applies gradient descent\nto the outer minimization formulation and estimates the gradient of the inner\nmaximization based on a sample average approximation. The latter uses a subset\nof the data in each iteration, progressively increasing the subset size to\nensure convergence. Theoretical results include establishing the optimal manner\nfor growing the support size to balance a fundamental tradeoff between\nstochastic error and computational effort. Empirical results demonstrate the\nsignificant benefits of our approach over previous work, and also illustrate\nhow learning with DRO can improve generalization.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:38:41 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 14:41:30 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ghosh", "Soumyadip", ""], ["Squillante", "Mark", ""], ["Wollega", "Ebisa", ""]]}, {"id": "1805.08736", "submitter": "Kevin Roth", "authors": "Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, Thomas Hofmann", "title": "Adversarially Robust Training through Structured Gradient Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data-dependent structured gradient regularizer to increase\nthe robustness of neural networks vis-a-vis adversarial perturbations. Our\nregularizer can be derived as a controlled approximation from first principles,\nleveraging the fundamental link between training with noise and regularization.\nIt adds very little computational overhead during learning and is simple to\nimplement generically in standard deep learning frameworks. Our experiments\nprovide strong evidence that structured gradient regularization can act as an\neffective first line of defense against attacks based on low-level signal\ncorruption.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:47:46 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Roth", "Kevin", ""], ["Lucchi", "Aurelien", ""], ["Nowozin", "Sebastian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1805.08743", "submitter": "Alexandros Kouris", "authors": "Alexandros Kouris, Stylianos I. Venieris, Christos-Savvas Bouganis", "title": "CascadeCNN: Pushing the performance limits of quantisation", "comments": "Accepted at SysML Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CascadeCNN, an automated toolflow that pushes the\nquantisation limits of any given CNN model, to perform high-throughput\ninference by exploiting the computation time-accuracy trade-off. Without the\nneed for retraining, a two-stage architecture tailored for any given FPGA\ndevice is generated, consisting of a low- and a high-precision unit. A\nconfidence evaluation unit is employed between them to identify misclassified\ncases at run time and forward them to the high-precision unit or terminate\ncomputation. Experiments demonstrate that CascadeCNN achieves a performance\nboost of up to 55% for VGG-16 and 48% for AlexNet over the baseline design for\nthe same resource budget and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:06:02 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Kouris", "Alexandros", ""], ["Venieris", "Stylianos I.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1805.08749", "submitter": "Vasileios Charisopoulos", "authors": "Vasileios Charisopoulos, Petros Maragos", "title": "A Tropical Approach to Neural Networks with Piecewise Linear Activations", "comments": "v2: Removed morphological perceptron section and added vertex\n  sampling section. Updated references. 18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, unifying approach following some recent developments on the\ncomplexity of neural networks with piecewise linear activations. We treat\nneural network layers with piecewise linear activations as tropical\npolynomials, which generalize polynomials in the so-called $(\\max, +)$ or\ntropical algebra, with possibly real-valued exponents. Motivated by the\ndiscussion in (arXiv:1402.1869), this approach enables us to refine their upper\nbounds on linear regions of layers with ReLU or leaky ReLU activations to\n$\\min\\left\\{ 2^m, \\sum_{j=0}^n \\binom{m}{j} \\right\\}$, where $n, m$ are the\nnumber of inputs and outputs, respectively. Additionally, we recover their\nupper bounds on maxout layers. Our work follows a novel path, exclusively under\nthe lens of tropical geometry, which is independent of the improvements\nreported in (arXiv:1611.01491, arXiv:1711.02114). Finally, we present a\ngeometric approach for effective counting of linear regions using random\nsampling in order to avoid the computational overhead of exact counting\napproaches\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:20:51 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 17:31:11 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Maragos", "Petros", ""]]}, {"id": "1805.08768", "submitter": "Felix Sattler", "authors": "Felix Sattler, Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Sparse Binary Compression: Towards Distributed Deep Learning with\n  minimal Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, progressively larger deep neural networks are trained on ever\ngrowing data corpora. As this trend is only going to increase in the future,\ndistributed training schemes are becoming increasingly relevant. A major issue\nin distributed training is the limited communication bandwidth between\ncontributing nodes or prohibitive communication cost in general. These\nchallenges become even more pressing, as the number of computation nodes\nincreases. To counteract this development we propose sparse binary compression\n(SBC), a compression framework that allows for a drastic reduction of\ncommunication cost for distributed training. SBC combines existing techniques\nof communication delay and gradient sparsification with a novel binarization\nmethod and optimal weight update encoding to push compression gains to new\nlimits. By doing so, our method also allows us to smoothly trade-off gradient\nsparsity and temporal sparsity to adapt to the requirements of the learning\ntask. Our experiments show, that SBC can reduce the upstream communication on a\nvariety of convolutional and recurrent neural network architectures by more\nthan four orders of magnitude without significantly harming the convergence\nspeed in terms of forward-backward passes. For instance, we can train ResNet50\non ImageNet in the same number of iterations to the baseline accuracy, using\n$\\times 3531$ less bits or train it to a $1\\%$ lower accuracy using $\\times\n37208$ less bits. In the latter case, the total upstream communication required\nis cut from 125 terabytes to 3.35 gigabytes for every participating client.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:54:13 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Sattler", "Felix", ""], ["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1805.08776", "submitter": "Arbaaz Khan", "authors": "Arbaaz Khan, Clark Zhang, Daniel D. Lee, Vijay Kumar, Alejandro\n  Ribeiro", "title": "Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore using deep reinforcement learning for problems with\nmultiple agents. Most existing methods for deep multi-agent reinforcement\nlearning consider only a small number of agents. When the number of agents\nincreases, the dimensionality of the input and control spaces increase as well,\nand these methods do not scale well. To address this, we propose casting the\nmulti-agent reinforcement learning problem as a distributed optimization\nproblem. Our algorithm assumes that for multi-agent settings, policies of\nindividual agents in a given population live close to each other in parameter\nspace and can be approximated by a single policy. With this simple assumption,\nwe show our algorithm to be extremely effective for reinforcement learning in\nmulti-agent settings. We demonstrate its effectiveness against existing\ncomparable approaches on co-operative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:31:03 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Khan", "Arbaaz", ""], ["Zhang", "Clark", ""], ["Lee", "Daniel D.", ""], ["Kumar", "Vijay", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1805.08786", "submitter": "Mirco Milletar\\`i", "authors": "Mirco Milletar\\'i, Thiparat Chotibut, Paolo E. Trevisanutto", "title": "Mean Field Theory of Activation Functions in Deep Neural Networks", "comments": "Presented at the ICML 2019 Workshop on Theoretical Physics forDeep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Statistical Mechanics (SM) model of deep neural networks,\nconnecting the energy-based and the feed forward networks (FFN) approach. We\ninfer that FFN can be understood as performing three basic steps: encoding,\nrepresentation validation and propagation. From the meanfield solution of the\nmodel, we obtain a set of natural activations -- such as Sigmoid, $\\tanh$ and\nReLu -- together with the state-of-the-art, Swish; this represents the expected\ninformation propagating through the network and tends to ReLu in the limit of\nzero noise.We study the spectrum of the Hessian on an associated classification\ntask, showing that Swish allows for more consistent performances over a wider\nrange of network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 18:00:02 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 03:33:45 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Milletar\u00ed", "Mirco", ""], ["Chotibut", "Thiparat", ""], ["Trevisanutto", "Paolo E.", ""]]}, {"id": "1805.08808", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Rongmei Lin, Alan Sullivan", "title": "Deformable Part Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose novel Deformable Part Networks (DPNs) to learn {\\em\npose-invariant} representations for 2D object recognition. In contrast to the\nstate-of-the-art pose-aware networks such as CapsNet \\cite{sabour2017dynamic}\nand STN \\cite{jaderberg2015spatial}, DPNs can be naturally {\\em interpreted} as\nan efficient solver for a challenging detection problem, namely Localized\nDeformable Part Models (LDPMs) where localization is introduced to DPMs as\nanother latent variable for searching for the best poses of objects over all\npixels and (predefined) scales. In particular we construct DPNs as sequences of\nsuch LDPM units to model the semantic and spatial relations among the\ndeformable parts as hierarchical composition and spatial parsing trees.\nEmpirically our 17-layer DPN can outperform both CapsNets and STNs\nsignificantly on affNIST \\cite{sabour2017dynamic}, for instance, by 19.19\\% and\n12.75\\%, respectively, with better generalization and better tolerance to\naffine transformations.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 18:35:28 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Zhang", "Ziming", ""], ["Lin", "Rongmei", ""], ["Sullivan", "Alan", ""]]}, {"id": "1805.08809", "submitter": "Alex Lambert", "authors": "Romain Brault, Alex Lambert, Zolt\\'an Szab\\'o, Maxime Sangnier,\n  Florence d'Alch\\'e-Buc", "title": "Infinite-Task Learning with RKHSs", "comments": "23 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has witnessed tremendous success in solving tasks depending\non a single hyperparameter. When considering simultaneously a finite number of\ntasks, multi-task learning enables one to account for the similarities of the\ntasks via appropriate regularizers. A step further consists of learning a\ncontinuum of tasks for various loss functions. A promising approach, called\n\\emph{Parametric Task Learning}, has paved the way in the continuum setting for\naffine models and piecewise-linear loss functions. In this work, we introduce a\nnovel approach called \\emph{Infinite Task Learning} whose goal is to learn a\nfunction whose output is a function over the hyperparameter space. We leverage\ntools from operator-valued kernels and the associated vector-valued RKHSs that\nprovide an explicit control over the role of the hyperparameters, and also\nallows us to consider new type of constraints. We provide generalization\nguarantees to the suggested scheme and illustrate its efficiency in\ncost-sensitive classification, quantile regression and density level set\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 18:38:59 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 15:45:48 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 09:35:12 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Brault", "Romain", ""], ["Lambert", "Alex", ""], ["Szab\u00f3", "Zolt\u00e1n", ""], ["Sangnier", "Maxime", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1805.08833", "submitter": "Hamid Tizhoosh", "authors": "Meghana Dinesh Kumar, Morteza Babaie, Hamid Tizhoosh", "title": "Deep Barcodes for Fast Retrieval of Histopathology Scans", "comments": "Accepted for publication in proceedings of the IEEE World Congress on\n  Computational Intelligence (IEEE WCCI), Rio de Janeiro, Brazil, 8-3 July,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the concept of deep barcodes and propose two methods to\ngenerate them in order to expedite the process of classification and retrieval\nof histopathology images. Since binary search is computationally less\nexpensive, in terms of both speed and storage, deep barcodes could be useful\nwhen dealing with big data retrieval. Our experiments use the dataset Kimia\nPath24 to test three pre-trained networks for image retrieval. The dataset\nconsists of 27,055 training images in 24 different classes with large\nvariability, and 1,325 test images for testing. Apart from the high-speed and\nefficiency, results show a surprising retrieval accuracy of 71.62% for deep\nbarcodes, as compared to 68.91% for deep features and 68.53% for compressed\ndeep features.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 23:27:29 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kumar", "Meghana Dinesh", ""], ["Babaie", "Morteza", ""], ["Tizhoosh", "Hamid", ""]]}, {"id": "1805.08837", "submitter": "Alessandro Luongo", "authors": "Iordanis Kerenidis, Alessandro Luongo", "title": "Quantum classification of the MNIST dataset with Slow Feature Analysis", "comments": "Ameliorated details and plots", "journal-ref": "Phys. Rev. A 101, 062327 (2020)", "doi": "10.1103/PhysRevA.101.062327", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantum machine learning carries the promise to revolutionize information and\ncommunication technologies. While a number of quantum algorithms with potential\nexponential speedups have been proposed already, it is quite difficult to\nprovide convincing evidence that quantum computers with quantum memories will\nbe in fact useful to solve real-world problems. Our work makes considerable\nprogress towards this goal.\n  We design quantum techniques for Dimensionality Reduction and for\nClassification, and combine them to provide an efficient and high accuracy\nquantum classifier that we test on the MNIST dataset. More precisely, we\npropose a quantum version of Slow Feature Analysis (QSFA), a dimensionality\nreduction technique that maps the dataset in a lower dimensional space where we\ncan apply a novel quantum classification procedure, the Quantum Frobenius\nDistance (QFD). We simulate the quantum classifier (including errors) and show\nthat it can provide classification of the MNIST handwritten digit dataset, a\nwidely used dataset for benchmarking classification algorithms, with $98.5\\%$\naccuracy, similar to the classical case. The running time of the quantum\nclassifier is polylogarithmic in the dimension and number of data points. We\nalso provide evidence that the other parameters on which the running time\ndepends (condition number, Frobenius norm, error threshold, etc.) scale\nfavorably in practice, thus ascertaining the efficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 19:56:37 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 09:03:04 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 01:18:41 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Luongo", "Alessandro", ""]]}, {"id": "1805.08838", "submitter": "Shai Ben-David", "authors": "Shai Ben-David", "title": "Clustering - What Both Theoreticians and Practitioners are Doing Wrong", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning is widely recognized as one of the most important\nchallenges facing machine learning nowa- days. However, in spite of hundreds of\npapers on the topic being published every year, current theoretical\nunderstanding and practical implementations of such tasks, in particular of\nclustering, is very rudimentary. This note focuses on clustering. I claim that\nthe most signif- icant challenge for clustering is model selection. In contrast\nwith other common computational tasks, for clustering, dif- ferent algorithms\noften yield drastically different outcomes. Therefore, the choice of a\nclustering algorithm, and their pa- rameters (like the number of clusters) may\nplay a crucial role in the usefulness of an output clustering solution.\nHowever, currently there exists no methodical guidance for clustering\ntool-selection for a given clustering task. Practitioners pick the algorithms\nthey use without awareness to the implications of their choices and the vast\nmajority of theory of clustering papers focus on providing savings to the\nresources needed to solve optimization problems that arise from picking some\nconcrete clustering objective. Saving that pale in com- parison to the costs of\nmismatch between those objectives and the intended use of clustering results. I\nargue the severity of this problem and describe some recent proposals aiming to\naddress this crucial lacuna.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 19:59:06 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Ben-David", "Shai", ""]]}, {"id": "1805.08841", "submitter": "Sina Honari", "authors": "Joseph Paul Cohen, Margaux Luck, Sina Honari", "title": "Distribution Matching Losses Can Hallucinate Features in Medical Image\n  Translation", "comments": "Published at Medical Image Computing & Computer Assisted Intervention\n  (MICCAI 2018). An abstract is published at the Medical Imaging with Deep\n  Learning Conference (MIDL 2018) as \"How to Cure Cancer (in images) with\n  Unpaired Image Translation\"", "journal-ref": "Medical Image Computing & Computer Assisted Intervention (MICCAI\n  2018 Oral)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses how distribution matching losses, such as those used in\nCycleGAN, when used to synthesize medical images can lead to mis-diagnosis of\nmedical conditions. It seems appealing to use these new image synthesis methods\nfor translating images from a source to a target domain because they can\nproduce high quality images and some even do not require paired data. However,\nthe basis of how these image translation models work is through matching the\ntranslation output to the distribution of the target domain. This can cause an\nissue when the data provided in the target domain has an over or under\nrepresentation of some classes (e.g. healthy or sick). When the output of an\nalgorithm is a transformed image there are uncertainties whether all known and\nunknown class labels have been preserved or changed. Therefore, we recommend\nthat these translated images should not be used for direct interpretation (e.g.\nby doctors) because they may lead to misdiagnosis of patients based on\nhallucinated image features by an algorithm that matches a distribution.\nHowever there are many recent papers that seem as though this is the goal.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 20:06:33 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 22:36:57 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 05:44:12 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Luck", "Margaux", ""], ["Honari", "Sina", ""]]}, {"id": "1805.08845", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Motonobu Kanagawa, Sorawit Saengkyongam, Sanparith\n  Marukatat", "title": "Counterfactual Mean Embeddings", "comments": "71 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual inference has become a ubiquitous tool in online\nadvertisement, recommendation systems, medical diagnosis, and econometrics.\nAccurate modeling of outcome distributions associated with different\ninterventions -- known as counterfactual distributions -- is crucial for the\nsuccess of these applications. In this work, we propose to model counterfactual\ndistributions using a novel Hilbert space representation called counterfactual\nmean embedding (CME). The CME embeds the associated counterfactual distribution\ninto a reproducing kernel Hilbert space (RKHS) endowed with a positive definite\nkernel, which allows us to perform causal inference over the entire landscape\nof the counterfactual distribution. Based on this representation, we propose a\ndistributional treatment effect (DTE) that can quantify the causal effect over\nentire outcome distributions. Our approach is nonparametric as the CME can be\nestimated under the unconfoundedness assumption from observational data without\nrequiring any parametric assumption about the underlying distributions. We also\nestablish a rate of convergence of the proposed estimator which depends on the\nsmoothness of the conditional mean and the Radon-Nikodym derivative of the\nunderlying marginal distributions. Furthermore, our framework allows for more\ncomplex outcomes such as images, sequences, and graphs. Our experimental\nresults on synthetic data and off-policy evaluation tasks demonstrate the\nadvantages of the proposed estimator.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 20:12:05 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 21:54:46 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 19:49:12 GMT"}, {"version": "v4", "created": "Sat, 10 Jul 2021 18:58:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Muandet", "Krikamol", ""], ["Kanagawa", "Motonobu", ""], ["Saengkyongam", "Sorawit", ""], ["Marukatat", "Sanparith", ""]]}, {"id": "1805.08855", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel, Wen Huang, Paul Hand, and Vladislav Voroninski", "title": "Rate-Optimal Denoising with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks provide state-of-the-art performance for image\ndenoising, where the goal is to recover a near noise-free image from a noisy\nobservation. The underlying principle is that neural networks trained on large\ndatasets have empirically been shown to be able to generate natural images well\nfrom a low-dimensional latent representation of the image. Given such a\ngenerator network, a noisy image can be denoised by i) finding the closest\nimage in the range of the generator or by ii) passing it through an\nencoder-generator architecture (known as an autoencoder). However, there is\nlittle theory to justify this success, let alone to predict the denoising\nperformance as a function of the network parameters. In this paper we consider\nthe problem of denoising an image from additive Gaussian noise using the two\ngenerator based approaches. In both cases, we assume the image is well\ndescribed by a deep neural network with ReLU activations functions, mapping a\n$k$-dimensional code to an $n$-dimensional image. In the case of the\nautoencoder, we show that the feedforward network reduces noise energy by a\nfactor of $O(k/n)$. In the case of optimizing over the range of a generative\nmodel, we state and analyze a simple gradient algorithm that minimizes a\nnon-convex loss function, and provably reduces noise energy by a factor of\n$O(k/n)$. We also demonstrate in numerical experiments that this denoising\nperformance is, indeed, achieved by generative priors learned from data.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 20:33:52 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 15:48:53 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Heckel", "Reinhard", ""], ["Huang", "Wen", ""], ["Hand", "Paul", ""], ["Voroninski", "Vladislav", ""]]}, {"id": "1805.08877", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie and Bert Huang", "title": "Adversarial Label Learning", "comments": "Accepted at AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of training classifiers without labels. We propose a\nweakly supervised method---adversarial label learning---that trains classifiers\nto perform well against an adversary that chooses labels for training data. The\nweak supervision constrains what labels the adversary can choose. The method\ntherefore minimizes an upper bound of the classifier's error rate using\nprojected primal-dual subgradient descent. Minimizing this bound protects\nagainst bias and dependencies in the weak supervision. Experiments on three\nreal datasets show that our method can train without labels and outperforms\nother approaches for weakly supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:41:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 22:15:08 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 20:47:00 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Arachie", "Chidubem", ""], ["Huang", "Bert", ""]]}, {"id": "1805.08878", "submitter": "Narendra Patwardhan", "authors": "Narendra Patwardhan, Madhura Ingalhalikar, Rahee Walambe", "title": "ARiA: Utilizing Richard's Curve for Controlling the Non-monotonicity of\n  the Activation Function in Deep Neural Nets", "comments": "Modified version Submitted to ECCV '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel activation unit that can be efficiently employed\nin deep neural nets (DNNs) and performs significantly better than the\ntraditional Rectified Linear Units (ReLU). The function developed is a two\nparameter version of the specialized Richard's Curve and we call it Adaptive\nRichard's Curve weighted Activation (ARiA). This function is non-monotonous,\nanalogous to the newly introduced Swish, however allows a precise control over\nits non-monotonous convexity by varying the hyper-parameters. We first\ndemonstrate the mathematical significance of the two parameter ARiA followed by\nits application to benchmark problems such as MNIST, CIFAR-10 and CIFAR-100,\nwhere we compare the performance with ReLU and Swish units. Our results\nillustrate a significantly superior performance on all these datasets, making\nARiA a potential replacement for ReLU and other activations in DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:46:08 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Patwardhan", "Narendra", ""], ["Ingalhalikar", "Madhura", ""], ["Walambe", "Rahee", ""]]}, {"id": "1805.08882", "submitter": "Adam Gleave", "authors": "Adam Gleave and Oliver Habryka", "title": "Multi-task Maximum Entropy Inverse Reinforcement Learning", "comments": "Presented at 1st Workshop on Goal Specifications for Reinforcement\n  Learning (ICML/IJCAI/AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task Inverse Reinforcement Learning (IRL) is the problem of inferring\nmultiple reward functions from expert demonstrations. Prior work, built on\nBayesian IRL, is unable to scale to complex environments due to computational\nconstraints. This paper contributes a formulation of multi-task IRL in the more\ncomputationally efficient Maximum Causal Entropy (MCE) IRL framework.\nExperiments show our approach can perform one-shot imitation learning in a\ngridworld environment that single-task IRL algorithms need hundreds of\ndemonstrations to solve. We outline preliminary work using meta-learning to\nextend our method to the function approximator setting of modern MCE IRL\nalgorithms. Evaluating on multi-task variants of common simulated robotics\nbenchmarks, we discover serious limitations of these IRL algorithms, and\nconclude with suggestions for further work.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:57:34 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2018 13:58:18 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Gleave", "Adam", ""], ["Habryka", "Oliver", ""]]}, {"id": "1805.08890", "submitter": "Kamil Nar", "authors": "Kamil Nar, S. Shankar Sastry", "title": "Step Size Matters in Deep Learning", "comments": "Advances in Neural Information Processing Systems (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network with the gradient descent algorithm gives rise to a\ndiscrete-time nonlinear dynamical system. Consequently, behaviors that are\ntypically observed in these systems emerge during training, such as convergence\nto an orbit but not to a fixed point or dependence of convergence on the\ninitialization. Step size of the algorithm plays a critical role in these\nbehaviors: it determines the subset of the local optima that the algorithm can\nconverge to, and it specifies the magnitude of the oscillations if the\nalgorithm converges to an orbit. To elucidate the effects of the step size on\ntraining of neural networks, we study the gradient descent algorithm as a\ndiscrete-time dynamical system, and by analyzing the Lyapunov stability of\ndifferent solutions, we show the relationship between the step size of the\nalgorithm and the solutions that can be obtained with this algorithm. The\nresults provide an explanation for several phenomena observed in practice,\nincluding the deterioration in the training error with increased depth, the\nhardness of estimating linear mappings with large singular values, and the\ndistinct performance of deep residual networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 22:35:50 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 06:10:32 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Nar", "Kamil", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1805.08899", "submitter": "Bojian Zheng", "authors": "Bojian Zheng, Abhishek Tiwari, Nandita Vijaykumar, Gennady Pekhimenko", "title": "Echo: Compiler-based GPU Memory Footprint Reduction for LSTM RNN\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Long-Short-Term-Memory Recurrent Neural Networks (LSTM RNNs) are a\npopular class of machine learning models for analyzing sequential data. Their\ntraining on modern GPUs, however, is limited by the GPU memory capacity. Our\nprofiling results of the LSTM RNN-based Neural Machine Translation (NMT) model\nreveal that feature maps of the attention and RNN layers form the memory\nbottleneck and runtime is unevenly distributed across different layers when\ntraining on GPUs. Based on these two observations, we propose to recompute the\nfeature maps rather than stashing them persistently in the GPU memory.\n  While the idea of feature map recomputation has been considered before,\nexisting solutions fail to deliver satisfactory footprint reduction, as they do\nnot address two key challenges. For each feature map recomputation to be\neffective and efficient, its effect on (1) the total memory footprint, and (2)\nthe total execution time has to be carefully estimated. To this end, we propose\n*Echo*, a new compiler-based optimization scheme that addresses the first\nchallenge with a practical mechanism that estimates the memory benefits of\nrecomputation over the entire computation graph, and the second challenge by\nnon-conservatively estimating the recomputation overhead leveraging layer\nspecifics. *Echo* reduces the GPU memory footprint automatically and\ntransparently without any changes required to the training source code, and is\neffective for models beyond LSTM RNNs.\n  We evaluate *Echo* on numerous state-of-the-art machine learning workloads on\nreal systems with modern GPUs and observe footprint reduction ratios of 1.89X\non average and 3.13X maximum. Such reduction can be converted into faster\ntraining with a larger batch size, savings in GPU energy consumption (e.g.,\ntraining with one GPU as fast as with four), and/or an increase in the maximum\nnumber of layers under the same GPU memory budget.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 23:01:25 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 06:11:50 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 00:34:17 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 03:26:15 GMT"}, {"version": "v5", "created": "Thu, 28 Nov 2019 22:34:49 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zheng", "Bojian", ""], ["Tiwari", "Abhishek", ""], ["Vijaykumar", "Nandita", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1805.08905", "submitter": "Tianle Ma", "authors": "Tianle Ma and Aidong Zhang", "title": "AffinityNet: semi-supervised few-shot learning for disease type\n  prediction", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has achieved great success in computer vision and many\nother fields, currently it does not work very well on patient genomic data with\nthe \"big p, small N\" problem (i.e., a relatively small number of samples with\nhigh-dimensional features). In order to make deep learning work with a small\namount of training data, we have to design new models that facilitate few-shot\nlearning. Here we present the Affinity Network Model (AffinityNet), a data\nefficient deep learning model that can learn from a limited number of training\nexamples and generalize well. The backbone of the AffinityNet model consists of\nstacked k-Nearest-Neighbor (kNN) attention pooling layers. The kNN attention\npooling layer is a generalization of the Graph Attention Model (GAM), and can\nbe applied to not only graphs but also any set of objects regardless of whether\na graph is given or not. As a new deep learning module, kNN attention pooling\nlayers can be plugged into any neural network model just like convolutional\nlayers. As a simple special case of kNN attention pooling layer, feature\nattention layer can directly select important features that are useful for\nclassification tasks. Experiments on both synthetic data and cancer genomic\ndata from TCGA projects show that our AffinityNet model has better\ngeneralization power than conventional neural network models with little\ntraining data. The code is freely available at\nhttps://github.com/BeautyOfWeb/AffinityNet .\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 23:22:18 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 22:14:06 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Ma", "Tianle", ""], ["Zhang", "Aidong", ""]]}, {"id": "1805.08913", "submitter": "Rui Shu", "authors": "Rui Shu, Hung H. Bui, Shengjia Zhao, Mykel J. Kochenderfer, Stefano\n  Ermon", "title": "Amortized Inference Regularization", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) is a popular model for density estimation\nand representation learning. Canonically, the variational principle suggests to\nprefer an expressive inference model so that the variational approximation is\naccurate. However, it is often overlooked that an overly-expressive inference\nmodel can be detrimental to the test set performance of both the amortized\nposterior approximator and, more importantly, the generative density estimator.\nIn this paper, we leverage the fact that VAEs rely on amortized inference and\npropose techniques for amortized inference regularization (AIR) that control\nthe smoothness of the inference model. We demonstrate that, by applying AIR, it\nis possible to improve VAE generalization on both inference and generative\nperformance. Our paper challenges the belief that amortized inference is simply\na mechanism for approximating maximum likelihood training and illustrates that\nregularization of the amortization family provides a new direction for\nunderstanding and improving generalization in VAEs.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 00:14:56 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:56:45 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Shu", "Rui", ""], ["Bui", "Hung H.", ""], ["Zhao", "Shengjia", ""], ["Kochenderfer", "Mykel J.", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.08916", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Mehran Khodabandeh, Greg Mori", "title": "Distribution Aware Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminative learning machines often need a large set of labeled samples\nfor training. Active learning (AL) settings assume that the learner has the\nfreedom to ask an oracle to label its desired samples. Traditional AL\nalgorithms heuristically choose query samples about which the current learner\nis uncertain. This strategy does not make good use of the structure of the\ndataset at hand and is prone to be misguided by outliers. To alleviate this\nproblem, we propose to distill the structural information into a probabilistic\ngenerative model which acts as a \\emph{teacher} in our model. The active\n\\emph{learner} uses this information effectively at each cycle of active\nlearning. The proposed method is generic and does not depend on the type of\nlearner and teacher. We then suggest a query criterion for active learning that\nis aware of distribution of data and is more robust against outliers. Our\nmethod can be combined readily with several other query criteria for active\nlearning. We provide the formulation and empirically show our idea via toy and\nreal examples.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 00:32:36 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Mehrjou", "Arash", ""], ["Khodabandeh", "Mehran", ""], ["Mori", "Greg", ""]]}, {"id": "1805.08920", "submitter": "Tianyang Li", "authors": "Tianyang Li, Anastasios Kyrillidis, Liu Liu, Constantine Caramanis", "title": "Approximate Newton-based statistical inference using only stochastic\n  gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel statistical inference framework for convex empirical risk\nminimization, using approximate stochastic Newton steps. The proposed algorithm\nis based on the notion of finite differences and allows the approximation of a\nHessian-vector product from first-order information. In theory, our method\nefficiently computes the statistical error covariance in $M$-estimation, both\nfor unregularized convex learning problems and high-dimensional LASSO\nregression, without using exact second order information, or resampling the\nentire data set. We also present a stochastic gradient sampling scheme for\nstatistical inference in non-i.i.d. time series analysis, where we sample\ncontiguous blocks of indices. In practice, we demonstrate the effectiveness of\nour framework on large-scale machine learning problems, that go even beyond\nconvexity: as a highlight, our work can be used to detect certain adversarial\nattacks on neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 01:07:47 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 15:23:47 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Li", "Tianyang", ""], ["Kyrillidis", "Anastasios", ""], ["Liu", "Liu", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1805.08930", "submitter": "Fang Liu", "authors": "Fang Liu, Zizhan Zheng and Ness Shroff", "title": "Analysis of Thompson Sampling for Graphical Bandits Without the Graphs", "comments": "Accepted by UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multi-armed bandit problems with graph feedback, in which the\ndecision maker is allowed to observe the neighboring actions of the chosen\naction, in a setting where the graph may vary over time and is never fully\nrevealed to the decision maker. We show that when the feedback graphs are\nundirected, the original Thompson Sampling achieves the optimal (within\nlogarithmic factors) regret $\\tilde{O}\\left(\\sqrt{\\beta_0(G)T}\\right)$ over\ntime horizon $T$, where $\\beta_0(G)$ is the average independence number of the\nlatent graphs. To the best of our knowledge, this is the first result showing\nthat the original Thompson Sampling is optimal for graphical bandits in the\nundirected setting. A slightly weaker regret bound of Thompson Sampling in the\ndirected setting is also presented. To fill this gap, we propose a variant of\nThompson Sampling, that attains the optimal regret in the directed setting\nwithin a logarithmic factor. Both algorithms can be implemented efficiently and\ndo not require the knowledge of the feedback graphs at any time.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 01:47:56 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Liu", "Fang", ""], ["Zheng", "Zizhan", ""], ["Shroff", "Ness", ""]]}, {"id": "1805.08939", "submitter": "Zhuoran Song", "authors": "Zhuoran Song, Ru Wang, Dongyu Ru, Hongru Huang, Zhenghao Peng, Jing\n  Ke, Xiaoyao Liang, Li Jiang", "title": "Approximate Random Dropout", "comments": "7 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training phases of Deep neural network~(DNN) consumes enormous processing\ntime and energy. Compression techniques utilizing the sparsity of DNNs can\neffectively accelerate the inference phase of DNNs. However, it can be hardly\nused in the training phase because the training phase involves dense\nmatrix-multiplication using General Purpose Computation on Graphics Processors\n(GPGPU), which endorse regular and structural data layout. In this paper, we\npropose the Approximate Random Dropout that replaces the conventional random\ndropout of neurons and synapses with a regular and predefined patterns to\neliminate the unnecessary computation and data access. To compensate the\npotential performance loss we develop a SGD-based Search Algorithm to produce\nthe distribution of dropout patterns. We prove our approach is statistically\nequivalent to the previous dropout method. Experiments results on MLP and LSTM\nusing well-known benchmarks show that the proposed Approximate Random Dropout\ncan reduce the training time by $20\\%$-$77\\%$ ($19\\%$-$60\\%$) when dropout rate\nis $0.3$-$0.7$ on MLP (LSTM) with marginal accuracy drop.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 02:34:00 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 08:01:45 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Song", "Zhuoran", ""], ["Wang", "Ru", ""], ["Ru", "Dongyu", ""], ["Huang", "Hongru", ""], ["Peng", "Zhenghao", ""], ["Ke", "Jing", ""], ["Liang", "Xiaoyao", ""], ["Jiang", "Li", ""]]}, {"id": "1805.08948", "submitter": "Maria Dimakopoulou", "authors": "Maria Dimakopoulou, Ian Osband, Benjamin Van Roy", "title": "Scalable Coordinated Exploration in Concurrent Reinforcement Learning", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a team of reinforcement learning agents that concurrently operate\nin a common environment, and we develop an approach to efficient coordinated\nexploration that is suitable for problems of practical scale. Our approach\nbuilds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value\nfunction learning (Osband et al., 2016). We demonstrate that, for simple\ntabular contexts, the approach is competitive with previously proposed tabular\nmodel learning methods (Dimakopoulou and Van Roy, 2018). With a\nhigher-dimensional problem and a neural network value function representation,\nthe approach learns quickly with far fewer agents than alternative exploration\nschemes.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 03:36:01 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 08:23:55 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Dimakopoulou", "Maria", ""], ["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1805.08952", "submitter": "Tsung-Han Lin", "authors": "Tsung-Han Lin and Ping Tak Peter Tang", "title": "Dictionary Learning by Dynamical Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dynamical neural network consists of a set of interconnected neurons that\ninteract over time continuously. It can exhibit computational properties in the\nsense that the dynamical system's evolution and/or limit points in the\nassociated state space can correspond to numerical solutions to certain\nmathematical optimization or learning problems. Such a computational system is\nparticularly attractive in that it can be mapped to a massively parallel\ncomputer architecture for power and throughput efficiency, especially if each\nneuron can rely solely on local information (i.e., local memory). Deriving\ngradients from the dynamical network's various states while conforming to this\nlast constraint, however, is challenging. We show that by combining ideas of\ntop-down feedback and contrastive learning, a dynamical network for solving the\nl1-minimizing dictionary learning problem can be constructed, and the true\ngradients for learning are provably computable by individual neurons. Using\nspiking neurons to construct our dynamical network, we present a learning\nprocess, its rigorous mathematical analysis, and numerical results on several\ndictionary learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 03:51:21 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lin", "Tsung-Han", ""], ["Tang", "Ping Tak Peter", ""]]}, {"id": "1805.08957", "submitter": "Bruno Lecouat", "authors": "Bruno Lecouat, Chuan-Sheng Foo, Houssam Zenati, Vijay R. Chandrasekhar", "title": "Semi-Supervised Learning with GANs: Revisiting Manifold Regularization", "comments": "Accepted paper", "journal-ref": "Workshop track - ICLR 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANS are powerful generative models that are able to model the manifold of\nnatural images. We leverage this property to perform manifold regularization by\napproximating the Laplacian norm using a Monte Carlo approximation that is\neasily computed with the GAN. When incorporated into the feature-matching GAN\nof Improved GAN, we achieve state-of-the-art results for GAN-based\nsemi-supervised learning on the CIFAR-10 dataset, with a method that is\nsignificantly easier to implement than competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 04:26:50 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lecouat", "Bruno", ""], ["Foo", "Chuan-Sheng", ""], ["Zenati", "Houssam", ""], ["Chandrasekhar", "Vijay R.", ""]]}, {"id": "1805.08958", "submitter": "Yu Zhu", "authors": "Yu Zhu, Junxiong Zhu, Jie Hou, Yongliang Li, Beidou Wang, Ziyu Guan,\n  Deng Cai", "title": "A Brand-level Ranking System with the Customized Attention-GRU Model", "comments": "7 pages, 6 figures, 3 tables. Published in IJCAI 2018. Make some\n  figures and tables more clear", "journal-ref": "International Joint Conferences on Artificial Intelligence, 2018:\n  3947-3953", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce websites like Taobao, brand is playing a more important role in\ninfluencing users' decision of click/purchase, partly because users are now\nattaching more importance to the quality of products and brand is an indicator\nof quality. However, existing ranking systems are not specifically designed to\nsatisfy this kind of demand. Some design tricks may partially alleviate this\nproblem, but still cannot provide satisfactory results or may create additional\ninteraction cost. In this paper, we design the first brand-level ranking system\nto address this problem. The key challenge of this system is how to\nsufficiently exploit users' rich behavior in e-commerce websites to rank the\nbrands. In our solution, we firstly conduct the feature engineering\nspecifically tailored for the personalized brand ranking problem and then rank\nthe brands by an adapted Attention-GRU model containing three important\nmodifications. Note that our proposed modifications can also apply to many\nother machine learning models on various tasks. We conduct a series of\nexperiments to evaluate the effectiveness of our proposed ranking model and\ntest the response to the brand-level ranking system from real users on a\nlarge-scale e-commerce platform, i.e. Taobao.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 04:30:48 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 10:59:42 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Zhu", "Yu", ""], ["Zhu", "Junxiong", ""], ["Hou", "Jie", ""], ["Li", "Yongliang", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Cai", "Deng", ""]]}, {"id": "1805.08966", "submitter": "Ramya Ramakrishnan", "authors": "Ramya Ramakrishnan, Ece Kamar, Debadeepta Dey, Julie Shah, Eric\n  Horvitz", "title": "Discovering Blind Spots in Reinforcement Learning", "comments": "To appear at AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained in simulation may make errors in the real world due to\nmismatches between training and execution environments. These mistakes can be\ndangerous and difficult to discover because the agent cannot predict them a\npriori. We propose using oracle feedback to learn a predictive model of these\nblind spots to reduce costly errors in real-world applications. We focus on\nblind spots in reinforcement learning (RL) that occur due to incomplete state\nrepresentation: The agent does not have the appropriate features to represent\nthe true state of the world and thus cannot distinguish among numerous states.\nWe formalize the problem of discovering blind spots in RL as a noisy supervised\nlearning problem with class imbalance. We learn models to predict blind spots\nin unseen regions of the state space by combining techniques for label\naggregation, calibration, and supervised learning. The models take into\nconsideration noise emerging from different forms of oracle feedback, including\ndemonstrations and corrections. We evaluate our approach on two domains and\nshow that it achieves higher predictive performance than baseline methods, and\nthat the learned model can be used to selectively query an oracle at execution\ntime to prevent errors. We also empirically analyze the biases of various\nfeedback types and how they influence the discovery of blind spots.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 05:30:17 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Ramakrishnan", "Ramya", ""], ["Kamar", "Ece", ""], ["Dey", "Debadeepta", ""], ["Shah", "Julie", ""], ["Horvitz", "Eric", ""]]}, {"id": "1805.08969", "submitter": "Pei Guo", "authors": "Pei Guo, Connor Anderson, Kolten Pearson, Ryan Farrell", "title": "Neural Network Interpretation via Fine Grained Textual Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current visualization based network interpretation methodssuffer from lacking\nsemantic-level information. In this paper, we introduce the novel task of\ninterpreting classification models using fine grained textual summarization.\nAlong with the label prediction, the network will generate a sentence\nexplaining its decision. Constructing a fully annotated dataset of filter|text\npairs is unrealistic because of image to filter response function complexity.\nWe instead propose a weakly-supervised learning algorithm leveraging\noff-the-shelf image caption annotations. Central to our algorithm is the\nfilter-level attribute probability density function (p.d.f.), learned as a\nconditional probability through Bayesian inference with the input image and its\nfeature map as latent variables. We show our algorithm faithfully reflects the\nfeatures learned by the model using rigorous applications like attribute based\nimage retrieval and unsupervised text grounding. We further show that the\ntextual summarization process can help in understanding network failure\npatterns and can provide clues for further improvements.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 05:54:15 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 18:32:52 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Guo", "Pei", ""], ["Anderson", "Connor", ""], ["Pearson", "Kolten", ""], ["Farrell", "Ryan", ""]]}, {"id": "1805.08970", "submitter": "Aydogan Ozcan", "authors": "Yair Rivenson and Aydogan Ozcan", "title": "Toward a Thinking Microscope: Deep Learning in Optical Microscopy and\n  Image Reconstruction", "comments": null, "journal-ref": "OPN (2018)", "doi": "10.1364/OPN.29.7.000034", "report-no": null, "categories": "cs.LG cs.CV physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss recently emerging applications of the state-of-art deep learning\nmethods on optical microscopy and microscopic image reconstruction, which\nenable new transformations among different modes and modalities of microscopic\nimaging, driven entirely by image data. We believe that deep learning will\nfundamentally change both the hardware and image reconstruction methods used in\noptical microscopy in a holistic manner.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 05:54:51 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Rivenson", "Yair", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1805.08974", "submitter": "Simon Kornblith", "authors": "Simon Kornblith, Jonathon Shlens, Quoc V. Le", "title": "Do Better ImageNet Models Transfer Better?", "comments": "CVPR 2019 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a cornerstone of computer vision, yet little work has\nbeen done to evaluate the relationship between architecture and transfer. An\nimplicit hypothesis in modern computer vision research is that models that\nperform better on ImageNet necessarily perform better on other vision tasks.\nHowever, this hypothesis has never been systematically tested. Here, we compare\nthe performance of 16 classification networks on 12 image classification\ndatasets. We find that, when networks are used as fixed feature extractors or\nfine-tuned, there is a strong correlation between ImageNet accuracy and\ntransfer accuracy ($r = 0.99$ and $0.96$, respectively). In the former setting,\nwe find that this relationship is very sensitive to the way in which networks\nare trained on ImageNet; many common forms of regularization slightly improve\nImageNet accuracy but yield penultimate layer features that are much worse for\ntransfer learning. Additionally, we find that, on two small fine-grained image\nclassification datasets, pretraining on ImageNet provides minimal benefits,\nindicating the learned features from ImageNet do not transfer well to\nfine-grained tasks. Together, our results show that ImageNet architectures\ngeneralize well across datasets, but ImageNet features are less general than\npreviously suggested.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 06:12:35 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 20:14:42 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 16:25:07 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kornblith", "Simon", ""], ["Shlens", "Jonathon", ""], ["Le", "Quoc V.", ""]]}, {"id": "1805.08975", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu and Wee Sun Lee", "title": "Particle Filter Networks with Application to Visual Localization", "comments": "CoRL 2018 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle filtering is a powerful approach to sequential state estimation and\nfinds application in many domains, including robot localization, object\ntracking, etc. To apply particle filtering in practice, a critical challenge is\nto construct probabilistic system models, especially for systems with complex\ndynamics or rich sensory inputs such as camera images. This paper introduces\nthe Particle Filter Network (PFnet), which encodes both a system model and a\nparticle filter algorithm in a single neural network. The PF-net is fully\ndifferentiable and trained end-to-end from data. Instead of learning a generic\nsystem model, it learns a model optimized for the particle filter algorithm. We\napply the PF-net to a visual localization task, in which a robot must localize\nin a rich 3-D world, using only a schematic 2-D floor map. In simulation\nexperiments, PF-net consistently outperforms alternative learning\narchitectures, as well as a traditional model-based method, under a variety of\nsensor inputs. Further, PF-net generalizes well to new, unseen environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 06:21:08 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 17:44:03 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 17:23:11 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1805.09001", "submitter": "Sizhong Lan", "authors": "Sizhong Lan", "title": "One-to-one Mapping between Stimulus and Neural State: Memory and\n  Classification", "comments": "8 pages, 15 figures, final for AIP Advances", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synaptic strength can be seen as probability to propagate impulse, and\naccording to synaptic plasticity, function could exist from propagation\nactivity to synaptic strength. If the function satisfies constraints such as\ncontinuity and monotonicity, neural network under external stimulus will always\ngo to fixed point, and there could be one-to-one mapping between external\nstimulus and synaptic strength at fixed point. In other words, neural network\n\"memorizes\" external stimulus in its synapses. A biological classifier is\nproposed to utilize this mapping.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 08:08:23 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 16:52:34 GMT"}, {"version": "v3", "created": "Sun, 19 Aug 2018 17:00:10 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 17:19:11 GMT"}, {"version": "v5", "created": "Tue, 8 Jan 2019 05:27:46 GMT"}, {"version": "v6", "created": "Wed, 24 Apr 2019 03:07:16 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Lan", "Sizhong", ""]]}, {"id": "1805.09023", "submitter": "Yu Zhu", "authors": "Yu Zhu, Jinhao Lin, Shibi He, Beidou Wang, Ziyu Guan, Haifeng Liu and\n  Deng Cai", "title": "Addressing the Item Cold-start Problem by Attribute-driven Active\n  Learning", "comments": "14 pages, 7 figures, 9 tables. Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recommender systems, cold-start issues are situations where no previous\nevents, e.g. ratings, are known for certain users or items. In this paper, we\nfocus on the item cold-start problem. Both content information (e.g. item\nattributes) and initial user ratings are valuable for seizing users'\npreferences on a new item. However, previous methods for the item cold-start\nproblem either 1) incorporate content information into collaborative filtering\nto perform hybrid recommendation, or 2) actively select users to rate the new\nitem without considering content information and then do collaborative\nfiltering. In this paper, we propose a novel recommendation scheme for the item\ncold-start problem by leverage both active learning and items' attribute\ninformation. Specifically, we design useful user selection criteria based on\nitems' attributes and users' rating history, and combine the criteria in an\noptimization framework for selecting users. By exploiting the feedback ratings,\nusers' previous ratings and items' attributes, we then generate accurate rating\npredictions for the other unselected users. Experimental results on two\nreal-world datasets show the superiority of our proposed method over\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 09:21:53 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Zhu", "Yu", ""], ["Lin", "Jinhao", ""], ["He", "Shibi", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Liu", "Haifeng", ""], ["Cai", "Deng", ""]]}, {"id": "1805.09039", "submitter": "Sotirios Chatzis", "authors": "Kyriacos Tolias, Ioannis Kourouklides, Sotirios Chatzis", "title": "Amortized Context Vector Inference for Sequence-to-Sequence Networks", "comments": "Submitted for Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural attention (NA) has become a key component of sequence-to-sequence\nmodels that yield state-of-the-art performance in as hard tasks as abstractive\ndocument summarization (ADS) and video captioning (VC). NA mechanisms perform\ninference of context vectors; these constitute weighted sums of deterministic\ninput sequence encodings, adaptively sourced over long temporal horizons.\nInspired from recent work in the field of amortized variational inference\n(AVI), in this work we consider treating the context vectors generated by\nsoft-attention (SA) models as latent variables, with approximate finite mixture\nmodel posteriors inferred via AVI. We posit that this formulation may yield\nstronger generalization capacity, in line with the outcomes of existing\napplications of AVI to deep networks. To illustrate our method, we implement it\nand experimentally evaluate it considering challenging ADS, VC, and MT\nbenchmarks. This way, we exhibit its improved effectiveness over\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 10:16:59 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 17:46:02 GMT"}, {"version": "v3", "created": "Sun, 3 Jun 2018 10:54:02 GMT"}, {"version": "v4", "created": "Sat, 9 Jun 2018 13:51:28 GMT"}, {"version": "v5", "created": "Fri, 15 Jun 2018 13:35:18 GMT"}, {"version": "v6", "created": "Wed, 26 Sep 2018 19:24:17 GMT"}, {"version": "v7", "created": "Sun, 23 Dec 2018 21:11:30 GMT"}, {"version": "v8", "created": "Tue, 1 Jan 2019 12:01:37 GMT"}, {"version": "v9", "created": "Fri, 4 Jan 2019 15:55:31 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Tolias", "Kyriacos", ""], ["Kourouklides", "Ioannis", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1805.09044", "submitter": "Yao Liu", "authors": "Yao Liu, Omer Gottesman, Aniruddh Raghu, Matthieu Komorowski, Aldo\n  Faisal, Finale Doshi-Velez, Emma Brunskill", "title": "Representation Balancing MDPs for Off-Policy Policy Evaluation", "comments": "appeared at NeurIPS 18; updated style file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy policy evaluation (OPPE) in RL. In\ncontrast to prior work, we consider how to estimate both the individual policy\nvalue and average policy value accurately. We draw inspiration from recent work\nin causal reasoning, and propose a new finite sample generalization error bound\nfor value estimates from MDP models. Using this upper bound as an objective, we\ndevelop a learning algorithm of an MDP model with a balanced representation,\nand show that our approach can yield substantially lower MSE in common\nsynthetic benchmarks and a HIV treatment simulation domain.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 10:43:16 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 00:53:09 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 05:21:47 GMT"}, {"version": "v4", "created": "Wed, 17 Apr 2019 19:54:27 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Yao", ""], ["Gottesman", "Omer", ""], ["Raghu", "Aniruddh", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo", ""], ["Doshi-Velez", "Finale", ""], ["Brunskill", "Emma", ""]]}, {"id": "1805.09045", "submitter": "Yao Liu", "authors": "Yao Liu, Emma Brunskill", "title": "When Simple Exploration is Sample Efficient: Identifying Sufficient\n  Conditions for Random Exploration to Yield PAC RL Algorithms", "comments": "Appeared in The 14th European Workshop on Reinforcement Learning\n  (EWRL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is one of the key challenges for reinforcement learning\n(RL) algorithms. Most traditional sample efficiency bounds require strategic\nexploration. Recently many deep RL algorithms with simple heuristic exploration\nstrategies that have few formal guarantees, achieve surprising success in many\ndomains. These results pose an important question about understanding these\nexploration strategies such as $e$-greedy, as well as understanding what\ncharacterize the difficulty of exploration in MDPs. In this work we propose\nproblem specific sample complexity bounds of $Q$ learning with random walk\nexploration that rely on several structural properties. We also link our\ntheoretical results to some empirical benchmark domains, to illustrate if our\nbound gives polynomial sample complexity in these domains and how that is\nrelated with the empirical performance.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 10:43:56 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 07:11:34 GMT"}, {"version": "v3", "created": "Sat, 4 Aug 2018 01:13:03 GMT"}, {"version": "v4", "created": "Wed, 17 Apr 2019 19:58:38 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Yao", ""], ["Brunskill", "Emma", ""]]}, {"id": "1805.09076", "submitter": "Alexander Gaunt", "authors": "Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, Alexander L. Gaunt", "title": "Constrained Graph Variational Autoencoders for Molecule Design", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are ubiquitous data structures for representing interactions between\nentities. With an emphasis on the use of graphs to represent chemical\nmolecules, we explore the task of learning to generate graphs that conform to a\ndistribution observed in training data. We propose a variational autoencoder\nmodel in which both encoder and decoder are graph-structured. Our decoder\nassumes a sequential ordering of graph extension steps and we discuss and\nanalyze design choices that mitigate the potential downsides of this\nlinearization. Experiments compare our approach with a wide range of baselines\non the molecule generation task and show that our method is more successful at\nmatching the statistics of the original dataset on semantically important\nmetrics. Furthermore, we show that by using appropriate shaping of the latent\nspace, our model allows us to design molecules that are (locally) optimal in\ndesired properties.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 12:01:44 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:51:05 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Liu", "Qi", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Gaunt", "Alexander L.", ""]]}, {"id": "1805.09091", "submitter": "Sebastian Lerch", "authors": "Stephan Rasp and Sebastian Lerch", "title": "Neural networks for post-processing ensemble weather forecasts", "comments": null, "journal-ref": "Monthly Weather Review 2018, 146, 3885-3900", "doi": "10.1175/MWR-D-18-0187.1", "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble weather predictions require statistical post-processing of\nsystematic errors to obtain reliable and accurate probabilistic forecasts.\nTraditionally, this is accomplished with distributional regression models in\nwhich the parameters of a predictive distribution are estimated from a training\nperiod. We propose a flexible alternative based on neural networks that can\nincorporate nonlinear relationships between arbitrary predictor variables and\nforecast distribution parameters that are automatically learned in a\ndata-driven way rather than requiring pre-specified link functions. In a case\nstudy of 2-meter temperature forecasts at surface stations in Germany, the\nneural network approach significantly outperforms benchmark post-processing\nmethods while being computationally more affordable. Key components to this\nimprovement are the use of auxiliary predictor variables and station-specific\ninformation with the help of embeddings. Furthermore, the trained neural\nnetwork can be used to gain insight into the importance of meteorological\nvariables thereby challenging the notion of neural networks as uninterpretable\nblack boxes. Our approach can easily be extended to other statistical\npost-processing and forecasting problems. We anticipate that recent advances in\ndeep learning combined with the ever-increasing amounts of model and\nobservation data will transform the post-processing of numerical weather\nforecasts in the coming decade.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 12:30:28 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Rasp", "Stephan", ""], ["Lerch", "Sebastian", ""]]}, {"id": "1805.09108", "submitter": "Luciano Melodia", "authors": "Luciano Melodia", "title": "Deep Learning Estimation of Absorbed Dose for Nuclear Medicine\n  Diagnostics", "comments": "Master Thesis", "journal-ref": "Lib.Univ.Rgbg 2018 (1-36)", "doi": "10.31219/osf.io/zp6nv", "report-no": null, "categories": "stat.ML cs.LG nucl-ex physics.med-ph stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of energy dose from Lu$^{177}$ radiotherapy can be estimated\nby convolving an image of a time-integrated activity distribution with a dose\nvoxel kernel (DVK) consisting of different types of tissues. This fast and\ninacurate approximation is inappropriate for personalized dosimetry as it\nneglects tissue heterogenity. The latter can be calculated using different\nimaging techniques such as CT and SPECT combined with a time consuming\nmonte-carlo simulation. The aim of this study is, for the first time, an\nestimation of DVKs from CT-derived density kernels (DK) via deep learning in\nconvolutional neural networks (CNNs). The proposed CNN achieved, on the test\nset, a mean intersection over union (IOU) of $= 0.86$ after $308$ epochs and a\ncorresponding mean squared error (MSE) $= 1.24 \\cdot 10^{-4}$. This\ngeneralization ability shows that the trained CNN can indeed learn the\ndifficult transfer function from DK to DVK. Future work will evaluate DVKs\nestimated by CNNs with full monte-carlo simulations of a whole body CT to\npredict patient specific voxel dose maps.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:54:00 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 11:45:48 GMT"}, {"version": "v3", "created": "Sun, 10 Jun 2018 12:45:11 GMT"}, {"version": "v4", "created": "Thu, 2 Jan 2020 10:26:13 GMT"}, {"version": "v5", "created": "Wed, 10 Jun 2020 11:59:14 GMT"}, {"version": "v6", "created": "Thu, 19 Nov 2020 14:02:22 GMT"}, {"version": "v7", "created": "Fri, 20 Nov 2020 09:40:38 GMT"}, {"version": "v8", "created": "Fri, 4 Dec 2020 14:37:57 GMT"}, {"version": "v9", "created": "Thu, 18 Mar 2021 12:59:38 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Melodia", "Luciano", ""]]}, {"id": "1805.09112", "submitter": "Octavian-Eugen Ganea", "authors": "Octavian-Eugen Ganea, Gary B\\'ecigneul, Thomas Hofmann", "title": "Hyperbolic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic spaces have recently gained momentum in the context of machine\nlearning due to their high capacity and tree-likeliness properties. However,\nthe representational power of hyperbolic geometry is not yet on par with\nEuclidean geometry, mostly because of the absence of corresponding hyperbolic\nneural network layers. This makes it hard to use hyperbolic embeddings in\ndownstream tasks. Here, we bridge this gap in a principled manner by combining\nthe formalism of M\\\"obius gyrovector spaces with the Riemannian geometry of the\nPoincar\\'e model of hyperbolic spaces. As a result, we derive hyperbolic\nversions of important deep learning tools: multinomial logistic regression,\nfeed-forward and recurrent neural networks such as gated recurrent units. This\nallows to embed sequential data and perform classification in the hyperbolic\nspace. Empirically, we show that, even if hyperbolic optimization tools are\nlimited, hyperbolic sentence embeddings either outperform or are on par with\ntheir Euclidean variants on textual entailment and noisy-prefix recognition\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:08:07 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 17:20:43 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Ganea", "Octavian-Eugen", ""], ["B\u00e9cigneul", "Gary", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1805.09114", "submitter": "Vayer Titouan", "authors": "Titouan Vayer, Laetitia Chapel, R\\'emi Flamary, Romain Tavenard,\n  Nicolas Courty", "title": "Optimal Transport for structured data with application on graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the problem of computing distances between structured\nobjects such as undirected graphs, seen as probability distributions in a\nspecific metric space. We consider a new transportation distance (i.e. that\nminimizes a total cost of transporting probability masses) that unveils the\ngeometric nature of the structured objects space. Unlike Wasserstein or\nGromov-Wasserstein metrics that focus solely and respectively on features (by\nconsidering a metric in the feature space) or structure (by seeing structure as\na metric space), our new distance exploits jointly both information, and is\nconsequently called Fused Gromov-Wasserstein (FGW). After discussing its\nproperties and computational aspects, we show results on a graph classification\ntask, where our method outperforms both graph kernels and deep graph\nconvolutional networks. Exploiting further on the metric properties of FGW,\ninteresting geometric objects such as Fr\\'echet means or barycenters of graphs\nare illustrated and discussed in a clustering context.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:13:27 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 09:59:17 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 15:44:06 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Vayer", "Titouan", ""], ["Chapel", "Laetitia", ""], ["Flamary", "R\u00e9mi", ""], ["Tavenard", "Romain", ""], ["Courty", "Nicolas", ""]]}, {"id": "1805.09122", "submitter": "Anton Mallasto", "authors": "Anton Mallasto, S{\\o}ren Hauberg and Aasa Feragen", "title": "Probabilistic Riemannian submanifold learning with wrapped Gaussian\n  process latent variable models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models (LVMs) learn probabilistic models of data manifolds\nlying in an \\emph{ambient} Euclidean space. In a number of applications, a\npriori known spatial constraints can shrink the ambient space into a\nconsiderably smaller manifold. Additionally, in these applications the\nEuclidean geometry might induce a suboptimal similarity measure, which could be\nimproved by choosing a different metric. Euclidean models ignore such\ninformation and assign probability mass to data points that can never appear as\ndata, and vastly different likelihoods to points that are similar under the\ndesired metric. We propose the wrapped Gaussian process latent variable model\n(WGPLVM), that extends Gaussian process latent variable models to take values\nstrictly on a given ambient Riemannian manifold, making the model blind to\nimpossible data points. This allows non-linear, probabilistic inference of\nlow-dimensional Riemannian submanifolds from data. Our evaluation on diverse\ndatasets show that we improve performance on several tasks, including encoding,\nvisualization and uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:22:08 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 14:58:51 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mallasto", "Anton", ""], ["Hauberg", "S\u00f8ren", ""], ["Feragen", "Aasa", ""]]}, {"id": "1805.09155", "submitter": "Umar Iqbal", "authors": "Umar Iqbal (1 and 2), Peter Snyder (2), Shitong Zhu (3), Benjamin\n  Livshits (2 and 4), Zhiyun Qian (3), and Zubair Shafiq (1) ((1) The\n  University of Iowa, (2) Brave Software, (3) University of California\n  Riverside, (4) Imperial College London)", "title": "AdGraph: A Graph-Based Approach to Ad and Tracker Blocking", "comments": "To appear in the Proceedings of the IEEE Symposium on Security &\n  Privacy, May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User demand for blocking advertising and tracking online is large and\ngrowing. Existing tools, both deployed and described in research, have proven\nuseful, but lack either the completeness or robustness needed for a general\nsolution. Existing detection approaches generally focus on only one aspect of\nadvertising or tracking (e.g. URL patterns, code structure), making existing\napproaches susceptible to evasion.\n  In this work we present AdGraph, a novel graph-based machine learning\napproach for detecting advertising and tracking resources on the web. AdGraph\ndiffers from existing approaches by building a graph representation of the HTML\nstructure, network requests, and JavaScript behavior of a webpage, and using\nthis unique representation to train a classifier for identifying advertising\nand tracking resources. Because AdGraph considers many aspects of the context a\nnetwork request takes place in, it is less susceptible to the single-factor\nevasion techniques that flummox existing approaches.\n  We evaluate AdGraph on the Alexa top-10K websites, and find that it is highly\naccurate, able to replicate the labels of human-generated filter lists with\n95.33% accuracy, and can even identify many mistakes in filter lists. We\nimplement AdGraph as a modification to Chromium. AdGraph adds only minor\noverhead to page loading and execution, and is actually faster than stock\nChromium on 42% of websites and AdBlock Plus on 78% of websites. Overall, we\nconclude that AdGraph is both accurate enough and performant enough for online\nuse, breaking comparable or fewer websites than popular filter list based\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:16:03 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:02:07 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Iqbal", "Umar", "", "1 and 2"], ["Snyder", "Peter", "", "2 and 4"], ["Zhu", "Shitong", "", "2 and 4"], ["Livshits", "Benjamin", "", "2 and 4"], ["Qian", "Zhiyun", ""], ["Shafiq", "Zubair", ""]]}, {"id": "1805.09156", "submitter": "Miao Xu", "authors": "Miao Xu, Gang Niu, Bo Han, Ivor W. Tsang, Zhi-Hua Zhou, Masashi\n  Sugiyama", "title": "Matrix Co-completion for Multi-label Classification with Missing\n  Features and Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a challenging multi-label classification problem where both\nfeature matrix $\\X$ and label matrix $\\Y$ have missing entries. An existing\nmethod concatenated $\\X$ and $\\Y$ as $[\\X; \\Y]$ and applied a matrix completion\n(MC) method to fill the missing entries, under the assumption that $[\\X; \\Y]$\nis of low-rank. However, since entries of $\\Y$ take binary values in the\nmulti-label setting, it is unlikely that $\\Y$ is of low-rank. Moreover, such\nassumption implies a linear relationship between $\\X$ and $\\Y$ which may not\nhold in practice. In this paper, we consider a latent matrix $\\Z$ that produces\nthe probability $\\sigma(Z_{ij})$ of generating label $Y_{ij}$, where\n$\\sigma(\\cdot)$ is nonlinear. Considering label correlation, we assume $[\\X;\n\\Z]$ is of low-rank, and propose an MC algorithm based on subgradient descent\nnamed co-completion (COCO) motivated by elastic net and one-bit MC. We give a\ntheoretical bound on the recovery effect of COCO and demonstrate its practical\nusefulness through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:39:29 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Xu", "Miao", ""], ["Niu", "Gang", ""], ["Han", "Bo", ""], ["Tsang", "Ivor W.", ""], ["Zhou", "Zhi-Hua", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1805.09174", "submitter": "Pierre Gaillard", "authors": "Pierre Gaillard (SIERRA), Olivier Wintenberger (LPSM UMR 8001)", "title": "Efficient online algorithms for fast-rate regret bounds under sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online convex optimization problem. In the setting of\narbitrary sequences and finite set of parameters, we establish a new fast-rate\nquantile regret bound. Then we investigate the optimization into the L1-ball by\ndiscretizing the parameter space. Our algorithm is projection free and we\npropose an efficient solution by restarting the algorithm on adaptive\ndiscretization grids. In the adversarial setting, we develop an algorithm that\nachieves several rates of convergence with different dependencies on the\nsparsity of the objective. In the i.i.d. setting, we establish new risk bounds\nthat are adaptive to the sparsity of the problem and to the regularity of the\nrisk (ranging from a rate 1 / $\\sqrt T$ for general convex risk to 1 /T for\nstrongly convex risk). These results generalize previous works on sparse online\nlearning. They are obtained under a weak assumption on the risk\n({\\L}ojasiewicz's assumption) that allows multiple optima which is crucial when\ndealing with degenerate situations.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:49:11 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Gaillard", "Pierre", "", "SIERRA"], ["Wintenberger", "Olivier", "", "LPSM UMR 8001"]]}, {"id": "1805.09180", "submitter": "Alejandro  Cholaquidis", "authors": "Alejandro Cholaquidis, Ricardo Fraiman and Mariela Sued", "title": "On semi-supervised learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.05673", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning deals with the problem of how, if possible, to take\nadvantage of a huge amount of unclassified data, to perform a classification in\nsituations when, typically, there is little labeled data. Even though this is\nnot always possible (it depends on how useful, for inferring the labels, it\nwould be to know the distribution of the unlabeled data), several algorithm\nhave been proposed recently. %but in general they are not proved to outperform\n  A new algorithm is proposed, that under almost necessary conditions, %and it\nis proved that it attains asymptotically the performance of the best\ntheoretical rule as the amount of unlabeled data tends to infinity. The set of\nnecessary assumptions, although reasonable, show that semi-supervised\nclassification only works for very well conditioned problems. The focus is on\nunderstanding when and why semi-supervised learning works when the size of the\ninitial training sample remains fixed and the asymptotic is on the size of the\nunlabeled data. The performance of the algorithm is assessed in the well known\n\"Isolet\" real-data of phonemes, where a strong dependence on the choice of the\ninitial training sample is shown.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:23:39 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 13:24:24 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 11:41:17 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cholaquidis", "Alejandro", ""], ["Fraiman", "Ricardo", ""], ["Sued", "Mariela", ""]]}, {"id": "1805.09208", "submitter": "G\\'abor Melis", "authors": "G\\'abor Melis, Charles Blundell, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Karl\n  Moritz Hermann, Chris Dyer, Phil Blunsom", "title": "Pushing the bounds of dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that dropout training is best understood as performing MAP estimation\nconcurrently for a family of conditional models whose objectives are themselves\nlower bounded by the original dropout objective. This discovery allows us to\npick any model from this family after training, which leads to a substantial\nimprovement on regularisation-heavy language modelling. The family includes\nmodels that compute a power mean over the sampled dropout masks, and their less\nstochastic subvariants with tighter and higher lower bounds than the fully\nstochastic dropout objective. We argue that since the deterministic\nsubvariant's bound is equal to its objective, and the highest amongst these\nmodels, the predominant view of it as a good approximation to MC averaging is\nmisleading. Rather, deterministic dropout is the best available approximation\nto the true objective.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:55:39 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 15:19:20 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Melis", "G\u00e1bor", ""], ["Blundell", "Charles", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Hermann", "Karl Moritz", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""]]}, {"id": "1805.09213", "submitter": "Kevin Bello", "authors": "Kevin Bello, Jean Honorio", "title": "Learning latent variable structured prediction models with Gaussian\n  perturbations", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS) 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard margin-based structured prediction commonly uses a maximum loss\nover all possible structured outputs. The large-margin formulation including\nlatent variables not only results in a non-convex formulation but also\nincreases the search space by a factor of the size of the latent space. Recent\nwork has proposed the use of the maximum loss over random structured outputs\nsampled independently from some proposal distribution, with theoretical\nguarantees. We extend this work by including latent variables. We study a new\nfamily of loss functions under Gaussian perturbations and analyze the effect of\nthe latent space on the generalization bounds. We show that the non-convexity\nof learning with latent variables originates naturally, as it relates to a\ntight upper bound of the Gibbs decoder distortion with respect to the latent\nspace. Finally, we provide a formulation using random samples that produces a\ntighter upper bound of the Gibbs decoder distortion up to a statistical\naccuracy, which enables a faster evaluation of the objective function. We\nillustrate the method with synthetic experiments and a computer vision\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:09:23 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Bello", "Kevin", ""], ["Honorio", "Jean", ""]]}, {"id": "1805.09214", "submitter": "Hadi Ghauch", "authors": "Hadi Ghauch, Hossein Shokri-Ghadikolaei, Carlo Fischione, Mikael\n  Skoglund", "title": "A Unified Framework for Training Neural Networks", "comments": "15 pages, submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of mathematical tractability of Deep Neural Networks (DNNs) has\nhindered progress towards having a unified convergence analysis of training\nalgorithms, in the general setting. We propose a unified optimization framework\nfor training different types of DNNs, and establish its convergence for\narbitrary loss, activation, and regularization functions, assumed to be smooth.\nWe show that framework generalizes well-known first- and second-order training\nmethods, and thus allows us to show the convergence of these methods for\nvarious DNN architectures and learning tasks, as a special case of our\napproach. We discuss some of its applications in training various DNN\narchitectures (e.g., feed-forward, convolutional, linear networks), to\nregression and classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:13:56 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Ghauch", "Hadi", ""], ["Shokri-Ghadikolaei", "Hossein", ""], ["Fischione", "Carlo", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1805.09217", "submitter": "Jiecao Chen", "authors": "Jiecao Chen, Qin Zhang, Yuan Zhou", "title": "Tight Bounds for Collaborative PAC Learning via Multiplicative Weights", "comments": "Accepted to NIPS 2018. 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the collaborative PAC learning problem recently proposed in Blum et\nal.~\\cite{BHPQ17}, in which we have $k$ players and they want to learn a target\nfunction collaboratively, such that the learned function approximates the\ntarget function well on all players' distributions simultaneously. The quality\nof the collaborative learning algorithm is measured by the ratio between the\nsample complexity of the algorithm and that of the learning algorithm for a\nsingle distribution (called the overhead). We obtain a collaborative learning\nalgorithm with overhead $O(\\ln k)$, improving the one with overhead $O(\\ln^2\nk)$ in \\cite{BHPQ17}. We also show that an $\\Omega(\\ln k)$ overhead is\ninevitable when $k$ is polynomial bounded by the VC dimension of the hypothesis\nclass. Finally, our experimental study has demonstrated the superiority of our\nalgorithm compared with the one in Blum et al. on real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:18:01 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 19:58:29 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Chen", "Jiecao", ""], ["Zhang", "Qin", ""], ["Zhou", "Yuan", ""]]}, {"id": "1805.09218", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens, Aske Plaat and Catholijn M. Jonker", "title": "Monte Carlo Tree Search for Asymmetric Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of Monte Carlo Tree Search (MCTS) that strongly\nincreases its efficiency for trees with asymmetry and/or loops. Asymmetric\ntermination of search trees introduces a type of uncertainty for which the\nstandard upper confidence bound (UCB) formula does not account. Our first\nalgorithm (MCTS-T), which assumes a non-stochastic environment, backs-up tree\nstructure uncertainty and leverages it for exploration in a modified UCB\nformula. Results show vastly improved efficiency in a well-known asymmetric\ndomain in which MCTS performs arbitrarily bad. Next, we connect the ideas about\nasymmetric termination to the presence of loops in the tree, where the same\nstate appears multiple times in a single trace. An extension to our algorithm\n(MCTS-T+), which in addition to non-stochasticity assumes full state\nobservability, further increases search efficiency for domains with loops as\nwell. Benchmark testing on a set of OpenAI Gym and Atari 2600 games indicates\nthat our algorithms always perform better than or at least equivalent to\nstandard MCTS, and could be first-choice tree search algorithms for\nnon-stochastic, fully-observable environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:19:40 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Plaat", "Aske", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1805.09235", "submitter": "Przemys\u00c5\u0082aw Spurek", "authors": "Szymon Knop, Jacek Tabor, Przemys{\\l}aw Spurek, Igor Podolak, Marcin\n  Mazur, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Cramer-Wold AutoEncoder", "comments": null, "journal-ref": "Journal of Machine Learning Research, 21, 164, 1-28 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new generative model, Cramer-Wold Autoencoder (CWAE). Following\nWAE, we directly encourage normality of the latent space. Our paper uses also\nthe recent idea from Sliced WAE (SWAE) model, which uses one-dimensional\nprojections as a method of verifying closeness of two distributions. The\ncrucial new ingredient is the introduction of a new (Cramer-Wold) metric in the\nspace of densities, which replaces the Wasserstein metric used in SWAE. We show\nthat the Cramer-Wold metric between Gaussian mixtures is given by a simple\nanalytic formula, which results in the removal of sampling necessary to\nestimate the cost function in WAE and SWAE models. As a consequence, while\ndrastically simplifying the optimization procedure, CWAE produces samples of a\nmatching perceptual quality to other SOTA models.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:48:31 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 17:31:37 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 09:00:24 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Knop", "Szymon", ""], ["Tabor", "Jacek", ""], ["Spurek", "Przemys\u0142aw", ""], ["Podolak", "Igor", ""], ["Mazur", "Marcin", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "1805.09238", "submitter": "Ron Shoham", "authors": "Ron Shoham and Haim Permuter", "title": "Highway State Gating for Recurrent Highway Networks: improving\n  information flow through time", "comments": "Accepted at CSCML (Cyber Security Cryptography and Machine Learning)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) play a major role in the field of sequential\nlearning, and have outperformed traditional algorithms on many benchmarks.\nTraining deep RNNs still remains a challenge, and most of the state-of-the-art\nmodels are structured with a transition depth of 2-4 layers. Recurrent Highway\nNetworks (RHNs) were introduced in order to tackle this issue. These have\nachieved state-of-the-art performance on a few benchmarks using a depth of 10\nlayers. However, the performance of this architecture suffers from a\nbottleneck, and ceases to improve when an attempt is made to add more layers.\nIn this work, we analyze the causes for this, and postulate that the main\nsource is the way that the information flows through time. We introduce a novel\nand simple variation for the RHN cell, called Highway State Gating (HSG), which\nallows adding more layers, while continuing to improve performance. By using a\ngating mechanism for the state, we allow the net to \"choose\" whether to pass\ninformation directly through time, or to gate it. This mechanism also allows\nthe gradient to back-propagate directly through time and, therefore, results in\na slightly faster convergence. We use the Penn Treebank (PTB) dataset as a\nplatform for empirical proof of concept. Empirical results show that the\nimprovement due to Highway State Gating is for all depths, and as the depth\nincreases, the improvement also increases.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:53:10 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Shoham", "Ron", ""], ["Permuter", "Haim", ""]]}, {"id": "1805.09244", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Andrea Bongiorno", "title": "Concentric ESN: Assessing the Effect of Modularity in Cycle Reservoirs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces concentric Echo State Network, an approach to design\nreservoir topologies that tries to bridge the gap between deterministically\nconstructed simple cycle models and deep reservoir computing approaches. We\nshow how to modularize the reservoir into simple unidirectional and concentric\ncycles with pairwise bidirectional jump connections between adjacent loops. We\nprovide a preliminary experimental assessment showing how concentric reservoirs\nyield to superior predictive accuracy and memory capacity with respect to\nsingle cycle reservoirs and deep reservoir models.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:58:57 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bacciu", "Davide", ""], ["Bongiorno", "Andrea", ""]]}, {"id": "1805.09247", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Csaba Szepesvari", "title": "Cleaning up the neighborhood: A full classification for adversarial\n  partial monitoring", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial monitoring is a generalization of the well-known multi-armed bandit\nframework where the loss is not directly observed by the learner. We complete\nthe classification of finite adversarial partial monitoring to include all\ngames, solving an open problem posed by Bartok et al. [2014]. Along the way we\nsimplify and improve existing algorithms and correct errors in previous\nanalyses. Our second contribution is a new algorithm for the class of games\nstudied by Bartok [2013] where we prove upper and lower regret bounds that shed\nmore light on the dependence of the regret on the game structure.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 16:04:00 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1805.09253", "submitter": "Sumudu Samarakoon Mr.", "authors": "Sumudu Samarakoon and Mehdi Bennis and Walid Saad and Merouane Debbah", "title": "Federated Learning for Ultra-Reliable Low-Latency V2V Communications", "comments": "7 pages, 5 figures, 2 tables, 1 algorithm, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel joint transmit power and resource allocation approach\nfor enabling ultra-reliable low-latency communication (URLLC) in vehicular\nnetworks is proposed. The objective is to minimize the network-wide power\nconsumption of vehicular users (VUEs) while ensuring high reliability in terms\nof probabilistic queuing delays. In particular, a reliability measure is\ndefined to characterize extreme events (i.e., when vehicles' queue lengths\nexceed a predefined threshold with non-negligible probability) using extreme\nvalue theory (EVT). Leveraging principles from federated learning (FL), the\ndistribution of these extreme events corresponding to the tail distribution of\nqueues is estimated by VUEs in a decentralized manner. Finally, Lyapunov\noptimization is used to find the joint transmit power and resource allocation\npolicies for each VUE in a distributed manner. The proposed solution is\nvalidated via extensive simulations using a Manhattan mobility model. It is\nshown that FL enables the proposed distributed method to estimate the tail\ndistribution of queues with an accuracy that is very close to a centralized\nsolution with up to 79\\% reductions in the amount of data that need to be\nexchanged. Furthermore, the proposed method yields up to 60\\% reductions of\nVUEs with large queue lengths, without an additional power consumption,\ncompared to an average queue-based baseline. Compared to systems with fixed\npower consumption and focusing on queue stability while minimizing average\npower consumption, the reduction in extreme events of the proposed method is\nabout two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 11:31:42 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Saad", "Walid", ""], ["Debbah", "Merouane", ""]]}, {"id": "1805.09266", "submitter": "Trong Nghia Hoang", "authors": "Trong Nghia Hoang, Quang Minh Hoang, Kian Hsiang Low and Jonathan How", "title": "Collective Online Learning of Gaussian Processes in Massive Multi-Agent\n  Systems", "comments": "Extended version with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning (ML) is a modern computation paradigm that\ndivides its workload into independent tasks that can be simultaneously achieved\nby multiple machines (i.e., agents) for better scalability. However, a typical\ndistributed system is usually implemented with a central server that collects\ndata statistics from multiple independent machines operating on different\nsubsets of data to build a global analytic model. This centralized\ncommunication architecture however exposes a single choke point for operational\nfailure and places severe bottlenecks on the server's communication and\ncomputation capacities as it has to process a growing volume of communication\nfrom a crowd of learning agents. To mitigate these bottlenecks, this paper\nintroduces a novel Collective Online Learning Gaussian Process framework for\nmassive distributed systems that allows each agent to build its local model,\nwhich can be exchanged and combined efficiently with others via peer-to-peer\ncommunication to converge on a global model of higher quality. Finally, our\nempirical results consistently demonstrate the efficiency of our framework on\nboth synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 16:26:41 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 20:08:05 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hoang", "Trong Nghia", ""], ["Hoang", "Quang Minh", ""], ["Low", "Kian Hsiang", ""], ["How", "Jonathan", ""]]}, {"id": "1805.09267", "submitter": "Prashant Doshi", "authors": "Roi Ceren and Prashant Doshi and Keyang He", "title": "Reinforcement Learning for Heterogeneous Teams with PALO Bounds", "comments": null, "journal-ref": "Neurocomputing, Volume 420, 8 January 2021, Pages 36-56", "doi": "10.1016/j.neucom.2020.08.054", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce reinforcement learning for heterogeneous teams in which rewards\nfor an agent are additively factored into local costs, stimuli unique to each\nagent, and global rewards, those shared by all agents in the domain. Motivating\ndomains include coordination of varied robotic platforms, which incur different\ncosts for the same action, but share an overall goal. We present two templates\nfor learning in this setting with factored rewards: a generalization of\nPerkins' Monte Carlo exploring starts for POMDPs to canonical MPOMDPs, with a\nsingle policy mapping joint observations of all agents to joint actions\n(MCES-MP); and another with each agent individually mapping joint observations\nto their own action (MCES-FMP). We use probably approximately local optimal\n(PALO) bounds to analyze sample complexity, instantiating these templates to\nPALO learning. We promote sample efficiency by including a policy space pruning\ntechnique, and evaluate the approaches on three domains of heterogeneous agents\ndemonstrating that MCES-FMP yields improved policies in less samples compared\nto MCES-MP and a previous benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 16:27:51 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ceren", "Roi", ""], ["Doshi", "Prashant", ""], ["He", "Keyang", ""]]}, {"id": "1805.09281", "submitter": "Sebastian Tschiatschek", "authors": "Sebastian Tschiatschek, Kai Arulkumaran, Jan St\\\"uhmer, Katja Hofmann", "title": "Variational Inference for Data-Efficient Model Learning in POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially observable Markov decision processes (POMDPs) are a powerful\nabstraction for tasks that require decision making under uncertainty, and\ncapture a wide range of real world tasks. Today, effective planning approaches\nexist that generate effective strategies given black-box models of a POMDP\ntask. Yet, an open question is how to acquire accurate models for complex\ndomains. In this paper we propose DELIP, an approach to model learning for\nPOMDPs that utilizes amortized structured variational inference. We empirically\nshow that our model leads to effective control strategies when coupled with\nstate-of-the-art planners. Intuitively, model-based approaches should be\nparticularly beneficial in environments with changing reward structures, or\nwhere rewards are initially unknown. Our experiments confirm that DELIP is\nparticularly effective in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 16:54:08 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Tschiatschek", "Sebastian", ""], ["Arulkumaran", "Kai", ""], ["St\u00fchmer", "Jan", ""], ["Hofmann", "Katja", ""]]}, {"id": "1805.09293", "submitter": "Rafid Mahmood", "authors": "Aaron Babier, Timothy C. Y. Chan, Adam Diamant, Rafid Mahmood", "title": "Learning to Optimize with Hidden Constraints", "comments": "69 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of learning to solve optimization problems has received interest\nfrom both the operations research and machine learning communities where each\nconsiders contrasting approaches: conditional stochastic optimization\nframeworks solved using provably optimal structured models versus deep learning\nmodels that leverage large data sets to yield empirically effective decision\nestimators. In this work, we combine the best of both worlds to solve the\nproblem of learning to generate decisions to instances of continuous\noptimization problems where the feasible set varies with contextual features.\nWe propose a novel framework for training a generative model to estimate\noptimal decisions by combining interior point methods and adversarial learning\nwhich we further embed within an active learning algorithm. Decisions generated\nby our model satisfy in-sample and out-of-sample optimality guarantees.\nFinally, we investigate case studies in portfolio optimization and personalized\ntreatment design, demonstrating that our approach yields significant advantages\nover predict-then-optimize and supervised deep learning techniques,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 17:25:34 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 21:55:04 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 18:02:36 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Babier", "Aaron", ""], ["Chan", "Timothy C. Y.", ""], ["Diamant", "Adam", ""], ["Mahmood", "Rafid", ""]]}, {"id": "1805.09294", "submitter": "Jan-Matthis Lueckmann", "authors": "Jan-Matthis Lueckmann, Giacomo Bassetto, Theofanis Karaletsos, Jakob\n  H. Macke", "title": "Likelihood-free inference with emulator networks", "comments": "In Advances in Approximate Bayesian Inference (AABI 2018)", "journal-ref": "PMLR 96:32-53, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation (ABC) provides methods for Bayesian\ninference in simulation-based stochastic models which do not permit tractable\nlikelihoods. We present a new ABC method which uses probabilistic neural\nemulator networks to learn synthetic likelihoods on simulated data -- both\nlocal emulators which approximate the likelihood for specific observed data, as\nwell as global ones which are applicable to a range of data. Simulations are\nchosen adaptively using an acquisition function which takes into account\nuncertainty about either the posterior distribution of interest, or the\nparameters of the emulator. Our approach does not rely on user-defined\nrejection thresholds or distance functions. We illustrate inference with\nemulator networks on synthetic examples and on a biophysical neuron model, and\nshow that emulators allow accurate and efficient inference even on\nhigh-dimensional problems which are challenging for conventional ABC\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 17:27:23 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 17:16:30 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Lueckmann", "Jan-Matthis", ""], ["Bassetto", "Giacomo", ""], ["Karaletsos", "Theofanis", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1805.09298", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Rongmei Lin, Zhen Liu, Lixin Liu, Zhiding Yu, Bo Dai, Le\n  Song", "title": "Learning towards Minimum Hyperspherical Energy", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are a powerful class of nonlinear functions that can be\ntrained end-to-end on various applications. While the over-parametrization\nnature in many neural networks renders the ability to fit complex functions and\nthe strong representation power to handle challenging tasks, it also leads to\nhighly correlated neurons that can hurt the generalization ability and incur\nunnecessary computation cost. As a result, how to regularize the network to\navoid undesired representation redundancy becomes an important issue. To this\nend, we draw inspiration from a well-known problem in physics -- Thomson\nproblem, where one seeks to find a state that distributes N electrons on a unit\nsphere as evenly as possible with minimum potential energy. In light of this\nintuition, we reduce the redundancy regularization problem to generic energy\nminimization, and propose a minimum hyperspherical energy (MHE) objective as\ngeneric regularization for neural networks. We also propose a few novel\nvariants of MHE, and provide some insights from a theoretical point of view.\nFinally, we apply neural networks with MHE regularization to several\nchallenging tasks. Extensive experiments demonstrate the effectiveness of our\nintuition, by showing the superior performance with MHE regularization.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 17:34:47 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 21:50:09 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 22:44:57 GMT"}, {"version": "v4", "created": "Sat, 16 Jun 2018 07:47:21 GMT"}, {"version": "v5", "created": "Sat, 27 Oct 2018 07:17:57 GMT"}, {"version": "v6", "created": "Sat, 1 Dec 2018 09:28:53 GMT"}, {"version": "v7", "created": "Wed, 9 Jan 2019 09:16:13 GMT"}, {"version": "v8", "created": "Tue, 5 Mar 2019 03:07:32 GMT"}, {"version": "v9", "created": "Wed, 22 Jul 2020 15:23:29 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Liu", "Weiyang", ""], ["Lin", "Rongmei", ""], ["Liu", "Zhen", ""], ["Liu", "Lixin", ""], ["Yu", "Zhiding", ""], ["Dai", "Bo", ""], ["Song", "Le", ""]]}, {"id": "1805.09302", "submitter": "Safa Cicek", "authors": "Safa Cicek and Stefano Soatto", "title": "Input and Weight Space Smoothing for Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose regularizing the empirical loss for semi-supervised learning by\nacting on both the input (data) space, and the weight (parameter) space. We\nshow that the two are not equivalent, and in fact are complementary, one\naffecting the minimality of the resulting representation, the other\ninsensitivity to nuisance variability. We propose a method to perform such\nsmoothing, which combines known input-space smoothing with a novel weight-space\nsmoothing, based on a min-max (adversarial) optimization. The resulting\nAdversarial Block Coordinate Descent (ABCD) algorithm performs gradient ascent\nwith a small learning rate for a random subset of the weights, and standard\ngradient descent on the remaining weights in the same mini-batch. It achieves\ncomparable performance to the state-of-the-art without resorting to heavy data\naugmentation, using a relatively simple architecture.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 17:39:38 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Cicek", "Safa", ""], ["Soatto", "Stefano", ""]]}, {"id": "1805.09317", "submitter": "Hyeji Kim", "authors": "Hyeji Kim, Yihan Jiang, Ranvir Rana, Sreeram Kannan, Sewoong Oh,\n  Pramod Viswanath", "title": "Communication Algorithms via Deep Learning", "comments": "19 pages, published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coding theory is a central discipline underpinning wireline and wireless\nmodems that are the workhorses of the information age. Progress in coding\ntheory is largely driven by individual human ingenuity with sporadic\nbreakthroughs over the past century. In this paper we study whether it is\npossible to automate the discovery of decoding algorithms via deep learning. We\nstudy a family of sequential codes parameterized by recurrent neural network\n(RNN) architectures. We show that creatively designed and trained RNN\narchitectures can decode well known sequential codes such as the convolutional\nand turbo codes with close to optimal performance on the additive white\nGaussian noise (AWGN) channel, which itself is achieved by breakthrough\nalgorithms of our times (Viterbi and BCJR decoders, representing dynamic\nprograming and forward-backward algorithms). We show strong generalizations,\ni.e., we train at a specific signal to noise ratio and block length but test at\na wide range of these quantities, as well as robustness and adaptivity to\ndeviations from the AWGN setting.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 17:58:37 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kim", "Hyeji", ""], ["Jiang", "Yihan", ""], ["Rana", "Ranvir", ""], ["Kannan", "Sreeram", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1805.09355", "submitter": "Marek Rei", "authors": "Marek Rei, Daniela Gerz, Ivan Vuli\\'c", "title": "Scoring Lexical Entailment with a Supervised Directional Similarity\n  Network", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Supervised Directional Similarity Network (SDSN), a novel\nneural architecture for learning task-specific transformation functions on top\nof general-purpose word embeddings. Relying on only a limited amount of\nsupervision from task-specific scores on a subset of the vocabulary, our\narchitecture is able to generalise and transform a general-purpose\ndistributional vector space to model the relation of lexical entailment.\nExperiments show excellent performance on scoring graded lexical entailment,\nraising the state-of-the-art on the HyperLex dataset by approximately 25%.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:03:40 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Rei", "Marek", ""], ["Gerz", "Daniela", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.09360", "submitter": "Utkarsh Upadhyay", "authors": "Utkarsh Upadhyay, Abir De, Manuel Gomez-Rodriguez", "title": "Deep Reinforcement Learning of Marked Temporal Point Processes", "comments": "To appear in Proceedings of the 32nd Conference on Neural Information\n  Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide variety of applications, humans interact with a complex environment\nby means of asynchronous stochastic discrete events in continuous time. Can we\ndesign online interventions that will help humans achieve certain goals in such\nasynchronous setting? In this paper, we address the above problem from the\nperspective of deep reinforcement learning of marked temporal point processes,\nwhere both the actions taken by an agent and the feedback it receives from the\nenvironment are asynchronous stochastic discrete events characterized using\nmarked temporal point processes. In doing so, we define the agent's policy\nusing the intensity and mark distribution of the corresponding process and then\nderive a flexible policy gradient method, which embeds the agent's actions and\nthe feedback it receives into real-valued vectors using deep recurrent neural\nnetworks. Our method does not make any assumptions on the functional form of\nthe intensity and mark distribution of the feedback and it allows for\narbitrarily complex reward functions. We apply our methodology to two different\napplications in personalized teaching and viral marketing and, using data\ngathered from Duolingo and Twitter, we show that it may be able to find\ninterventions to help learners and marketers achieve their goals more\neffectively than alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:06:10 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 12:42:28 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Upadhyay", "Utkarsh", ""], ["De", "Abir", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1805.09365", "submitter": "Qingyun Wu", "authors": "Qingyun Wu, Naveen Iyer, Hongning Wang", "title": "Learning Contextual Bandits in a Non-stationary Environment", "comments": "10 pages, 13 figures, To appear on ACM Special Interest Group on\n  Information Retrieval (SIGIR) 2018", "journal-ref": null, "doi": "10.1145/3209978.3210051", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandit algorithms have become a reference solution for handling\nthe explore/exploit dilemma in recommender systems, and many other important\nreal-world problems, such as display advertisement. However, such algorithms\nusually assume a stationary reward distribution, which hardly holds in practice\nas users' preferences are dynamic. This inevitably costs a recommender system\nconsistent suboptimal performance. In this paper, we consider the situation\nwhere the underlying distribution of reward remains unchanged over (possibly\nshort) epochs and shifts at unknown time instants. In accordance, we propose a\ncontextual bandit algorithm that detects possible changes of environment based\non its reward estimation confidence and updates its arm selection strategy\nrespectively. Rigorous upper regret bound analysis of the proposed algorithm\ndemonstrates its learning effectiveness in such a non-trivial environment.\nExtensive empirical evaluations on both synthetic and real-world datasets for\nrecommendation confirm its practical utility in a changing environment.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:16:39 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Wu", "Qingyun", ""], ["Iyer", "Naveen", ""], ["Wang", "Hongning", ""]]}, {"id": "1805.09366", "submitter": "Zining Zhu", "authors": "Zining Zhu, Jekaterina Novikova, Frank Rudzicz", "title": "Semi-supervised classification by reaching consensus among modalities", "comments": "NIPS IRASL Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has demonstrated abilities to learn complex structures, but\nthey can be restricted by available data. Recently, Consensus Networks (CNs)\nwere proposed to alleviate data sparsity by utilizing features from multiple\nmodalities, but they too have been limited by the size of labeled data. In this\npaper, we extend CN to Transductive Consensus Networks (TCNs), suitable for\nsemi-supervised learning. In TCNs, different modalities of input are compressed\ninto latent representations, which we encourage to become indistinguishable\nduring iterative adversarial training. To understand TCNs two mechanisms,\nconsensus and classification, we put forward its three variants in ablation\nstudies on these mechanisms. To further investigate TCN models, we treat the\nlatent representations as probability distributions and measure their\nsimilarities as the negative relative Jensen-Shannon divergences. We show that\na consensus state beneficial for classification desires a stable but imperfect\nsimilarity between the representations. Overall, TCNs outperform or align with\nthe best benchmark algorithms given 20 to 200 labeled samples on the Bank\nMarketing and the DementiaBank datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:19:11 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 17:56:13 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhu", "Zining", ""], ["Novikova", "Jekaterina", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1805.09370", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Zirui Xu, Yanzhi Wang, Chenchen Liu, Xiang Chen", "title": "Towards Robust Training of Neural Networks by Regularizing Adversarial\n  Gradients", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have demonstrated outstanding effectiveness\nin a large amount of applications.However, recent works have shown that neural\nnetworks are susceptible to adversarial examples, indicating possible flaws\nintrinsic to the network structures. To address this problem and improve the\nrobustness of neural networks, we investigate the fundamental mechanisms behind\nadversarial examples and propose a novel robust training method via regulating\nadversarial gradients. The regulation effectively squeezes the adversarial\ngradients of neural networks and significantly increases the difficulty of\nadversarial example generation.Without any adversarial example involved, the\nrobust training method could generate naturally robust networks, which are\nnear-immune to various types of adversarial examples. Experiments show the\nnaturally robust networks can achieve optimal accuracy against Fast Gradient\nSign Method (FGSM) and C\\&W attacks on MNIST, Cifar10, and Google Speech\nCommand dataset. Moreover, our proposed method also provides neural networks\nwith consistent robustness against transferable attacks.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:30:58 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 01:08:32 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Yu", "Fuxun", ""], ["Xu", "Zirui", ""], ["Wang", "Yanzhi", ""], ["Liu", "Chenchen", ""], ["Chen", "Xiang", ""]]}, {"id": "1805.09386", "submitter": "Jun Li", "authors": "Jun Li, Hongfu Liu, Bineng Zhong, Yue Wu, and Yun Fu", "title": "Predictive Local Smoothness for Stochastic Gradient Methods", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient methods are dominant in nonconvex optimization especially\nfor deep models but have low asymptotical convergence due to the fixed\nsmoothness. To address this problem, we propose a simple yet effective method\nfor improving stochastic gradient methods named predictive local smoothness\n(PLS). First, we create a convergence condition to build a learning rate which\nvaries adaptively with local smoothness. Second, the local smoothness can be\npredicted by the latest gradients. Third, we use the adaptive learning rate to\nupdate the stochastic gradients for exploring linear convergence rates. By\napplying the PLS method, we implement new variants of three popular algorithms:\nPLS-stochastic gradient descent (PLS-SGD), PLS-accelerated SGD (PLS-AccSGD),\nand PLS-AMSGrad. Moreover, we provide much simpler proofs to ensure their\nlinear convergence. Empirical results show that the variants have better\nperformance gains than the popular algorithms, such as, faster convergence and\nalleviating explosion and vanish of gradients.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 19:08:19 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Li", "Jun", ""], ["Liu", "Hongfu", ""], ["Zhong", "Bineng", ""], ["Wu", "Yue", ""], ["Fu", "Yun", ""]]}, {"id": "1805.09388", "submitter": "Stephen Tu", "authors": "Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, Stephen Tu", "title": "Regret Bounds for Robust Adaptive Control of the Linear Quadratic\n  Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider adaptive control of the Linear Quadratic Regulator (LQR), where\nan unknown linear system is controlled subject to quadratic costs. Leveraging\nrecent developments in the estimation of linear systems and in robust\ncontroller synthesis, we present the first provably polynomial time algorithm\nthat provides high probability guarantees of sub-linear regret on this problem.\nWe further study the interplay between regret minimization and parameter\nestimation by proving a lower bound on the expected regret in terms of the\nexploration schedule used by any algorithm. Finally, we conduct a numerical\nstudy comparing our robust adaptive algorithm to other methods from the\nadaptive LQR literature, and demonstrate the flexibility of our proposed method\nby extending it to a demand forecasting problem subject to state constraints.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 19:19:15 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Dean", "Sarah", ""], ["Mania", "Horia", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""], ["Tu", "Stephen", ""]]}, {"id": "1805.09406", "submitter": "Marcel Hirt", "authors": "Marcel Hirt and Petros Dellaportas", "title": "Scalable Bayesian Learning for State Space Models using Variational\n  Inference with SMC Samplers", "comments": "To appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable approach to performing approximate fully Bayesian\ninference in generic state space models. The proposed method is an alternative\nto particle MCMC that provides fully Bayesian inference of both the dynamic\nlatent states and the static parameters of the model. We build up on recent\nadvances in computational statistics that combine variational methods with\nsequential Monte Carlo sampling and we demonstrate the advantages of performing\nfull Bayesian inference over the static parameters rather than just performing\nvariational EM approximations. We illustrate how our approach enables scalable\ninference in multivariate stochastic volatility models and self-exciting point\nprocess models that allow for flexible dynamics in the latent intensity\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:00:41 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 22:56:01 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 14:17:22 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Hirt", "Marcel", ""], ["Dellaportas", "Petros", ""]]}, {"id": "1805.09411", "submitter": "Tiago Pimentel", "authors": "Tiago Pimentel, Marianne Monteiro, Adriano Veloso, Nivio Ziviani", "title": "Deep Active Learning for Anomaly Detection", "comments": "Accepted for publication at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies are intuitively easy for human experts to understand, but they are\nhard to define mathematically. Therefore, in order to have performance\nguarantees in unsupervised anomaly detection, priors need to be assumed on what\nthe anomalies are. By contrast, active learning provides the necessary priors\nthrough appropriate expert feedback. Thus, in this work we present an active\nlearning method that can be built upon existing deep learning solutions for\nunsupervised anomaly detection, so that outliers can be separated from normal\ndata effectively. We introduce a new layer that can be easily attached to any\ndeep learning model designed for unsupervised anomaly detection to transform it\ninto an active method. We report results on both synthetic and real anomaly\ndetection datasets, using multi-layer perceptrons and autoencoder architectures\nempowered with the proposed active layer, and we discuss their performance on\nfinding clustered and low density anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:09:07 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 16:36:30 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Pimentel", "Tiago", ""], ["Monteiro", "Marianne", ""], ["Veloso", "Adriano", ""], ["Ziviani", "Nivio", ""]]}, {"id": "1805.09416", "submitter": "Hejian Sang", "authors": "Hejian Sang, Jia Liu", "title": "Adaptive Stochastic Gradient Langevin Dynamics: Taming Convergence and\n  Saddle Point Escape Time", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a new adaptive stochastic gradient Langevin\ndynamics (ASGLD) algorithmic framework and its two specialized versions, namely\nadaptive stochastic gradient (ASG) and adaptive gradient Langevin\ndynamics(AGLD), for non-convex optimization problems. All proposed algorithms\ncan escape from saddle points with at most $O(\\log d)$ iterations, which is\nnearly dimension-free. Further, we show that ASGLD and ASG converge to a local\nminimum with at most $O(\\log d/\\epsilon^4)$ iterations. Also, ASGLD with full\ngradients or ASGLD with a slowly linearly increasing batch size converge to a\nlocal minimum with iterations bounded by $O(\\log d/\\epsilon^2)$, which\noutperforms existing first-order methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:26:56 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Sang", "Hejian", ""], ["Liu", "Jia", ""]]}, {"id": "1805.09441", "submitter": "Ekraam Sabir", "authors": "Ekraam Sabir, Stephen Rawls and Prem Natarajan", "title": "Implicit Language Model in LSTM for OCR", "comments": null, "journal-ref": "2017 14th IAPR International Conference on Document Analysis and\n  Recognition (ICDAR), vol. 7 (2017) pp. 27-31", "doi": "10.1109/ICDAR.2017.361", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become the technique of choice for OCR, but many aspects\nof how and why they deliver superior performance are still unknown. One key\ndifference between current neural network techniques using LSTMs and the\nprevious state-of-the-art HMM systems is that HMM systems have a strong\nindependence assumption. In comparison LSTMs have no explicit constraints on\nthe amount of context that can be considered during decoding. In this paper we\nshow that they learn an implicit LM and attempt to characterize the strength of\nthe LM in terms of equivalent n-gram context. We show that this implicitly\nlearned language model provides a 2.4\\% CER improvement on our synthetic test\nset when compared against a test set of random characters (i.e. not naturally\noccurring sequences), and that the LSTM learns to use up to 5 characters of\ncontext (which is roughly 88 frames in our configuration). We believe that this\nis the first ever attempt at characterizing the strength of the implicit LM in\nLSTM based OCR systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 22:01:38 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Sabir", "Ekraam", ""], ["Rawls", "Stephen", ""], ["Natarajan", "Prem", ""]]}, {"id": "1805.09450", "submitter": "Matthew Thorpe", "authors": "Matthew M. Dunlop, Dejan Slep\\v{c}ev, Andrew M. Stuart, Matthew Thorpe", "title": "Large Data and Zero Noise Limits of Graph-Based Semi-Supervised Learning\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalings in which the graph Laplacian approaches a differential operator in\nthe large graph limit are used to develop understanding of a number of\nalgorithms for semi-supervised learning; in particular the extension, to this\ngraph setting, of the probit algorithm, level set and kriging methods, are\nstudied. Both optimization and Bayesian approaches are considered, based around\na regularizing quadratic form found from an affine transformation of the\nLaplacian, raised to a, possibly fractional, exponent. Conditions on the\nparameters defining this quadratic form are identified under which well-defined\nlimiting continuum analogues of the optimization and Bayesian semi-supervised\nlearning problems may be found, thereby shedding light on the design of\nalgorithms in the large graph setting. The large graph limits of the\noptimization formulations are tackled through $\\Gamma-$convergence, using the\nrecently introduced $TL^p$ metric. The small labelling noise limits of the\nBayesian formulations are also identified, and contrasted with pre-existing\nharmonic function approaches to the problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 22:50:53 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 21:12:52 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Dunlop", "Matthew M.", ""], ["Slep\u010dev", "Dejan", ""], ["Stuart", "Andrew M.", ""], ["Thorpe", "Matthew", ""]]}, {"id": "1805.09458", "submitter": "Daniel Moyer", "authors": "Daniel Moyer, Shuyang Gao, Rob Brekelmans, Greg Ver Steeg, Aram\n  Galstyan", "title": "Invariant Representations without Adversarial Training", "comments": "NeurIPS 2018, with corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations of data that are invariant to changes in specified factors\nare useful for a wide range of problems: removing potential biases in\nprediction problems, controlling the effects of covariates, and disentangling\nmeaningful factors of variation. Unfortunately, learning representations that\nexhibit invariance to arbitrary nuisance factors yet remain useful for other\ntasks is challenging. Existing approaches cast the trade-off between task\nperformance and invariance in an adversarial way, using an iterative minimax\noptimization. We show that adversarial training is unnecessary and sometimes\ncounter-productive; we instead cast invariant representation learning as a\nsingle information-theoretic objective that can be directly optimized. We\ndemonstrate that this approach matches or exceeds performance of\nstate-of-the-art adversarial approaches for learning fair representations and\nfor generative modeling with controllable transformations.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 00:12:59 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 17:15:41 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 20:12:46 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 16:17:45 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Moyer", "Daniel", ""], ["Gao", "Shuyang", ""], ["Brekelmans", "Rob", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1805.09460", "submitter": "Yotam Hechtlinger", "authors": "Yotam Hechtlinger, Barnab\\'as P\\'oczos and Larry Wasserman", "title": "Cautious Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most classifiers operate by selecting the maximum of an estimate of the\nconditional distribution $p(y|x)$ where $x$ stands for the features of the\ninstance to be classified and $y$ denotes its label. This often results in a\n{\\em hubristic bias}: overconfidence in the assignment of a definite label.\nUsually, the observations are concentrated on a small volume but the classifier\nprovides definite predictions for the entire space. We propose constructing\nconformal prediction sets which contain a set of labels rather than a single\nlabel. These conformal prediction sets contain the true label with probability\n$1-\\alpha$. Our construction is based on $p(x|y)$ rather than $p(y|x)$ which\nresults in a classifier that is very cautious: it outputs the null set ---\nmeaning \"I don't know\" --- when the object does not resemble the training\nexamples. An important property of our approach is that adversarial attacks are\nlikely to be predicted as the null set or would also include the true label. We\ndemonstrate the performance on the ImageNet ILSVRC dataset and the CelebA and\nIMDB-Wiki facial datasets using high dimensional features obtained from state\nof the art convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 00:17:24 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 19:27:58 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Hechtlinger", "Yotam", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Wasserman", "Larry", ""]]}, {"id": "1805.09461", "submitter": "Yaser Keneshloo", "authors": "Yaser Keneshloo, Tian Shi, Naren Ramakrishnan, Chandan K. Reddy", "title": "Deep Reinforcement Learning For Sequence to Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, sequence-to-sequence (seq2seq) models have gained a lot of\npopularity and provide state-of-the-art performance in a wide variety of tasks\nsuch as machine translation, headline generation, text summarization, speech to\ntext conversion, and image caption generation. The underlying framework for all\nthese models is usually a deep neural network comprising an encoder and a\ndecoder. Although simple encoder-decoder models produce competitive results,\nmany researchers have proposed additional improvements over these\nsequence-to-sequence models, e.g., using an attention-based model over the\ninput, pointer-generation models, and self-attention models. However, such\nseq2seq models suffer from two common problems: 1) exposure bias and 2)\ninconsistency between train/test measurement. Recently, a completely novel\npoint of view has emerged in addressing these two problems in seq2seq models,\nleveraging methods from reinforcement learning (RL). In this survey, we\nconsider seq2seq problems from the RL point of view and provide a formulation\ncombining the power of RL methods in decision-making with sequence-to-sequence\nmodels that enable remembering long-term memories. We present some of the most\nrecent frameworks that combine concepts from RL and deep neural networks and\nexplain how these two areas could benefit from each other in solving complex\nseq2seq tasks. Our work aims to provide insights into some of the problems that\ninherently arise with current approaches and how we can address them with\nbetter RL models. We also provide the source code for implementing most of the\nRL models discussed in this paper to support the complex task of abstractive\ntext summarization.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 00:21:34 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 01:36:20 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 21:02:17 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2019 23:56:10 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Keneshloo", "Yaser", ""], ["Shi", "Tian", ""], ["Ramakrishnan", "Naren", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1805.09464", "submitter": "Anastasios Kyrillidis", "authors": "Anastasios Kyrillidis", "title": "Simple and practical algorithms for $\\ell_p$-norm low-rank approximation", "comments": "16 pages, 11 figures, to appear in UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NA math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose practical algorithms for entrywise $\\ell_p$-norm low-rank\napproximation, for $p = 1$ or $p = \\infty$. The proposed framework, which is\nnon-convex and gradient-based, is easy to implement and typically attains\nbetter approximations, faster, than state of the art.\n  From a theoretical standpoint, we show that the proposed scheme can attain\n$(1 + \\varepsilon)$-OPT approximations. Our algorithms are not\nhyperparameter-free: they achieve the desiderata only assuming algorithm's\nhyperparameters are known a priori---or are at least approximable. I.e., our\ntheory indicates what problem quantities need to be known, in order to get a\ngood solution within polynomial time, and does not contradict to recent\ninapproximabilty results, as in [46].\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 00:41:25 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Kyrillidis", "Anastasios", ""]]}, {"id": "1805.09470", "submitter": "Xin Zhang", "authors": "Xin Zhang, Jia Liu, Zhengyuan Zhu", "title": "Taming Convergence for Asynchronous Stochastic Gradient Descent with\n  Unbounded Delay in Non-Convex Learning", "comments": "2020 IEEE 59th Conference on Decision and Control (CDC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the convergence performance of asynchronous stochastic gradient\ndescent method (Async-SGD) has received increasing attention in recent years\ndue to their foundational role in machine learning. To date, however, most of\nthe existing works are restricted to either bounded gradient delays or convex\nsettings. In this paper, we focus on Async-SGD and its variant Async-SGDI\n(which uses increasing batch size) for non-convex optimization problems with\nunbounded gradient delays. We prove $o(1/\\sqrt{k})$ convergence rate for\nAsync-SGD and $o(1/k)$ for Async-SGDI. Also, a unifying sufficient condition\nfor Async-SGD's convergence is established, which includes two major gradient\ndelay models in the literature as special cases and yields a new delay model\nnot considered thus far.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 01:10:36 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 17:57:22 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zhang", "Xin", ""], ["Liu", "Jia", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1805.09473", "submitter": "Yi Yang", "authors": "Yi Yang, Andy Chen, Xiaoming Chen, Jiang Ji, Zhenyang Chen, Yan Dai", "title": "Deploy Large-Scale Deep Neural Networks in Resource Constrained IoT\n  Devices with Local Quantization Region", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing large-scale deep neural networks with high computational\ncomplexity on low-cost IoT devices may inevitably be constrained by limited\ncomputation resource, making the devices hard to respond in real-time. This\ndisjunction makes the state-of-art deep learning algorithms, i.e. CNN\n(Convolutional Neural Networks), incompatible with IoT world. We present a\nlow-bit (range from 8-bit to 1-bit) scheme with our local quantization region\nalgorithm. We use models in Caffe model zoo as our example tasks to evaluate\nthe effect of our low precision data representation scheme. With the available\nof local quantization region, we find implementations on top of those schemes\ncould greatly retain the model accuracy, besides the reduction of computational\ncomplexity. For example, our 8-bit scheme has no drops on top-1 and top-5\naccuracy with 2x speedup on Intel Edison IoT platform. Implementations based on\nour 4-bit, 2-bit or 1-bit scheme are also applicable to IoT devices with\nadvances of low computational complexity. For example, the drop on our task is\nonly 0.7% when using 2-bit scheme, a scheme which could largely save\ntransistors. Making low-bit scheme usable here opens a new door for further\noptimization on commodity IoT controller, i.e. extra speed-up could be achieved\nby replacing multiply-accumulate operations with the proposed table look-up\noperations. The whole study offers a new approach to relief the challenge of\nbring advanced deep learning algorithm to resource constrained low-cost IoT\ndevice.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 01:15:42 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Yang", "Yi", ""], ["Chen", "Andy", ""], ["Chen", "Xiaoming", ""], ["Ji", "Jiang", ""], ["Chen", "Zhenyang", ""], ["Dai", "Yan", ""]]}, {"id": "1805.09476", "submitter": "Rad Niazadeh", "authors": "Vaggos Chatziafratis, Rad Niazadeh, Moses Charikar", "title": "Hierarchical Clustering with Structural Constraints", "comments": "In Proc. 35th International Conference on Machine Learning (ICML\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is a popular unsupervised data analysis method. For\nmany real-world applications, we would like to exploit prior information about\nthe data that imposes constraints on the clustering hierarchy, and is not\ncaptured by the set of features available to the algorithm. This gives rise to\nthe problem of \"hierarchical clustering with structural constraints\".\nStructural constraints pose major challenges for bottom-up approaches like\naverage/single linkage and even though they can be naturally incorporated into\ntop-down divisive algorithms, no formal guarantees exist on the quality of\ntheir output. In this paper, we provide provable approximation guarantees for\ntwo simple top-down algorithms, using a recently introduced optimization\nviewpoint of hierarchical clustering with pairwise similarity information\n[Dasgupta, 2016]. We show how to find good solutions even in the presence of\nconflicting prior information, by formulating a constraint-based regularization\nof the objective. We further explore a variation of this objective for\ndissimilarity information [Cohen-Addad et al., 2018] and improve upon current\ntechniques. Finally, we demonstrate our approach on a real dataset for the\ntaxonomy application.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 01:32:19 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2018 16:12:51 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Chatziafratis", "Vaggos", ""], ["Niazadeh", "Rad", ""], ["Charikar", "Moses", ""]]}, {"id": "1805.09480", "submitter": "Rad Niazadeh", "authors": "Rad Niazadeh, Tim Roughgarden, Joshua R. Wang", "title": "Optimal Algorithms for Continuous Non-monotone Submodular and\n  DR-Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the fundamental problems of maximizing a continuous\nnon-monotone submodular function over the hypercube, both with and without\ncoordinate-wise concavity. This family of optimization problems has several\napplications in machine learning, economics, and communication systems. Our\nmain result is the first $\\frac{1}{2}$-approximation algorithm for continuous\nsubmodular function maximization; this approximation factor of $\\frac{1}{2}$ is\nthe best possible for algorithms that only query the objective function at\npolynomially many points. For the special case of DR-submodular maximization,\ni.e. when the submodular functions is also coordinate wise concave along all\ncoordinates, we provide a different $\\frac{1}{2}$-approximation algorithm that\nruns in quasilinear time. Both of these results improve upon prior work [Bian\net al, 2017, Soma and Yoshida, 2017].\n  Our first algorithm uses novel ideas such as reducing the guaranteed\napproximation problem to analyzing a zero-sum game for each coordinate, and\nincorporates the geometry of this zero-sum game to fix the value at this\ncoordinate. Our second algorithm exploits coordinate-wise concavity to identify\na monotone equilibrium condition sufficient for getting the required\napproximation guarantee, and hunts for the equilibrium point using binary\nsearch. We further run experiments to verify the performance of our proposed\nalgorithms in related machine learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 02:08:14 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Niazadeh", "Rad", ""], ["Roughgarden", "Tim", ""], ["Wang", "Joshua R.", ""]]}, {"id": "1805.09484", "submitter": "Jing Zhang", "authors": "Hong Wen, Jing Zhang, Quan Lin, Keping Yang and Pipei Huang", "title": "Multi-Level Deep Cascade Trees for Conversion Rate Prediction in\n  Recommendation System", "comments": "8 pages, 5 figures, To appear in AAAI'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing effective and efficient recommendation methods is very challenging\nfor modern e-commerce platforms. Generally speaking, two essential modules\nnamed \"Click-Through Rate Prediction\" (\\textit{CTR}) and \"Conversion Rate\nPrediction\" (\\textit{CVR}) are included, where \\textit{CVR} module is a crucial\nfactor that affects the final purchasing volume directly. However, it is indeed\nvery challenging due to its sparseness nature. In this paper, we tackle this\nproblem by proposing multi-Level Deep Cascade Trees (\\textit{ldcTree}), which\nis a novel decision tree ensemble approach. It leverages deep cascade\nstructures by stacking Gradient Boosting Decision Trees (\\textit{GBDT}) to\neffectively learn feature representation. In addition, we propose to utilize\nthe cross-entropy in each tree of the preceding \\textit{GBDT} as the input\nfeature representation for next level \\textit{GBDT}, which has a clear\nexplanation, i.e., a traversal from root to leaf nodes in the next level\n\\textit{GBDT} corresponds to the combination of certain traversals in the\npreceding \\textit{GBDT}. The deep cascade structure and the combination rule\nenable the proposed \\textit{ldcTree} to have a stronger distributed feature\nrepresentation ability. Moreover, inspired by ensemble learning, we propose an\nEnsemble \\textit{ldcTree} (\\textit{E-ldcTree}) to encourage the model's\ndiversity and enhance the representation ability further. Finally, we propose\nan improved Feature learning method based on \\textit{EldcTree}\n(\\textit{F-EldcTree}) for taking adequate use of weak and strong correlation\nfeatures identified by pre-trained \\textit{GBDT} models. Experimental results\non off-line data set and online deployment demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 02:22:08 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 04:14:30 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 03:36:18 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wen", "Hong", ""], ["Zhang", "Jing", ""], ["Lin", "Quan", ""], ["Yang", "Keping", ""], ["Huang", "Pipei", ""]]}, {"id": "1805.09496", "submitter": "Yuanlong Li", "authors": "Yuanlong Li, Linsen Dong, Xin Zhou, Yonggang Wen and Kyle Guan", "title": "Intelligent Trainer for Model-Based Reinforcement Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) has been proposed as a promising\nalternative solution to tackle the high sampling cost challenge in the\ncanonical reinforcement learning (RL), by leveraging a learned model to\ngenerate synthesized data for policy training purpose. The MBRL framework,\nnevertheless, is inherently limited by the convoluted process of jointly\nlearning control policy and configuring hyper-parameters (e.g., global/local\nmodels, real and synthesized data, etc). The training process could be tedious\nand prohibitively costly. In this research, we propose an \"reinforcement on\nreinforcement\" (RoR) architecture to decompose the convoluted tasks into two\nlayers of reinforcement learning. The inner layer is the canonical model-based\nRL training process environment (TPE), which learns the control policy for the\nunderlying system and exposes interfaces to access states, actions and rewards.\nThe outer layer presents an RL agent, called as AI trainer, to learn an optimal\nhyper-parameter configuration for the inner TPE. This decomposition approach\nprovides a desirable flexibility to implement different trainer designs, called\nas \"train the trainer\". In our research, we propose and optimize two\nalternative trainer designs: 1) a uni-head trainer and 2) a multi-head trainer.\nOur proposed RoR framework is evaluated for five tasks in the OpenAI gym (i.e.,\nPendulum, Mountain Car, Reacher, Half Cheetah and Swimmer). Compared to three\nother baseline algorithms, our proposed Train-the-Trainer algorithm has a\ncompetitive performance in auto-tuning capability, with upto 56% expected\nsampling cost saving without knowing the best parameter setting in advance. The\nproposed trainer framework can be easily extended to other cases in which the\nhyper-parameter tuning is costly.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 03:08:40 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 09:14:20 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 03:22:35 GMT"}, {"version": "v4", "created": "Sun, 10 Mar 2019 05:13:36 GMT"}, {"version": "v5", "created": "Sat, 23 Mar 2019 13:45:03 GMT"}, {"version": "v6", "created": "Wed, 5 Jun 2019 13:02:28 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Li", "Yuanlong", ""], ["Dong", "Linsen", ""], ["Zhou", "Xin", ""], ["Wen", "Yonggang", ""], ["Guan", "Kyle", ""]]}, {"id": "1805.09501", "submitter": "Ekin Dogus Cubuk", "authors": "Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V.\n  Le", "title": "AutoAugment: Learning Augmentation Policies from Data", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is an effective technique for improving the accuracy of\nmodern image classifiers. However, current data augmentation implementations\nare manually designed. In this paper, we describe a simple procedure called\nAutoAugment to automatically search for improved data augmentation policies. In\nour implementation, we have designed a search space where a policy consists of\nmany sub-policies, one of which is randomly chosen for each image in each\nmini-batch. A sub-policy consists of two operations, each operation being an\nimage processing function such as translation, rotation, or shearing, and the\nprobabilities and magnitudes with which the functions are applied. We use a\nsearch algorithm to find the best policy such that the neural network yields\nthe highest validation accuracy on a target dataset. Our method achieves\nstate-of-the-art accuracy on CIFAR-10, CIFAR-100, SVHN, and ImageNet (without\nadditional data). On ImageNet, we attain a Top-1 accuracy of 83.5% which is\n0.4% better than the previous record of 83.1%. On CIFAR-10, we achieve an error\nrate of 1.5%, which is 0.6% better than the previous state-of-the-art.\nAugmentation policies we find are transferable between datasets. The policy\nlearned on ImageNet transfers well to achieve significant improvements on other\ndatasets, such as Oxford Flowers, Caltech-101, Oxford-IIT Pets, FGVC Aircraft,\nand Stanford Cars.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 04:05:42 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 20:27:22 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 22:39:27 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Cubuk", "Ekin D.", ""], ["Zoph", "Barret", ""], ["Mane", "Dandelion", ""], ["Vasudevan", "Vijay", ""], ["Le", "Quoc V.", ""]]}, {"id": "1805.09527", "submitter": "Ridho Rahmadi", "authors": "Ridho Rahmadi, Perry Groot, Tom Heskes", "title": "Stable specification search in structural equation model with latent\n  variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous study, we introduced stable specification search for\ncross-sectional data (S3C). It is an exploratory causal method that combines\nstability selection concept and multi-objective optimization to search for\nstable and parsimonious causal structures across the entire range of model\ncomplexities. In this study, we extended S3C to S3C-Latent, to model causal\nrelations between latent variables. We evaluated S3C-Latent on simulated data\nand compared the results to those of PC-MIMBuild, an extension of the PC\nalgorithm, the state-of-the-art causal discovery method. The comparison showed\nthat S3C-Latent achieved better performance. We also applied S3C-Latent to\nreal-world data of children with attention deficit/hyperactivity disorder and\ndata about measuring mental abilities among pupils. The results are consistent\nwith those of previous studies.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 07:07:43 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Rahmadi", "Ridho", ""], ["Groot", "Perry", ""], ["Heskes", "Tom", ""]]}, {"id": "1805.09547", "submitter": "Ryo Takahashi", "authors": "Ryo Takahashi, Ran Tian, Kentaro Inui", "title": "Interpretable and Compositional Relation Learning by Joint Training with\n  an Autoencoder", "comments": "Equal contribution from first two authors. Accepted for publication\n  in the ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models for entities and relations are extremely useful for\nrecovering missing facts in a knowledge base. Intuitively, a relation can be\nmodeled by a matrix mapping entity vectors. However, relations reside on low\ndimension sub-manifolds in the parameter space of arbitrary matrices---for one\nreason, composition of two relations $\\boldsymbol{M}_1,\\boldsymbol{M}_2$ may\nmatch a third $\\boldsymbol{M}_3$ (e.g. composition of relations\ncurrency_of_country and country_of_film usually matches\ncurrency_of_film_budget), which imposes compositional constraints to be\nsatisfied by the parameters (i.e. $\\boldsymbol{M}_1\\cdot\n\\boldsymbol{M}_2\\approx \\boldsymbol{M}_3$). In this paper we investigate a\ndimension reduction technique by training relations jointly with an\nautoencoder, which is expected to better capture compositional constraints. We\nachieve state-of-the-art on Knowledge Base Completion tasks with strongly\nimproved Mean Rank, and show that joint training with an autoencoder leads to\ninterpretable sparse codings of relations, helps discovering compositional\nconstraints and benefits from compositional training. Our source code is\nreleased at github.com/tianran/glimvec.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 08:32:53 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Takahashi", "Ryo", ""], ["Tian", "Ran", ""], ["Inui", "Kentaro", ""]]}, {"id": "1805.09563", "submitter": "Michele Scalas", "authors": "Michele Scalas, Davide Maiorca, Francesco Mercaldo, Corrado Aaron\n  Visaggio, Fabio Martinelli and Giorgio Giacinto", "title": "On the Effectiveness of System API-Related Information for Android\n  Ransomware Detection", "comments": null, "journal-ref": "Computers & Security 86C (2019) pp. 168-182", "doi": "10.1016/j.cose.2019.06.004", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ransomware constitutes a significant threat to the Android operating system.\nIt can either lock or encrypt the target devices, and victims are forced to pay\nransoms to restore their data. Hence, the prompt detection of such attacks has\na priority in comparison to other malicious threats. Previous works on Android\nmalware detection mainly focused on Machine Learning-oriented approaches that\nwere tailored to identifying malware families, without a clear focus on\nransomware. More specifically, such approaches resorted to complex information\ntypes such as permissions, user-implemented API calls, and native calls.\nHowever, this led to significant drawbacks concerning complexity, resilience\nagainst obfuscation, and explainability. To overcome these issues, in this\npaper, we propose and discuss learning-based detection strategies that rely on\nSystem API information. These techniques leverage the fact that ransomware\nattacks heavily resort to System API to perform their actions, and allow\ndistinguishing between generic malware, ransomware and goodware.\n  We tested three different ways of employing System API information, i.e.,\nthrough packages, classes, and methods, and we compared their performances to\nother, more complex state-of-the-art approaches. The attained results showed\nthat systems based on System API could detect ransomware and generic malware\nwith very good accuracy, comparable to systems that employed more complex\ninformation. Moreover, the proposed systems could accurately detect novel\nsamples in the wild and showed resilience against static obfuscation attempts.\nFinally, to guarantee early on-device detection, we developed and released on\nthe Android platform a complete ransomware and malware detector (R-PackDroid)\nthat employed one of the methodologies proposed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 09:18:08 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 10:29:25 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 10:58:04 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2019 09:46:16 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Scalas", "Michele", ""], ["Maiorca", "Davide", ""], ["Mercaldo", "Francesco", ""], ["Visaggio", "Corrado Aaron", ""], ["Martinelli", "Fabio", ""], ["Giacinto", "Giorgio", ""]]}, {"id": "1805.09567", "submitter": "Ricardo Pio Monti", "authors": "Ricardo Pio Monti and Aapo Hyv\\\"arinen", "title": "A Unified Probabilistic Model for Learning Latent Factors and Their\n  Connectivities from High-Dimensional Data", "comments": "13 pages, 6 figures. To appear in UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectivity estimation is challenging in the context of high-dimensional\ndata. A useful preprocessing step is to group variables into clusters, however,\nit is not always clear how to do so from the perspective of connectivity\nestimation. Another practical challenge is that we may have data from multiple\nrelated classes (e.g., multiple subjects or conditions) and wish to incorporate\nconstraints on the similarities across classes. We propose a probabilistic\nmodel which simultaneously performs both a grouping of variables (i.e.,\ndetecting community structure) and estimation of connectivities between the\ngroups which correspond to latent variables. The model is essentially a factor\nanalysis model where the factors are allowed to have arbitrary correlations,\nwhile the factor loading matrix is constrained to express a community\nstructure. The model can be applied on multiple classes so that the\nconnectivities can be different between the classes, while the community\nstructure is the same for all classes. We propose an efficient estimation\nalgorithm based on score matching, and prove the identifiability of the model.\nFinally, we present an extension to directed (causal) connectivities over\nlatent variables. Simulations and experiments on fMRI data validate the\npractical utility of the method.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 09:27:57 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Monti", "Ricardo Pio", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "1805.09575", "submitter": "Mevlana Gemici", "authors": "Mevlana Gemici, Zeynep Akata, Max Welling", "title": "Primal-Dual Wasserstein GAN", "comments": "14 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Primal-Dual Wasserstein GAN, a new learning algorithm for\nbuilding latent variable models of the data distribution based on the primal\nand the dual formulations of the optimal transport (OT) problem. We utilize the\nprimal formulation to learn a flexible inference mechanism and to create an\noptimal approximate coupling between the data distribution and the generative\nmodel. In order to learn the generative model, we use the dual formulation and\ntrain the decoder adversarially through a critic network that is regularized by\nthe approximate coupling obtained from the primal. Unlike previous methods that\nviolate various properties of the optimal critic, we regularize the norm and\nthe direction of the gradients of the critic function. Our model shares many of\nthe desirable properties of auto-encoding models in terms of mode coverage and\nlatent structure, while avoiding their undesirable averaging properties, e.g.\ntheir inability to capture sharp visual features when modeling real images. We\ncompare our algorithm with several other generative modeling techniques that\nutilize Wasserstein distances on Frechet Inception Distance (FID) and Inception\nScores (IS).\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 09:47:16 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Gemici", "Mevlana", ""], ["Akata", "Zeynep", ""], ["Welling", "Max", ""]]}, {"id": "1805.09585", "submitter": "Francois Rousseau", "authors": "Francois Rousseau and Ronan Fablet", "title": "Residual Networks as Geodesic Flows of Diffeomorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the understanding and characterization of residual\nnetworks (ResNet), which are among the state-of-the-art deep learning\narchitectures for a variety of supervised learning problems. We focus on the\nmapping component of ResNets, which map the embedding space towards a new\nunknown space where the prediction or classification can be stated according to\nlinear criteria. We show that this mapping component can be regarded as the\nnumerical implementation of continuous flows of diffeomorphisms governed by\nordinary differential equations. Especially, ResNets with shared weights are\nfully characterized as numerical approximation of exponential diffeomorphic\noperators. We stress both theoretically and numerically the relevance of the\nenforcement of diffeormorphic properties and the importance of numerical issues\nto make consistent the continuous formulation and the discretized ResNet\nimplementation. We further discuss the resulting theoretical and computational\ninsights on ResNet architectures.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 10:07:46 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 13:02:03 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Rousseau", "Francois", ""], ["Fablet", "Ronan", ""]]}, {"id": "1805.09613", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens, Aske Plaat and Catholijn M. Jonker", "title": "A0C: Alpha Zero in Continuous Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core novelty of Alpha Zero is the interleaving of tree search and deep\nlearning, which has proven very successful in board games like Chess, Shogi and\nGo. These games have a discrete action space. However, many real-world\nreinforcement learning domains have continuous action spaces, for example in\nrobotic control, navigation and self-driving cars. This paper presents the\nnecessary theoretical extensions of Alpha Zero to deal with continuous action\nspace. We also provide some preliminary experiments on the Pendulum swing-up\ntask, empirically showing the feasibility of our approach. Thereby, this work\nprovides a first step towards the application of iterated search and learning\nin domains with a continuous action space.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 11:33:49 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Plaat", "Aske", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1805.09621", "submitter": "Zhe Cheng Fan", "authors": "Zhe-Cheng Fan, Tak-Shing T. Chan, Yi-Hsuan Yang, and Jyh-Shing R. Jang", "title": "Backpropagation with N-D Vector-Valued Neurons Using Arbitrary Bilinear\n  Products", "comments": "14 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector-valued neural learning has emerged as a promising direction in deep\nlearning recently. Traditionally, training data for neural networks (NNs) are\nformulated as a vector of scalars; however, its performance may not be optimal\nsince associations among adjacent scalars are not modeled. In this paper, we\npropose a new vector neural architecture called the Arbitrary BIlinear Product\nNeural Network (ABIPNN), which processes information as vectors in each neuron,\nand the feedforward projections are defined using arbitrary bilinear products.\nSuch bilinear products can include circular convolution, seven-dimensional\nvector product, skew circular convolution, reversed- time circular convolution,\nor other new products not seen in previous work. As a proof-of-concept, we\napply our proposed network to multispectral image denoising and singing voice\nsepa- ration. Experimental results show that ABIPNN gains substantial\nimprovements when compared to conventional NNs, suggesting that associations\nare learned during training.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 12:01:53 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Fan", "Zhe-Cheng", ""], ["Chan", "Tak-Shing T.", ""], ["Yang", "Yi-Hsuan", ""], ["Jang", "Jyh-Shing R.", ""]]}, {"id": "1805.09622", "submitter": "Or Litany", "authors": "Or Litany and Daniel Freedman", "title": "SOSELETO: A Unified Approach to Transfer Learning and Training with\n  Noisy Labels", "comments": "ICLR workshop on Learning from Limited Labeled Data (LLD) -- Best\n  Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SOSELETO (SOurce SELEction for Target Optimization), a new method\nfor exploiting a source dataset to solve a classification problem on a target\ndataset. SOSELETO is based on the following simple intuition: some source\nexamples are more informative than others for the target problem. To capture\nthis intuition, source samples are each given weights; these weights are solved\nfor jointly with the source and target classification problems via a bilevel\noptimization scheme. The target therefore gets to choose the source samples\nwhich are most informative for its own classification task. Furthermore, the\nbilevel nature of the optimization acts as a kind of regularization on the\ntarget, mitigating overfitting. SOSELETO may be applied to both classic\ntransfer learning, as well as the problem of training on datasets with noisy\nlabels; we show state of the art results on both of these problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 12:03:58 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 15:41:44 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Litany", "Or", ""], ["Freedman", "Daniel", ""]]}, {"id": "1805.09639", "submitter": "Damien Scieur", "authors": "Damien Scieur, Edouard Oyallon, Alexandre d'Aspremont and Francis Bach", "title": "Online Regularized Nonlinear Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized nonlinear acceleration (RNA) estimates the minimum of a function\nby post-processing iterates from an algorithm such as the gradient method. It\ncan be seen as a regularized version of Anderson acceleration, a classical\nacceleration scheme from numerical analysis. The new scheme provably improves\nthe rate of convergence of fixed step gradient descent, and its empirical\nperformance is comparable to that of quasi-Newton methods. However, RNA cannot\naccelerate faster multistep algorithms like Nesterov's method and often\ndiverges in this context. Here, we adapt RNA to overcome these issues, so that\nour scheme can be used on fast algorithms such as gradient methods with\nmomentum. We show optimal complexity bounds for quadratics and asymptotically\noptimal rates on general convex minimization problems. Moreover, this new\nscheme works online, i.e., extrapolated solution estimates can be reinjected at\neach iteration, significantly improving numerical performance over classical\naccelerated methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 12:49:13 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 18:56:01 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Scieur", "Damien", ""], ["Oyallon", "Edouard", ""], ["d'Aspremont", "Alexandre", ""], ["Bach", "Francis", ""]]}, {"id": "1805.09653", "submitter": "Jay Heo", "authors": "Jay Heo, Hae Beom Lee, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho\n  Yang, and Sung Ju Hwang", "title": "Uncertainty-Aware Attention for Reliable Interpretation and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism is effective in both focusing the deep learning models on\nrelevant features and interpreting them. However, attentions may be unreliable\nsince the networks that generate them are often trained in a weakly-supervised\nmanner. To overcome this limitation, we introduce the notion of input-dependent\nuncertainty to the attention mechanism, such that it generates attention for\neach feature with varying degrees of noise based on the given input, to learn\nlarger variance on instances it is uncertain about. We learn this\nUncertainty-aware Attention (UA) mechanism using variational inference, and\nvalidate it on various risk prediction tasks from electronic health records on\nwhich our model significantly outperforms existing attention models. The\nanalysis of the learned attentions shows that our model generates attentions\nthat comply with clinicians' interpretation, and provide richer interpretation\nvia learned variance. Further evaluation of both the accuracy of the\nuncertainty calibration and the prediction performance with \"I don't know\"\ndecision show that UA yields networks with high reliability as well.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 13:17:08 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Heo", "Jay", ""], ["Lee", "Hae Beom", ""], ["Kim", "Saehoon", ""], ["Lee", "Juho", ""], ["Kim", "Kwang Joon", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1805.09654", "submitter": "Thomas Moreau", "authors": "Tom Dupr\\'e La Tour, Thomas Moreau, Mainak Jas and Alexandre Gramfort", "title": "Multivariate Convolutional Sparse Coding for Electromagnetic Brain\n  Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency-specific patterns of neural activity are traditionally interpreted\nas sustained rhythmic oscillations, and related to cognitive mechanisms such as\nattention, high level visual processing or motor control. While alpha waves\n(8-12 Hz) are known to closely resemble short sinusoids, and thus are revealed\nby Fourier analysis or wavelet transforms, there is an evolving debate that\nelectromagnetic neural signals are composed of more complex waveforms that\ncannot be analyzed by linear filters and traditional signal representations. In\nthis paper, we propose to learn dedicated representations of such recordings\nusing a multivariate convolutional sparse coding (CSC) algorithm. Applied to\nelectroencephalography (EEG) or magnetoencephalography (MEG) data, this method\nis able to learn not only prototypical temporal waveforms, but also associated\nspatial patterns so their origin can be localized in the brain. Our algorithm\nis based on alternated minimization and a greedy coordinate descent solver that\nleads to state-of-the-art running time on long time series. To demonstrate the\nimplications of this method, we apply it to MEG data and show that it is able\nto recover biological artifacts. More remarkably, our approach also reveals the\npresence of non-sinusoidal mu-shaped patterns, along with their topographic\nmaps related to the somatosensory cortex.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 13:26:12 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 16:55:03 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["La Tour", "Tom Dupr\u00e9", ""], ["Moreau", "Thomas", ""], ["Jas", "Mainak", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1805.09657", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Anand Singh, Kris Korrel, German Kruszewski, Elia\n  Bruni", "title": "Learning compositionally through attentive guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural network models have been successfully applied to domains that\nrequire substantial generalisation skills, recent studies have implied that\nthey struggle when solving the task they are trained on requires inferring its\nunderlying compositional structure. In this paper, we introduce Attentive\nGuidance, a mechanism to direct a sequence to sequence model equipped with\nattention to find more compositional solutions. We test it on two tasks,\ndevised precisely to assess the compositional capabilities of neural models,\nand we show that vanilla sequence to sequence models with attention overfit the\ntraining distribution, while the guided versions come up with compositional\nsolutions that fit the training and testing distributions almost equally well.\nMoreover, the learned solutions generalise even in cases where the training and\ntesting distributions strongly diverge. In this way, we demonstrate that\nsequence to sequence models are capable of finding compositional solutions\nwithout requiring extra components. These results helps to disentangle the\ncauses for the lack of systematic compositionality in neural networks, which\ncan in turn fuel future work.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 10:33:00 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 09:46:30 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 12:02:27 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 12:41:30 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Singh", "Anand", ""], ["Korrel", "Kris", ""], ["Kruszewski", "German", ""], ["Bruni", "Elia", ""]]}, {"id": "1805.09692", "submitter": "Sam Ritter", "authors": "Samuel Ritter, Jane X. Wang, Zeb Kurth-Nelson, Siddhant M. Jayakumar,\n  Charles Blundell, Razvan Pascanu, Matthew Botvinick", "title": "Been There, Done That: Meta-Learning with Episodic Recall", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning agents excel at rapidly learning new tasks from open-ended task\ndistributions; yet, they forget what they learn about each task as soon as the\nnext begins. When tasks reoccur - as they do in natural environments -\nmetalearning agents must explore again instead of immediately exploiting\npreviously discovered solutions. We propose a formalism for generating\nopen-ended yet repetitious environments, then develop a meta-learning\narchitecture for solving these environments. This architecture melds the\nstandard LSTM working memory with a differentiable neural episodic memory. We\nexplore the capabilities of agents with this episodic LSTM in five\nmeta-learning environments with reoccurring tasks, ranging from bandits to\nnavigation and stochastic sequential decision problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:15:27 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 14:59:58 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ritter", "Samuel", ""], ["Wang", "Jane X.", ""], ["Kurth-Nelson", "Zeb", ""], ["Jayakumar", "Siddhant M.", ""], ["Blundell", "Charles", ""], ["Pascanu", "Razvan", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1805.09701", "submitter": "Pan Lu", "authors": "Pan Lu, Lei Ji, Wei Zhang, Nan Duan, Ming Zhou, Jianyong Wang", "title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual\n  Question Answering", "comments": "10 pages, 5 figures, accepted as an oral paper in SIGKDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3220036", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Visual Question Answering (VQA) has emerged as one of the most\nsignificant tasks in multimodal learning as it requires understanding both\nvisual and textual modalities. Existing methods mainly rely on extracting image\nand question features to learn their joint feature embedding via multimodal\nfusion or attention mechanism. Some recent studies utilize external\nVQA-independent models to detect candidate entities or attributes in images,\nwhich serve as semantic knowledge complementary to the VQA task. However, these\ncandidate entities or attributes might be unrelated to the VQA task and have\nlimited semantic capacities. To better utilize semantic knowledge in images, we\npropose a novel framework to learn visual relation facts for VQA. Specifically,\nwe build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset\nvia a semantic similarity module, in which each data consists of an image, a\ncorresponding question, a correct answer and a supporting relation fact. A\nwell-defined relation detector is then adopted to predict visual\nquestion-related relation facts. We further propose a multi-step attention\nmodel composed of visual attention and semantic attention sequentially to\nextract related visual knowledge and semantic knowledge. We conduct\ncomprehensive experiments on the two benchmark datasets, demonstrating that our\nmodel achieves state-of-the-art performance and verifying the benefit of\nconsidering visual relation facts.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:43:30 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 03:45:04 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Lu", "Pan", ""], ["Ji", "Lei", ""], ["Zhang", "Wei", ""], ["Duan", "Nan", ""], ["Zhou", "Ming", ""], ["Wang", "Jianyong", ""]]}, {"id": "1805.09717", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Andr\\'e F. T. Martins, Vlad Niculae", "title": "Learning Classifiers with Fenchel-Young Losses: Generalized Entropies,\n  Margins, and Algorithms", "comments": "In proceedings of AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies Fenchel-Young losses, a generic way to construct convex\nloss functions from a regularization function. We analyze their properties in\ndepth, showing that they unify many well-known loss functions and allow to\ncreate useful new ones easily. Fenchel-Young losses constructed from a\ngeneralized entropy, including the Shannon and Tsallis entropies, induce\npredictive probability distributions. We formulate conditions for a generalized\nentropy to yield losses with a separation margin, and probability distributions\nwith sparse support. Finally, we derive efficient algorithms, making\nFenchel-Young losses appealing both in theory and practice.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:05:49 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 11:31:33 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 08:50:50 GMT"}, {"version": "v4", "created": "Fri, 22 Feb 2019 05:59:09 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Blondel", "Mathieu", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Niculae", "Vlad", ""]]}, {"id": "1805.09719", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb, Eran Kaufman, Aryeh Kontorovich, Gabriel Nivasch", "title": "Learning convex polytopes with margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved algorithm for properly learning convex polytopes in\nthe realizable PAC setting from data with a margin. Our learning algorithm\nconstructs a consistent polytope as an intersection of about $t \\log t$\nhalfspaces with margins in time polynomial in $t$ (where $t$ is the number of\nhalfspaces forming an optimal polytope).\n  We also identify distinct generalizations of the notion of margin from\nhyperplanes to polytopes and investigate how they relate geometrically; this\nresult may be of interest beyond the learning setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:07:14 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 13:29:21 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kaufman", "Eran", ""], ["Kontorovich", "Aryeh", ""], ["Nivasch", "Gabriel", ""]]}, {"id": "1805.09733", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Yarin Gal", "title": "Towards Robust Evaluations of Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments used in current continual learning research do not faithfully\nassess fundamental challenges of learning continually. Instead of assessing\nperformance on challenging and representative experiment designs, recent\nresearch has focused on increased dataset difficulty, while still using flawed\nexperiment set-ups. We examine standard evaluations and show why these\nevaluations make some continual learning approaches look better than they are.\nWe introduce desiderata for continual learning evaluations and explain why\ntheir absence creates misleading comparisons. Based on our desiderata we then\npropose new experiment designs which we demonstrate with various continual\nlearning approaches and datasets. Our analysis calls for a reprioritization of\nresearch effort by the community.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:38:07 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 16:37:46 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 16:34:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Gal", "Yarin", ""]]}, {"id": "1805.09757", "submitter": "Zhe Jiang", "authors": "Miao Xie, Zhe Jiang, Arpan Man Sainju", "title": "Geographical Hidden Markov Tree for Flood Extent Mapping (With Proof\n  Appendix)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flood extent mapping plays a crucial role in disaster management and national\nwater forecasting. Unfortunately, traditional classification methods are often\nhampered by the existence of noise, obstacles and heterogeneity in spectral\nfeatures as well as implicit anisotropic spatial dependency across class\nlabels. In this paper, we propose geographical hidden Markov tree, a\nprobabilistic graphical model that generalizes the common hidden Markov model\nfrom a one dimensional sequence to a two dimensional map. Anisotropic spatial\ndependency is incorporated in the hidden class layer with a reverse tree\nstructure. We also investigate computational algorithms for reverse tree\nconstruction, model parameter learning and class inference. Extensive\nevaluations on both synthetic and real world datasets show that proposed model\noutperforms multiple baselines in flood mapping, and our algorithms are\nscalable on large data sizes.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:21:11 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Xie", "Miao", ""], ["Jiang", "Zhe", ""], ["Sainju", "Arpan Man", ""]]}, {"id": "1805.09767", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich", "title": "Local SGD Converges Fast and Communicates Little", "comments": "to appear at ICLR 2019, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch stochastic gradient descent (SGD) is state of the art in large\nscale distributed training. The scheme can reach a linear speedup with respect\nto the number of workers, but this is rarely seen in practice as the scheme\noften suffers from large network delays and bandwidth limits. To overcome this\ncommunication bottleneck recent works propose to reduce the communication\nfrequency. An algorithm of this type is local SGD that runs SGD independently\nin parallel on different workers and averages the sequences only once in a\nwhile.\n  This scheme shows promising results in practice, but eluded thorough\ntheoretical analysis. We prove concise convergence rates for local SGD on\nconvex problems and show that it converges at the same rate as mini-batch SGD\nin terms of number of evaluated gradients, that is, the scheme achieves linear\nspeedup in the number of workers and mini-batch size. The number of\ncommunication rounds can be reduced up to a factor of T^{1/2}---where T denotes\nthe number of total steps---compared to mini-batch SGD. This also holds for\nasynchronous implementations. Local SGD can also be used for large scale\ntraining of deep learning models.\n  The results shown here aim serving as a guideline to further explore the\ntheoretical and practical aspects of local SGD in these applications.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:38:51 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 08:19:47 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 12:58:04 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Stich", "Sebastian U.", ""]]}, {"id": "1805.09772", "submitter": "Hamid Tizhoosh", "authors": "Graham Bleaney, Matthew Kuzyk, Julian Man, Hossein Mayanloo,\n  H.R.Tizhoosh", "title": "Auto-Detection of Safety Issues in Baby Products", "comments": "To appear in proceedings of The 31st IEA-AIE 2018, June 25-28, 2018,\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year, thousands of people receive consumer product related injuries.\nResearch indicates that online customer reviews can be processed to\nautonomously identify product safety issues. Early identification of safety\nissues can lead to earlier recalls, and thus fewer injuries and deaths. A\ndataset of product reviews from Amazon.com was compiled, along with\n\\emph{SaferProducts.gov} complaints and recall descriptions from the Consumer\nProduct Safety Commission (CPSC) and European Commission Rapid Alert system. A\nsystem was built to clean the collected text and to extract relevant features.\nDimensionality reduction was performed by computing feature relevance through a\nRandom Forest and discarding features with low information gain. Various\nclassifiers were analyzed, including Logistic Regression, SVMs,\nNa{\\\"i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentation\nwith various features and classifier combinations resulted in a logistic\nregression model with 66\\% precision in the top 50 reviews surfaced. This\nclassifier outperforms all benchmarks set by related literature and consumer\nproduct safety professionals.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:33:50 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 23:43:59 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bleaney", "Graham", ""], ["Kuzyk", "Matthew", ""], ["Man", "Julian", ""], ["Mayanloo", "Hossein", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1805.09781", "submitter": "Virginia Aglietti", "authors": "Virginia Aglietti, Theodoros Damoulas, Edwin Bonilla", "title": "Efficient Inference in Multi-task Cox Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the log Gaussian Cox process (LGCP) framework to model multiple\ncorrelated point data jointly. The observations are treated as realizations of\nmultiple LGCPs, whose log intensities are given by linear combinations of\nlatent functions drawn from Gaussian process priors. The combination\ncoefficients are also drawn from Gaussian processes and can incorporate\nadditional dependencies. We derive closed-form expressions for the moments of\nthe intensity functions and develop an efficient variational inference\nalgorithm that is orders of magnitude faster than competing deterministic and\nstochastic approximations of multivariate LGCP, coregionalization models, and\nmulti-task permanental processes. Our approach outperforms these benchmarks in\nmultiple problems, offering the current state of the art in modeling\nmultivariate point processes.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:01:34 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 23:32:03 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 17:29:55 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Aglietti", "Virginia", ""], ["Damoulas", "Theodoros", ""], ["Bonilla", "Edwin", ""]]}, {"id": "1805.09785", "submitter": "Marylou Gabri\\'e", "authors": "Marylou Gabri\\'e, Andre Manoel, Cl\\'ement Luneau, Jean Barbier,\n  Nicolas Macris, Florent Krzakala, Lenka Zdeborov\\'a", "title": "Entropy and mutual information in models of deep neural networks", "comments": null, "journal-ref": "J. Stat. Mech. (2019) 124014. & NeurIPS 2018", "doi": "10.1088/1742-5468/ab3430", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a class of deep learning models with a tractable method to compute\ninformation-theoretic quantities. Our contributions are three-fold: (i) We show\nhow entropies and mutual informations can be derived from heuristic statistical\nphysics methods, under the assumption that weight matrices are independent and\northogonally-invariant. (ii) We extend particular cases in which this result is\nknown to be rigorously exact by providing a proof for two-layers networks with\nGaussian random weights, using the recently introduced adaptive interpolation\nmethod. (iii) We propose an experiment framework with generative models of\nsynthetic datasets, on which we train deep neural networks with a weight\nconstraint designed so that the assumption in (i) is verified during learning.\nWe study the behavior of entropies and mutual informations throughout learning\nand conclude that, in the proposed setting, the relationship between\ncompression and generalization remains elusive.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:07:45 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 19:42:49 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gabri\u00e9", "Marylou", ""], ["Manoel", "Andre", ""], ["Luneau", "Cl\u00e9ment", ""], ["Barbier", "Jean", ""], ["Macris", "Nicolas", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1805.09791", "submitter": "Xiaoxi He", "authors": "Xiaoxi He, Zimu Zhou, Lothar Thiele", "title": "Multi-Task Zipping via Layer-wise Neuron Sharing", "comments": "Published as a conference paper at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future mobile devices are anticipated to perceive, understand and react to\nthe world on their own by running multiple correlated deep neural networks\non-device. Yet the complexity of these neural networks needs to be trimmed down\nboth within-model and cross-model to fit in mobile storage and memory. Previous\nstudies focus on squeezing the redundancy within a single neural network. In\nthis work, we aim to reduce the redundancy across multiple models. We propose\nMulti-Task Zipping (MTZ), a framework to automatically merge correlated,\npre-trained deep neural networks for cross-model compression. Central in MTZ is\na layer-wise neuron sharing and incoming weight updating scheme that induces a\nminimal change in the error function. MTZ inherits information from each model\nand demands light retraining to re-boost the accuracy of individual tasks.\nEvaluations show that MTZ is able to fully merge the hidden layers of two\nVGG-16 networks with a 3.18% increase in the test error averaged on ImageNet\nand CelebA, or share 39.61% parameters between the two networks with <0.5%\nincrease in the test errors for both tasks. The number of iterations to retrain\nthe combined network is at least 17.8 times lower than that of training a\nsingle VGG-16 network. Moreover, experiments show that MTZ is also able to\neffectively merge multiple residual networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:33:38 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:05:31 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["He", "Xiaoxi", ""], ["Zhou", "Zimu", ""], ["Thiele", "Lothar", ""]]}, {"id": "1805.09793", "submitter": "Sharan Vaswani", "authors": "Sharan Vaswani, Branislav Kveton, Zheng Wen, Anup Rao, Mark Schmidt,\n  Yasin Abbasi-Yadkori", "title": "New Insights into Bootstrapping for Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of bootstrapping in the bandit setting. We first show\nthat the commonly used non-parametric bootstrapping (NPB) procedure can be\nprovably inefficient and establish a near-linear lower bound on the regret\nincurred by it under the bandit model with Bernoulli rewards. We show that NPB\nwith an appropriate amount of forced exploration can result in sub-linear\nalbeit sub-optimal regret. As an alternative to NPB, we propose a weighted\nbootstrapping (WB) procedure. For Bernoulli rewards, WB with multiplicative\nexponential weights is mathematically equivalent to Thompson sampling (TS) and\nresults in near-optimal regret bounds. Similarly, in the bandit setting with\nGaussian rewards, we show that WB with additive Gaussian weights achieves\nnear-optimal regret. Beyond these special cases, we show that WB leads to\nbetter empirical performance than TS for several reward distributions bounded\non $[0,1]$. For the contextual bandit setting, we give practical guidelines\nthat make bootstrapping simple and efficient to implement and result in good\nempirical performance on real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:37:17 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Vaswani", "Sharan", ""], ["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Rao", "Anup", ""], ["Schmidt", "Mark", ""], ["Abbasi-Yadkori", "Yasin", ""]]}, {"id": "1805.09801", "submitter": "Zhongwen Xu", "authors": "Zhongwen Xu, Hado van Hasselt, David Silver", "title": "Meta-Gradient Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of reinforcement learning algorithms is to estimate and/or optimise\nthe value function. However, unlike supervised learning, no teacher or oracle\nis available to provide the true value function. Instead, the majority of\nreinforcement learning algorithms estimate and/or optimise a proxy for the\nvalue function. This proxy is typically based on a sampled and bootstrapped\napproximation to the true value function, known as a return. The particular\nchoice of return is one of the chief components determining the nature of the\nalgorithm: the rate at which future rewards are discounted; when and how values\nshould be bootstrapped; or even the nature of the rewards themselves. It is\nwell-known that these decisions are crucial to the overall success of RL\nalgorithms. We discuss a gradient-based meta-learning algorithm that is able to\nadapt the nature of the return, online, whilst interacting and learning from\nthe environment. When applied to 57 games on the Atari 2600 environment over\n200 million frames, our algorithm achieved a new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:45:11 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Xu", "Zhongwen", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""]]}, {"id": "1805.09804", "submitter": "Alireza Makhzani", "authors": "Alireza Makhzani", "title": "Implicit Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the \"implicit autoencoder\" (IAE), a generative\nautoencoder in which both the generative path and the recognition path are\nparametrized by implicit distributions. We use two generative adversarial\nnetworks to define the reconstruction and the regularization cost functions of\nthe implicit autoencoder, and derive the learning rules based on\nmaximum-likelihood learning. Using implicit distributions allows us to learn\nmore expressive posterior and conditional likelihood distributions for the\nautoencoder. Learning an expressive conditional likelihood distribution enables\nthe latent code to only capture the abstract and high-level information of the\ndata, while the remaining low-level information is captured by the implicit\nconditional likelihood distribution. We show the applications of implicit\nautoencoders in disentangling content and style information, clustering,\nsemi-supervised classification, learning expressive variational distributions,\nand multimodal image-to-image translation from unpaired data.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:46:43 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 03:40:18 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Makhzani", "Alireza", ""]]}, {"id": "1805.09843", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Guoyin Wang, Wenlin Wang, Martin Renqiang Min, Qinliang\n  Su, Yizhe Zhang, Chunyuan Li, Ricardo Henao, Lawrence Carin", "title": "Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n  Associated Pooling Mechanisms", "comments": "To appear at ACL 2018 (code: https://github.com/dinghanshen/SWEM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning architectures have been proposed to model the\ncompositionality in text sequences, requiring a substantial number of\nparameters and expensive computations. However, there has not been a rigorous\nevaluation regarding the added value of sophisticated compositional functions.\nIn this paper, we conduct a point-by-point comparative study between Simple\nWord-Embedding-based Models (SWEMs), consisting of parameter-free pooling\noperations, relative to word-embedding-based RNN/CNN models. Surprisingly,\nSWEMs exhibit comparable or even superior performance in the majority of cases\nconsidered. Based upon this understanding, we propose two additional pooling\nstrategies over learned word embeddings: (i) a max-pooling operation for\nimproved interpretability; and (ii) a hierarchical pooling operation, which\npreserves spatial (n-gram) information within text sequences. We present\nexperiments on 17 datasets encompassing three tasks: (i) (long) document\nclassification; (ii) text sequence matching; and (iii) short text tasks,\nincluding classification and tagging. The source code and datasets can be\nobtained from https:// github.com/dinghanshen/SWEM.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 18:27:21 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Shen", "Dinghan", ""], ["Wang", "Guoyin", ""], ["Wang", "Wenlin", ""], ["Min", "Martin Renqiang", ""], ["Su", "Qinliang", ""], ["Zhang", "Yizhe", ""], ["Li", "Chunyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1805.09864", "submitter": "Zhengwei Wu", "authors": "Zhengwei Wu, Paul Schrater, Xaq Pitkow", "title": "Inverse Rational Control: Inferring What You Think from How You Forage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex behaviors are often driven by an internal model, which integrates\nsensory information over time and facilitates long-term planning. Inferring an\nagent's internal model is a crucial ingredient in social interactions (theory\nof mind), for imitation learning, and for interpreting neural activities of\nbehaving agents. Here we describe a generic method to model an agent's behavior\nunder an environment with uncertainty, and infer the agent's internal model,\nreward function, and dynamic beliefs. We apply our method to a simulated agent\nperforming a naturalistic foraging task. We assume the agent behaves rationally\n--- that is, they take actions that optimize their subjective utility according\nto their understanding of the task and its relevant causal variables. We model\nthis rational solution as a Partially Observable Markov Decision Process\n(POMDP) where the agent may make wrong assumptions about the task parameters.\nGiven the agent's sensory observations and actions, we learn its internal model\nand reward function by maximum likelihood estimation over a set of\ntask-relevant parameters. The Markov property of the POMDP enables us to\ncharacterize the transition probabilities between internal belief states and\niteratively estimate the agent's policy using a constrained\nExpectation-Maximization (EM) algorithm. We validate our method on simulated\nagents performing suboptimally on a foraging task currently used in many\nneuroscience experiments, and successfully recover their internal model and\nreward function. Our work lays a critical foundation to discover how the brain\nrepresents and computes with dynamic beliefs.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 19:36:12 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 15:18:53 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2018 04:41:28 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 19:59:06 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Wu", "Zhengwei", ""], ["Schrater", "Paul", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1805.09874", "submitter": "Aleksandr Aravkin", "authors": "German Abrevaya, Irina Rish, Aleksandr Y. Aravkin, Guillermo Cecchi,\n  James Kozloski, Pablo Polosecki, Peng Zheng, Silvina Ponce Dawson, Juliana\n  Rhee, David Cox", "title": "Learning Nonlinear Brain Dynamics: van der Pol Meets LSTM", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world data sets, especially in biology, are produced by complex\nnonlinear dynamical systems. In this paper, we focus on brain calcium imaging\n(CaI) of different organisms (zebrafish and rat), aiming to build a model of\njoint activation dynamics in large neuronal populations, including the whole\nbrain of zebrafish. We propose a new approach for capturing dynamics of\ntemporal SVD components that uses the coupled (multivariate) van der Pol (VDP)\noscillator, a nonlinear ordinary differential equation (ODE) model describing\nneural activity, with a new parameter estimation technique that combines\nvariable projection optimization and stochastic search. We show that the\napproach successfully handles nonlinearities and hidden state variables in the\ncoupled VDP. The approach is accurate, achieving 0.82 to 0.94 correlation\nbetween the actual and model-generated components, and interpretable, as VDP's\ncoupling matrix reveals anatomically meaningful positive (excitatory) and\nnegative (inhibitory) interactions across different brain subsystems\ncorresponding to spatial SVD components. Moreover, VDP is comparable to (or\nsometimes better than) recurrent neural networks (LSTM) for (short-term)\nprediction of future brain activity; VDP needs less parameters to train, which\nwas a plus on our small training data. Finally, the overall best predictive\nmethod, greatly outperforming both VDP and LSTM in short- and long-term\npredictive settings on both datasets, was the new hybrid VDP-LSTM approach that\nused VDP to simulate large domain-specific dataset for LSTM pretraining; note\nthat simple LSTM data-augmentation via noisy versions of training data was much\nless effective.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 19:58:37 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 02:03:39 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Abrevaya", "German", ""], ["Rish", "Irina", ""], ["Aravkin", "Aleksandr Y.", ""], ["Cecchi", "Guillermo", ""], ["Kozloski", "James", ""], ["Polosecki", "Pablo", ""], ["Zheng", "Peng", ""], ["Dawson", "Silvina Ponce", ""], ["Rhee", "Juliana", ""], ["Cox", "David", ""]]}, {"id": "1805.09898", "submitter": "Kin Sum Liu", "authors": "Kin Sum Liu, Chaowei Xiao, Bo Li, Jie Gao", "title": "Performing Co-Membership Attacks Against Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new membership attack method called co-membership\nattacks against deep generative models including Variational Autoencoders\n(VAEs) and Generative Adversarial Networks (GANs). Specifically, membership\nattack aims to check whether a given instance x was used in the training data\nor not. A co-membership attack checks whether the given bundle of n instances\nwere in the training, with the prior knowledge that the bundle was either\nentirely used in the training or none at all. Successful membership attacks can\ncompromise the privacy of training data when the generative model is published.\nOur main idea is to cast membership inference of target data x as the\noptimization of another neural network (called the attacker network) to search\nfor the latent encoding to reproduce x. The final reconstruction error is used\ndirectly to conclude whether x was in the training data or not. We conduct\nextensive experiments on a variety of datasets and generative models showing\nthat: our attacker network outperforms prior membership attacks; co-membership\nattacks can be substantially more powerful than single attacks; and VAEs are\nmore susceptible to membership attacks compared to GANs.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:06:36 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 17:41:21 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 07:43:40 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Liu", "Kin Sum", ""], ["Xiao", "Chaowei", ""], ["Li", "Bo", ""], ["Gao", "Jie", ""]]}, {"id": "1805.09909", "submitter": "Kush Varshney", "authors": "Bernat Guillen Pegueroles, Bhanukiran Vinzamuri, Karthikeyan\n  Shanmugam, Steve Hedden, Jonathan D. Moyer, and Kush R. Varshney", "title": "Structure Learning from Time Series with False Discovery Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Granger causal structure learning problem from time series\ndata. Granger causal algorithms predict a 'Granger causal effect' between two\nvariables by testing if prediction error of one decreases significantly in the\nabsence of the other variable among the predictor covariates. Almost all\nexisting Granger causal algorithms condition on a large number of variables\n(all but two variables) to test for effects between a pair of variables. We\npropose a new structure learning algorithm called MMPC-p inspired by the well\nknown MMHC algorithm for non-time series data. We show that under some\nassumptions, the algorithm provides false discovery rate control. The algorithm\nis sound and complete when given access to perfect directed information testing\noracles. We also outline a novel tester for the linear Gaussian case. We show\nthrough our extensive experiments that the MMPC-p algorithm scales to larger\nproblems and has improved statistical power compared to existing state of the\nart for large sparse graphs. We also apply our algorithm on a global\ndevelopment dataset and validate our findings with subject matter experts.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:34:17 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Pegueroles", "Bernat Guillen", ""], ["Vinzamuri", "Bhanukiran", ""], ["Shanmugam", "Karthikeyan", ""], ["Hedden", "Steve", ""], ["Moyer", "Jonathan D.", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1805.09910", "submitter": "Kush Varshney", "authors": "Prasanna Sattigeri, Samuel C. Hoffman, Vijil Chenthamarakshan, and\n  Kush R. Varshney", "title": "Fairness GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Fairness GAN, an approach for generating a\ndataset that is plausibly similar to a given multimedia dataset, but is more\nfair with respect to protected attributes in allocative decision making. We\npropose a novel auxiliary classifier GAN that strives for demographic parity or\nequality of opportunity and show empirical results on several datasets,\nincluding the CelebFaces Attributes (CelebA) dataset, the Quick, Draw!\\\ndataset, and a dataset of soccer player images and the offenses they were\ncalled for. The proposed formulation is well-suited to absorbing unlabeled\ndata; we leverage this to augment the soccer dataset with the much larger\nCelebA dataset. The methodology tends to improve demographic parity and\nequality of opportunity while generating plausible images.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:34:55 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Sattigeri", "Prasanna", ""], ["Hoffman", "Samuel C.", ""], ["Chenthamarakshan", "Vijil", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1805.09916", "submitter": "Mike Gartrell", "authors": "Romain Warlop, J\\'er\\'emie Mary, Mike Gartrell", "title": "Multi-Task Determinantal Point Processes for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) have received significant attention in\nthe recent years as an elegant model for a variety of machine learning tasks,\ndue to their ability to elegantly model set diversity and item quality or\npopularity. Recent work has shown that DPPs can be effective models for product\nrecommendation and basket completion tasks. We present an enhanced DPP model\nthat is specialized for the task of basket completion, the multi-task DPP. We\nview the basket completion problem as a multi-class classification problem, and\nleverage ideas from tensor factorization and multi-class classification to\ndesign the multi-task DPP model. We evaluate our model on several real-world\ndatasets, and find that the multi-task DPP provides significantly better\npredictive quality than a number of state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:59:31 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 15:58:55 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Warlop", "Romain", ""], ["Mary", "J\u00e9r\u00e9mie", ""], ["Gartrell", "Mike", ""]]}, {"id": "1805.09921", "submitter": "Matthias Bauer", "authors": "Jonathan Gordon, John Bronskill, Matthias Bauer, Sebastian Nowozin,\n  and Richard E. Turner", "title": "Meta-Learning Probabilistic Inference For Prediction", "comments": "International Conference on Learning Representations (ICLR) 2019", "journal-ref": "International Conference on Learning Representations (2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new framework for data efficient and versatile\nlearning. Specifically: 1) We develop ML-PIP, a general framework for\nMeta-Learning approximate Probabilistic Inference for Prediction. ML-PIP\nextends existing probabilistic interpretations of meta-learning to cover a\nbroad class of methods. 2) We introduce VERSA, an instance of the framework\nemploying a flexible and versatile amortization network that takes few-shot\nlearning datasets as inputs, with arbitrary numbers of shots, and outputs a\ndistribution over task-specific parameters in a single forward pass. VERSA\nsubstitutes optimization at test time with forward passes through inference\nnetworks, amortizing the cost of inference and relieving the need for second\nderivatives during training. 3) We evaluate VERSA on benchmark datasets where\nthe method sets new state-of-the-art results, handles arbitrary numbers of\nshots, and for classification, arbitrary numbers of classes at train and test\ntime. The power of the approach is then demonstrated through a challenging\nfew-shot ShapeNet view reconstruction task.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 22:08:27 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 21:37:48 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 11:14:21 GMT"}, {"version": "v4", "created": "Tue, 6 Aug 2019 15:16:42 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Gordon", "Jonathan", ""], ["Bronskill", "John", ""], ["Bauer", "Matthias", ""], ["Nowozin", "Sebastian", ""], ["Turner", "Richard E.", ""]]}, {"id": "1805.09934", "submitter": "Songze Li", "authors": "Songze Li, Seyed Mohammadreza Mousavi Kalan, Qian Yu, Mahdi\n  Soltanolkotabi, A. Salman Avestimehr", "title": "Polynomially Coded Regression: Optimal Straggler Mitigation via Data\n  Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training a least-squares regression model on a\nlarge dataset using gradient descent. The computation is carried out on a\ndistributed system consisting of a master node and multiple worker nodes. Such\ndistributed systems are significantly slowed down due to the presence of\nslow-running machines (stragglers) as well as various communication\nbottlenecks. We propose \"polynomially coded regression\" (PCR) that\nsubstantially reduces the effect of stragglers and lessens the communication\nburden in such systems. The key idea of PCR is to encode the partial data\nstored at each worker, such that the computations at the workers can be viewed\nas evaluating a polynomial at distinct points. This allows the master to\ncompute the final gradient by interpolating this polynomial. PCR significantly\nreduces the recovery threshold, defined as the number of workers the master has\nto wait for prior to computing the gradient. In particular, PCR requires a\nrecovery threshold that scales inversely proportionally with the amount of\ncomputation/storage available at each worker. In comparison, state-of-the-art\nstraggler-mitigation schemes require a much higher recovery threshold that only\ndecreases linearly in the per worker computation/storage load. We prove that\nPCR's recovery threshold is near minimal and within a factor two of the best\npossible scheme. Our experiments over Amazon EC2 demonstrate that compared with\nstate-of-the-art schemes, PCR improves the run-time by 1.50x ~ 2.36x with\nnaturally occurring stragglers, and by as much as 2.58x ~ 4.29x with artificial\nstragglers.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 23:59:20 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Li", "Songze", ""], ["Kalan", "Seyed Mohammadreza Mousavi", ""], ["Yu", "Qian", ""], ["Soltanolkotabi", "Mahdi", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1805.09938", "submitter": "Francesco Leofante", "authors": "Francesco Leofante, Nina Narodytska, Luca Pulina, Armando Tacchella", "title": "Automated Verification of Neural Networks: Advances, Challenges and\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are one of the most investigated and widely used techniques\nin Machine Learning. In spite of their success, they still find limited\napplication in safety- and security-related contexts, wherein assurance about\nnetworks' performances must be provided. In the recent past, automated\nreasoning techniques have been proposed by several researchers to close the gap\nbetween neural networks and applications requiring formal guarantees about\ntheir behavior. In this work, we propose a primer of such techniques and a\ncomprehensive categorization of existing approaches for the automated\nverification of neural networks. A discussion about current limitations and\ndirections for future investigation is provided to foster research on this\ntopic at the crossroads of Machine Learning and Automated Reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 00:19:57 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Leofante", "Francesco", ""], ["Narodytska", "Nina", ""], ["Pulina", "Luca", ""], ["Tacchella", "Armando", ""]]}, {"id": "1805.09943", "submitter": "Tyler Hughes", "authors": "Tyler W. Hughes, Momchil Minkov, Yu Shi, Shanhui Fan", "title": "Training of photonic neural networks through in situ backpropagation", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": "10.1364/OPTICA.5.000864", "report-no": null, "categories": "physics.optics cs.LG cs.NE physics.app-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, integrated optics has gained interest as a hardware platform for\nimplementing machine learning algorithms. Of particular interest are artificial\nneural networks, since matrix-vector multi- plications, which are used heavily\nin artificial neural networks, can be done efficiently in photonic circuits.\nThe training of an artificial neural network is a crucial step in its\napplication. However, currently on the integrated photonics platform there is\nno efficient protocol for the training of these networks. In this work, we\nintroduce a method that enables highly efficient, in situ training of a\nphotonic neural network. We use adjoint variable methods to derive the photonic\nanalogue of the backpropagation algorithm, which is the standard method for\ncomputing gradients of conventional neural networks. We further show how these\ngradients may be obtained exactly by performing intensity measurements within\nthe device. As an application, we demonstrate the training of a numerically\nsimulated photonic artificial neural network. Beyond the training of photonic\nmachine learning implementations, our method may also be of broad interest to\nexperimental sensitivity analysis of photonic systems and the optimization of\nreconfigurable optics platforms.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 01:24:05 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Hughes", "Tyler W.", ""], ["Minkov", "Momchil", ""], ["Shi", "Yu", ""], ["Fan", "Shanhui", ""]]}, {"id": "1805.09949", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Karthikeyan Natesan Ramamurthy and Kush R. Varshney and Krishnan Mody", "title": "Topological Data Analysis of Decision Boundaries with Application to\n  Model Selection", "comments": "Reproducible software available, 17 pages, 10 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the labeled \\v{C}ech complex, the plain labeled Vietoris-Rips\ncomplex, and the locally scaled labeled Vietoris-Rips complex to perform\npersistent homology inference of decision boundaries in classification tasks.\nWe provide theoretical conditions and analysis for recovering the homology of a\ndecision boundary from samples. Our main objective is quantification of deep\nneural network complexity to enable matching of datasets to pre-trained models;\nwe report results for experiments using MNIST, FashionMNIST, and CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 02:02:45 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ramamurthy", "Karthikeyan Natesan", ""], ["Varshney", "Kush R.", ""], ["Mody", "Krishnan", ""]]}, {"id": "1805.09964", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Willie Neiswanger, Reed Zhang, Akshay\n  Krishnamurthy, Jeff Schneider, Barnabas Poczos", "title": "Myopic Bayesian Design of Experiments via Posterior Sampling and\n  Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new myopic strategy for a wide class of sequential design of\nexperiment (DOE) problems, where the goal is to collect data in order to to\nfulfil a certain problem specific goal. Our approach, Myopic Posterior Sampling\n(MPS), is inspired by the classical posterior (Thompson) sampling algorithm for\nmulti-armed bandits and leverages the flexibility of probabilistic programming\nand approximate Bayesian inference to address a broad set of problems.\nEmpirically, this general-purpose strategy is competitive with more specialised\nmethods in a wide array of DOE tasks, and more importantly, enables addressing\ncomplex DOE goals where no existing method seems applicable. On the theoretical\nside, we leverage ideas from adaptive submodularity and reinforcement learning\nto derive conditions under which MPS achieves sublinear regret against natural\nbenchmark policies.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 03:36:09 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Neiswanger", "Willie", ""], ["Zhang", "Reed", ""], ["Krishnamurthy", "Akshay", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1805.09965", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Georgios B. Giannakis, Tao Sun, Wotao Yin", "title": "LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed\n  Learning", "comments": "Fix a typo in equation (11)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new class of gradient methods for distributed machine\nlearning that adaptively skip the gradient calculations to learn with reduced\ncommunication and computation. Simple rules are designed to detect\nslowly-varying gradients and, therefore, trigger the reuse of outdated\ngradients. The resultant gradient-based algorithms are termed Lazily Aggregated\nGradient --- justifying our acronym LAG used henceforth. Theoretically, the\nmerits of this contribution are: i) the convergence rate is the same as batch\ngradient descent in strongly-convex, convex, and nonconvex smooth cases; and,\nii) if the distributed datasets are heterogeneous (quantified by certain\nmeasurable constants), the communication rounds needed to achieve a targeted\naccuracy are reduced thanks to the adaptive reuse of lagged gradients.\nNumerical experiments on both synthetic and real data corroborate a significant\ncommunication reduction compared to alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 03:36:14 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 07:02:44 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""], ["Sun", "Tao", ""], ["Yin", "Wotao", ""]]}, {"id": "1805.09969", "submitter": "Zebang Shen", "authors": "Zebang Shen, Aryan Mokhtari, Tengfei Zhou, Peilin Zhao, Hui Qian", "title": "Towards More Efficient Stochastic Decentralized Learning: Faster\n  Convergence and Sparse Communication", "comments": "Accepted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the decentralized optimization problem is attracting growing\nattention. Most existing methods are deterministic with high per-iteration cost\nand have a convergence rate quadratically depending on the problem condition\nnumber. Besides, the dense communication is necessary to ensure the convergence\neven if the dataset is sparse. In this paper, we generalize the decentralized\noptimization problem to a monotone operator root finding problem, and propose a\nstochastic algorithm named DSBA that (i) converges geometrically with a rate\nlinearly depending on the problem condition number, and (ii) can be implemented\nusing sparse communication only. Additionally, DSBA handles learning problems\nlike AUC-maximization which cannot be tackled efficiently in the decentralized\nsetting. Experiments on convex minimization and AUC-maximization validate the\nefficiency of our method.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 03:49:33 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Shen", "Zebang", ""], ["Mokhtari", "Aryan", ""], ["Zhou", "Tengfei", ""], ["Zhao", "Peilin", ""], ["Qian", "Hui", ""]]}, {"id": "1805.09978", "submitter": "James Sharpnack", "authors": "Shitong Wei, Oscar Hernan Madrid-Padilla, James Sharpnack", "title": "Distributed Cartesian Power Graph Segmentation for Graphon Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extention of total variation denoising over images to over\nCartesian power graphs and its applications to estimating non-parametric\nnetwork models. The power graph fused lasso (PGFL) segments a matrix by\nexploiting a known graphical structure, $G$, over the rows and columns. Our\nmain results shows that for any connected graph, under subGaussian noise, the\nPGFL achieves the same mean-square error rate as 2D total variation denoising\nfor signals of bounded variation. We study the use of the PGFL for denoising an\nobserved network $H$, where we learn the graph $G$ as the $K$-nearest\nneighborhood graph of an estimated metric over the vertices. We provide\ntheoretical and empirical results for estimating graphons, a non-parametric\nexchangeable network model, and compare to the state of the art graphon\nestimation methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 04:27:58 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Wei", "Shitong", ""], ["Madrid-Padilla", "Oscar Hernan", ""], ["Sharpnack", "James", ""]]}, {"id": "1805.09980", "submitter": "Lingfei Wu", "authors": "Xiaojie Guo, Lingfei Wu, and Liang Zhao", "title": "Deep Graph Translation", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the tremendous success of deep generative models on generating\ncontinuous data like image and audio, in the most recent year, few deep graph\ngenerative models have been proposed to generate discrete data such as graphs.\nThey are typically unconditioned generative models which has no control on\nmodes of the graphs being generated. Differently, in this paper, we are\ninterested in a new problem named \\emph{Deep Graph Translation}: given an input\ngraph, we want to infer a target graph based on their underlying (both global\nand local) translation mapping. Graph translation could be highly desirable in\nmany applications such as disaster management and rare event forecasting, where\nthe rare and abnormal graph patterns (e.g., traffic congestions and terrorism\nevents) will be inferred prior to their occurrence even without historical data\non the abnormal patterns for this graph (e.g., a road network or human contact\nnetwork). To achieve this, we propose a novel Graph-Translation-Generative\nAdversarial Networks (GT-GAN) which will generate a graph translator from input\nto target graphs. GT-GAN consists of a graph translator where we propose new\ngraph convolution and deconvolution layers to learn the global and local\ntranslation mapping. A new conditional graph discriminator has also been\nproposed to classify target graphs by conditioning on input graphs. Extensive\nexperiments on multiple synthetic and real-world datasets demonstrate the\neffectiveness and scalability of the proposed GT-GAN.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 04:56:07 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 16:06:37 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Guo", "Xiaojie", ""], ["Wu", "Lingfei", ""], ["Zhao", "Liang", ""]]}, {"id": "1805.09987", "submitter": "Zheng Xu", "authors": "Zheng Xu, Michael Wilber, Chen Fang, Aaron Hertzmann, Hailin Jin", "title": "Learning from Multi-domain Artistic Images for Arbitrary Style Transfer", "comments": "Update code link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast feed-forward network for arbitrary style transfer, which\ncan generate stylized image for previously unseen content and style image\npairs. Besides the traditional content and style representation based on deep\nfeatures and statistics for textures, we use adversarial networks to regularize\nthe generation of stylized images. Our adversarial network learns the intrinsic\nproperty of image styles from large-scale multi-domain artistic images. The\nadversarial training is challenging because both the input and output of our\ngenerator are diverse multi-domain images. We use a conditional generator that\nstylized content by shifting the statistics of deep features, and a conditional\ndiscriminator based on the coarse category of styles. Moreover, we propose a\nmask module to spatially decide the stylization level and stabilize adversarial\ntraining by avoiding mode collapse. As a side effect, our trained discriminator\ncan be applied to rank and select representative stylized images. We\nqualitatively and quantitatively evaluate the proposed method, and compare with\nrecent style transfer methods. We release our code and model at\nhttps://github.com/nightldj/behance_release.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 05:54:39 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 06:22:51 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Xu", "Zheng", ""], ["Wilber", "Michael", ""], ["Fang", "Chen", ""], ["Hertzmann", "Aaron", ""], ["Jin", "Hailin", ""]]}, {"id": "1805.09994", "submitter": "Zlatan Ajanovic", "authors": "Zlatan Ajanovic, Bakir Lacevic, Georg Stettinger, Daniel Watzenig,\n  Martin Horn", "title": "Safe learning-based optimal motion planning for automated driving", "comments": "3 pages, 1 figure, 1 pseudocode, extended abstract accepted to ICML /\n  IJCAI / AAMAS 2018 Workshop on Planning and Learning (PAL-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents preliminary work on learning the search heuristic for the\noptimal motion planning for automated driving in urban traffic. Previous work\nconsidered search-based optimal motion planning framework (SBOMP) that utilized\nnumerical or model-based heuristics that did not consider dynamic obstacles.\nOptimal solution was still guaranteed since dynamic obstacles can only increase\nthe cost. However, significant variations in the search efficiency are observed\ndepending whether dynamic obstacles are present or not. This paper introduces\nmachine learning (ML) based heuristic that takes into account dynamic\nobstacles, thus adding to the performance consistency for achieving real-time\nimplementation.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 06:18:01 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 13:15:03 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Ajanovic", "Zlatan", ""], ["Lacevic", "Bakir", ""], ["Stettinger", "Georg", ""], ["Watzenig", "Daniel", ""], ["Horn", "Martin", ""]]}, {"id": "1805.10002", "submitter": "Yanbin Liu", "authors": "Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju\n  Hwang and Yi Yang", "title": "Learning to Propagate Labels: Transductive Propagation Network for\n  Few-shot Learning", "comments": "Accepted in ICLR 2019; code available at\n  https://github.com/csyanbin/TPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot learning is to learn a classifier that generalizes well\neven when trained with a limited number of training instances per class. The\nrecently introduced meta-learning approaches tackle this problem by learning a\ngeneric classifier across a large number of multiclass classification tasks and\ngeneralizing the model to a new task. Yet, even with such meta-learning, the\nlow-data problem in the novel classification task still remains. In this paper,\nwe propose Transductive Propagation Network (TPN), a novel meta-learning\nframework for transductive inference that classifies the entire test set at\nonce to alleviate the low-data problem. Specifically, we propose to learn to\npropagate labels from labeled instances to unlabeled test instances, by\nlearning a graph construction module that exploits the manifold structure in\nthe data. TPN jointly learns both the parameters of feature embedding and the\ngraph construction in an end-to-end manner. We validate TPN on multiple\nbenchmark datasets, on which it largely outperforms existing few-shot learning\napproaches and achieves the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:00:31 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 06:31:47 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 04:31:05 GMT"}, {"version": "v4", "created": "Fri, 1 Feb 2019 04:36:54 GMT"}, {"version": "v5", "created": "Fri, 8 Feb 2019 09:30:53 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Liu", "Yanbin", ""], ["Lee", "Juho", ""], ["Park", "Minseop", ""], ["Kim", "Saehoon", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Yi", ""]]}, {"id": "1805.10004", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Masked Conditional Neural Networks for Environmental Sound\n  Classification", "comments": "Conditional Neural Networks, CLNN, Masked Conditional Neural\n  Networks, MCLNN, Restricted Boltzmann Machine, RBM, Conditional Restricted\n  Boltz-mann Machine, CRBM, Deep Belief Nets, Environmental Sound Recognition,\n  ESR, YorNoise", "journal-ref": "Artificial Intelligence XXXIV. SGAI 2017", "doi": "10.1007/978-3-319-71078-5_2", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ConditionaL Neural Network (CLNN) exploits the nature of the temporal\nsequencing of the sound signal represented in a spectrogram, and its variant\nthe Masked ConditionaL Neural Network (MCLNN) induces the network to learn in\nfrequency bands by embedding a filterbank-like sparseness over the network's\nlinks using a binary mask. Additionally, the masking automates the exploration\nof different feature combinations concurrently analogous to handcrafting the\noptimum combination of features for a recognition task. We have evaluated the\nMCLNN performance using the Urbansound8k dataset of environmental sounds.\nAdditionally, we present a collection of manually recorded sounds for rail and\nroad traffic, YorNoise, to investigate the confusion rates among machine\ngenerated sounds possessing low-frequency components. MCLNN has achieved\ncompetitive results without augmentation and using 12% of the trainable\nparameters utilized by an equivalent model based on state-of-the-art\nConvolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k\ndataset with YorNoise, where experiments have shown that common tonal\nproperties affect the classification performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:02:38 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 13:48:45 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1805.10005", "submitter": "Haifang Li", "authors": "Haifang Li, Yingce Xia and Wensheng Zhang", "title": "Finite Sample Analysis of LSTD with Random Projections and Eligibility\n  Traces", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation with linear function approximation is an important problem\nin reinforcement learning. When facing high-dimensional feature spaces, such a\nproblem becomes extremely hard considering the computation efficiency and\nquality of approximations. We propose a new algorithm, LSTD($\\lambda$)-RP,\nwhich leverages random projection techniques and takes eligibility traces into\nconsideration to tackle the above two challenges. We carry out theoretical\nanalysis of LSTD($\\lambda$)-RP, and provide meaningful upper bounds of the\nestimation error, approximation error and total generalization error. These\nresults demonstrate that LSTD($\\lambda$)-RP can benefit from random projection\nand eligibility traces strategies, and LSTD($\\lambda$)-RP can achieve better\nperformances than prior LSTD-RP and LSTD($\\lambda$) algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:04:42 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Li", "Haifang", ""], ["Xia", "Yingce", ""], ["Zhang", "Wensheng", ""]]}, {"id": "1805.10014", "submitter": "Konstantin Kutzkov", "authors": "Moez Draief, Konstantin Kutzkov, Kevin Scaman, Milan Vojnovic", "title": "KONG: Kernels for ordered-neighborhood graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel graph kernels for graphs with node and edge labels that have\nordered neighborhoods, i.e. when neighbor nodes follow an order. Graphs with\nordered neighborhoods are a natural data representation for evolving graphs\nwhere edges are created over time, which induces an order. Combining\nconvolutional subgraph kernels and string kernels, we design new scalable\nalgorithms for generation of explicit graph feature maps using sketching\ntechniques. We obtain precise bounds for the approximation accuracy and\ncomputational complexity of the proposed approaches and demonstrate their\napplicability on real datasets. In particular, our experiments demonstrate that\nneighborhood ordering results in more informative features. For the special\ncase of general graphs, i.e. graphs without ordered neighborhoods, the new\ngraph kernels yield efficient and simple algorithms for the comparison of label\ndistributions between graphs.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:40:21 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 07:43:12 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Draief", "Moez", ""], ["Kutzkov", "Konstantin", ""], ["Scaman", "Kevin", ""], ["Vojnovic", "Milan", ""]]}, {"id": "1805.10032", "submitter": "Cong Xie", "authors": "Cong Xie, Oluwasanmi Koyejo, Indranil Gupta", "title": "Zeno: Distributed Stochastic Gradient Descent with Suspicion-based\n  Fault-tolerance", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Zeno, a technique to make distributed machine learning,\nparticularly Stochastic Gradient Descent (SGD), tolerant to an arbitrary number\nof faulty workers. Zeno generalizes previous results that assumed a majority of\nnon-faulty nodes; we need assume only one non-faulty worker. Our key idea is to\nsuspect workers that are potentially defective. Since this is likely to lead to\nfalse positives, we use a ranking-based preference mechanism. We prove the\nconvergence of SGD for non-convex problems under these scenarios. Experimental\nresults show that Zeno outperforms existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 08:33:24 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 08:20:57 GMT"}, {"version": "v3", "created": "Sat, 18 May 2019 00:52:06 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Xie", "Cong", ""], ["Koyejo", "Oluwasanmi", ""], ["Gupta", "Indranil", ""]]}, {"id": "1805.10043", "submitter": "Yulong Pei", "authors": "Yulong Pei, Xin Du, Jianpeng Zhang, George Fletcher, Mykola\n  Pechenizkiy", "title": "struc2gauss: Structural Role Preserving Network Embedding via Gaussian\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding (NE) is playing a principal role in network mining, due to\nits ability to map nodes into efficient low-dimensional embedding vectors.\nHowever, two major limitations exist in state-of-the-art NE methods: role\npreservation and uncertainty modeling. Almost all previous methods represent a\nnode into a point in space and focus on local structural information, i.e.,\nneighborhood information. However, neighborhood information does not capture\nglobal structural information and point vector representation fails in modeling\nthe uncertainty of node representations. In this paper, we propose a new NE\nframework, struc2gauss, which learns node representations in the space of\nGaussian distributions and performs network embedding based on global\nstructural information. struc2gauss first employs a given node similarity\nmetric to measure the global structural information, then generates structural\ncontext for nodes and finally learns node representations via Gaussian\nembedding. Different structural similarity measures of networks and energy\nfunctions of Gaussian embedding are investigated. Experiments conducted on\nreal-world networks demonstrate that struc2gauss effectively captures global\nstructural information while state-of-the-art network embedding methods fail\nto, outperforms other methods on the structure-based clustering and\nclassification task and provides more information on uncertainties of node\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 08:55:25 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:33:35 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pei", "Yulong", ""], ["Du", "Xin", ""], ["Zhang", "Jianpeng", ""], ["Fletcher", "George", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1805.10050", "submitter": "Andrea Insabato", "authors": "Andrea Insabato, John P. Cunningham and Matthieu Gilson", "title": "Bayesian estimation for large scale multivariate Ornstein-Uhlenbeck\n  model of brain connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Estimation of reliable whole-brain connectivity is a crucial step towards the\nuse of connectivity information in quantitative approaches to the study of\nneuropsychiatric disorders. When estimating brain connectivity a challenge is\nimposed by the paucity of time samples and the large dimensionality of the\nmeasurements. Bayesian estimation methods for network models offer a number of\nadvantages in this context but are not commonly employed. Here we compare three\ndifferent estimation methods for the multivariate Ornstein-Uhlenbeck model,\nthat has recently gained some popularity for characterizing whole-brain\nconnectivity. We first show that a Bayesian estimation of model parameters\nassuming uniform priors is equivalent to an application of the method of\nmoments. Then, using synthetic data, we show that the Bayesian estimate scales\npoorly with number of nodes in the network as compared to an iterative Lyapunov\noptimization. In particular when the network size is in the order of that used\nfor whole-brain studies (about 100 nodes) the Bayesian method needs about eight\ntimes more time samples than Lyapunov method in order to achieve similar\nestimation accuracy. We also show that the higher estimation accuracy of\nLyapunov method is reflected in a much better classification of individuals\nbased on the estimated connectivity from a real dataset of BOLD fMRI. Finally\nwe show that the poor accuracy of Bayesian method is due to numerical errors,\nwhen the imaginary part of the connectivity estimate gets large compared to its\nreal part.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 09:08:01 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Insabato", "Andrea", ""], ["Cunningham", "John P.", ""], ["Gilson", "Matthieu", ""]]}, {"id": "1805.10054", "submitter": "Pierre Ablin", "authors": "Pierre Ablin, Alexandre Gramfort, Jean-Fran\\c{c}ois Cardoso and\n  Francis Bach", "title": "Stochastic algorithms with descent guarantees for ICA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is a widespread data exploration\ntechnique, where observed signals are modeled as linear mixtures of independent\ncomponents. From a machine learning point of view, it amounts to a matrix\nfactorization problem with a statistical independence criterion. Infomax is one\nof the most used ICA algorithms. It is based on a loss function which is a\nnon-convex log-likelihood. We develop a new majorization-minimization framework\nadapted to this loss function. We derive an online algorithm for the streaming\nsetting, and an incremental algorithm for the finite sum setting, with the\nfollowing benefits. First, unlike most algorithms found in the literature, the\nproposed methods do not rely on any critical hyper-parameter like a step size,\nnor do they require a line-search technique. Second, the algorithm for the\nfinite sum setting, although stochastic, guarantees a decrease of the loss\nfunction at each iteration. Experiments demonstrate progress on the\nstate-of-the-art for large scale datasets, without the necessity for any manual\nparameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 09:29:33 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 09:33:30 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ablin", "Pierre", ""], ["Gramfort", "Alexandre", ""], ["Cardoso", "Jean-Fran\u00e7ois", ""], ["Bach", "Francis", ""]]}, {"id": "1805.10066", "submitter": "Pratik Gajane", "authors": "Pratik Gajane, Ronald Ortner, and Peter Auer", "title": "A Sliding-Window Algorithm for Markov Decision Processes with\n  Arbitrarily Changing Rewards and Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reinforcement learning in changing Markov Decision Processes\nwhere both the state-transition probabilities and the reward functions may vary\nover time. For this problem setting, we propose an algorithm using a sliding\nwindow approach and provide performance guarantees for the regret evaluated\nagainst the optimal non-stationary policy. We also characterize the optimal\nwindow size suitable for our algorithm. These results are complemented by a\nsample complexity bound on the number of sub-optimal steps taken by the\nalgorithm. Finally, we present some experimental results to support our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 10:14:20 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Gajane", "Pratik", ""], ["Ortner", "Ronald", ""], ["Auer", "Peter", ""]]}, {"id": "1805.10074", "submitter": "Loucas Pillaud-Vivien", "authors": "Loucas Pillaud-Vivien (SIERRA, PSL), Alessandro Rudi (SIERRA, PSL),\n  Francis Bach (SIERRA, PSL)", "title": "Statistical Optimality of Stochastic Gradient Descent on Hard Learning\n  Problems through Multiple Passes", "comments": null, "journal-ref": "Neural Information Processing Systems (NIPS), Dec 2018,\n  Montr{\\'e}al, Canada. 2018", "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic gradient descent (SGD) for least-squares regression\nwith potentially several passes over the data. While several passes have been\nwidely reported to perform practically better in terms of predictive\nperformance on unseen data, the existing theoretical analysis of SGD suggests\nthat a single pass is statistically optimal. While this is true for\nlow-dimensional easy problems, we show that for hard problems, multiple passes\nlead to statistically optimal predictions while single pass does not; we also\nshow that in these hard models, the optimal number of passes over the data\nincreases with sample size. In order to define the notion of hardness and show\nthat our predictive performances are optimal, we consider potentially\ninfinite-dimensional models and notions typically associated to kernel methods,\nnamely, the decay of eigenvalues of the covariance matrix of the features and\nthe complexity of the optimal predictor as measured through the covariance\nmatrix. We illustrate our results on synthetic experiments with non-linear\nkernel methods and on a classical benchmark with a linear model.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 10:45:09 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 14:12:22 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2018 07:13:47 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Pillaud-Vivien", "Loucas", "", "SIERRA, PSL"], ["Rudi", "Alessandro", "", "SIERRA, PSL"], ["Bach", "Francis", "", "SIERRA, PSL"]]}, {"id": "1805.10111", "submitter": "Yue Yu", "authors": "Yue Yu, Jiaxiang Wu, Longbo Huang", "title": "Double Quantization for Communication-Efficient Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed training of machine learning models suffers from high\ncommunication overhead for synchronizing stochastic gradients and model\nparameters. In this paper, to reduce the communication complexity, we propose\n\\emph{double quantization}, a general scheme for quantizing both model\nparameters and gradients. Three communication-efficient algorithms are proposed\nunder this general scheme. Specifically, (i) we propose a low-precision\nalgorithm AsyLPG with asynchronous parallelism, (ii) we explore integrating\ngradient sparsification with double quantization and develop Sparse-AsyLPG,\n(iii) we show that double quantization can also be accelerated by momentum\ntechnique and design accelerated AsyLPG. We establish rigorous performance\nguarantees for the algorithms, and conduct experiments on a multi-server\ntest-bed to demonstrate that our algorithms can effectively save transmitted\nbits without performance degradation.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 12:42:00 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 11:14:01 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 09:11:46 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 15:13:51 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yu", "Yue", ""], ["Wu", "Jiaxiang", ""], ["Huang", "Longbo", ""]]}, {"id": "1805.10118", "submitter": "Stefan Klus", "authors": "Stefan Klus, Sebastian Peitz, Ingmar Schuster", "title": "Analyzing high-dimensional time-series data using kernel transfer\n  operator eigenfunctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel transfer operators, which can be regarded as approximations of\ntransfer operators such as the Perron-Frobenius or Koopman operator in\nreproducing kernel Hilbert spaces, are defined in terms of covariance and\ncross-covariance operators and have been shown to be closely related to the\nconditional mean embedding framework developed by the machine learning\ncommunity. The goal of this paper is to show how the dominant eigenfunctions of\nthese operators in combination with gradient-based optimization techniques can\nbe used to detect long-lived coherent patterns in high-dimensional time-series\ndata. The results will be illustrated using video data and a fluid flow\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:13:36 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Klus", "Stefan", ""], ["Peitz", "Sebastian", ""], ["Schuster", "Ingmar", ""]]}, {"id": "1805.10122", "submitter": "Shifeng Xiong Doc", "authors": "Shifeng Xiong", "title": "The Reconstruction Approach: From Interpolation to Regression", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an interpolation-based method, called the\nreconstruction approach, for nonparametric regression. Based on the fact that\ninterpolation usually has negligible errors compared to statistical estimation,\nthe reconstruction approach uses an interpolator to parameterize the regression\nfunction with its values at finite knots, and then estimates these values by\n(regularized) least squares. Some popular methods including kernel ridge\nregression can be viewed as its special cases. It is shown that, the\nreconstruction idea not only provides different angles to look into existing\nmethods, but also produces new effective experimental design and estimation\nmethods for nonparametric models. In particular, for some methods of complexity\nO(n3), where n is the sample size, this approach provides effective surrogates\nwith much less computational burden. This point makes it very suitable for\nlarge datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 12:56:54 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 07:18:59 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 12:09:07 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Xiong", "Shifeng", ""]]}, {"id": "1805.10123", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin and Pau Rodriguez and Alexandre Lacoste", "title": "TADAM: Task dependent adaptive metric for improved few-shot learning", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 31, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning has become essential for producing models that generalize\nfrom few examples. In this work, we identify that metric scaling and metric\ntask conditioning are important to improve the performance of few-shot\nalgorithms. Our analysis reveals that simple metric scaling completely changes\nthe nature of few-shot algorithm parameter updates. Metric scaling provides\nimprovements up to 14% in accuracy for certain metrics on the mini-Imagenet\n5-way 5-shot classification task. We further propose a simple and effective way\nof conditioning a learner on the task sample set, resulting in learning a\ntask-dependent metric space. Moreover, we propose and empirically test a\npractical end-to-end optimization procedure based on auxiliary task co-training\nto learn a task-dependent metric space. The resulting few-shot learning model\nbased on the task-dependent scaled metric achieves state of the art on\nmini-Imagenet. We confirm these results on another few-shot dataset that we\nintroduce in this paper based on CIFAR100. Our code is publicly available at\nhttps://github.com/ElementAI/TADAM.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:17:59 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 22:42:57 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 14:36:12 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2019 18:47:30 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Rodriguez", "Pau", ""], ["Lacoste", "Alexandre", ""]]}, {"id": "1805.10129", "submitter": "Ryan Faulkner", "authors": "Ryan Faulkner, Doina Precup", "title": "Dyna Planning using a Feature Based Generative Model", "comments": "8 pages, 7 figures", "journal-ref": "24th Annual Proceedings of the Advances in Neural Information\n  Processing Systems (2010) pp. 1-9", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyna-style reinforcement learning is a powerful approach for problems where\nnot much real data is available. The main idea is to supplement real\ntrajectories, or sequences of sampled states over time, with simulated ones\nsampled from a learned model of the environment. However, in large state\nspaces, the problem of learning a good generative model of the environment has\nbeen open so far. We propose to use deep belief networks to learn an\nenvironment model for use in Dyna. We present our approach and validate it\nempirically on problems where the state observations consist of images. Our\nresults demonstrate that using deep belief networks, which are full generative\nmodels, significantly outperforms the use of linear expectation models,\nproposed in Sutton et al. (2008)\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 23:23:34 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Faulkner", "Ryan", ""], ["Precup", "Doina", ""]]}, {"id": "1805.10130", "submitter": "Yingjing Lu", "authors": "Yingjing Lu", "title": "Cross Domain Image Generation through Latent Space Exploration with\n  Adversarial Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional domain generation is a good way to interactively control sample\ngeneration process of deep generative models. However, once a conditional\ngenerative model has been created, it is often expensive to allow it to adapt\nto new conditional controls, especially the network structure is relatively\ndeep. We propose a conditioned latent domain transfer framework across latent\nspaces of unconditional variational autoencoders(VAE). With this framework, we\ncan allow unconditionally trained VAEs to generate images in its domain with\nconditionals provided by a latent representation of another domain. This\nframework does not assume commonalities between two domains. We demonstrate\neffectiveness and robustness of our model under widely used image datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 04:02:26 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Lu", "Yingjing", ""]]}, {"id": "1805.10133", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Eduardo Rosar Kos Lassance, Vincent Gripon and Antonio Ortega", "title": "Laplacian Networks: Bounding Indicator Function Smoothness for Neural\n  Network Robustness", "comments": "12 pages, github link coming soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past few years, Deep Neural Network (DNN) robustness has become a\nquestion of paramount importance. As a matter of fact, in sensitive settings\nmisclassification can lead to dramatic consequences. Such misclassifications\nare likely to occur when facing adversarial attacks, hardware failures or\nlimitations, and imperfect signal acquisition. To address this question,\nauthors have proposed different approaches aiming at increasing the robustness\nof DNNs, such as adding regularizers or training using noisy examples. In this\npaper we propose a new regularizer built upon the Laplacian of similarity\ngraphs obtained from the representation of training data at each layer of the\nDNN architecture. This regularizer penalizes large changes (across consecutive\nlayers in the architecture) in the distance between examples of different\nclasses, and as such enforces smooth variations of the class boundaries. Since\nit is agnostic to the type of deformations that are expected when predicting\nwith the DNN, the proposed regularizer can be combined with existing ad-hoc\nmethods. We provide theoretical justification for this regularizer and\ndemonstrate its effectiveness to improve robustness of DNNs on classical\nsupervised learning vision datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 07:36:16 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 20:44:38 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Lassance", "Carlos Eduardo Rosar Kos", ""], ["Gripon", "Vincent", ""], ["Ortega", "Antonio", ""]]}, {"id": "1805.10168", "submitter": "Kumarjit Pathak", "authors": "Kumarjit Pathak, Jitin Kapila, Aasheesh Barvey", "title": "Futuristic Classification with Dynamic Reference Frame Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the widely used analytical techniques in data\nscience domain across different business to associate a pattern which\ncontribute to the occurrence of certain event which is predicted with some\nlikelihood. This Paper address a lacuna of creating some time window before the\nprediction actually happen to enable organizations some space to act on the\nprediction. There are some really good state of the art machine learning\ntechniques to optimally identify the possible churners in either customer base\nor employee base, similarly for fault prediction too if the prediction does not\ncome with some buffer time to act on the fault it is very difficult to provide\na seamless experience to the user. New concept of reference frame creation is\nintroduced to solve this problem in this paper\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:14:10 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""], ["Barvey", "Aasheesh", ""]]}, {"id": "1805.10170", "submitter": "Neerav Karani", "authors": "Neerav Karani, Krishna Chaitanya, Christian Baumgartner, Ender\n  Konukoglu", "title": "A Lifelong Learning Approach to Brain MR Segmentation Across Scanners\n  and Protocols", "comments": "Accepted at the 21st International Conference on Medical Image\n  Computing and Computer Assisted Interventions (MICCAI 2018) in Granada, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have shown promising results on several\nsegmentation tasks in magnetic resonance (MR) images. However, the accuracy of\nCNNs may degrade severely when segmenting images acquired with different\nscanners and/or protocols as compared to the training data, thus limiting their\npractical utility. We address this shortcoming in a lifelong multi-domain\nlearning setting by treating images acquired with different scanners or\nprotocols as samples from different, but related domains. Our solution is a\nsingle CNN with shared convolutional filters and domain-specific batch\nnormalization layers, which can be tuned to new domains with only a few\n($\\approx$ 4) labelled images. Importantly, this is achieved while retaining\nperformance on the older domains whose training data may no longer be\navailable. We evaluate the method for brain structure segmentation in MR\nimages. Results demonstrate that the proposed method largely closes the gap to\nthe benchmark, which is training a dedicated CNN for each scanner.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:20:39 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Karani", "Neerav", ""], ["Chaitanya", "Krishna", ""], ["Baumgartner", "Christian", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1805.10181", "submitter": "Wenshan Cai", "authors": "Zhaocheng Liu, Dayu Zhu, Sean P. Rodrigues, Kyu-Tae Lee, and Wenshan\n  Cai", "title": "A Generative Model for Inverse Design of Metamaterials", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.1021/acs.nanolett.8b03171", "report-no": null, "categories": "physics.optics cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of two-dimensional metamaterials in recent years has ushered in a\nrevolutionary means to manipulate the behavior of light on the nanoscale. The\neffective parameters of these architected materials render unprecedented\ncontrol over the optical properties of light, thereby eliciting previously\nunattainable applications in flat lenses, holographic imaging, and emission\ncontrol among others. The design of such structures, to date, has relied on the\nexpertise of an optical scientist to guide a progression of electromagnetic\nsimulations that iteratively solve Maxwell's equations until a locally\noptimized solution can be attained. In this work, we identify a solution to\ncircumvent this intuition-guided design by means of a deep learning\narchitecture. When fed an input set of optical spectra, the constructed\ngenerative network assimilates a candidate pattern from a user-defined dataset\nof geometric structures in order to match the input spectra. The generated\nmetamaterial patterns demonstrate high fidelity, yielding equivalent optical\nspectra at an average accuracy of about 0.9. This approach reveals an\nopportunity to expedite the discovery and design of metasurfaces for tailored\noptical responses in a systematic, inverse-design manner.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:41:15 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Liu", "Zhaocheng", ""], ["Zhu", "Dayu", ""], ["Rodrigues", "Sean P.", ""], ["Lee", "Kyu-Tae", ""], ["Cai", "Wenshan", ""]]}, {"id": "1805.10196", "submitter": "James Wilson", "authors": "James T. Wilson, Frank Hutter, Marc Peter Deisenroth", "title": "Maximizing acquisition functions for Bayesian optimization", "comments": "Proceedings of the Thirty-second Conference on Neural Information\n  Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a sample-efficient approach to global optimization\nthat relies on theoretically motivated value heuristics (acquisition functions)\nto guide its search process. Fully maximizing acquisition functions produces\nthe Bayes' decision rule, but this ideal is difficult to achieve since these\nfunctions are frequently non-trivial to optimize. This statement is especially\ntrue when evaluating queries in parallel, where acquisition functions are\nroutinely non-convex, high-dimensional, and intractable. We first show that\nacquisition functions estimated via Monte Carlo integration are consistently\namenable to gradient-based optimization. Subsequently, we identify a common\nfamily of acquisition functions, including EI and UCB, whose properties not\nonly facilitate but justify use of greedy approaches for their maximization.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:28:46 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 23:16:16 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wilson", "James T.", ""], ["Hutter", "Frank", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1805.10204", "submitter": "Ilya Razenshteyn", "authors": "S\\'ebastien Bubeck, Eric Price, Ilya Razenshteyn", "title": "Adversarial examples from computational constraints", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why are classifiers in high dimension vulnerable to \"adversarial\"\nperturbations? We show that it is likely not due to information theoretic\nlimitations, but rather it could be due to computational constraints.\n  First we prove that, for a broad set of classification tasks, the mere\nexistence of a robust classifier implies that it can be found by a possibly\nexponential-time algorithm with relatively few training examples. Then we give\na particular classification task where learning a robust classifier is\ncomputationally intractable. More precisely we construct a binary\nclassification task in high dimensional space which is (i) information\ntheoretically easy to learn robustly for large perturbations, (ii) efficiently\nlearnable (non-robustly) by a simple linear separator, (iii) yet is not\nefficiently robustly learnable, even for small perturbations, by any algorithm\nin the statistical query (SQ) model. This example gives an exponential\nseparation between classical learning and robust learning in the statistical\nquery model. It suggests that adversarial examples may be an unavoidable\nbyproduct of computational limitations of learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:39:06 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Price", "Eric", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1805.10205", "submitter": "Anthony Hu", "authors": "Anthony Hu, Seth Flaxman", "title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "comments": "Accepted as a conference paper at KDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3219853", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to multimodal sentiment analysis using deep\nneural networks combining visual analysis and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting\nwhether a sentence expresses positive or negative sentiment; instead, we aim to\ninfer the latent emotional state of the user. Thus, we focus on predicting the\nemotion word tags attached by users to their Tumblr posts, treating these as\n\"self-reported emotions.\" We demonstrate that our multimodal model combining\nboth text and image features outperforms separate models based solely on either\nimages or text. Our model's results are interpretable, automatically yielding\nsensible word lists associated with emotions. We explore the structure of\nemotions implied by our model and compare it to what has been posited in the\npsychology literature, and validate our model on a set of images that have been\nused in psychology studies. Finally, our work also provides a useful tool for\nthe growing academic study of images - both photographs and memes - on social\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:40:11 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Hu", "Anthony", ""], ["Flaxman", "Seth", ""]]}, {"id": "1805.10206", "submitter": "Paul Smith Mr.", "authors": "Elena Issoglio, Paul Smith, Jochen Voss", "title": "On the Estimation of Entropy in the FastICA Algorithm", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The fastICA method is a popular dimension reduction technique used to reveal\npatterns in data. Here we show both theoretically and in practice that the\napproximations used in fastICA can result in patterns not being successfully\nrecognised. We demonstrate this problem using a two-dimensional example where a\nclear structure is immediately visible to the naked eye, but where the\nprojection chosen by fastICA fails to reveal this structure. This implies that\ncare is needed when applying fastICA. We discuss how the problem arises and how\nit is intrinsically connected to the approximations that form the basis of the\ncomputational efficiency of fastICA.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:43:50 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 12:02:26 GMT"}, {"version": "v3", "created": "Fri, 12 Apr 2019 14:59:24 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 16:44:57 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 15:51:13 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Issoglio", "Elena", ""], ["Smith", "Paul", ""], ["Voss", "Jochen", ""]]}, {"id": "1805.10212", "submitter": "Anil Goyal", "authors": "Anil Goyal (AMA, LHC), Emilie Morvant (LHC), Massih-Reza Amini (AMA)", "title": "Multiview Learning of Weighted Majority Vote by Bregman Divergence\n  Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the issue of classifier combinations when observations have\nmultiple views. Our method jointly learns view-specific weighted majority vote\nclassifiers (i.e. for each view) over a set of base voters, and a second\nweighted majority vote classifier over the set of these view-specific weighted\nmajority vote classifiers. We show that the empirical risk minimization of the\nfinal majority vote given a multiview training set can be cast as the\nminimization of Bregman divergences. This allows us to derive a parallel-update\noptimization algorithm for learning our multiview model. We empirically study\nour algorithm with a particular focus on the impact of the training set size on\nthe multiview learning results. The experiments show that our approach is able\nto overcome the lack of labeled information.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:51:15 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Goyal", "Anil", "", "AMA, LHC"], ["Morvant", "Emilie", "", "LHC"], ["Amini", "Massih-Reza", "", "AMA"]]}, {"id": "1805.10222", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Jialei Wang, Adam Smith, Brendan McMahan, Nathan\n  Srebro", "title": "Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a general oracle-based framework that captures different parallel\nstochastic optimization settings described by a dependency graph, and derive\ngeneric lower bounds in terms of this graph. We then use the framework and\nderive lower bounds for several specific parallel optimization settings,\nincluding delayed updates and parallel processing with intermittent\ncommunication. We highlight gaps between lower and upper bounds on the oracle\ncomplexity, and cases where the \"natural\" algorithms are not known to be\noptimal.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 16:06:09 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 16:26:22 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 16:42:09 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Woodworth", "Blake", ""], ["Wang", "Jialei", ""], ["Smith", "Adam", ""], ["McMahan", "Brendan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1805.10251", "submitter": "Richard Zhang", "authors": "Richard Y. Zhang, C\\'edric Josz, Somayeh Sojoudi, Javad Lavaei", "title": "How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the linear measurements of an instance of low-rank matrix recovery\nsatisfy a restricted isometry property (RIP)---i.e. they are approximately\nnorm-preserving---the problem is known to contain no spurious local minima, so\nexact recovery is guaranteed. In this paper, we show that moderate RIP is not\nenough to eliminate spurious local minima, so existing results can only hold\nfor near-perfect RIP. In fact, counterexamples are ubiquitous: we prove that\nevery x is the spurious local minimum of a rank-1 instance of matrix recovery\nthat satisfies RIP. One specific counterexample has RIP constant $\\delta=1/2$,\nbut causes randomly initialized stochastic gradient descent (SGD) to fail 12%\nof the time. SGD is frequently able to avoid and escape spurious local minima,\nbut this empirical result shows that it can occasionally be defeated by their\nexistence. Hence, while exact recovery guarantees will likely require a proof\nof no spurious local minima, arguments based solely on norm preservation will\nonly be applicable to a narrow set of nearly-isotropic instances.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:08:06 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 21:19:52 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zhang", "Richard Y.", ""], ["Josz", "C\u00e9dric", ""], ["Sojoudi", "Somayeh", ""], ["Lavaei", "Javad", ""]]}, {"id": "1805.10255", "submitter": "Manoj Kumar", "authors": "Manoj Kumar, George E. Dahl, Vijay Vasudevan, Mohammad Norouzi", "title": "Parallel Architecture and Hyperparameter Search via Successive Halving\n  and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and powerful algorithm for parallel black box\noptimization called Successive Halving and Classification (SHAC). The algorithm\noperates in $K$ stages of parallel function evaluations and trains a cascade of\nbinary classifiers to iteratively cull the undesirable regions of the search\nspace. SHAC is easy to implement, requires no tuning of its own configuration\nparameters, is invariant to the scale of the objective function and can be\nbuilt using any choice of binary classifier. We adopt tree-based classifiers\nwithin SHAC and achieve competitive performance against several strong\nbaselines for optimizing synthetic functions, hyperparameters and\narchitectures.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:12:38 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Kumar", "Manoj", ""], ["Dahl", "George E.", ""], ["Vasudevan", "Vijay", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1805.10262", "submitter": "Ankur Moitra", "authors": "Guy Bresler, Frederic Koehler, Ankur Moitra, Elchanan Mossel", "title": "Learning Restricted Boltzmann Machines via Influence Maximization", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are a rich language for describing high-dimensional\ndistributions in terms of their dependence structure. While there are\nalgorithms with provable guarantees for learning undirected graphical models in\na variety of settings, there has been much less progress in the important\nscenario when there are latent variables. Here we study Restricted Boltzmann\nMachines (or RBMs), which are a popular model with wide-ranging applications in\ndimensionality reduction, collaborative filtering, topic modeling, feature\nextraction and deep learning.\n  The main message of our paper is a strong dichotomy in the feasibility of\nlearning RBMs, depending on the nature of the interactions between variables:\nferromagnetic models can be learned efficiently, while general models cannot.\nIn particular, we give a simple greedy algorithm based on influence\nmaximization to learn ferromagnetic RBMs with bounded degree. In fact, we learn\na description of the distribution on the observed variables as a Markov Random\nField. Our analysis is based on tools from mathematical physics that were\ndeveloped to show the concavity of magnetization. Our algorithm extends\nstraighforwardly to general ferromagnetic Ising models with latent variables.\n  Conversely, we show that even for a contant number of latent variables with\nconstant degree, without ferromagneticity the problem is as hard as sparse\nparity with noise. This hardness result is based on a sharp and surprising\ncharacterization of the representational power of bounded degree RBMs: the\ndistribution on their observed variables can simulate any bounded order MRF.\nThis result is of independent interest since RBMs are the building blocks of\ndeep belief networks.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:32:19 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 19:31:28 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Bresler", "Guy", ""], ["Koehler", "Frederic", ""], ["Moitra", "Ankur", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1805.10265", "submitter": "Krishnamurthy Dvijotham", "authors": "Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja\n  Arandjelovic, Brendan O'Donoghue, Jonathan Uesato, Pushmeet Kohli", "title": "Training verified learners with learned verifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithmic framework, predictor-verifier training,\nto train neural networks that are verifiable, i.e., networks that provably\nsatisfy some desired input-output properties. The key idea is to simultaneously\ntrain two networks: a predictor network that performs the task at hand,e.g.,\npredicting labels given inputs, and a verifier network that computes a bound on\nhow well the predictor satisfies the properties being verified. Both networks\ncan be trained simultaneously to optimize a weighted combination of the\nstandard data-fitting loss and a term that bounds the maximum violation of the\nproperty. Experiments show that not only is the predictor-verifier architecture\nable to train networks to achieve state of the art verified robustness to\nadversarial examples with much shorter training times (outperforming previous\nalgorithms on small datasets like MNIST and SVHN), but it can also be scaled to\nproduce the first known (to the best of our knowledge) verifiably robust\nnetworks for CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:35:39 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 09:48:05 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Dvijotham", "Krishnamurthy", ""], ["Gowal", "Sven", ""], ["Stanforth", "Robert", ""], ["Arandjelovic", "Relja", ""], ["O'Donoghue", "Brendan", ""], ["Uesato", "Jonathan", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1805.10289", "submitter": "Sandro Ackermann", "authors": "Sandro Ackermann, Kevin Schawinski, Ce Zhang, Anna K. Weigel and M.\n  Dennis Turp", "title": "Using transfer learning to detect galaxy mergers", "comments": "Accepted for publication in MNRAS. Code and data on\n  https://space.ml/proj/transfer_learning", "journal-ref": null, "doi": "10.1093/mnras/sty1398", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of deep convolutional neural networks (deep CNNs) for\nautomatic visual detection of galaxy mergers. Moreover, we investigate the use\nof transfer learning in conjunction with CNNs, by retraining networks first\ntrained on pictures of everyday objects. We test the hypothesis that transfer\nlearning is useful for improving classification performance for small training\nsets. This would make transfer learning useful for finding rare objects in\nastronomical imaging datasets. We find that these deep learning methods perform\nsignificantly better than current state-of-the-art merger detection methods\nbased on nonparametric systems like CAS and GM$_{20}$. Our method is end-to-end\nand robust to image noise and distortions; it can be applied directly without\nimage preprocessing. We also find that transfer learning can act as a\nregulariser in some cases, leading to better overall classification accuracy\n($p = 0.02$). Transfer learning on our full training set leads to a lowered\nerror rate from 0.038 $\\pm$ 1 down to 0.032 $\\pm$ 1, a relative improvement of\n15%. Finally, we perform a basic sanity-check by creating a merger sample with\nour method, and comparing with an already existing, manually created merger\ncatalogue in terms of colour-mass distribution and stellar mass function.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 18:00:01 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:09:34 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ackermann", "Sandro", ""], ["Schawinski", "Kevin", ""], ["Zhang", "Ce", ""], ["Weigel", "Anna K.", ""], ["Turp", "M. Dennis", ""]]}, {"id": "1805.10309", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Qiang Liu, Jian Peng", "title": "Learning Self-Imitating Diverse Policies", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of popular algorithms for deep reinforcement learning, such as\npolicy-gradients and Q-learning, relies heavily on the availability of an\ninformative reward signal at each timestep of the sequential decision-making\nprocess. When rewards are only sparsely available during an episode, or a\nrewarding feedback is provided only after episode termination, these algorithms\nperform sub-optimally due to the difficultly in credit assignment.\nAlternatively, trajectory-based policy optimization methods, such as\ncross-entropy method and evolution strategies, do not require per-timestep\nrewards, but have been found to suffer from high sample complexity by\ncompleting forgoing the temporal nature of the problem. Improving the\nefficiency of RL algorithms in real-world problems with sparse or episodic\nrewards is therefore a pressing need. In this work, we introduce a\nself-imitation learning algorithm that exploits and explores well in the sparse\nand episodic reward settings. We view each policy as a state-action visitation\ndistribution and formulate policy optimization as a divergence minimization\nproblem. We show that with Jensen-Shannon divergence, this divergence\nminimization problem can be reduced into a policy-gradient algorithm with\nshaped rewards learned from experience replays. Experimental results indicate\nthat our algorithm works comparable to existing algorithms in environments with\ndense rewards, and significantly better in environments with sparse and\nepisodic rewards. We then discuss limitations of self-imitation learning, and\npropose to solve them by using Stein variational policy gradient descent with\nthe Jensen-Shannon kernel to learn multiple diverse policies. We demonstrate\nits effectiveness on a challenging variant of continuous-control MuJoCo\nlocomotion tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 18:17:55 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 00:27:50 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Liu", "Qiang", ""], ["Peng", "Jian", ""]]}, {"id": "1805.10318", "submitter": "Manuel Gomez Rodriguez", "authors": "Isabel Valera and Adish Singla and Manuel Gomez Rodriguez", "title": "Enhancing the Accuracy and Fairness of Human Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Societies often rely on human experts to take a wide variety of decisions\naffecting their members, from jail-or-release decisions taken by judges and\nstop-and-frisk decisions taken by police officers to accept-or-reject decisions\ntaken by academics. In this context, each decision is taken by an expert who is\ntypically chosen uniformly at random from a pool of experts. However, these\ndecisions may be imperfect due to limited experience, implicit biases, or\nfaulty probabilistic reasoning. Can we improve the accuracy and fairness of the\noverall decision making process by optimizing the assignment between experts\nand decisions?\n  In this paper, we address the above problem from the perspective of\nsequential decision making and show that, for different fairness notions from\nthe literature, it reduces to a sequence of (constrained) weighted bipartite\nmatchings, which can be solved efficiently using algorithms with approximation\nguarantees. Moreover, these algorithms also benefit from posterior sampling to\nactively trade off exploitation---selecting expert assignments which lead to\naccurate and fair decisions---and exploration---selecting expert assignments to\nlearn about the experts' preferences and biases. We demonstrate the\neffectiveness of our algorithms on both synthetic and real-world data and show\nthat they can significantly improve both the accuracy and fairness of the\ndecisions taken by pools of experts.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 18:33:01 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Valera", "Isabel", ""], ["Singla", "Adish", ""], ["Rodriguez", "Manuel Gomez", ""]]}, {"id": "1805.10341", "submitter": "Furong Huang", "authors": "Christopher DeCarolis, Mukul Ram, Seyed A. Esmaeili, Yu-Xiang Wang,\n  Furong Huang", "title": "An end-to-end Differentially Private Latent Dirichlet Allocation Using a\n  Spectral Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an end-to-end differentially private spectral algorithm for\nlearning LDA, based on matrix/tensor decompositions, and establish theoretical\nguarantees on utility/consistency of the estimated model parameters. The\nspectral algorithm consists of multiple algorithmic steps, named as \"{edges}\",\nto which noise could be injected to obtain differential privacy. We identify\n\\emph{subsets of edges}, named as \"{configurations}\", such that adding noise to\nall edges in such a subset guarantees differential privacy of the end-to-end\nspectral algorithm. We characterize the sensitivity of the edges with respect\nto the input and thus estimate the amount of noise to be added to each edge for\nany required privacy level. We then characterize the utility loss for each\nconfiguration as a function of injected noise. Overall, by combining the\nsensitivity and utility characterization, we obtain an end-to-end\ndifferentially private spectral algorithm for LDA and identify the\ncorresponding configuration that outperforms others in any specific regime. We\nare the first to achieve utility guarantees under the required level of\ndifferential privacy for learning in LDA. Overall our method systematically\noutperforms differentially private variational inference.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 19:30:47 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 15:25:47 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 06:01:52 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["DeCarolis", "Christopher", ""], ["Ram", "Mukul", ""], ["Esmaeili", "Seyed A.", ""], ["Wang", "Yu-Xiang", ""], ["Huang", "Furong", ""]]}, {"id": "1805.10348", "submitter": "Furong Huang", "authors": "Furong Huang, Jialin Li, Xuchen You", "title": "Guaranteed Simultaneous Asymmetric Tensor Decomposition via\n  Orthogonalized Alternating Least Squares", "comments": "Alphabetic order of author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor CANDECOMP/PARAFAC (CP) decomposition is an important tool that solves\na wide class of machine learning problems. Existing popular approaches recover\ncomponents one by one, not necessarily in the order of larger components first.\nRecently developed simultaneous power method obtains only a high probability\nrecovery of top $r$ components even when the observed tensor is noiseless. We\npropose a Slicing Initialized Alternating Subspace Iteration (s-ASI) method\nthat is guaranteed to recover top $r$ components ($\\epsilon$-close)\nsimultaneously for (a)symmetric tensors almost surely under the noiseless case\n(with high probability for a bounded noise) using $O(\\log(\\log\n\\frac{1}{\\epsilon}))$ steps of tensor subspace iterations. Our s-ASI method\nintroduces a Slice-Based Initialization that runs\n$O(1/\\log(\\frac{\\lambda_r}{\\lambda_{r+1}}))$ steps of matrix subspace\niterations, where $\\lambda_r$ denotes the r-th top singular value of the\ntensor. We are the first to provide a theoretical guarantee on simultaneous\northogonal asymmetric tensor decomposition. Under the noiseless case, we are\nthe first to provide an \\emph{almost sure} theoretical guarantee on\nsimultaneous orthogonal tensor decomposition. When tensor is noisy, our\nalgorithm for asymmetric tensor is robust to noise smaller than\n$\\min\\{O(\\frac{(\\lambda_r - \\lambda_{r+1})\\epsilon}{\\sqrt{r}}),\nO(\\delta_0\\frac{\\lambda_r -\\lambda_{r+1}}{\\sqrt{d}})\\}$, where $\\delta_0$ is a\nsmall constant proportional to the probability of bad initializations in the\nnoisy setting.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 20:05:17 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 01:46:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Huang", "Furong", ""], ["Li", "Jialin", ""], ["You", "Xuchen", ""]]}, {"id": "1805.10352", "submitter": "Jiahao Su", "authors": "Jiahao Su, Jingling Li, Bobby Bhattacharjee, Furong Huang", "title": "Tensorial Neural Networks: Generalization of Neural Networks and\n  Application to Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose tensorial neural networks (TNNs), a generalization of existing\nneural networks by extending tensor operations on low order operands to those\non high order ones. The problem of parameter learning is challenging, as it\ncorresponds to hierarchical nonlinear tensor decomposition. We propose to solve\nthe learning problem using stochastic gradient descent by deriving nontrivial\nbackpropagation rules in generalized tensor algebra we introduce. Our proposed\nTNNs has three advantages over existing neural networks: (1) TNNs naturally\napply to high order input object and thus preserve the multi-dimensional\nstructure in the input, as there is no need to flatten the data. (2) TNNs\ninterpret designs of existing neural network architectures. (3) Mapping a\nneural network to TNNs with the same expressive power results in a TNN of fewer\nparameters. TNN based compression of neural network improves existing low-rank\napproximation based compression methods as TNNs exploit two other types of\ninvariant structures, periodicity and modulation, in addition to the low\nrankness. Experiments on LeNet-5 (MNIST), ResNet-32 (CIFAR10) and ResNet-50\n(ImageNet) demonstrate that our TNN based compression outperforms (5% test\naccuracy improvement universally on CIFAR10) the state-of-the-art low-rank\napproximation based compression methods under the same compression rate,\nbesides achieving orders of magnitude faster convergence rates due to the\nefficiency of TNNs.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 20:21:50 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 19:03:18 GMT"}, {"version": "v3", "created": "Sat, 8 Dec 2018 23:16:03 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Su", "Jiahao", ""], ["Li", "Jingling", ""], ["Bhattacharjee", "Bobby", ""], ["Huang", "Furong", ""]]}, {"id": "1805.10354", "submitter": "Rolando Estrada", "authors": "Blake Camp, Jaya Krishna Mandivarapu, Rolando Estrada", "title": "Self-Net: Lifelong Learning via Continual Self-Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a set of tasks over time, also known as continual learning (CL), is\none of the most challenging problems in artificial intelligence. While recent\napproaches achieve some degree of CL in deep neural networks, they either (1)\ngrow the network parameters linearly with the number of tasks, (2) require\nstoring training data from previous tasks, or (3) restrict the network's\nability to learn new tasks. To address these issues, we propose a novel\nframework, Self-Net, that uses an autoencoder to learn a set of low-dimensional\nrepresentations of the weights learned for different tasks. We demonstrate that\nthese low-dimensional vectors can then be used to generate high-fidelity\nrecollections of the original weights. Self-Net can incorporate new tasks over\ntime with little retraining and with minimal loss in performance for older\ntasks. Our system does not require storing prior training data and its\nparameters grow only logarithmically with the number of tasks. We show that our\ntechnique outperforms current state-of-the-art approaches on numerous\ndatasets---including continual versions of MNIST, CIFAR10, CIFAR100, and\nAtari---and we demonstrate that our method can achieve over 10X storage\ncompression in a continual fashion. To the best of our knowledge, we are the\nfirst to use autoencoders to sequentially encode sets of network weights to\nenable continual learning.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 20:24:45 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 21:37:07 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 01:05:46 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Camp", "Blake", ""], ["Mandivarapu", "Jaya Krishna", ""], ["Estrada", "Rolando", ""]]}, {"id": "1805.10364", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Aravind Machiry, Shirin Nilizadeh, Christopher\n  Kruegel, and Giovanni Vigna", "title": "Detecting Deceptive Reviews using Generative Adversarial Networks", "comments": "accepted at 1st Deep Learning and Security Workshop co-located with\n  the 39th IEEE Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, consumer review sites have become the main target of\ndeceptive opinion spam, where fictitious opinions or reviews are deliberately\nwritten to sound authentic. Most of the existing work to detect the deceptive\nreviews focus on building supervised classifiers based on syntactic and lexical\npatterns of an opinion. With the successful use of Neural Networks on various\nclassification applications, in this paper, we propose FakeGAN a system that\nfor the first time augments and adopts Generative Adversarial Networks (GANs)\nfor a text classification task, in particular, detecting deceptive reviews.\nUnlike standard GAN models which have a single Generator and Discriminator\nmodel, FakeGAN uses two discriminator models and one generative model. The\ngenerator is modeled as a stochastic policy agent in reinforcement learning\n(RL), and the discriminators use Monte Carlo search algorithm to estimate and\npass the intermediate action-value as the RL reward to the generator. Providing\nthe generator model with two discriminator models avoids the mod collapse issue\nby learning from both distributions of truthful and deceptive reviews. Indeed,\nour experiments show that using two discriminators provides FakeGAN high\nstability, which is a known issue for GAN architectures. While FakeGAN is built\nupon a semi-supervised classifier, known for less accuracy, our evaluation\nresults on a dataset of TripAdvisor hotel reviews show the same performance in\nterms of accuracy as of the state-of-the-art approaches that apply supervised\nmachine learning. These results indicate that GANs can be effective for text\nclassification tasks. Specifically, FakeGAN is effective at detecting deceptive\nreviews.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:06:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Machiry", "Aravind", ""], ["Nilizadeh", "Shirin", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "1805.10367", "submitter": "Sijia Liu", "authors": "Sijia Liu and Bhavya Kailkhura and Pin-Yu Chen and Paishun Ting and\n  Shiyu Chang and Lisa Amini", "title": "Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As application demands for zeroth-order (gradient-free) optimization\naccelerate, the need for variance reduced and faster converging approaches is\nalso intensifying. This paper addresses these challenges by presenting: a) a\ncomprehensive theoretical analysis of variance reduced zeroth-order (ZO)\noptimization, b) a novel variance reduced ZO algorithm, called ZO-SVRG, and c)\nan experimental evaluation of our approach in the context of two compelling\napplications, black-box chemical material classification and generation of\nadversarial examples from black-box deep neural network models. Our theoretical\nanalysis uncovers an essential difficulty in the analysis of ZO-SVRG: the\nunbiased assumption on gradient estimates no longer holds. We prove that\ncompared to its first-order counterpart, ZO-SVRG with a two-point random\ngradient estimator could suffer an additional error of order $O(1/b)$, where\n$b$ is the mini-batch size. To mitigate this error, we propose two accelerated\nversions of ZO-SVRG utilizing variance reduced gradient estimators, which\nachieve the best rate known for ZO stochastic optimization (in terms of\niterations). Our extensive experimental results show that our approaches\noutperform other state-of-the-art ZO algorithms, and strike a balance between\nthe convergence rate and the function query complexity.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:18:19 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 17:02:19 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Liu", "Sijia", ""], ["Kailkhura", "Bhavya", ""], ["Chen", "Pin-Yu", ""], ["Ting", "Paishun", ""], ["Chang", "Shiyu", ""], ["Amini", "Lisa", ""]]}, {"id": "1805.10369", "submitter": "John Miller", "authors": "John Miller and Moritz Hardt", "title": "Stable Recurrent Models", "comments": "To appear in ICLR 2019. This paper was previously titled \"When\n  Recurrent Models Don't Need to Be Recurrent.\" The current version subsumes\n  all previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability is a fundamental property of dynamical systems, yet to this date it\nhas had little bearing on the practice of recurrent neural networks. In this\nwork, we conduct a thorough investigation of stable recurrent models.\nTheoretically, we prove stable recurrent neural networks are well approximated\nby feed-forward networks for the purpose of both inference and training by\ngradient descent. Empirically, we demonstrate stable recurrent models often\nperform as well as their unstable counterparts on benchmark sequence tasks.\nTaken together, these findings shed light on the effective power of recurrent\nnetworks and suggest much of sequence learning happens, or can be made to\nhappen, in the stable regime. Moreover, our results help to explain why in many\ncases practitioners succeed in replacing recurrent models by feed-forward\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:37:35 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 17:41:22 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 02:20:16 GMT"}, {"version": "v4", "created": "Sat, 2 Mar 2019 00:55:07 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Miller", "John", ""], ["Hardt", "Moritz", ""]]}, {"id": "1805.10377", "submitter": "Yichuan Zhang", "authors": "Yichuan Zhang, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Ergodic Inference: Accelerate Convergence by Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical inference methods are fundamentally important in machine\nlearning. Most state-of-the-art inference algorithms are variants of Markov\nchain Monte Carlo (MCMC) or variational inference (VI). However, both methods\nstruggle with limitations in practice: MCMC methods can be computationally\ndemanding; VI methods may have large bias. In this work, we aim to improve upon\nMCMC and VI by a novel hybrid method based on the idea of reducing simulation\nbias of finite-length MCMC chains using gradient-based optimisation. The\nproposed method can generate low-biased samples by increasing the length of\nMCMC simulation and optimising the MCMC hyper-parameters, which offers\nattractive balance between approximation bias and computational efficiency. We\nshow that our method produces promising results on popular benchmarks when\ncompared to recent hybrid methods of MCMC and VI.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:55:12 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 17:27:52 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 08:28:18 GMT"}, {"version": "v4", "created": "Wed, 16 Oct 2019 09:26:51 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Zhang", "Yichuan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1805.10378", "submitter": "Zachary Charles", "authors": "Zachary Charles, Dimitris Papailiopoulos", "title": "Gradient Coding via the Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent and its many variants, including mini-batch stochastic\ngradient descent, form the algorithmic foundation of modern large-scale machine\nlearning. Due to the size and scale of modern data, gradient computations are\noften distributed across multiple compute nodes. Unfortunately, such\ndistributed implementations can face significant delays caused by straggler\nnodes, i.e., nodes that are much slower than average. Gradient coding is a new\ntechnique for mitigating the effect of stragglers via algorithmic redundancy.\nWhile effective, previously proposed gradient codes can be computationally\nexpensive to construct, inaccurate, or susceptible to adversarial stragglers.\nIn this work, we present the stochastic block code (SBC), a gradient code based\non the stochastic block model. We show that SBCs are efficient, accurate, and\nthat under certain settings, adversarial straggler selection becomes as hard as\ndetecting a community structure in the multiple community, block stochastic\ngraph model.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 22:02:30 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1805.10384", "submitter": "Qi Qian", "authors": "Qi Qian, Jiasheng Tang, Hao Li, Shenghuo Zhu and Rong Jin", "title": "Large-scale Distance Metric Learning with Uncertainty", "comments": "accepted by CVPR'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning (DML) has been studied extensively in the past\ndecades for its superior performance with distance-based algorithms. Most of\nthe existing methods propose to learn a distance metric with pairwise or\ntriplet constraints. However, the number of constraints is quadratic or even\ncubic in the number of the original examples, which makes it challenging for\nDML to handle the large-scale data set. Besides, the real-world data may\ncontain various uncertainty, especially for the image data. The uncertainty can\nmislead the learning procedure and cause the performance degradation. By\ninvestigating the image data, we find that the original data can be observed\nfrom a small set of clean latent examples with different distortions. In this\nwork, we propose the margin preserving metric learning framework to learn the\ndistance metric and latent examples simultaneously. By leveraging the ideal\nproperties of latent examples, the training efficiency can be improved\nsignificantly while the learned metric also becomes robust to the uncertainty\nin the original data. Furthermore, we can show that the metric is learned from\nlatent examples only, but it can preserve the large margin property even for\nthe original data. The empirical study on the benchmark image data sets\ndemonstrates the efficacy and efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 22:44:59 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Qian", "Qi", ""], ["Tang", "Jiasheng", ""], ["Li", "Hao", ""], ["Zhu", "Shenghuo", ""], ["Jin", "Rong", ""]]}, {"id": "1805.10397", "submitter": "Dan Nguyen", "authors": "Dan Nguyen, Xun Jia, David Sher, Mu-Han Lin, Zohaib Iqbal, Hui Liu,\n  Steve Jiang", "title": "Three-Dimensional Radiotherapy Dose Prediction on Head and Neck Cancer\n  Patients with a Hierarchically Densely Connected U-net Deep Learning\n  Architecture", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6560/ab039b", "report-no": null, "categories": "physics.med-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The treatment planning process for patients with head and neck (H&N) cancer\nis regarded as one of the most complicated due to large target volume, multiple\nprescription dose levels, and many radiation-sensitive critical structures near\nthe target. Treatment planning for this site requires a high level of human\nexpertise and a tremendous amount of effort to produce personalized high\nquality plans, taking as long as a week, which deteriorates the chances of\ntumor control and patient survival. To solve this problem, we propose to\ninvestigate a deep learning-based dose prediction model, Hierarchically Densely\nConnected U-net, based on two highly popular network architectures: U-net and\nDenseNet. We find that this new architecture is able to accurately and\nefficiently predict the dose distribution, outperforming the other two models,\nthe Standard U-net and DenseNet, in homogeneity, dose conformity, and dose\ncoverage on the test data. Averaging across all organs at risk, our proposed\nmodel is capable of predicting the organ-at-risk max dose within 6.3% and mean\ndose within 5.1% of the prescription dose on the test data. The other models,\nthe Standard U-net and DenseNet, performed worse, having an averaged\norgan-at-risk max dose prediction error of 8.2% and 9.3%, respectively, and\naveraged mean dose prediction error of 6.4% and 6.8%, respectively. In\naddition, our proposed model used 12 times less trainable parameters than the\nStandard U-net, and predicted the patient dose 4 times faster than DenseNet.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:40:32 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 21:40:34 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 20:46:44 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nguyen", "Dan", ""], ["Jia", "Xun", ""], ["Sher", "David", ""], ["Lin", "Mu-Han", ""], ["Iqbal", "Zohaib", ""], ["Liu", "Hui", ""], ["Jiang", "Steve", ""]]}, {"id": "1805.10402", "submitter": "Xiran Zhou", "authors": "Xiran Zhou, Wenwen Li, Samantha T. Arundel, Jun Liu", "title": "Deep Convolutional Neural Networks for Map-Type Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maps are an important medium that enable people to comprehensively understand\nthe configuration of cultural activities and natural elements over different\ntimes and places. Although massive maps are available in the digital era, how\nto effectively and accurately access the required map remains a challenge\ntoday. Previous works partially related to map-type classification mainly\nfocused on map comparison and map matching at the local scale. The features\nderived from local map areas might be insufficient to characterize map content.\nTo facilitate establishing an automatic approach for accessing the needed map,\nthis paper reports our investigation into using deep learning techniques to\nrecognize seven types of map, including topographic map, terrain map, physical\nmap, urban scene map, the National Map, 3D map, nighttime map, orthophoto map,\nand land cover classification map. Experimental results show that the\nstate-of-the-art deep convolutional neural networks can support automatic\nmap-type classification. Additionally, the classification accuracy varies\naccording to different map-types. We hope our work can contribute to the\nimplementation of deep learning techniques in cartographical community and\nadvance the progress of Geographical Artificial Intelligence (GeoAI).\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 00:05:41 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhou", "Xiran", ""], ["Li", "Wenwen", ""], ["Arundel", "Samantha T.", ""], ["Liu", "Jun", ""]]}, {"id": "1805.10406", "submitter": "Simon Du", "authors": "Simon S. Du, Yining Wang, Sivaraman Balakrishnan, Pradeep Ravikumar,\n  Aarti Singh", "title": "Robust Nonparametric Regression under Huber's $\\epsilon$-contamination\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the non-parametric regression problem under Huber's\n$\\epsilon$-contamination model, in which an $\\epsilon$ fraction of observations\nare subject to arbitrary adversarial noise. We first show that a simple local\nbinning median step can effectively remove the adversary noise and this median\nestimator is minimax optimal up to absolute constants over the H\\\"{o}lder\nfunction class with smoothness parameters smaller than or equal to 1.\nFurthermore, when the underlying function has higher smoothness, we show that\nusing local binning median as pre-preprocessing step to remove the adversarial\nnoise, then we can apply any non-parametric estimator on top of the medians. In\nparticular we show local median binning followed by kernel smoothing and local\npolynomial regression achieve minimaxity over H\\\"{o}lder and Sobolev classes\nwith arbitrary smoothness parameters. Our main proof technique is a decoupled\nanalysis of adversary noise and stochastic noise, which can be potentially\napplied to other robust estimation problems. We also provide numerical results\nto verify the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 00:39:12 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Du", "Simon S.", ""], ["Wang", "Yining", ""], ["Balakrishnan", "Sivaraman", ""], ["Ravikumar", "Pradeep", ""], ["Singh", "Aarti", ""]]}, {"id": "1805.10407", "submitter": "Sang Michael Xie", "authors": "Neal Jean, Sang Michael Xie, Stefano Ermon", "title": "Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by\n  Minimizing Predictive Variance", "comments": "In Proceedings of Neural Information Processing Systems (NeurIPS)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large amounts of labeled data are typically required to train deep learning\nmodels. For many real-world problems, however, acquiring additional data can be\nexpensive or even impossible. We present semi-supervised deep kernel learning\n(SSDKL), a semi-supervised regression model based on minimizing predictive\nvariance in the posterior regularization framework. SSDKL combines the\nhierarchical representation learning of neural networks with the probabilistic\nmodeling capabilities of Gaussian processes. By leveraging unlabeled data, we\nshow improvements on a diverse set of real-world regression tasks over\nsupervised deep kernel learning and semi-supervised methods such as VAT and\nmean teacher adapted for regression.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 00:47:14 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 00:36:05 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 18:41:06 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 18:55:13 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Jean", "Neal", ""], ["Xie", "Sang Michael", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.10408", "submitter": "Hanie Sedghi", "authors": "Hanie Sedghi, Vineet Gupta, Philip M. Long", "title": "The Singular Values of Convolutional Layers", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the singular values of the linear transformation associated\nwith a standard 2D multi-channel convolutional layer, enabling their efficient\ncomputation. This characterization also leads to an algorithm for projecting a\nconvolutional layer onto an operator-norm ball. We show that this is an\neffective regularizer; for example, it improves the test error of a deep\nresidual network using batch normalization on CIFAR-10 from 6.2\\% to 5.3\\%.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 00:49:27 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 00:06:27 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Sedghi", "Hanie", ""], ["Gupta", "Vineet", ""], ["Long", "Philip M.", ""]]}, {"id": "1805.10413", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Xinyan Yan, Nolan Wagener, Byron Boots", "title": "Fast Policy Learning through Imitation and Reinforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) consists of a set of tools that leverage expert\ndemonstrations to quickly learn policies. However, if the expert is suboptimal,\nIL can yield policies with inferior performance compared to reinforcement\nlearning (RL). In this paper, we aim to provide an algorithm that combines the\nbest aspects of RL and IL. We accomplish this by formulating several popular RL\nand IL algorithms in a common mirror descent framework, showing that these\nalgorithms can be viewed as a variation on a single approach. We then propose\nLOKI, a strategy for policy learning that first performs a small but random\nnumber of IL iterations before switching to a policy gradient RL method. We\nshow that if the switching time is properly randomized, LOKI can learn to\noutperform a suboptimal expert and converge faster than running policy gradient\nfrom scratch. Finally, we evaluate the performance of LOKI experimentally in\nseveral simulated environments.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 02:18:01 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Cheng", "Ching-An", ""], ["Yan", "Xinyan", ""], ["Wagener", "Nolan", ""], ["Boots", "Byron", ""]]}, {"id": "1805.10437", "submitter": "Yanjun Li", "authors": "Yanjun Li and Yoram Bresler", "title": "Multichannel Sparse Blind Deconvolution on the Sphere", "comments": "50 pages, 10 figures. Some of the results in this paper were\n  presented at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multichannel blind deconvolution is the problem of recovering an unknown\nsignal $f$ and multiple unknown channels $x_i$ from their circular convolution\n$y_i=x_i \\circledast f$ ($i=1,2,\\dots,N$). We consider the case where the\n$x_i$'s are sparse, and convolution with $f$ is invertible. Our nonconvex\noptimization formulation solves for a filter $h$ on the unit sphere that\nproduces sparse output $y_i\\circledast h$. Under some technical assumptions, we\nshow that all local minima of the objective function correspond to the inverse\nfilter of $f$ up to an inherent sign and shift ambiguity, and all saddle points\nhave strictly negative curvatures. This geometric structure allows successful\nrecovery of $f$ and $x_i$ using a simple manifold gradient descent (MGD)\nalgorithm. Our theoretical findings are complemented by numerical experiments,\nwhich demonstrate superior performance of the proposed approach over the\nprevious methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 07:04:18 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 20:59:36 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Li", "Yanjun", ""], ["Bresler", "Yoram", ""]]}, {"id": "1805.10451", "submitter": "Na Lei", "authors": "Na Lei, Zhongxuan Luo, Shing-Tung Yau, David Xianfeng Gu", "title": "Geometric Understanding of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is the mainstream technique for many machine learning tasks,\nincluding image recognition, machine translation, speech recognition, and so\non. It has outperformed conventional methods in various fields and achieved\ngreat successes. Unfortunately, the understanding on how it works remains\nunclear. It has the central importance to lay down the theoretic foundation for\ndeep learning.\n  In this work, we give a geometric view to understand deep learning: we show\nthat the fundamental principle attributing to the success is the manifold\nstructure in data, namely natural high dimensional data concentrates close to a\nlow-dimensional manifold, deep learning learns the manifold and the probability\ndistribution on it.\n  We further introduce the concepts of rectified linear complexity for deep\nneural network measuring its learning capability, rectified linear complexity\nof an embedding manifold describing the difficulty to be learned. Then we show\nfor any deep neural network with fixed architecture, there exists a manifold\nthat cannot be learned by the network. Finally, we propose to apply optimal\nmass transportation theory to control the probability distribution in the\nlatent space.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 09:15:53 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 00:30:35 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Lei", "Na", ""], ["Luo", "Zhongxuan", ""], ["Yau", "Shing-Tung", ""], ["Gu", "David Xianfeng", ""]]}, {"id": "1805.10458", "submitter": "Mouhammd Alkasassbeh", "authors": "Ibrahim Obeidat, Nabhan Hamadneh, Mouhammd Al-kasassbeh, Mohammad\n  Almseidin", "title": "Intensive Preprocessing of KDD Cup 99 for Network Intrusion\n  Classification Using Machine Learning Techniques", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network security engineers work to keep services available all the time by\nhandling intruder attacks. Intrusion Detection System (IDS) is one of the\nobtainable mechanism that used to sense and classify any abnormal actions.\nTherefore, the IDS must be always up to date with the latest intruder attacks\nsignatures to preserve confidentiality, integrity and availability of the\nservices. The speed of the IDS is very important issue as well learning the new\nattacks. This research work illustrates how the Knowledge Discovery and Data\nMining (or Knowledge Discovery in Databases) KDD dataset is very handy for\ntesting and evaluating different Machine Learning Techniques. It mainly focuses\non the KDD preprocess part in order to prepare a decent and fair experimental\ndata set. The techniques J48, Random Forest, Random Tree, MLP, Na\\\"ive Bayes\nand Bayes Network classifiers have been chosen for this study. It has been\nproven that the Random forest classifier has achieved the highest accuracy rate\nfor detecting and classifying all KDD dataset attacks, which are of type (DOS,\nR2L, U2R, and PROBE)\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 10:12:27 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 08:10:15 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Obeidat", "Ibrahim", ""], ["Hamadneh", "Nabhan", ""], ["Al-kasassbeh", "Mouhammd", ""], ["Almseidin", "Mohammad", ""]]}, {"id": "1805.10469", "submitter": "Tuan Anh Le", "authors": "Tuan Anh Le, Adam R. Kosiorek, N. Siddharth, Yee Whye Teh, Frank Wood", "title": "Revisiting Reweighted Wake-Sleep for Models with Stochastic Control Flow", "comments": "Tuan Anh Le and Adam R. Kosiorek contributed equally; accepted to\n  Uncertainty in Artificial Intelligence 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic control-flow models (SCFMs) are a class of generative models that\ninvolve branching on choices from discrete random variables. Amortized\ngradient-based learning of SCFMs is challenging as most approaches targeting\ndiscrete variables rely on their continuous relaxations---which can be\nintractable in SCFMs, as branching on relaxations requires evaluating all\n(exponentially many) branching paths. Tractable alternatives mainly combine\nREINFORCE with complex control-variate schemes to improve the variance of naive\nestimators. Here, we revisit the reweighted wake-sleep (RWS) (Bornschein and\nBengio, 2015) algorithm, and through extensive evaluations, show that it\noutperforms current state-of-the-art methods in learning SCFMs. Further, in\ncontrast to the importance weighted autoencoder, we observe that RWS learns\nbetter models and inference networks with increasing numbers of particles. Our\nresults suggest that RWS is a competitive, often preferable, alternative for\nlearning SCFMs.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 12:16:46 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 13:04:45 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Le", "Tuan Anh", ""], ["Kosiorek", "Adam R.", ""], ["Siddharth", "N.", ""], ["Teh", "Yee Whye", ""], ["Wood", "Frank", ""]]}, {"id": "1805.10477", "submitter": "Zhao Song", "authors": "Kai Zhong, Zhao Song, Prateek Jain, Inderjit S. Dhillon", "title": "Nonlinear Inductive Matrix Completion based on One-layer Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of a recommendation system is to predict the interest of a user in a\ngiven item by exploiting the existing set of ratings as well as certain\nuser/item features. A standard approach to modeling this problem is Inductive\nMatrix Completion where the predicted rating is modeled as an inner product of\nthe user and the item features projected onto a latent space. In order to learn\nthe parameters effectively from a small number of observed ratings, the latent\nspace is constrained to be low-dimensional which implies that the parameter\nmatrix is constrained to be low-rank. However, such bilinear modeling of the\nratings can be limiting in practice and non-linear prediction functions can\nlead to significant improvements. A natural approach to introducing\nnon-linearity in the prediction function is to apply a non-linear activation\nfunction on top of the projected user/item features. Imposition of\nnon-linearities further complicates an already challenging problem that has two\nsources of non-convexity: a) low-rank structure of the parameter matrix, and b)\nnon-linear activation function. We show that one can still solve the non-linear\nInductive Matrix Completion problem using gradient descent type methods as long\nas the solution is initialized well. That is, close to the optima, the\noptimization function is strongly convex and hence admits standard optimization\ntechniques, at least for certain activation functions, such as Sigmoid and\ntanh. We also highlight the importance of the activation function and show how\nReLU can behave significantly differently than say a sigmoid function. Finally,\nwe apply our proposed technique to recommendation systems and semi-supervised\nclustering, and show that our method can lead to much better performance than\nstandard linear Inductive Matrix Completion methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 13:01:40 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhong", "Kai", ""], ["Song", "Zhao", ""], ["Jain", "Prateek", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1805.10487", "submitter": "Atsushi Suzuki", "authors": "Yosuke Enokida, Atsushi Suzuki, Kenji Yamanishi", "title": "Stable Geodesic Update on Hyperbolic Space and its Application to\n  Poincare Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hyperbolic space has been shown to be more capable of modeling complex\nnetworks than a Euclidean space. This paper proposes an explicit update rule\nalong geodesics in a hyperbolic space. The convergence of our algorithm is\ntheoretically guaranteed, and the convergence rate is better than the\nconventional Euclidean gradient descent algorithm. Moreover, our algorithm\navoids the \"bias\" problem of existing methods using the Riemannian gradient.\nExperimental results demonstrate the good performance of our algorithm in the\n\\Poincare embeddings of knowledge base data.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 14:06:23 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Enokida", "Yosuke", ""], ["Suzuki", "Atsushi", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1805.10498", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Maurizio Omologo", "title": "Automatic context window composition for distant speech recognition", "comments": "This is a preprint version of the paper published on Speech\n  Communication Journal, 2018. Please see\n  https://www.sciencedirect.com/science/article/pii/S0167639318300128 for the\n  published version of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant speech recognition is being revolutionized by deep learning, that has\ncontributed to significantly outperform previous HMM-GMM systems. A key aspect\nbehind the rapid rise and success of DNNs is their ability to better manage\nlarge time contexts. With this regard, asymmetric context windows that embed\nmore past than future frames have been recently used with feed-forward neural\nnetworks. This context configuration turns out to be useful not only to address\nlow-latency speech recognition, but also to boost the recognition performance\nunder reverberant conditions. This paper investigates on the mechanisms\noccurring inside DNNs, which lead to an effective application of asymmetric\ncontexts.In particular, we propose a novel method for automatic context window\ncomposition based on a gradient analysis. The experiments, performed with\ndifferent acoustic environments, features, DNN architectures, microphone\nsettings, and recognition tasks show that our simple and efficient strategy\nleads to a less redundant frame configuration, which makes DNN training more\neffective in reverberant scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 15:36:44 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Omologo", "Maurizio", ""]]}, {"id": "1805.10503", "submitter": "Pengfei Zhang", "authors": "Ning Sun, Jinmin Yi, Pengfei Zhang, Huitao Shen and Hui Zhai", "title": "Deep Learning Topological Invariants of Band Insulators", "comments": "8 pages, 5 figures", "journal-ref": "Phys. Rev. B 98, 085402 (2018)", "doi": "10.1103/PhysRevB.98.085402", "report-no": null, "categories": "cond-mat.str-el cs.AI cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we design and train deep neural networks to predict topological\ninvariants for one-dimensional four-band insulators in AIII class whose\ntopological invariant is the winding number, and two-dimensional two-band\ninsulators in A class whose topological invariant is the Chern number. Given\nHamiltonians in the momentum space as the input, neural networks can predict\ntopological invariants for both classes with accuracy close to or higher than\n90%, even for Hamiltonians whose invariants are beyond the training data set.\nDespite the complexity of the neural network, we find that the output of\ncertain intermediate hidden layers resembles either the winding angle for\nmodels in AIII class or the solid angle (Berry curvature) for models in A\nclass, indicating that neural networks essentially capture the mathematical\nformula of topological invariants. Our work demonstrates the ability of neural\nnetworks to predict topological invariants for complicated models with local\nHamiltonians as the only input, and offers an example that even a deep neural\nnetwork is understandable.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 16:10:47 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 10:48:10 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Sun", "Ning", ""], ["Yi", "Jinmin", ""], ["Zhang", "Pengfei", ""], ["Shen", "Huitao", ""], ["Zhai", "Hui", ""]]}, {"id": "1805.10522", "submitter": "Maurizio Filippone", "authors": "Gia-Lac Tran, Edwin V. Bonilla, John P. Cunningham, Pietro Michiardi,\n  Maurizio Filippone", "title": "Calibrating Deep Convolutional Gaussian Processes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of Convolutional Neural Networks (CNNs) in applications\nwhere decision-making under uncertainty is fundamental, has brought a great\ndeal of attention to the ability of these models to accurately quantify the\nuncertainty in their predictions. Previous work on combining CNNs with Gaussian\nprocesses (GPs) has been developed under the assumption that the predictive\nprobabilities of these models are well-calibrated. In this paper we show that,\nin fact, current combinations of CNNs and GPs are miscalibrated. We proposes a\nnovel combination that considerably outperforms previous approaches on this\naspect, while achieving state-of-the-art performance on image classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 19:00:01 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tran", "Gia-Lac", ""], ["Bonilla", "Edwin V.", ""], ["Cunningham", "John P.", ""], ["Michiardi", "Pietro", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1805.10531", "submitter": "Christopher Metzler", "authors": "Christopher A. Metzler, Ali Mousavi, Reinhard Heckel, Richard G.\n  Baraniuk", "title": "Unsupervised Learning with Stein's Unbiased Risk Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from unlabeled and noisy data is one of the grand challenges of\nmachine learning. As such, it has seen a flurry of research with new ideas\nproposed continuously. In this work, we revisit a classical idea: Stein's\nUnbiased Risk Estimator (SURE). We show that, in the context of image recovery,\nSURE and its generalizations can be used to train convolutional neural networks\n(CNNs) for a range of image denoising and recovery problems without any ground\ntruth data.\n  Specifically, our goal is to reconstruct an image $x$ from a noisy linear\ntransformation (measurement) of the image. We consider two scenarios: one where\nno additional data is available and one where we have measurements of other\nimages that are drawn from the same noisy distribution as $x$, but have no\naccess to the clean images. Such is the case, for instance, in the context of\nmedical imaging, microscopy, and astronomy, where noise-less ground truth data\nis rarely available.\n  We show that in this situation, SURE can be used to estimate the\nmean-squared-error loss associated with an estimate of $x$. Using this estimate\nof the loss, we train networks to perform denoising and compressed sensing\nrecovery. In addition, we also use the SURE framework to partially explain and\nimprove upon an intriguing results presented by Ulyanov et al. in \"Deep Image\nPrior\": that a network initialized with random weights and fit to a single\nnoisy image can effectively denoise that image.\n  Public implementations of the networks and methods described in this paper\ncan be found at https://github.com/ricedsp/D-AMP_Toolbox.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 20:01:15 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 22:21:21 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 20:24:17 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Metzler", "Christopher A.", ""], ["Mousavi", "Ali", ""], ["Heckel", "Reinhard", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1805.10559", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Ananda Theertha Suresh, Felix Yu, Sanjiv Kumar, H.\n  Brendan Mcmahan", "title": "cpSGD: Communication-efficient and differentially-private distributed\n  SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stochastic gradient descent is an important subroutine in\ndistributed learning. A setting of particular interest is when the clients are\nmobile devices, where two important concerns are communication efficiency and\nthe privacy of the clients. Several recent works have focused on reducing the\ncommunication cost or introducing privacy guarantees, but none of the proposed\ncommunication efficient methods are known to be privacy preserving and none of\nthe known privacy mechanisms are known to be communication efficient. To this\nend, we study algorithms that achieve both communication efficiency and\ndifferential privacy. For $d$ variables and $n \\approx d$ clients, the proposed\nmethod uses $O(\\log \\log(nd))$ bits of communication per client per coordinate\nand ensures constant privacy.\n  We also extend and improve previous analysis of the \\emph{Binomial mechanism}\nshowing that it achieves nearly the same utility as the Gaussian mechanism,\nwhile requiring fewer representation bits, which can be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 00:37:59 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Agarwal", "Naman", ""], ["Suresh", "Ananda Theertha", ""], ["Yu", "Felix", ""], ["Kumar", "Sanjiv", ""], ["Mcmahan", "H. Brendan", ""]]}, {"id": "1805.10561", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Russell Stewart, Jiaming Song, Volodymyr Kuleshov, Stefano\n  Ermon", "title": "Adversarial Constraint Learning for Structured Prediction", "comments": "To appear at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based learning reduces the burden of collecting labels by having\nusers specify general properties of structured outputs, such as constraints\nimposed by physical laws. We propose a novel framework for simultaneously\nlearning these constraints and using them for supervision, bypassing the\ndifficulty of using domain expertise to manually specify constraints. Learning\nrequires a black-box simulator of structured outputs, which generates valid\nlabels, but need not model their corresponding inputs or the input-label\nrelationship. At training time, we constrain the model to produce outputs that\ncannot be distinguished from simulated labels by adversarial training.\nProviding our framework with a small number of labeled inputs gives rise to a\nnew semi-supervised structured prediction model; we evaluate this model on\nmultiple tasks --- tracking, pose estimation and time series prediction --- and\nfind that it achieves high accuracy with only a small number of labeled inputs.\nIn some cases, no labels are required at all.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 01:27:28 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 02:28:48 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Ren", "Hongyu", ""], ["Stewart", "Russell", ""], ["Song", "Jiaming", ""], ["Kuleshov", "Volodymyr", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.10572", "submitter": "Wei Cao", "authors": "Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li, Yitan Li", "title": "BRITS: Bidirectional Recurrent Imputation for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are widely used as signals in many classification/regression\ntasks. It is ubiquitous that time series contains many missing values. Given\nmultiple correlated time series data, how to fill in missing values and to\npredict their class labels? Existing imputation methods often impose strong\nassumptions of the underlying data generating process, such as linear dynamics\nin the state space. In this paper, we propose BRITS, a novel method based on\nrecurrent neural networks for missing value imputation in time series data. Our\nproposed method directly learns the missing values in a bidirectional recurrent\ndynamical system, without any specific assumption. The imputed values are\ntreated as variables of RNN graph and can be effectively updated during the\nbackpropagation.BRITS has three advantages: (a) it can handle multiple\ncorrelated missing values in time series; (b) it generalizes to time series\nwith nonlinear dynamics underlying; (c) it provides a data-driven imputation\nprocedure and applies to general settings with missing data.We evaluate our\nmodel on three real-world datasets, including an air quality dataset, a\nhealth-care data, and a localization data for human activity. Experiments show\nthat our model outperforms the state-of-the-art methods in both imputation and\nclassification/regression accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 02:42:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Cao", "Wei", ""], ["Wang", "Dong", ""], ["Li", "Jian", ""], ["Zhou", "Hao", ""], ["Li", "Lei", ""], ["Li", "Yitan", ""]]}, {"id": "1805.10579", "submitter": "Alireza Fallah", "authors": "Necdet Serhat Aybat, Alireza Fallah, Mert Gurbuzbalaban, Asuman\n  Ozdaglar", "title": "Robust Accelerated Gradient Methods for Smooth Strongly Convex Functions", "comments": "To appear in SIAM Journal on Optimization (SIOPT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the trade-offs between convergence rate and robustness to gradient\nerrors in designing a first-order algorithm. We focus on gradient descent (GD)\nand accelerated gradient (AG) methods for minimizing strongly convex functions\nwhen the gradient has random errors in the form of additive white noise. With\ngradient errors, the function values of the iterates need not converge to the\noptimal value; hence, we define the robustness of an algorithm to noise as the\nasymptotic expected suboptimality of the iterate sequence to input noise power.\nFor this robustness measure, we provide exact expressions for the quadratic\ncase using tools from robust control theory and tight upper bounds for the\nsmooth strongly convex case using Lyapunov functions certified through matrix\ninequalities. We use these characterizations within an optimization problem\nwhich selects parameters of each algorithm to achieve a particular trade-off\nbetween rate and robustness. Our results show that AG can achieve acceleration\nwhile being more robust to random gradient errors. This behavior is quite\ndifferent than previously reported in the deterministic gradient noise setting.\nWe also establish some connections between the robustness of an algorithm and\nhow quickly it can converge back to the optimal solution if it is perturbed\nfrom the optimal point with deterministic noise. Our framework also leads to\npractical algorithms that can perform better than other state-of-the-art\nmethods in the presence of random gradient noise.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 04:22:14 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 19:58:24 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 03:42:55 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 19:18:43 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Aybat", "Necdet Serhat", ""], ["Fallah", "Alireza", ""], ["Gurbuzbalaban", "Mert", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "1805.10582", "submitter": "Sen Zhao", "authors": "Sen Zhao, Mahdi Milani Fard, Harikrishna Narasimhan and Maya Gupta", "title": "Metric-Optimized Example Weights", "comments": "Proceedings of the 36th International Conference on Machine Learning\n  (ICML'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world machine learning applications often have complex test metrics, and\nmay have training and test data that are not identically distributed. Motivated\nby known connections between complex test metrics and cost-weighted learning,\nwe propose addressing these issues by using a weighted loss function with a\nstandard loss, where the weights on the training examples are learned to\noptimize the test metric on a validation set. These metric-optimized example\nweights can be learned for any test metric, including black box and customized\nones for specific applications. We illustrate the performance of the proposed\nmethod on diverse public benchmark datasets and real-world applications. We\nalso provide a generalization bound for the method.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 06:12:50 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 06:13:30 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 19:09:40 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhao", "Sen", ""], ["Fard", "Mahdi Milani", ""], ["Narasimhan", "Harikrishna", ""], ["Gupta", "Maya", ""]]}, {"id": "1805.10611", "submitter": "Rui Gao", "authors": "Rui Gao, Liyan Xie, Yao Xie and Huan Xu", "title": "Robust Hypothesis Testing Using Wasserstein Uncertainty Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a novel computationally efficient and general framework for robust\nhypothesis testing. The new framework features a new way to construct\nuncertainty sets under the null and the alternative distributions, which are\nsets centered around the empirical distribution defined via Wasserstein metric,\nthus our approach is data-driven and free of distributional assumptions. We\ndevelop a convex safe approximation of the minimax formulation and show that\nsuch approximation renders a nearly-optimal detector among the family of all\npossible tests. By exploiting the structure of the least favorable\ndistribution, we also develop a tractable reformulation of such approximation,\nwith complexity independent of the dimension of observation space and can be\nnearly sample-size-independent in general. Real-data example using human\nactivity data demonstrated the excellent performance of the new robust\ndetector.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 11:50:54 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Gao", "Rui", ""], ["Xie", "Liyan", ""], ["Xie", "Yao", ""], ["Xu", "Huan", ""]]}, {"id": "1805.10615", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Friedrich Solowjow, Sebastian Trimpe, Bernhard\n  Sch\\\"olkopf", "title": "A Local Information Criterion for Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding a sequence of observations is an essential task with many\napplications. The encoding can become highly efficient when the observations\nare generated by a dynamical system. A dynamical system imposes regularities on\nthe observations that can be leveraged to achieve a more efficient code. We\npropose a method to encode a given or learned dynamical system. Apart from its\napplication for encoding a sequence of observations, we propose to use the\ncompression achieved by this encoding as a criterion for model selection. Given\na dataset, different learning algorithms result in different models. But not\nall learned models are equally good. We show that the proposed encoding\napproach can be used to choose the learned model which is closer to the true\nunderlying dynamics. We provide experiments for both encoding and model\nselection, and theoretical results that shed light on why the approach works.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 12:57:54 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Mehrjou", "Arash", ""], ["Solowjow", "Friedrich", ""], ["Trimpe", "Sebastian", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1805.10616", "submitter": "Elahe Ghalebi", "authors": "Elahe Ghalebi, Baharan Mirzasoleiman, Radu Grosu, Jure Leskovec", "title": "Dynamic Network Model from Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can evolving networks be inferred and modeled without directly observing\ntheir nodes and edges? In many applications, the edges of a dynamic network\nmight not be observed, but one can observe the dynamics of stochastic cascading\nprocesses (e.g., information diffusion, virus propagation) occurring over the\nunobserved network. While there have been efforts to infer networks based on\nsuch data, providing a generative probabilistic model that is able to identify\nthe underlying time-varying network remains an open question. Here we consider\nthe problem of inferring generative dynamic network models based on network\ncascade diffusion data. We propose a novel framework for providing a\nnon-parametric dynamic network model--based on a mixture of coupled\nhierarchical Dirichlet processes-- based on data capturing cascade node\ninfection times. Our approach allows us to infer the evolving community\nstructure in networks and to obtain an explicit predictive distribution over\nthe edges of the underlying network--including those that were not involved in\ntransmission of any cascade, or are likely to appear in the future. We show the\neffectiveness of our approach using extensive experiments on synthetic as well\nas real-world networks.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 12:57:58 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 17:17:13 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 10:15:52 GMT"}, {"version": "v4", "created": "Mon, 25 Feb 2019 15:01:59 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ghalebi", "Elahe", ""], ["Mirzasoleiman", "Baharan", ""], ["Grosu", "Radu", ""], ["Leskovec", "Jure", ""]]}, {"id": "1805.10636", "submitter": "Federico Errica", "authors": "Davide Bacciu, Federico Errica, Alessio Micheli", "title": "Contextual Graph Markov Model: A Deep and Generative Approach to Graph\n  Processing", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80 (2018) 294-303", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Contextual Graph Markov Model, an approach combining ideas\nfrom generative models and neural networks for the processing of graph data. It\nfounds on a constructive methodology to build a deep architecture comprising\nlayers of probabilistic models that learn to encode the structured information\nin an incremental fashion. Context is diffused in an efficient and scalable way\nacross the graph vertexes and edges. The resulting graph encoding is used in\ncombination with discriminative models to address structure classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 15:04:05 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 09:45:51 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bacciu", "Davide", ""], ["Errica", "Federico", ""], ["Micheli", "Alessio", ""]]}, {"id": "1805.10638", "submitter": "Bailin Deng", "authors": "Juyong Zhang, Yuxin Yao, Yue Peng, Hao Yu, Bailin Deng", "title": "Fast K-Means Clustering with Anderson Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to accelerate Lloyd's algorithm for K-Means\nclustering. Unlike previous acceleration approaches that reduce computational\ncost per iterations or improve initialization, our approach is focused on\nreducing the number of iterations required for convergence. This is achieved by\ntreating the assignment step and the update step of Lloyd's algorithm as a\nfixed-point iteration, and applying Anderson acceleration, a well-established\ntechnique for accelerating fixed-point solvers. Classical Anderson acceleration\nutilizes m previous iterates to find an accelerated iterate, and its\nperformance on K-Means clustering can be sensitive to choice of m and the\ndistribution of samples. We propose a new strategy to dynamically adjust the\nvalue of m, which achieves robust and consistent speedups across different\nproblem instances. Our method complements existing acceleration techniques, and\ncan be combined with them to achieve state-of-the-art performance. We perform\nextensive experiments to evaluate the performance of the proposed method, where\nit outperforms other algorithms in 106 out of 120 test cases, and the mean\ndecrease ratio of computational time is more than 33%.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 15:17:33 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhang", "Juyong", ""], ["Yao", "Yuxin", ""], ["Peng", "Yue", ""], ["Yu", "Hao", ""], ["Deng", "Bailin", ""]]}, {"id": "1805.10652", "submitter": "Gokula Krishnan Santhanam", "authors": "Gokula Krishnan Santhanam, Paulina Grnarova", "title": "Defending Against Adversarial Attacks by Leveraging an Entire GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that state-of-the-art models are highly vulnerable to\nadversarial perturbations of the input. We propose cowboy, an approach to\ndetecting and defending against adversarial attacks by using both the\ndiscriminator and generator of a GAN trained on the same dataset. We show that\nthe discriminator consistently scores the adversarial samples lower than the\nreal samples across multiple attacks and datasets. We provide empirical\nevidence that adversarial samples lie outside of the data manifold learned by\nthe GAN. Based on this, we propose a cleaning method which uses both the\ndiscriminator and generator of the GAN to project the samples back onto the\ndata manifold. This cleaning procedure is independent of the classifier and\ntype of attack and thus can be deployed in existing systems.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 16:47:31 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Santhanam", "Gokula Krishnan", ""], ["Grnarova", "Paulina", ""]]}, {"id": "1805.10662", "submitter": "Supratik Paul", "authors": "Supratik Paul, Michael A. Osborne, Shimon Whiteson", "title": "Fingerprint Policy Optimisation for Robust Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods ignore the potential value of adjusting environment\nvariables: unobservable state features that are randomly determined by the\nenvironment in a physical setting, but are controllable in a simulator. This\ncan lead to slow learning, or convergence to suboptimal policies, if the\nenvironment variable has a large impact on the transition dynamics. In this\npaper, we present fingerprint policy optimisation (FPO), which finds a policy\nthat is optimal in expectation across the distribution of environment\nvariables. The central idea is to use Bayesian optimisation (BO) to actively\nselect the distribution of the environment variable that maximises the\nimprovement generated by each iteration of the policy gradient method. To make\nthis BO practical, we contribute two easy-to-compute low-dimensional\nfingerprints of the current policy. Our experiments show that FPO can\nefficiently learn policies that are robust to significant rare events, which\nare unlikely to be observable under random sampling, but are key to learning\ngood policies.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 17:50:22 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 14:20:57 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 14:07:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Paul", "Supratik", ""], ["Osborne", "Michael A.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1805.10665", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Eli Gibson, Nooshin Ghavami, Ester Bonmati, Caroline M.\n  Moore, Mark Emberton, Tom Vercauteren, J. Alison Noble, Dean C. Barratt", "title": "Adversarial Deformation Regularization for Training Image Registration\n  Neural Networks", "comments": "Accepted to MICCAI 2018", "journal-ref": null, "doi": "10.1007/978-3-030-00928-1_87", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an adversarial learning approach to constrain convolutional\nneural network training for image registration, replacing heuristic smoothness\nmeasures of displacement fields often used in these tasks. Using\nminimally-invasive prostate cancer intervention as an example application, we\ndemonstrate the feasibility of utilizing biomechanical simulations to\nregularize a weakly-supervised anatomical-label-driven registration network for\naligning pre-procedural magnetic resonance (MR) and 3D intra-procedural\ntransrectal ultrasound (TRUS) images. A discriminator network is optimized to\ndistinguish the registration-predicted displacement fields from the motion data\nsimulated by finite element analysis. During training, the registration network\nsimultaneously aims to maximize similarity between anatomical labels that\ndrives image alignment and to minimize an adversarial generator loss that\nmeasures divergence between the predicted- and simulated deformation. The\nend-to-end trained network enables efficient and fully-automated registration\nthat only requires an MR and TRUS image pair as input, without anatomical\nlabels or simulated data during inference. 108 pairs of labelled MR and TRUS\nimages from 76 prostate cancer patients and 71,500 nonlinear finite-element\nsimulations from 143 different patients were used for this study. We show that,\nwith only gland segmentation as training labels, the proposed method can help\npredict physically plausible deformation without any other smoothness penalty.\nBased on cross-validation experiments using 834 pairs of independent validation\nlandmarks, the proposed adversarial-regularized registration achieved a target\nregistration error of 6.3 mm that is significantly lower than those from\nseveral other regularization methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 17:56:51 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Hu", "Yipeng", ""], ["Gibson", "Eli", ""], ["Ghavami", "Nooshin", ""], ["Bonmati", "Ester", ""], ["Moore", "Caroline M.", ""], ["Emberton", "Mark", ""], ["Vercauteren", "Tom", ""], ["Noble", "J. Alison", ""], ["Barratt", "Dean C.", ""]]}, {"id": "1805.10692", "submitter": "Simon Wiedemann", "authors": "Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Compact and Computationally Efficient Representation of Deep Neural\n  Networks", "comments": "17 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the core of any inference procedure in deep neural networks are dot\nproduct operations, which are the component that require the highest\ncomputational resources. A common approach to reduce the cost of inference is\nto reduce its memory complexity by lowering the entropy of the weight matrices\nof the neural network, e.g., by pruning and quantizing their elements. However,\nthe quantized weight matrices are then usually represented either by a dense or\nsparse matrix storage format, whose associated dot product complexity is not\nbounded by the entropy of the matrix. This means that the associated inference\ncomplexity ultimately depends on the implicit statistical assumptions that\nthese matrix representations make about the weight distribution, which can be\nin many cases suboptimal. In this paper we address this issue and present new\nefficient representations for matrices with low entropy statistics. These new\nmatrix formats have the novel property that their memory and algorithmic\ncomplexity are implicitly bounded by the entropy of the matrix, consequently\nimplying that they are guaranteed to become more efficient as the entropy of\nthe matrix is being reduced. In our experiments we show that performing the dot\nproduct under these new matrix formats can indeed be more energy and time\nefficient under practically relevant assumptions. For instance, we are able to\nattain up to x42 compression ratios, x5 speed ups and x90 energy savings when\nwe convert in a lossless manner the weight matrices of state-of-the-art\nnetworks such as AlexNet, VGG-16, ResNet152 and DenseNet into the new matrix\nformats and benchmark their respective dot product operation.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 21:30:33 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 17:38:52 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1805.10694", "submitter": "Hadi Daneshmand", "authors": "Jonas Kohler, Hadi Daneshmand, Aurelien Lucchi, Ming Zhou, Klaus\n  Neymeyr, Thomas Hofmann", "title": "Exponential convergence rates for Batch Normalization: The power of\n  length-direction decoupling in non-convex optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization techniques such as Batch Normalization have been applied\nsuccessfully for training deep neural networks. Yet, despite its apparent\nempirical benefits, the reasons behind the success of Batch Normalization are\nmostly hypothetical. We here aim to provide a more thorough theoretical\nunderstanding from a classical optimization perspective. Our main contribution\ntowards this goal is the identification of various problem instances in the\nrealm of machine learning where % -- under certain assumptions-- Batch\nNormalization can provably accelerate optimization. We argue that this\nacceleration is due to the fact that Batch Normalization splits the\noptimization task into optimizing length and direction of the parameters\nseparately. This allows gradient-based methods to leverage a favourable global\nstructure in the loss landscape that we prove to exist in Learning Halfspace\nproblems and neural network training with Gaussian inputs. We thereby turn\nBatch Normalization from an effective practical heuristic into a provably\nconverging algorithm for these settings. Furthermore, we substantiate our\nanalysis with empirical evidence that suggests the validity of our theoretical\nresults in a broader context.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 21:33:37 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 21:28:18 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2018 08:49:36 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Kohler", "Jonas", ""], ["Daneshmand", "Hadi", ""], ["Lucchi", "Aurelien", ""], ["Zhou", "Ming", ""], ["Neymeyr", "Klaus", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1805.10724", "submitter": "Bum Chul Kwon", "authors": "Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin\n  Kim, Soonwook Kwon, Jimeng Sun, Jaegul Choo", "title": "RetainVis: Visual Analytics with Interpretable and Interactive Recurrent\n  Neural Networks on Electronic Medical Records", "comments": "Accepted at IEEE VIS 2018. To appear in IEEE Transactions on\n  Visualization and Computer Graphics in January 2019", "journal-ref": null, "doi": "10.1109/TVCG.2018.2865027", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently seen many successful applications of recurrent neural\nnetworks (RNNs) on electronic medical records (EMRs), which contain histories\nof patients' diagnoses, medications, and other various events, in order to\npredict the current and future states of patients. Despite the strong\nperformance of RNNs, it is often challenging for users to understand why the\nmodel makes a particular prediction. Such black-box nature of RNNs can impede\nits wide adoption in clinical practice. Furthermore, we have no established\nmethods to interactively leverage users' domain expertise and prior knowledge\nas inputs for steering the model. Therefore, our design study aims to provide a\nvisual analytics solution to increase interpretability and interactivity of\nRNNs via a joint effort of medical experts, artificial intelligence scientists,\nand visual analytics researchers. Following the iterative design process\nbetween the experts, we design, implement, and evaluate a visual analytics tool\ncalled RetainVis, which couples a newly improved, interpretable and interactive\nRNN-based model called RetainEX and visualizations for users' exploration of\nEMR data in the context of prediction tasks. Our study shows the effective use\nof RetainVis for gaining insights into how individual medical codes contribute\nto making risk predictions, using EMRs of patients with heart failure and\ncataract symptoms. Our study also demonstrates how we made substantial changes\nto the state-of-the-art RNN model called RETAIN in order to make use of\ntemporal information and increase interactivity. This study will provide a\nuseful guideline for researchers that aim to design an interpretable and\ninteractive visual analytics tool for RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 01:30:53 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 16:34:35 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 05:31:15 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Kwon", "Bum Chul", ""], ["Choi", "Min-Je", ""], ["Kim", "Joanne Taery", ""], ["Choi", "Edward", ""], ["Kim", "Young Bin", ""], ["Kwon", "Soonwook", ""], ["Sun", "Jimeng", ""], ["Choo", "Jaegul", ""]]}, {"id": "1805.10727", "submitter": "Shichen Liu", "authors": "Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, Luo Si", "title": "Perceive Your Users in Depth: Learning Universal User Representations\n  from Multiple E-commerce Tasks", "comments": "10 pages, accepted an oral paper in sigKDD2018(industry track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks such as search and recommendation have become increas- ingly important\nfor E-commerce to deal with the information over- load problem. To meet the\ndiverse needs of di erent users, person- alization plays an important role. In\nmany large portals such as Taobao and Amazon, there are a bunch of di erent\ntypes of search and recommendation tasks operating simultaneously for person-\nalization. However, most of current techniques address each task separately.\nThis is suboptimal as no information about users shared across di erent tasks.\nIn this work, we propose to learn universal user representations across\nmultiple tasks for more e ective personalization. In partic- ular, user\nbehavior sequences (e.g., click, bookmark or purchase of products) are modeled\nby LSTM and attention mechanism by integrating all the corresponding content,\nbehavior and temporal information. User representations are shared and learned\nin an end-to-end setting across multiple tasks. Bene ting from better\ninformation utilization of multiple tasks, the user representations are more e\nective to re ect their interests and are more general to be transferred to new\ntasks. We refer this work as Deep User Perception Network (DUPN) and conduct an\nextensive set of o ine and online experiments. Across all tested ve di erent\ntasks, our DUPN consistently achieves better results by giving more e ective\nuser representations. Moreover, we deploy DUPN in large scale operational tasks\nin Taobao. Detailed implementations, e.g., incre- mental model updating, are\nalso provided to address the practical issues for the real world applications.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 01:43:04 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Ni", "Yabo", ""], ["Ou", "Dan", ""], ["Liu", "Shichen", ""], ["Li", "Xiang", ""], ["Ou", "Wenwu", ""], ["Zeng", "Anxiang", ""], ["Si", "Luo", ""]]}, {"id": "1805.10734", "submitter": "William Lotter", "authors": "William Lotter, Gabriel Kreiman, David Cox", "title": "A neural network trained to predict future video frames mimics critical\n  properties of biological neuronal responses and perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks take loose inspiration from neuroscience, it is an\nopen question how seriously to take the analogies between artificial deep\nnetworks and biological neuronal systems. Interestingly, recent work has shown\nthat deep convolutional neural networks (CNNs) trained on large-scale image\nrecognition tasks can serve as strikingly good models for predicting the\nresponses of neurons in visual cortex to visual stimuli, suggesting that\nanalogies between artificial and biological neural networks may be more than\nsuperficial. However, while CNNs capture key properties of the average\nresponses of cortical neurons, they fail to explain other properties of these\nneurons. For one, CNNs typically require large quantities of labeled input data\nfor training. Our own brains, in contrast, rarely have access to this kind of\nsupervision, so to the extent that representations are similar between CNNs and\nbrains, this similarity must arise via different training paths. In addition,\nneurons in visual cortex produce complex time-varying responses even to static\ninputs, and they dynamically tune themselves to temporal regularities in the\nvisual environment. We argue that these differences are clues to fundamental\ndifferences between the computations performed in the brain and in deep\nnetworks. To begin to close the gap, here we study the emergent properties of a\npreviously-described recurrent generative network that is trained to predict\nfuture video frames in a self-supervised manner. Remarkably, the model is able\nto capture a wide variety of seemingly disparate phenomena observed in visual\ncortex, ranging from single unit response dynamics to complex perceptual motion\nillusions. These results suggest potentially deep connections between recurrent\npredictive neural network models and the brain, providing new leads that can\nenrich both fields.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 02:15:09 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 02:47:58 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Lotter", "William", ""], ["Kreiman", "Gabriel", ""], ["Cox", "David", ""]]}, {"id": "1805.10755", "submitter": "Wen Sun", "authors": "Wen Sun, Geoffrey J. Gordon, Byron Boots, J. Andrew Bagnell", "title": "Dual Policy Iteration", "comments": "NeurIPS 2018; Additional related works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel class of Approximate Policy Iteration (API) algorithms have\ndemonstrated impressive practical performance (e.g., ExIt from [2],\nAlphaGo-Zero from [27]). This new family of algorithms maintains, and\nalternately optimizes, two policies: a fast, reactive policy (e.g., a deep\nneural network) deployed at test time, and a slow, non-reactive policy (e.g.,\nTree Search), that can plan multiple steps ahead. The reactive policy is\nupdated under supervision from the non-reactive policy, while the non-reactive\npolicy is improved with guidance from the reactive policy. In this work we\nstudy this Dual Policy Iteration (DPI) strategy in an alternating optimization\nframework and provide a convergence analysis that extends existing API theory.\nWe also develop a special instance of this framework which reduces the update\nof non-reactive policies to model-based optimal control using learned local\nmodels, and provides a theoretically sound way of unifying model-free and\nmodel-based RL approaches with unknown dynamics. We demonstrate the efficacy of\nour approach on various continuous control Markov Decision Processes.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 03:41:56 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 20:34:35 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Sun", "Wen", ""], ["Gordon", "Geoffrey J.", ""], ["Boots", "Byron", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1805.10759", "submitter": "Shohei Hidaka", "authors": "Shohei Hidaka and Neeraj Kashyap", "title": "Clustering by latent dimensions", "comments": "This paper is submitted to NIPS 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new clustering technique, called {\\em dimensional\nclustering}, which clusters each data point by its latent {\\em pointwise\ndimension}, which is a measure of the dimensionality of the data set local to\nthat point. Pointwise dimension is invariant under a broad class of\ntransformations. As a result, dimensional clustering can be usefully applied to\na wide range of datasets. Concretely, we present a statistical model which\nestimates the pointwise dimension of a dataset around the points in that\ndataset using the distance of each point from its $n^{\\text{th}}$ nearest\nneighbor. We demonstrate the applicability of our technique to the analysis of\ndynamical systems, images, and complex human movements.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 04:01:31 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Hidaka", "Shohei", ""], ["Kashyap", "Neeraj", ""]]}, {"id": "1805.10766", "submitter": "Shayan Sadigh", "authors": "Shayan Sadigh, Pradeep Sen", "title": "Improving the Resolution of CNN Feature Maps Efficiently with\n  Multisampling", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new class of subsampling techniques for CNNs, termed\nmultisampling, that significantly increases the amount of information kept by\nfeature maps through subsampling layers. One version of our method, which we\ncall checkered subsampling, significantly improves the accuracy of\nstate-of-the-art architectures such as DenseNet and ResNet without any\nadditional parameters and, remarkably, improves the accuracy of certain\npretrained ImageNet models without any training or fine-tuning. We glean new\ninsight into the nature of data augmentations and demonstrate, for the first\ntime, that coarse feature maps are significantly bottlenecking the performance\nof neural networks in image classification.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 04:29:02 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Sadigh", "Shayan", ""], ["Sen", "Pradeep", ""]]}, {"id": "1805.10767", "submitter": "Pan Zhou", "authors": "Pan Zhou and Jiashi Feng", "title": "Understanding Generalization and Optimization Performance of Deep CNNs", "comments": "This paper was accepted by ICML. It has 38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work aims to provide understandings on the remarkable success of deep\nconvolutional neural networks (CNNs) by theoretically analyzing their\ngeneralization performance and establishing optimization guarantees for\ngradient descent based training algorithms. Specifically, for a CNN model\nconsisting of $l$ convolutional layers and one fully connected layer, we prove\nthat its generalization error is bounded by\n$\\mathcal{O}(\\sqrt{\\dt\\widetilde{\\varrho}/n})$ where $\\theta$ denotes freedom\ndegree of the network parameters and\n$\\widetilde{\\varrho}=\\mathcal{O}(\\log(\\prod_{i=1}^{l}\\rwi{i}\n(\\ki{i}-\\si{i}+1)/p)+\\log(\\rf))$ encapsulates architecture parameters including\nthe kernel size $\\ki{i}$, stride $\\si{i}$, pooling size $p$ and parameter\nmagnitude $\\rwi{i}$. To our best knowledge, this is the first generalization\nbound that only depends on $\\mathcal{O}(\\log(\\prod_{i=1}^{l+1}\\rwi{i}))$,\ntighter than existing ones that all involve an exponential term like\n$\\mathcal{O}(\\prod_{i=1}^{l+1}\\rwi{i})$. Besides, we prove that for an\narbitrary gradient descent algorithm, the computed approximate stationary point\nby minimizing empirical risk is also an approximate stationary point to the\npopulation risk. This well explains why gradient descent training algorithms\nusually perform sufficiently well in practice. Furthermore, we prove the\none-to-one correspondence and convergence guarantees for the non-degenerate\nstationary points between the empirical and population risks. It implies that\nthe computed local minimum for the empirical risk is also close to a local\nminimum for the population risk, thus ensuring the good generalization\nperformance of CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 04:39:24 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhou", "Pan", ""], ["Feng", "Jiashi", ""]]}, {"id": "1805.10769", "submitter": "Ding-Xuan Zhou Professor", "authors": "Ding-Xuan Zhou", "title": "Universality of Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been widely applied and brought breakthroughs in speech\nrecognition, computer vision, and many other domains. The involved deep neural\nnetwork architectures and computational issues have been well studied in\nmachine learning. But there lacks a theoretical foundation for understanding\nthe approximation or generalization ability of deep learning methods generated\nby the network architectures such as deep convolutional neural networks having\nconvolutional structures. Here we show that a deep convolutional neural network\n(CNN) is universal, meaning that it can be used to approximate any continuous\nfunction to an arbitrary accuracy when the depth of the neural network is large\nenough. This answers an open question in learning theory. Our quantitative\nestimate, given tightly in terms of the number of free parameters to be\ncomputed, verifies the efficiency of deep CNNs in dealing with large\ndimensional data. Our study also demonstrates the role of convolutions in deep\nCNNs.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 04:58:26 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 02:10:24 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Zhou", "Ding-Xuan", ""]]}, {"id": "1805.10777", "submitter": "Liangqu Long", "authors": "Liangqu Long, Wei Wang, Jun Wen, Meihui Zhang, Qian Lin, Beng Chin Ooi", "title": "Object-Level Representation Learning for Few-Shot Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning that trains image classifiers over few labeled examples per\ncategory is a challenging task. In this paper, we propose to exploit an\nadditional big dataset with different categories to improve the accuracy of\nfew-shot learning over our target dataset. Our approach is based on the\nobservation that images can be decomposed into objects, which may appear in\nimages from both the additional dataset and our target dataset. We use the\nobject-level relation learned from the additional dataset to infer the\nsimilarity of images in our target dataset with unseen categories. Nearest\nneighbor search is applied to do image classification, which is a\nnon-parametric model and thus does not need fine-tuning. We evaluate our\nalgorithm on two popular datasets, namely Omniglot and MiniImagenet. We obtain\n8.5\\% and 2.7\\% absolute improvements for 5-way 1-shot and 5-way 5-shot\nexperiments on MiniImagenet, respectively. Source code will be published upon\nacceptance.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 05:46:17 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Long", "Liangqu", ""], ["Wang", "Wei", ""], ["Wen", "Jun", ""], ["Zhang", "Meihui", ""], ["Lin", "Qian", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "1805.10795", "submitter": "Elad Tzoreff", "authors": "Elad Tzoreff, Olga Kogan and Yoni Choukroun", "title": "Deep Discriminative Latent Space for Clustering", "comments": "A version of this paper has been submitted to NIPS 2018. The paper\n  contains 9 pages including references, and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most fundamental tasks in data analysis and machine\nlearning. It is central to many data-driven applications that aim to separate\nthe data into groups with similar patterns. Moreover, clustering is a complex\nprocedure that is affected significantly by the choice of the data\nrepresentation method. Recent research has demonstrated encouraging clustering\nresults by learning effectively these representations. In most of these works a\ndeep auto-encoder is initially pre-trained to minimize a reconstruction loss,\nand then jointly optimized with clustering centroids in order to improve the\nclustering objective. Those works focus mainly on the clustering phase of the\nprocedure, while not utilizing the potential benefit out of the initial phase.\nIn this paper we propose to optimize an auto-encoder with respect to a\ndiscriminative pairwise loss function during the auto-encoder pre-training\nphase. We demonstrate the high accuracy obtained by the proposed method as well\nas its rapid convergence (e.g. reaching above 92% accuracy on MNIST during the\npre-training phase, in less than 50 epochs), even with small networks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:34:14 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tzoreff", "Elad", ""], ["Kogan", "Olga", ""], ["Choukroun", "Yoni", ""]]}, {"id": "1805.10796", "submitter": "Micha{\\l} Karwatowski", "authors": "Krzysztof Wr\\'obel, Marcin Pietro\\'n, Maciej Wielgosz, Micha{\\l}\n  Karwatowski and Kazimierz Wiatr", "title": "Convolutional neural network compression for natural language processing", "comments": "7 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are modern models that are very efficient in\nmany classification tasks. They were originally created for image processing\npurposes. Then some trials were performed to use them in different domains like\nnatural language processing. The artificial intelligence systems (like humanoid\nrobots) are very often based on embedded systems with constraints on memory,\npower consumption etc. Therefore convolutional neural network because of its\nmemory capacity should be reduced to be mapped to given hardware. In this\npaper, results are presented of compressing the efficient convolutional neural\nnetworks for sentiment analysis. The main steps are quantization and pruning\nprocesses. The method responsible for mapping compressed network to FPGA and\nresults of this implementation are presented. The described simulations showed\nthat 5-bit width is enough to have no drop in accuracy from floating point\nversion of the network. Additionally, significant memory footprint reduction\nwas achieved (from 85% up to 93%).\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:40:33 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Wr\u00f3bel", "Krzysztof", ""], ["Pietro\u0144", "Marcin", ""], ["Wielgosz", "Maciej", ""], ["Karwatowski", "Micha\u0142", ""], ["Wiatr", "Kazimierz", ""]]}, {"id": "1805.10808", "submitter": "Lonce Wyse", "authors": "Lonce Wyse", "title": "Real-valued parametric conditioning of an RNN for interactive sound\n  synthesis", "comments": "Wyse, Lonce. (2018), Real-valued parametric conditioning of an RNN\n  for real-time interactive sound synthesis. 6th International Workshop on\n  Musical Metacreation, International Conference on Computational Creativity\n  (ICCC) June 25-26, 2018, Salamanca, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A Recurrent Neural Network (RNN) for audio synthesis is trained by augmenting\nthe audio input with information about signal characteristics such as pitch,\namplitude, and instrument. The result after training is an audio synthesizer\nthat is played like a musical instrument with the desired musical\ncharacteristics provided as continuous parametric control. The focus of this\npaper is on conditioning data-driven synthesis models with real-valued\nparameters, and in particular, on the ability of the system a) to generalize\nand b) to be responsive to parameter values and sequences not seen during\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 08:18:51 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 00:06:29 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Wyse", "Lonce", ""]]}, {"id": "1805.10817", "submitter": "Nicola Pezzotti", "authors": "Nicola Pezzotti, Julian Thijssen, Alexander Mordvintsev, Thomas Hollt,\n  Baldur van Lew, Boudewijn P.F. Lelieveldt, Elmar Eisemann and Anna Vilanova", "title": "GPGPU Linear Complexity t-SNE Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The t-distributed Stochastic Neighbor Embedding (tSNE) algorithm has become\nin recent years one of the most used and insightful techniques for the\nexploratory data analysis of high-dimensional data. tSNE reveals clusters of\nhigh-dimensional data points at different scales while it requires only minimal\ntuning of its parameters. Despite these advantages, the computational\ncomplexity of the algorithm limits its application to relatively small\ndatasets. To address this problem, several evolutions of tSNE have been\ndeveloped in recent years, mainly focusing on the scalability of the similarity\ncomputations between data points. However, these contributions are insufficient\nto achieve interactive rates when visualizing the evolution of the tSNE\nembedding for large datasets. In this work, we present a novel approach to the\nminimization of the tSNE objective function that heavily relies on modern\ngraphics hardware and has linear computational complexity. Our technique does\nnot only beat the state of the art, but can even be executed on the client side\nin a browser. We propose to approximate the repulsion forces between data\npoints using adaptive-resolution textures that are drawn at every iteration\nwith WebGL. This approximation allows us to reformulate the tSNE minimization\nproblem as a series of tensor operation that are computed with TensorFlow.js, a\nJavaScript library for scalable tensor computations.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 08:49:46 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 20:45:40 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Pezzotti", "Nicola", ""], ["Thijssen", "Julian", ""], ["Mordvintsev", "Alexander", ""], ["Hollt", "Thomas", ""], ["van Lew", "Baldur", ""], ["Lelieveldt", "Boudewijn P. F.", ""], ["Eisemann", "Elmar", ""], ["Vilanova", "Anna", ""]]}, {"id": "1805.10829", "submitter": "Sekitoshi Kanai", "authors": "Sekitoshi Kanai, Yasuhiro Fujiwara, Yuki Yamanaka, Shuichi Adachi", "title": "Sigsoftmax: Reanalysis of the Softmax Bottleneck", "comments": "15pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softmax is an output activation function for modeling categorical probability\ndistributions in many applications of deep learning. However, a recent study\nrevealed that softmax can be a bottleneck of representational capacity of\nneural networks in language modeling (the softmax bottleneck). In this paper,\nwe propose an output activation function for breaking the softmax bottleneck\nwithout additional parameters. We re-analyze the softmax bottleneck from the\nperspective of the output set of log-softmax and identify the cause of the\nsoftmax bottleneck. On the basis of this analysis, we propose sigsoftmax, which\nis composed of a multiplication of an exponential function and sigmoid\nfunction. Sigsoftmax can break the softmax bottleneck. The experiments on\nlanguage modeling demonstrate that sigsoftmax and mixture of sigsoftmax\noutperform softmax and mixture of softmax, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 09:16:08 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Kanai", "Sekitoshi", ""], ["Fujiwara", "Yasuhiro", ""], ["Yamanaka", "Yuki", ""], ["Adachi", "Shuichi", ""]]}, {"id": "1805.10833", "submitter": "Gonzalo Rios", "authors": "Julio Backhoff-Veraguas, Joaquin Fontbona, Gonzalo Rios, Felipe Tobar", "title": "Bayesian Learning with Wasserstein Barycenters", "comments": "This version is a significant expansion from the previous one. As a\n  new contribution we introduce a numerical method, that corresponds to a\n  stochastic gradient descent algorithm in Wasserstein space. Additionally, we\n  expanded the study about statistical consistency, and included a\n  comprehensive numerical experiment for validation. 32 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel paradigm for Bayesian learning based on optimal\ntransport theory. Namely, we propose to use the Wasserstein barycenter of the\nposterior law on models as a predictive posterior, thus introducing an\nalternative to classical choices like the maximum a posteriori estimator and\nthe Bayesian model average. We exhibit conditions granting the existence and\nstatistical consistency of this estimator, discuss some of its basic and\nspecific properties, and provide insight into its theoretical advantages.\nFinally, we introduce a novel numerical method which is ideally suited for the\ncomputation of our estimator, and we explicitly discuss its implementations for\nspecific families of models. This method can be seen as a stochastic gradient\ndescent algorithm in the Wasserstein space, and is of independent interest and\napplicability for the computation of Wasserstein barycenters. We also provide\nan illustrative numerical example for experimental validation of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 09:21:29 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 17:56:42 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 16:08:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Backhoff-Veraguas", "Julio", ""], ["Fontbona", "Joaquin", ""], ["Rios", "Gonzalo", ""], ["Tobar", "Felipe", ""]]}, {"id": "1805.10842", "submitter": "Asier Mujika", "authors": "Asier Mujika and Florian Meier and Angelika Steger", "title": "Approximating Real-Time Recurrent Learning with Random Kronecker Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite all the impressive advances of recurrent neural networks, sequential\ndata is still in need of better modelling. Truncated backpropagation through\ntime (TBPTT), the learning algorithm most widely used in practice, suffers from\nthe truncation bias, which drastically limits its ability to learn long-term\ndependencies.The Real-Time Recurrent Learning algorithm (RTRL) addresses this\nissue, but its high computational requirements make it infeasible in practice.\nThe Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRL\nwith a smaller runtime and memory cost, but with the disadvantage of obtaining\nnoisy gradients that also limit its practical applicability. In this paper we\npropose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kronecker\nproduct decomposition to approximate the gradients for a large class of RNNs.\nWe show that KF-RTRL is an unbiased and memory efficient online learning\nalgorithm. Our theoretical analysis shows that, under reasonable assumptions,\nthe noise introduced by our algorithm is not only stable over time but also\nasymptotically much smaller than the one of the UORO algorithm. We also confirm\nthese theoretical results experimentally. Further, we show empirically that the\nKF-RTRL algorithm captures long-term dependencies and almost matches the\nperformance of TBPTT on real world tasks by training Recurrent Highway Networks\non a synthetic string memorization task and on the Penn TreeBank task,\nrespectively. These results indicate that RTRL based approaches might be a\npromising future alternative to TBPTT.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 09:40:04 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 20:34:34 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Mujika", "Asier", ""], ["Meier", "Florian", ""], ["Steger", "Angelika", ""]]}, {"id": "1805.10844", "submitter": "Philip Schulz", "authors": "Philip Schulz, Wilker Aziz, Trevor Cohn", "title": "A Stochastic Decoder for Neural Machine Translation", "comments": "Accepted at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of translation is ambiguous, in that there are typically many\nvalid trans- lations for a given sentence. This gives rise to significant\nvariation in parallel cor- pora, however, most current models of machine\ntranslation do not account for this variation, instead treating the prob- lem\nas a deterministic process. To this end, we present a deep generative model of\nmachine translation which incorporates a chain of latent variables, in order to\nac- count for local lexical and syntactic varia- tion in parallel corpora. We\nprovide an in- depth analysis of the pitfalls encountered in variational\ninference for training deep generative models. Experiments on sev- eral\ndifferent language pairs demonstrate that the model consistently improves over\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 09:49:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Schulz", "Philip", ""], ["Aziz", "Wilker", ""], ["Cohn", "Trevor", ""]]}, {"id": "1805.10863", "submitter": "Patrick McClure", "authors": "Patrick McClure, Charles Y. Zheng, Jakub R. Kaczmarzyk, John A. Lee,\n  Satrajit S. Ghosh, Dylan Nielson, Peter Bandettini, and Francisco Pereira", "title": "Distributed Weight Consolidation: A Brain Segmentation Case Study", "comments": "Published in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting the large datasets needed to train deep neural networks can be\nvery difficult, particularly for the many applications for which sharing and\npooling data is complicated by practical, ethical, or legal concerns. However,\nit may be the case that derivative datasets or predictive models developed\nwithin individual sites can be shared and combined with fewer restrictions.\nTraining on distributed data and combining the resulting networks is often\nviewed as continual learning, but these methods require networks to be trained\nsequentially. In this paper, we introduce distributed weight consolidation\n(DWC), a continual learning method to consolidate the weights of separate\nneural networks, each trained on an independent dataset. We evaluated DWC with\na brain segmentation case study, where we consolidated dilated convolutional\nneural networks trained on independent structural magnetic resonance imaging\n(sMRI) datasets from different sites. We found that DWC led to increased\nperformance on test sets from the different sites, while maintaining\ngeneralization performance for a very large and completely independent\nmulti-site dataset, compared to an ensemble baseline.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 10:50:11 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 18:03:02 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 18:19:22 GMT"}, {"version": "v4", "created": "Thu, 15 Nov 2018 19:12:31 GMT"}, {"version": "v5", "created": "Mon, 26 Nov 2018 21:07:14 GMT"}, {"version": "v6", "created": "Fri, 7 Dec 2018 16:11:55 GMT"}, {"version": "v7", "created": "Mon, 17 Dec 2018 03:18:45 GMT"}, {"version": "v8", "created": "Tue, 18 Dec 2018 18:58:45 GMT"}, {"version": "v9", "created": "Wed, 16 Jan 2019 11:37:26 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["McClure", "Patrick", ""], ["Zheng", "Charles Y.", ""], ["Kaczmarzyk", "Jakub R.", ""], ["Lee", "John A.", ""], ["Ghosh", "Satrajit S.", ""], ["Nielson", "Dylan", ""], ["Bandettini", "Peter", ""], ["Pereira", "Francisco", ""]]}, {"id": "1805.10880", "submitter": "Rainer Kelz", "authors": "Rainer Kelz, Gerhard Widmer", "title": "Investigating Label Noise Sensitivity of Convolutional Neural Networks\n  for Fine Grained Audio Signal Labelling", "comments": "accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We measure the effect of small amounts of systematic and random label noise\ncaused by slightly misaligned ground truth labels in a fine grained audio\nsignal labeling task. The task we choose to demonstrate these effects on is\nalso known as framewise polyphonic transcription or note quantized multi-f0\nestimation, and transforms a monaural audio signal into a sequence of note\nindicator labels. It will be shown that even slight misalignments have clearly\napparent effects, demonstrating a great sensitivity of convolutional neural\nnetworks to label noise. The implications are clear: when using convolutional\nneural networks for fine grained audio signal labeling tasks, great care has to\nbe taken to ensure that the annotations have precise timing, and are free from\nsystematic or random error as much as possible - even small misalignments will\nhave a noticeable impact.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 12:02:26 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Kelz", "Rainer", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1805.10886", "submitter": "Andrea Tirinzoni", "authors": "Andrea Tirinzoni, Andrea Sessa, Matteo Pirotta, Marcello Restelli", "title": "Importance Weighted Transfer of Samples in Reinforcement Learning", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the transfer of experience samples (i.e., tuples < s, a, s', r >)\nin reinforcement learning (RL), collected from a set of source tasks to improve\nthe learning process in a given target task. Most of the related approaches\nfocus on selecting the most relevant source samples for solving the target\ntask, but then all the transferred samples are used without considering anymore\nthe discrepancies between the task models. In this paper, we propose a\nmodel-based technique that automatically estimates the relevance (importance\nweight) of each source sample for solving the target task. In the proposed\napproach, all the samples are transferred and used by a batch RL algorithm to\nsolve the target task, but their contribution to the learning process is\nproportional to their importance weight. By extending the results for\nimportance weighting provided in supervised learning literature, we develop a\nfinite-sample analysis of the proposed batch RL algorithm. Furthermore, we\nempirically compare the proposed algorithm to state-of-the-art approaches,\nshowing that it achieves better learning performance and is very robust to\nnegative transfer, even when some source tasks are significantly different from\nthe target task.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 12:12:05 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tirinzoni", "Andrea", ""], ["Sessa", "Andrea", ""], ["Pirotta", "Matteo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1805.10887", "submitter": "\\c{C}a\\u{g}lar Aytekin", "authors": "Caglar Aytekin, Xingyang Ni, Francesco Cricri, Jani Lainema, Emre Aksu\n  and Miska Hannuksela", "title": "Block-optimized Variable Bit Rate Neural Image Compression", "comments": "Accepted, Workshop and Challenge on Learned Image Compression (CLIC),\n  CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an end-to-end block-based auto-encoder system for\nimage compression. We introduce novel contributions to neural-network based\nimage compression, mainly in achieving binarization simulation, variable bit\nrates with multiple networks, entropy-friendly representations, inference-stage\ncode optimization and performance-improving normalization layers in the\nauto-encoder. We evaluate and show the incremental performance increase of each\nof our contributions.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 12:12:19 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aytekin", "Caglar", ""], ["Ni", "Xingyang", ""], ["Cricri", "Francesco", ""], ["Lainema", "Jani", ""], ["Aksu", "Emre", ""], ["Hannuksela", "Miska", ""]]}, {"id": "1805.10896", "submitter": "Juho Lee", "authors": "Juho Lee, Saehoon Kim, Jaehong Yoon, Hae Beom Lee, Eunho Yang, Sung Ju\n  Hwang", "title": "Adaptive Network Sparsification with Dependent Variational\n  Beta-Bernoulli Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While variational dropout approaches have been shown to be effective for\nnetwork sparsification, they are still suboptimal in the sense that they set\nthe dropout rate for each neuron without consideration of the input data. With\nsuch input-independent dropout, each neuron is evolved to be generic across\ninputs, which makes it difficult to sparsify networks without accuracy loss. To\novercome this limitation, we propose adaptive variational dropout whose\nprobabilities are drawn from sparsity-inducing beta Bernoulli prior. It allows\neach neuron to be evolved either to be generic or specific for certain inputs,\nor dropped altogether. Such input-adaptive sparsity-inducing dropout allows the\nresulting network to tolerate larger degree of sparsity without losing its\nexpressive power by removing redundancies among features. We validate our\ndependent variational beta-Bernoulli dropout on multiple public datasets, on\nwhich it obtains significantly more compact networks than baseline methods,\nwith consistent accuracy improvements over the base networks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 12:50:02 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 14:10:40 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 03:27:59 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Lee", "Juho", ""], ["Kim", "Saehoon", ""], ["Yoon", "Jaehong", ""], ["Lee", "Hae Beom", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1805.10915", "submitter": "Dimitrios Milios", "authors": "Dimitrios Milios, Raffaello Camoriano, Pietro Michiardi, Lorenzo\n  Rosasco, Maurizio Filippone", "title": "Dirichlet-based Gaussian Processes for Large-scale Calibrated\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of deriving fast and accurate\nclassification algorithms with uncertainty quantification. Gaussian process\nclassification provides a principled approach, but the corresponding\ncomputational burden is hardly sustainable in large-scale problems and devising\nefficient alternatives is a challenge. In this work, we investigate if and how\nGaussian process regression directly applied to the classification labels can\nbe used to tackle this question. While in this case training time is remarkably\nfaster, predictions need be calibrated for classification and uncertainty\nestimation. To this aim, we propose a novel approach based on interpreting the\nlabels as the output of a Dirichlet distribution. Extensive experimental\nresults show that the proposed approach provides essentially the same accuracy\nand uncertainty quantification of Gaussian process classification while\nrequiring only a fraction of computational resources.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 13:34:58 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Milios", "Dimitrios", ""], ["Camoriano", "Raffaello", ""], ["Michiardi", "Pietro", ""], ["Rosasco", "Lorenzo", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1805.10917", "submitter": "Izhak Golan", "authors": "Izhak Golan, Ran El-Yaniv", "title": "Deep Anomaly Detection Using Geometric Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of anomaly detection in images, and present a new\ndetection technique. Given a sample of images, all known to belong to a\n\"normal\" class (e.g., dogs), we show how to train a deep neural model that can\ndetect out-of-distribution images (i.e., non-dog objects). The main idea behind\nour scheme is to train a multi-class model to discriminate between dozens of\ngeometric transformations applied on all the given images. The auxiliary\nexpertise learned by the model generates feature detectors that effectively\nidentify, at test time, anomalous images based on the softmax activation\nstatistics of the model when applied on transformed images. We present\nextensive experiments using the proposed detector, which indicate that our\nalgorithm improves state-of-the-art methods by a wide margin.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 13:37:39 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 14:11:41 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Golan", "Izhak", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1805.10927", "submitter": "Andre Beckus", "authors": "Mostafa Rahmani, Andre Beckus, Adel Karimian, and George Atia", "title": "Scalable and Robust Community Detection with Randomized Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores and analyzes the unsupervised clustering of large\npartially observed graphs. We propose a scalable and provable randomized\nframework for clustering graphs generated from the stochastic block model. The\nclustering is first applied to a sub-matrix of the graph's adjacency matrix\nassociated with a reduced graph sketch constructed using random sampling. Then,\nthe clusters of the full graph are inferred based on the clusters extracted\nfrom the sketch using a correlation-based retrieval step. Uniform random node\nsampling is shown to improve the computational complexity over clustering of\nthe full graph when the cluster sizes are balanced. A new random degree-based\nnode sampling algorithm is presented which significantly improves upon the\nperformance of the clustering algorithm even when clusters are unbalanced. This\nalgorithm improves the phase transitions for matrix-decomposition-based\nclustering with regard to computational complexity and minimum cluster size,\nwhich are shown to be nearly dimension-free in the low inter-cluster\nconnectivity regime. A third sampling technique is shown to improve balance by\nrandomly sampling nodes based on spatial distribution. We provide analysis and\nnumerical results using a convex clustering algorithm based on matrix\ncompletion.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:19:13 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 04:52:18 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 04:20:01 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Beckus", "Andre", ""], ["Karimian", "Adel", ""], ["Atia", "George", ""]]}, {"id": "1805.10940", "submitter": "Kumarjit Pathak", "authors": "Kumarjit Pathak, Jitin Kapila, Aasheesh Barvey", "title": "Personalized Influence Estimation Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer Satisfaction is the most important factors in the industry\nirrespective of domain. Key Driver Analysis is a common practice in data\nscience to help the business to evaluate the same. Understanding key features,\nwhich influence the outcome or dependent feature, is highly important in\nstatistical model building. This helps to eliminate not so important factors\nfrom the model to minimize noise coming from the features, which does not\ncontribute significantly enough to explain the behavior of the dependent\nfeature, which we want to predict. Personalized Influence Estimation is a\ntechnique introduced in this paper, which can estimate key factor influence for\nindividual observations, which contribute most for each observations behavior\npattern based on the dependent class or estimate. Observations can come from\nmultiple business problem i.e. customers related to satisfaction study,\ncustomer related to Fraud Detection, network devices for Fault detection etc.\nIt is highly important to understand the cause of issue at each observation\nlevel to take appropriate Individualized action at customer level or device\nlevel etc. This technique is based on joint behavior of the feature dimension\nfor the specific observation, and relative importance of the feature to\nestimate impact. The technique mentioned in this paper is aimed to help\norganizations to understand each respondents or observations individual key\ncontributing factor of Influence. Result of the experiment is really\nencouraging and able to justify key reasons for churn for majority of the\nsample appropriately\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:19:51 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Pathak", "Kumarjit", ""], ["Kapila", "Jitin", ""], ["Barvey", "Aasheesh", ""]]}, {"id": "1805.10958", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison, Vincent Adam, Srinivas C. Turaga", "title": "Discrete flow posteriors for variational inference in discrete dynamical\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each training step for a variational autoencoder (VAE) requires us to sample\nfrom the approximate posterior, so we usually choose simple (e.g. factorised)\napproximate posteriors in which sampling is an efficient computation that fully\nexploits GPU parallelism. However, such simple approximate posteriors are often\ninsufficient, as they eliminate statistical dependencies in the posterior.\nWhile it is possible to use normalizing flow approximate posteriors for\ncontinuous latents, some problems have discrete latents and strong statistical\ndependencies. The most natural approach to model these dependencies is an\nautoregressive distribution, but sampling from such distributions is inherently\nsequential and thus slow. We develop a fast, parallel sampling procedure for\nautoregressive distributions based on fixed-point iterations which enables\nefficient and accurate variational inference in discrete state-space latent\nvariable dynamical systems. To optimize the variational bound, we considered\ntwo ways to evaluate probabilities: inserting the relaxed samples directly into\nthe pmf for the discrete distribution, or converting to continuous logistic\nlatent variables and interpreting the K-step fixed-point iterations as a\nnormalizing flow. We found that converting to continuous latent variables gave\nconsiderable additional scope for mismatch between the true and approximate\nposteriors, which resulted in biased inferences, we thus used the former\napproach. Using our fast sampling procedure, we were able to realize the\nbenefits of correlated posteriors, including accurate uncertainty estimates for\none cell, and accurate connectivity estimates for multiple cells, in an order\nof magnitude less time.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 14:56:26 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aitchison", "Laurence", ""], ["Adam", "Vincent", ""], ["Turaga", "Srinivas C.", ""]]}, {"id": "1805.10965", "submitter": "Kevin Scaman", "authors": "Kevin Scaman and Aladin Virmaux", "title": "Lipschitz regularity of deep neural networks: analysis and efficient\n  estimation", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are notorious for being sensitive to small well-chosen\nperturbations, and estimating the regularity of such architectures is of utmost\nimportance for safe and robust practical applications. In this paper, we\ninvestigate one of the key characteristics to assess the regularity of such\nmethods: the Lipschitz constant of deep learning architectures. First, we show\nthat, even for two layer neural networks, the exact computation of this\nquantity is NP-hard and state-of-art methods may significantly overestimate it.\nThen, we both extend and improve previous estimation methods by providing\nAutoLip, the first generic algorithm for upper bounding the Lipschitz constant\nof any automatically differentiable function. We provide a power method\nalgorithm working with automatic differentiation, allowing efficient\ncomputations even on large convolutions. Second, for sequential neural\nnetworks, we propose an improved algorithm named SeqLip that takes advantage of\nthe linear computation graph to split the computation per pair of consecutive\nlayers. Third we propose heuristics on SeqLip in order to tackle very large\nnetworks. Our experiments show that SeqLip can significantly improve on the\nexisting upper bounds. Finally, we provide an implementation of AutoLip in the\nPyTorch environment that may be used to better estimate the robustness of a\ngiven neural network to small perturbations or regularize it using more precise\nLipschitz estimations.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:08:15 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 09:36:34 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Scaman", "Kevin", ""], ["Virmaux", "Aladin", ""]]}, {"id": "1805.10970", "submitter": "Matthew Kusner", "authors": "John Bradshaw, Matt J. Kusner, Brooks Paige, Marwin H. S. Segler,\n  Jos\\'e Miguel Hern\\'andez-Lobato", "title": "A Generative Model For Electron Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical reactions can be described as the stepwise redistribution of\nelectrons in molecules. As such, reactions are often depicted using\n`arrow-pushing' diagrams which show this movement as a sequence of arrows. We\npropose an electron path prediction model (ELECTRO) to learn these sequences\ndirectly from raw reaction data. Instead of predicting product molecules\ndirectly from reactant molecules in one shot, learning a model of electron\nmovement has the benefits of (a) being easy for chemists to interpret, (b)\nincorporating constraints of chemistry, such as balanced atom counts before and\nafter the reaction, and (c) naturally encoding the sparsity of chemical\nreactions, which usually involve changes in only a small number of atoms in the\nreactants.We design a method to extract approximate reaction paths from any\ndataset of atom-mapped reaction SMILES strings. Our model achieves excellent\nperformance on an important subset of the USPTO reaction dataset, comparing\nfavorably to the strongest baselines. Furthermore, we show that our model\nrecovers a basic knowledge of chemistry without being explicitly trained to do\nso.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 19:31:35 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 12:15:41 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Bradshaw", "John", ""], ["Kusner", "Matt J.", ""], ["Paige", "Brooks", ""], ["Segler", "Marwin H. S.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1805.10981", "submitter": "Ivan Zubarev", "authors": "Ivan Zubarev, Rasmus Zetter, Hanna-Leena Halme and Lauri Parkkonen", "title": "Adaptive neural network classifier for decoding MEG signals", "comments": "12 pages, 4 figures, 4 tables. keywords: MEG, BCI, real-time,\n  convolutional neural networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) outperform traditional classification\nmethods in many domains. Recently these methods have gained attention in\nneuroscience and particularly in brain-computer interface (BCI) community.\nHere, we introduce a CNN optimized for classification of brain states from\nmagnetoencephalographic (MEG) measurements. Our CNN design is based on a\ngenerative model of the electromagnetic (EEG and MEG) brain signals and is\nreadily interpretable in neurophysiological terms. We show here that the\nproposed network is able to decode event-related responses as well as\nmodulations of oscillatory brain activity and that it outperforms more complex\nneural networks and traditional classifiers used in the field. Importantly, the\nmodel is robust to inter-individual differences and can successfully generalize\nto new subjects in offline and online classification.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:40:44 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 17:47:02 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zubarev", "Ivan", ""], ["Zetter", "Rasmus", ""], ["Halme", "Hanna-Leena", ""], ["Parkkonen", "Lauri", ""]]}, {"id": "1805.10982", "submitter": "Konstantin Berestizshevsky", "authors": "Konstantin Berestizshevsky and Guy Even", "title": "Dynamically Sacrificing Accuracy for Reduced Computation: Cascaded\n  Inference Based on Softmax Confidence", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30484-3_26", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the tradeoff between computational effort and classification\naccuracy in a cascade of deep neural networks. During inference, the user sets\nthe acceptable accuracy degradation which then automatically determines\nconfidence thresholds for the intermediate classifiers. As soon as the\nconfidence threshold is met, inference terminates immediately without having to\ncompute the output of the complete network. Confidence levels are derived\ndirectly from the softmax outputs of intermediate classifiers, as we do not\ntrain special decision functions. We show that using a softmax output as a\nconfidence measure in a cascade of deep neural networks leads to a reduction of\n15%-50% in the number of MAC operations while degrading the classification\naccuracy by roughly 1%. Our method can be easily incorporated into pre-trained\nnon-cascaded architectures, as we exemplify on ResNet. Our main contribution is\na method that dynamically adjusts the tradeoff between accuracy and computation\nwithout retraining the model.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:44:13 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 13:04:31 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Berestizshevsky", "Konstantin", ""], ["Even", "Guy", ""]]}, {"id": "1805.10988", "submitter": "Seongok Ryu", "authors": "Seongok Ryu, Jaechang Lim, Seung Hwan Hong and Woo Youn Kim", "title": "Deeply learning molecular structure-property relationships using\n  attention- and gate-augmented graph convolutional network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular structure-property relationships are key to molecular engineering\nfor materials and drug discovery. The rise of deep learning offers a new viable\nsolution to elucidate the structure-property relationships directly from\nchemical data. Here we show that the performance of graph convolutional\nnetworks (GCNs) for the prediction of molecular properties can be improved by\nincorporating attention and gate mechanisms. The attention mechanism enables a\nGCN to identify atoms in different environments. The gated skip-connection\nfurther improves the GCN by updating feature maps at an appropriate rate. We\ndemonstrate that the resulting attention- and gate-augmented GCN could extract\nbetter structural features related to a target molecular property such as\nsolubility, polarity, synthetic accessibility and photovoltaic efficiency\ncompared to the vanilla GCN. More interestingly, it identified two distinct\nparts of molecules as essential structural features for high photovoltaic\nefficiency, and each of them coincided with the areas of donor and acceptor\norbitals for charge-transfer excitations, respectively. As a result, the new\nmodel could accurately predict molecular properties and place molecules with\nsimilar properties close to each other in a well-trained latent space, which is\ncritical for successful molecular engineering.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:49:28 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 05:49:58 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 08:44:36 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ryu", "Seongok", ""], ["Lim", "Jaechang", ""], ["Hong", "Seung Hwan", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1805.11004", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Soft Layer-Specific Multi-Task Summarization with Entailment and\n  Question Generation", "comments": "ACL 2018 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate abstractive summary of a document should contain all its salient\ninformation and should be logically entailed by the input document. We improve\nthese important aspects of abstractive summarization via multi-task learning\nwith the auxiliary tasks of question generation and entailment generation,\nwhere the former teaches the summarization model how to look for salient\nquestioning-worthy details, and the latter teaches the model how to rewrite a\nsummary which is a directed-logical subset of the input document. We also\npropose novel multi-task architectures with high-level (semantic)\nlayer-specific sharing across multiple encoder and decoder layers of the three\ntasks, as well as soft-sharing mechanisms (and show performance ablations and\nanalysis examples of each contribution). Overall, we achieve statistically\nsignificant improvements over the state-of-the-art on both the CNN/DailyMail\nand Gigaword datasets, as well as on the DUC-2002 transfer setup. We also\npresent several quantitative and qualitative analysis studies of our model's\nlearned saliency and entailment skills.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:05:39 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.11016", "submitter": "Vardaan Pahuja", "authors": "Shagun Sodhani, Vardaan Pahuja", "title": "Memory Augmented Self-Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-play is an unsupervised training procedure which enables the\nreinforcement learning agents to explore the environment without requiring any\nexternal rewards. We augment the self-play setting by providing an external\nmemory where the agent can store experience from the previous tasks. This\nenables the agent to come up with more diverse self-play tasks resulting in\nfaster exploration of the environment. The agent pretrained in the memory\naugmented self-play setting easily outperforms the agent pretrained in\nno-memory self-play setting.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:22:02 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 02:16:46 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Sodhani", "Shagun", ""], ["Pahuja", "Vardaan", ""]]}, {"id": "1805.11022", "submitter": "Julia Olkhovskaya", "authors": "Julia Olkhovskaya, Gergely Neu, G\\'abor Lugosi", "title": "Online Influence Maximization with Local Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online influence maximization problem in which a decision\nmaker selects a node among a large number of possibilities and places a piece\nof information at the node. The node transmits the information to some others\nthat are in the same connected component in a random graph. The goal of the\ndecision maker is to reach as many nodes as possible, with the added\ncomplication that feedback is only available about the degree of the selected\nnode. Our main result shows that such local observations can be sufficient for\nmaximizing global influence in two broadly studied families of random graph\nmodels: stochastic block models and Chung--Lu models. With this insight, we\npropose a bandit algorithm that aims at maximizing local (and thus global)\ninfluence, and provide its theoretical analysis in both the subcritical and\nsupercritical regimes of both considered models. Notably, our performance\nguarantees show no explicit dependence on the total number of nodes in the\nnetwork, making our approach well-suited for large-scale applications.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:32:58 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Olkhovskaya", "Julia", ""], ["Neu", "Gergely", ""], ["Lugosi", "G\u00e1bor", ""]]}, {"id": "1805.11028", "submitter": "Pierre Laforgue", "authors": "Pierre Laforgue, Stephan Cl\\'emen\\c{c}on, Florence d'Alch\\'e-Buc", "title": "Autoencoding any Data through Kernel Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a novel algorithmic approach to data representation\nbased on kernel methods. Assuming that the observations lie in a Hilbert space\nX, the introduced Kernel Autoencoder (KAE) is the composition of mappings from\nvector-valued Reproducing Kernel Hilbert Spaces (vv-RKHSs) that minimizes the\nexpected reconstruction error. Beyond a first extension of the autoencoding\nscheme to possibly infinite dimensional Hilbert spaces, KAE further allows to\nautoencode any kind of data by choosing X to be itself a RKHS. A theoretical\nanalysis of the model is carried out, providing a generalization bound, and\nshedding light on its connection with Kernel Principal Component Analysis. The\nproposed algorithms are then detailed at length: they crucially rely on the\nform taken by the minimizers, revealed by a dedicated Representer Theorem.\nFinally, numerical experiments on both simulated data and real labeled graphs\n(molecules) provide empirical evidence of the KAE performances.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:36:22 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 12:15:55 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 16:26:13 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Laforgue", "Pierre", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""], ["d'Alch\u00e9-Buc", "Florence", ""]]}, {"id": "1805.11046", "submitter": "Ron Banner", "authors": "Ron Banner, Itay Hubara, Elad Hoffer and Daniel Soudry", "title": "Scalable Methods for 8-bit Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantized Neural Networks (QNNs) are often used to improve network efficiency\nduring the inference phase, i.e. after the network has been trained. Extensive\nresearch in the field suggests many different quantization schemes. Still, the\nnumber of bits required, as well as the best quantization scheme, are yet\nunknown. Our theoretical analysis suggests that most of the training process is\nrobust to substantial precision reduction, and points to only a few specific\noperations that require higher precision. Armed with this knowledge, we\nquantize the model parameters, activations and layer gradients to 8-bit,\nleaving at a higher precision only the final step in the computation of the\nweight gradients. Additionally, as QNNs require batch-normalization to be\ntrained at high precision, we introduce Range Batch-Normalization (BN) which\nhas significantly higher tolerance to quantization noise and improved\ncomputational complexity. Our simulations show that Range BN is equivalent to\nthe traditional batch norm if a precise scale adjustment, which can be\napproximated analytically, is applied. To the best of the authors' knowledge,\nthis work is the first to quantize the weights, activations, as well as a\nsubstantial volume of the gradients stream, in all layers (including batch\nnormalization) to 8-bit while showing state-of-the-art results over the\nImageNet-1K dataset.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:20:37 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 19:44:45 GMT"}, {"version": "v3", "created": "Sun, 17 Jun 2018 18:37:14 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Banner", "Ron", ""], ["Hubara", "Itay", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "1805.11048", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Pin-Yu Chen, Ian En-Hsu Yen, Fangli Xu, Yinglong Xia and\n  Charu Aggarwal", "title": "Scalable Spectral Clustering Using Random Binning Features", "comments": "KDD'18, Oral Paper, Data and Code link available in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most effective clustering approaches that\ncapture hidden cluster structures in the data. However, it does not scale well\nto large-scale problems due to its quadratic complexity in constructing\nsimilarity graphs and computing subsequent eigendecomposition. Although a\nnumber of methods have been proposed to accelerate spectral clustering, most of\nthem compromise considerable information loss in the original data for reducing\ncomputational bottlenecks. In this paper, we present a novel scalable spectral\nclustering method using Random Binning features (RB) to simultaneously\naccelerate both similarity graph construction and the eigendecomposition.\nSpecifically, we implicitly approximate the graph similarity (kernel) matrix by\nthe inner product of a large sparse feature matrix generated by RB. Then we\nintroduce a state-of-the-art SVD solver to effectively compute eigenvectors of\nthis large matrix for spectral clustering. Using these two building blocks, we\nreduce the computational cost from quadratic to linear in the number of data\npoints while achieving similar accuracy. Our theoretical analysis shows that\nspectral clustering via RB converges faster to the exact spectral clustering\nthan the standard Random Feature approximation. Extensive experiments on 8\nbenchmarks show that the proposed method either outperforms or matches the\nstate-of-the-art methods in both accuracy and runtime. Moreover, our method\nexhibits linear scalability in both the number of data samples and the number\nof RB features.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 04:46:48 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 17:26:17 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 18:47:44 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wu", "Lingfei", ""], ["Chen", "Pin-Yu", ""], ["Yen", "Ian En-Hsu", ""], ["Xu", "Fangli", ""], ["Xia", "Yinglong", ""], ["Aggarwal", "Charu", ""]]}, {"id": "1805.11051", "submitter": "Eszter V\\'ertes", "authors": "Eszter Vertes, Maneesh Sahani", "title": "Flexible and accurate inference and learning for deep generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to learning in hierarchical latent-variable\ngenerative models called the \"distributed distributional code Helmholtz\nmachine\", which emphasises flexibility and accuracy in the inferential process.\nIn common with the original Helmholtz machine and later variational autoencoder\nalgorithms (but unlike adverserial methods) our approach learns an explicit\ninference or \"recognition\" model to approximate the posterior distribution over\nthe latent variables. Unlike in these earlier methods, the posterior\nrepresentation is not limited to a narrow tractable parameterised form (nor is\nit represented by samples). To train the generative and recognition models we\ndevelop an extended wake-sleep algorithm inspired by the original Helmholtz\nMachine. This makes it possible to learn hierarchical latent models with both\ndiscrete and continuous variables, where an accurate posterior representation\nis essential. We demonstrate that the new algorithm outperforms current\nstate-of-the-art methods on synthetic, natural image patch and the MNIST data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:01:37 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Vertes", "Eszter", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1805.11057", "submitter": "Michael Tschannen", "authors": "Michael Tschannen, Eirikur Agustsson, Mario Lucic", "title": "Deep Generative Models for Distribution-Preserving Lossy Compression", "comments": "NIPS 2018. Code: https://github.com/mitscha/dplc . Changes w.r.t. v1:\n  Some clarifications in the text and additional numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study the problem of distribution-preserving lossy\ncompression. Motivated by recent advances in extreme image compression which\nallow to maintain artifact-free reconstructions even at very low bitrates, we\npropose to optimize the rate-distortion tradeoff under the constraint that the\nreconstructed samples follow the distribution of the training data. The\nresulting compression system recovers both ends of the spectrum: On one hand,\nat zero bitrate it learns a generative model of the data, and at high enough\nbitrates it achieves perfect reconstruction. Furthermore, for intermediate\nbitrates it smoothly interpolates between learning a generative model of the\ntraining data and perfectly reconstructing the training samples. We study\nseveral methods to approximately solve the proposed optimization problem,\nincluding a novel combination of Wasserstein GAN and Wasserstein Autoencoder,\nand present an extensive theoretical and empirical characterization of the\nproposed compression systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:07:01 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 11:05:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tschannen", "Michael", ""], ["Agustsson", "Eirikur", ""], ["Lucic", "Mario", ""]]}, {"id": "1805.11063", "submitter": "Aurko Roy", "authors": "Aurko Roy, Ashish Vaswani, Arvind Neelakantan, Niki Parmar", "title": "Theory and Experiments on Vector Quantized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with discrete latent variables offer the promise of\nbetter symbolic reasoning, and learning abstractions that are more useful to\nnew tasks. There has been a surge in interest in discrete latent variable\nmodels, however, despite several recent improvements, the training of discrete\nlatent variable models has remained challenging and their performance has\nmostly failed to match their continuous counterparts. Recent work on vector\nquantized autoencoders (VQ-VAE) has made substantial progress in this\ndirection, with its perplexity almost matching that of a VAE on datasets such\nas CIFAR-10. In this work, we investigate an alternate training technique for\nVQ-VAE, inspired by its connection to the Expectation Maximization (EM)\nalgorithm. Training the discrete bottleneck with EM helps us achieve better\nimage generation results on CIFAR-10, and together with knowledge distillation,\nallows us to develop a non-autoregressive machine translation model whose\naccuracy almost matches a strong greedy autoregressive baseline Transformer,\nwhile being 3.3 times faster at inference.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:16:20 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 06:55:09 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Roy", "Aurko", ""], ["Vaswani", "Ashish", ""], ["Neelakantan", "Arvind", ""], ["Parmar", "Niki", ""]]}, {"id": "1805.11074", "submitter": "Chen Tessler", "authors": "Chen Tessler, Daniel J. Mankowitz, Shie Mannor", "title": "Reward Constrained Policy Optimization", "comments": "Accepted as a poster to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving tasks in Reinforcement Learning is no easy feat. As the goal of the\nagent is to maximize the accumulated reward, it often learns to exploit\nloopholes and misspecifications in the reward signal resulting in unwanted\nbehavior. While constraints may solve this issue, there is no closed form\nsolution for general constraints. In this work we present a novel\nmulti-timescale approach for constrained policy optimization, called `Reward\nConstrained Policy Optimization' (RCPO), which uses an alternative penalty\nsignal to guide the policy towards a constraint satisfying one. We prove the\nconvergence of our approach and provide empirical evidence of its ability to\ntrain constraint satisfying policies.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:31:11 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 09:31:44 GMT"}, {"version": "v3", "created": "Wed, 26 Dec 2018 11:09:40 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Tessler", "Chen", ""], ["Mankowitz", "Daniel J.", ""], ["Mannor", "Shie", ""]]}, {"id": "1805.11080", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Mohit Bansal", "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence\n  Rewriting", "comments": "ACL 2018 (17 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by how humans summarize long documents, we propose an accurate and\nfast summarization model that first selects salient sentences and then rewrites\nthem abstractively (i.e., compresses and paraphrases) to generate a concise\noverall summary. We use a novel sentence-level policy gradient method to bridge\nthe non-differentiable computation between these two neural networks in a\nhierarchical way, while maintaining language fluency. Empirically, we achieve\nthe new state-of-the-art on all metrics (including human evaluation) on the\nCNN/Daily Mail dataset, as well as significantly higher abstractiveness scores.\nMoreover, by first operating at the sentence-level and then the word-level, we\nenable parallel decoding of our neural generative model that results in\nsubstantially faster (10-20x) inference speed as well as 4x faster training\nconvergence than previous long-paragraph encoder-decoder models. We also\ndemonstrate the generalization of our model on the test-only DUC-2002 dataset,\nwhere we achieve higher scores than a state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:49:10 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.11085", "submitter": "Roberto Calandra", "authors": "Roberto Calandra and Andrew Owens and Dinesh Jayaraman and Justin Lin\n  and Wenzhen Yuan and Jitendra Malik and Edward H. Adelson and Sergey Levine", "title": "More Than a Feeling: Learning to Grasp and Regrasp using Vision and\n  Touch", "comments": "8 pages. Published on IEEE Robotics and Automation Letters (RAL).\n  Website: https://sites.google.com/view/more-than-a-feeling", "journal-ref": null, "doi": "10.1109/LRA.2018.2852779", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For humans, the process of grasping an object relies heavily on rich tactile\nfeedback. Most recent robotic grasping work, however, has been based only on\nvisual input, and thus cannot easily benefit from feedback after initiating\ncontact. In this paper, we investigate how a robot can learn to use tactile\ninformation to iteratively and efficiently adjust its grasp. To this end, we\npropose an end-to-end action-conditional model that learns regrasping policies\nfrom raw visuo-tactile data. This model -- a deep, multimodal convolutional\nnetwork -- predicts the outcome of a candidate grasp adjustment, and then\nexecutes a grasp by iteratively selecting the most promising actions. Our\napproach requires neither calibration of the tactile sensors, nor any\nanalytical modeling of contact forces, thus reducing the engineering effort\nrequired to obtain efficient grasping policies. We train our model with data\nfrom about 6,450 grasping trials on a two-finger gripper equipped with GelSight\nhigh-resolution tactile sensors on each finger. Across extensive experiments,\nour approach outperforms a variety of baselines at (i) estimating grasp\nadjustment outcomes, (ii) selecting efficient grasp adjustments for quick\ngrasping, and (iii) reducing the amount of force applied at the fingers, while\nmaintaining competitive performance. Finally, we study the choices made by our\nmodel and show that it has successfully acquired useful and interpretable\ngrasping behaviors.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:54:31 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 23:04:28 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Calandra", "Roberto", ""], ["Owens", "Andrew", ""], ["Jayaraman", "Dinesh", ""], ["Lin", "Justin", ""], ["Yuan", "Wenzhen", ""], ["Malik", "Jitendra", ""], ["Adelson", "Edward H.", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.11088", "submitter": "Guiliang Liu", "authors": "Guiliang Liu and Oliver Schulte", "title": "Deep Reinforcement Learning in Ice Hockey for Context-Aware Player\n  Evaluation", "comments": "This paper has been accepted by IJCAI 2018", "journal-ref": null, "doi": "10.24963/ijcai.2018/478", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of machine learning models have been proposed to assess the\nperformance of players in professional sports. However, they have only a\nlimited ability to model how player performance depends on the game context.\nThis paper proposes a new approach to capturing game context: we apply Deep\nReinforcement Learning (DRL) to learn an action-value Q function from 3M\nplay-by-play events in the National Hockey League (NHL). The neural network\nrepresentation integrates both continuous context signals and game history,\nusing a possession-based LSTM. The learned Q-function is used to value players'\nactions under different game contexts. To assess a player's overall\nperformance, we introduce a novel Game Impact Metric (GIM) that aggregates the\nvalues of the player's actions. Empirical Evaluation shows GIM is consistent\nthroughout a play season, and correlates highly with standard success measures\nand future salary.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 19:23:51 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 16:55:07 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 14:08:47 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Liu", "Guiliang", ""], ["Schulte", "Oliver", ""]]}, {"id": "1805.11090", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty, Huan Zhang,\n  Cho-Jui Hsieh, Mani Srivastava", "title": "GenAttack: Practical Black-box Attacks with Gradient-Free Optimization", "comments": "Accepted in The Genetic and Evolutionary Computation Conference\n  (GECCO) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, even in the\nblack-box setting, where the attacker is restricted solely to query access.\nExisting black-box approaches to generating adversarial examples typically\nrequire a significant number of queries, either for training a substitute\nnetwork or performing gradient estimation. We introduce GenAttack, a\ngradient-free optimization technique that uses genetic algorithms for\nsynthesizing adversarial examples in the black-box setting. Our experiments on\ndifferent datasets (MNIST, CIFAR-10, and ImageNet) show that GenAttack can\nsuccessfully generate visually imperceptible adversarial examples against\nstate-of-the-art image recognition models with orders of magnitude fewer\nqueries than previous approaches. Against MNIST and CIFAR-10 models, GenAttack\nrequired roughly 2,126 and 2,568 times fewer queries respectively, than ZOO,\nthe prior state-of-the-art black-box attack. In order to scale up the attack to\nlarge-scale high-dimensional ImageNet models, we perform a series of\noptimizations that further improve the query efficiency of our attack leading\nto 237 times fewer queries against the Inception-v3 model than ZOO.\nFurthermore, we show that GenAttack can successfully attack some\nstate-of-the-art ImageNet defenses, including ensemble adversarial training and\nnon-differentiable or randomized input transformations. Our results suggest\nthat evolutionary algorithms open up a promising area of research into\neffective black-box attacks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 06:40:55 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 08:08:31 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 00:32:03 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Sharma", "Yash", ""], ["Chakraborty", "Supriyo", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""], ["Srivastava", "Mani", ""]]}, {"id": "1805.11122", "submitter": "Rico Jonschkowski", "authors": "Rico Jonschkowski, Divyam Rastogi, Oliver Brock", "title": "Differentiable Particle Filters: End-to-End Learning with Algorithmic\n  Priors", "comments": "Accepted at Robotics: Science and Systems 2018\n  (http://www.roboticsconference.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present differentiable particle filters (DPFs): a differentiable\nimplementation of the particle filter algorithm with learnable motion and\nmeasurement models. Since DPFs are end-to-end differentiable, we can\nefficiently train their models by optimizing end-to-end state estimation\nperformance, rather than proxy objectives such as model accuracy. DPFs encode\nthe structure of recursive state estimation with prediction and measurement\nupdate that operate on a probability distribution over states. This structure\nrepresents an algorithmic prior that improves learning performance in state\nestimation problems while enabling explainability of the learned model. Our\nexperiments on simulated and real data show substantial benefits from end-to-\nend learning with algorithmic priors, e.g. reducing error rates by ~80%. Our\nexperiments also show that, unlike long short-term memory networks, DPFs learn\nlocalization in a policy-agnostic way and thus greatly improve generalization.\nSource code is available at\nhttps://github.com/tu-rbo/differentiable-particle-filters .\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 18:30:56 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 02:56:52 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Jonschkowski", "Rico", ""], ["Rastogi", "Divyam", ""], ["Brock", "Oliver", ""]]}, {"id": "1805.11155", "submitter": "Daan Wynen", "authors": "Daan Wynen, Cordelia Schmid, Julien Mairal", "title": "Unsupervised Learning of Artistic Styles with Archetypal Style Analysis", "comments": "Accepted at NIPS 2018, Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an unsupervised learning approach to\nautomatically discover, summarize, and manipulate artistic styles from large\ncollections of paintings. Our method is based on archetypal analysis, which is\nan unsupervised learning technique akin to sparse coding with a geometric\ninterpretation. When applied to deep image representations from a collection of\nartworks, it learns a dictionary of archetypal styles, which can be easily\nvisualized. After training the model, the style of a new image, which is\ncharacterized by local statistics of deep visual features, is approximated by a\nsparse convex combination of archetypes. This enables us to interpret which\narchetypal styles are present in the input image, and in which proportion.\nFinally, our approach allows us to manipulate the coefficients of the latent\narchetypal decomposition, and achieve various special effects such as style\nenhancement, transfer, and interpolation between multiple archetypes.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 19:58:01 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 15:59:02 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wynen", "Daan", ""], ["Schmid", "Cordelia", ""], ["Mairal", "Julien", ""]]}, {"id": "1805.11182", "submitter": "Shupeng Gui", "authors": "Shupeng Gui (1), Xiangliang Zhang (2), Shuang Qiu (3), Mingrui Wu (4),\n  Jieping Ye (3), Ji Liu (1) ((1) University of Rochester, (2) KAUST, Saudi\n  Arabia, (3) University of Michigan, (4) Alibaba Group)", "title": "GESF: A Universal Discriminative Mapping Mechanism for Graph\n  Representation Learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is a central problem in social network analysis and many\nother applications, aiming to learn the vector representation for each node.\nWhile most existing approaches need to specify the neighborhood and the\ndependence form to the neighborhood, which may significantly degrades the\nflexibility of representation, we propose a novel graph node embedding method\n(namely GESF) via the set function technique. Our method can 1) learn an\narbitrary form of representation function from neighborhood, 2) automatically\ndecide the significance of neighbors at different distances, and 3) be applied\nto heterogeneous graph embedding, which may contain multiple types of nodes.\nTheoretical guarantee for the representation capability of our method has been\nproved for general homogeneous and heterogeneous graphs and evaluation results\non benchmark data sets show that the proposed GESF outperforms the\nstate-of-the-art approaches on producing node vectors for classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 21:49:54 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 04:16:16 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 04:19:56 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Gui", "Shupeng", ""], ["Zhang", "Xiangliang", ""], ["Qiu", "Shuang", ""], ["Wu", "Mingrui", ""], ["Ye", "Jieping", ""], ["Liu", "Ji", ""]]}, {"id": "1805.11183", "submitter": "Mingyuan Zhou", "authors": "Mingzhang Yin and Mingyuan Zhou", "title": "Semi-Implicit Variational Inference", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-implicit variational inference (SIVI) is introduced to expand the\ncommonly used analytic variational distribution family, by mixing the\nvariational parameter with a flexible distribution. This mixing distribution\ncan assume any density function, explicit or not, as long as independent random\nsamples can be generated via reparameterization. Not only does SIVI expand the\nvariational family to incorporate highly flexible variational distributions,\nincluding implicit ones that have no analytic density functions, but also\nsandwiches the evidence lower bound (ELBO) between a lower bound and an upper\nbound, and further derives an asymptotically exact surrogate ELBO that is\namenable to optimization via stochastic gradient ascent. With a substantially\nexpanded variational family and a novel optimization algorithm, SIVI is shown\nto closely match the accuracy of MCMC in inferring the posterior in a variety\nof Bayesian inference tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 21:55:02 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1805.11191", "submitter": "Anurag Sahoo", "authors": "Vishal Kaushal, Anurag Sahoo, Khoshrav Doctor, Narasimha Raju, Suyash\n  Shetty, Pankaj Singh, Rishabh Iyer, Ganesh Ramakrishnan", "title": "Learning From Less Data: Diversified Subset Selection and Active\n  Learning in Image Classification Tasks", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning based state-of-the-art computer vision techniques\nare in general data hungry and pose the challenges of not having adequate\ncomputing resources and of high costs involved in human labeling efforts.\nTraining data subset selection and active learning techniques have been\nproposed as possible solutions to these challenges respectively. A special\nclass of subset selection functions naturally model notions of diversity,\ncoverage and representation and they can be used to eliminate redundancy and\nthus lend themselves well for training data subset selection. They can also\nhelp improve the efficiency of active learning in further reducing human\nlabeling efforts by selecting a subset of the examples obtained using the\nconventional uncertainty sampling based techniques. In this work we empirically\ndemonstrate the effectiveness of two diversity models, namely the\nFacility-Location and Disparity-Min models for training-data subset selection\nand reducing labeling effort. We do this for a variety of computer vision tasks\nincluding Gender Recognition, Scene Recognition and Object Recognition. Our\nresults show that subset selection done in the right way can add 2-3% in\naccuracy on existing baselines, particularly in the case of less training data.\nThis allows the training of complex machine learning models (like Convolutional\nNeural Networks) with much less training data while incurring minimal\nperformance loss.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 22:27:29 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Kaushal", "Vishal", ""], ["Sahoo", "Anurag", ""], ["Doctor", "Khoshrav", ""], ["Raju", "Narasimha", ""], ["Shetty", "Suyash", ""], ["Singh", "Pankaj", ""], ["Iyer", "Rishabh", ""], ["Ramakrishnan", "Ganesh", ""]]}, {"id": "1805.11195", "submitter": "Rinat Mukhometzianov", "authors": "Rinat Mukhometzianov, Juan Carrillo", "title": "CapsNet comparative performance evaluation for image classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has become one of the main tasks in the field of\ncomputer vision technologies. In this context, a recent algorithm called\nCapsNet that implements an approach based on activity vectors and dynamic\nrouting between capsules may overcome some of the limitations of the current\nstate of the art artificial neural networks (ANN) classifiers, such as\nconvolutional neural networks (CNN). In this paper, we evaluated the\nperformance of the CapsNet algorithm in comparison with three well-known\nclassifiers (Fisher-faces, LeNet, and ResNet). We tested the classification\naccuracy on four datasets with a different number of instances and classes,\nincluding images of faces, traffic signs, and everyday objects. The evaluation\nresults show that even for simple architectures, training the CapsNet algorithm\nrequires significant computational resources and its classification performance\nfalls below the average accuracy values of the other three classifiers.\nHowever, we argue that CapsNet seems to be a promising new technique for image\nclassification, and further experiments using more robust computation resources\nand re-fined CapsNet architectures may produce better outcomes.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 22:54:17 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mukhometzianov", "Rinat", ""], ["Carrillo", "Juan", ""]]}, {"id": "1805.11199", "submitter": "Nantas Nardelli", "authors": "Nantas Nardelli, Gabriel Synnaeve, Zeming Lin, Pushmeet Kohli, Philip\n  H. S. Torr, Nicolas Usunier", "title": "Value Propagation Networks", "comments": "Updated to match ICLR 2019 OpenReview's version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Value Propagation (VProp), a set of parameter-efficient\ndifferentiable planning modules built on Value Iteration which can successfully\nbe trained using reinforcement learning to solve unseen tasks, has the\ncapability to generalize to larger map sizes, and can learn to navigate in\ndynamic environments. We show that the modules enable learning to plan when the\nenvironment also includes stochastic elements, providing a cost-efficient\nlearning system to build low-level size-invariant planners for a variety of\ninteractive navigation problems. We evaluate on static and dynamic\nconfigurations of MazeBase grid-worlds, with randomly generated environments of\nseveral different sizes, and on a StarCraft navigation scenario, with more\ncomplex dynamics, and pixels as input.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 23:21:32 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 17:48:22 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nardelli", "Nantas", ""], ["Synnaeve", "Gabriel", ""], ["Lin", "Zeming", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1805.11202", "submitter": "Xintao Wu", "authors": "Depeng Xu and Shuhan Yuan and Lu Zhang and Xintao Wu", "title": "FairGAN: Fairness-aware Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware learning is increasingly important in data mining.\nDiscrimination prevention aims to prevent discrimination in the training data\nbefore it is used to conduct predictive analysis. In this paper, we focus on\nfair data generation that ensures the generated data is discrimination free.\nInspired by generative adversarial networks (GAN), we present fairness-aware\ngenerative adversarial networks, called FairGAN, which are able to learn a\ngenerator producing fair data and also preserving good data utility. Compared\nwith the naive fair data generation models, FairGAN further ensures the\nclassifiers which are trained on generated data can achieve fair classification\non real data. Experiments on a real dataset show the effectiveness of FairGAN.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 23:50:20 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Xu", "Depeng", ""], ["Yuan", "Shuhan", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1805.11204", "submitter": "Rudrasis Chakraborty Dr.", "authors": "Rudrasis Chakraborty, Chun-Hao Yang, Xingjian Zhen, Monami Banerjee,\n  Derek Archer, David Vaillancourt, Vikas Singh and Baba C. Vemuri", "title": "A Statistical Recurrent Model on the Manifold of Symmetric Positive\n  Definite Matrices", "comments": "Accepted in Thirty-second Conference on Neural Information Processing\n  Systems (NIPS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a number of disciplines, the data (e.g., graphs, manifolds) to be analyzed\nare non-Euclidean in nature. Geometric deep learning corresponds to techniques\nthat generalize deep neural network models to such non-Euclidean spaces.\nSeveral recent papers have shown how convolutional neural networks (CNNs) can\nbe extended to learn with graph-based data. In this work, we study the setting\nwhere the data (or measurements) are ordered, longitudinal or temporal in\nnature and live on a Riemannian manifold -- this setting is common in a variety\nof problems in statistical machine learning, vision and medical imaging. We\nshow how recurrent statistical recurrent network models can be defined in such\nspaces. We give an efficient algorithm and conduct a rigorous analysis of its\nstatistical properties. We perform extensive numerical experiments\ndemonstrating competitive performance with state of the art methods but with\nsignificantly less number of parameters. We also show applications to a\nstatistical analysis task in brain imaging, a regime where deep neural network\nmodels have only been utilized in limited ways.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 00:10:39 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 16:50:39 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chakraborty", "Rudrasis", ""], ["Yang", "Chun-Hao", ""], ["Zhen", "Xingjian", ""], ["Banerjee", "Monami", ""], ["Archer", "Derek", ""], ["Vaillancourt", "David", ""], ["Singh", "Vikas", ""], ["Vemuri", "Baba C.", ""]]}, {"id": "1805.11221", "submitter": "San Gultekin", "authors": "San Gultekin, Avishek Saha, Adwait Ratnaparkhi, John Paisley", "title": "MBA: Mini-Batch AUC Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Area under the receiver operating characteristics curve (AUC) is an important\nmetric for a wide range of signal processing and machine learning problems, and\nscalable methods for optimizing AUC have recently been proposed. However,\nhandling very large datasets remains an open challenge for this problem. This\npaper proposes a novel approach to AUC maximization, based on sampling\nmini-batches of positive/negative instance pairs and computing U-statistics to\napproximate a global risk minimization problem. The resulting algorithm is\nsimple, fast, and learning-rate free. We show that the number of samples\nrequired for good performance is independent of the number of pairs available,\nwhich is a quadratic function of the positive and negative instances. Extensive\nexperiments show the practical utility of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 02:30:40 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 05:00:08 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Gultekin", "San", ""], ["Saha", "Avishek", ""], ["Ratnaparkhi", "Adwait", ""], ["Paisley", "John", ""]]}, {"id": "1805.11222", "submitter": "Edouard Grave", "authors": "Edouard Grave, Armand Joulin, Quentin Berthet", "title": "Unsupervised Alignment of Embeddings with Wasserstein Procrustes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of aligning two sets of points in high dimension, which\nhas many applications in natural language processing and computer vision. As an\nexample, it was recently shown that it is possible to infer a bilingual\nlexicon, without supervised data, by aligning word embeddings trained on\nmonolingual data. These recent advances are based on adversarial training to\nlearn the mapping between the two embeddings. In this paper, we propose to use\nan alternative formulation, based on the joint estimation of an orthogonal\nmatrix and a permutation matrix. While this problem is not convex, we propose\nto initialize our optimization algorithm by using a convex relaxation,\ntraditionally considered for the graph isomorphism problem. We propose a\nstochastic algorithm to minimize our cost function on large scale problems.\nFinally, we evaluate our method on the problem of unsupervised word\ntranslation, by aligning word embeddings trained on monolingual data. On this\ntask, our method obtains state of the art results, while requiring less\ncomputational resources than competing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 02:35:15 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Berthet", "Quentin", ""]]}, {"id": "1805.11232", "submitter": "Gon\\c{c}alo Abreu", "authors": "Gon\\c{c}alo Abreu, Rui Neves, Nuno Horta", "title": "Currency exchange prediction using machine learning, genetic algorithms\n  and technical analysis", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical analysis is used to discover investment opportunities. To test this\nhypothesis we propose an hybrid system using machine learning techniques\ntogether with genetic algorithms. Using technical analysis there are more ways\nto represent a currency exchange time series than the ones it is possible to\ntest computationally, i.e., it is unfeasible to search the whole input feature\nspace thus a genetic algorithm is an alternative. In this work, an architecture\nfor automatic feature selection is proposed to optimize the cross validated\nperformance estimation of a Naive Bayes model using a genetic algorithm. The\nproposed architecture improves the return on investment of the unoptimized\nsystem from 0,43% to 10,29% in the validation set. The features selected and\nthe model decision boundary are visualized using the algorithm t-Distributed\nStochastic Neighbor embedding.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:36:34 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Abreu", "Gon\u00e7alo", ""], ["Neves", "Rui", ""], ["Horta", "Nuno", ""]]}, {"id": "1805.11233", "submitter": "Dongsoo Lee", "authors": "Dongsoo Lee and Byeongwook Kim", "title": "Retraining-Based Iterative Weight Quantization for Deep Neural Networks", "comments": "12 pages, 13 figures, NIPS 2018 (32nd Annual Conference on Neural\n  Information Processing Systems) submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has gained a lot of attention due to its ability to reduce\nhardware resource requirements significantly while maintaining accuracy of\nDNNs. Model compression is especially useful for memory-intensive recurrent\nneural networks because smaller memory footprint is crucial not only for\nreducing storage requirement but also for fast inference operations.\nQuantization is known to be an effective model compression method and\nresearchers are interested in minimizing the number of bits to represent\nparameters. In this work, we introduce an iterative technique to apply\nquantization, presenting high compression ratio without any modifications to\nthe training algorithm. In the proposed technique, weight quantization is\nfollowed by retraining the model with full precision weights. We show that\niterative retraining generates new sets of weights which can be quantized with\ndecreasing quantization loss at each iteration. We also show that quantization\nis efficiently able to leverage pruning, another effective model compression\nmethod. Implementation issues on combining the two methods are also addressed.\nOur experimental results demonstrate that an LSTM model using 1-bit quantized\nweights is sufficient for PTB dataset without any accuracy degradation while\nprevious methods demand at least 2-4 bits for quantized weights.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:36:40 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kim", "Byeongwook", ""]]}, {"id": "1805.11240", "submitter": "Wen Sun", "authors": "Wen Sun, J. Andrew Bagnell, Byron Boots", "title": "Truncated Horizon Policy Search: Combining Reinforcement Learning &\n  Imitation Learning", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to combine imitation and reinforcement learning via\nthe idea of reward shaping using an oracle. We study the effectiveness of the\nnear-optimal cost-to-go oracle on the planning horizon and demonstrate that the\ncost-to-go oracle shortens the learner's planning horizon as function of its\naccuracy: a globally optimal oracle can shorten the planning horizon to one,\nleading to a one-step greedy Markov Decision Process which is much easier to\noptimize, while an oracle that is far away from the optimality requires\nplanning over a longer horizon to achieve near-optimal performance. Hence our\nnew insight bridges the gap and interpolates between imitation learning and\nreinforcement learning. Motivated by the above mentioned insights, we propose\nTruncated HORizon Policy Search (THOR), a method that focuses on searching for\npolicies that maximize the total reshaped reward over a finite planning horizon\nwhen the oracle is sub-optimal. We experimentally demonstrate that a\ngradient-based implementation of THOR can achieve superior performance compared\nto RL baselines and IL baselines even when the oracle is sub-optimal.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 04:24:17 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Sun", "Wen", ""], ["Bagnell", "J. Andrew", ""], ["Boots", "Byron", ""]]}, {"id": "1805.11243", "submitter": "YooJung Choi", "authors": "YooJung Choi, Guy Van den Broeck", "title": "On Robust Trimming of Bayesian Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of removing costly features from a Bayesian\nnetwork classifier. We want the classifier to be robust to these changes, and\nmaintain its classification behavior. To this end, we propose a closeness\nmetric between Bayesian classifiers, called the expected classification\nagreement (ECA). Our corresponding trimming algorithm finds an optimal subset\nof features and a new classification threshold that maximize the expected\nagreement, subject to a budgetary constraint. It utilizes new theoretical\ninsights to perform branch-and-bound search in the space of feature sets, while\ncomputing bounds on the ECA. Our experiments investigate both the runtime cost\nof trimming and its effect on the robustness and accuracy of the final\nclassifier.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 04:46:16 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Choi", "YooJung", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1805.11264", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, James Glass", "title": "Disentangling by Partitioning: A Representation Learning Framework for\n  Multimodal Sensory Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sensory data resembles the form of information perceived by humans\nfor learning, and are easy to obtain in large quantities. Compared to unimodal\ndata, synchronization of concepts between modalities in such data provides\nsupervision for disentangling the underlying explanatory factors of each\nmodality. Previous work leveraging multimodal data has mainly focused on\nretaining only the modality-invariant factors while discarding the rest. In\nthis paper, we present a partitioned variational autoencoder (PVAE) and several\ntraining objectives to learn disentangled representations, which encode not\nonly the shared factors, but also modality-dependent ones, into separate latent\nvariables. Specifically, PVAE integrates a variational inference framework and\na multimodal generative model that partitions the explanatory factors and\nconditions only on the relevant subset of them for generation. We evaluate our\nmodel on two parallel speech/image datasets, and demonstrate its ability to\nlearn disentangled representations by qualitatively exploring within-modality\nand cross-modality conditional generation with semantics and styles specified\nby examples. For quantitative analysis, we evaluate the classification accuracy\nof automatically discovered semantic units. Our PVAE can achieve over 99%\naccuracy on both modalities.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 06:45:02 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1805.11272", "submitter": "Cecilia Summers", "authors": "Cecilia Summers, Michael J. Dinneen", "title": "Improved Mixed-Example Data Augmentation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reduce overfitting, neural networks are typically trained with\ndata augmentation, the practice of artificially generating additional training\ndata via label-preserving transformations of existing training examples. While\nthese types of transformations make intuitive sense, recent work has\ndemonstrated that even non-label-preserving data augmentation can be\nsurprisingly effective, examining this type of data augmentation through linear\ncombinations of pairs of examples. Despite their effectiveness, little is known\nabout why such methods work. In this work, we aim to explore a new, more\ngeneralized form of this type of data augmentation in order to determine\nwhether such linearity is necessary. By considering this broader scope of\n\"mixed-example data augmentation\", we find a much larger space of practical\naugmentation techniques, including methods that improve upon previous\nstate-of-the-art. This generalization has benefits beyond the promise of\nimproved performance, revealing a number of types of mixed-example data\naugmentation that are radically different from those considered in prior work,\nwhich provides evidence that current theories for the effectiveness of such\nmethods are incomplete and suggests that any such theory must explain a much\nbroader phenomenon. Code is available at\nhttps://github.com/ceciliaresearch/MixedExample.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 07:06:58 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 06:50:22 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 06:10:23 GMT"}, {"version": "v4", "created": "Sat, 19 Jan 2019 07:04:35 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Summers", "Cecilia", ""], ["Dinneen", "Michael J.", ""]]}, {"id": "1805.11284", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Umut G\\\"u\\c{c}l\\\"u, Ya\\u{g}mur G\\\"u\\c{c}l\\\"ut\\\"urk,\n  Max Hinne, Eric Maris and Marcel A. J. van Gerven", "title": "Wasserstein Variational Inference", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Wasserstein variational inference, a new form of\napproximate Bayesian inference based on optimal transport theory. Wasserstein\nvariational inference uses a new family of divergences that includes both\nf-divergences and the Wasserstein distance as special cases. The gradients of\nthe Wasserstein variational loss are obtained by backpropagating through the\nSinkhorn iterations. This technique results in a very stable likelihood-free\ntraining method that can be used with implicit distributions and probabilistic\nprograms. Using the Wasserstein variational inference framework, we introduce\nseveral new forms of autoencoders and test their robustness and performance\nagainst existing variational autoencoding techniques.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 07:50:26 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 12:24:22 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Ambrogioni", "Luca", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["G\u00fc\u00e7l\u00fct\u00fcrk", "Ya\u011fmur", ""], ["Hinne", "Max", ""], ["Maris", "Eric", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1805.11317", "submitter": "Ren-Jie Han", "authors": "Yue-Gang Song, Yu-Long Zhou, Ren-Jie Han", "title": "Neural networks for stock price prediction", "comments": "13 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the extremely volatile nature of financial markets, it is commonly\naccepted that stock price prediction is a task full of challenge. However in\norder to make profits or understand the essence of equity market, numerous\nmarket participants or researchers try to forecast stock price using various\nstatistical, econometric or even neural network models. In this work, we survey\nand compare the predictive power of five neural network models, namely, back\npropagation (BP) neural network, radial basis function (RBF) neural network,\ngeneral regression neural network (GRNN), support vector machine regression\n(SVMR), least squares support vector machine regresssion (LS-SVMR). We apply\nthe five models to make price prediction of three individual stocks, namely,\nBank of China, Vanke A and Kweichou Moutai. Adopting mean square error and\naverage absolute percentage error as criteria, we find BP neural network\nconsistently and robustly outperforms the other four models.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 09:14:49 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Song", "Yue-Gang", ""], ["Zhou", "Yu-Long", ""], ["Han", "Ren-Jie", ""]]}, {"id": "1805.11324", "submitter": "Tim Pearce", "authors": "Tim Pearce, Nicolas Anastassacos, Mohamed Zaki, Andy Neely", "title": "Bayesian Inference with Anchored Ensembles of Neural Networks, and\n  Application to Exploration in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of ensembles of neural networks (NNs) for the quantification of\npredictive uncertainty is widespread. However, the current justification is\nintuitive rather than analytical. This work proposes one minor modification to\nthe normal ensembling methodology, which we prove allows the ensemble to\nperform Bayesian inference, hence converging to the corresponding Gaussian\nProcess as both the total number of NNs, and the size of each, tend to\ninfinity. This working paper provides early-stage results in a reinforcement\nlearning setting, analysing the practicality of the technique for an ensemble\nof small, finite number. Using the uncertainty estimates produced by anchored\nensembles to govern the exploration-exploitation process results in steadier,\nmore stable learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 09:36:16 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 17:03:00 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 11:45:45 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Pearce", "Tim", ""], ["Anastassacos", "Nicolas", ""], ["Zaki", "Mohamed", ""], ["Neely", "Andy", ""]]}, {"id": "1805.11327", "submitter": "Jochen Gast", "authors": "Jochen Gast and Stefan Roth", "title": "Lightweight Probabilistic Deep Networks", "comments": "To appear at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though probabilistic treatments of neural networks have a long history,\nthey have not found widespread use in practice. Sampling approaches are often\ntoo slow already for simple networks. The size of the inputs and the depth of\ntypical CNN architectures in computer vision only compound this problem.\nUncertainty in neural networks has thus been largely ignored in practice,\ndespite the fact that it may provide important information about the\nreliability of predictions and the inner workings of the network. In this\npaper, we introduce two lightweight approaches to making supervised learning\nwith probabilistic deep networks practical: First, we suggest probabilistic\noutput layers for classification and regression that require only minimal\nchanges to existing networks. Second, we employ assumed density filtering and\nshow that activation uncertainties can be propagated in a practical fashion\nthrough the entire network, again with minor changes. Both probabilistic\nnetworks retain the predictive power of the deterministic counterpart, but\nyield uncertainties that correlate well with the empirical error induced by\ntheir predictions. Moreover, the robustness to adversarial examples is\nsignificantly increased.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 09:40:52 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Gast", "Jochen", ""], ["Roth", "Stefan", ""]]}, {"id": "1805.11328", "submitter": "Anthony Caterini", "authors": "Anthony L. Caterini, Arnaud Doucet, Dino Sejdinovic", "title": "Hamiltonian Variational Auto-Encoder", "comments": "Accepted as a poster in the proceedings of the 32nd Conference on\n  Neural Information Processing Systems (NeurIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoders (VAEs) have become very popular techniques to\nperform inference and learning in latent variable models as they allow us to\nleverage the rich representational power of neural networks to obtain flexible\napproximations of the posterior of latent variables as well as tight evidence\nlower bounds (ELBOs). Combined with stochastic variational inference, this\nprovides a methodology scaling to large datasets. However, for this methodology\nto be practically efficient, it is necessary to obtain low-variance unbiased\nestimators of the ELBO and its gradients with respect to the parameters of\ninterest. While the use of Markov chain Monte Carlo (MCMC) techniques such as\nHamiltonian Monte Carlo (HMC) has been previously suggested to achieve this\n[23, 26], the proposed methods require specifying reverse kernels which have a\nlarge impact on performance. Additionally, the resulting unbiased estimator of\nthe ELBO for most MCMC kernels is typically not amenable to the\nreparameterization trick. We show here how to optimally select reverse kernels\nin this setting and, by building upon Hamiltonian Importance Sampling (HIS)\n[17], we obtain a scheme that provides low-variance unbiased estimators of the\nELBO and its gradients using the reparameterization trick. This allows us to\ndevelop a Hamiltonian Variational Auto-Encoder (HVAE). This method can be\nreinterpreted as a target-informed normalizing flow [20] which, within our\ncontext, only requires a few evaluations of the gradient of the sampled\nlikelihood and trivial Jacobian calculations at each iteration.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 09:43:12 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 15:24:55 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Caterini", "Anthony L.", ""], ["Doucet", "Arnaud", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1805.11350", "submitter": "Nikola Mrk\\v{s}i\\'c", "authors": "Nikola Mrk\\v{s}i\\'c and Ivan Vuli\\'c", "title": "Fully Statistical Neural Belief Tracking", "comments": "Accepted as a short paper for the 56th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improvement to the existing data-driven Neural Belief\nTracking (NBT) framework for Dialogue State Tracking (DST). The existing NBT\nmodel uses a hand-crafted belief state update mechanism which involves an\nexpensive manual retuning step whenever the model is deployed to a new dialogue\ndomain. We show that this update mechanism can be learned jointly with the\nsemantic decoding and context modelling parts of the NBT model, eliminating the\nlast rule-based module from this DST framework. We propose two different\nstatistical update mechanisms and show that dialogue dynamics can be modelled\nwith a very small number of additional model parameters. In our DST evaluation\nover three languages, we show that this model achieves competitive performance\nand provides a robust framework for building resource-light DST models.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 10:41:08 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mrk\u0161i\u0107", "Nikola", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.11365", "submitter": "Prateek Yadav", "authors": "Prateek Yadav, Madhav Nimishakavi, Naganand Yadati, Shikhar Vashishth,\n  Arun Rajkumar, Partha Talukdar", "title": "Lovasz Convolutional Networks", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning on graph structured data has received significant\nattention with the recent introduction of Graph Convolution Networks (GCN).\nWhile traditional methods have focused on optimizing a loss augmented with\nLaplacian regularization framework, GCNs perform an implicit Laplacian type\nregularization to capture local graph structure. In this work, we propose\nLovasz Convolutional Network (LCNs) which are capable of incorporating global\ngraph properties. LCNs achieve this by utilizing Lovasz's orthonormal\nembeddings of the nodes. We analyse local and global properties of graphs and\ndemonstrate settings where LCNs tend to work better than GCNs. We validate the\nproposed method on standard random graph models such as stochastic block models\n(SBM) and certain community structure based graphs where LCNs outperform GCNs\nand learn more intuitive embeddings. We also perform extensive binary and\nmulti-class classification experiments on real world datasets to demonstrate\nLCN's effectiveness. In addition to simple graphs, we also demonstrate the use\nof LCNs on hyper-graphs by identifying settings where they are expected to work\nbetter than GCNs.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 11:48:00 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 20:51:27 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2019 13:20:22 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Yadav", "Prateek", ""], ["Nimishakavi", "Madhav", ""], ["Yadati", "Naganand", ""], ["Vashishth", "Shikhar", ""], ["Rajkumar", "Arun", ""], ["Talukdar", "Partha", ""]]}, {"id": "1805.11380", "submitter": "Manuel Pulido", "authors": "Manuel Pulido and Peter Jan vanLeeuwen", "title": "Kernel embedding of maps for sequential Bayesian inference: The\n  variational mapping particle filter", "comments": "Submitted to PNAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a novel sequential Monte Carlo filter is introduced which aims\nat efficient sampling of high-dimensional state spaces with a limited number of\nparticles. Particles are pushed forward from the prior to the posterior density\nusing a sequence of mappings that minimizes the Kullback-Leibler divergence\nbetween the posterior and the sequence of intermediate densities. The sequence\nof mappings represents a gradient flow. A key ingredient of the mappings is\nthat they are embedded in a reproducing kernel Hilbert space, which allows for\na practical and efficient algorithm. The embedding provides a direct means to\ncalculate the gradient of the Kullback-Leibler divergence leading to quick\nconvergence using well-known gradient-based stochastic optimization algorithms.\nEvaluation of the method is conducted in the chaotic Lorenz-63 system, the\nLorenz-96 system, which is a coarse prototype of atmospheric dynamics, and an\nepidemic model that describes cholera dynamics. No resampling is required in\nthe mapping particle filter even for long recursive sequences. The number of\neffective particles remains close to the total number of particles in all the\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:19:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pulido", "Manuel", ""], ["vanLeeuwen", "Peter Jan", ""]]}, {"id": "1805.11384", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Kun Yuan and Ali H. Sayed", "title": "Supervised Learning Under Distributed Features", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2881661", "report-no": null, "categories": "cs.MA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of learning under both large datasets and\nlarge-dimensional feature space scenarios. The feature information is assumed\nto be spread across agents in a network, where each agent observes some of the\nfeatures. Through local cooperation, the agents are supposed to interact with\neach other to solve an inference problem and converge towards the global\nminimizer of an empirical risk. We study this problem exclusively in the primal\ndomain, and propose new and effective distributed solutions with guaranteed\nconvergence to the minimizer with linear rate under strong convexity. This is\nachieved by combining a dynamic diffusion construction, a pipeline strategy,\nand variance-reduced techniques. Simulation results illustrate the conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:25:37 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 08:17:47 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 18:06:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ying", "Bicheng", ""], ["Yuan", "Kun", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1805.11386", "submitter": "Gilles Stoltz", "authors": "Pierre Gaillard (SIERRA), S\\'ebastien Gerchinovitz (IMT), Malo Huard\n  (LMO), Gilles Stoltz (LMO)", "title": "Uniform regret bounds over $R^d$ for the sequential linear regression\n  problem with the square loss", "comments": "Proceedings of ALT'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of online linear regression for arbitrary\ndeterministic sequences, with the square loss. We are interested in the aim set\nby Bartlett et al. (2015): obtain regret bounds that hold uniformly over all\ncompetitor vectors. When the feature sequence is known at the beginning of the\ngame, they provided closed-form regret bounds of $2d B^2 \\ln T +\n\\mathcal{O}_T(1)$, where $T$ is the number of rounds and $B$ is a bound on the\nobservations. Instead, we derive bounds with an optimal constant of $1$ in\nfront of the $d B^2 \\ln T$ term. In the case of sequentially revealed features,\nwe also derive an asymptotic regret bound of $d B^2 \\ln T$ for any individual\nsequence of features and bounded observations. All our algorithms are variants\nof the online non-linear ridge regression forecaster, either with a\ndata-dependent regularization or with almost no regularization.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:26:14 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 11:39:00 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Gaillard", "Pierre", "", "SIERRA"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"], ["Huard", "Malo", "", "LMO"], ["Stoltz", "Gilles", "", "LMO"]]}, {"id": "1805.11394", "submitter": "Yiming Hu", "authors": "Yiming Hu, Siyang Sun, Jianquan Li, Xingang Wang, Qingyi Gu", "title": "A novel channel pruning method for deep neural network compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have achieved great success in the\nfield of computer vision. However, it is still a big challenge to deploy these\ndeep models on resource-constrained embedded devices such as mobile robots,\nsmart phones and so on. Therefore, network compression for such platforms is a\nreasonable solution to reduce memory consumption and computation complexity. In\nthis paper, a novel channel pruning method based on genetic algorithm is\nproposed to compress very deep Convolution Neural Networks (CNNs). Firstly, a\npre-trained CNN model is pruned layer by layer according to the sensitivity of\neach layer. After that, the pruned model is fine-tuned based on knowledge\ndistillation framework. These two improvements significantly decrease the model\nredundancy with less accuracy drop. Channel selection is a combinatorial\noptimization problem that has exponential solution space. In order to\naccelerate the selection process, the proposed method formulates it as a search\nproblem, which can be solved efficiently by genetic algorithm. Meanwhile, a\ntwo-step approximation fitness function is designed to further improve the\nefficiency of genetic process. The proposed method has been verified on three\nbenchmark datasets with two popular CNN models: VGGNet and ResNet. On the\nCIFAR-100 and ImageNet datasets, our approach outperforms several\nstate-of-the-art methods. On the CIFAR-10 and SVHN datasets, the pruned VGGNet\nachieves better performance than the original model with 8 times parameters\ncompression and 3 times FLOPs reduction.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:37:46 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Hu", "Yiming", ""], ["Sun", "Siyang", ""], ["Li", "Jianquan", ""], ["Wang", "Xingang", ""], ["Gu", "Qingyi", ""]]}, {"id": "1805.11405", "submitter": "Andrej Risteski", "authors": "Frederic Koehler, Andrej Risteski", "title": "Representational Power of ReLU Networks and Polynomial Kernels: Beyond\n  Worst-Case Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a large amount of interest, both in the past and particularly\nrecently, into the power of different families of universal approximators, e.g.\nReLU networks, polynomials, rational functions. However, current research has\nfocused almost exclusively on understanding this problem in a worst-case\nsetting, e.g. bounding the error of the best infinity-norm approximation in a\nbox. In this setting a high-degree polynomial is required to even approximate a\nsingle ReLU.\n  However, in real applications with high dimensional data we expect it is only\nimportant to approximate the desired function well on certain relevant parts of\nits domain. With this motivation, we analyze the ability of neural networks and\npolynomial kernels of bounded degree to achieve good statistical performance on\na simple, natural inference problem with sparse latent structure. We give\nalmost-tight bounds on the performance of both neural networks and low degree\npolynomials for this problem. Our bounds for polynomials involve new techniques\nwhich may be of independent interest and show major qualitative differences\nwith what is known in the worst-case setting.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:05:56 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Koehler", "Frederic", ""], ["Risteski", "Andrej", ""]]}, {"id": "1805.11447", "submitter": "El Mahdi El Mhamdi", "authors": "Henrik Aslund, El Mahdi El Mhamdi, Rachid Guerraoui, Alexandre Maurer", "title": "Virtuously Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We show that when a third party, the adversary, steps into the two-party\nsetting (agent and operator) of safely interruptible reinforcement learning, a\ntrade-off has to be made between the probability of following the optimal\npolicy in the limit, and the probability of escaping a dangerous situation\ncreated by the adversary. So far, the work on safely interruptible agents has\nassumed a perfect perception of the agent about its environment (no adversary),\nand therefore implicitly set the second probability to zero, by explicitly\nseeking a value of one for the first probability. We show that (1) agents can\nbe made both interruptible and adversary-resilient, and (2) the\ninterruptibility can be made safe in the sense that the agent itself will not\nseek to avoid it. We also solve the problem that arises when the agent does not\ngo completely greedy, i.e. issues with safe exploration in the limit.\nResilience to perturbed perception, safe exploration in the limit, and safe\ninterruptibility are the three pillars of what we call \\emph{virtuously safe\nreinforcement learning}.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:34:39 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Aslund", "Henrik", ""], ["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Maurer", "Alexandre", ""]]}, {"id": "1805.11450", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen and Paraschos Koutris and Arun Kumar", "title": "Model-based Pricing for Machine Learning in a Data Marketplace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.GT cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics using machine learning (ML) has become ubiquitous in science,\nbusiness intelligence, journalism and many other domains. While a lot of work\nfocuses on reducing the training cost, inference runtime and storage cost of ML\nmodels, little work studies how to reduce the cost of data acquisition, which\npotentially leads to a loss of sellers' revenue and buyers' affordability and\nefficiency.\n  In this paper, we propose a model-based pricing (MBP) framework, which\ninstead of pricing the data, directly prices ML model instances. We first\nformally describe the desired properties of the MBP framework, with a focus on\navoiding arbitrage. Next, we show a concrete realization of the MBP framework\nvia a noise injection approach, which provably satisfies the desired formal\nproperties. Based on the proposed framework, we then provide algorithmic\nsolutions on how the seller can assign prices to models under different market\nscenarios (such as to maximize revenue). Finally, we conduct extensive\nexperiments, which validate that the MBP framework can provide high revenue to\nthe seller, high affordability to the buyer, and also operate on low runtime\ncost.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 06:02:40 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Chen", "Lingjiao", ""], ["Koutris", "Paraschos", ""], ["Kumar", "Arun", ""]]}, {"id": "1805.11452", "submitter": "Takashi Sano", "authors": "Takashi Sano", "title": "An Analytic Solution to the Inverse Ising Problem in the Tree-reweighted\n  Approximation", "comments": "8 pages, to be published in proceedings of the 2018 International\n  Joint Conference on Neural Networks (IJCNN 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many iterative and non-iterative methods have been developed for inverse\nproblems associated with Ising models. Aiming to derive an accurate\nnon-iterative method for the inverse problems, we employ the tree-reweighted\napproximation. Using the tree-reweighted approximation, we can optimize the\nrigorous lower bound of the objective function. By solving the moment-matching\nand self-consistency conditions analytically, we can derive the interaction\nmatrix as a function of the given data statistics. With this solution, we can\nobtain the optimal interaction matrix without iterative computation. To\nevaluate the accuracy of the proposed inverse formula, we compared our results\nto those obtained by existing inverse formulae derived with other\napproximations. In an experiment to reconstruct the interaction matrix, we\nfound that the proposed formula returns the best estimates in\nstrongly-attractive regions for various graph structures. We also performed an\nexperiment using real-world biological data. When applied to finding the\nconnectivity of neurons from spike train data, the proposed formula gave the\nclosest result to that obtained by a gradient ascent algorithm, which typically\nrequires thousands of iterations.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:38:18 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Sano", "Takashi", ""]]}, {"id": "1805.11494", "submitter": "Christian Donner", "authors": "Christian Donner and Manfred Opper", "title": "Efficient Bayesian Inference for a Gaussian Process Density Model", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We reconsider a nonparametric density model based on Gaussian processes. By\naugmenting the model with latent P\\'olya--Gamma random variables and a latent\nmarked Poisson process we obtain a new likelihood which is conjugate to the\nmodel's Gaussian process prior. The augmented posterior allows for efficient\ninference by Gibbs sampling and an approximate variational mean field approach.\nFor the latter we utilise sparse GP approximations to tackle the infinite\ndimensionality of the problem. The performance of both algorithms and\ncomparisons with other density estimators are demonstrated on artificial and\nreal datasets with up to several thousand data points.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 14:24:31 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Donner", "Christian", ""], ["Opper", "Manfred", ""]]}, {"id": "1805.11504", "submitter": "Umair Javaid", "authors": "Umair Javaid and John A. Lee", "title": "Capturing Variabilities from Computed Tomography Images with Generative\n  Adversarial Networks", "comments": null, "journal-ref": "European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESANN) Proceedings, pages 403-408, 25-27th\n  April, 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the advent of Deep Learning (DL) techniques, especially Generative\nAdversarial Networks (GANs), data augmentation and generation are quickly\nevolving domains that have raised much interest recently. However, the DL\ntechniques are data demanding and since, medical data is not easily accessible,\nthey suffer from data insufficiency. To deal with this limitation, different\ndata augmentation techniques are used. Here, we propose a novel unsupervised\ndata-driven approach for data augmentation that can generate 2D Computed\nTomography (CT) images using a simple GAN. The generated CT images have good\nglobal and local features of a real CT image and can be used to augment the\ntraining datasets for effective learning. In this proof-of-concept study, we\nshow that our proposed solution using GANs is able to capture some of the\nglobal and local CT variabilities. Our network is able to generate visually\nrealistic CT images and we aim to further enhance its output by scaling it to a\nhigher resolution and potentially from 2D to 3D.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 14:34:56 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Javaid", "Umair", ""], ["Lee", "John A.", ""]]}, {"id": "1805.11526", "submitter": "Rainer Kelz", "authors": "Rainer Kelz, Gerhard Widmer", "title": "Learning to Transcribe by Ear", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rethinking how to model polyphonic transcription formally, we frame it as a\nreinforcement learning task. Such a task formulation encompasses the notion of\na musical agent and an environment containing an instrument as well as the\nsound source to be transcribed. Within this conceptual framework, the\ntranscription process can be described as the agent interacting with the\ninstrument in the environment, and obtaining reward by playing along with what\nit hears. Choosing from a discrete set of actions - the notes to play on its\ninstrument - the amount of reward the agent experiences depends on which notes\nit plays and when. This process resembles how a human musician might approach\nthe task of transcription, and the satisfaction she achieves by closely\nmimicking the sound source to transcribe on her instrument. Following a\ndiscussion of the theoretical framework and the benefits of modelling the\nproblem in this way, we focus our attention on several practical considerations\nand address the difficulties in training an agent to acceptable performance on\na set of tasks with increasing difficulty. We demonstrate promising results in\npartially constrained environments.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 14:58:35 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Kelz", "Rainer", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1805.11534", "submitter": "M. Benjamin Sabath", "authors": "M. Benjamin Sabath, Qian Di, Danielle Braun, Joel Schwarz, Francesca\n  Dominici, Christine Choirat", "title": "airpred: A Flexible R Package Implementing Methods for Predicting Air\n  Pollution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine particulate matter (PM$_{2.5}$) is one of the criteria air pollutants\nregulated by the Environmental Protection Agency in the United States. There is\nstrong evidence that ambient exposure to (PM$_{2.5}$) increases risk of\nmortality and hospitalization. Large scale epidemiological studies on the\nhealth effects of PM$_{2.5}$ provide the necessary evidence base for lowering\nthe safety standards and inform regulatory policy. However, ambient monitors of\nPM$_{2.5}$ (as well as monitors for other pollutants) are sparsely located\nacross the U.S., and therefore studies based only on the levels of PM$_{2.5}$\nmeasured from the monitors would inevitably exclude large amounts of the\npopulation. One approach to resolving this issue has been developing models to\npredict local PM$_{2.5}$, NO$_2$, and ozone based on satellite, meteorological,\nand land use data. This process typically relies developing a prediction model\nthat relies on large amounts of input data and is highly computationally\nintensive to predict levels of air pollution in unmonitored areas. We have\ndeveloped a flexible R package that allows for environmental health researchers\nto design and train spatio-temporal models capable of predicting multiple\npollutants, including PM$_{2.5}$. We utilize H2O, an open source big data\nplatform, to achieve both performance and scalability when used in conjunction\nwith cloud or cluster computing systems.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:12:58 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 14:32:18 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Sabath", "M. Benjamin", ""], ["Di", "Qian", ""], ["Braun", "Danielle", ""], ["Schwarz", "Joel", ""], ["Dominici", "Francesca", ""], ["Choirat", "Christine", ""]]}, {"id": "1805.11542", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Umut G\\\"u\\c{c}l\\\"u, Julia Berezutskaya, Eva W. P. van\n  den Borne, Ya\\u{g}mur G\\\"u\\c{c}l\\\"ut\\\"urk, Max Hinne, Eric Maris and Marcel\n  A. J. van Gerven", "title": "Forward Amortized Inference for Likelihood-Free Variational\n  Marginalization", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new form of amortized variational inference by\nusing the forward KL divergence in a joint-contrastive variational loss. The\nresulting forward amortized variational inference is a likelihood-free method\nas its gradient can be sampled without bias and without requiring any\nevaluation of either the model joint distribution or its derivatives. We prove\nthat our new variational loss is optimized by the exact posterior marginals in\nthe fully factorized mean-field approximation, a property that is not shared\nwith the more conventional reverse KL inference. Furthermore, we show that\nforward amortized inference can be easily marginalized over large families of\nlatent variables in order to obtain a marginalized variational posterior. We\nconsider two examples of variational marginalization. In our first example we\ntrain a Bayesian forecaster for predicting a simplified chaotic model of\natmospheric convection. In the second example we train an amortized variational\napproximation of a Bayesian optimal classifier by marginalizing over the model\nspace. The result is a powerful meta-classification network that can solve\narbitrary classification problems without further training.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:33:08 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Ambrogioni", "Luca", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["Berezutskaya", "Julia", ""], ["Borne", "Eva W. P. van den", ""], ["G\u00fc\u00e7l\u00fct\u00fcrk", "Ya\u011fmur", ""], ["Hinne", "Max", ""], ["Maris", "Eric", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1805.11565", "submitter": "Danica J. Sutherland", "authors": "Michael Arbel, Danica J. Sutherland, Miko{\\l}aj Bi\\'nkowski, Arthur\n  Gretton", "title": "On gradient regularizers for MMD GANs", "comments": "Code at https://github.com/MichaelArbel/Scaled-MMD-GAN", "journal-ref": "Advances in Neural Information Processing Systems 31 (NeurIPS\n  2018), 6700-6710", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a principled method for gradient-based regularization of the\ncritic of GAN-like models trained by adversarially optimizing the kernel of a\nMaximum Mean Discrepancy (MMD). We show that controlling the gradient of the\ncritic is vital to having a sensible loss function, and devise a method to\nenforce exact, analytical gradient constraints at no additional cost compared\nto existing approximate techniques based on additive regularizers. The new loss\nfunction is provably continuous, and experiments show that it stabilizes and\naccelerates training, giving image generation models that outperform\nstate-of-the art methods on $160 \\times 160$ CelebA and $64 \\times 64$\nunconditional ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 16:23:56 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 13:25:28 GMT"}, {"version": "v3", "created": "Sat, 24 Nov 2018 03:35:54 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 20:56:44 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 05:27:48 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Arbel", "Michael", ""], ["Sutherland", "Danica J.", ""], ["Bi\u0144kowski", "Miko\u0142aj", ""], ["Gretton", "Arthur", ""]]}, {"id": "1805.11571", "submitter": "Isaac Lage", "authors": "Isaac Lage, Andrew Slavin Ross, Been Kim, Samuel J. Gershman, Finale\n  Doshi-Velez", "title": "Human-in-the-Loop Interpretability Prior", "comments": "To appear at NIPS 2018, selected for a spotlight. 13 pages (incl\n  references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We often desire our models to be interpretable as well as accurate. Prior\nwork on optimizing models for interpretability has relied on easy-to-quantify\nproxies for interpretability, such as sparsity or the number of operations\nrequired. In this work, we optimize for interpretability by directly including\nhumans in the optimization loop. We develop an algorithm that minimizes the\nnumber of user studies to find models that are both predictive and\ninterpretable and demonstrate our approach on several data sets. Our human\nsubjects results show trends towards different proxy notions of\ninterpretability on different datasets, which suggests that different proxies\nare preferred on different tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 16:27:32 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:37:19 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lage", "Isaac", ""], ["Ross", "Andrew Slavin", ""], ["Kim", "Been", ""], ["Gershman", "Samuel J.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1805.11572", "submitter": "Sebastian Lunz", "authors": "Sebastian Lunz, Ozan \\\"Oktem, Carola-Bibiane Sch\\\"onlieb", "title": "Adversarial Regularizers in Inverse Problems", "comments": "published at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse Problems in medical imaging and computer vision are traditionally\nsolved using purely model-based methods. Among those variational regularization\nmodels are one of the most popular approaches. We propose a new framework for\napplying data-driven approaches to inverse problems, using a neural network as\na regularization functional. The network learns to discriminate between the\ndistribution of ground truth images and the distribution of unregularized\nreconstructions. Once trained, the network is applied to the inverse problem by\nsolving the corresponding variational problem. Unlike other data-based\napproaches for inverse problems, the algorithm can be applied even if only\nunsupervised training data is available. Experiments demonstrate the potential\nof the framework for denoising on the BSDS dataset and for computed tomography\nreconstruction on the LIDC dataset.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 16:40:37 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 17:24:06 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Lunz", "Sebastian", ""], ["\u00d6ktem", "Ozan", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1805.11576", "submitter": "Haidar Khan", "authors": "Haidar Khan, Lara Marcuse, Madeline Fields, Kalina Swann, B\\\"ulent\n  Yener", "title": "Focal onset seizure prediction using convolutional networks", "comments": "8 pages, 6 figures, 3 tables", "journal-ref": "Khan, H., Marcuse, L., Fields, M., Swann, K., & Yener, B. (2017).\n  Focal onset seizure prediction using convolutional networks. IEEE\n  Transactions on Biomedical Engineering", "doi": "10.1109/TBME.2017.2785401", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This work investigates the hypothesis that focal seizures can be\npredicted using scalp electroencephalogram (EEG) data. Our first aim is to\nlearn features that distinguish between the interictal and preictal regions.\nThe second aim is to define a prediction horizon in which the prediction is as\naccurate and as early as possible, clearly two competing objectives. Methods:\nConvolutional filters on the wavelet transformation of the EEG signal are used\nto define and learn quantitative signatures for each period: interictal,\npreictal, and ictal. The optimal seizure prediction horizon is also learned\nfrom the data as opposed to making an a priori assumption. Results:\nComputational solutions to the optimization problem indicate a ten-minute\nseizure prediction horizon. This result is verified by measuring\nKullback-Leibler divergence on the distributions of the automatically extracted\nfeatures. Conclusion: The results on the EEG database of 204 recordings\ndemonstrate that (i) the preictal phase transition occurs approximately ten\nminutes before seizure onset, and (ii) the prediction results on the test set\nare promising, with a sensitivity of 87.8% and a low false prediction rate of\n0.142 FP/h. Our results significantly outperform a random predictor and other\nseizure prediction algorithms. Significance: We demonstrate that a robust set\nof features can be learned from scalp EEG that characterize the preictal state\nof focal seizures.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 16:51:56 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Khan", "Haidar", ""], ["Marcuse", "Lara", ""], ["Fields", "Madeline", ""], ["Swann", "Kalina", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "1805.11592", "submitter": "Yusuf Aytar", "authors": "Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang,\n  Nando de Freitas", "title": "Playing hard exploration games by watching YouTube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning methods traditionally struggle with tasks where\nenvironment rewards are particularly sparse. One successful method of guiding\nexploration in these domains is to imitate trajectories provided by a human\ndemonstrator. However, these demonstrations are typically collected under\nartificial conditions, i.e. with access to the agent's exact environment setup\nand the demonstrator's action and reward trajectories. Here we propose a\ntwo-stage method that overcomes these limitations by relying on noisy,\nunaligned footage without access to such data. First, we learn to map unaligned\nvideos from multiple sources to a common representation using self-supervised\nobjectives constructed over both time and modality (i.e. vision and sound).\nSecond, we embed a single YouTube video in this representation to construct a\nreward function that encourages an agent to imitate human gameplay. This method\nof one-shot imitation allows our agent to convincingly exceed human-level\nperformance on the infamously hard exploration games Montezuma's Revenge,\nPitfall! and Private Eye for the first time, even if the agent is not presented\nwith any environment rewards.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:19:36 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 15:59:27 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Aytar", "Yusuf", ""], ["Pfaff", "Tobias", ""], ["Budden", "David", ""], ["Paine", "Tom Le", ""], ["Wang", "Ziyu", ""], ["de Freitas", "Nando", ""]]}, {"id": "1805.11593", "submitter": "Tobias Pohlen", "authors": "Tobias Pohlen, Bilal Piot, Todd Hester, Mohammad Gheshlaghi Azar, Dan\n  Horgan, David Budden, Gabriel Barth-Maron, Hado van Hasselt, John Quan, Mel\n  Ve\\v{c}er\\'ik, Matteo Hessel, R\\'emi Munos, Olivier Pietquin", "title": "Observe and Look Further: Achieving Consistent Performance on Atari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant advances in the field of deep Reinforcement Learning\n(RL), today's algorithms still fail to learn human-level policies consistently\nover a set of diverse tasks such as Atari 2600 games. We identify three key\nchallenges that any algorithm needs to master in order to perform well on all\ngames: processing diverse reward distributions, reasoning over long time\nhorizons, and exploring efficiently. In this paper, we propose an algorithm\nthat addresses each of these challenges and is able to learn human-level\npolicies on nearly all Atari games. A new transformed Bellman operator allows\nour algorithm to process rewards of varying densities and scales; an auxiliary\ntemporal consistency loss allows us to train stably using a discount factor of\n$\\gamma = 0.999$ (instead of $\\gamma = 0.99$) extending the effective planning\nhorizon by an order of magnitude; and we ease the exploration problem by using\nhuman demonstrations that guide the agent towards rewarding states. When tested\non a set of 42 Atari games, our algorithm exceeds the performance of an average\nhuman on 40 games using a common set of hyper parameters. Furthermore, it is\nthe first deep RL algorithm to solve the first level of Montezuma's Revenge.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:19:59 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pohlen", "Tobias", ""], ["Piot", "Bilal", ""], ["Hester", "Todd", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Horgan", "Dan", ""], ["Budden", "David", ""], ["Barth-Maron", "Gabriel", ""], ["van Hasselt", "Hado", ""], ["Quan", "John", ""], ["Ve\u010der\u00edk", "Mel", ""], ["Hessel", "Matteo", ""], ["Munos", "R\u00e9mi", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1805.11596", "submitter": "Yaniv Romano", "authors": "Yaniv Romano, Aviad Aberdam, Jeremias Sulam, Michael Elad", "title": "Adversarial Noise Attacks of Deep Learning Architectures -- Stability\n  Analysis via Sparse Modeled Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance, deep convolutional neural networks\n(CNNs) have been shown to be sensitive to small adversarial perturbations.\nThese nuisances, which one can barely notice, are powerful enough to fool\nsophisticated and well performing classifiers, leading to ridiculous\nmisclassification results. In this paper we analyze the stability of\nstate-of-the-art deep-learning classification machines to adversarial\nperturbations, where we assume that the signals belong to the (possibly\nmulti-layer) sparse representation model. We start with convolutional sparsity\nand then proceed to its multi-layered version, which is tightly connected to\nCNNs. Our analysis links between the stability of the classification to noise\nand the underlying structure of the signal, quantified by the sparsity of its\nrepresentation under a fixed dictionary. In addition, we offer similar\nstability theorems for two practical pursuit algorithms, which are posed as two\ndifferent deep-learning architectures - the layered Thresholding and the\nlayered Basis Pursuit. Our analysis establishes the better robustness of the\nlater to adversarial attacks. We corroborate these theoretical results by\nnumerical experiments on three datasets: MNIST, CIFAR-10 and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:25:11 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 06:01:52 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 20:40:54 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Romano", "Yaniv", ""], ["Aberdam", "Aviad", ""], ["Sulam", "Jeremias", ""], ["Elad", "Michael", ""]]}, {"id": "1805.11597", "submitter": "Hao-Tien Lewis Chiang", "authors": "Hao-Tien Lewis Chiang, Aleksandra Faust, Lydia Tapia", "title": "Deep Neural Networks for Swept Volume Prediction Between Configurations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swept Volume (SV), the volume displaced by an object when it is moving along\na trajectory, is considered a useful metric for motion planning. First, SV has\nbeen used to identify collisions along a trajectory, because it directly\nmeasures the amount of space required for an object to move. Second, in\nsampling-based motion planning, SV is an ideal distance metric, because it\ncorrelates to the likelihood of success of the expensive local planning step\nbetween two sampled configurations. However, in both of these applications,\ntraditional SV algorithms are too computationally expensive for efficient\nmotion planning. In this work, we train Deep Neural Networks (DNNs) to learn\nthe size of SV for specific robot geometries. Results for two robots, a 6\ndegree of freedom (DOF) rigid body and a 7 DOF fixed-based manipulator,\nindicate that the network estimations are very close to the true size of SV and\nis more than 1500 times faster than a state of the art SV estimation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:29:35 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Chiang", "Hao-Tien Lewis", ""], ["Faust", "Aleksandra", ""], ["Tapia", "Lydia", ""]]}, {"id": "1805.11604", "submitter": "Dimitris Tsipras", "authors": "Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, Aleksander Madry", "title": "How Does Batch Normalization Help Optimization?", "comments": "In NeurIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BatchNorm) is a widely adopted technique that enables\nfaster and more stable training of deep neural networks (DNNs). Despite its\npervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly\nunderstood. The popular belief is that this effectiveness stems from\ncontrolling the change of the layers' input distributions during training to\nreduce the so-called \"internal covariate shift\". In this work, we demonstrate\nthat such distributional stability of layer inputs has little to do with the\nsuccess of BatchNorm. Instead, we uncover a more fundamental impact of\nBatchNorm on the training process: it makes the optimization landscape\nsignificantly smoother. This smoothness induces a more predictive and stable\nbehavior of the gradients, allowing for faster training.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:42:00 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 16:07:57 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 03:07:13 GMT"}, {"version": "v4", "created": "Wed, 6 Mar 2019 15:59:21 GMT"}, {"version": "v5", "created": "Mon, 15 Apr 2019 02:34:55 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Ilyas", "Andrew", ""], ["Madry", "Aleksander", ""]]}, {"id": "1805.11614", "submitter": "John Lambert", "authors": "John Lambert, Ozan Sener, Silvio Savarese", "title": "Deep Learning under Privileged Information Using Heteroscedastic Dropout", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike machines, humans learn through rapid, abstract model-building. The\nrole of a teacher is not simply to hammer home right or wrong answers, but\nrather to provide intuitive comments, comparisons, and explanations to a pupil.\nThis is what the Learning Under Privileged Information (LUPI) paradigm\nendeavors to model by utilizing extra knowledge only available during training.\nWe propose a new LUPI algorithm specifically designed for Convolutional Neural\nNetworks (CNNs) and Recurrent Neural Networks (RNNs). We propose to use a\nheteroscedastic dropout (i.e. dropout with a varying variance) and make the\nvariance of the dropout a function of privileged information. Intuitively, this\ncorresponds to using the privileged information to control the uncertainty of\nthe model output. We perform experiments using CNNs and RNNs for the tasks of\nimage classification and machine translation. Our method significantly\nincreases the sample efficiency during learning, resulting in higher accuracy\nwith a large margin when the number of training examples is limited. We also\ntheoretically justify the gains in sample efficiency by providing a\ngeneralization error bound decreasing with $O(\\frac{1}{n})$, where $n$ is the\nnumber of training examples, in an oracle case.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:58:12 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Lambert", "John", ""], ["Sener", "Ozan", ""], ["Savarese", "Silvio", ""]]}, {"id": "1805.11640", "submitter": "Jihun Hamm", "authors": "Jihun Hamm, Yung-Kyun Noh", "title": "K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning", "comments": "Accepted for ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax optimization plays a key role in adversarial training of machine\nlearning algorithms, such as learning generative models, domain adaptation,\nprivacy preservation, and robust learning. In this paper, we demonstrate the\nfailure of alternating gradient descent in minimax optimization problems due to\nthe discontinuity of solutions of the inner maximization. To address this, we\npropose a new epsilon-subgradient descent algorithm that addresses this problem\nby simultaneously tracking K candidate solutions. Practically, the algorithm\ncan find solutions that previous saddle-point algorithms cannot find, with only\na sublinear increase of complexity in K. We analyze the conditions under which\nthe algorithm converges to the true solution in detail. A significant\nimprovement in stability and convergence speed of the algorithm is observed in\nsimple representative problems, GAN training, and domain-adaptation problems.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 18:30:12 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 03:25:18 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Hamm", "Jihun", ""], ["Noh", "Yung-Kyun", ""]]}, {"id": "1805.11643", "submitter": "Liu Liu", "authors": "Liu Liu, Yanyao Shen, Tianyang Li, Constantine Caramanis", "title": "High Dimensional Robust Sparse Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel -- and to the best of our knowledge, the first --\nalgorithm for high dimensional sparse regression with constant fraction of\ncorruptions in explanatory and/or response variables. Our algorithm recovers\nthe true sparse parameters with sub-linear sample complexity, in the presence\nof a constant fraction of arbitrary corruptions. Our main contribution is a\nrobust variant of Iterative Hard Thresholding. Using this, we provide accurate\nestimators: when the covariance matrix in sparse regression is identity, our\nerror guarantee is near information-theoretically optimal. We then deal with\nrobust sparse regression with unknown structured covariance matrix. We propose\na filtering algorithm which consists of a novel randomized outlier removal\ntechnique for robust sparse mean estimation that may be of interest in its own\nright: the filtering algorithm is flexible enough to deal with unknown\ncovariance. Also, it is orderwise more efficient computationally than the\nellipsoid algorithm. Using sub-linear sample complexity, our algorithm achieves\nthe best known (and first) error guarantee. We demonstrate the effectiveness on\nlarge-scale sparse regression problems with arbitrary corruptions.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 18:33:23 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 06:04:34 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 19:34:15 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Liu", "Liu", ""], ["Shen", "Yanyao", ""], ["Li", "Tianyang", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1805.11659", "submitter": "Changyou Chen", "authors": "Changyou Chen, Ruiyi Zhang, Wenlin Wang, Bai Li and Liqun Chen", "title": "A Unified Particle-Optimization Framework for Scalable Bayesian Sampling", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recent interest in developing scalable Bayesian sampling\nmethods such as stochastic gradient MCMC (SG-MCMC) and Stein variational\ngradient descent (SVGD) for big-data analysis. A standard SG-MCMC algorithm\nsimulates samples from a discrete-time Markov chain to approximate a target\ndistribution, thus samples could be highly correlated, an undesired property\nfor SG-MCMC. In contrary, SVGD directly optimizes a set of particles to\napproximate a target distribution, and thus is able to obtain good\napproximations with relatively much fewer samples. In this paper, we propose a\nprinciple particle-optimization framework based on Wasserstein gradient flows\nto unify SG-MCMC and SVGD, and to allow new algorithms to be developed. Our\nframework interprets SG-MCMC as particle optimization on the space of\nprobability measures, revealing a strong connection between SG-MCMC and SVGD.\nThe key component of our framework is several particle-approximate techniques\nto efficiently solve the original partial differential equations on the space\nof probability measures. Extensive experiments on both synthetic data and deep\nneural networks demonstrate the effectiveness and efficiency of our framework\nfor scalable Bayesian sampling.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 18:58:20 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 06:09:04 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Chen", "Changyou", ""], ["Zhang", "Ruiyi", ""], ["Wang", "Wenlin", ""], ["Li", "Bai", ""], ["Chen", "Liqun", ""]]}, {"id": "1805.11686", "submitter": "Avi Singh", "authors": "Justin Fu, Avi Singh, Dibya Ghosh, Larry Yang, Sergey Levine", "title": "Variational Inverse Control with Events: A General Framework for\n  Data-Driven Reward Definition", "comments": "First two authors contributed equally. Accepted to NIPS. Website:\n  https://sites.google.com/view/inverse-event", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of a reward function often poses a major practical challenge to\nreal-world applications of reinforcement learning. Approaches such as inverse\nreinforcement learning attempt to overcome this challenge, but require expert\ndemonstrations, which can be difficult or expensive to obtain in practice. We\npropose variational inverse control with events (VICE), which generalizes\ninverse reinforcement learning methods to cases where full demonstrations are\nnot needed, such as when only samples of desired goal states are available. Our\nmethod is grounded in an alternative perspective on control and reinforcement\nlearning, where an agent's goal is to maximize the probability that one or more\nevents will happen at some point in the future, rather than maximizing\ncumulative rewards. We demonstrate the effectiveness of our methods on\ncontinuous control tasks, with a focus on high-dimensional observations like\nimages where rewards are hard or even impossible to specify.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 19:55:10 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 21:08:38 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 20:35:41 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Fu", "Justin", ""], ["Singh", "Avi", ""], ["Ghosh", "Dibya", ""], ["Yang", "Larry", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.11703", "submitter": "Alexander Ororbia", "authors": "Alexander G. Ororbia, Ankur Mali", "title": "Biologically Motivated Algorithms for Propagating Local Target\n  Representations", "comments": "Final version for AAAI (accepted paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding biologically plausible alternatives to back-propagation of errors is\na fundamentally important challenge in artificial neural network research. In\nthis paper, we propose a learning algorithm called error-driven Local\nRepresentation Alignment (LRA-E), which has strong connections to predictive\ncoding, a theory that offers a mechanistic way of describing neurocomputational\nmachinery. In addition, we propose an improved variant of Difference Target\nPropagation, another procedure that comes from the same family of algorithms as\nLRA-E. We compare our procedures to several other biologically-motivated\nalgorithms, including two feedback alignment algorithms and Equilibrium\nPropagation. In two benchmarks, we find that both of our proposed algorithms\nyield stable performance and strong generalization compared to other competing\nback-propagation alternatives when training deeper, highly nonlinear networks,\nwith LRA-E performing the best overall.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 15:11:16 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 18:52:00 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 22:21:04 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ororbia", "Alexander G.", ""], ["Mali", "Ankur", ""]]}, {"id": "1805.11706", "submitter": "Quan Vuong", "authors": "Quan Vuong, Yiming Zhang, Keith W. Ross", "title": "Supervised Policy Update for Deep Reinforcement Learning", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new sample-efficient methodology, called Supervised Policy\nUpdate (SPU), for deep reinforcement learning. Starting with data generated by\nthe current policy, SPU formulates and solves a constrained optimization\nproblem in the non-parameterized proximal policy space. Using supervised\nregression, it then converts the optimal non-parameterized policy to a\nparameterized policy, from which it draws new samples. The methodology is\ngeneral in that it applies to both discrete and continuous action spaces, and\ncan handle a wide variety of proximity constraints for the non-parameterized\noptimization problem. We show how the Natural Policy Gradient and Trust Region\nPolicy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization\n(PPO) problem can be addressed by this methodology. The SPU implementation is\nmuch simpler than TRPO. In terms of sample efficiency, our extensive\nexperiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and\noutperforms PPO in Atari video game tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 20:57:19 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 16:58:54 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 03:20:00 GMT"}, {"version": "v4", "created": "Mon, 24 Dec 2018 01:42:07 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Vuong", "Quan", ""], ["Zhang", "Yiming", ""], ["Ross", "Keith W.", ""]]}, {"id": "1805.11710", "submitter": "Yuheng Bu", "authors": "Yuheng Bu, Jiaxun Lu, Venugopal V. Veeravalli", "title": "Active and Adaptive Sequential learning", "comments": "8-page version submit to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is introduced for actively and adaptively solving a sequence of\nmachine learning problems, which are changing in bounded manner from one time\nstep to the next. An algorithm is developed that actively queries the labels of\nthe most informative samples from an unlabeled data pool, and that adapts to\nthe change by utilizing the information acquired in the previous steps. Our\nanalysis shows that the proposed active learning algorithm based on stochastic\ngradient descent achieves a near-optimal excess risk performance for maximum\nlikelihood estimation. Furthermore, an estimator of the change in the learning\nproblems using the active learning samples is constructed, which provides an\nadaptive sample size selection rule that guarantees the excess risk is bounded\nfor sufficiently large number of time steps. Experiments with synthetic and\nreal data are presented to validate our algorithm and theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 21:15:42 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Bu", "Yuheng", ""], ["Lu", "Jiaxun", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1805.11711", "submitter": "Katja Hofmann", "authors": "Justas Dauparas, Ryota Tomioka, and Katja Hofmann", "title": "Depth and nonlinearity induce implicit exploration for RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how to explore, i.e., take actions with uncertain outcomes to\nlearn about possible future rewards, is a key question in reinforcement\nlearning (RL). Here, we show a surprising result: We show that Q-learning with\nnonlinear Q-function and no explicit exploration (i.e., a purely greedy policy)\ncan learn several standard benchmark tasks, including mountain car, equally\nwell as, or better than, the most commonly-used $\\epsilon$-greedy exploration.\nWe carefully examine this result and show that both the depth of the Q-network\nand the type of nonlinearity are important to induce such deterministic\nexploration.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 21:21:18 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Dauparas", "Justas", ""], ["Tomioka", "Ryota", ""], ["Hofmann", "Katja", ""]]}, {"id": "1805.11712", "submitter": "Elaheh Rashedi", "authors": "Elaheh Rashedi, Abdolreza Mirzaei", "title": "A Novel Multi-clustering Method for Hierarchical Clusterings, Based on\n  Boosting", "comments": "19th Iranian Conference on Electrical Engineering (ICEE 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bagging and boosting are proved to be the best methods of building multiple\nclassifiers in classification combination problems. In the area of \"flat\nclustering\" problems, it is also recognized that multi-clustering methods based\non boosting provide clusterings of an improved quality. In this paper, we\nintroduce a novel multi-clustering method for \"hierarchical clusterings\" based\non boosting theory, which creates a more stable hierarchical clustering of a\ndataset. The proposed algorithm includes a boosting iteration in which a\nbootstrap of samples is created by weighted random sampling of elements from\nthe original dataset. A hierarchical clustering algorithm is then applied to\nselected subsample to build a dendrogram which describes the hierarchy.\nFinally, dissimilarity description matrices of multiple dendrogram results are\ncombined to a consensus one, using a hierarchical-clustering-combination\napproach. Experiments on real popular datasets show that boosted method\nprovides superior quality solutions compared to standard hierarchical\nclustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 21:22:53 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Rashedi", "Elaheh", ""], ["Mirzaei", "Abdolreza", ""]]}, {"id": "1805.11718", "submitter": "Sidharth Gupta", "authors": "Sidharth Gupta, Konik Kothari, Maarten V. de Hoop and Ivan Dokmani\\'c", "title": "Random mesh projectors for inverse problems", "comments": "S. Gupta and K. Kothari contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new learning-based approach to solve ill-posed inverse problems\nin imaging. We address the case where ground truth training samples are rare\nand the problem is severely ill-posed - both because of the underlying physics\nand because we can only get few measurements. This setting is common in\ngeophysical imaging and remote sensing. We show that in this case the common\napproach to directly learn the mapping from the measured data to the\nreconstruction becomes unstable. Instead, we propose to first learn an ensemble\nof simpler mappings from the data to projections of the unknown image into\nrandom piecewise-constant subspaces. We then combine the projections to form a\nfinal reconstruction by solving a deconvolution-like problem. We show\nexperimentally that the proposed method is more robust to measurement noise and\ncorruptions not seen during training than a directly learned inverse.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 21:36:05 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 15:52:04 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 04:31:08 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Gupta", "Sidharth", ""], ["Kothari", "Konik", ""], ["de Hoop", "Maarten V.", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "1805.11730", "submitter": "Kuan Liu", "authors": "Kuan Liu, Yanen Li, Ning Xu, Prem Natarajan", "title": "Learn to Combine Modalities in Multimodal Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining complementary information from multiple modalities is intuitively\nappealing for improving the performance of learning-based approaches. However,\nit is challenging to fully leverage different modalities due to practical\nchallenges such as varying levels of noise and conflicts between modalities.\nExisting methods do not adopt a joint approach to capturing synergies between\nthe modalities while simultaneously filtering noise and resolving conflicts on\na per sample basis. In this work we propose a novel deep neural network based\ntechnique that multiplicatively combines information from different source\nmodalities. Thus the model training process automatically focuses on\ninformation from more reliable modalities while reducing emphasis on the less\nreliable modalities. Furthermore, we propose an extension that multiplicatively\ncombines not only the single-source modalities, but a set of mixtured source\nmodalities to better capture cross-modal signal correlations. We demonstrate\nthe effectiveness of our proposed technique by presenting empirical results on\nthree multimodal classification tasks from different domains. The results show\nconsistent accuracy improvements on all three tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 22:24:48 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Liu", "Kuan", ""], ["Li", "Yanen", ""], ["Xu", "Ning", ""], ["Natarajan", "Prem", ""]]}, {"id": "1805.11752", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Alan Salimov, Anish Khazane, Erik T. Mueller", "title": "Multi-turn Dialogue Response Generation in an Adversarial Learning\n  Framework", "comments": "Accepted at ACL 2019 Workshop on NLP for Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose an adversarial learning approach for generating multi-turn\ndialogue responses. Our proposed framework, hredGAN, is based on conditional\ngenerative adversarial networks (GANs). The GAN's generator is a modified\nhierarchical recurrent encoder-decoder network (HRED) and the discriminator is\na word-level bidirectional RNN that shares context and word embeddings with the\ngenerator. During inference, noise samples conditioned on the dialogue history\nare used to perturb the generator's latent space to generate several possible\nresponses. The final response is the one ranked best by the discriminator. The\nhredGAN shows improved performance over existing methods: (1) it generalizes\nbetter than networks trained using only the log-likelihood criterion, and (2)\nit generates longer, more informative and more diverse responses with high\nutterance and topic relevance even with limited training data. This improvement\nis demonstrated on the Movie triples and Ubuntu dialogue datasets using both\nautomatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:05:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 20:49:03 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:35:08 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:26:28 GMT"}, {"version": "v5", "created": "Wed, 26 Jun 2019 14:39:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Salimov", "Alan", ""], ["Khazane", "Anish", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1805.11754", "submitter": "Sven Schmit", "authors": "Sven Schmit, Virag Shah, Ramesh Johari", "title": "Optimal Testing in the Experiment-rich Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the widespread adoption of large-scale A/B testing in industry,\nwe propose a new experimentation framework for the setting where potential\nexperiments are abundant (i.e., many hypotheses are available to test), and\nobservations are costly; we refer to this as the experiment-rich regime. Such\nscenarios require the experimenter to internalize the opportunity cost of\nassigning a sample to a particular experiment. We fully characterize the\noptimal policy and give an algorithm to compute it. Furthermore, we develop a\nsimple heuristic that also provides intuition for the optimal policy. We use\nsimulations based on real data to compare both the optimal algorithm and the\nheuristic to other natural alternative experimental design frameworks. In\nparticular, we discuss the paradox of power: high-powered classical tests can\nlead to highly inefficient sampling in the experiment-rich regime.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:20:31 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Schmit", "Sven", ""], ["Shah", "Virag", ""], ["Johari", "Ramesh", ""]]}, {"id": "1805.11761", "submitter": "Guocong Song", "authors": "Guocong Song, Wei Chai", "title": "Collaborative Learning for Deep Neural Networks", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce collaborative learning in which multiple classifier heads of the\nsame network are simultaneously trained on the same training data to improve\ngeneralization and robustness to label noise with no extra inference cost. It\nacquires the strengths from auxiliary training, multi-task learning and\nknowledge distillation. There are two important mechanisms involved in\ncollaborative learning. First, the consensus of multiple views from different\nclassifier heads on the same example provides supplementary information as well\nas regularization to each classifier, thereby improving generalization. Second,\nintermediate-level representation (ILR) sharing with backpropagation rescaling\naggregates the gradient flows from all heads, which not only reduces training\ncomputational complexity, but also facilitates supervision to the shared\nlayers. The empirical results on CIFAR and ImageNet datasets demonstrate that\ndeep neural networks learned as a group in a collaborative way significantly\nreduce the generalization error and increase the robustness to label noise.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:46:33 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 00:06:03 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Song", "Guocong", ""], ["Chai", "Wei", ""]]}, {"id": "1805.11769", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen, Lingfei Wu, Sijia Liu, Indika Rajapakse", "title": "Fast Incremental von Neumann Graph Entropy Computation: Theory,\n  Algorithm, and Applications", "comments": "Published at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The von Neumann graph entropy (VNGE) facilitates measurement of information\ndivergence and distance between graphs in a graph sequence. It has been\nsuccessfully applied to various learning tasks driven by network-based data.\nWhile effective, VNGE is computationally demanding as it requires the full\neigenspectrum of the graph Laplacian matrix. In this paper, we propose a new\ncomputational framework, Fast Incremental von Neumann Graph EntRopy (FINGER),\nwhich approaches VNGE with a performance guarantee. FINGER reduces the cubic\ncomplexity of VNGE to linear complexity in the number of nodes and edges, and\nthus enables online computation based on incremental graph changes. We also\nshow asymptotic equivalence of FINGER to the exact VNGE, and derive its\napproximation error bounds. Based on FINGER, we propose efficient algorithms\nfor computing Jensen-Shannon distance between graphs. Our experimental results\non different random graph models demonstrate the computational efficiency and\nthe asymptotic equivalence of FINGER. In addition, we apply FINGER to two\nreal-world applications and one synthesized anomaly detection dataset, and\ncorroborate its superior performance over seven baseline graph similarity\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 01:37:01 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 21:03:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Wu", "Lingfei", ""], ["Liu", "Sijia", ""], ["Rajapakse", "Indika", ""]]}, {"id": "1805.11783", "submitter": "Heinrich Jiang", "authors": "Heinrich Jiang, Been Kim, Melody Y. Guan, Maya Gupta", "title": "To Trust Or Not To Trust A Classifier", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing when a classifier's prediction can be trusted is useful in many\napplications and critical for safely using AI. While the bulk of the effort in\nmachine learning research has been towards improving classifier performance,\nunderstanding when a classifier's predictions should and should not be trusted\nhas received far less attention. The standard approach is to use the\nclassifier's discriminant or confidence score; however, we show there exists an\nalternative that is more effective in many situations. We propose a new score,\ncalled the trust score, which measures the agreement between the classifier and\na modified nearest-neighbor classifier on the testing example. We show\nempirically that high (low) trust scores produce surprisingly high precision at\nidentifying correctly (incorrectly) classified examples, consistently\noutperforming the classifier's confidence score as well as many other\nbaselines. Further, under some mild distributional assumptions, we show that if\nthe trust score for an example is high (low), the classifier will likely agree\n(disagree) with the Bayes-optimal classifier. Our guarantees consist of\nnon-asymptotic rates of statistical consistency under various nonparametric\nsettings and build on recent developments in topological data analysis.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 02:48:58 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 20:32:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jiang", "Heinrich", ""], ["Kim", "Been", ""], ["Guan", "Melody Y.", ""], ["Gupta", "Maya", ""]]}, {"id": "1805.11792", "submitter": "Jonathan Scarlett", "authors": "Jonathan Scarlett", "title": "Tight Regret Bounds for Bayesian Optimization in One Dimension", "comments": "ICML 2018 + supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Bayesian optimization (BO) in one dimension, under\na Gaussian process prior and Gaussian sampling noise. We provide a theoretical\nanalysis showing that, under fairly mild technical assumptions on the kernel,\nthe best possible cumulative regret up to time $T$ behaves as\n$\\Omega(\\sqrt{T})$ and $O(\\sqrt{T\\log T})$. This gives a tight characterization\nup to a $\\sqrt{\\log T}$ factor, and includes the first non-trivial lower bound\nfor noisy BO. Our assumptions are satisfied, for example, by the squared\nexponential and Mat\\'ern-$\\nu$ kernels, with the latter requiring $\\nu > 2$.\nOur results certify the near-optimality of existing bounds (Srinivas {\\em et\nal.}, 2009) for the SE kernel, while proving them to be strictly suboptimal for\nthe Mat\\'ern kernel with $\\nu > 2$.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 03:33:37 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 08:38:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Scarlett", "Jonathan", ""]]}, {"id": "1805.11793", "submitter": "Shouri Hu", "authors": "Hock Peng Chan and Shouri Hu", "title": "Infinite Arms Bandit: Optimality via Confidence Bounds", "comments": "Fourth version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Berry et al. (1997) initiated the development of the infinite arms bandit\nproblem. They derived a regret lower bound of all allocation strategies for\nBernoulli rewards with uniform priors, and proposed strategies based on success\nruns. Bonald and Prouti\\`{e}re (2013) proposed a two-target algorithm that\nachieves the regret lower bound, and extended optimality to Bernoulli rewards\nwith general priors. We present here a confidence bound target (CBT) algorithm\nthat achieves optimality for rewards that are bounded above. For each arm we\nconstruct a confidence bound and compare it against each other and a target\nvalue to determine if the arm should be sampled further. The target value\ndepends on the assumed priors of the arm means. In the absence of information\non the prior, the target value is determined empirically. Numerical studies\nhere show that CBT is versatile and outperforms its competitors.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 03:45:17 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 08:25:03 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 03:43:47 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 03:14:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chan", "Hock Peng", ""], ["Hu", "Shouri", ""]]}, {"id": "1805.11797", "submitter": "Xiaoliang Dai", "authors": "Xiaoliang Dai, Hongxu Yin, Niraj K. Jha", "title": "Grow and Prune Compact, Fast, and Accurate LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory (LSTM) has been widely used for sequential data\nmodeling. Researchers have increased LSTM depth by stacking LSTM cells to\nimprove performance. This incurs model redundancy, increases run-time delay,\nand makes the LSTMs more prone to overfitting. To address these problems, we\npropose a hidden-layer LSTM (H-LSTM) that adds hidden layers to LSTM's original\none level non-linear control gates. H-LSTM increases accuracy while employing\nfewer external stacked layers, thus reducing the number of parameters and\nrun-time latency significantly. We employ grow-and-prune (GP) training to\niteratively adjust the hidden layers through gradient-based growth and\nmagnitude-based pruning of connections. This learns both the weights and the\ncompact architecture of H-LSTM control gates. We have GP-trained H-LSTMs for\nimage captioning and speech recognition applications. For the NeuralTalk\narchitecture on the MSCOCO dataset, our three models reduce the number of\nparameters by 38.7x [floating-point operations (FLOPs) by 45.5x], run-time\nlatency by 4.5x, and improve the CIDEr score by 2.6. For the DeepSpeech2\narchitecture on the AN4 dataset, our two models reduce the number of parameters\nby 19.4x (FLOPs by 23.5x), run-time latency by 15.7%, and the word error rate\nfrom 12.9% to 8.7%. Thus, GP-trained H-LSTMs can be seen to be compact, fast,\nand accurate.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 04:15:58 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 03:49:25 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Dai", "Xiaoliang", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1805.11799", "submitter": "Taro Sekiyama", "authors": "Taro Sekiyama and Kohei Suenaga", "title": "Automated proof synthesis for propositional logic with deep neural\n  networks", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the application of deep learning, a machine learning\ntechnique that uses deep neural networks (DNN) in its core, to an automated\ntheorem proving (ATP) problem. To this end, we construct a statistical model\nwhich quantifies the likelihood that a proof is indeed a correct one of a given\nproposition. Based on this model, we give a proof-synthesis procedure that\nsearches for a proof in the order of the likelihood. This procedure uses an\nestimator of the likelihood of an inference rule being applied at each step of\na proof. As an implementation of the estimator, we propose a\nproposition-to-proof architecture, which is a DNN tailored to the automated\nproof synthesis problem. To empirically demonstrate its usefulness, we apply\nour model to synthesize proofs of propositional logic. We train the\nproposition-to-proof model using a training dataset of proposition-proof pairs.\nThe evaluation against a benchmark set shows the very high accuracy and an\nimprovement to the recent work of neural proof synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 04:22:51 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sekiyama", "Taro", ""], ["Suenaga", "Kohei", ""]]}, {"id": "1805.11811", "submitter": "Liu Liu", "authors": "Liu Liu, Minhao Cheng, Cho-Jui Hsieh, Dacheng Tao", "title": "Stochastic Zeroth-order Optimization via Variance Reduction method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Derivative-free optimization has become an important technique used in\nmachine learning for optimizing black-box models. To conduct updates without\nexplicitly computing gradient, most current approaches iteratively sample a\nrandom search direction from Gaussian distribution and compute the estimated\ngradient along that direction. However, due to the variance in the search\ndirection, the convergence rates and query complexities of existing methods\nsuffer from a factor of $d$, where $d$ is the problem dimension. In this paper,\nwe introduce a novel Stochastic Zeroth-order method with Variance Reduction\nunder Gaussian smoothing (SZVR-G) and establish the complexity for optimizing\nnon-convex problems. With variance reduction on both sample space and search\nspace, the complexity of our algorithm is sublinear to $d$ and is strictly\nbetter than current approaches, in both smooth and non-smooth cases. Moreover,\nwe extend the proposed method to the mini-batch version. Our experimental\nresults demonstrate the superior performance of the proposed method over\nexisting derivative-free optimization techniques. Furthermore, we successfully\napply our method to conduct a universal black-box attack to deep neural\nnetworks and present some interesting results.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 05:23:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 00:26:05 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 11:51:44 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Liu", "Liu", ""], ["Cheng", "Minhao", ""], ["Hsieh", "Cho-Jui", ""], ["Tao", "Dacheng", ""]]}, {"id": "1805.11837", "submitter": "Vadim Ratner", "authors": "Vadim Ratner, Yoel Shoshan, Tal Kachman", "title": "Learning multiple non-mutually-exclusive tasks for improved\n  classification of inherently ordered labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medical image classification involves thresholding of labels that represent\nmalignancy risk levels. Usually, a task defines a single threshold, and when\ndeveloping computer-aided diagnosis tools, a single network is trained per such\nthreshold, e.g. as screening out healthy (very low risk) patients to leave\npossibly sick ones for further analysis (low threshold), or trying to find\nmalignant cases among those marked as non-risk by the radiologist (\"second\nreading\", high threshold). We propose a way to rephrase the classification\nproblem in a manner that yields several problems (corresponding to different\nthresholds) to be solved simultaneously. This allows the use of Multiple Task\nLearning (MTL) methods, significantly improving the performance of the original\nclassifier, by facilitating effective extraction of information from existing\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 07:25:54 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 07:06:08 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Ratner", "Vadim", ""], ["Shoshan", "Yoel", ""], ["Kachman", "Tal", ""]]}, {"id": "1805.11845", "submitter": "Shi Dong", "authors": "Shi Dong, Benjamin Van Roy", "title": "An Information-Theoretic Analysis for Thompson Sampling with Many\n  Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic Bayesian regret bounds of Russo and Van Roy capture the\ndependence of regret on prior uncertainty. However, this dependence is through\nentropy, which can become arbitrarily large as the number of actions increases.\nWe establish new bounds that depend instead on a notion of rate-distortion.\nAmong other things, this allows us to recover through information-theoretic\narguments a near-optimal bound for the linear bandit. We also offer a bound for\nthe logistic bandit that dramatically improves on the best previously\navailable, though this bound depends on an information-theoretic statistic that\nwe have only been able to quantify via computation.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 07:56:40 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 03:15:46 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 17:09:47 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 02:16:21 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Dong", "Shi", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1805.11852", "submitter": "Nilaksh Das", "authors": "Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Li Chen, Michael E.\n  Kounavis, Duen Horng Chau", "title": "ADAGIO: Interactive Experimentation with Adversarial Attack and Defense\n  for Audio", "comments": "Demo paper; for supplementary video, see https://youtu.be/0W2BKMwSfVQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning research has recently demonstrated the\nfeasibility to confuse automatic speech recognition (ASR) models by introducing\nacoustically imperceptible perturbations to audio samples. To help researchers\nand practitioners gain better understanding of the impact of such attacks, and\nto provide them with tools to help them more easily evaluate and craft strong\ndefenses for their models, we present ADAGIO, the first tool designed to allow\ninteractive experimentation with adversarial attacks and defenses on an ASR\nmodel in real time, both visually and aurally. ADAGIO incorporates AMR and MP3\naudio compression techniques as defenses, which users can interactively apply\nto attacked audio samples. We show that these techniques, which are based on\npsychoacoustic principles, effectively eliminate targeted attacks, reducing the\nattack success rate from 92.5% to 0%. We will demonstrate ADAGIO and invite the\naudience to try it on the Mozilla Common Voice dataset.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 08:24:52 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Das", "Nilaksh", ""], ["Shanbhogue", "Madhuri", ""], ["Chen", "Shang-Tse", ""], ["Chen", "Li", ""], ["Kounavis", "Michael E.", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1805.11861", "submitter": "Anil Sharma", "authors": "Anil Sharma and Prabhat Kumar", "title": "Foresee: Attentive Future Projections of Chaotic Road Environments with\n  Online Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we train a recurrent neural network to learn dynamics of a\nchaotic road environment and to project the future of the environment on an\nimage. Future projection can be used to anticipate an unseen environment for\nexample, in autonomous driving. Road environment is highly dynamic and complex\ndue to the interaction among traffic participants such as vehicles and\npedestrians. Even in this complex environment, a human driver is efficacious to\nsafely drive on chaotic roads irrespective of the number of traffic\nparticipants. The proliferation of deep learning research has shown the\nefficacy of neural networks in learning this human behavior. In the same\ndirection, we investigate recurrent neural networks to understand the chaotic\nroad environment which is shared by pedestrians, vehicles (cars, trucks,\nbicycles etc.), and sometimes animals as well. We propose \\emph{Foresee}, a\nunidirectional gated recurrent units (GRUs) network with attention to project\nfuture of the environment in the form of images. We have collected several\nvideos on Delhi roads consisting of various traffic participants, background\nand infrastructure differences (like 3D pedestrian crossing) at various times\non various days. We train \\emph{Foresee} in an unsupervised way and we use\nonline training to project frames up to $0.5$ seconds in advance. We show that\nour proposed model performs better than state of the art methods (prednet and\nEnc. Dec. LSTM) and finally, we show that our trained model generalizes to a\npublic dataset for future projections.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 08:51:02 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sharma", "Anil", ""], ["Kumar", "Prabhat", ""]]}, {"id": "1805.11877", "submitter": "Carl Witt", "authors": "Carl Witt, Marc Bux, Wladislaw Gusew, Ulf Leser", "title": "Predictive Performance Modeling for Distributed Computing using\n  Black-Box Monitoring and Machine Learning", "comments": "19 pages, 3 figures, 5 tables", "journal-ref": "Information Systems 2019", "doi": "10.1016/j.is.2019.01.006", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, the previous decade was characterized by increasing data\nvolumes and growing complexity of computational workloads, creating new demands\nfor highly data-parallel computing in distributed systems. Effective operation\nof these systems is challenging when facing uncertainties about the performance\nof jobs and tasks under varying resource configurations, e.g., for scheduling\nand resource allocation. We survey predictive performance modeling (PPM)\napproaches to estimate performance metrics such as execution duration, required\nmemory or wait times of future jobs and tasks based on past performance\nobservations. We focus on non-intrusive methods, i.e., methods that can be\napplied to any workload without modification, since the workload is usually a\nblack-box from the perspective of the systems managing the computational\ninfrastructure. We classify and compare sources of performance variation,\npredicted performance metrics, required training data, use cases, and the\nunderlying prediction techniques. We conclude by identifying several open\nproblems and pressing research needs in the field.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 09:24:08 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Witt", "Carl", ""], ["Bux", "Marc", ""], ["Gusew", "Wladislaw", ""], ["Leser", "Ulf", ""]]}, {"id": "1805.11897", "submitter": "Giulia Luise", "authors": "Giulia Luise, Alessandro Rudi, Massimiliano Pontil, Carlo Ciliberto", "title": "Differential Properties of Sinkhorn Approximation for Learning with\n  Wasserstein Distance", "comments": "26 pages, 4 figures", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Dec\n  2018, Montr\\'eal, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of optimal transport have recently gained remarkable attention\nthanks to the computational advantages of entropic regularization. However, in\nmost situations the Sinkhorn approximation of the Wasserstein distance is\nreplaced by a regularized version that is less accurate but easy to\ndifferentiate. In this work we characterize the differential properties of the\noriginal Sinkhorn distance, proving that it enjoys the same smoothness as its\nregularized version and we explicitly provide an efficient algorithm to compute\nits gradient. We show that this result benefits both theory and applications:\non one hand, high order smoothness confers statistical guarantees to learning\nwith Wasserstein approximations. On the other hand, the gradient formula allows\nus to efficiently solve learning and optimization problems in practice.\nPromising preliminary experiments complement our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 11:09:16 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Luise", "Giulia", ""], ["Rudi", "Alessandro", ""], ["Pontil", "Massimiliano", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "1805.11913", "submitter": "Abdelrahman Eldesokey", "authors": "Abdelrahman Eldesokey, Michael Felsberg and Fahad Shahbaz Khan", "title": "Propagating Confidences through CNNs for Sparse Data Regression", "comments": "To appear in the British Machine Vision Conference (BMVC2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most computer vision applications, convolutional neural networks (CNNs)\noperate on dense image data generated by ordinary cameras. Designing CNNs for\nsparse and irregularly spaced input data is still an open problem with numerous\napplications in autonomous driving, robotics, and surveillance. To tackle this\nchallenging problem, we introduce an algebraically-constrained convolution\nlayer for CNNs with sparse input and demonstrate its capabilities for the scene\ndepth completion task. We propose novel strategies for determining the\nconfidence from the convolution operation and propagating it to consecutive\nlayers. Furthermore, we propose an objective function that simultaneously\nminimizes the data error while maximizing the output confidence. Comprehensive\nexperiments are performed on the KITTI depth benchmark and the results clearly\ndemonstrate that the proposed approach achieves superior performance while\nrequiring three times fewer parameters than the state-of-the-art methods.\nMoreover, our approach produces a continuous pixel-wise confidence map enabling\ninformation fusion, state inference, and decision support.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 12:09:51 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 13:53:05 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 09:05:49 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Eldesokey", "Abdelrahman", ""], ["Felsberg", "Michael", ""], ["Khan", "Fahad Shahbaz", ""]]}, {"id": "1805.11916", "submitter": "Zhenyu Liao", "authors": "Zhenyu Liao and Romain Couillet", "title": "On the Spectrum of Random Features Maps of High Dimensional Data", "comments": "13 pages (with Supplementary Material), 10 figure, ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018), in PMLR 80:3063-3071", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random feature maps are ubiquitous in modern statistical machine learning,\nwhere they generalize random projections by means of powerful, yet often\ndifficult to analyze nonlinear operators. In this paper, we leverage the\n\"concentration\" phenomenon induced by random matrix theory to perform a\nspectral analysis on the Gram matrix of these random feature maps, here for\nGaussian mixture models of simultaneously large dimension and size. Our results\nare instrumental to a deeper understanding on the interplay of the nonlinearity\nand the statistics of the data, thereby allowing for a better tuning of random\nfeature-based techniques.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 12:16:27 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 07:08:14 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""]]}, {"id": "1805.11917", "submitter": "Zhenyu Liao", "authors": "Zhenyu Liao and Romain Couillet", "title": "The Dynamics of Learning: A Random Matrix Approach", "comments": "14 pages (with Supplementary Material), 7 figures, ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018), in PMLR 80:3072-3081", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the learning dynamics of neural networks is one of the key\nissues for the improvement of optimization algorithms as well as for the\ntheoretical comprehension of why deep neural nets work so well today. In this\npaper, we introduce a random matrix-based framework to analyze the learning\ndynamics of a single-layer linear network on a binary classification problem,\nfor data of simultaneously large dimension and size, trained by gradient\ndescent. Our results provide rich insights into common questions in neural\nnets, such as overfitting, early stopping and the initialization of training,\nthereby opening the door for future studies of more elaborate structures and\nmodels appearing in today's neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 12:21:17 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 07:06:39 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""]]}, {"id": "1805.11921", "submitter": "Sergei Ivanov", "authors": "Sergey Ivanov, Evgeny Burnaev", "title": "Anonymous Walk Embeddings", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of representing entire graphs has seen a surge of prominent results,\nmainly due to learning convolutional neural networks (CNNs) on graph-structured\ndata. While CNNs demonstrate state-of-the-art performance in graph\nclassification task, such methods are supervised and therefore steer away from\nthe original problem of network representation in task-agnostic manner. Here,\nwe coherently propose an approach for embedding entire graphs and show that our\nfeature representations with SVM classifier increase classification accuracy of\nCNN algorithms and traditional graph kernels. For this we describe a recently\ndiscovered graph object, anonymous walk, on which we design task-independent\nalgorithms for learning graph representations in explicit and distributed way.\nOverall, our work represents a new scalable unsupervised learning of\nstate-of-the-art representations of entire graphs.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 12:43:47 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 15:14:49 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 09:31:56 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Ivanov", "Sergey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1805.11949", "submitter": "Wang Hao", "authors": "Hao Wang, Ruibin Feng, and Chi-Sing Leung", "title": "Fast L1-Minimization Algorithm for Sparse Approximation Based on an\n  Improved LPNN-LCA framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of sparse approximation is to estimate a sparse signal according to\nthe measurement matrix and an observation vector. It is widely used in data\nanalytics, image processing, and communication, etc. Up to now, a lot of\nresearch has been done in this area, and many off-the-shelf algorithms have\nbeen proposed. However, most of them cannot offer a real-time solution. To some\nextent, this shortcoming limits its application prospects. To address this\nissue, we devise a novel sparse approximation algorithm based on Lagrange\nprogramming neural network (LPNN), locally competitive algorithm (LCA), and\nprojection theorem. LPNN and LCA are both analog neural network which can help\nus get a real-time solution. The non-differentiable objective function can be\nsolved by the concept of LCA. Utilizing the projection theorem, we further\nmodify the dynamics and proposed a new system with global asymptotic stability.\nSimulation results show that the proposed sparse approximation method has the\nreal-time solutions with satisfactory MSEs.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:39:58 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Wang", "Hao", ""], ["Feng", "Ruibin", ""], ["Leung", "Chi-Sing", ""]]}, {"id": "1805.11954", "submitter": "Ren-Jie Han", "authors": "Yu-Long Zhou, Ren-Jie Han, Qian Xu, Wei-Ke Zhang", "title": "Long Short-Term Memory Networks for CSI300 Volatility Prediction with\n  Baidu Search Volume", "comments": "7 pages, 3 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:1512.04916 by other authors", "journal-ref": null, "doi": "10.1002/cpe.4721", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intense volatility in financial markets affect humans worldwide. Therefore,\nrelatively accurate prediction of volatility is critical. We suggest that\nmassive data sources resulting from human interaction with the Internet may\noffer a new perspective on the behavior of market participants in periods of\nlarge market movements. First we select 28 key words, which are related to\nfinance as indicators of the public mood and macroeconomic factors. Then those\n28 words of the daily search volume based on Baidu index are collected\nmanually, from June 1, 2006 to October 29, 2017. We apply a Long Short-Term\nMemory neural network to forecast CSI300 volatility using those search volume\ndata. Compared to the benchmark GARCH model, our forecast is more accurate,\nwhich demonstrates the effectiveness of the LSTM neural network in volatility\nforecasting.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 09:38:55 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Zhou", "Yu-Long", ""], ["Han", "Ren-Jie", ""], ["Xu", "Qian", ""], ["Zhang", "Wei-Ke", ""]]}, {"id": "1805.11956", "submitter": "Kunjin Chen", "authors": "Kunjin Chen, Kunlong Chen, Qin Wang, Ziyu He, Jun Hu, Jinliang He", "title": "Short-term Load Forecasting with Deep Residual Networks", "comments": "This paper is currently accepted by IEEE Transactions on Smart Grid", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a model for forecasting short-term power loads based\non deep residual networks. The proposed model is able to integrate domain\nknowledge and researchers' understanding of the task by virtue of different\nneural network building blocks. Specifically, a modified deep residual network\nis formulated to improve the forecast results. Further, a two-stage ensemble\nstrategy is used to enhance the generalization capability of the proposed\nmodel. We also apply the proposed model to probabilistic load forecasting using\nMonte Carlo dropout. Three public datasets are used to prove the effectiveness\nof the proposed model. Multiple test cases and comparison with existing models\nshow that the proposed model is able to provide accurate load forecasting\nresults and has high generalization capability.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:45:12 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Chen", "Kunjin", ""], ["Chen", "Kunlong", ""], ["Wang", "Qin", ""], ["He", "Ziyu", ""], ["Hu", "Jun", ""], ["He", "Jinliang", ""]]}, {"id": "1805.11959", "submitter": "Chuyu Xiong", "authors": "Chuyu Xiong", "title": "Algebraic Expression of Subjective Spatial and Temporal Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal learning machine is a theory trying to study machine learning from\nmathematical point of view. The outside world is reflected inside an universal\nlearning machine according to pattern of incoming data. This is subjective\npattern of learning machine. In [2,4], we discussed subjective spatial pattern,\nand established a powerful tool -- X-form, which is an algebraic expression for\nsubjective spatial pattern. However, as the initial stage of study, there we\nonly discussed spatial pattern. Here, we will discuss spatial and temporal\npatterns, and algebraic expression for them.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 20:54:13 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 03:03:40 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Xiong", "Chuyu", ""]]}, {"id": "1805.11970", "submitter": "Rodrigo Berriel", "authors": "Rodrigo F. Berriel, Franco Schmidt Rossi, Alberto F. de Souza, Thiago\n  Oliveira-Santos", "title": "Automatic Large-Scale Data Acquisition via Crowdsourcing for Crosswalk\n  Classification: A Deep Learning Approach", "comments": "13 pages, 13 figures, 3 videos, and GitHub with models", "journal-ref": "Computers & Graphics, 2017, vol. 68, pp. 32-42", "doi": "10.1016/J.CAG.2017.08.004", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly identifying crosswalks is an essential task for the driving\nactivity and mobility autonomy. Many crosswalk classification, detection and\nlocalization systems have been proposed in the literature over the years. These\nsystems use different perspectives to tackle the crosswalk classification\nproblem: satellite imagery, cockpit view (from the top of a car or behind the\nwindshield), and pedestrian perspective. Most of the works in the literature\nare designed and evaluated using small and local datasets, i.e. datasets that\npresent low diversity. Scaling to large datasets imposes a challenge for the\nannotation procedure. Moreover, there is still need for cross-database\nexperiments in the literature because it is usually hard to collect the data in\nthe same place and conditions of the final application. In this paper, we\npresent a crosswalk classification system based on deep learning. For that,\ncrowdsourcing platforms, such as OpenStreetMap and Google Street View, are\nexploited to enable automatic training via automatic acquisition and annotation\nof a large-scale database. Additionally, this work proposes a comparison study\nof models trained using fully-automatic data acquisition and annotation against\nmodels that were partially annotated. Cross-database experiments were also\nincluded in the experimentation to show that the proposed methods enable use\nwith real world applications. Our results show that the model trained on the\nfully-automatic database achieved high overall accuracy (94.12%), and that a\nstatistically significant improvement (to 96.30%) can be achieved by manually\nannotating a specific part of the database. Finally, the results of the\ncross-database experiments show that both models are robust to the many\nvariations of image and scenarios, presenting a consistent behavior.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:55:14 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Berriel", "Rodrigo F.", ""], ["Rossi", "Franco Schmidt", ""], ["de Souza", "Alberto F.", ""], ["Oliveira-Santos", "Thiago", ""]]}, {"id": "1805.11973", "submitter": "Nicola De Cao", "authors": "Nicola De Cao and Thomas Kipf", "title": "MolGAN: An implicit generative model for small molecular graphs", "comments": "11 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models for graph-structured data offer a new angle on the\nproblem of chemical synthesis: by optimizing differentiable models that\ndirectly generate molecular graphs, it is possible to side-step expensive\nsearch procedures in the discrete and vast space of chemical structures. We\nintroduce MolGAN, an implicit, likelihood-free generative model for small\nmolecular graphs that circumvents the need for expensive graph matching\nprocedures or node ordering heuristics of previous likelihood-based methods.\nOur method adapts generative adversarial networks (GANs) to operate directly on\ngraph-structured data. We combine our approach with a reinforcement learning\nobjective to encourage the generation of molecules with specific desired\nchemical properties. In experiments on the QM9 chemical database, we\ndemonstrate that our model is capable of generating close to 100% valid\ncompounds. MolGAN compares favorably both to recent proposals that use\nstring-based (SMILES) representations of molecules and to a likelihood-based\nmethod that directly generates graphs, albeit being susceptible to mode\ncollapse.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:56:06 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["De Cao", "Nicola", ""], ["Kipf", "Thomas", ""]]}, {"id": "1805.11987", "submitter": "Wang Hao", "authors": "Hao Wang, Chi-Sing Leung, Hing Cheung So, Ruibin Feng, and Zifa Han", "title": "l0-norm Based Centers Selection for Training Fault Tolerant RBF Networks\n  and Selecting Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to train an RBF neural network and select centers\nunder concurrent faults. It is well known that fault tolerance is a very\nattractive property for neural networks. And center selection is an important\nprocedure during the training process of an RBF neural network. In this paper,\nwe devise two novel algorithms to address these two issues simultaneously. Both\nof them are based on the ADMM framework. In the first method, the minimax\nconcave penalty (MCP) function is introduced to select centers. In the second\nmethod, an l0-norm term is directly used, and the hard threshold (HT) is\nutilized to address the l0-norm term. Under several mild conditions, we can\nprove that both methods can globally converge to a unique limit point.\nSimulation results show that, under concurrent fault, the proposed algorithms\nare superior to many existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 14:01:55 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 09:01:58 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 02:14:50 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Wang", "Hao", ""], ["Leung", "Chi-Sing", ""], ["So", "Hing Cheung", ""], ["Feng", "Ruibin", ""], ["Han", "Zifa", ""]]}, {"id": "1805.11999", "submitter": "Raj Thilak Rajan", "authors": "Raj Thilak Rajan, Rob-van Schaijk, Anup Das, Jac Romme and Frank\n  Pasveer", "title": "Reference-free Calibration in Sensor Networks", "comments": "Submitted to IEEE Sensor Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor calibration is one of the fundamental challenges in large-scale IoT\nnetworks. In this article, we address the challenge of reference-free\ncalibration of a densely deployed sensor network. Conventionally, to calibrate\nan in-place sensor network (or sensor array), a reference is arbitrarily chosen\nwith or without prior information on sensor performance. However, an arbitrary\nselection of a reference could prove fatal, if an erroneous sensor is\ninadvertently chosen. To avert single point of dependence, and to improve\nestimator performance, we propose unbiased reference-free algorithms. Although,\nour focus is on reference-free solutions, the proposed framework, allows the\nincorporation of additional references, if available. We show with the help of\nsimulations that the proposed solutions achieve the derived statistical lower\nbounds asymptotically. In addition, the proposed algorithms show improvements\non real-life datasets, as compared to prevalent algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 14:26:41 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Rajan", "Raj Thilak", ""], ["Schaijk", "Rob-van", ""], ["Das", "Anup", ""], ["Romme", "Jac", ""], ["Pasveer", "Frank", ""]]}, {"id": "1805.12002", "submitter": "Irene Y Chen", "authors": "Irene Chen, Fredrik D. Johansson, David Sontag", "title": "Why Is My Classifier Discriminatory?", "comments": "Appeared in Advances in Neural Information Processing Systems\n  (NeurIPS 2018); 3 figures, 8 pages, 6 page supplementary", "journal-ref": null, "doi": null, "report-no": "Advances in Neural Information Processing Systems 31, pages\n  3543--3554. Dec. 2018", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attempts to achieve fairness in predictive models focus on the balance\nbetween fairness and accuracy. In sensitive applications such as healthcare or\ncriminal justice, this trade-off is often undesirable as any increase in\nprediction error could have devastating consequences. In this work, we argue\nthat the fairness of predictions should be evaluated in context of the data,\nand that unfairness induced by inadequate samples sizes or unmeasured\npredictive variables should be addressed through data collection, rather than\nby constraining the model. We decompose cost-based metrics of discrimination\ninto bias, variance, and noise, and propose actions aimed at estimating and\nreducing each term. Finally, we perform case-studies on prediction of income,\nmortality, and review ratings, confirming the value of this analysis. We find\nthat data collection is often a means to reduce discrimination without\nsacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 14:29:34 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 20:45:48 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Chen", "Irene", ""], ["Johansson", "Fredrik D.", ""], ["Sontag", "David", ""]]}, {"id": "1805.12017", "submitter": "Vignesh Srinivasan", "authors": "Vignesh Srinivasan, Arturo Marban, Klaus-Robert M\\\"uller, Wojciech\n  Samek and Shinichi Nakajima", "title": "Robustifying Models Against Adversarial Attacks by Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks on deep learning models have compromised their\nperformance considerably. As remedies, a lot of defense methods were proposed,\nwhich however, have been circumvented by newer attacking strategies. In the\nmidst of this ensuing arms race, the problem of robustness against adversarial\nattacks still remains unsolved. This paper proposes a novel, simple yet\neffective defense strategy where adversarial samples are relaxed onto the\nunderlying manifold of the (unknown) target class distribution. Specifically,\nour algorithm drives off-manifold adversarial samples towards high density\nregions of the data generating distribution of the target class by the\nMetroplis-adjusted Langevin algorithm (MALA) with perceptual boundary taken\ninto account. Although the motivation is similar to projection methods, e.g.,\nDefense-GAN, our algorithm, called MALA for DEfense (MALADE), is equipped with\nsignificant dispersion - projection is distributed broadly, and therefore any\nwhitebox attack cannot accurately align the input so that the MALADE moves it\nto a targeted untrained spot where the model predicts a wrong label. In our\nexperiments, MALADE exhibited state-of-the-art performance against various\nelaborate attacking strategies.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:01:38 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 15:25:03 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Srinivasan", "Vignesh", ""], ["Marban", "Arturo", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""], ["Nakajima", "Shinichi", ""]]}, {"id": "1805.12021", "submitter": "Paul Temple", "authors": "Paul Temple, Mathieu Acher, Battista Biggio, Jean-Marc J\\'ez\\'equel,\n  Fabio Roli", "title": "Towards Adversarial Configurations for Software Product Lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring that all supposedly valid configurations of a software product line\n(SPL) lead to well-formed and acceptable products is challenging since it is\nmost of the time impractical to enumerate and test all individual products of\nan SPL. Machine learning classifiers have been recently used to predict the\nacceptability of products associated with unseen configurations. For some\nconfigurations, a tiny change in their feature values can make them pass from\nacceptable to non-acceptable regarding users' requirements and vice-versa. In\nthis paper, we introduce the idea of leveraging these specific configurations\nand their positions in the feature space to improve the classifier and\ntherefore the engineering of an SPL. Starting from a variability model, we\npropose to use Adversarial Machine Learning techniques to create new,\nadversarial configurations out of already known configurations by modifying\ntheir feature values. Using an industrial video generator we show how\nadversarial configurations can improve not only the classifier, but also the\nvariability model, the variability implementation, and the testing oracle.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:04:31 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Temple", "Paul", ""], ["Acher", "Mathieu", ""], ["Biggio", "Battista", ""], ["J\u00e9z\u00e9quel", "Jean-Marc", ""], ["Roli", "Fabio", ""]]}, {"id": "1805.12024", "submitter": "Sam Leroux", "authors": "Sam Leroux, Tim Verbelen, Pieter Simoens, Bart Dhoedt", "title": "Privacy Aware Offloading of Deep Neural Networks", "comments": "ICML 2018 Privacy in Machine Learning and Artificial Intelligence\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks require large amounts of resources which makes them hard\nto use on resource constrained devices such as Internet-of-things devices.\nOffloading the computations to the cloud can circumvent these constraints but\nintroduces a privacy risk since the operator of the cloud is not necessarily\ntrustworthy. We propose a technique that obfuscates the data before sending it\nto the remote computation node. The obfuscated data is unintelligible for a\nhuman eavesdropper but can still be classified with a high accuracy by a neural\nnetwork trained on unobfuscated images.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:10:20 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Leroux", "Sam", ""], ["Verbelen", "Tim", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1805.12044", "submitter": "Chao Liu", "authors": "Zehui Jiang, Chao Liu, Nathan P. Hendricks, Baskar\n  Ganapathysubramanian, Dermot J. Hayes and Soumik Sarkar", "title": "Predicting County Level Corn Yields Using Deep Long Short Term Memory\n  Models", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corn yield prediction is beneficial as it provides valuable information about\nproduction and prices prior the harvest. Publicly available high-quality corn\nyield prediction can help address emergent information asymmetry problems and\nin doing so improve price efficiency in futures markets. This paper is the\nfirst to employ Long Short-Term Memory (LSTM), a special form of Recurrent\nNeural Network (RNN) method to predict corn yields. A cross sectional time\nseries of county-level corn yield and hourly weather data made the sample space\nlarge enough to use deep learning technics. LSTM is efficient in time series\nprediction with complex inner relations, which makes it suitable for this task.\nThe empirical results from county level data in Iowa show promising predictive\npower relative to existing survey based methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:48:05 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Jiang", "Zehui", ""], ["Liu", "Chao", ""], ["Hendricks", "Nathan P.", ""], ["Ganapathysubramanian", "Baskar", ""], ["Hayes", "Dermot J.", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1805.12062", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh, Tom Sercu, Anant Raj", "title": "Sobolev Descent", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a simplification of GAN training: the problem of transporting\nparticles from a source to a target distribution. Starting from the Sobolev GAN\ncritic, part of the gradient regularized GAN family, we show a strong relation\nwith Optimal Transport (OT). Specifically with the less popular dynamic\nformulation of OT that finds a path of distributions from source to target\nminimizing a ``kinetic energy''. We introduce Sobolev descent that constructs\nsimilar paths by following gradient flows of a critic function in a kernel\nspace or parametrized by a neural network. In the kernel version, we show\nconvergence to the target distribution in the MMD sense. We show in theory and\nexperiments that regularization has an important role in favoring smooth\ntransitions between distributions, avoiding large gradients from the critic.\nThis analysis in a simplified particle setting provides insight in paths to\nequilibrium in GANs.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 16:30:21 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 14:54:04 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mroueh", "Youssef", ""], ["Sercu", "Tom", ""], ["Raj", "Anant", ""]]}, {"id": "1805.12076", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, Nathan\n  Srebro", "title": "Towards Understanding the Role of Over-Parametrization in Generalization\n  of Neural Networks", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite existing work on ensuring generalization of neural networks in terms\nof scale sensitive complexity measures, such as norms, margin and sharpness,\nthese complexity measures do not offer an explanation of why neural networks\ngeneralize better with over-parametrization. In this work we suggest a novel\ncomplexity measure based on unit-wise capacities resulting in a tighter\ngeneralization bound for two layer ReLU networks. Our capacity bound correlates\nwith the behavior of test error with increasing network sizes, and could\npotentially explain the improvement in generalization with\nover-parametrization. We further present a matching lower bound for the\nRademacher complexity that improves over previous capacity lower bounds for\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 16:50:28 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Li", "Zhiyuan", ""], ["Bhojanapalli", "Srinadh", ""], ["LeCun", "Yann", ""], ["Srebro", "Nathan", ""]]}, {"id": "1805.12085", "submitter": "Lazar Supic", "authors": "Lazar Supic, Rawan Naous, Ranko Sredojevic, Aleksandra Faust, Vladimir\n  Stojanovic", "title": "MPDCompress - Matrix Permutation Decomposition Algorithm for Deep Neural\n  Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become the state-of-the-art technique for\nmachine learning tasks in various applications. However, due to their size and\nthe computational complexity, large DNNs are not readily deployable on edge\ndevices in real-time. To manage complexity and accelerate computation, network\ncompression techniques based on pruning and quantization have been proposed and\nshown to be effective in reducing network size. However, such network\ncompression can result in irregular matrix structures that are mismatched with\nmodern hardware-accelerated platforms, such as graphics processing units (GPUs)\ndesigned to perform the DNN matrix multiplications in a structured\n(block-based) way. We propose MPDCompress, a DNN compression algorithm based on\nmatrix permutation decomposition via random mask generation. In-training\napplication of the masks molds the synaptic weight connection matrix to a\nsub-graph separation format. Aided by the random permutations, a\nhardware-desirable block matrix is generated, allowing for a more efficient\nimplementation and compression of the network. To show versatility, we\nempirically verify MPDCompress on several network models, compression rates,\nand image datasets. On the LeNet 300-100 model (MNIST dataset), Deep MNIST, and\nCIFAR10, we achieve 10 X network compression with less than 1% accuracy loss\ncompared to non-compressed accuracy performance. On AlexNet for the full\nImageNet ILSVRC-2012 dataset, we achieve 8 X network compression with less than\n1% accuracy loss, with top-5 and top-1 accuracies of 79.6% and 56.4%,\nrespectively. Finally, we observe that the algorithm can offer inference\nspeedups across various hardware platforms, with 4 X faster operation achieved\non several mobile GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:01:30 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Supic", "Lazar", ""], ["Naous", "Rawan", ""], ["Sredojevic", "Ranko", ""], ["Faust", "Aleksandra", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "1805.12111", "submitter": "Zhengyang Dong", "authors": "Zhengyang Dong", "title": "Dynamic Advisor-Based Ensemble (dynABE): Case study in stock trend\n  prediction of critical metal companies", "comments": "This is the latest version published in Plos ONE", "journal-ref": "PLOS ONE 14(2): e0212487 (2019)", "doi": "10.1371/journal.pone.0212487", "report-no": null, "categories": "q-fin.ST cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock trend prediction is a challenging task due to the market's noise, and\nmachine learning techniques have recently been successful in coping with this\nchallenge. In this research, we create a novel framework for stock prediction,\nDynamic Advisor-Based Ensemble (dynABE). dynABE explores domain-specific areas\nbased on the companies of interest, diversifies the feature set by creating\ndifferent \"advisors\" that each handles a different area, follows an effective\nmodel ensemble procedure for each advisor, and combines the advisors together\nin a second-level ensemble through an online update strategy we developed.\ndynABE is able to adapt to price pattern changes of the market during the\nactive trading period robustly, without needing to retrain the entire model. We\ntest dynABE on three cobalt-related companies, and it achieves the best-case\nmisclassification error of 31.12% and an annualized absolute return of 359.55%\nwith zero maximum drawdown. dynABE also consistently outperforms the baseline\nmodels of support vector machine, neural network, and random forest in all case\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 04:03:39 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 02:39:02 GMT"}, {"version": "v3", "created": "Wed, 15 Aug 2018 03:00:45 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 00:47:43 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Dong", "Zhengyang", ""]]}, {"id": "1805.12114", "submitter": "Roberto Calandra", "authors": "Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey\n  Levine", "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic\n  Dynamics Models", "comments": "NIPS 2018, video and code available at\n  https://sites.google.com/view/drl-in-a-handful-of-trials/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) algorithms can attain excellent\nsample efficiency, but often lag behind the best model-free algorithms in terms\nof asymptotic performance. This is especially true with high-capacity\nparametric function approximators, such as deep networks. In this paper, we\nstudy how to bridge this gap, by employing uncertainty-aware dynamics models.\nWe propose a new algorithm called probabilistic ensembles with trajectory\nsampling (PETS) that combines uncertainty-aware deep network dynamics models\nwith sampling-based uncertainty propagation. Our comparison to state-of-the-art\nmodel-based and model-free deep RL algorithms shows that our approach matches\nthe asymptotic performance of model-free algorithms on several challenging\nbenchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125\ntimes fewer samples than Soft Actor Critic and Proximal Policy Optimization\nrespectively on the half-cheetah task).\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:55:21 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 17:19:02 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chua", "Kurtland", ""], ["Calandra", "Roberto", ""], ["McAllister", "Rowan", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.12120", "submitter": "Aditya Balu", "authors": "Zhanhong Jiang, Aditya Balu, Chinmay Hegde, and Soumik Sarkar", "title": "On Consensus-Optimality Trade-offs in Collaborative Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed machine learning, where agents collaboratively learn from\ndiverse private data sets, there is a fundamental tension between consensus and\noptimality. In this paper, we build on recent algorithmic progresses in\ndistributed deep learning to explore various consensus-optimality trade-offs\nover a fixed communication topology. First, we propose the incremental\nconsensus-based distributed SGD (i-CDSGD) algorithm, which involves multiple\nconsensus steps (where each agent communicates information with its neighbors)\nwithin each SGD iteration. Second, we propose the generalized consensus-based\ndistributed SGD (g-CDSGD) algorithm that enables us to navigate the full\nspectrum from complete consensus (all agents agree) to complete disagreement\n(each agent converges to individual model parameters). We analytically\nestablish convergence of the proposed algorithms for strongly convex and\nnonconvex objective functions; we also analyze the momentum variants of the\nalgorithms for the strongly convex case. We support our algorithms via\nnumerical experiments, and demonstrate significant improvements over existing\nmethods for collaborative deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:59:24 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Jiang", "Zhanhong", ""], ["Balu", "Aditya", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1805.12152", "submitter": "Dimitris Tsipras", "authors": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner,\n  Aleksander Madry", "title": "Robustness May Be at Odds with Accuracy", "comments": "ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there may exist an inherent tension between the goal of\nadversarial robustness and that of standard generalization. Specifically,\ntraining robust models may not only be more resource-consuming, but also lead\nto a reduction of standard accuracy. We demonstrate that this trade-off between\nthe standard accuracy of a model and its robustness to adversarial\nperturbations provably exists in a fairly simple and natural setting. These\nfindings also corroborate a similar phenomenon observed empirically in more\ncomplex settings. Further, we argue that this phenomenon is a consequence of\nrobust classifiers learning fundamentally different feature representations\nthan standard classifiers. These differences, in particular, seem to result in\nunexpected benefits: the representations learned by robust models tend to align\nbetter with salient data characteristics and human perception.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 18:00:32 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 03:35:11 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 05:09:19 GMT"}, {"version": "v4", "created": "Fri, 30 Aug 2019 22:57:22 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2019 08:09:25 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tsipras", "Dimitris", ""], ["Santurkar", "Shibani", ""], ["Engstrom", "Logan", ""], ["Turner", "Alexander", ""], ["Madry", "Aleksander", ""]]}, {"id": "1805.12164", "submitter": "Carl Allen", "authors": "Carl Allen, Ivana Bala\\v{z}evi\\'c, Timothy Hospedales", "title": "What the Vec? Towards Probabilistically Grounded Embeddings", "comments": "Advances in Neural Information Processing, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2Vec (W2V) and GloVe are popular, fast and efficient word embedding\nalgorithms. Their embeddings are widely used and perform well on a variety of\nnatural language processing tasks. Moreover, W2V has recently been adopted in\nthe field of graph embedding, where it underpins several leading algorithms.\nHowever, despite their ubiquity and relatively simple model architecture, a\ntheoretical understanding of what the embedding parameters of W2V and GloVe\nlearn and why that is useful in downstream tasks has been lacking. We show that\ndifferent interactions between PMI vectors reflect semantic word relationships,\nsuch as similarity and paraphrasing, that are encoded in low dimensional word\nembeddings under a suitable projection, theoretically explaining why embeddings\nof W2V and GloVe work. As a consequence, we also reveal an interesting\nmathematical interconnection between the considered semantic relationships\nthemselves.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 18:19:38 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 14:38:29 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 15:11:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Allen", "Carl", ""], ["Bala\u017eevi\u0107", "Ivana", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1805.12168", "submitter": "Biswajit Paria", "authors": "Biswajit Paria, Kirthevasan Kandasamy, Barnab\\'as P\\'oczos", "title": "A Flexible Framework for Multi-Objective Bayesian Optimization using\n  Random Scalarizations", "comments": "Accepted to UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world applications can be framed as multi-objective optimization\nproblems, where we wish to simultaneously optimize for multiple criteria.\nBayesian optimization techniques for the multi-objective setting are pertinent\nwhen the evaluation of the functions in question are expensive. Traditional\nmethods for multi-objective optimization, both Bayesian and otherwise, are\naimed at recovering the Pareto front of these objectives. However, in certain\ncases a practitioner might desire to identify Pareto optimal points only in a\nsubset of the Pareto front due to external considerations. In this work, we\npropose a strategy based on random scalarizations of the objectives that\naddresses this problem. Our approach is able to flexibly sample from desired\nregions of the Pareto front and, computationally, is considerably cheaper than\nmost approaches for MOO. We also study a notion of regret in the\nmulti-objective setting and show that our strategy achieves sublinear regret.\nWe experiment with both synthetic and real-life problems, and demonstrate\nsuperior performance of our proposed algorithm in terms of the flexibility and\nregret.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 18:27:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 23:21:50 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 18:21:08 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Paria", "Biswajit", ""], ["Kandasamy", "Kirthevasan", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1805.12176", "submitter": "Kevin Joslyn", "authors": "Kevin Joslyn, Naifan Zhuang, Kien A. Hua", "title": "Deep Segment Hash Learning for Music Generation", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music generation research has grown in popularity over the past decade,\nthanks to the deep learning revolution that has redefined the landscape of\nartificial intelligence. In this paper, we propose a novel approach to music\ngeneration inspired by musical segment concatenation methods and hash learning\nalgorithms. Given a segment of music, we use a deep recurrent neural network\nand ranking-based hash learning to assign a forward hash code to the segment to\nretrieve candidate segments for continuation with matching backward hash codes.\nThe proposed method is thus called Deep Segment Hash Learning (DSHL). To the\nbest of our knowledge, DSHL is the first end-to-end segment hash learning\nmethod for music generation, and the first to use pair-wise training with\nsegments of music. We demonstrate that this method is capable of generating\nmusic which is both original and enjoyable, and that DSHL offers a promising\nnew direction for music generation research.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 18:49:35 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Joslyn", "Kevin", ""], ["Zhuang", "Naifan", ""], ["Hua", "Kien A.", ""]]}, {"id": "1805.12185", "submitter": "Kang Liu", "authors": "Kang Liu, Brendan Dolan-Gavitt, Siddharth Garg", "title": "Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) provide excellent performance across a wide range\nof classification tasks, but their training requires high computational\nresources and is often outsourced to third parties. Recent work has shown that\noutsourced training introduces the risk that a malicious trainer will return a\nbackdoored DNN that behaves normally on most inputs but causes targeted\nmisclassifications or degrades the accuracy of the network when a trigger known\nonly to the attacker is present. In this paper, we provide the first effective\ndefenses against backdoor attacks on DNNs. We implement three backdoor attacks\nfrom prior work and use them to investigate two promising defenses, pruning and\nfine-tuning. We show that neither, by itself, is sufficient to defend against\nsophisticated attackers. We then evaluate fine-pruning, a combination of\npruning and fine-tuning, and show that it successfully weakens or even\neliminates the backdoors, i.e., in some cases reducing the attack success rate\nto 0% with only a 0.4% drop in accuracy for clean (non-triggering) inputs. Our\nwork provides the first step toward defenses against backdoor attacks in deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 19:13:00 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Liu", "Kang", ""], ["Dolan-Gavitt", "Brendan", ""], ["Garg", "Siddharth", ""]]}, {"id": "1805.12218", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim, Michael Cochez, Achille Zappa, Ratnesh Sahay, Oya\n  Beyan, Dietrich-Rebholz Schuhmann, Stefan Decker", "title": "Convolutional Embedded Networks for Population Scale Clustering and\n  Bio-ancestry Inferencing", "comments": "This article is under review in IEEE/ACM Transactions on\n  Computational Biology and Bioinformatics. It is based on a workshop paper\n  discussed at the Extended Semantic Web Conference (ESWC'2017) workshop on\n  Semantic Web Solutions for Large-scale Biomedical Data Analytics (SeWeBMeDA),\n  Slovenia, May, 28-29, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of genetic variants can help find correlating population groups to\nidentify cohorts that are predisposed to common diseases and explain\ndifferences in disease susceptibility and how patients react to drugs. Machine\nlearning algorithms are increasingly being applied to identify interacting GVs\nto understand their complex phenotypic traits. Since the performance of a\nlearning algorithm not only depends on the size and nature of the data but also\non the quality of underlying representation, deep neural networks can learn\nnon-linear mappings that allow transforming GVs data into more clustering and\nclassification friendly representations than manual feature selection. In this\npaper, we proposed convolutional embedded networks in which we combine two DNN\narchitectures called convolutional embedded clustering and convolutional\nautoencoder classifier for clustering individuals and predicting geographic\nethnicity based on GVs, respectively. We employed CAE-based representation\nlearning on 95 million GVs from the 1000 genomes and Simons genome diversity\nprojects. Quantitative and qualitative analyses with a focus on accuracy and\nscalability show that our approach outperforms state-of-the-art approaches such\nas VariantSpark and ADMIXTURE. In particular, CEC can cluster targeted\npopulation groups in 22 hours with an adjusted rand index of 0.915, the\nnormalized mutual information of 0.92, and the clustering accuracy of 89%.\nContrarily, the CAE classifier can predict the geographic ethnicity of unknown\nsamples with an F1 and Mathews correlation coefficient(MCC) score of 0.9004 and\n0.8245, respectively. To provide interpretations of the predictions, we\nidentify significant biomarkers using gradient boosted trees(GBT) and SHAP.\nOverall, our approach is transparent and faster than the baseline methods, and\nscalable for 5% to 100% of the full human genome.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 20:30:13 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 19:18:51 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Cochez", "Michael", ""], ["Zappa", "Achille", ""], ["Sahay", "Ratnesh", ""], ["Beyan", "Oya", ""], ["Schuhmann", "Dietrich-Rebholz", ""], ["Decker", "Stefan", ""]]}, {"id": "1805.12233", "submitter": "Qiqi Yan", "authors": "Kedar Dhamdhere and Mukund Sundararajan and Qiqi Yan", "title": "How Important Is a Neuron?", "comments": "under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of attributing a deep network's prediction to its\n\\emph{input/base} features is well-studied. We introduce the notion of\n\\emph{conductance} to extend the notion of attribution to the understanding the\nimportance of \\emph{hidden} units.\n  Informally, the conductance of a hidden unit of a deep network is the\n\\emph{flow} of attribution via this hidden unit. We use conductance to\nunderstand the importance of a hidden unit to the prediction for a specific\ninput, or over a set of inputs. We evaluate the effectiveness of conductance in\nmultiple ways, including theoretical properties, ablation studies, and a\nfeature selection task. The empirical evaluations are done using the Inception\nnetwork over ImageNet data, and a sentiment analysis network over reviews. In\nboth cases, we demonstrate the effectiveness of conductance in identifying\ninteresting insights about the internal workings of these networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 21:26:22 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Dhamdhere", "Kedar", ""], ["Sundararajan", "Mukund", ""], ["Yan", "Qiqi", ""]]}, {"id": "1805.12243", "submitter": "Henglai Wei", "authors": "Henglai Wei, Xiaochuan Yin, Penghong Lin", "title": "Novel Video Prediction for Large-scale Scene using Optical Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making predictions of future frames is a critical challenge in autonomous\ndriving research. Most of the existing methods for video prediction attempt to\ngenerate future frames in simple and fixed scenes. In this paper, we propose a\nnovel and effective optical flow conditioned method for the task of video\nprediction with an application to complex urban scenes. In contrast with\nprevious work, the prediction model only requires video sequences and optical\nflow sequences for training and testing. Our method uses the rich\nspatial-temporal features in video sequences. The method takes advantage of the\nmotion information extracting from optical flow maps between neighbor images as\nwell as previous images. Empirical evaluations on the KITTI dataset and the\nCityscapes dataset demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 22:11:54 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Wei", "Henglai", ""], ["Yin", "Xiaochuan", ""], ["Lin", "Penghong", ""]]}, {"id": "1805.12244", "submitter": "Johann Brehmer Mr", "authors": "Johann Brehmer, Gilles Louppe, Juan Pavez, and Kyle Cranmer", "title": "Mining gold from implicit models to improve likelihood-free inference", "comments": "Code available at\n  https://github.com/johannbrehmer/simulator-mining-example . v2: Fixed typos.\n  v3: Expanded discussion, added Lotka-Volterra example. v4: Improved clarity", "journal-ref": null, "doi": "10.1073/pnas.1915980117", "report-no": null, "categories": "stat.ML cs.LG hep-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulators often provide the best description of real-world phenomena.\nHowever, they also lead to challenging inverse problems because the density\nthey implicitly define is often intractable. We present a new suite of\nsimulation-based inference techniques that go beyond the traditional\nApproximate Bayesian Computation approach, which struggles in a\nhigh-dimensional setting, and extend methods that use surrogate models based on\nneural networks. We show that additional information, such as the joint\nlikelihood ratio and the joint score, can often be extracted from simulators\nand used to augment the training data for these surrogate models. Finally, we\ndemonstrate that these new techniques are more sample efficient and provide\nhigher-fidelity inference than traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 22:14:20 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 18:20:58 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 20:35:08 GMT"}, {"version": "v4", "created": "Mon, 5 Aug 2019 14:02:58 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Brehmer", "Johann", ""], ["Louppe", "Gilles", ""], ["Pavez", "Juan", ""], ["Cranmer", "Kyle", ""]]}, {"id": "1805.12270", "submitter": "Elaheh Rashedi", "authors": "Elaheh Rashedi, Abdolreza Mirzaei", "title": "Optimized Participation of Multiple Fusion Functions in Consensus\n  Creation: An Evolutionary Approach", "comments": "The 16th CSI International Symposium on Artificial Intelligence and\n  Signal Processing (AISP 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that ensemble methods enhance the stability and\nrobustness of unsupervised learning. These approaches are successfully utilized\nto construct multiple clustering and combine them into a one representative\nconsensus clustering of an improved quality. The quality of the consensus\nclustering is directly depended on fusion functions used in combination. In\nthis article, the hierarchical clustering ensemble techniques are extended by\nintroducing a new evolutionary fusion function. In the proposed method,\nmultiple hierarchical clustering methods are generated via bagging. Thereafter,\nthe consensus clustering is obtained using the search capability of genetic\nalgorithm among different aggregated clustering methods made by different\nfusion functions. Putting some popular data sets to empirical study, the\nquality of the proposed method is compared with regular clustering ensembles.\nExperimental results demonstrate the accuracy improvement of the aggregated\nclustering results.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 00:44:37 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Rashedi", "Elaheh", ""], ["Mirzaei", "Abdolreza", ""]]}, {"id": "1805.12296", "submitter": "Chao Liu", "authors": "Chao Liu, Kin Gwn Lore, Zhanhong Jiang and Soumik Sarkar", "title": "Root-cause Analysis for Time-series Anomalies via Spatiotemporal\n  Graphical Modeling in Distributed Complex Systems", "comments": "42 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1605.06421", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance monitoring, anomaly detection, and root-cause analysis in complex\ncyber-physical systems (CPSs) are often highly intractable due to widely\ndiverse operational modes, disparate data types, and complex fault propagation\nmechanisms. This paper presents a new data-driven framework for root-cause\nanalysis, based on a spatiotemporal graphical modeling approach built on the\nconcept of symbolic dynamics for discovering and representing causal\ninteractions among sub-systems of complex CPSs. We formulate the root-cause\nanalysis problem as a minimization problem via the proposed inference based\nmetric and present two approximate approaches for root-cause analysis, namely\nthe sequential state switching ($S^3$, based on free energy concept of a\nrestricted Boltzmann machine, RBM) and artificial anomaly association ($A^3$, a\nclassification framework using deep neural networks, DNN). Synthetic data from\ncases with failed pattern(s) and anomalous node(s) are simulated to validate\nthe proposed approaches. Real dataset based on Tennessee Eastman process (TEP)\nis also used for comparison with other approaches. The results show that: (1)\n$S^3$ and $A^3$ approaches can obtain high accuracy in root-cause analysis\nunder both pattern-based and node-based fault scenarios, in addition to\nsuccessfully handling multiple nominal operating modes, (2) the proposed\ntool-chain is shown to be scalable while maintaining high accuracy, and (3) the\nproposed framework is robust and adaptive in different fault conditions and\nperforms better in comparison with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 02:45:02 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Liu", "Chao", ""], ["Lore", "Kin Gwn", ""], ["Jiang", "Zhanhong", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1805.12298", "submitter": "Omer Gottesman", "authors": "Omer Gottesman, Fredrik Johansson, Joshua Meier, Jack Dent, Donghun\n  Lee, Srivatsan Srinivasan, Linying Zhang, Yi Ding, David Wihl, Xuefeng Peng,\n  Jiayu Yao, Isaac Lage, Christopher Mosch, Li-wei H. Lehman, Matthieu\n  Komorowski, Matthieu Komorowski, Aldo Faisal, Leo Anthony Celi, David Sontag,\n  Finale Doshi-Velez", "title": "Evaluating Reinforcement Learning Algorithms in Observational Health\n  Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much attention has been devoted recently to the development of machine\nlearning algorithms with the goal of improving treatment policies in\nhealthcare. Reinforcement learning (RL) is a sub-field within machine learning\nthat is concerned with learning how to make sequences of decisions so as to\noptimize long-term effects. Already, RL algorithms have been proposed to\nidentify decision-making strategies for mechanical ventilation, sepsis\nmanagement and treatment of schizophrenia. However, before implementing\ntreatment policies learned by black-box algorithms in high-stakes clinical\ndecision problems, special care must be taken in the evaluation of these\npolicies.\n  In this document, our goal is to expose some of the subtleties associated\nwith evaluating RL algorithms in healthcare. We aim to provide a conceptual\nstarting point for clinical and computational researchers to ask the right\nquestions when designing and evaluating algorithms for new ways of treating\npatients. In the following, we describe how choices about how to summarize a\nhistory, variance of statistical estimators, and confounders in more ad-hoc\nmeasures can result in unreliable, even misleading estimates of the quality of\na treatment policy. We also provide suggestions for mitigating these\neffects---for while there is much promise for mining observational health data\nto uncover better treatment policies, evaluation must be performed\nthoughtfully.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 02:56:26 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Gottesman", "Omer", ""], ["Johansson", "Fredrik", ""], ["Meier", "Joshua", ""], ["Dent", "Jack", ""], ["Lee", "Donghun", ""], ["Srinivasan", "Srivatsan", ""], ["Zhang", "Linying", ""], ["Ding", "Yi", ""], ["Wihl", "David", ""], ["Peng", "Xuefeng", ""], ["Yao", "Jiayu", ""], ["Lage", "Isaac", ""], ["Mosch", "Christopher", ""], ["Lehman", "Li-wei H.", ""], ["Komorowski", "Matthieu", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo", ""], ["Celi", "Leo Anthony", ""], ["Sontag", "David", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1805.12301", "submitter": "Benjamin Chidester", "authors": "Benjamin Chidester, Minh N. Do, Jian Ma", "title": "Rotation Equivariance and Invariance in Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of neural networks can be significantly improved by encoding\nknown invariance for particular tasks. Many image classification tasks, such as\nthose related to cellular imaging, exhibit invariance to rotation. We present a\nnovel scheme using the magnitude response of the 2D-discrete-Fourier transform\n(2D-DFT) to encode rotational invariance in neural networks, along with a new,\nefficient convolutional scheme for encoding rotational equivariance throughout\nconvolutional layers. We implemented this scheme for several image\nclassification tasks and demonstrated improved performance, in terms of\nclassification accuracy, time required to train the model, and robustness to\nhyperparameter selection, over a standard CNN and another state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 03:13:41 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Chidester", "Benjamin", ""], ["Do", "Minh N.", ""], ["Ma", "Jian", ""]]}, {"id": "1805.12302", "submitter": "Avishek Bose", "authors": "Avishek Joey Bose and Parham Aarabi", "title": "Adversarial Attacks on Face Detectors using Neural Net based Constrained\n  Optimization", "comments": "Accepted to IEEE MMSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks involve adding, small, often imperceptible, perturbations\nto inputs with the goal of getting a machine learning model to misclassifying\nthem. While many different adversarial attack strategies have been proposed on\nimage classification models, object detection pipelines have been much harder\nto break. In this paper, we propose a novel strategy to craft adversarial\nexamples by solving a constrained optimization problem using an adversarial\ngenerator network. Our approach is fast and scalable, requiring only a forward\npass through our trained generator network to craft an adversarial sample.\nUnlike in many attack strategies, we show that the same trained generator is\ncapable of attacking new images without explicitly optimizing on them. We\nevaluate our attack on a trained Faster R-CNN face detector on the cropped\n300-W face dataset where we manage to reduce the number of detected faces to\n$0.5\\%$ of all originally detected faces. In a different experiment, also on\n300-W, we demonstrate the robustness of our attack to a JPEG compression based\ndefense typical JPEG compression level of $75\\%$ reduces the effectiveness of\nour attack from only $0.5\\%$ of detected faces to a modest $5.0\\%$.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 03:18:32 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Aarabi", "Parham", ""]]}, {"id": "1805.12313", "submitter": "Yunlong Liu", "authors": "Yunlong Liu and L. Mario Amzel", "title": "Conformation Clustering of Long MD Protein Dynamics with an Adversarial\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in specialized computer hardware have greatly accelerated\natomic level Molecular Dynamics (MD) simulations. A single GPU-attached cluster\nis capable of producing microsecond-length trajectories in reasonable amounts\nof time. Multiple protein states and a large number of microstates associated\nwith folding and with the function of the protein can be observed as\nconformations sampled in the trajectories. Clustering those conformations,\nhowever, is needed for identifying protein states, evaluating transition rates\nand understanding protein behavior. In this paper, we propose a novel\ndata-driven generative conformation clustering method based on the adversarial\nautoencoder (AAE) and provide the associated software implementation Cong. The\nmethod was tested using a 208 microseconds MD simulation of the fast-folding\npeptide Trp-Cage (20 residues) obtained from the D.E. Shaw Research Group. The\nproposed clustering algorithm identifies many of the salient features of the\nfolding process by grouping a large number of conformations that share common\nfeatures not easily identifiable in the trajectory.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 03:46:27 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Liu", "Yunlong", ""], ["Amzel", "L. Mario", ""]]}, {"id": "1805.12316", "submitter": "Puyudi Yang", "authors": "Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I.\n  Jordan", "title": "Greedy Attack and Gumbel Attack: Generating Adversarial Examples for\n  Discrete Data", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic framework for studying adversarial attacks on\ndiscrete data. Based on this framework, we derive a perturbation-based method,\nGreedy Attack, and a scalable learning-based method, Gumbel Attack, that\nillustrate various tradeoffs in the design of attacks. We demonstrate the\neffectiveness of these methods using both quantitative metrics and human\nevaluation on various state-of-the-art models for text classification,\nincluding a word-based CNN, a character-based CNN and an LSTM. As as example of\nour results, we show that the accuracy of character-based convolutional\nnetworks drops to the level of random selection by modifying only five\ncharacters through Greedy Attack.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 04:40:32 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Yang", "Puyudi", ""], ["Chen", "Jianbo", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Jane-Ling", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1805.12317", "submitter": "Michael P. Kim", "authors": "Michael P. Kim, Amirata Ghorbani, James Zou", "title": "Multiaccuracy: Black-Box Post-Processing for Fairness in Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction systems are successfully deployed in applications ranging from\ndisease diagnosis, to predicting credit worthiness, to image recognition. Even\nwhen the overall accuracy is high, these systems may exhibit systematic biases\nthat harm specific subpopulations; such biases may arise inadvertently due to\nunderrepresentation in the data used to train a machine-learning model, or as\nthe result of intentional malicious discrimination. We develop a rigorous\nframework of *multiaccuracy* auditing and post-processing to ensure accurate\npredictions across *identifiable subgroups*.\n  Our algorithm, MULTIACCURACY-BOOST, works in any setting where we have\nblack-box access to a predictor and a relatively small set of labeled data for\nauditing; importantly, this black-box framework allows for improved fairness\nand accountability of predictions, even when the predictor is minimally\ntransparent. We prove that MULTIACCURACY-BOOST converges efficiently and show\nthat if the initial model is accurate on an identifiable subgroup, then the\npost-processed model will be also. We experimentally demonstrate the\neffectiveness of the approach to improve the accuracy among minority subgroups\nin diverse applications (image classification, finance, population health).\nInterestingly, MULTIACCURACY-BOOST can improve subpopulation accuracy (e.g. for\n\"black women\") even when the sensitive features (e.g. \"race\", \"gender\") are not\ngiven to the algorithm explicitly.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 04:51:08 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 16:53:44 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Kim", "Michael P.", ""], ["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "1805.12321", "submitter": "Xiaofeng Cao", "authors": "Xiaofeng Cao", "title": "A Divide-and-Conquer Approach to Geometric Sampling for Active Learning", "comments": "This paper has been withdrawn. The first author quitted the PhD study\n  from AAI, University of Technology Sydney. The manuscript stopped updating", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) repeatedly trains the classifier with the minimum\nlabeling budget to improve the current classification model. The training\nprocess is usually supervised by an uncertainty evaluation strategy. However,\nthe uncertainty evaluation always suffers from performance degeneration when\nthe initial labeled set has insufficient labels. To completely eliminate the\ndependence on the uncertainty evaluation sampling in AL, this paper proposes a\ndivide-and-conquer idea that directly transfers the AL sampling as the\ngeometric sampling over the clusters. By dividing the points of the clusters\ninto cluster boundary and core points, we theoretically discuss their margin\ndistance and {hypothesis relationship}. With the advantages of cluster boundary\npoints in the above two properties, we propose a Geometric Active Learning\n(GAL) algorithm by knight's tour. Experimental studies of the two reported\nexperimental tasks including cluster boundary detection and AL classification\nshow that the proposed GAL method significantly outperforms the\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 05:31:10 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 01:07:23 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 23:53:47 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Cao", "Xiaofeng", ""]]}, {"id": "1805.12324", "submitter": "Isao Ishikawa", "authors": "Isao Ishikawa, Keisuke Fujii, Masahiro Ikeda, Yuka Hashimoto,\n  Yoshinobu Kawahara", "title": "Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators", "comments": "accepted to NIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a metric for structural data is a long-term problem in\npattern recognition and machine learning. In this paper, we develop a general\nmetric for comparing nonlinear dynamical systems that is defined with\nPerron-Frobenius operators in reproducing kernel Hilbert spaces. Our metric\nincludes the existing fundamental metrics for dynamical systems, which are\nbasically defined with principal angles between some appropriately-chosen\nsubspaces, as its special cases. We also describe the estimation of our metric\nfrom finite data. We empirically illustrate our metric with an example of\nrotation dynamics in a unit disk in a complex plane, and evaluate the\nperformance with real-world time-series data.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 05:45:41 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 14:23:18 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Ishikawa", "Isao", ""], ["Fujii", "Keisuke", ""], ["Ikeda", "Masahiro", ""], ["Hashimoto", "Yuka", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1805.12332", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Hidetoshi Shimodaira", "title": "On representation power of neural network-based graph embedding and\n  beyond", "comments": "13 pages (with Supplementary Material), 12 figures, ICML2018 workshop\n  on Theoretical Foundations and Applications of Deep Generative Models (TADGM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the representation power of siamese-style similarity functions\nused in neural network-based graph embedding. The inner product similarity\n(IPS) with feature vectors computed via neural networks is commonly used for\nrepresenting the strength of association between two nodes. However, only a\nlittle work has been done on the representation capability of IPS. A very\nrecent work shed light on the nature of IPS and reveals that IPS has the\ncapability of approximating any positive definite (PD) similarities. However, a\nsimple example demonstrates the fundamental limitation of IPS to approximate\nnon-PD similarities. We then propose a novel model named Shifted IPS (SIPS)\nthat approximates any Conditionally PD (CPD) similarities arbitrary well. CPD\nis a generalization of PD with many examples such as negative Poincar\\'e\ndistance and negative Wasserstein distance, thus SIPS has a potential impact to\nsignificantly improve the applicability of graph embedding without taking great\ncare in configuring the similarity function. Our numerical experiments\ndemonstrate the SIPS's superiority over IPS. In theory, we further extend SIPS\nbeyond CPD by considering the inner product in Minkowski space so that it\napproximates more general similarities.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 06:10:29 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 06:49:32 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Okuno", "Akifumi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1805.12352", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Kyunghyun Cho, Jung-Woo Ha, Sunghun Kim", "title": "DialogWAE: Multimodal Response Generation with Conditional Wasserstein\n  Auto-Encoder", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders~(VAEs) have shown a promise in data-driven\nconversation modeling. However, most VAE conversation models match the\napproximate posterior distribution over the latent variables to a simple prior\nsuch as standard normal distribution, thereby restricting the generated\nresponses to a relatively simple (e.g., unimodal) scope. In this paper, we\npropose DialogWAE, a conditional Wasserstein autoencoder~(WAE) specially\ndesigned for dialogue modeling. Unlike VAEs that impose a simple distribution\nover the latent variables, DialogWAE models the distribution of data by\ntraining a GAN within the latent variable space. Specifically, our model\nsamples from the prior and posterior distributions over the latent variables by\ntransforming context-dependent random noise using neural networks and minimizes\nthe Wasserstein distance between the two distributions. We further develop a\nGaussian mixture prior network to enrich the latent space. Experiments on two\npopular datasets show that DialogWAE outperforms the state-of-the-art\napproaches in generating more coherent, informative and diverse responses.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:25:04 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 02:32:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gu", "Xiaodong", ""], ["Cho", "Kyunghyun", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Sunghun", ""]]}, {"id": "1805.12353", "submitter": "Daigo Shoji", "authors": "Daigo Shoji, Rina Noguchi, Shizuka Otsuki, Hideitsu Hino", "title": "Classification of volcanic ash particles using a convolutional neural\n  network and probability", "comments": "25 pages, 4 tables, 7 figurs, published in Scientific Reports", "journal-ref": "D. Shoji, R. Noguchi, S. Otsuki and H. Hino. Classification of\n  volcanic ash particles using a convolutional neural network and probability.\n  Scientific Reports 8, 8111 (2018)", "doi": "10.1038/s41598-018-26200-2", "report-no": null, "categories": "physics.geo-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyses of volcanic ash are typically performed either by qualitatively\nclassifying ash particles by eye or by quantitatively parameterizing its shape\nand texture. While complex shapes can be classified through qualitative\nanalyses, the results are subjective due to the difficulty of categorizing\ncomplex shapes into a single class. Although quantitative analyses are\nobjective, selection of shape parameters is required. Here, we applied a\nconvolutional neural network (CNN) for the classification of volcanic ash.\nFirst, we defined four basal particle shapes (blocky, vesicular, elongated,\nrounded) generated by different eruption mechanisms (e.g., brittle\nfragmentation), and then trained the CNN using particles composed of only one\nbasal shape. The CNN could recognize the basal shapes with over 90% accuracy.\nUsing the trained network, we classified ash particles composed of multiple\nbasal shapes based on the output of the network, which can be interpreted as a\nmixing ratio of the four basal shapes. Clustering of samples by the averaged\nprobabilities and the intensity is consistent with the eruption type. The\nmixing ratio output by the CNN can be used to quantitatively classify complex\nshapes in nature without categorizing forcibly and without the need for shape\nparameters, which may lead to a new taxonomy.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:30:48 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Shoji", "Daigo", ""], ["Noguchi", "Rina", ""], ["Otsuki", "Shizuka", ""], ["Hino", "Hideitsu", ""]]}, {"id": "1805.12355", "submitter": "Alona Golts", "authors": "Alona Golts and Daniel Freedman and Michael Elad", "title": "Deep-Energy: Unsupervised Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2021.3049634", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning has been due, in no small part, to the\navailability of large annotated datasets. Thus, a major bottleneck in current\nlearning pipelines is the time-consuming human annotation of data. In scenarios\nwhere such input-output pairs cannot be collected, simulation is often used\ninstead, leading to a domain-shift between synthesized and real-world data.\nThis work offers an unsupervised alternative that relies on the availability of\ntask-specific energy functions, replacing the generic supervised loss. Such\nenergy functions are assumed to lead to the desired label as their minimizer\ngiven the input. The proposed approach, termed \"Deep Energy\", trains a Deep\nNeural Network (DNN) to approximate this minimization for any chosen input.\nOnce trained, a simple and fast feed-forward computation provides the inferred\nlabel. This approach allows us to perform unsupervised training of DNNs with\nreal-world inputs only, and without the need for manually-annotated labels, nor\nsynthetically created data. \"Deep Energy\" is demonstrated in this paper on\nthree different tasks -- seeded segmentation, image matting and single image\ndehazing -- exposing its generality and wide applicability. Our experiments\nshow that the solution provided by the network is often much better in quality\nthan the one obtained by a direct minimization of the energy function,\nsuggesting an added regularization property in our scheme.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:32:57 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 12:29:39 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Golts", "Alona", ""], ["Freedman", "Daniel", ""], ["Elad", "Michael", ""]]}, {"id": "1805.12369", "submitter": "Zhanxing Zhu", "authors": "Ju Xu, Zhanxing Zhu", "title": "Reinforced Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most artificial intelligence models have limiting ability to solve new tasks\nfaster, without forgetting previously acquired knowledge. The recently emerging\nparadigm of continual learning aims to solve this issue, in which the model\nlearns various tasks in a sequential fashion. In this work, a novel approach\nfor continual learning is proposed, which searches for the best neural\narchitecture for each coming task via sophisticatedly designed reinforcement\nlearning strategies. We name it as Reinforced Continual Learning. Our method\nnot only has good performance on preventing catastrophic forgetting but also\nfits new tasks well. The experiments on sequential classification tasks for\nvariants of MNIST and CIFAR-100 datasets demonstrate that the proposed approach\noutperforms existing continual learning alternatives for deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 08:11:12 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Xu", "Ju", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1805.12372", "submitter": "Daniele Castellana", "authors": "Davide Bacciu and Daniele Castellana", "title": "Learning Tree Distributions by Hidden Markov Models", "comments": "Accepted in LearnAut2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hidden tree Markov models allow learning distributions for tree structured\ndata while being interpretable as nondeterministic automata. We provide a\nconcise summary of the main approaches in literature, focusing in particular on\nthe causality assumptions introduced by the choice of a specific tree visit\ndirection. We will then sketch a novel non-parametric generalization of the\nbottom-up hidden tree Markov model with its interpretation as a\nnondeterministic tree automaton with infinite states.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 08:22:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Bacciu", "Davide", ""], ["Castellana", "Daniele", ""]]}, {"id": "1805.12375", "submitter": "Su Young Lee", "authors": "Su Young Lee, Sungik Choi, Sae-Young Chung", "title": "Sample-Efficient Deep Reinforcement Learning via Episodic Backward\n  Update", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Episodic Backward Update (EBU) - a novel deep reinforcement\nlearning algorithm with a direct value propagation. In contrast to the\nconventional use of the experience replay with uniform random sampling, our\nagent samples a whole episode and successively propagates the value of a state\nto its previous states. Our computationally efficient recursive algorithm\nallows sparse and delayed rewards to propagate directly through all transitions\nof the sampled episode. We theoretically prove the convergence of the EBU\nmethod and experimentally demonstrate its performance in both deterministic and\nstochastic environments. Especially in 49 games of Atari 2600 domain, EBU\nachieves the same mean and median human normalized performance of DQN by using\nonly 5% and 10% of samples, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 08:28:24 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 04:07:31 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 04:16:25 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lee", "Su Young", ""], ["Choi", "Sungik", ""], ["Chung", "Sae-Young", ""]]}, {"id": "1805.12381", "submitter": "Tanujit Chakraborty", "authors": "Tanujit Chakraborty", "title": "Imbalanced Ensemble Classifier for learning from imbalanced business\n  school data set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private business schools in India face a common problem of selecting quality\nstudents for their MBA programs to achieve the desired placement percentage.\nGenerally, such data sets are biased towards one class, i.e., imbalanced in\nnature. And learning from the imbalanced dataset is a difficult proposition.\nThis paper proposes an imbalanced ensemble classifier which can handle the\nimbalanced nature of the dataset and achieves higher accuracy in case of the\nfeature selection (selection of important characteristics of students) cum\nclassification problem (prediction of placements based on the students'\ncharacteristics) for Indian business school dataset. The optimal value of an\nimportant model parameter is found. Numerical evidence is also provided using\nIndian business school dataset to assess the outstanding performance of the\nproposed classifier.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 08:53:32 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 08:36:45 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Chakraborty", "Tanujit", ""]]}, {"id": "1805.12387", "submitter": "Laurent Orseau", "authors": "Laurent Orseau, Simon McGregor McGill, Shane Legg", "title": "Agents and Devices: A Relative Definition of Agency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to Dennett, the same system may be described using a `physical'\n(mechanical) explanatory stance, or using an `intentional' (belief- and\ngoal-based) explanatory stance. Humans tend to find the physical stance more\nhelpful for certain systems, such as planets orbiting a star, and the\nintentional stance for others, such as living animals. We define a formal\ncounterpart of physical and intentional stances within computational theory: a\ndescription of a system as either a device, or an agent, with the key\ndifference being that `devices' are directly described in terms of an\ninput-output mapping, while `agents' are described in terms of the function\nthey optimise. Bayes' rule can then be applied to calculate the subjective\nprobability of a system being a device or an agent, based only on its\nbehaviour. We illustrate this using the trajectories of an object in a toy\ngrid-world domain.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:12:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Orseau", "Laurent", ""], ["McGill", "Simon McGregor", ""], ["Legg", "Shane", ""]]}, {"id": "1805.12393", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Hanjun Dai, Kamil Toraman, Le Song", "title": "KG^2: Learning to Reason Science Exam Questions with Contextual\n  Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question\nanswering (QA) has been recently released. ARC only contains natural science\nquestions authored for human exams, which are hard to answer and require\nadvanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art\nQA systems fail to significantly outperform random baseline, reflecting the\ndifficult nature of this task. In this paper, we propose a novel framework for\nanswering science exam questions, which mimics human solving process in an\nopen-book exam. To address the reasoning challenge, we construct contextual\nknowledge graphs respectively for the question itself and supporting sentences.\nOur model learns to reason with neural embeddings of both knowledge graphs.\nExperiments on the ARC Challenge Set show that our model outperforms the\nprevious state-of-the-art QA systems.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:39:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Zhang", "Yuyu", ""], ["Dai", "Hanjun", ""], ["Toraman", "Kamil", ""], ["Song", "Le", ""]]}, {"id": "1805.12421", "submitter": "Priyesh Vijayan", "authors": "Priyesh Vijayan, Yash Chandak, Mitesh M. Khapra, Srinivasan\n  Parthasarathy, Balaraman Ravindran", "title": "HOPF: Higher Order Propagation Framework for Deep Collective\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a graph where every node has certain attributes associated with it and\nsome nodes have labels associated with them, Collective Classification (CC) is\nthe task of assigning labels to every unlabeled node using information from the\nnode as well as its neighbors. It is often the case that a node is not only\ninfluenced by its immediate neighbors but also by higher order neighbors,\nmultiple hops away. Recent state-of-the-art models for CC learn end-to-end\ndifferentiable variations of Weisfeiler-Lehman (WL) kernels to aggregate\nmulti-hop neighborhood information. In this work, we propose a Higher Order\nPropagation Framework, HOPF, which provides an iterative inference mechanism\nfor these powerful differentiable kernels. Such a combination of classical\niterative inference mechanism with recent differentiable kernels allows the\nframework to learn graph convolutional filters that simultaneously exploit the\nattribute and label information available in the neighborhood. Further, these\niterative differentiable kernels can scale to larger hops beyond the memory\nlimitations of existing differentiable kernels. We also show that existing WL\nkernel-based models suffer from the problem of Node Information Morphing where\nthe information of the node is morphed or overwhelmed by the information of its\nneighbors when considering multiple hops. To address this, we propose a\nspecific instantiation of HOPF, called the NIP models, which preserves the node\ninformation at every propagation step. The iterative formulation of NIP models\nfurther helps in incorporating distant hop information concisely as summaries\nof the inferred labels. We do an extensive evaluation across 11 datasets from\ndifferent domains. We show that existing CC models do not provide consistent\nperformance across datasets, while the proposed NIP model with iterative\ninference is more robust.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 11:28:10 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 07:23:02 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 09:50:35 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2018 16:40:11 GMT"}, {"version": "v5", "created": "Fri, 9 Nov 2018 20:12:19 GMT"}, {"version": "v6", "created": "Tue, 13 Nov 2018 11:26:31 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Vijayan", "Priyesh", ""], ["Chandak", "Yash", ""], ["Khapra", "Mitesh M.", ""], ["Parthasarathy", "Srinivasan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1805.12462", "submitter": "Eitan Richardson", "authors": "Eitan Richardson and Yair Weiss", "title": "On GANs and GMMs", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A longstanding problem in machine learning is to find unsupervised methods\nthat can learn the statistical structure of high dimensional signals. In recent\nyears, GANs have gained much attention as a possible solution to the problem,\nand in particular have shown the ability to generate remarkably realistic high\nresolution sampled images. At the same time, many authors have pointed out that\nGANs may fail to model the full distribution (\"mode collapse\") and that using\nthe learned models for anything other than generating samples may be very\ndifficult. In this paper, we examine the utility of GANs in learning\nstatistical models of images by comparing them to perhaps the simplest\nstatistical model, the Gaussian Mixture Model. First, we present a simple\nmethod to evaluate generative models based on relative proportions of samples\nthat fall into predetermined bins. Unlike previous automatic methods for\nevaluating models, our method does not rely on an additional neural network nor\ndoes it require approximating intractable computations. Second, we compare the\nperformance of GANs to GMMs trained on the same datasets. While GMMs have\npreviously been shown to be successful in modeling small patches of images, we\nshow how to train them on full sized images despite the high dimensionality.\nOur results show that GMMs can generate realistic samples (although less sharp\nthan those of GANs) but also capture the full distribution, which GANs fail to\ndo. Furthermore, GMMs allow efficient inference and explicit representation of\nthe underlying statistical structure. Finally, we discuss how GMMs can be used\nto generate sharp images.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 13:37:59 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 18:58:50 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Richardson", "Eitan", ""], ["Weiss", "Yair", ""]]}, {"id": "1805.12472", "submitter": "Uri Hadar", "authors": "Uri Hadar and Ofer Shayevitz", "title": "Distributed Estimation of Gaussian Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG eess.SP math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a distributed estimation problem in which two remotely located\nparties, Alice and Bob, observe an unlimited number of i.i.d. samples\ncorresponding to two different parts of a random vector. Alice can send $k$\nbits on average to Bob, who in turn wants to estimate the cross-correlation\nmatrix between the two parts of the vector. In the case where the parties\nobserve jointly Gaussian scalar random variables with an unknown correlation\n$\\rho$, we obtain two constructive and simple unbiased estimators attaining a\nvariance of $(1-\\rho^2)/(2k\\ln 2)$, which coincides with a known but\nnon-constructive random coding result of Zhang and Berger. We extend our\napproach to the vector Gaussian case, which has not been treated before, and\nconstruct an estimator that is uniformly better than the scalar estimator\napplied separately to each of the correlations. We then show that the Gaussian\nperformance can essentially be attained even when the distribution is\ncompletely unknown. This in particular implies that in the general problem of\ndistributed correlation estimation, the variance can decay at least as $O(1/k)$\nwith the number of transmitted bits. This behavior, however, is not tight: we\ngive an example of a rich family of distributions for which local samples\nreveal essentially nothing about the correlations, and where a slightly\nmodified estimator attains a variance of $2^{-\\Omega(k)}$.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 13:52:23 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 13:44:28 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Hadar", "Uri", ""], ["Shayevitz", "Ofer", ""]]}, {"id": "1805.12487", "submitter": "Seong Joon Oh", "authors": "Edgar Tretschk, Seong Joon Oh, Mario Fritz", "title": "Sequential Attacks on Agents for Long-Term Adversarial Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has advanced greatly in the past few years with\nthe employment of effective deep neural networks (DNNs) on the policy networks.\nWith the great effectiveness came serious vulnerability issues with DNNs that\nsmall adversarial perturbations on the input can change the output of the\nnetwork. Several works have pointed out that learned agents with a DNN policy\nnetwork can be manipulated against achieving the original task through a\nsequence of small perturbations on the input states. In this paper, we\ndemonstrate furthermore that it is also possible to impose an arbitrary\nadversarial reward on the victim policy network through a sequence of attacks.\nOur method involves the latest adversarial attack technique, Adversarial\nTransformer Network (ATN), that learns to generate the attack and is easy to\nintegrate into the policy network. As a result of our attack, the victim agent\nis misguided to optimise for the adversarial reward over time. Our results\nexpose serious security threats for RL applications in safety-critical systems\nincluding drones, medical analysis, and self-driving cars.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 14:22:09 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 17:31:14 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Tretschk", "Edgar", ""], ["Oh", "Seong Joon", ""], ["Fritz", "Mario", ""]]}, {"id": "1805.12507", "submitter": "Chuanhou Gao", "authors": "Shaohan Chen, and Chuanhou Gao", "title": "Asymptotic performance of regularized multi-task learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes asymptotic performance of a regularized multi-task\nlearning model where task parameters are optimized jointly. If tasks are\nclosely related, empirical work suggests multi-task learning models to\noutperform single-task ones in finite sample cases. As data size grows\nindefinitely, we show the learned multi-classifier to optimize an average\nmisclassification error function which depicts the risk of applying multi-task\nlearning algorithm to making decisions. This technique conclusion demonstrates\nthe regularized multi-task learning model to be able to produce reliable\ndecision rule for each task in the sense that it will asymptotically converge\nto the corresponding Bayes rule. Also, we find the interaction effect between\ntasks vanishes as data size growing indefinitely, which is quite different from\nthe behavior in finite sample cases.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:10:58 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Chen", "Shaohan", ""], ["Gao", "Chuanhou", ""]]}, {"id": "1805.12511", "submitter": "Amin Rasekh", "authors": "Sarin E. Chandy, Amin Rasekh, Zachary A. Barker, M. Ehsan Shafiee", "title": "Cyberattack Detection using Deep Generative Models with Variational\n  Inference", "comments": null, "journal-ref": "Journal of Water Resources Planning and Management 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a rise in the frequency and intensity of\ncyberattacks targeted at critical infrastructure systems. This study designs a\nversatile, data-driven cyberattack detection platform for infrastructure\nsystems cybersecurity, with a special demonstration in water sector. A deep\ngenerative model with variational inference autonomously learns normal system\nbehavior and detects attacks as they occur. The model can process the natural\ndata in its raw form and automatically discover and learn its representations,\nhence augmenting system knowledge discovery and reducing the need for laborious\nhuman engineering and domain expertise. The proposed model is applied to a\nsimulated cyberattack detection problem involving a drinking water distribution\nsystem subject to programmable logic controller hacks, malicious actuator\nactivation, and deception attacks. The model is only provided with observations\nof the system, such as pump pressure and tank water level reads, and is blind\nto the internal structures and workings of the water distribution system. The\nsimulated attacks are manifested in the model's generated reproduction\nprobability plot, indicating its ability to discern the attacks. There is,\nhowever, need for improvements in reducing false alarms, especially by\noptimizing detection thresholds. Altogether, the results indicate ability of\nthe model in distinguishing attacks and their repercussions from normal system\noperation in water distribution systems, and the promise it holds for\ncyberattack detection in other domains.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:21:52 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Chandy", "Sarin E.", ""], ["Rasekh", "Amin", ""], ["Barker", "Zachary A.", ""], ["Shafiee", "M. Ehsan", ""]]}, {"id": "1805.12514", "submitter": "Eric Wong", "authors": "Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, J. Zico Kolter", "title": "Scaling provable adversarial defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has developed methods for learning deep network classifiers that\nare provably robust to norm-bounded adversarial perturbation; however, these\nmethods are currently only possible for relatively small feedforward networks.\nIn this paper, in an effort to scale these approaches to substantially larger\nmodels, we extend previous work in three main directions. First, we present a\ntechnique for extending these training procedures to much more general\nnetworks, with skip connections (such as ResNets) and general nonlinearities;\nthe approach is fully modular, and can be implemented automatically (analogous\nto automatic differentiation). Second, in the specific case of $\\ell_\\infty$\nadversarial perturbations and networks with ReLU nonlinearities, we adopt a\nnonlinear random projection for training, which scales linearly in the number\nof hidden units (previous approaches scaled quadratically). Third, we show how\nto further improve robust error through cascade models. On both MNIST and CIFAR\ndata sets, we train classifiers that improve substantially on the state of the\nart in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST\n(with $\\ell_\\infty$ perturbations of $\\epsilon=0.1$), and from 80% to 36.4% on\nCIFAR (with $\\ell_\\infty$ perturbations of $\\epsilon=2/255$). Code for all\nexperiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial/.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:25:10 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 19:53:03 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wong", "Eric", ""], ["Schmidt", "Frank R.", ""], ["Metzen", "Jan Hendrik", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1805.12528", "submitter": "Priyesh Vijayan", "authors": "Priyesh Vijayan, Yash Chandak, Mitesh M. Khapra, Srinivasan\n  Parthasarathy, Balaraman Ravindran", "title": "Fusion Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised node classification in attributed graphs, i.e., graphs with\nnode features, involves learning to classify unlabeled nodes given a partially\nlabeled graph. Label predictions are made by jointly modeling the node and its'\nneighborhood features. State-of-the-art models for node classification on such\nattributed graphs use differentiable recursive functions that enable\naggregation and filtering of neighborhood information from multiple hops. In\nthis work, we analyze the representation capacity of these models to regulate\ninformation from multiple hops independently. From our analysis, we conclude\nthat these models despite being powerful, have limited representation capacity\nto capture multi-hop neighborhood information effectively. Further, we also\npropose a mathematically motivated, yet simple extension to existing graph\nconvolutional networks (GCNs) which has improved representation capacity. We\nextensively evaluate the proposed model, F-GCN on eight popular datasets from\ndifferent domains. F-GCN outperforms the state-of-the-art models for\nsemi-supervised learning on six datasets while being extremely competitive on\nthe other two.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:57:33 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 06:50:50 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 05:24:06 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2018 14:38:50 GMT"}, {"version": "v5", "created": "Fri, 21 Sep 2018 16:35:53 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Vijayan", "Priyesh", ""], ["Chandak", "Yash", ""], ["Khapra", "Mitesh M.", ""], ["Parthasarathy", "Srinivasan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1805.12529", "submitter": "Anna Ma", "authors": "Saiprasad Ravishankar, Anna Ma, Deanna Needell", "title": "Analysis of Fast Structured Dictionary Learning", "comments": "This article has been accepted for publication in Information and\n  Inference Published by Oxford University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-based models and techniques have been exploited in many signal\nprocessing and imaging applications. Data-driven methods based on dictionary\nand sparsifying transform learning enable learning rich image features from\ndata, and can outperform analytical models. In particular, alternating\noptimization algorithms have been popular for learning such models. In this\nwork, we focus on alternating minimization for a specific structured unitary\nsparsifying operator learning problem, and provide a convergence analysis.\nWhile the algorithm converges to the critical points of the problem generally,\nour analysis establishes under mild assumptions, the local linear convergence\nof the algorithm to the underlying sparsifying model of the data. Analysis and\nnumerical simulations show that our assumptions hold for standard probabilistic\ndata models. In practice, the algorithm is robust to initialization.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:59:14 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 19:23:33 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 22:09:38 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Ma", "Anna", ""], ["Needell", "Deanna", ""]]}, {"id": "1805.12547", "submitter": "Shaowu Pan", "authors": "Shaowu Pan, Karthik Duraisamy", "title": "Long-time predictive modeling of nonlinear dynamical systems using\n  neural networks", "comments": "30 pages. Complexity, 2018", "journal-ref": null, "doi": "10.1155/2018/4801012", "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of feedforward neural networks (FNN) to develop models of\nnonlinear dynamical systems from data. Emphasis is placed on predictions at\nlong times, with limited data availability. Inspired by global stability\nanalysis, and the observation of the strong correlation between the local error\nand the maximum singular value of the Jacobian of the ANN, we introduce\nJacobian regularization in the loss function. This regularization suppresses\nthe sensitivity of the prediction to the local error and is shown to improve\naccuracy and robustness. Comparison between the proposed approach and sparse\npolynomial regression is presented in numerical examples ranging from simple\nODE systems to nonlinear PDE systems including vortex shedding behind a\ncylinder, and instability-driven buoyant mixing flow. Furthermore, limitations\nof feedforward neural networks are highlighted, especially when the training\ndata does not include a low dimensional attractor. Strategies of data\naugmentation are presented as remedies to address these issues to a certain\nextent.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 16:36:26 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 04:02:14 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 05:35:36 GMT"}, {"version": "v4", "created": "Mon, 10 Sep 2018 00:06:27 GMT"}, {"version": "v5", "created": "Wed, 14 Nov 2018 19:55:44 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Pan", "Shaowu", ""], ["Duraisamy", "Karthik", ""]]}, {"id": "1805.12549", "submitter": "Weizhe Hua", "authors": "Weizhe Hua, Yuan Zhou, Christopher De Sa, Zhiru Zhang, and G. Edward\n  Suh", "title": "Channel Gating Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces channel gating, a dynamic, fine-grained, and\nhardware-efficient pruning scheme to reduce the computation cost for\nconvolutional neural networks (CNNs). Channel gating identifies regions in the\nfeatures that contribute less to the classification result, and skips the\ncomputation on a subset of the input channels for these ineffective regions.\nUnlike static network pruning, channel gating optimizes CNN inference at\nrun-time by exploiting input-specific characteristics, which allows\nsubstantially reducing the compute cost with almost no accuracy loss. We\nexperimentally show that applying channel gating in state-of-the-art networks\nachieves 2.7-8.0$\\times$ reduction in floating-point operations (FLOPs) and\n2.0-4.4$\\times$ reduction in off-chip memory accesses with a minimal accuracy\nloss on CIFAR-10. Combining our method with knowledge distillation reduces the\ncompute cost of ResNet-18 by 2.6$\\times$ without accuracy drop on ImageNet. We\nfurther demonstrate that channel gating can be realized in hardware\nefficiently. Our approach exhibits sparsity patterns that are well-suited to\ndense systolic arrays with minimal additional hardware. We have designed an\naccelerator for channel gating networks, which can be implemented using either\nFPGAs or ASICs. Running a quantized ResNet-18 model for ImageNet, our\naccelerator achieves an encouraging speedup of 2.4$\\times$ on average, with a\ntheoretical FLOP reduction of 2.8$\\times$.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 20:11:56 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 23:53:50 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Hua", "Weizhe", ""], ["Zhou", "Yuan", ""], ["De Sa", "Christopher", ""], ["Zhang", "Zhiru", ""], ["Suh", "G. Edward", ""]]}, {"id": "1805.12573", "submitter": "Kelvin Xu", "authors": "Kelvin Xu, Ellis Ratner, Anca Dragan, Sergey Levine, Chelsea Finn", "title": "Learning a Prior over Intent via Meta-Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge for the practical application of reinforcement\nlearning in the real world is the need to specify an oracle reward function\nthat correctly defines a task. Inverse reinforcement learning (IRL) seeks to\navoid this challenge by instead inferring a reward function from expert\nbehavior. While appealing, it can be impractically expensive to collect\ndatasets of demonstrations that cover the variation common in the real world\n(e.g. opening any type of door). Thus in practice, IRL must commonly be\nperformed with only a limited set of demonstrations where it can be exceedingly\ndifficult to unambiguously recover a reward function. In this work, we exploit\nthe insight that demonstrations from other tasks can be used to constrain the\nset of possible reward functions by learning a \"prior\" that is specifically\noptimized for the ability to infer expressive reward functions from limited\nnumbers of demonstrations. We demonstrate that our method can efficiently\nrecover rewards from images for novel tasks and provide intuition as to how our\napproach is analogous to learning a prior.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 17:29:25 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 16:37:36 GMT"}, {"version": "v3", "created": "Wed, 10 Oct 2018 18:34:48 GMT"}, {"version": "v4", "created": "Tue, 29 Jan 2019 18:55:05 GMT"}, {"version": "v5", "created": "Mon, 14 Oct 2019 19:55:15 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Xu", "Kelvin", ""], ["Ratner", "Ellis", ""], ["Dragan", "Anca", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}]