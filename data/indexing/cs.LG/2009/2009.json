[{"id": "2009.00003", "submitter": "Andrew Allmon", "authors": "Andrew G. Allmon, J.S. Marron, and Michael G. Hudgens", "title": "diproperm: An R Package for the DiProPerm Test", "comments": "Package located at https://github.com/allmondrew/diproperm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional low sample size (HDLSS) data sets emerge frequently in many\nbiomedical applications. A common task for analyzing HDLSS data is to assign\ndata to the correct class using a classifier. Classifiers which use two labels\nand a linear combination of features are known as binary linear classifiers.\nThe direction-projection-permutation (DiProPerm) test was developed for testing\nthe difference of two high-dimensional distributions induced by a binary linear\nclassifier. This paper discusses the key components of the DiProPerm test,\nintroduces the diproperm R package, and demonstrates the package on a\nreal-world data set.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:14:26 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Allmon", "Andrew G.", ""], ["Marron", "J. S.", ""], ["Hudgens", "Michael G.", ""]]}, {"id": "2009.00038", "submitter": "Panagiota Birmpa", "authors": "Panagiota Birmpa, Markos A. Katsoulakis", "title": "Uncertainty quantification for Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-based uncertainty quantification method for general\nMarkov Random Fields. Markov Random Fields (MRF) are structured, probabilistic\ngraphical models over undirected graphs, and provide a fundamental unifying\nmodeling tool for statistical mechanics, probabilistic machine learning, and\nartificial intelligence. Typically MRFs are complex and high-dimensional with\nnodes and edges (connections) built in a modular fashion from simpler,\nlow-dimensional probabilistic models and their local connections; in turn, this\nmodularity allows to incorporate available data to MRFs and efficiently\nsimulate them by leveraging their graph-theoretic structure. Learning graphical\nmodels from data and/or constructing them from physical modeling and\nconstraints necessarily involves uncertainties inherited from data, modeling\nchoices, or numerical approximations. These uncertainties in the MRF can be\nmanifested either in the graph structure or the probability distribution\nfunctions, and necessarily will propagate in predictions for quantities of\ninterest. Here we quantify such uncertainties using tight, information based\nbounds on the predictions of quantities of interest; these bounds take\nadvantage of the graphical structure of MRFs and are capable of handling the\ninherent high-dimensionality of such graphical models. We demonstrate our\nmethods in MRFs for medical diagnostics and statistical mechanics models. In\nthe latter, we develop uncertainty quantification bounds for finite size\neffects and phase diagrams, which constitute two of the typical predictions\ngoals of statistical mechanics modeling.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 18:07:24 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 02:18:47 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 04:35:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Birmpa", "Panagiota", ""], ["Katsoulakis", "Markos A.", ""]]}, {"id": "2009.00089", "submitter": "Dai Feng", "authors": "Dai Feng and Richard Baumgartner", "title": "Random Forest (RF) Kernel for Regression, Classification and Survival", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breiman's random forest (RF) can be interpreted as an implicit kernel\ngenerator,where the ensuing proximity matrix represents the data-driven RF\nkernel. Kernel perspective on the RF has been used to develop a principled\nframework for theoretical investigation of its statistical properties. However,\npractical utility of the links between kernels and the RF has not been widely\nexplored and systematically evaluated.Focus of our work is investigation of the\ninterplay between kernel methods and the RF. We elucidate the performance and\nproperties of the data driven RF kernels used by regularized linear models in a\ncomprehensive simulation study comprising of continuous, binary and survival\ntargets. We show that for continuous and survival targets, the RF kernels are\ncompetitive to RF in higher dimensional scenarios with larger number of noisy\nfeatures. For the binary target, the RF kernel and RF exhibit comparable\nperformance. As the RF kernel asymptotically converges to the Laplace kernel,\nwe included it in our evaluation. For most simulation setups, the RF and\nRFkernel outperformed the Laplace kernel. Nevertheless, in some cases the\nLaplace kernel was competitive, showing its potential value for applications.\nWe also provide the results from real life data sets for the regression,\nclassification and survival to illustrate how these insights may be leveraged\nin practice.Finally, we discuss further extensions of the RF kernels in the\ncontext of interpretable prototype and landmarking classification, regression\nand survival. We outline future line of research for kernels furnished by\nBayesian counterparts of the RF.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 20:21:27 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Feng", "Dai", ""], ["Baumgartner", "Richard", ""]]}, {"id": "2009.00093", "submitter": "Zheda Mai", "authors": "Dongsub Shim, Zheda Mai, Jihwan Jeong, Scott Sanner, Hyunwoo Kim,\n  Jongseong Jang", "title": "Online Class-Incremental Continual Learning with Adversarial Shapley\n  Value", "comments": "Proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As image-based deep learning becomes pervasive on every device, from cell\nphones to smart watches, there is a growing need to develop methods that\ncontinually learn from data while minimizing memory footprint and power\nconsumption. While memory replay techniques have shown exceptional promise for\nthis task of continual learning, the best method for selecting which buffered\nimages to replay is still an open question. In this paper, we specifically\nfocus on the online class-incremental setting where a model needs to learn new\nclasses continually from an online data stream. To this end, we contribute a\nnovel Adversarial Shapley value scoring method that scores memory data samples\naccording to their ability to preserve latent decision boundaries for\npreviously observed classes (to maintain learning stability and avoid\nforgetting) while interfering with latent decision boundaries of current\nclasses being learned (to encourage plasticity and optimal learning of new\nclass boundaries). Overall, we observe that our proposed ASER method provides\ncompetitive or improved performance compared to state-of-the-art replay-based\ncontinual learning methods on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 20:52:27 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 07:27:00 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 03:05:46 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 20:03:10 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Shim", "Dongsub", ""], ["Mai", "Zheda", ""], ["Jeong", "Jihwan", ""], ["Sanner", "Scott", ""], ["Kim", "Hyunwoo", ""], ["Jang", "Jongseong", ""]]}, {"id": "2009.00096", "submitter": "Dongjie Wang", "authors": "Dongjie Wang, Yan Yang, Shangming Ning", "title": "DeepSTCL: A Deep Spatio-temporal ConvLSTM for Travel Demand Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban resource scheduling is an important part of the development of a smart\ncity, and transportation resources are the main components of urban resources.\nCurrently, a series of problems with transportation resources such as\nunbalanced distribution and road congestion disrupt the scheduling discipline.\nTherefore, it is significant to predict travel demand for urban resource\ndispatching. Previously, the traditional time series models were used to\nforecast travel demand, such as AR, ARIMA and so on. However, the prediction\nefficiency of these methods is poor and the training time is too long. In order\nto improve the performance, deep learning is used to assist prediction. But\nmost of the deep learning methods only utilize temporal dependence or spatial\ndependence of data in the forecasting process. To address these limitations, a\nnovel deep learning traffic demand forecasting framework which based on Deep\nSpatio-Temporal ConvLSTM is proposed in this paper. In order to evaluate the\nperformance of the framework, an end-to-end deep learning system is designed\nand a real dataset is used. Furthermore, the proposed method can capture\ntemporal dependence and spatial dependence simultaneously. The closeness,\nperiod and trend components of spatio-temporal data are used in three predicted\nbranches. These branches have the same network structures, but do not share\nweights. Then a linear fusion method is used to get the final result. Finally,\nthe experimental results on DIDI order dataset of Chengdu demonstrate that our\nmethod outperforms traditional models with accuracy and speed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 13:33:31 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Dongjie", ""], ["Yang", "Yan", ""], ["Ning", "Shangming", ""]]}, {"id": "2009.00097", "submitter": "Linjun Zhou", "authors": "Linjun Zhou, Peng Cui, Yinan Jiang, Shiqiang Yang", "title": "Adversarial Eigen Attack on Black-Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box adversarial attack has attracted a lot of research interests for\nits practical use in AI safety. Compared with the white-box attack, a black-box\nsetting is more difficult for less available information related to the\nattacked model and the additional constraint on the query budget. A general way\nto improve the attack efficiency is to draw support from a pre-trained\ntransferable white-box model. In this paper, we propose a novel setting of\ntransferable black-box attack: attackers may use external information from a\npre-trained model with available network parameters, however, different from\nprevious studies, no additional training data is permitted to further change or\ntune the pre-trained model. To this end, we further propose a new algorithm,\nEigenBA to tackle this problem. Our method aims to explore more gradient\ninformation of the black-box model, and promote the attack efficiency, while\nkeeping the perturbation to the original attacked image small, by leveraging\nthe Jacobian matrix of the pre-trained white-box model. We show the optimal\nperturbations are closely related to the right singular vectors of the Jacobian\nmatrix. Further experiments on ImageNet and CIFAR-10 show that even the\nunlearnable pre-trained white-box model could also significantly boost the\nefficiency of the black-box attack and our proposed method could further\nimprove the attack efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:37:43 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zhou", "Linjun", ""], ["Cui", "Peng", ""], ["Jiang", "Yinan", ""], ["Yang", "Shiqiang", ""]]}, {"id": "2009.00100", "submitter": "Young-Min Song", "authors": "Young-min Song, Young-chul Yoon, Kwangjin Yoon, Moongu Jeon,\n  Seong-Whan Lee, Witold Pedrycz", "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and\n  Mask-based Affinity Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:06:22 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 10:55:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Song", "Young-min", ""], ["Yoon", "Young-chul", ""], ["Yoon", "Kwangjin", ""], ["Jeon", "Moongu", ""], ["Lee", "Seong-Whan", ""], ["Pedrycz", "Witold", ""]]}, {"id": "2009.00104", "submitter": "William Falcon", "authors": "William Falcon, Kyunghyun Cho", "title": "A Framework For Contrastive Self-Supervised Learning And Designing A New\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive self-supervised learning (CSL) is an approach to learn useful\nrepresentations by solving a pretext task that selects and compares anchor,\nnegative and positive (APN) features from an unlabeled dataset. We present a\nconceptual framework that characterizes CSL approaches in five aspects (1) data\naugmentation pipeline, (2) encoder selection, (3) representation extraction,\n(4) similarity measure, and (5) loss function. We analyze three leading CSL\napproaches--AMDIM, CPC, and SimCLR--, and show that despite different\nmotivations, they are special cases under this framework. We show the utility\nof our framework by designing Yet Another DIM (YADIM) which achieves\ncompetitive results on CIFAR-10, STL-10 and ImageNet, and is more robust to the\nchoice of encoder and the representation extraction strategy. To support\nongoing CSL research, we release the PyTorch implementation of this conceptual\nframework along with standardized implementations of AMDIM, CPC (V2), SimCLR,\nBYOL, Moco (V2) and YADIM.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:11:48 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Falcon", "William", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2009.00105", "submitter": "Manal Eltanab", "authors": "Manal El Tanab and Walaa Hamouda", "title": "Fast Grant Learning-Based Approach for Machine Type Communications with\n  NOMA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a non-orthogonal multiple access (NOMA)-based\ncommunication framework that allows machine type devices (MTDs) to access the\nnetwork while avoiding congestion. The proposed technique is a 2-step mechanism\nthat first employs fast uplink grant to schedule the devices without sending a\nrequest to the base station (BS). Secondly, NOMA pairing is employed in a\ndistributed manner to reduce signaling overhead. Due to the limited capability\nof information gathering at the BS in massive scenarios, learning techniques\nare best fit for such problems. Therefore, multi-arm bandit learning is adopted\nto schedule the fast grant MTDs. Then, constrained random NOMA pairing is\nproposed that assists in decoupling the two main challenges of fast uplink\ngrant schemes namely, active set prediction and optimal scheduling. Using NOMA,\nwe were able to significantly reduce the resource wastage due to prediction\nerrors. Additionally, the results show that the proposed scheme can easily\nattain the impractical optimal OMA performance, in terms of the achievable\nrewards, at an affordable complexity.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:14:21 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Tanab", "Manal El", ""], ["Hamouda", "Walaa", ""]]}, {"id": "2009.00131", "submitter": "Prasanth Shyamsundar", "authors": "Konstantin T. Matchev, Prasanth Shyamsundar", "title": "InClass Nets: Independent Classifier Networks for Nonparametric\n  Estimation of Conditional Independence Mixture Models and Unsupervised\n  Classification", "comments": "46 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM hep-ph physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new machine-learning-based approach, which we call the\nIndependent Classifier networks (InClass nets) technique, for the\nnonparameteric estimation of conditional independence mixture models (CIMMs).\nWe approach the estimation of a CIMM as a multi-class classification problem,\nsince dividing the dataset into different categories naturally leads to the\nestimation of the mixture model. InClass nets consist of multiple independent\nclassifier neural networks (NNs), each of which handles one of the variates of\nthe CIMM. Fitting the CIMM to the data is performed by simultaneously training\nthe individual NNs using suitable cost functions. The ability of NNs to\napproximate arbitrary functions makes our technique nonparametric. Further\nleveraging the power of NNs, we allow the conditionally independent variates of\nthe model to be individually high-dimensional, which is the main advantage of\nour technique over existing non-machine-learning-based approaches. We derive\nsome new results on the nonparametric identifiability of bivariate CIMMs, in\nthe form of a necessary and a (different) sufficient condition for a bivariate\nCIMM to be identifiable. We provide a public implementation of InClass nets as\na Python package called RainDancesVI and validate our InClass nets technique\nwith several worked out examples. Our method also has applications in\nunsupervised and semi-supervised classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 22:24:09 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Matchev", "Konstantin T.", ""], ["Shyamsundar", "Prasanth", ""]]}, {"id": "2009.00133", "submitter": "Siqi Sun", "authors": "Siqi Sun", "title": "Unsupervised and Supervised Structure Learning for Protein Contact\n  Prediction", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein contacts provide key information for the understanding of protein\nstructure and function, and therefore contact prediction from sequences is an\nimportant problem. Recent research shows that some correctly predicted\nlong-range contacts could help topology-level structure modeling. Thus, contact\nprediction and contact-assisted protein folding also proves the importance of\nthis problem. In this thesis, I will briefly introduce the extant related work,\nthen show how to establish the contact prediction through unsupervised\ngraphical models with topology constraints. Further, I will explain how to use\nthe supervised deep learning methods to further boost the accuracy of contact\nprediction. Finally, I will propose a scoring system called diversity score to\nmeasure the novelty of contact predictions, as well as an algorithm that\npredicts contacts with respect to the new scoring system.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 22:37:16 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Sun", "Siqi", ""]]}, {"id": "2009.00142", "submitter": "Pan Li", "authors": "Pan Li, Yanbang Wang, Hongwei Wang, Jure Leskovec", "title": "Distance Encoding: Design Provably More Powerful Neural Networks for\n  Graph Representation Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of sets of nodes in a graph is crucial for\napplications ranging from node-role discovery to link prediction and molecule\nclassification. Graph Neural Networks (GNNs) have achieved great success in\ngraph representation learning. However, expressive power of GNNs is limited by\nthe 1-Weisfeiler-Lehman (WL) test and thus GNNs generate identical\nrepresentations for graph substructures that may in fact be very different.\nMore powerful GNNs, proposed recently by mimicking higher-order-WL tests, only\nfocus on representing entire graphs and they are computationally inefficient as\nthey cannot utilize sparsity of the underlying graph. Here we propose and\nmathematically analyze a general class of structure-related features, termed\nDistance Encoding (DE). DE assists GNNs in representing any set of nodes, while\nproviding strictly more expressive power than the 1-WL test. DE captures the\ndistance between the node set whose representation is to be learned and each\nnode in the graph. To capture the distance DE can apply various graph-distance\nmeasures such as shortest path distance or generalized PageRank scores. We\npropose two ways for GNNs to use DEs (1) as extra node features, and (2) as\ncontrollers of message aggregation in GNNs. Both approaches can utilize the\nsparse structure of the underlying graph, which leads to computational\nefficiency and scalability. We also prove that DE can distinguish node sets\nembedded in almost all regular graphs where traditional GNNs always fail. We\nevaluate DE on three tasks over six real networks: structural role prediction,\nlink prediction, and triangle prediction. Results show that our models\noutperform GNNs without DE by up-to 15\\% in accuracy and AUROC. Furthermore,\nour models also significantly outperform other state-of-the-art methods\nespecially designed for the above tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 23:15:40 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 15:18:27 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 15:46:32 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 17:11:07 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Li", "Pan", ""], ["Wang", "Yanbang", ""], ["Wang", "Hongwei", ""], ["Leskovec", "Jure", ""]]}, {"id": "2009.00149", "submitter": "Timo Bolkart", "authors": "Partha Ghosh, Pravir Singh Gupta, Roy Uziel, Anurag Ranjan, Michael\n  Black, Timo Bolkart", "title": "GIF: Generative Interpretable Faces", "comments": "International Conference on 3D Vision (3DV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo-realistic visualization and animation of expressive human faces have\nbeen a long standing challenge. 3D face modeling methods provide parametric\ncontrol but generates unrealistic images, on the other hand, generative 2D\nmodels like GANs (Generative Adversarial Networks) output photo-realistic face\nimages, but lack explicit control. Recent methods gain partial control, either\nby attempting to disentangle different factors in an unsupervised manner, or by\nadding control post hoc to a pre-trained model. Unconditional GANs, however,\nmay entangle factors that are hard to undo later. We condition our generative\nmodel on pre-defined control parameters to encourage disentanglement in the\ngeneration process. Specifically, we condition StyleGAN2 on FLAME, a generative\n3D face model. While conditioning on FLAME parameters yields unsatisfactory\nresults, we find that conditioning on rendered FLAME geometry and photometric\ndetails works well. This gives us a generative 2D face model named GIF\n(Generative Interpretable Faces) that offers FLAME's parametric control. Here,\ninterpretable refers to the semantic meaning of different parameters. Given\nFLAME parameters for shape, pose, expressions, parameters for appearance,\nlighting, and an additional style vector, GIF outputs photo-realistic face\nimages. We perform an AMT based perceptual study to quantitatively and\nqualitatively evaluate how well GIF follows its conditioning. The code, data,\nand trained model are publicly available for research purposes at\nhttp://gif.is.tue.mpg.de.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 23:40:26 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 13:37:01 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ghosh", "Partha", ""], ["Gupta", "Pravir Singh", ""], ["Uziel", "Roy", ""], ["Ranjan", "Anurag", ""], ["Black", "Michael", ""], ["Bolkart", "Timo", ""]]}, {"id": "2009.00155", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Xiangyu Yue, Shanghang Zhang, Bo Li, Han Zhao, Bichen\n  Wu, Ravi Krishna, Joseph E. Gonzalez, Alberto L. Sangiovanni-Vincentelli,\n  Sanjit A. Seshia, Kurt Keutzer", "title": "A Review of Single-Source Deep Unsupervised Visual Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale labeled training datasets have enabled deep neural networks to\nexcel across a wide range of benchmark vision tasks. However, in many\napplications, it is prohibitively expensive and time-consuming to obtain large\nquantities of labeled data. To cope with limited labeled training data, many\nhave attempted to directly apply models trained on a large-scale labeled source\ndomain to another sparsely labeled or unlabeled target domain. Unfortunately,\ndirect transfer across domains often performs poorly due to the presence of\ndomain shift or dataset bias. Domain adaptation is a machine learning paradigm\nthat aims to learn a model from a source domain that can perform well on a\ndifferent (but related) target domain. In this paper, we review the latest\nsingle-source deep unsupervised domain adaptation methods focused on visual\ntasks and discuss new perspectives for future research. We begin with the\ndefinitions of different domain adaptation strategies and the descriptions of\nexisting benchmark datasets. We then summarize and compare different categories\nof single-source unsupervised domain adaptation methods, including\ndiscrepancy-based methods, adversarial discriminative methods, adversarial\ngenerative methods, and self-supervision-based methods. Finally, we discuss\nfuture research directions with challenges and possible solutions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 00:06:50 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 06:35:19 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 00:46:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Sicheng", ""], ["Yue", "Xiangyu", ""], ["Zhang", "Shanghang", ""], ["Li", "Bo", ""], ["Zhao", "Han", ""], ["Wu", "Bichen", ""], ["Krishna", "Ravi", ""], ["Gonzalez", "Joseph E.", ""], ["Sangiovanni-Vincentelli", "Alberto L.", ""], ["Seshia", "Sanjit A.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2009.00162", "submitter": "Yue Guan", "authors": "Yue Guan, Qifan Zhang, Panagiotis Tsiotras", "title": "Learning Nash Equilibria in Zero-Sum Stochastic Games via\n  Entropy-Regularized Policy Approximation", "comments": "Accepted at IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of policy approximations to reduce the computational cost\nof learning Nash equilibria in zero-sum stochastic games. We propose a new\nQ-learning type algorithm that uses a sequence of entropy-regularized soft\npolicies to approximate the Nash policy during the Q-function updates. We prove\nthat under certain conditions, by updating the regularized Q-function, the\nalgorithm converges to a Nash equilibrium. We also demonstrate the proposed\nalgorithm's ability to transfer previous training experiences, enabling the\nagents to adapt quickly to new environments. We provide a dynamic\nhyper-parameter scheduling scheme to further expedite convergence. Empirical\nresults applied to a number of stochastic games verify that the proposed\nalgorithm converges to the Nash equilibrium, while exhibiting a major speed-up\nover existing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:03:44 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 04:26:01 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Guan", "Yue", ""], ["Zhang", "Qifan", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "2009.00163", "submitter": "Binghui Wang", "authors": "Houxiang Fan, Binghui Wang, Pan Zhou, Ang Li, Meng Pang, Zichuan Xu,\n  Cai Fu, Hai Li, Yiran Chen", "title": "Reinforcement Learning-based Black-Box Evasion Attacks to Link\n  Prediction in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in dynamic graphs (LPDG) is an important research problem\nthat has diverse applications such as online recommendations, studies on\ndisease contagion, organizational studies, etc. Various LPDG methods based on\ngraph embedding and graph neural networks have been recently proposed and\nachieved state-of-the-art performance. In this paper, we study the\nvulnerability of LPDG methods and propose the first practical black-box evasion\nattack. Specifically, given a trained LPDG model, our attack aims to perturb\nthe graph structure, without knowing to model parameters, model architecture,\netc., such that the LPDG model makes as many wrong predicted links as possible.\nWe design our attack based on a stochastic policy-based RL algorithm. Moreover,\nwe evaluate our attack on three real-world graph datasets from different\napplication domains. Experimental results show that our attack is both\neffective and efficient.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:04:49 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:58:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Fan", "Houxiang", ""], ["Wang", "Binghui", ""], ["Zhou", "Pan", ""], ["Li", "Ang", ""], ["Pang", "Meng", ""], ["Xu", "Zichuan", ""], ["Fu", "Cai", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2009.00165", "submitter": "Yakun Yu", "authors": "Tong Mo, Yakun Yu, Mohammad Salameh, Di Niu, Shangling Jui", "title": "Neural Architecture Search For Keyword Spotting", "comments": "will be presented in INTERSPEECH 2020", "journal-ref": "Proc. Interspeech 2020, 1982-1986", "doi": "10.21437/Interspeech.2020-3132", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have recently become a popular solution to keyword\nspotting systems, which enable the control of smart devices via voice. In this\npaper, we apply neural architecture search to search for convolutional neural\nnetwork models that can help boost the performance of keyword spotting based on\nfeatures extracted from acoustic signals while maintaining an acceptable memory\nfootprint. Specifically, we use differentiable architecture search techniques\nto search for operators and their connections in a predefined cell search\nspace. The found cells are then scaled up in both depth and width to achieve\ncompetitive performance. We evaluated the proposed method on Google's Speech\nCommands Dataset and achieved a state-of-the-art accuracy of over 97% on the\nsetting of 12-class utterance classification commonly reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:11:41 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 04:10:58 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Mo", "Tong", ""], ["Yu", "Yakun", ""], ["Salameh", "Mohammad", ""], ["Niu", "Di", ""], ["Jui", "Shangling", ""]]}, {"id": "2009.00169", "submitter": "Yang Wang", "authors": "Yang Wang", "title": "A Mathematical Introduction to Generative Adversarial Nets (GAN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Nets (GAN) have received considerable attention since\nthe 2014 groundbreaking work by Goodfellow et al. Such attention has led to an\nexplosion in new ideas, techniques and applications of GANs. To better\nunderstand GANs we need to understand the mathematical foundation behind them.\nThis paper attempts to provide an overview of GANs from a mathematical point of\nview. Many students in mathematics may find the papers on GANs more difficulty\nto fully understand because most of them are written from computer science and\nengineer point of view. The aim of this paper is to give more mathematically\noriented students an introduction to GANs in a language that is more familiar\nto them.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:31:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Yang", ""]]}, {"id": "2009.00203", "submitter": "Binghui Wang", "authors": "Binghui Wang, Tianxiang Zhou, Minhua Lin, Pan Zhou, Ang Li, Meng Pang,\n  Cai Fu, Hai Li, Yiran Chen", "title": "Evasion Attacks to Graph Neural Networks via Influence Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved state-of-the-art performance in\nmany graph-related tasks, e.g., node classification. However, recent works show\nthat GNNs are vulnerable to evasion attacks, i.e., an attacker can slightly\nperturb the graph structure to fool GNN models. Existing evasion attacks to\nGNNs have several key drawbacks: 1) they are limited to attack two-layer GNNs;\n2) they are not efficient; or/and 3) they need to know GNN model parameters. We\naddress the above drawbacks in this paper and propose an influence-based\nevasion attack against GNNs. Specifically, we first introduce two influence\nfunctions, i.e., feature-label influence and label influence, that are defined\non GNNs and label propagation (LP), respectively. Then, we build a strong\nconnection between GNNs and LP in terms of influence. Next, we reformulate the\nevasion attack against GNNs to be related to calculating label influence on LP,\nwhich is applicable to multi-layer GNNs and does not need to know the GNN\nmodel. We also propose an efficient algorithm to calculate label influence.\nFinally, we evaluate our influence-based attack on three benchmark graph\ndatasets. Our experimental results show that, compared to state-of-the-art\nattack, our attack can achieve comparable attack performance, but has a 5-50x\nspeedup when attacking two-layer GNNs. Moreover, our attack is effective to\nattack multi-layer GNNs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 03:24:51 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:50:56 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Binghui", ""], ["Zhou", "Tianxiang", ""], ["Lin", "Minhua", ""], ["Zhou", "Pan", ""], ["Li", "Ang", ""], ["Pang", "Meng", ""], ["Fu", "Cai", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2009.00236", "submitter": "Pengzhen Ren", "authors": "Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li,\n  Xiaojiang Chen and Xin Wang", "title": "A Survey of Deep Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) attempts to maximize the performance gain of the model\nby marking the fewest samples. Deep learning (DL) is greedy for data and\nrequires a large amount of data supply to optimize massive parameters, so that\nthe model learns how to extract high-quality features. In recent years, due to\nthe rapid development of internet technology, we are in an era of information\ntorrents and we have massive amounts of data. In this way, DL has aroused\nstrong interest of researchers and has been rapidly developed. Compared with\nDL, researchers have relatively low interest in AL. This is mainly because\nbefore the rise of DL, traditional machine learning requires relatively few\nlabeled samples. Therefore, early AL is difficult to reflect the value it\ndeserves. Although DL has made breakthroughs in various fields, most of this\nsuccess is due to the publicity of the large number of existing annotation\ndatasets. However, the acquisition of a large number of high-quality annotated\ndatasets consumes a lot of manpower, which is not allowed in some fields that\nrequire high expertise, especially in the fields of speech recognition,\ninformation extraction, medical images, etc. Therefore, AL has gradually\nreceived due attention. A natural idea is whether AL can be used to reduce the\ncost of sample annotations, while retaining the powerful learning capabilities\nof DL. Therefore, deep active learning (DAL) has emerged. Although the related\nresearch has been quite abundant, it lacks a comprehensive survey of DAL. This\narticle is to fill this gap, we provide a formal classification method for the\nexisting work, and a comprehensive and systematic overview. In addition, we\nalso analyzed and summarized the development of DAL from the perspective of\napplication. Finally, we discussed the confusion and problems in DAL, and gave\nsome possible development directions for DAL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 04:28:31 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ren", "Pengzhen", ""], ["Xiao", "Yun", ""], ["Chang", "Xiaojun", ""], ["Huang", "Po-Yao", ""], ["Li", "Zhihui", ""], ["Chen", "Xiaojiang", ""], ["Wang", "Xin", ""]]}, {"id": "2009.00237", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat and Bogdan Gabrys", "title": "An in-depth comparison of methods handling mixed-attribute data for\n  general fuzzy min-max neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A general fuzzy min-max (GFMM) neural network is one of the efficient\nneuro-fuzzy systems for classification problems. However, a disadvantage of\nmost of the current learning algorithms for GFMM is that they can handle\neffectively numerical valued features only. Therefore, this paper provides some\npotential approaches to adapting GFMM learning algorithms for classification\nproblems with mixed-type or only categorical features as they are very common\nin practical applications and often carry very useful information. We will\ncompare and assess three main methods of handling datasets with mixed features,\nincluding the use of encoding methods, the combination of the GFMM model with\nother classifiers, and employing the specific learning algorithms for both\ntypes of features. The experimental results showed that the target and\nJames-Stein are appropriate categorical encoding methods for learning\nalgorithms of GFMM models, while the combination of GFMM neural networks and\ndecision trees is a flexible way to enhance the classification performance of\nGFMM models on datasets with the mixed features. The learning algorithms with\nthe mixed-type feature abilities are potential approaches to deal with\nmixed-attribute data in a natural way, but they need further improvement to\nachieve a better classification accuracy. Based on the analysis, we also\nidentify the strong and weak points of different methods and propose potential\nresearch directions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:12:22 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2009.00254", "submitter": "Sarkar Snigdha Sarathi Das", "authors": "Sarkar Snigdha Sarathi Das, Mohammed Eunus Ali, Yuan-Fang Li, Yong-Bin\n  Kang, Timos Sellis", "title": "Boosting House Price Predictions using Geo-Spatial Network Embedding", "comments": "23 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate contributes significantly to all major economies around the\nworld. In particular, house prices have a direct impact on stakeholders,\nranging from house buyers to financing companies. Thus, a plethora of\ntechniques have been developed for real estate price prediction. Most of the\nexisting techniques rely on different house features to build a variety of\nprediction models to predict house prices. Perceiving the effect of spatial\ndependence on house prices, some later works focused on introducing spatial\nregression models for improving prediction performance. However, they fail to\ntake into account the geo-spatial context of the neighborhood amenities such as\nhow close a house is to a train station, or a highly-ranked school, or a\nshopping center. Such contextual information may play a vital role in users'\ninterests in a house and thereby has a direct influence on its price. In this\npaper, we propose to leverage the concept of graph neural networks to capture\nthe geo-spatial context of the neighborhood of a house. In particular, we\npresent a novel method, the Geo-Spatial Network Embedding (GSNE), that learns\nthe embeddings of houses and various types of Points of Interest (POIs) in the\nform of multipartite networks, where the houses and the POIs are represented as\nattributed nodes and the relationships between them as edges. Extensive\nexperiments with a large number of regression techniques show that the\nembeddings produced by our proposed GSNE technique consistently and\nsignificantly improve the performance of the house price prediction task\nregardless of the downstream regression model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 06:17:21 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Das", "Sarkar Snigdha Sarathi", ""], ["Ali", "Mohammed Eunus", ""], ["Li", "Yuan-Fang", ""], ["Kang", "Yong-Bin", ""], ["Sellis", "Timos", ""]]}, {"id": "2009.00268", "submitter": "Marco Mobilio", "authors": "Anna Ferrari, Daniela Micucci, Marco Mobilio, Paolo Napoletano", "title": "Personalization in Human Activity Recognition", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years there has been a growing interest in techniques able to\nautomatically recognize activities performed by people. This field is known as\nHuman Activity recognition (HAR). HAR can be crucial in monitoring the\nwellbeing of the people, with special regard to the elder population and those\npeople affected by degenerative conditions. One of the main challenges concerns\nthe diversity of the population and how the same activities can be performed in\ndifferent ways due to physical characteristics and life-style. In this paper we\nexplore the possibility of exploiting physical characteristics and signal\nsimilarity to achieve better results with respect to deep learning classifiers\nthat do not rely on this information.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 06:59:17 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ferrari", "Anna", ""], ["Micucci", "Daniela", ""], ["Mobilio", "Marco", ""], ["Napoletano", "Paolo", ""]]}, {"id": "2009.00278", "submitter": "Shaolei Ren", "authors": "Bingqian Lu, Jianyi Yang, and Shaolei Ren", "title": "Scaling Up Deep Neural Network Optimization for Edge Inference", "comments": "Position paper. New algorithm added. Part of the content (from\n  Section 5 \"Learning to Optimize\") will be presented in the work-in-progress\n  poster session of the ACM/IEEE Symposium on Edge Computing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been increasingly deployed on and integrated\nwith edge devices, such as mobile phones, drones, robots and wearables. To run\nDNN inference directly on edge devices (a.k.a. edge inference) with a\nsatisfactory performance, optimizing the DNN design (e.g., network architecture\nand quantization policy) is crucial. While state-of-the-art DNN designs have\nleveraged performance predictors to speed up the optimization process, they are\ndevice-specific (i.e., each predictor for only one target device) and hence\ncannot scale well in the presence of extremely diverse edge devices. Moreover,\neven with performance predictors, the optimizer (e.g., search-based\noptimization) can still be time-consuming when optimizing DNNs for many\ndifferent devices. In this work, we propose two approaches to scaling up DNN\noptimization. In the first approach, we reuse the performance predictors built\non a proxy device, and leverage the performance monotonicity to scale up the\nDNN optimization without re-building performance predictors for each different\ndevice. In the second approach, we build scalable performance predictors that\ncan estimate the resulting performance (e.g., inference\naccuracy/latency/energy) given a DNN-device pair, and use a neural\nnetwork-based automated optimizer that takes both device features and\noptimization parameters as input and then directly outputs the optimal DNN\ndesign without going through a lengthy optimization process for each individual\ndevice.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 07:47:22 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:06:22 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 07:41:44 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lu", "Bingqian", ""], ["Yang", "Jianyi", ""], ["Ren", "Shaolei", ""]]}, {"id": "2009.00296", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori, Simone Marullo, Stefano Melacci", "title": "Developing Constrained Neural Units Over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a foundational study on a constrained method that\ndefines learning problems with Neural Networks in the context of the principle\nof least cognitive action, which very much resembles the principle of least\naction in mechanics. Starting from a general approach to enforce constraints\ninto the dynamical laws of learning, this work focuses on an alternative way of\ndefining Neural Networks, that is different from the majority of existing\napproaches. In particular, the structure of the neural architecture is defined\nby means of a special class of constraints that are extended also to the\ninteraction with data, leading to \"architectural\" and \"input-related\"\nconstraints, respectively. The proposed theory is cast into the time domain, in\nwhich data are presented to the network in an ordered manner, that makes this\nstudy an important step toward alternative ways of processing continuous\nstreams of data with Neural Networks. The connection with the classic\nBackpropagation-based update rule of the weights of networks is discussed,\nshowing that there are conditions under which our approach degenerates to\nBackpropagation. Moreover, the theory is experimentally evaluated on a simple\nproblem that allows us to deeply study several aspects of the theory itself and\nto show the soundness of the model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 09:07:25 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""], ["Marullo", "Simone", ""], ["Melacci", "Stefano", ""]]}, {"id": "2009.00298", "submitter": "Quoc Hoan Tran", "authors": "Takahiro Goto, Quoc Hoan Tran, and Kohei Nakajima", "title": "Universal Approximation Property of Quantum Feature Map", "comments": "Main (5 pages, 2 figures); Supplemental material (12 pages, 1\n  figure); Add the evaluation for approximation rate", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding classical inputs into quantum states is considered a quantum feature\nmap to map classical data into a quantum Hilbert space. This feature map\nprovides opportunities to incorporate quantum advantages into machine learning\nalgorithms to be performed on near-term intermediate-scale quantum computers.\nWhile the quantum feature map has demonstrated its capability when combined\nwith linear classification models in some specific applications, its expressive\npower from the theoretical perspective remains unknown. We prove that the\nquantum feature map is a universal approximator of continuous functions under\nits typical settings in many practical applications. We also study the\ncapability of the quantum feature map in the classification of disjoint\nregions. Our work enables an important theoretical analysis to ensure that\nquantum-enhanced machine learning algorithms based on quantum feature maps can\nhandle a broad class of machine learning tasks. In light of this, one can\ndesign a quantum machine learning model with more powerful expressivity.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 09:09:29 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 15:24:37 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Goto", "Takahiro", ""], ["Tran", "Quoc Hoan", ""], ["Nakajima", "Kohei", ""]]}, {"id": "2009.00300", "submitter": "Radu Tudor Ionescu", "authors": "Cezara Benegui and Radu Tudor Ionescu", "title": "To augment or not to augment? Data augmentation in user identification\n  based on motion sensors", "comments": "Extended version (12 pages, 2 figures) of our paper (9 pages)\n  accepted at ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, commonly-used authentication systems for mobile device users, e.g.\npassword checking, face recognition or fingerprint scanning, are susceptible to\nvarious kinds of attacks. In order to prevent some of the possible attacks,\nthese explicit authentication systems can be enhanced by considering a\ntwo-factor authentication scheme, in which the second factor is an implicit\nauthentication system based on analyzing motion sensor data captured by\naccelerometers or gyroscopes. In order to avoid any additional burdens to the\nuser, the registration process of the implicit authentication system must be\nperformed quickly, i.e. the number of data samples collected from the user is\ntypically small. In the context of designing a machine learning model for\nimplicit user authentication based on motion signals, data augmentation can\nplay an important role. In this paper, we study several data augmentation\ntechniques in the quest of finding useful augmentation methods for motion\nsensor data. We propose a set of four research questions related to data\naugmentation in the context of few-shot user identification based on motion\nsensor signals. We conduct experiments on a benchmark data set, using two deep\nlearning architectures, convolutional neural networks and Long Short-Term\nMemory networks, showing which and when data augmentation methods bring\naccuracy improvements. Interestingly, we find that data augmentation is not\nvery helpful, most likely because the signal patterns useful to discriminate\nusers are too sensitive to the transformations brought by certain data\naugmentation techniques. This result is somewhat contradictory to the common\nbelief that data augmentation is expected to increase the accuracy of machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 09:11:12 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Benegui", "Cezara", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2009.00329", "submitter": "Giambattista Parascandolo", "authors": "Giambattista Parascandolo, Alexander Neitz, Antonio Orvieto, Luigi\n  Gresele, Bernhard Sch\\\"olkopf", "title": "Learning explanations that are hard to vary", "comments": "From v1: extended 2.2 and 2.3, added details for reproducibility and\n  link to codebase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the principle that `good explanations are hard\nto vary' in the context of deep learning. We show that averaging gradients\nacross examples -- akin to a logical OR of patterns -- can favor memorization\nand `patchwork' solutions that sew together different strategies, instead of\nidentifying invariances. To inspect this, we first formalize a notion of\nconsistency for minima of the loss surface, which measures to what extent a\nminimum appears only when examples are pooled. We then propose and\nexperimentally validate a simple alternative algorithm based on a logical AND,\nthat focuses on invariances and prevents memorization in a set of real-world\ntasks. Finally, using a synthetic dataset with a clear distinction between\ninvariant and spurious mechanisms, we dissect learning signals and compare this\napproach to well-established regularizers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 10:17:48 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 14:46:16 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 11:32:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Neitz", "Alexander", ""], ["Orvieto", "Antonio", ""], ["Gresele", "Luigi", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2009.00349", "submitter": "Sinem Sav", "authors": "Sinem Sav, Apostolos Pyrgelis, Juan R. Troncoso-Pastoriza, David\n  Froelicher, Jean-Philippe Bossuat, Joao Sa Sousa, and Jean-Pierre Hubaux", "title": "POSEIDON: Privacy-Preserving Federated Neural Network Learning", "comments": "Accepted for publication at Network and Distributed Systems Security\n  (NDSS) Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of privacy-preserving training and\nevaluation of neural networks in an $N$-party, federated learning setting. We\npropose a novel system, POSEIDON, the first of its kind in the regime of\nprivacy-preserving neural network training. It employs multiparty lattice-based\ncryptography to preserve the confidentiality of the training data, the model,\nand the evaluation data, under a passive-adversary model and collusions between\nup to $N-1$ parties. To efficiently execute the secure backpropagation\nalgorithm for training neural networks, we provide a generic packing approach\nthat enables Single Instruction, Multiple Data (SIMD) operations on encrypted\ndata. We also introduce arbitrary linear transformations within the\ncryptographic bootstrapping operation, optimizing the costly cryptographic\ncomputations over the parties, and we define a constrained optimization problem\nfor choosing the cryptographic parameters. Our experimental results show that\nPOSEIDON achieves accuracy similar to centralized or decentralized non-private\napproaches and that its computation and communication overhead scales linearly\nwith the number of parties. POSEIDON trains a 3-layer neural network on the\nMNIST dataset with 784 features and 60K samples distributed among 10 parties in\nless than 2 hours.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:06:31 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:34:46 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 13:27:01 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Sav", "Sinem", ""], ["Pyrgelis", "Apostolos", ""], ["Troncoso-Pastoriza", "Juan R.", ""], ["Froelicher", "David", ""], ["Bossuat", "Jean-Philippe", ""], ["Sousa", "Joao Sa", ""], ["Hubaux", "Jean-Pierre", ""]]}, {"id": "2009.00351", "submitter": "Haining Zheng", "authors": "Haining Zheng and Antonio R. Paiva and Chris S. Gurciullo", "title": "Advancing from Predictive Maintenance to Intelligent Maintenance with AI\n  and IIoT", "comments": "The 3rd International Workshop on Artificial Intelligence of Things\n  (AIoT) In conjunction with the 26th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Artificial Intelligent (AI) technology advances and increasingly large\namounts of data become readily available via various Industrial Internet of\nThings (IIoT) projects, we evaluate the state of the art of predictive\nmaintenance approaches and propose our innovative framework to improve the\ncurrent practice. The paper first reviews the evolution of reliability\nmodelling technology in the past 90 years and discusses major technologies\ndeveloped in industry and academia. We then introduce the next generation\nmaintenance framework - Intelligent Maintenance, and discuss its key\ncomponents. This AI and IIoT based Intelligent Maintenance framework is\ncomposed of (1) latest machine learning algorithms including probabilistic\nreliability modelling with deep learning, (2) real-time data collection,\ntransfer, and storage through wireless smart sensors, (3) Big Data\ntechnologies, (4) continuously integration and deployment of machine learning\nmodels, (5) mobile device and AR/VR applications for fast and better\ndecision-making in the field. Particularly, we proposed a novel probabilistic\ndeep learning reliability modelling approach and demonstrate it in the Turbofan\nEngine Degradation Dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:10:13 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zheng", "Haining", ""], ["Paiva", "Antonio R.", ""], ["Gurciullo", "Chris S.", ""]]}, {"id": "2009.00365", "submitter": "Ievgen Redko", "authors": "Charlotte Laclau, Franck Iutzeler, Ievgen Redko", "title": "Rank-one partitioning: formalization, illustrative examples, and a new\n  cluster enhancing strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and formalize a rank-one partitioning learning\nparadigm that unifies partitioning methods that proceed by summarizing a data\nset using a single vector that is further used to derive the final clustering\npartition. Using this unification as a starting point, we propose a novel\nalgorithmic solution for the partitioning problem based on rank-one matrix\nfactorization and denoising of piecewise constant signals. Finally, we propose\nan empirical demonstration of our findings and demonstrate the robustness of\nthe proposed denoising step. We believe that our work provides a new point of\nview for several unsupervised learning techniques that helps to gain a deeper\nunderstanding about the general mechanisms of data partitioning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:37:28 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Laclau", "Charlotte", ""], ["Iutzeler", "Franck", ""], ["Redko", "Ievgen", ""]]}, {"id": "2009.00378", "submitter": "Christoph Angermann", "authors": "Christoph Angermann and Markus Haltmeier", "title": "Deep Structure Learning using Feature Extraction in Trained Projection\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade of machine learning, convolutional neural networks have\nbeen the most striking successes for feature extraction of rich sensory and\nhigh-dimensional data. While learning data representations via convolutions is\nalready well studied and efficiently implemented in various deep learning\nlibraries, one often faces limited memory capacity and insufficient number of\ntraining data, especially for high-dimensional and large-scale tasks. To\novercome these limitations, we introduce a network architecture using a\nself-adjusting and data dependent version of the Radon-transform (linear data\nprojection), also known as x-ray projection, to enable feature extraction via\nconvolutions in lower-dimensional space. The resulting framework, named PiNet,\ncan be trained end-to-end and shows promising performance on volumetric\nsegmentation tasks. We test proposed model on public datasets to show that our\napproach achieves comparable results only using fractional amount of\nparameters. Investigation of memory usage and processing time confirms PiNet's\nsuperior efficiency compared to other segmentation models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:16:55 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 12:25:22 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 15:58:00 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Angermann", "Christoph", ""], ["Haltmeier", "Markus", ""]]}, {"id": "2009.00387", "submitter": "Xiaokai Chen", "authors": "Xiaokai Chen and Xiaoguang Gu and Libo Fu", "title": "Boosting Share Routing for Multi-task Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3442442.3452323", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task learning (MTL) aims to make full use of the knowledge contained in\nmulti-task supervision signals to improve the overall performance. How to make\nthe knowledge of multiple tasks shared appropriately is an open problem for\nMTL. Most existing deep MTL models are based on parameter sharing. However,\nsuitable sharing mechanism is hard to design as the relationship among tasks is\ncomplicated. In this paper, we propose a general framework called Multi-Task\nNeural Architecture Search (MTNAS) to efficiently find a suitable sharing route\nfor a given MTL problem. MTNAS modularizes the sharing part into multiple\nlayers of sub-networks. It allows sparse connection among these sub-networks\nand soft sharing based on gating is enabled for a certain route. Benefiting\nfrom such setting, each candidate architecture in our search space defines a\ndynamic sparse sharing route which is more flexible compared with full-sharing\nin previous approaches. We show that existing typical sharing approaches are\nsub-graphs in our search space. Extensive experiments on three real-world\nrecommendation datasets demonstrate MTANS achieves consistent improvement\ncompared with single-task models and typical multi-task methods while\nmaintaining high computation efficiency. Furthermore, in-depth experiments\ndemonstrates that MTNAS can learn suitable sparse route to mitigate negative\ntransfer.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:37:19 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 12:00:31 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chen", "Xiaokai", ""], ["Gu", "Xiaoguang", ""], ["Fu", "Libo", ""]]}, {"id": "2009.00394", "submitter": "Fatemeh Jahedpari", "authors": "Fatemeh Jahedpari", "title": "Continuous Artificial Prediction Markets as a Syndromic Surveillance\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of syndromic surveillance systems is early detection of an\noutbreak in a society using available data sources. In this paper, we discuss\nwhat are the challenges of syndromic surveillance systems and how continuous\nArtificial Prediction Market [Jahedpari et al., 2017] can effectively be\napplied to the problem of syndromic surveillance.\n  We use two well-known models of (i) Google Flu Trends, and (ii) the latest\nimprovement of Google Flu Trends model, named as GP [Lampos et al., 2015], as\nour case study and we show how c-APM can improve upon their performance. Our\nresults demonstrate that c-APM typically has a lower MAE to that of Google Flu\nTrends in each year. Though this difference is relatively small in some years\nlike 2004 and 2007, it is relatively large in most years and very large between\n2011 and 2013.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:51:48 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Jahedpari", "Fatemeh", ""]]}, {"id": "2009.00395", "submitter": "Shadi Rahimian", "authors": "Shadi Rahimian and Tribhuvanesh Orekondy and Mario Fritz", "title": "Sampling Attacks: Amplification of Membership Inference Attacks by\n  Repeated Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been shown to leak information violating the\nprivacy of their training set. We focus on membership inference attacks on\nmachine learning models which aim to determine whether a data point was used to\ntrain the victim model. Our work consists of two sides: We introduce sampling\nattack, a novel membership inference technique that unlike other standard\nmembership adversaries is able to work under severe restriction of no access to\nscores of the victim model. We show that a victim model that only publishes the\nlabels is still susceptible to sampling attacks and the adversary can recover\nup to 100% of its performance compared to when posterior vectors are provided.\nThe other sides of our work includes experimental results on two recent\nmembership inference attack models and the defenses against them. For defense,\nwe choose differential privacy in the form of gradient perturbation during the\ntraining of the victim model as well as output perturbation at prediction time.\nWe carry out our experiments on a wide range of datasets which allows us to\nbetter analyze the interaction between adversaries, defense mechanism and\ndatasets. We find out that our proposed fast and easy-to-implement output\nperturbation technique offers good privacy protection for membership inference\nattacks at little impact on utility.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:54:54 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Rahimian", "Shadi", ""], ["Orekondy", "Tribhuvanesh", ""], ["Fritz", "Mario", ""]]}, {"id": "2009.00437", "submitter": "Xuanyi Dong", "authors": "Xuanyi Dong, Lu Liu, Katarzyna Musial, Bogdan Gabrys", "title": "NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and\n  Size", "comments": "Accepted to IEEE TPAMI 2021, an extended version of NAS-Bench-201\n  (ICLR 2020) [arXiv:2001.00326]", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3054824", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has attracted a lot of attention and has\nbeen illustrated to bring tangible benefits in a large number of applications\nin the past few years. Architecture topology and architecture size have been\nregarded as two of the most important aspects for the performance of deep\nlearning models and the community has spawned lots of searching algorithms for\nboth aspects of the neural architectures. However, the performance gain from\nthese searching algorithms is achieved under different search spaces and\ntraining setups. This makes the overall performance of the algorithms to some\nextent incomparable and the improvement from a sub-module of the searching\nmodel unclear. In this paper, we propose NATS-Bench, a unified benchmark on\nsearching for both topology and size, for (almost) any up-to-date NAS\nalgorithm. NATS-Bench includes the search space of 15,625 neural cell\ncandidates for architecture topology and 32,768 for architecture size on three\ndatasets. We analyze the validity of our benchmark in terms of various criteria\nand performance comparison of all candidates in the search space. We also show\nthe versatility of NATS-Bench by benchmarking 13 recent state-of-the-art NAS\nalgorithms on it. All logs and diagnostic information trained using the same\nsetup for each candidate are provided. This facilitates a much larger community\nof researchers to focus on developing better NAS algorithms in a more\ncomparable and computationally cost friendly environment. All codes are\npublicly available at: https://xuanyidong.com/assets/projects/NATS-Bench.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:34:56 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 01:50:27 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 05:39:42 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 15:19:25 GMT"}, {"version": "v5", "created": "Mon, 25 Jan 2021 02:42:25 GMT"}, {"version": "v6", "created": "Tue, 26 Jan 2021 02:33:39 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Dong", "Xuanyi", ""], ["Liu", "Lu", ""], ["Musial", "Katarzyna", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2009.00457", "submitter": "Harideep Nair", "authors": "Harideep Nair, John Paul Shen, James E. Smith", "title": "Direct CMOS Implementation of Neuromorphic Temporal Neural Networks for\n  Sensory Processing", "comments": "Submission Under Review for an IEEE Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Neural Networks (TNNs) use time as a resource to represent and\nprocess information, mimicking the behavior of the mammalian neocortex. This\nwork focuses on implementing TNNs using off-the-shelf digital CMOS technology.\nA microarchitecture framework is introduced with a hierarchy of building blocks\nincluding: multi-neuron columns, multi-column layers, and multi-layer TNNs. We\npresent the direct CMOS gate-level implementation of the multi-neuron column\nmodel as the key building block for TNNs. Post-synthesis results are obtained\nusing Synopsys tools and the 45 nm CMOS standard cell library. The TNN\nmicroarchitecture framework is embodied in a set of characteristic equations\nfor assessing the total gate count, die area, compute time, and power\nconsumption for any TNN design. We develop a multi-layer TNN prototype of 32M\ngates. In 7 nm CMOS process, it consumes only 1.54 mm^2 die area and 7.26 mW\npower and can process 28x28 images at 107M FPS (9.34 ns per image). We evaluate\nthe prototype's performance and complexity relative to a recent\nstate-of-the-art TNN model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 20:36:34 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Nair", "Harideep", ""], ["Shen", "John Paul", ""], ["Smith", "James E.", ""]]}, {"id": "2009.00470", "submitter": "Monica Arul", "authors": "Monica Arul and Ahsan Kareem", "title": "Data Anomaly Detection for Structural Health Monitoring of Bridges using\n  Shapelet Transform", "comments": "arXiv admin note: text overlap with arXiv:2004.11243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wider availability of sensor technology, a number of Structural\nHealth Monitoring (SHM) systems are deployed to monitor civil infrastructure.\nThe continuous monitoring provides valuable information about the structure\nthat can help in providing a decision support system for retrofits and other\nstructural modifications. However, when the sensors are exposed to harsh\nenvironmental conditions, the data measured by the SHM systems tend to be\naffected by multiple anomalies caused by faulty or broken sensors. Given a\ndeluge of high-dimensional data collected continuously over time, research into\nusing machine learning methods to detect anomalies are a topic of great\ninterest to the SHM community. This paper contributes to this effort by\nproposing the use of a relatively new time series representation named Shapelet\nTransform in combination with a Random Forest classifier to autonomously\nidentify anomalies in SHM data. The shapelet transform is a unique time series\nrepresentation that is solely based on the shape of the time series data. In\nconsideration of the individual characteristics unique to every anomaly, the\napplication of this transform yields a new shape-based feature representation\nthat can be combined with any standard machine learning algorithm to detect\nanomalous data with no manual intervention. For the present study, the anomaly\ndetection framework consists of three steps: identifying unique shapes from\nanomalous data, using these shapes to transform the SHM data into a local-shape\nspace and training machine learning algorithm on this transformed data to\nidentify anomalies. The efficacy of this method is demonstrated by the\nidentification of anomalies in acceleration data from a SHM system installed on\na long-span bridge in China. The results show that multiple data anomalies in\nSHM data can be automatically detected with high accuracy using the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 01:11:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Arul", "Monica", ""], ["Kareem", "Ahsan", ""]]}, {"id": "2009.00505", "submitter": "Firas Laakom", "authors": "Firas Laakom, Jenni Raitoharju, Nikolaos Passalis, Alexandros\n  Iosifidis, Moncef Gabbouj", "title": "Graph Embedding with Data Uncertainty", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  spectral-based subspace learning is a common data preprocessing step in many\nmachine learning pipelines. The main aim is to learn a meaningful low\ndimensional embedding of the data. However, most subspace learning methods do\nnot take into consideration possible measurement inaccuracies or artifacts that\ncan lead to data with high uncertainty. Thus, learning directly from raw data\ncan be misleading and can negatively impact the accuracy. In this paper, we\npropose to model artifacts in training data using probability distributions;\neach data point is represented by a Gaussian distribution centered at the\noriginal data point and having a variance modeling its uncertainty. We\nreformulate the Graph Embedding framework to make it suitable for learning from\ndistributions and we study as special cases the Linear Discriminant Analysis\nand the Marginal Fisher Analysis techniques. Furthermore, we propose two\nschemes for modeling data uncertainty based on pair-wise distances in an\nunsupervised and a supervised contexts.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:08:23 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Laakom", "Firas", ""], ["Raitoharju", "Jenni", ""], ["Passalis", "Nikolaos", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.00520", "submitter": "Weikai Li", "authors": "Weikai Li and Songcan Chen", "title": "Unsupervised Domain Adaptation with Progressive Adaptation of Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) aims to classify unlabeled target domain\nby transferring knowledge from labeled source domain with domain shift. Most of\nthe existing UDA methods try to mitigate the adverse impact induced by the\nshift via reducing domain discrepancy. However, such approaches easily suffer a\nnotorious mode collapse issue due to the lack of labels in target domain.\nNaturally, one of the effective ways to mitigate this issue is to reliably\nestimate the pseudo labels for target domain, which itself is hard. To overcome\nthis, we propose a novel UDA method named Progressive Adaptation of Subspaces\napproach (PAS) in which we utilize such an intuition that appears much\nreasonable to gradually obtain reliable pseudo labels. Speci fically, we\nprogressively and steadily refine the shared subspaces as bridge of knowledge\ntransfer by adaptively anchoring/selecting and leveraging those target samples\nwith reliable pseudo labels. Subsequently, the refined subspaces can in turn\nprovide more reliable pseudo-labels of the target domain, making the mode\ncollapse highly mitigated. Our thorough evaluation demonstrates that PAS is not\nonly effective for common UDA, but also outperforms the state-of-the arts for\nmore challenging Partial Domain Adaptation (PDA) situation, where the source\nlabel set subsumes the target one.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:40:50 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Li", "Weikai", ""], ["Chen", "Songcan", ""]]}, {"id": "2009.00524", "submitter": "Binhang Yuan", "authors": "Binhang Yuan and Dimitrije Jankov and Jia Zou and Yuxin Tang and\n  Daniel Bourgeois and Chris Jermaine", "title": "Tensor Relational Algebra for Machine Learning System Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) systems have to support various tensor operations.\nHowever, such ML systems were largely developed without asking: what are the\nfoundational abstractions necessary for building machine learning systems? We\nbelieve that proper computational and implementation abstractions will allow\nfor the construction of self-configuring, declarative ML systems, especially\nwhen the goal is to execute tensor operations in a distributed environment, or\npartitioned across multiple AI accelerators (ASICs). To this end, we first\nintroduce a tensor relational algebra (TRA), which is expressive to encode any\ntensor operation that can be written in the Einstein notation. We consider how\nTRA expressions can be re-written into an implementation algebra (IA) that\nenables effective implementation in a distributed environment, as well as how\nexpressions in the IA can be optimized. Our empirical study shows that the\noptimized implementation provided by IA can reach or even out-perform carefully\nengineered HPC or ML systems for large scale tensor manipulations and ML\nworkflows in distributed clusters.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:51:24 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 23:21:30 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Yuan", "Binhang", ""], ["Jankov", "Dimitrije", ""], ["Zou", "Jia", ""], ["Tang", "Yuxin", ""], ["Bourgeois", "Daniel", ""], ["Jermaine", "Chris", ""]]}, {"id": "2009.00534", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu", "title": "Improved Weighted Random Forest for Classification Problems", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-66501-2_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several studies have shown that combining machine learning models in an\nappropriate way will introduce improvements in the individual predictions made\nby the base models. The key to make well-performing ensemble model is in the\ndiversity of the base models. Of the most common solutions for introducing\ndiversity into the decision trees are bagging and random forest. Bagging\nenhances the diversity by sampling with replacement and generating many\ntraining data sets, while random forest adds selecting a random number of\nfeatures as well. This has made the random forest a winning candidate for many\nmachine learning applications. However, assuming equal weights for all base\ndecision trees does not seem reasonable as the randomization of sampling and\ninput feature selection may lead to different levels of decision-making\nabilities across base decision trees. Therefore, we propose several algorithms\nthat intend to modify the weighting strategy of regular random forest and\nconsequently make better predictions. The designed weighting frameworks include\noptimal weighted random forest based on ac-curacy, optimal weighted random\nforest based on the area under the curve (AUC), performance-based weighted\nrandom forest, and several stacking-based weighted random forest models. The\nnumerical results show that the proposed models are able to introduce\nsignificant improvements compared to regular random forest.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:08:45 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""]]}, {"id": "2009.00538", "submitter": "Tijin Yan", "authors": "Tijin Yan, Hongwei Zhang, Zirui Li, Yuanqing Xia", "title": "Stochastic Graph Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning over graph structure data has been widely studied due\nto its wide application prospects. However, previous methods mainly focus on\nstatic graphs while many real-world graphs evolve over time. Modeling such\nevolution is important for predicting properties of unseen networks. To resolve\nthis challenge, we propose SGRNN, a novel neural architecture that applies\nstochastic latent variables to simultaneously capture the evolution in node\nattributes and topology. Specifically, deterministic states are separated from\nstochastic states in the iterative process to suppress mutual interference.\nWith semi-implicit variational inference integrated to SGRNN, a non-Gaussian\nvariational distribution is proposed to help further improve the performance.\nIn addition, to alleviate KL-vanishing problem in SGRNN, a simple and\ninterpretable structure is proposed based on the lower bound of KL-divergence.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nthe proposed model. Code is available at\nhttps://github.com/StochasticGRNN/SGRNN.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:14:30 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Yan", "Tijin", ""], ["Zhang", "Hongwei", ""], ["Li", "Zirui", ""], ["Xia", "Yuanqing", ""]]}, {"id": "2009.00540", "submitter": "Prasanna Date", "authors": "Prasanna Date, Christopher D. Carothers, John E. Mitchell, James A.\n  Hendler, Malik Magdon-Ismail", "title": "Training Deep Neural Networks with Constrained Learning Parameters", "comments": null, "journal-ref": null, "doi": "10.1109/ICRC2020.2020.00018", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's deep learning models are primarily trained on CPUs and GPUs. Although\nthese models tend to have low error, they consume high power and utilize large\namount of memory owing to double precision floating point learning parameters.\nBeyond the Moore's law, a significant portion of deep learning tasks would run\non edge computing systems, which will form an indispensable part of the entire\ncomputation fabric. Subsequently, training deep learning models for such\nsystems will have to be tailored and adopted to generate models that have the\nfollowing desirable characteristics: low error, low memory, and low power. We\nbelieve that deep neural networks (DNNs), where learning parameters are\nconstrained to have a set of finite discrete values, running on neuromorphic\ncomputing systems would be instrumental for intelligent edge computing systems\nhaving these desirable characteristics. To this extent, we propose the\nCombinatorial Neural Network Training Algorithm (CoNNTrA), that leverages a\ncoordinate gradient descent-based approach for training deep learning models\nwith finite discrete learning parameters. Next, we elaborate on the theoretical\nunderpinnings and evaluate the computational complexity of CoNNTrA. As a proof\nof concept, we use CoNNTrA to train deep learning models with ternary learning\nparameters on the MNIST, Iris and ImageNet data sets and compare their\nperformance to the same models trained using Backpropagation. We use following\nperformance metrics for the comparison: (i) Training error; (ii) Validation\nerror; (iii) Memory usage; and (iv) Training time. Our results indicate that\nCoNNTrA models use 32x less memory and have errors at par with the\nBackpropagation models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:20:11 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Date", "Prasanna", ""], ["Carothers", "Christopher D.", ""], ["Mitchell", "John E.", ""], ["Hendler", "James A.", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "2009.00542", "submitter": "Waheeda Saib", "authors": "Waheeda Saib, Tapiwa Chiwewe, Elvira Singh", "title": "Hierarchical Deep Learning Classification of Unstructured Pathology\n  Reports to Automate ICD-O Morphology Grading", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216. arXiv admin note: substantial text overlap with\n  arXiv:2008.12571", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/135", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely cancer reporting data are required in order to understand the impact\nof cancer, inform public health resource planning and implement cancer policy\nespecially in Sub Saharan Africa where the reporting lag is behind world\naverages. Unstructured pathology reports, which contain tumor specific data,\nare the main source of information collected by cancer registries. Due to\nmanual processing and labelling of pathology reports using the International\nClassification of Disease for oncology (ICD-O) codes, by human coders employed\nby cancer registries, has led to a considerable lag in cancer reporting. We\npresent a hierarchical deep learning classification method that employs\nconvolutional neural network models to automate the classification of 1813\nanonymized breast cancer pathology reports with applicable ICD-O morphology\ncodes across 9 classes. We demonstrate that the hierarchical deep learning\nclassification method improves on performance in comparison to a flat\nmulticlass CNN model for ICD-O morphology classification of the same reports.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:36:58 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Saib", "Waheeda", ""], ["Chiwewe", "Tapiwa", ""], ["Singh", "Elvira", ""]]}, {"id": "2009.00544", "submitter": "Kamwoo Lee", "authors": "Kamwoo Lee and Jeanine Braithwaite", "title": "High-Resolution Poverty Maps in Sub-Saharan Africa", "comments": "Changed an author's affiliation, updated the narrowing method for DHS\n  clusters leading to slight changes to all validation results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up-to-date poverty maps are an important tool for policy makers, but until\nnow, have been prohibitively expensive to produce. We propose a generalizable\nprediction methodology to produce poverty maps at the village level using\ngeospatial data and machine learning algorithms. We tested the proposed method\nfor 25 Sub-Saharan African countries and validated them against survey data.\nThe proposed method can increase the validity of both single country and\ncross-country estimations leading to higher precision in poverty maps of 44\nSub-Saharan African countries than previously available. More importantly, our\ncross-country estimation enables the creation of poverty maps when it is not\npractical or cost-effective to field new national household surveys, as is the\ncase with many low- and middle-income countries.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:23:43 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:27:19 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 03:54:39 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 17:37:05 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 02:00:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lee", "Kamwoo", ""], ["Braithwaite", "Jeanine", ""]]}, {"id": "2009.00548", "submitter": "Philipp Meschenmoser", "authors": "Philipp Meschenmoser, Juri F. Buchm\\\"uller, Daniel Seebacher, Martin\n  Wikelski and Daniel A. Keim", "title": "MultiSegVA: Using Visual Analytics to Segment Biologging Time Series on\n  Multiple Scales", "comments": "IEEE VAST 2020 - Proceedings of IEEE Conference on Visual Analytics\n  Science and Technology (VAST), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmenting biologging time series of animals on multiple temporal scales is\nan essential step that requires complex techniques with careful\nparameterization and possibly cross-domain expertise. Yet, there is a lack of\nvisual-interactive tools that strongly support such multi-scale segmentation.\nTo close this gap, we present our MultiSegVA platform for interactively\ndefining segmentation techniques and parameters on multiple temporal scales.\nMultiSegVA primarily contributes tailored, visual-interactive means and visual\nanalytics paradigms for segmenting unlabeled time series on multiple scales.\nFurther, to flexibly compose the multi-scale segmentation, the platform\ncontributes a new visual query language that links a variety of segmentation\ntechniques. To illustrate our approach, we present a domain-oriented set of\nsegmentation techniques derived in collaboration with movement ecologists. We\ndemonstrate the applicability and usefulness of MultiSegVA in two real-world\nuse cases from movement ecology, related to behavior analysis after\nenvironment-aware segmentation, and after progressive clustering. Expert\nfeedback from movement ecologists shows the effectiveness of tailored\nvisual-interactive means and visual analytics paradigms at segmenting\nmulti-scale data, enabling them to perform semantically meaningful analyses. A\nthird use case demonstrates that MultiSegVA is generalizable to other domains.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:27:08 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 08:22:29 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Meschenmoser", "Philipp", ""], ["Buchm\u00fcller", "Juri F.", ""], ["Seebacher", "Daniel", ""], ["Wikelski", "Martin", ""], ["Keim", "Daniel A.", ""]]}, {"id": "2009.00564", "submitter": "Alexander Mathis", "authors": "Alexander Mathis and Steffen Schneider and Jessy Lauer and Mackenzie\n  W. Mathis", "title": "A Primer on Motion Capture with Deep Learning: Principles, Pitfalls and\n  Perspectives", "comments": "Review, 21 pages, 8 figures and 5 boxes", "journal-ref": "Neuron Volume 108, Issue 1, 14 October 2020, Pages 44-65", "doi": "10.1016/j.neuron.2020.09.017", "report-no": null, "categories": "cs.CV cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting behavioral measurements non-invasively from video is stymied by\nthe fact that it is a hard computational problem. Recent advances in deep\nlearning have tremendously advanced predicting posture from videos directly,\nwhich quickly impacted neuroscience and biology more broadly. In this primer we\nreview the budding field of motion capture with deep learning. In particular,\nwe will discuss the principles of those novel algorithms, highlight their\npotential as well as pitfalls for experimentalists, and provide a glimpse into\nthe future.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:51:33 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 20:29:12 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Mathis", "Alexander", ""], ["Schneider", "Steffen", ""], ["Lauer", "Jessy", ""], ["Mathis", "Mackenzie W.", ""]]}, {"id": "2009.00565", "submitter": "Jordan Masakuna F", "authors": "Jordan F. Masakuna, Simukai W. Utete, Steve Kroon", "title": "Performance-Agnostic Fusion of Probabilistic Classifier Outputs", "comments": "This paper was accepted at the 23rd International Conference on\n  Information Fusion 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for combining probabilistic outputs of classifiers to\nmake a single consensus class prediction when no further information about the\nindividual classifiers is available, beyond that they have been trained for the\nsame task. The lack of relevant prior information rules out typical\napplications of Bayesian or Dempster-Shafer methods, and the default approach\nhere would be methods based on the principle of indifference, such as the sum\nor product rule, which essentially weight all classifiers equally. In contrast,\nour approach considers the diversity between the outputs of the various\nclassifiers, iteratively updating predictions based on their correspondence\nwith other predictions until the predictions converge to a consensus decision.\nThe intuition behind this approach is that classifiers trained for the same\ntask should typically exhibit regularities in their outputs on a new task; the\npredictions of classifiers which differ significantly from those of others are\nthus given less credence using our approach. The approach implicitly assumes a\nsymmetric loss function, in that the relative cost of various prediction errors\nare not taken into account. Performance of the model is demonstrated on\ndifferent benchmark datasets. Our proposed method works well in situations\nwhere accuracy is the performance metric; however, it does not output\ncalibrated probabilities, so it is not suitable in situations where such\nprobabilities are required for further processing.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:53:29 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Masakuna", "Jordan F.", ""], ["Utete", "Simukai W.", ""], ["Kroon", "Steve", ""]]}, {"id": "2009.00578", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona and Kenza Hamidouche and Mathieu Lauri\\`ere and Zongjun\n  Tan", "title": "Linear-Quadratic Zero-Sum Mean-Field Type Games: Optimality Conditions\n  and Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, zero-sum mean-field type games (ZSMFTG) with linear dynamics\nand quadratic cost are studied under infinite-horizon discounted utility\nfunction. ZSMFTG are a class of games in which two decision makers whose\nutilities sum to zero, compete to influence a large population of\nindistinguishable agents. In particular, the case in which the transition and\nutility functions depend on the state, the action of the controllers, and the\nmean of the state and the actions, is investigated. The optimality conditions\nof the game are analysed for both open-loop and closed-loop controls, and\nexplicit expressions for the Nash equilibrium strategies are derived. Moreover,\ntwo policy optimization methods that rely on policy gradient are proposed for\nboth model-based and sample-based frameworks. In the model-based case, the\ngradients are computed exactly using the model, whereas they are estimated\nusing Monte-Carlo simulations in the sample-based case. Numerical experiments\nare conducted to show the convergence of the utility function as well as the\ntwo players' controls.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:08:24 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Hamidouche", "Kenza", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Tan", "Zongjun", ""]]}, {"id": "2009.00584", "submitter": "Bram Ruijsink", "authors": "Bram Ruijsink, Esther Puyol-Anton, Ye Li, Wenja Bai, Eric Kerfoot,\n  Reza Razavi, and Andrew P. King", "title": "Quality-aware semi-supervised learning for CMR segmentation", "comments": "MICCAI STACOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in developing deep learning algorithms for medical\nimage segmentation is the scarcity of annotated training data. To overcome this\nlimitation, data augmentation and semi-supervised learning (SSL) methods have\nbeen developed. However, these methods have limited effectiveness as they\neither exploit the existing data set only (data augmentation) or risk negative\nimpact by adding poor training examples (SSL). Segmentations are rarely the\nfinal product of medical image analysis - they are typically used in downstream\ntasks to infer higher-order patterns to evaluate diseases. Clinicians take into\naccount a wealth of prior knowledge on biophysics and physiology when\nevaluating image analysis results. We have used these clinical assessments in\nprevious works to create robust quality-control (QC) classifiers for automated\ncardiac magnetic resonance (CMR) analysis. In this paper, we propose a novel\nscheme that uses QC of the downstream task to identify high quality outputs of\nCMR segmentation networks, that are subsequently utilised for further network\ntraining. In essence, this provides quality-aware augmentation of training data\nin a variant of SSL for segmentation networks (semiQCSeg). We evaluate our\napproach in two CMR segmentation tasks (aortic and short axis cardiac volume\nsegmentation) using UK Biobank data and two commonly used network architectures\n(U-net and a Fully Convolutional Network) and compare against supervised and\nSSL strategies. We show that semiQCSeg improves training of the segmentation\nnetworks. It decreases the need for labelled data, while outperforming the\nother methods in terms of Dice and clinical metrics. SemiQCSeg can be an\nefficient approach for training segmentation networks for medical image data\nwhen labelled datasets are scarce.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:18:22 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ruijsink", "Bram", ""], ["Puyol-Anton", "Esther", ""], ["Li", "Ye", ""], ["Bai", "Wenja", ""], ["Kerfoot", "Eric", ""], ["Razavi", "Reza", ""], ["King", "Andrew P.", ""]]}, {"id": "2009.00585", "submitter": "Guilherme Pires", "authors": "Guilherme G. P. Freitas Pires, M\\'ario A. T. Figueiredo", "title": "Variational Mixture of Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, deep generative models, such as generative adversarial\nnetworks \\autocite{GAN}, variational autoencoders \\autocite{vaepaper}, and\ntheir variants, have seen wide adoption for the task of modelling complex data\ndistributions. In spite of the outstanding sample quality achieved by those\nearly methods, they model the target distributions \\emph{implicitly}, in the\nsense that the probability density functions induced by them are not explicitly\naccessible. This fact renders those methods unfit for tasks that require, for\nexample, scoring new instances of data with the learned distributions.\nNormalizing flows have overcome this limitation by leveraging the\nchange-of-variables formula for probability density functions, and by using\ntransformations designed to have tractable and cheaply computable Jacobians.\nAlthough flexible, this framework lacked (until recently\n\\autocites{semisuplearning_nflows, RAD}) a way to introduce discrete structure\n(such as the one found in mixtures) in the models it allows to construct, in an\nunsupervised scenario. The present work overcomes this by using normalizing\nflows as components in a mixture model and devising an end-to-end training\nprocedure for such a model. This procedure is based on variational inference,\nand uses a variational posterior parameterized by a neural network. As will\nbecome clear, this model naturally lends itself to (multimodal) density\nestimation, semi-supervised learning, and clustering. The proposed model is\nillustrated on two synthetic datasets, as well as on a real-world dataset.\nKeywords: Deep generative models, normalizing flows, variational inference,\nprobabilistic modelling, mixture models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:20:08 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Pires", "Guilherme G. P. Freitas", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "2009.00603", "submitter": "Weidi Xie", "authors": "Weidi Xie, Jeffrey Byrne, Andrew Zisserman", "title": "Inducing Predictive Uncertainty Estimation for Face Recognition", "comments": "To Appear at the British Machine Vision Conference (BMVC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowing when an output can be trusted is critical for reliably using face\nrecognition systems. While there has been enormous effort in recent research on\nimproving face verification performance, understanding when a model's\npredictions should or should not be trusted has received far less attention.\nOur goal is to assign a confidence score for a face image that reflects its\nquality in terms of recognizable information. To this end, we propose a method\nfor generating image quality training data automatically from 'mated-pairs' of\nface images, and use the generated data to train a lightweight Predictive\nConfidence Network, termed as PCNet, for estimating the confidence score of a\nface image. We systematically evaluate the usefulness of PCNet with its error\nversus reject performance, and demonstrate that it can be universally paired\nwith and improve the robustness of any verification model. We describe three\nuse cases on the public IJB-C face verification benchmark: (i) to improve 1:1\nimage-based verification error rates by rejecting low-quality face images; (ii)\nto improve quality score based fusion performance on the 1:1 set-based\nverification benchmark; and (iii) its use as a quality measure for selecting\nhigh quality (unblurred, good lighting, more frontal) faces from a collection,\ne.g. for automatic enrolment or display.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:52:00 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Xie", "Weidi", ""], ["Byrne", "Jeffrey", ""], ["Zisserman", "Andrew", ""]]}, {"id": "2009.00606", "submitter": "Oren Yuval", "authors": "Oren Yuval and Saharon Rosset", "title": "Semi-Supervised Empirical Risk Minimization: When can unlabeled data\n  improve prediction?", "comments": "36 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general methodology for using unlabeled data to design semi\nsupervised learning (SSL) variants of the Empirical Risk Minimization (ERM)\nlearning process. Focusing on generalized linear regression, we provide a\ncareful treatment of the effectiveness of the SSL to improve prediction\nperformance. The key ideas are carefully considering the null model as a\ncompetitor, and utilizing the unlabeled data to determine signal-noise\ncombinations where the SSL outperforms both the ERM learning and the null\nmodel. In the special case of linear regression with Gaussian covariates, we\nshow that the previously suggested semi-supervised estimator is in fact not\ncapable of improving on both the supervised estimator and the null model\nsimultaneously. However, the new estimator presented in this work, can achieve\nan improvement of $O(1/n)$ term over both competitors simultaneously. On the\nother hand, we show that in other scenarios, such as non-Gaussian covariates,\nmisspecified linear regression, or generalized linear regression with\nnon-linear link functions, having unlabeled data can derive substantial\nimprovement in practice by applying our suggested SSL approach. Moreover, it is\npossible to identify the situations where SSL improves prediction, by using the\nresults we establish throughout this work. This is shown empirically through\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:55:51 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 11:49:52 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 14:58:19 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yuval", "Oren", ""], ["Rosset", "Saharon", ""]]}, {"id": "2009.00611", "submitter": "Krutarth Patel", "authors": "Krutarth Patel, Cornelia Caragea, Mark Phillips, Nathaniel Fox", "title": "Identifying Documents In-Scope of a Collection from Web Archives", "comments": "10 pages", "journal-ref": "In Proceedings of the ACM/IEEE Joint Conference on Digital\n  Libraries in 2020 (JCDL 2020)", "doi": "10.1145/3383583.3398540", "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web archive data usually contains high-quality documents that are very useful\nfor creating specialized collections of documents, e.g., scientific digital\nlibraries and repositories of technical reports. In doing so, there is a\nsubstantial need for automatic approaches that can distinguish the documents of\ninterest for a collection out of the huge number of documents collected by web\narchiving institutions. In this paper, we explore different learning models and\nfeature representations to determine the best performing ones for identifying\nthe documents of interest from the web archived data. Specifically, we study\nboth machine learning and deep learning models and \"bag of words\" (BoW)\nfeatures extracted from the entire document or from specific portions of the\ndocument, as well as structural features that capture the structure of\ndocuments. We focus our evaluation on three datasets that we created from three\ndifferent Web archives. Our experimental results show that the BoW classifiers\nthat focus only on specific portions of the documents (rather than the full\ntext) outperform all compared methods on all three datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:22:23 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Patel", "Krutarth", ""], ["Caragea", "Cornelia", ""], ["Phillips", "Mark", ""], ["Fox", "Nathaniel", ""]]}, {"id": "2009.00612", "submitter": "Junaid Malik", "authors": "Junaid Malik, Serkan Kiranyaz, Moncef Gabbouj", "title": "Operational vs Convolutional Neural Networks for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have recently become a favored technique\nfor image denoising due to its adaptive learning ability, especially with a\ndeep configuration. However, their efficacy is inherently limited owing to\ntheir homogenous network formation with the unique use of linear convolution.\nIn this study, we propose a heterogeneous network model which allows greater\nflexibility for embedding additional non-linearity at the core of the data\ntransformation. To this end, we propose the idea of an operational neuron or\nOperational Neural Networks (ONN), which enables a flexible non-linear and\nheterogeneous configuration employing both inter and intra-layer neuronal\ndiversity. Furthermore, we propose a robust operator search strategy inspired\nby the Hebbian theory, called the Synaptic Plasticity Monitoring (SPM) which\ncan make data-driven choices for non-linearities in any architecture. An\nextensive set of comparative evaluations of ONNs and CNNs over two severe image\ndenoising problems yield conclusive evidence that ONNs enriched by non-linear\noperators can achieve a superior denoising performance against CNNs with both\nequivalent and well-known deep configurations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:15:28 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Malik", "Junaid", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.00647", "submitter": "Chen Wang", "authors": "Chen Wang, Yuheng Qiu, Sebastian Scherer", "title": "Lifelong Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks are powerful models for many graph-structured tasks. In\nthis paper, we aim to solve the problem of lifelong learning for graph neural\nnetworks. One of the main challenges is the effect of \"catastrophic forgetting\"\nfor continuously learning a sequence of tasks, as the nodes can only be present\nto the model once. Moreover, the number of nodes changes dynamically in\nlifelong learning and this makes many graph models and sampling strategies\ninapplicable. To solve these problems, we construct a new graph topology,\ncalled the feature graph. It takes features as new nodes and turns nodes into\nindependent graphs. This successfully converts the original problem of node\nclassification to graph classification. In this way, the increasing nodes in\nlifelong learning can be regarded as increasing training samples, which makes\nlifelong learning easier. We demonstrate that the feature graph achieves much\nhigher accuracy than the state-of-the-art methods in both data-incremental and\nclass-incremental tasks. We expect that the feature graph will have broad\npotential applications for graph-structured tasks in lifelong learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 18:21:34 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Wang", "Chen", ""], ["Qiu", "Yuheng", ""], ["Scherer", "Sebastian", ""]]}, {"id": "2009.00664", "submitter": "Carlos Oliver Mr", "authors": "Carlos Oliver, Vincent Mallet, Pericles Philippopoulos, William L.\n  Hamilton, Jerome Waldispuhl", "title": "VeRNAl: Mining RNA Structures for Fuzzy Base Pairing Network Motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RNA 3D motifs are recurrent substructures, modelled as networks of base pair\ninteractions, which are crucial for understanding structure-function\nrelationships. The task of automatically identifying such motifs is\ncomputationally hard, and remains a key challenge in the field of RNA\nstructural biology and network analysis. State of the art methods solve special\ncases of the motif problem by constraining the structural variability in\noccurrences of a motif, and narrowing the substructure search space. Here, we\nrelax these constraints by posing the motif finding problem as a graph\nrepresentation learning and clustering task. This framing takes advantage of\nthe continuous nature of graph representations to model the flexibility and\nvariability of RNA motifs in an efficient manner. We propose a set of node\nsimilarity functions, clustering methods, and motif construction algorithms to\nrecover flexible RNA motifs. Our tool, VeRNAl can be easily customized by users\nto desired levels of motif flexibility, abundance and size. We show that VeRNAl\nis able to retrieve and expand known classes of motifs, as well as to propose\nnovel motifs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:03:06 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 20:34:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Oliver", "Carlos", ""], ["Mallet", "Vincent", ""], ["Philippopoulos", "Pericles", ""], ["Hamilton", "William L.", ""], ["Waldispuhl", "Jerome", ""]]}, {"id": "2009.00666", "submitter": "Akash Kumar Dhaka", "authors": "Akash Kumar Dhaka, Alejandro Catalina, Michael Riis Andersen, M{\\aa}ns\n  Magnusson, Jonathan H. Huggins, Aki Vehtari", "title": "Robust, Accurate Stochastic Optimization for Variational Inference", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fitting variational posterior approximations using\nstochastic optimization methods. The performance of these approximations\ndepends on (1) how well the variational family matches the true posterior\ndistribution,(2) the choice of divergence, and (3) the optimization of the\nvariational objective. We show that even in the best-case scenario when the\nexact posterior belongs to the assumed variational family, common stochastic\noptimization methods lead to poor variational approximations if the problem\ndimension is moderately large. We also demonstrate that these methods are not\nrobust across diverse model types. Motivated by these findings, we develop a\nmore robust and accurate stochastic optimization framework by viewing the\nunderlying optimization algorithm as producing a Markov chain. Our approach is\ntheoretically motivated and includes a diagnostic for convergence and a novel\nstopping rule, both of which are robust to noisy evaluations of the objective\nfunction. We show empirically that the proposed framework works well on a\ndiverse set of models: it can automatically detect stochastic optimization\nfailure or inaccurate variational approximation\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:12:11 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 15:45:09 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Dhaka", "Akash Kumar", ""], ["Catalina", "Alejandro", ""], ["Andersen", "Michael Riis", ""], ["Magnusson", "M\u00e5ns", ""], ["Huggins", "Jonathan H.", ""], ["Vehtari", "Aki", ""]]}, {"id": "2009.00668", "submitter": "Daiqing Li", "authors": "Daiqing Li, Amlan Kar, Nishant Ravikumar, Alejandro F Frangi, Sanja\n  Fidler", "title": "Fed-Sim: Federated Simulation for Medical Imaging", "comments": "MICCAI 2020 (Early Accept)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labelling data is expensive and time consuming especially for domains such as\nmedical imaging that contain volumetric imaging data and require expert\nknowledge. Exploiting a larger pool of labeled data available across multiple\ncenters, such as in federated learning, has also seen limited success since\ncurrent deep learning approaches do not generalize well to images acquired with\nscanners from different manufacturers. We aim to address these problems in a\ncommon, learning-based image simulation framework which we refer to as\nFederated Simulation. We introduce a physics-driven generative approach that\nconsists of two learnable neural modules: 1) a module that synthesizes 3D\ncardiac shapes along with their materials, and 2) a CT simulator that renders\nthese into realistic 3D CT Volumes, with annotations. Since the model of\ngeometry and material is disentangled from the imaging sensor, it can\neffectively be trained across multiple medical centers. We show that our data\nsynthesis framework improves the downstream segmentation performance on several\ndatasets. Project Page: https://nv-tlabs.github.io/fed-sim/ .\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:17:46 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Li", "Daiqing", ""], ["Kar", "Amlan", ""], ["Ravikumar", "Nishant", ""], ["Frangi", "Alejandro F", ""], ["Fidler", "Sanja", ""]]}, {"id": "2009.00673", "submitter": "Konstantinos Zygalakis", "authors": "J.M. Sanz-Serna and Konstantinos C. Zygalakis", "title": "The connections between Lyapunov functions for some optimization\n  algorithms and differential equations", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we study the properties of a family of second-order\ndifferential equations with damping, its discretizations and their connections\nwith accelerated optimization algorithms for $m$-strongly convex and $L$-smooth\nfunctions. In particular, using the Linear Matrix Inequality LMI framework\ndeveloped by \\emph{Fazlyab et. al. $(2018)$}, we derive analytically a\n(discrete) Lyapunov function for a two-parameter family of Nesterov\noptimization methods, which allows for the complete characterization of their\nconvergence rate. In the appropriate limit, this family of methods may be seen\nas a discretization of a family of second-order ordinary differential equations\nfor which we construct(continuous) Lyapunov functions by means of the LMI\nframework. The continuous Lyapunov functions may alternatively, be obtained by\nstudying the limiting behaviour of their discrete counterparts. Finally, we\nshow that the majority of typical discretizations of the family of ODEs, such\nas the Heavy ball method, do not possess Lyapunov functions with properties\nsimilar to those of the Lyapunov function constructed here for the Nesterov\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:49:11 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 11:18:40 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Sanz-Serna", "J. M.", ""], ["Zygalakis", "Konstantinos C.", ""]]}, {"id": "2009.00675", "submitter": "Seyedehnafiseh Mirniaharikandehei", "authors": "Seyedehnafiseh Mirniaharikandehei (1), Morteza Heidari (1), Gopichandh\n  Danala (1), Sivaramakrishnan Lakshmivarahan (2), Bin Zheng (1) ((1) School of\n  Electrical and Computer Engineering, University of Oklahoma, Norman, OK, USA,\n  (2) School of Computer Sciences, University of Oklahoma, Norman, OK, USA)", "title": "Applying a random projection algorithm to optimize machine learning\n  model for predicting peritoneal metastasis in gastric cancer patients using\n  CT images", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Objective: Non-invasively predicting the risk of cancer\nmetastasis before surgery plays an essential role in determining optimal\ntreatment methods for cancer patients (including who can benefit from\nneoadjuvant chemotherapy). Although developing radiomics based machine learning\n(ML) models has attracted broad research interest for this purpose, it often\nfaces a challenge of how to build a highly performed and robust ML model using\nsmall and imbalanced image datasets. Methods: In this study, we explore a new\napproach to build an optimal ML model. A retrospective dataset involving\nabdominal computed tomography (CT) images acquired from 159 patients diagnosed\nwith gastric cancer is assembled. Among them, 121 cases have peritoneal\nmetastasis (PM), while 38 cases do not have PM. A computer-aided detection\n(CAD) scheme is first applied to segment primary gastric tumor volumes and\ninitially computes 315 image features. Then, two Gradient Boosting Machine\n(GBM) models embedded with two different feature dimensionality reduction\nmethods, namely, the principal component analysis (PCA) and a random projection\nalgorithm (RPA) and a synthetic minority oversampling technique, are built to\npredict the risk of the patients having PM. All GBM models are trained and\ntested using a leave-one-case-out cross-validation method. Results: Results\nshow that the GBM embedded with RPA yielded a significantly higher prediction\naccuracy (71.2%) than using PCA (65.2%) (p<0.05). Conclusions: The study\ndemonstrated that CT images of the primary gastric tumors contain\ndiscriminatory information to predict the risk of PM, and RPA is a promising\nmethod to generate optimal feature vector, improving the performance of ML\nmodels of medical images.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:53:09 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mirniaharikandehei", "Seyedehnafiseh", ""], ["Heidari", "Morteza", ""], ["Danala", "Gopichandh", ""], ["Lakshmivarahan", "Sivaramakrishnan", ""], ["Zheng", "Bin", ""]]}, {"id": "2009.00690", "submitter": "Junyi Li", "authors": "Junyi Li, Bin Gu, Heng Huang", "title": "Improved Bilevel Model: Fast and Optimal Algorithm with Theoretical\n  Guarantee", "comments": "submitted to ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the hierarchical structure of many machine learning problems, bilevel\nprogramming is becoming more and more important recently, however, the\ncomplicated correlation between the inner and outer problem makes it extremely\nchallenging to solve. Although several intuitive algorithms based on the\nautomatic differentiation have been proposed and obtained success in some\napplications, not much attention has been paid to finding the optimal\nformulation of the bilevel model. Whether there exists a better formulation is\nstill an open problem. In this paper, we propose an improved bilevel model\nwhich converges faster and better compared to the current formulation. We\nprovide theoretical guarantee and evaluation results over two tasks: Data\nHyper-Cleaning and Hyper Representation Learning. The empirical results show\nthat our model outperforms the current bilevel model with a great margin.\n\\emph{This is a concurrent work with \\citet{liu2020generic} and we submitted to\nICML 2020. Now we put it on the arxiv for record.}\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:52:57 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Li", "Junyi", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "2009.00700", "submitter": "Utkarsh Sarawgi", "authors": "Utkarsh Sarawgi, Wazeer Zulfikar, Nouran Soliman, Pattie Maes", "title": "Multimodal Inductive Transfer Learning for Detection of Alzheimer's\n  Dementia and its Severity", "comments": "To appear in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alzheimer's disease is estimated to affect around 50 million people worldwide\nand is rising rapidly, with a global economic burden of nearly a trillion\ndollars. This calls for scalable, cost-effective, and robust methods for\ndetection of Alzheimer's dementia (AD). We present a novel architecture that\nleverages acoustic, cognitive, and linguistic features to form a multimodal\nensemble system. It uses specialized artificial neural networks with temporal\ncharacteristics to detect AD and its severity, which is reflected through\nMini-Mental State Exam (MMSE) scores. We first evaluate it on the ADReSS\nchallenge dataset, which is a subject-independent and balanced dataset matched\nfor age and gender to mitigate biases, and is available through DementiaBank.\nOur system achieves state-of-the-art test accuracy, precision, recall, and\nF1-score of 83.3% each for AD classification, and state-of-the-art test root\nmean squared error (RMSE) of 4.60 for MMSE score regression. To the best of our\nknowledge, the system further achieves state-of-the-art AD classification\naccuracy of 88.0% when evaluated on the full benchmark DementiaBank Pitt\ndatabase. Our work highlights the applicability and transferability of\nspontaneous speech to produce a robust inductive transfer learning model, and\ndemonstrates generalizability through a task-agnostic feature-space. The source\ncode is available at https://github.com/wazeerzulfikar/alzheimers-dementia\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 21:47:26 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Sarawgi", "Utkarsh", ""], ["Zulfikar", "Wazeer", ""], ["Soliman", "Nouran", ""], ["Maes", "Pattie", ""]]}, {"id": "2009.00707", "submitter": "Steven Kearnes", "authors": "Steven Kearnes", "title": "Pursuing a Prospective Perspective", "comments": "Trends in Chemistry (2020)", "journal-ref": null, "doi": "10.1016/j.trechm.2020.10.012", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrospective testing of predictive models does not consider the real-world\ncontext in which models are deployed. Prospective validation, on the other\nhand, enables meaningful comparisons between data generation processes by\nincorporating trained models and considering the subjective decisions that\naffect reproducibility. Prospective experiments are essential for consistent\nprogress in modeling.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:39:53 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 16:43:10 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kearnes", "Steven", ""]]}, {"id": "2009.00712", "submitter": "Kyungeun Lee", "authors": "Kyungeun Lee, Moonjung Eo, Euna Jung, Yoonjin Yoon, and Wonjong Rhee", "title": "Short-term Traffic Prediction with Deep Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern transportation systems, an enormous amount of traffic data is\ngenerated every day. This has led to rapid progress in short-term traffic\nprediction (STTP), in which deep learning methods have recently been applied.\nIn traffic networks with complex spatiotemporal relationships, deep neural\nnetworks (DNNs) often perform well because they are capable of automatically\nextracting the most important features and patterns. In this study, we survey\nrecent STTP studies applying deep networks from four perspectives. 1) We\nsummarize input data representation methods according to the number and type of\nspatial and temporal dependencies involved. 2) We briefly explain a wide range\nof DNN techniques from the earliest networks, including Restricted Boltzmann\nMachines, to the most recent, including graph-based and meta-learning networks.\n3) We summarize previous STTP studies in terms of the type of DNN techniques,\napplication area, dataset and code availability, and the type of the\nrepresented spatiotemporal dependencies. 4) We compile public traffic datasets\nthat are popular and can be used as the standard benchmarks. Finally, we\nsuggest challenging issues and possible future research directions in STTP.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:06:06 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lee", "Kyungeun", ""], ["Eo", "Moonjung", ""], ["Jung", "Euna", ""], ["Yoon", "Yoonjin", ""], ["Rhee", "Wonjong", ""]]}, {"id": "2009.00713", "submitter": "Nanxin Chen", "authors": "Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad Norouzi,\n  William Chan", "title": "WaveGrad: Estimating Gradients for Waveform Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces WaveGrad, a conditional model for waveform generation\nwhich estimates gradients of the data density. The model is built on prior work\non score matching and diffusion probabilistic models. It starts from a Gaussian\nwhite noise signal and iteratively refines the signal via a gradient-based\nsampler conditioned on the mel-spectrogram. WaveGrad offers a natural way to\ntrade inference speed for sample quality by adjusting the number of refinement\nsteps, and bridges the gap between non-autoregressive and autoregressive models\nin terms of audio quality. We find that it can generate high fidelity audio\nsamples using as few as six iterations. Experiments reveal WaveGrad to generate\nhigh fidelity audio, outperforming adversarial non-autoregressive baselines and\nmatching a strong likelihood-based autoregressive baseline using fewer\nsequential operations. Audio samples are available at\nhttps://wavegrad.github.io/.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:44:10 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 15:21:58 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Chen", "Nanxin", ""], ["Zhang", "Yu", ""], ["Zen", "Heiga", ""], ["Weiss", "Ron J.", ""], ["Norouzi", "Mohammad", ""], ["Chan", "William", ""]]}, {"id": "2009.00725", "submitter": "Davide Rigoni", "authors": "Davide Rigoni, Nicol\\`o Navarin and Alessandro Sperduti", "title": "Conditional Constrained Graph Variational Autoencoders for Molecule\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep generative models for graphs have been used to generate\nnew molecules. These models have produced good results, leading to several\nproposals in the literature. However, these models may have troubles learning\nsome of the complex laws governing the chemical world. In this work, we explore\nthe usage of the histogram of atom valences to drive the generation of\nmolecules in such models. We present Conditional Constrained Graph Variational\nAutoencoder (CCGVAE), a model that implements this key-idea in a\nstate-of-the-art model, and shows improved results on several evaluation\nmetrics on two commonly adopted datasets for molecule generation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 21:58:07 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Rigoni", "Davide", ""], ["Navarin", "Nicol\u00f2", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "2009.00748", "submitter": "Ali Hadi Zadeh", "authors": "Mostafa Mahmoud, Isak Edo, Ali Hadi Zadeh, Omar Mohamed Awad, Gennady\n  Pekhimenko, Jorge Albericio, and Andreas Moshovos", "title": "TensorDash: Exploiting Sparsity to Accelerate Deep Neural Network\n  Training and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorDash is a hardware level technique for enabling data-parallel MAC units\nto take advantage of sparsity in their input operand streams. When used to\ncompose a hardware accelerator for deep learning, TensorDash can speedup the\ntraining process while also increasing energy efficiency. TensorDash combines a\nlow-cost, sparse input operand interconnect comprising an 8-input multiplexer\nper multiplier input, with an area-efficient hardware scheduler. While the\ninterconnect allows a very limited set of movements per operand, the scheduler\ncan effectively extract sparsity when it is present in the activations, weights\nor gradients of neural networks. Over a wide set of models covering various\napplications, TensorDash accelerates the training process by $1.95{\\times}$\nwhile being $1.89\\times$ more energy-efficient, $1.6\\times$ more energy\nefficient when taking on-chip and off-chip memory accesses into account. While\nTensorDash works with any datatype, we demonstrate it with both\nsingle-precision floating-point units and bfloat16.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 23:39:35 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mahmoud", "Mostafa", ""], ["Edo", "Isak", ""], ["Zadeh", "Ali Hadi", ""], ["Awad", "Omar Mohamed", ""], ["Pekhimenko", "Gennady", ""], ["Albericio", "Jorge", ""], ["Moshovos", "Andreas", ""]]}, {"id": "2009.00757", "submitter": "Matt Shannon", "authors": "Matt Shannon", "title": "Properties of f-divergences and f-GAN training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this technical report we describe some properties of f-divergences and\nf-GAN training. We present an elementary derivation of the f-divergence lower\nbounds which form the basis of f-GAN training. We derive informative but\nperhaps underappreciated properties of f-divergences and f-GAN training,\nincluding a gradient matching property and the fact that all f-divergences\nagree up to an overall scale factor on the divergence between nearby\ndistributions. We provide detailed expressions for computing various common\nf-divergences and their variational lower bounds. Finally, based on our\nreformulation, we slightly generalize f-GAN training in a way that may improve\nits stability.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 00:21:57 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Shannon", "Matt", ""]]}, {"id": "2009.00768", "submitter": "Wei Xia", "authors": "Wei Xia, John H.L. Hansen", "title": "Speaker Representation Learning using Global Context Guided Channel and\n  Time-Frequency Transformations", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the global context guided channel and\ntime-frequency transformations to model the long-range, non-local\ntime-frequency dependencies and channel variances in speaker representations.\nWe use the global context information to enhance important channels and\nrecalibrate salient time-frequency locations by computing the similarity\nbetween the global context and local features. The proposed modules, together\nwith a popular ResNet based model, are evaluated on the VoxCeleb1 dataset,\nwhich is a large scale speaker verification corpus collected in the wild. This\nlightweight block can be easily incorporated into a CNN model with little\nadditional computational costs and effectively improves the speaker\nverification performance compared to the baseline ResNet-LDE model and the\nSqueeze&Excitation block by a large margin. Detailed ablation studies are also\nperformed to analyze various factors that may impact the performance of the\nproposed modules. We find that by employing the proposed L2-tf-GTFC\ntransformation block, the Equal Error Rate decreases from 4.56% to 3.07%, a\nrelative 32.68% reduction, and a relative 27.28% improvement in terms of the\nDCF score. The results indicate that our proposed global context guided\ntransformation modules can efficiently improve the learned speaker\nrepresentations by achieving time-frequency and channel-wise feature\nrecalibration.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 01:07:29 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 16:56:31 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Xia", "Wei", ""], ["Hansen", "John H. L.", ""]]}, {"id": "2009.00774", "submitter": "Yanchao Sun", "authors": "Yanchao Sun, Da Huo and Furong Huang", "title": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown\n  Dynamics", "comments": null, "journal-ref": "The Ninth International Conference on Learning Representations\n  (ICLR 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks on Reinforcement Learning (RL) systems could take advantage\nof RL algorithm's vulnerabilities and cause failure of the learning. However,\nprior works on poisoning RL usually either unrealistically assume the attacker\nknows the underlying Markov Decision Process (MDP), or directly apply the\npoisoning methods in supervised learning to RL. In this work, we build a\ngeneric poisoning framework for online RL via a comprehensive investigation of\nheterogeneous poisoning models in RL. Without any prior knowledge of the MDP,\nwe propose a strategic poisoning algorithm called Vulnerability-Aware\nAdversarial Critic Poison (VA2C-P), which works for most policy-based deep RL\nagents, closing the gap that no poisoning method exists for policy-based RL\nagents. VA2C-P uses a novel metric, stability radius in RL, that measures the\nvulnerability of RL algorithms. Experiments on multiple deep RL agents and\nmultiple environments show that our poisoning algorithm successfully prevents\nagents from learning a good policy or teaches the agents to converge to a\ntarget policy, with a limited attacking budget.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 01:43:30 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 22:24:47 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 16:09:16 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Sun", "Yanchao", ""], ["Huo", "Da", ""], ["Huang", "Furong", ""]]}, {"id": "2009.00792", "submitter": "Jun Shu", "authors": "Ziyi Yang, Jun Shu, Yong Liang, Deyu Meng and Zongben Xu", "title": "Select-ProtoNet: Learning to Select for Few-Shot Disease Subtype\n  Prediction", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current machine learning has made great progress on computer vision and many\nother fields attributed to the large amount of high-quality training samples,\nwhile it does not work very well on genomic data analysis, since they are\nnotoriously known as small data. In our work, we focus on few-shot disease\nsubtype prediction problem, identifying subgroups of similar patients that can\nguide treatment decisions for a specific individual through training on small\ndata. In fact, doctors and clinicians always address this problem by studying\nseveral interrelated clinical variables simultaneously. We attempt to simulate\nsuch clinical perspective, and introduce meta learning techniques to develop a\nnew model, which can extract the common experience or knowledge from\ninterrelated clinical tasks and transfer it to help address new tasks. Our new\nmodel is built upon a carefully designed meta-learner, called Prototypical\nNetwork, that is a simple yet effective meta learning machine for few-shot\nimage classification. Observing that gene expression data have specifically\nhigh dimensionality and high noise properties compared with image data, we\nproposed a new extension of it by appending two modules to address these\nissues. Concretely, we append a feature selection layer to automatically filter\nout the disease-irrelated genes and incorporate a sample reweighting strategy\nto adaptively remove noisy data, and meanwhile the extended model is capable of\nlearning from a limited number of training examples and generalize well.\nSimulations and real gene expression data experiments substantiate the\nsuperiority of the proposed method for predicting the subtypes of disease and\nidentifying potential disease-related genes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 02:50:30 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 15:50:22 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Yang", "Ziyi", ""], ["Shu", "Jun", ""], ["Liang", "Yong", ""], ["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}, {"id": "2009.00799", "submitter": "Houye Ji", "authors": "Jinghan Shi, Houye Ji, Chuan Shi, Xiao Wang, Zhiqiang Zhang, Jun Zhou", "title": "Heterogeneous Graph Neural Network for Recommendation", "comments": null, "journal-ref": "2020ICML Workshop", "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prosperous development of e-commerce has spawned diverse recommendation\nsystems. As a matter of fact, there exist rich and complex interactions among\nvarious types of nodes in real-world recommendation systems, which can be\nconstructed as heterogeneous graphs. How learn representative node embedding is\nthe basis and core of the personalized recommendation system. Meta-path is a\nwidely used structure to capture the semantics beneath such interactions and\nshow potential ability in improving node embedding. In this paper, we propose\nHeterogeneous Graph neural network for Recommendation (HGRec) which injects\nhigh-order semantic into node embedding via aggregating multi-hops meta-path\nbased neighbors and fuses rich semantics via multiple meta-paths based on\nattention mechanism to get comprehensive node embedding. Experimental results\ndemonstrate the importance of rich high-order semantics and also show the\npotentially good interpretability of HGRec.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:16:48 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Shi", "Jinghan", ""], ["Ji", "Houye", ""], ["Shi", "Chuan", ""], ["Wang", "Xiao", ""], ["Zhang", "Zhiqiang", ""], ["Zhou", "Jun", ""]]}, {"id": "2009.00801", "submitter": "Alfonso Landeros", "authors": "Alfonso Landeros, Oscar Hernan Madrid Padilla, Hua Zhou, Kenneth Lange", "title": "Extensions to the Proximal Distance of Method of Constrained\n  Optimization", "comments": "35 pages (22 main text, 10 appendices, 3 references), 9 tables, 1\n  figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current paper studies the problem of minimizing a loss\n$f(\\boldsymbol{x})$ subject to constraints of the form\n$\\boldsymbol{D}\\boldsymbol{x} \\in S$, where $S$ is a closed set, convex or not,\nand $\\boldsymbol{D}$ is a fusion matrix. Fusion constraints can capture\nsmoothness, sparsity, or more general constraint patterns. To tackle this\ngeneric class of problems, we combine the Beltrami-Courant penalty method of\noptimization with the proximal distance principle. The latter is driven by\nminimization of penalized objectives\n$f(\\boldsymbol{x})+\\frac{\\rho}{2}\\text{dist}(\\boldsymbol{D}\\boldsymbol{x},S)^2$\ninvolving large tuning constants $\\rho$ and the squared Euclidean distance of\n$\\boldsymbol{D}\\boldsymbol{x}$ from $S$. The next iterate\n$\\boldsymbol{x}_{n+1}$ of the corresponding proximal distance algorithm is\nconstructed from the current iterate $\\boldsymbol{x}_n$ by minimizing the\nmajorizing surrogate function\n$f(\\boldsymbol{x})+\\frac{\\rho}{2}\\|\\boldsymbol{D}\\boldsymbol{x}-\\mathcal{P}_S(\\boldsymbol{D}\\boldsymbol{x}_n)\\|^2$.\nFor fixed $\\rho$ and convex $f(\\boldsymbol{x})$ and $S$, we prove convergence,\nprovide convergence rates, and demonstrate linear convergence under stronger\nassumptions. We also construct a steepest descent (SD) variant to avoid costly\nlinear system solves. To benchmark our algorithms, we adapt the alternating\ndirection method of multipliers (ADMM) and compare on extensive numerical tests\nincluding problems in metric projection, convex regression, convex clustering,\ntotal variation image denoising, and projection of a matrix to one that has a\ngood condition number. Our experiments demonstrate the superior speed and\nacceptable accuracy of the steepest variant on high-dimensional problems. Julia\ncode to replicate all of our experiments can be found at\nhttps://github.com/alanderos91/ProximalDistanceAlgorithms.jl.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:32:41 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Landeros", "Alfonso", ""], ["Padilla", "Oscar Hernan Madrid", ""], ["Zhou", "Hua", ""], ["Lange", "Kenneth", ""]]}, {"id": "2009.00802", "submitter": "Andrew Lohn", "authors": "Andrew J. Lohn", "title": "Estimating the Brittleness of AI: Safety Integrity Levels and the Need\n  for Testing Out-Of-Distribution Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test, Evaluation, Verification, and Validation (TEVV) for Artificial\nIntelligence (AI) is a challenge that threatens to limit the economic and\nsocietal rewards that AI researchers have devoted themselves to producing. A\ncentral task of TEVV for AI is estimating brittleness, where brittleness\nimplies that the system functions well within some bounds and poorly outside of\nthose bounds. This paper argues that neither of those criteria are certain of\nDeep Neural Networks. First, highly touted AI successes (eg. image\nclassification and speech recognition) are orders of magnitude more\nfailure-prone than are typically certified in critical systems even within\ndesign bounds (perfectly in-distribution sampling). Second, performance falls\noff only gradually as inputs become further Out-Of-Distribution (OOD). Enhanced\nemphasis is needed on designing systems that are resilient despite\nfailure-prone AI components as well as on evaluating and improving OOD\nperformance in order to get AI to where it can clear the challenging hurdles of\nTEVV and certification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:33:40 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lohn", "Andrew J.", ""]]}, {"id": "2009.00804", "submitter": "Zhihui Zhang", "authors": "Zhihui Zhang, Jingwen Leng, Lingxiao Ma, Youshan Miao, Chao Li, Minyi\n  Guo", "title": "Architectural Implications of Graph Neural Networks", "comments": "4 pages, published in IEEE Computer Architecture Letters (CAL) 2020", "journal-ref": "in IEEE Computer Architecture Letters, vol. 19, no. 1, pp. 59-62,\n  1 Jan.-June 2020", "doi": "10.1109/LCA.2020.2988991", "report-no": null, "categories": "cs.AR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) represent an emerging line of deep learning\nmodels that operate on graph structures. It is becoming more and more popular\ndue to its high accuracy achieved in many graph-related tasks. However, GNN is\nnot as well understood in the system and architecture community as its\ncounterparts such as multi-layer perceptrons and convolutional neural networks.\nThis work tries to introduce the GNN to our community. In contrast to prior\nwork that only presents characterizations of GCNs, our work covers a large\nportion of the varieties for GNN workloads based on a general GNN description\nframework. By constructing the models on top of two widely-used libraries, we\ncharacterize the GNN computation at inference stage concerning general-purpose\nand application-specific architectures and hope our work can foster more system\nand architecture research for GNNs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:36:24 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Zhang", "Zhihui", ""], ["Leng", "Jingwen", ""], ["Ma", "Lingxiao", ""], ["Miao", "Youshan", ""], ["Li", "Chao", ""], ["Guo", "Minyi", ""]]}, {"id": "2009.00841", "submitter": "Waytehad Rose Moskolai", "authors": "Waytehad Moskola\\\"i, Wahabou Abdou (Le2i), Albert Dipanda (Le2i), Dina\n  Taiwe Kolyang (UMa)", "title": "Application of LSTM architectures for next frame forecasting in\n  Sentinel-1 images time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L'analyse pr{\\'e}dictive permet d'estimer les tendances des\n{\\'e}v{\\`e}nements futurs. De nos jours, les algorithmes Deep Learning\npermettent de faire de bonnes pr{\\'e}dictions. Cependant, pour chaque type de\nprobl{\\`e}me donn{\\'e}, il est n{\\'e}cessaire de choisir l'architecture\noptimale. Dans cet article, les mod{\\`e}les Stack-LSTM, CNN-LSTM et ConvLSTM\nsont appliqu{\\'e}s {\\`a} une s{\\'e}rie temporelle d'images radar sentinel-1, le\nbut {\\'e}tant de pr{\\'e}dire la prochaine occurrence dans une s{\\'e}quence. Les\nr{\\'e}sultats exp{\\'e}rimentaux {\\'e}valu{\\'e}s {\\`a} l'aide des indicateurs de\nperformance tels que le RMSE et le MAE, le temps de traitement et l'index de\nsimilarit{\\'e} SSIM, montrent que chacune des trois architectures peut produire\nde bons r{\\'e}sultats en fonction des param{\\`e}tres utilis{\\'e}s.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 06:44:16 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Moskola\u00ef", "Waytehad", "", "Le2i"], ["Abdou", "Wahabou", "", "Le2i"], ["Dipanda", "Albert", "", "Le2i"], ["Kolyang", "Dina Taiwe", "", "UMa"]]}, {"id": "2009.00845", "submitter": "Wouter Kouw", "authors": "Wouter M Kouw", "title": "Online system identification in a Duffing oscillator by free energy\n  minimisation", "comments": "10 pages, 5 figures. Accepted to the International Workshop on Active\n  Inference (final author version)", "journal-ref": null, "doi": "10.1007/978-3-030-64919-7_6", "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online system identification is the estimation of parameters of a dynamical\nsystem, such as mass or friction coefficients, for each measurement of the\ninput and output signals. Here, the nonlinear stochastic differential equation\nof a Duffing oscillator is cast to a generative model and dynamical parameters\nare inferred using variational message passing on a factor graph of the model.\nThe approach is validated with an experiment on data from an electronic\nimplementation of a Duffing oscillator. The proposed inference procedure\nperforms as well as offline prediction error minimisation in a state-of-the-art\nnonlinear model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 06:51:56 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kouw", "Wouter M", ""]]}, {"id": "2009.00872", "submitter": "Moritz Knolle", "authors": "Moritz Knolle (1 and 2), Georgios Kaissis (1 and 2 and 3 and 4),\n  Friederike Jungmann (1), Sebastian Ziegelmayer (1), Daniel Sasse (1), Marcus\n  Makowski (1), Daniel Rueckert (2 and 4), Rickmer Braren (1) ((1) Department\n  of diagnostic and interventional Radiology, Technical University of Munich,\n  Munich, Germany, (2) Institute for Artificial Intelligence and Data Science\n  in Medicine and Healthcare, Technical University of Munich, Munich, Germany,\n  (3) OpenMined Research, (4) Department of Computing, Imperial College London,\n  London, United Kingdom)", "title": "Efficient, high-performance pancreatic segmentation using multi-scale\n  feature extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For artificial intelligence-based image analysis methods to reach clinical\napplicability, the development of high-performance algorithms is crucial. For\nexample, existent segmentation algorithms based on natural images are neither\nefficient in their parameter use nor optimized for medical imaging. Here we\npresent MoNet, a highly optimized neural-network-based pancreatic segmentation\nalgorithm focused on achieving high performance by efficient multi-scale image\nfeature utilization.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 07:47:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 14:24:18 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Knolle", "Moritz", "", "1 and 2"], ["Kaissis", "Georgios", "", "1 and 2 and 3 and 4"], ["Jungmann", "Friederike", "", "2 and 4"], ["Ziegelmayer", "Sebastian", "", "2 and 4"], ["Sasse", "Daniel", "", "2 and 4"], ["Makowski", "Marcus", "", "2 and 4"], ["Rueckert", "Daniel", "", "2 and 4"], ["Braren", "Rickmer", ""]]}, {"id": "2009.00909", "submitter": "Wen Zhang", "authors": "Wen Zhang, Lingfei Deng, Lei Zhang, Dongrui Wu", "title": "A Survey on Negative Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning (TL) tries to utilize data or knowledge from one or more\nsource domains to facilitate the learning in a target domain. It is\nparticularly useful when the target domain has few or no labeled data, due to\nannotation expense, privacy concerns, etc. Unfortunately, the effectiveness of\nTL is not always guaranteed. Negative transfer (NT), i.e., the source domain\ndata/knowledge cause reduced learning performance in the target domain, has\nbeen a long-standing and challenging problem in TL. Various approaches to\nhandle NT have been proposed in the literature. However, this filed lacks a\nsystematic survey on the formalization of NT, their factors and the algorithms\nthat handle NT. This paper proposes to fill this gap. First, the definition of\nnegative transfer is considered and a taxonomy of the factors are discussed.\nThen, near fifty representative approaches for handling NT are categorized and\nreviewed, from four perspectives: secure transfer, domain similarity\nestimation, distant transfer and negative transfer mitigation. NT in related\nfields, e.g., multi-task learning, lifelong learning, and adversarial attacks\nare also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:20:20 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 03:05:51 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 13:01:08 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhang", "Wen", ""], ["Deng", "Lingfei", ""], ["Zhang", "Lei", ""], ["Wu", "Dongrui", ""]]}, {"id": "2009.00926", "submitter": "Paul Smyth", "authors": "Thomas Beznik, Paul Smyth, Ga\\\"el de Lannoy and John A. Lee", "title": "Deep Learning to Detect Bacterial Colonies for the Production of\n  Vaccines", "comments": "6 pages, 2 figures, accepted at ESANN 2020 (European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  During the development of vaccines, bacterial colony forming units (CFUs) are\ncounted in order to quantify the yield in the fermentation process. This manual\ntask is time-consuming and error-prone. In this work we test multiple\nsegmentation algorithms based on the U-Net CNN architecture and show that these\noffer robust, automated CFU counting. We show that the multiclass\ngeneralisation with a bespoke loss function allows distinguishing virulent and\navirulent colonies with acceptable accuracy. While many possibilities are left\nto explore, our results show the potential of deep learning for separating and\nclassifying bacterial colonies.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 10:10:43 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Beznik", "Thomas", ""], ["Smyth", "Paul", ""], ["de Lannoy", "Ga\u00ebl", ""], ["Lee", "John A.", ""]]}, {"id": "2009.00934", "submitter": "Lu Yu", "authors": "Lu Yu, Shichao Pei, Chuxu Zhang, Lizhong Ding, Jun Zhou, Longfei Li,\n  Xiangliang Zhang", "title": "Self-supervised Smoothing Graph Neural Networks", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies learning node representations with GNNs for unsupervised\nscenarios. We make a theoretical understanding and empirical demonstration\nabout the non-steady performance of GNNs over different graph datasets, when\nthe supervision signals are not appropriately defined. The performance of GNNs\ndepends on both the node feature smoothness and the graph locality. To smooth\nthe discrepancy of node proximity measured by graph topology and node feature,\nwe proposed KS2L - a novel graph \\underline{K}nowledge distillation regularized\n\\underline{S}elf-\\underline{S}upervised \\underline{L}earning framework, with\ntwo complementary regularization modules, for intra-and cross-model graph\nknowledge distillation. We demonstrate the competitive performance of KS2L on a\nvariety of benchmarks. Even with a single GCN layer, KS2L has consistently\ncompetitive or even better performance on various benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 10:27:30 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Yu", "Lu", ""], ["Pei", "Shichao", ""], ["Zhang", "Chuxu", ""], ["Ding", "Lizhong", ""], ["Zhou", "Jun", ""], ["Li", "Longfei", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2009.00945", "submitter": "Christos Koutlis", "authors": "Christos Koutlis, Symeon Papadopoulos, Manos Schinas, Ioannis\n  Kompatsiaris", "title": "LAVARNET: Neural Network Modeling of Causal Variable Relationships for\n  Multivariate Time Series Forecasting", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2020.106685", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is of great importance to many\nscientific disciplines and industrial sectors. The evolution of a multivariate\ntime series depends on the dynamics of its variables and the connectivity\nnetwork of causal interrelationships among them. Most of the existing time\nseries models do not account for the causal effects among the system's\nvariables and even if they do they rely just on determining the\nbetween-variables causality network. Knowing the structure of such a complex\nnetwork and even more specifically knowing the exact lagged variables that\ncontribute to the underlying process is crucial for the task of multivariate\ntime series forecasting. The latter is a rather unexplored source of\ninformation to leverage. In this direction, here a novel neural network-based\narchitecture is proposed, termed LAgged VAriable Representation NETwork\n(LAVARNET), which intrinsically estimates the importance of lagged variables\nand combines high dimensional latent representations of them to predict future\nvalues of time series. Our model is compared with other baseline and state of\nthe art neural network architectures on one simulated data set and four real\ndata sets from meteorology, music, solar activity, and finance areas. The\nproposed architecture outperforms the competitive architectures in most of the\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 10:57:28 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Koutlis", "Christos", ""], ["Papadopoulos", "Symeon", ""], ["Schinas", "Manos", ""], ["Kompatsiaris", "Ioannis", ""]]}, {"id": "2009.00952", "submitter": "Kun Zhan", "authors": "Kun Zhan, Chaoxi Niu", "title": "Mutual Teaching for Graph Convolutional Networks", "comments": "GCN, 8 pages, 1 figures", "journal-ref": "Future Generation Computer Systems, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks produce good predictions of unlabeled samples\ndue to its transductive label propagation. Since samples have different\npredicted confidences, we take high-confidence predictions as pseudo labels to\nexpand the label set so that more samples are selected for updating models. We\npropose a new training method named as mutual teaching, i.e., we train dual\nmodels and let them teach each other during each batch. First, each network\nfeeds forward all samples and selects samples with high-confidence predictions.\nSecond, each model is updated by samples selected by its peer network. We view\nthe high-confidence predictions as useful knowledge, and the useful knowledge\nof one network teaches the peer network with model updating in each batch. In\nmutual teaching, the pseudo-label set of a network is from its peer network.\nSince we use the new strategy of network training, performance improves\nsignificantly. Extensive experimental results demonstrate that our method\nachieves superior performance over state-of-the-art methods under very low\nlabel rates.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:10:55 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Zhan", "Kun", ""], ["Niu", "Chaoxi", ""]]}, {"id": "2009.00993", "submitter": "Albert Reuther PhD", "authors": "Albert Reuther, Peter Michaleas, Michael Jones, Vijay Gadepally,\n  Siddharth Samsi and Jeremy Kepner", "title": "Survey of Machine Learning Accelerators", "comments": "12 pages, 2 figures, IEEE-HPEC conference, Waltham, MA, September\n  21-25, 2020. arXiv admin note: text overlap with arXiv:1908.11348", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286149", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New machine learning accelerators are being announced and released each month\nfor a variety of applications from speech recognition, video object detection,\nassisted driving, and many data center applications. This paper updates the\nsurvey of of AI accelerators and processors from last year's IEEE-HPEC paper.\nThis paper collects and summarizes the current accelerators that have been\npublicly announced with performance and power consumption numbers. The\nperformance and power values are plotted on a scatter graph and a number of\ndimensions and observations from the trends on this plot are discussed and\nanalyzed. For instance, there are interesting trends in the plot regarding\npower consumption, numerical precision, and inference versus training. This\nyear, there are many more announced accelerators that are implemented with many\nmore architectures and technologies from vector engines, dataflow engines,\nneuromorphic designs, flash-based analog memory processing, and photonic-based\nprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:28:59 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Reuther", "Albert", ""], ["Michaleas", "Peter", ""], ["Jones", "Michael", ""], ["Gadepally", "Vijay", ""], ["Samsi", "Siddharth", ""], ["Kepner", "Jeremy", ""]]}, {"id": "2009.01004", "submitter": "Omar Mossad", "authors": "Omar Mossad, Amgad Ahmed, Anandharaju Raju, Hari Karthikeyan, and\n  Zayed Ahmed", "title": "FAT ALBERT: Finding Answers in Large Texts using Semantic Similarity\n  Attention Layer based on BERT", "comments": "source code available: https://github.com/omossad/fat-albert", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine based text comprehension has always been a significant research field\nin natural language processing. Once a full understanding of the text context\nand semantics is achieved, a deep learning model can be trained to solve a\nlarge subset of tasks, e.g. text summarization, classification and question\nanswering. In this paper we focus on the question answering problem,\nspecifically the multiple choice type of questions. We develop a model based on\nBERT, a state-of-the-art transformer network. Moreover, we alleviate the\nability of BERT to support large text corpus by extracting the highest\ninfluence sentences through a semantic similarity model. Evaluations of our\nproposed model demonstrate that it outperforms the leading models in the\nMovieQA challenge and we are currently ranked first in the leader board with\ntest accuracy of 87.79%. Finally, we discuss the model shortcomings and suggest\npossible improvements to overcome these limitations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 08:04:21 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mossad", "Omar", ""], ["Ahmed", "Amgad", ""], ["Raju", "Anandharaju", ""], ["Karthikeyan", "Hari", ""], ["Ahmed", "Zayed", ""]]}, {"id": "2009.01005", "submitter": "Akash Gupta", "authors": "Akash Gupta, Abhishek Aich, Amit K. Roy-Chowdhury", "title": "ALANET: Adaptive Latent Attention Network forJoint Video Deblurring and\n  Interpolation", "comments": "Accepted to ACM-MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing works address the problem of generating high frame-rate sharp videos\nby separately learning the frame deblurring and frame interpolation modules.\nMost of these approaches have a strong prior assumption that all the input\nframes are blurry whereas in a real-world setting, the quality of frames\nvaries. Moreover, such approaches are trained to perform either of the two\ntasks - deblurring or interpolation - in isolation, while many practical\nsituations call for both. Different from these works, we address a more\nrealistic problem of high frame-rate sharp video synthesis with no prior\nassumption that input is always blurry. We introduce a novel architecture,\nAdaptive Latent Attention Network (ALANET), which synthesizes sharp high\nframe-rate videos with no prior knowledge of input frames being blurry or not,\nthereby performing the task of both deblurring and interpolation. We\nhypothesize that information from the latent representation of the consecutive\nframes can be utilized to generate optimized representations for both frame\ndeblurring and frame interpolation. Specifically, we employ combination of\nself-attention and cross-attention module between consecutive frames in the\nlatent space to generate optimized representation for each frame. The optimized\nrepresentation learnt using these attention modules help the model to generate\nand interpolate sharp frames. Extensive experiments on standard datasets\ndemonstrate that our method performs favorably against various state-of-the-art\napproaches, even though we tackle a much more difficult problem.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:11:53 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Gupta", "Akash", ""], ["Aich", "Abhishek", ""], ["Roy-Chowdhury", "Amit K.", ""]]}, {"id": "2009.01008", "submitter": "Guangzhi Sun", "authors": "G. Sun, C. Zhang and P. C. Woodland", "title": "Cross-Utterance Language Models with Acoustic Error Sampling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effective exploitation of richer contextual information in language\nmodels (LMs) is a long-standing research problem for automatic speech\nrecognition (ASR). A cross-utterance LM (CULM) is proposed in this paper, which\naugments the input to a standard long short-term memory (LSTM) LM with a\ncontext vector derived from past and future utterances using an extraction\nnetwork. The extraction network uses another LSTM to encode surrounding\nutterances into vectors which are integrated into a context vector using either\na projection of LSTM final hidden states, or a multi-head self-attentive layer.\nIn addition, an acoustic error sampling technique is proposed to reduce the\nmismatch between training and test-time. This is achieved by considering\npossible ASR errors into the model training procedure, and can therefore\nimprove the word error rate (WER). Experiments performed on both AMI and\nSwitchboard datasets show that CULMs outperform the LSTM LM baseline WER. In\nparticular, the CULM with a self-attentive layer-based extraction network and\nacoustic error sampling achieves 0.6% absolute WER reduction on AMI, 0.3% WER\nreduction on the Switchboard part and 0.9% WER reduction on the Callhome part\nof Eval2000 test set over the respective baselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:40:11 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Sun", "G.", ""], ["Zhang", "C.", ""], ["Woodland", "P. C.", ""]]}, {"id": "2009.01016", "submitter": "Semin Kwak", "authors": "Semin Kwak and Nikolas Geroliminis", "title": "Travel time prediction for congested freeways with a dynamic linear\n  model", "comments": "in IEEE Transactions on Intelligent Transportation Systems, 2020", "journal-ref": null, "doi": "10.1109/TITS.2020.3006910", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of travel time is an essential feature to support\nIntelligent Transportation Systems (ITS). The non-linearity of traffic states,\nhowever, makes this prediction a challenging task. Here we propose to use\ndynamic linear models (DLMs) to approximate the non-linear traffic states.\nUnlike a static linear regression model, the DLMs assume that their parameters\nare changing across time. We design a DLM with model parameters defined at each\ntime unit to describe the spatio-temporal characteristics of time-series\ntraffic data. Based on our DLM and its model parameters analytically trained\nusing historical data, we suggest an optimal linear predictor in the minimum\nmean square error (MMSE) sense. We compare our prediction accuracy of travel\ntime for freeways in California (I210-E and I5-S) under highly congested\ntraffic conditions with those of other methods: the instantaneous travel time,\nk-nearest neighbor, support vector regression, and artificial neural network.\nWe show significant improvements in the accuracy, especially for short-term\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:48:06 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Kwak", "Semin", ""], ["Geroliminis", "Nikolas", ""]]}, {"id": "2009.01026", "submitter": "Hammond Pearce", "authors": "Hammond Pearce, Benjamin Tan, Ramesh Karri", "title": "DAVE: Deriving Automatically Verilog from English", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1145/3380446.3430634", "report-no": null, "categories": "cs.SE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While specifications for digital systems are provided in natural language,\nengineers undertake significant efforts to translate them into the programming\nlanguages understood by compilers for digital systems. Automating this process\nallows designers to work with the language in which they are most comfortable\n--the original natural language -- and focus instead on other downstream design\nchallenges. We explore the use of state-of-the-art machine learning (ML) to\nautomatically derive Verilog snippets from English via fine-tuning GPT-2, a\nnatural language ML system. We describe our approach for producing a suitable\ndataset of novice-level digital design tasks and provide a detailed exploration\nof GPT-2, finding encouraging translation performance across our task sets\n(94.8% correct), with the ability to handle both simple and abstract design\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:25:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pearce", "Hammond", ""], ["Tan", "Benjamin", ""], ["Karri", "Ramesh", ""]]}, {"id": "2009.01027", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Xiaoxing Wang, Bo Zhang, Shun Lu, Xiaolin Wei, Junchi\n  Yan", "title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators", "comments": "Accepted to ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fast development of differentiable architecture search (DARTS),\nit suffers from long-standing performance instability, which extremely limits\nits application. Existing robustifying methods draw clues from the resulting\ndeteriorated behavior instead of finding out its causing factor. Various\nindicators such as Hessian eigenvalues are proposed as a signal to stop\nsearching before the performance collapses. However, these indicator-based\nmethods tend to easily reject good architectures if the thresholds are\ninappropriately set, let alone the searching is intrinsically noisy. In this\npaper, we undertake a more subtle and direct approach to resolve the collapse.\nWe first demonstrate that skip connections have a clear advantage over other\ncandidate operations, where it can easily recover from a disadvantageous state\nand become dominant. We conjecture that this privilege is causing degenerated\nperformance. Therefore, we propose to factor out this benefit with an auxiliary\nskip connection, ensuring a fairer competition for all operations. We call this\napproach DARTS-. Extensive experiments on various datasets verify that it can\nsubstantially improve robustness. Our code is available at\nhttps://github.com/Meituan-AutoML/DARTS- .\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:54:13 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 07:58:11 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Wang", "Xiaoxing", ""], ["Zhang", "Bo", ""], ["Lu", "Shun", ""], ["Wei", "Xiaolin", ""], ["Yan", "Junchi", ""]]}, {"id": "2009.01040", "submitter": "Reza Khan Mohammadi", "authors": "Reza Khanmohammadi and Seyed Abolghasem Mirroshandel", "title": "PGST: a Polyglot Gender Style Transfer method", "comments": "It is submitted to the Natural Language Engineering Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Text Style Transfer have led this field to be more\nhighlighted than ever. The task of transferring an input's style to another is\naccompanied by plenty of challenges (e.g., fluency and content preservation)\nthat need to be taken care of. In this research, we introduce PGST, a novel\npolyglot text style transfer approach in the gender domain, composed of\ndifferent constitutive elements. In contrast to prior studies, it is feasible\nto apply a style transfer method in multiple languages by fulfilling our\nmethod's predefined elements. We have proceeded with a pre-trained word\nembedding for token replacement purposes, a character-based token classifier\nfor gender exchange purposes, and a beam search algorithm for extracting the\nmost fluent combination. Since different approaches are introduced in our\nresearch, we determine a trade-off value for evaluating different models'\nsuccess in faking our gender identification model with transferred text. To\ndemonstrate our method's multilingual applicability, we applied our method on\nboth English and Persian corpora and ended up defeating our proposed gender\nidentification model by 45.6% and 39.2%, respectively. While this research's\nfocus is not limited to a specific language, our obtained evaluation results\nare highly competitive in an analogy among English state of the art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:15:11 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 02:39:13 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Khanmohammadi", "Reza", ""], ["Mirroshandel", "Seyed Abolghasem", ""]]}, {"id": "2009.01041", "submitter": "Jiuniu Wang", "authors": "Jiuniu Wang, Wenjia Xu, Xingyu Fu, Guangluan Xu, Yirong Wu", "title": "ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition", "comments": null, "journal-ref": "Knowledge-Based Systems, Volume 197, 7 June 2020, 105842", "doi": "10.1016/j.knosys.2020.105842", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is a challenging task that extracts named\nentities from unstructured text data, including news, articles, social\ncomments, etc. The NER system has been studied for decades. Recently, the\ndevelopment of Deep Neural Networks and the progress of pre-trained word\nembedding have become a driving force for NER. Under such circumstances, how to\nmake full use of the information extracted by word embedding requires more\nin-depth research. In this paper, we propose an Adversarial Trained LSTM-CNN\n(ASTRAL) system to improve the current NER method from both the model structure\nand the training process. In order to make use of the spatial information\nbetween adjacent words, Gated-CNN is introduced to fuse the information of\nadjacent words. Besides, a specific Adversarial training method is proposed to\ndeal with the overfitting problem in NER. We add perturbation to variables in\nthe network during the training process, making the variables more diverse,\nimproving the generalization and robustness of the model. Our model is\nevaluated on three benchmarks, CoNLL-03, OntoNotes 5.0, and WNUT-17, achieving\nstate-of-the-art results. Ablation study and case study also show that our\nsystem can converge faster and is less prone to overfitting.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:15:25 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Wang", "Jiuniu", ""], ["Xu", "Wenjia", ""], ["Fu", "Xingyu", ""], ["Xu", "Guangluan", ""], ["Wu", "Yirong", ""]]}, {"id": "2009.01046", "submitter": "Marc-Andr\\'e Larochelle", "authors": "Khoury Richard and Larochelle Marc-Andr\\'e", "title": "Generalisation of Cyberbullying Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberbullying is a problem in today's ubiquitous online communities.\nFiltering it out of online conversations has proven a challenge, and efforts\nhave led to the creation of many different datasets, all offered as resources\nto train classifiers. Through these datasets, we will explore the variety of\ndefinitions of cyberbullying behaviors and the impact of these differences on\nthe portability of one classifier to another community. By analyzing the\nsimilarities between datasets, we also gain insight on the generalization power\nof the classifiers trained from them. A study of ensemble models combining\nthese classifiers will help us understand how they interact with each other.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 14:57:17 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Richard", "Khoury", ""], ["Marc-Andr\u00e9", "Larochelle", ""]]}, {"id": "2009.01047", "submitter": "Vahid Behzadan", "authors": "Bibek Upadhayay and Vahid Behzadan", "title": "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification", "comments": "Accepted for publication in the proceedings of IEEE ISI '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 02:48:11 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 04:57:21 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Upadhayay", "Bibek", ""], ["Behzadan", "Vahid", ""]]}, {"id": "2009.01048", "submitter": "Thai Le", "authors": "Thai Le, Suhang Wang, Dongwon Lee", "title": "MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models", "comments": "Accepted at the 20th IEEE International Conference on Data Mining\n  (ICDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the proliferation of so-called \"fake news\" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask \"what if adversaries\nattempt to attack such detection models?\" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:26:01 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 10:15:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Le", "Thai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""]]}, {"id": "2009.01054", "submitter": "Antti Airola", "authors": "Markus Viljanen, Antti Airola, Tapio Pahikkala", "title": "Generalized vec trick for fast learning of pairwise kernel models", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise learning corresponds to the supervised learning setting where the\ngoal is to make predictions for pairs of objects. Prominent applications\ninclude predicting drug-target or protein-protein interactions, or\ncustomer-product preferences. Several kernel functions have been proposed for\nincorporating prior knowledge about the relationship between the objects, when\ntraining kernel based learning methods. However, the number of training pairs n\nis often very large, making O(n^2) cost of constructing the pairwise kernel\nmatrix infeasible. If each training pair x= (d,t) consists of drug d and target\nt, let m and q denote the number of unique drugs and targets appearing in the\ntraining pairs. In many real-world applications m,q << n, which can be used to\ndevelop computational shortcuts. Recently, a O(nm+nq) time algorithm we refer\nto as the generalized vec trick was introduced for training kernel methods with\nthe Kronecker kernel. In this work, we show that a large class of pairwise\nkernels can be expressed as a sum of product matrices, which generalizes the\nresult to the most commonly used pairwise kernels. This includes symmetric and\nanti-symmetric, metric-learning, Cartesian, ranking, as well as linear,\npolynomial and Gaussian kernels. In the experiments, we demonstrate how the\nintroduced approach allows scaling pairwise kernels to much larger data sets\nthan previously feasible, and compare the kernels on a number of biological\ninteraction prediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:27:51 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Viljanen", "Markus", ""], ["Airola", "Antti", ""], ["Pahikkala", "Tapio", ""]]}, {"id": "2009.01062", "submitter": "Akram Hussain Engr.", "authors": "Akram Hussain, Yuan Luo", "title": "Decentralized Source Localization without Sensor Parameters in Wireless\n  Sensor Networks", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the source (event) localization problem in decentralized\nwireless sensor networks (WSNs) under the fault model without knowing the\nsensor parameters. Event localizations have many applications such as\nlocalizing intruders, Wifi hotspots and users, and faults in power systems.\nPrevious studies assume the true knowledge (or good estimates) of sensor\nparameters (e.g., fault model probability or Region of Influence (ROI) of the\nsource) for source localization. However, we propose two methods to estimate\nthe source location in this paper under the fault model: hitting set approach\nand feature selection method, which only utilize the noisy data set at the\nfusion center for estimation of the source location without knowing the sensor\nparameters. The proposed methods have been shown to localize the source\neffectively. We also study the lower bound on the sample complexity requirement\nfor hitting set method. These methods have also been extended for multiple\nsources localizations. In addition, we modify the proposed feature selection\napproach to use maximum likelihood. Finally, extensive simulations are carried\nout for different settings (i.e., the number of sensor nodes and sample\ncomplexity) to validate our proposed methods in comparison to centroid, maximum\nlikelihood, FTML, SNAP estimators.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:34:55 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 13:32:52 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 13:18:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hussain", "Akram", ""], ["Luo", "Yuan", ""]]}, {"id": "2009.01072", "submitter": "Zhe Jiang", "authors": "Arpan Man Sainju, Wenchong He, Zhe Jiang, Da Yan and Haiquan Chen", "title": "Spatial Classification With Limited Observations Based On Physics-Aware\n  Structural Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial classification with limited feature observations has been a\nchallenging problem in machine learning. The problem exists in applications\nwhere only a subset of sensors are deployed at certain spots or partial\nresponses are collected in field surveys. Existing research mostly focuses on\naddressing incomplete or missing data, e.g., data cleaning and imputation,\nclassification models that allow for missing feature values or model missing\nfeatures as hidden variables in the EM algorithm. These methods, however,\nassume that incomplete feature observations only happen on a small subset of\nsamples, and thus cannot solve problems where the vast majority of samples have\nmissing feature observations. To address this issue, we recently proposed a new\napproach that incorporates physics-aware structural constraint into the model\nrepresentation. Our approach assumes that a spatial contextual feature is\nobserved for all sample locations and establishes spatial structural constraint\nfrom the underlying spatial contextual feature map. We design efficient\nalgorithms for model parameter learning and class inference. This paper extends\nour recent approach by allowing feature values of samples in each class to\nfollow a multi-modal distribution. We propose learning algorithms for the\nextended model with multi-modal distribution. Evaluations on real-world\nhydrological applications show that our approach significantly outperforms\nbaseline methods in classification accuracy, and the multi-modal extension is\nmore robust than our early single-modal version especially when feature\ndistribution in training samples is multi-modal. Computational experiments show\nthat the proposed solution is computationally efficient on large datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:07:28 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Sainju", "Arpan Man", ""], ["He", "Wenchong", ""], ["Jiang", "Zhe", ""], ["Yan", "Da", ""], ["Chen", "Haiquan", ""]]}, {"id": "2009.01076", "submitter": "Simon Jaxy", "authors": "Simon Jaxy", "title": "Teaching a Machine to Diagnose a Heart Disease; Beginning from\n  digitizing scanned ECGs to detecting the Brugada Syndrome (BrS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical diagnoses can shape and change the life of a person drastically.\nTherefore, it is always best advised to collect as much evidence as possible to\nbe certain about the diagnosis. Unfortunately, in the case of the Brugada\nSyndrome (BrS), a rare and inherited heart disease, only one diagnostic\ncriterion exists, namely, a typical pattern in the Electrocardiogram (ECG). In\nthe following treatise, we question whether the investigation of ECG strips by\nthe means of machine learning methods improves the detection of BrS positive\ncases and hence, the diagnostic process. We propose a pipeline that reads in\nscanned images of ECGs, and transforms the encaptured signals to digital\ntime-voltage data after several processing steps. Then, we present a long\nshort-term memory (LSTM) classifier that is built based on the previously\nextracted data and that makes the diagnosis. The proposed pipeline\ndistinguishes between three major types of ECG images and recreates each\nrecorded lead signal. Features and quality are retained during the digitization\nof the data, albeit some encountered issues are not fully removed (Part I).\nNevertheless, the results of the aforesaid program are suitable for further\ninvestigation of the ECG by a computational method such as the proposed\nclassifier which proves the concept and could be the architectural basis for\nfuture research (Part II). This thesis is divided into two parts as they are\npart of the same process but conceptually different. It is hoped that this work\nbuilds a new foundation for computational investigations in the case of the BrS\nand its diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:12:50 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Jaxy", "Simon", ""]]}, {"id": "2009.01077", "submitter": "Isotta Landi", "authors": "Isotta Landi, Veronica Mandelli, Michael V. Lombardo", "title": "reval: a Python package to determine best clustering solutions with\n  stability-based relative clustering validation", "comments": null, "journal-ref": "Patterns (2021)", "doi": "10.1016/j.patter.2021.100228", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the best partition for a dataset can be a challenging task\nbecause of 1) the lack of a priori information within an unsupervised learning\nframework; and 2) the absence of a unique clustering validation approach to\nevaluate clustering solutions. Here we present reval: a Python package that\nleverages stability-based relative clustering validation methods to determine\nbest clustering solutions as the ones that best generalize to unseen data.\nStatistical software, both in R and Python, usually rely on internal validation\nmetrics, such as silhouette, to select the number of clusters that best fits\nthe data. Meanwhile, open-source software solutions that easily implement\nrelative clustering techniques are lacking. Internal validation methods exploit\ncharacteristics of the data itself to produce a result, whereas relative\napproaches attempt to leverage the unknown underlying distribution of data\npoints looking for generalizable and replicable results. The implementation of\nrelative validation methods can further the theory of clustering by enriching\nthe already available methods that can be used to investigate clustering\nresults in different situations and for different data distributions. This work\naims at contributing to this effort by developing a stability-based method that\nselects the best clustering solution as the one that replicates, via supervised\nlearning, on unseen subsets of data. The package works with multiple clustering\nand classification algorithms, hence allowing both the automatization of the\nlabeling process and the assessment of the stability of different clustering\nmechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:36:56 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 00:32:07 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Landi", "Isotta", ""], ["Mandelli", "Veronica", ""], ["Lombardo", "Michael V.", ""]]}, {"id": "2009.01109", "submitter": "Radu Tudor Ionescu", "authors": "Cezara Benegui, Radu Tudor Ionescu", "title": "Adversarial Attacks on Deep Learning Systems for User Identification\n  based on Motion Sensors", "comments": "Extended version (12 pages, 1 figure) of our paper (9 pages, 1\n  figure) accepted at ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the time being, mobile devices employ implicit authentication mechanisms,\nnamely, unlock patterns, PINs or biometric-based systems such as fingerprint or\nface recognition. While these systems are prone to well-known attacks, the\nintroduction of an explicit and unobtrusive authentication layer can greatly\nenhance security. In this study, we focus on deep learning methods for explicit\nauthentication based on motion sensor signals. In this scenario, attackers\ncould craft adversarial examples with the aim of gaining unauthorized access\nand even restraining a legitimate user to access his mobile device. To our\nknowledge, this is the first study that aims at quantifying the impact of\nadversarial attacks on machine learning models used for user identification\nbased on motion sensors. To accomplish our goal, we study multiple methods for\ngenerating adversarial examples. We propose three research questions regarding\nthe impact and the universality of adversarial examples, conducting relevant\nexperiments in order to answer our research questions. Our empirical results\ndemonstrate that certain adversarial example generation methods are specific to\nthe attacked classification model, while others tend to be generic. We thus\nconclude that deep neural networks trained for user identification tasks based\non motion sensors are subject to a high percentage of misclassification when\ngiven adversarial input.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:35:05 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 20:11:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Benegui", "Cezara", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2009.01110", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Bingli Liao, Takahiro Kanzaki", "title": "Perceptual Deep Neural Networks: Adversarial Robustness through Input\n  Recreation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have shown that albeit highly accurate, models learned\nby machines, differently from humans, have many weaknesses. However, humans'\nperception is also fundamentally different from machines, because we do not see\nthe signals which arrive at the retina but a rather complex recreation of them.\nIn this paper, we explore how machines could recreate the input as well as\ninvestigate the benefits of such an augmented perception. In this regard, we\npropose Perceptual Deep Neural Networks ($\\varphi$DNN) which also recreate\ntheir own input before further processing. The concept is formalized\nmathematically and two variations of it are developed (one based on inpainting\nthe whole image and the other based on a noisy resized super resolution\nrecreation). Experiments reveal that $\\varphi$DNNs and their adversarial\ntraining variations can increase the robustness substantially, surpassing both\nstate-of-the-art defenses and pre-processing types of defenses in 100% of the\ntests. $\\varphi$DNNs are shown to scale well to bigger image sizes, keeping a\nsimilar high accuracy throughout; while the state-of-the-art worsen up to 35%.\nMoreover, the recreation process intentionally corrupts the input image.\nInterestingly, we show by ablation tests that corrupting the input is, although\ncounter-intuitive, beneficial. Thus, $\\varphi$DNNs reveal that input recreation\nhas strong benefits for artificial neural networks similar to biological ones,\nshedding light into the importance of purposely corrupting the input as well as\npioneering an area of perception models based on GANs and autoencoders for\nrobust recognition in artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:36:36 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 09:39:09 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 08:58:13 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 10:36:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Liao", "Bingli", ""], ["Kanzaki", "Takahiro", ""]]}, {"id": "2009.01174", "submitter": "Sean I. Young", "authors": "Sean I. Young, Wang Zhe, David Taubman, and Bernd Girod", "title": "Transform Quantization for CNN Compression", "comments": "To appear in IEEE Trans Pattern Anal Mach Intell", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG eess.IV math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we compress convolutional neural network (CNN) weights\npost-training via transform quantization. Previous CNN quantization techniques\ntend to ignore the joint statistics of weights and activations, producing\nsub-optimal CNN performance at a given quantization bit-rate, or consider their\njoint statistics during training only and do not facilitate efficient\ncompression of already trained CNN models. We optimally transform (decorrelate)\nand quantize the weights post-training using a rate-distortion framework to\nimprove compression at any given quantization bit-rate. Transform quantization\nunifies quantization and dimensionality reduction (decorrelation) techniques in\na single framework to facilitate low bit-rate compression of CNNs and efficient\ninference in the transform domain. We first introduce a theory of rate and\ndistortion for CNN quantization, and pose optimum quantization as a\nrate-distortion optimization problem. We then show that this problem can be\nsolved using optimal bit-depth allocation following decorrelation by the\noptimal End-to-end Learned Transform (ELT) we derive in this paper. Experiments\ndemonstrate that transform quantization advances the state of the art in CNN\ncompression in both retrained and non-retrained quantization scenarios. In\nparticular, we find that transform quantization with retraining is able to\ncompress CNN models such as AlexNet, ResNet and DenseNet to very low bit-rates\n(1-2 bits).\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:33:42 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 17:52:53 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 04:02:55 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Young", "Sean I.", ""], ["Zhe", "Wang", ""], ["Taubman", "David", ""], ["Girod", "Bernd", ""]]}, {"id": "2009.01181", "submitter": "Sagar Kora Venu", "authors": "Sagar Kora Venu", "title": "Evaluation of Deep Convolutional Generative Adversarial Networks for\n  data augmentation of chest X-ray images", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.3390/fi13010008", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Medical image datasets are usually imbalanced, due to the high costs of\nobtaining the data and time-consuming annotations. Training deep neural network\nmodels on such datasets to accurately classify the medical condition does not\nyield desired results and often over-fits the data on majority class samples.\nIn order to address this issue, data augmentation is often performed on\ntraining data by position augmentation techniques such as scaling, cropping,\nflipping, padding, rotation, translation, affine transformation, and color\naugmentation techniques such as brightness, contrast, saturation, and hue to\nincrease the dataset sizes. These augmentation techniques are not guaranteed to\nbe advantageous in domains with limited data, especially medical image data,\nand could lead to further overfitting. In this work, we performed data\naugmentation on the Chest X-rays dataset through generative modeling (deep\nconvolutional generative adversarial network) which creates artificial\ninstances retaining similar characteristics to the original data and evaluation\nof the model resulted in Fr\\'echet Distance of Inception (FID) score of 1.289.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:43:55 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Venu", "Sagar Kora", ""]]}, {"id": "2009.01185", "submitter": "Zhongyang Li", "authors": "Zhongyang Li", "title": "Exact Recovery of Community Detection in k-Community Gaussian Mixture\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the community detection problem on a Gaussian mixture model, in\nwhich vertices are divided into $k\\geq 2$ distinct communities. The major\ndifference in our model is that the intensities for Gaussian perturbations are\ndifferent for different entries in the observation matrix, and we do not assume\nthat every community has the same number of vertices. We explicitly find the\nthreshold for the exact recovery of the maximum likelihood estimation.\nApplications include the community detection on hypergraphs.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 19:27:20 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Li", "Zhongyang", ""]]}, {"id": "2009.01192", "submitter": "Faezeh Nejati Hatamian", "authors": "Faezeh Nejati Hatamian, AmirAbbas Davari, Andreas Maier", "title": "The Effect of Various Strengths of Noises and Data Augmentations on\n  Classification of Short Single-Lead ECG Signals Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the multiple imperfections during the signal acquisition,\nElectrocardiogram (ECG) datasets are typically contaminated with numerous types\nof noise, like salt and pepper and baseline drift. These datasets may contain\ndifferent recordings with various types of noise [1] and thus, denoising may\nnot be the easiest task. Furthermore, usually, the number of labeled\nbio-signals is very limited for a proper classification task.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:26:17 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Hatamian", "Faezeh Nejati", ""], ["Davari", "AmirAbbas", ""], ["Maier", "Andreas", ""]]}, {"id": "2009.01194", "submitter": "Svetlana Kyas (Matculevich)", "authors": "Svetlana Kyas, Diego Volpatto, Martin O. Saar, and Allan M. M. Leal", "title": "Accelerated reactive transport simulations in heterogeneous porous media\n  using Reaktoro and Firedrake", "comments": "37 pages, 21 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the performance of the on-demand machine learning\n(ODML) algorithm introduced in Leal et al. (2020) when applied to different\nreactive transport problems in heterogeneous porous media. ODML was devised to\naccelerate the computationally expensive geochemical reaction calculations in\nreactive transport simulations. We demonstrate that the ODML algorithm speeds\nup these calculations by one to three orders of magnitude. Such acceleration,\nin turn, significantly accelerates the entire reactive transport simulation.\nThe numerical experiments are performed by implementing the coupling of two\nopen-source software packages: Reaktoro (Leal, 2015) and Firedrake (Rathgeber\net al., 2016).\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:06:43 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 13:24:31 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kyas", "Svetlana", ""], ["Volpatto", "Diego", ""], ["Saar", "Martin O.", ""], ["Leal", "Allan M. M.", ""]]}, {"id": "2009.01215", "submitter": "Michael Lyons", "authors": "Michael J. Lyons", "title": "Excavating \"Excavating AI\": The Elephant in the Gallery", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.5281/zenodo.4037538", "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two art exhibitions, \"Training Humans\" and \"Making Faces,\" and the\naccompanying essay \"Excavating AI: The politics of images in machine learning\ntraining sets\" by Kate Crawford and Trevor Paglen, are making substantial\nimpact on discourse taking place in the social and mass media networks, and\nsome scholarly circles. Critical scrutiny reveals, however, a\nself-contradictory stance regarding informed consent for the use of facial\nimages, as well as serious flaws in their critique of ML training sets. Our\nanalysis underlines the non-negotiability of informed consent when using human\ndata in artistic and other contexts, and clarifies issues relating to the\ndescription of ML training sets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:42:06 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 17:07:10 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 01:27:53 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lyons", "Michael J.", ""]]}, {"id": "2009.01220", "submitter": "Anamay Chaturvedi", "authors": "Anamay Chaturvedi, Huy Nguyen, Eric Xu", "title": "Differentially private $k$-means clustering via exponential mechanism\n  and max cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new $(\\epsilon_p, \\delta_p)$-differentially private algorithm\nfor the $k$-means clustering problem. Given a dataset in Euclidean space, the\n$k$-means clustering problem requires one to find $k$ points in that space such\nthat the sum of squares of Euclidean distances between each data point and its\nclosest respective point among the $k$ returned is minimised. Although there\nexist privacy-preserving methods with good theoretical guarantees to solve this\nproblem [Balcan et al., 2017; Kaplan and Stemmer, 2018], in practice it is seen\nthat it is the additive error which dictates the practical performance of these\nmethods. By reducing the problem to a sequence of instances of maximum coverage\non a grid, we are able to derive a new method that achieves lower additive\nerror then previous works. For input datasets with cardinality $n$ and diameter\n$\\Delta$, our algorithm has an $O(\\Delta^2 (k \\log^2 n\n\\log(1/\\delta_p)/\\epsilon_p + k\\sqrt{d \\log(1/\\delta_p)}/\\epsilon_p))$ additive\nerror whilst maintaining constant multiplicative error. We conclude with some\nexperiments and find an improvement over previously implemented work for this\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:52:54 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Nguyen", "Huy", ""], ["Xu", "Eric", ""]]}, {"id": "2009.01231", "submitter": "E M Wasifur Rahman Chowdhury", "authors": "Wasifur Rahman, Sangwu Lee, Md. Saiful Islam, Victor Nikhil Antony,\n  Harshil Ratnu, Mohammad Rafayet Ali, Abdullah Al Mamun, Ellen Wagner, Stella\n  Jensen-Roberts, Max A. Little, Ray Dorsey, and Ehsan Hoque", "title": "Detecting Parkinson's Disease From an Online Speech-task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CY cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we envision a web-based framework that can help anyone,\nanywhere around the world record a short speech task, and analyze the recorded\ndata to screen for Parkinson's disease (PD). We collected data from 726 unique\nparticipants (262 PD, 38% female; 464 non-PD, 65% female; average age: 61) --\nfrom all over the US and beyond. A small portion of the data was collected in a\nlab setting to compare quality. The participants were instructed to utter a\npopular pangram containing all the letters in the English alphabet \"the quick\nbrown fox jumps over the lazy dog..\". We extracted both standard acoustic\nfeatures (Mel Frequency Cepstral Coefficients (MFCC), jitter and shimmer\nvariants) and deep learning based features from the speech data. Using these\nfeatures, we trained several machine learning algorithms. We achieved 0.75 AUC\n(Area Under The Curve) performance on determining presence of self-reported\nParkinson's disease by modeling the standard acoustic features through the\nXGBoost -- a gradient-boosted decision tree model. Further analysis reveal that\nthe widely used MFCC features and a subset of previously validated dysphonia\nfeatures designed for detecting Parkinson's from verbal phonation task\n(pronouncing 'ahh') contains the most distinct information. Our model performed\nequally well on data collected in controlled lab environment as well as 'in the\nwild' across different gender and age groups. Using this tool, we can collect\ndata from almost anyone anywhere with a video/audio enabled device,\ncontributing to equity and access in neurological care.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:16:24 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 01:14:48 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 01:35:03 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 21:08:05 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rahman", "Wasifur", ""], ["Lee", "Sangwu", ""], ["Islam", "Md. Saiful", ""], ["Antony", "Victor Nikhil", ""], ["Ratnu", "Harshil", ""], ["Ali", "Mohammad Rafayet", ""], ["Mamun", "Abdullah Al", ""], ["Wagner", "Ellen", ""], ["Jensen-Roberts", "Stella", ""], ["Little", "Max A.", ""], ["Dorsey", "Ray", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2009.01235", "submitter": "Prasanna Date", "authors": "Prasanna Date", "title": "Quantum Discriminator for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computers operate in the high-dimensional tensor product spaces and\nare known to outperform classical computers on many problems. They are poised\nto accelerate machine learning tasks in the future. In this work, we operate in\nthe quantum machine learning (QML) regime where a QML model is trained using a\nquantum-classical hybrid algorithm and inferencing is performed using a quantum\nalgorithm. We leverage the traditional two-step machine learning workflow,\nwhere features are extracted from the data in the first step and a\ndiscriminator acting on the extracted features is used to classify the data in\nthe second step. Assuming that the binary features have been extracted from the\ndata, we propose a quantum discriminator for binary classification. The quantum\ndiscriminator takes as input the binary features of a data point and a\nprediction qubit in the zero state, and outputs the correct class of the data\npoint. The quantum discriminator is defined by a parameterized unitary matrix\n$U_\\Theta$ containing $\\mathcal{O}(N)$ parameters, where $N$ is the number of\ndata points in the training data set. Furthermore, we show that the quantum\ndiscriminator can be trained in $\\mathcal{O}(N \\log N)$ time using\n$\\mathcal{O}(N \\log N)$ classical bits and $\\mathcal{O}(\\log N)$ qubits. We\nalso show that inferencing for the quantum discriminator can be done in\n$\\mathcal{O}(N)$ time using $\\mathcal{O}(\\log N)$ qubits. Finally, we use the\nquantum discriminator to classify the XOR problem on the IBM Q universal\nquantum computer with $100\\%$ accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:00:23 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Date", "Prasanna", ""]]}, {"id": "2009.01270", "submitter": "Amogh Gudi", "authors": "Amogh Gudi, Xin Li, Jan van Gemert", "title": "Efficiency in Real-time Webcam Gaze Tracking", "comments": "Awarded Best Paper at European Conference on Computer Vision (ECCV)\n  Workshop on Eye Gaze in AR, VR, and in the Wild (OpenEyes) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency and ease of use are essential for practical applications of camera\nbased eye/gaze-tracking. Gaze tracking involves estimating where a person is\nlooking on a screen based on face images from a computer-facing camera. In this\npaper we investigate two complementary forms of efficiency in gaze tracking: 1.\nThe computational efficiency of the system which is dominated by the inference\nspeed of a CNN predicting gaze-vectors; 2. The usability efficiency which is\ndetermined by the tediousness of the mandatory calibration of the gaze-vector\nto a computer screen. To do so, we evaluate the computational speed/accuracy\ntrade-off for the CNN and the calibration effort/accuracy trade-off for screen\ncalibration. For the CNN, we evaluate the full face, two-eyes, and single eye\ninput. For screen calibration, we measure the number of calibration points\nneeded and evaluate three types of calibration: 1. pure geometry, 2. pure\nmachine learning, and 3. hybrid geometric regression. Results suggest that a\nsingle eye input and geometric regression calibration achieve the best\ntrade-off.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:07:41 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Gudi", "Amogh", ""], ["Li", "Xin", ""], ["van Gemert", "Jan", ""]]}, {"id": "2009.01272", "submitter": "Sirui Xie", "authors": "Sirui Xie, Shoukang Hu, Xinjiang Wang, Chunxiao Liu, Jianping Shi,\n  Xunying Liu, Dahua Lin", "title": "Understanding the wiring evolution in differentiable neural architecture\n  search", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Controversy exists on whether differentiable neural architecture search\nmethods discover wiring topology effectively. To understand how wiring topology\nevolves, we study the underlying mechanism of several existing differentiable\nNAS frameworks. Our investigation is motivated by three observed searching\npatterns of differentiable NAS: 1) they search by growing instead of pruning;\n2) wider networks are more preferred than deeper ones; 3) no edges are selected\nin bi-level optimization. To anatomize these phenomena, we propose a unified\nview on searching algorithms of existing frameworks, transferring the global\noptimization to local cost minimization. Based on this reformulation, we\nconduct empirical and theoretical analyses, revealing implicit inductive biases\nin the cost's assignment mechanism and evolution dynamics that cause the\nobserved phenomena. These biases indicate strong discrimination towards certain\ntopologies. To this end, we pose questions that future differentiable methods\nfor neural wiring discovery need to confront, hoping to evoke a discussion and\nrethinking on how much bias has been enforced implicitly in existing NAS\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:08:34 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 20:19:26 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 18:55:33 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 05:44:52 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Xie", "Sirui", ""], ["Hu", "Shoukang", ""], ["Wang", "Xinjiang", ""], ["Liu", "Chunxiao", ""], ["Shi", "Jianping", ""], ["Liu", "Xunying", ""], ["Lin", "Dahua", ""]]}, {"id": "2009.01279", "submitter": "Christopher Strohmeier", "authors": "C. Strohmeier, D. Needell", "title": "Clustering of Nonnegative Data and an Application to Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple algorithm to cluster nonnegative data\nlying in disjoint subspaces. We analyze its performance in relation to a\ncertain measure of correlation between said subspaces. We use our clustering\nalgorithm to develop a matrix completion algorithm which can outperform\nstandard matrix completion algorithms on data matrices satisfying certain\nnatural conditions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:24:47 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Strohmeier", "C.", ""], ["Needell", "D.", ""]]}, {"id": "2009.01282", "submitter": "Jeremy E. Block", "authors": "Jeremy E. Block, Eric D. Ragan", "title": "Micro-entries: Encouraging Deeper Evaluation of Mental Models Over Time\n  for Interactive Data Systems", "comments": "10 pages, submitted to BELIV 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interactive data systems combine visual representations of data with\nembedded algorithmic support for automation and data exploration. To\neffectively support transparent and explainable data systems, it is important\nfor researchers and designers to know how users understand the system. We\ndiscuss the evaluation of users' mental models of system logic. Mental models\nare challenging to capture and analyze. While common evaluation methods aim to\napproximate the user's final mental model after a period of system usage, user\nunderstanding continuously evolves as users interact with a system over time.\nIn this paper, we review many common mental model measurement techniques,\ndiscuss tradeoffs, and recommend methods for deeper, more meaningful evaluation\nof mental models when using interactive data analysis and visualization\nsystems. We present guidelines for evaluating mental models over time that\nreveal the evolution of specific model updates and how they may map to the\nparticular use of interface features and data queries. By asking users to\ndescribe what they know and how they know it, researchers can collect\nstructured, time-ordered insight into a user's conceptualization process while\nalso helping guide users to their own discoveries.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:27:04 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Block", "Jeremy E.", ""], ["Ragan", "Eric D.", ""]]}, {"id": "2009.01309", "submitter": "Jordi Luque", "authors": "Guillermo C\\'ambara, Jordi Luque and Mireia Farr\\'us", "title": "Convolutional Speech Recognition with Pitch and Voice Quality Features", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The effects of adding pitch and voice quality features such as jitter and\nshimmer to a state-of-the-art CNN model for Automatic Speech Recognition are\nstudied in this work. Pitch features have been previously used for improving\nclassical HMM and DNN baselines, while jitter and shimmer parameters have\nproven to be useful for tasks like speaker or emotion recognition. Up to our\nknowledge, this is the first work combining such pitch and voice quality\nfeatures with modern convolutional architectures, showing improvements up to 7%\nand 3% relative WER points, for the publicly available Spanish Common Voice and\nLibriSpeech 100h datasets, respectively. Particularly, our work combines these\nfeatures with mel-frequency spectral coefficients (MFSCs) to train a\nconvolutional architecture with Gated Linear Units (Conv GLUs). Such models\nhave shown to yield small word error rates, while being very suitable for\nparallel processing for online streaming recognition use cases. We have added\npitch and voice quality functionality to Facebook's wav2letter speech\nrecognition framework, and we provide with such code and recipes to the\ncommunity, to carry on with further experiments. Besides, to the best of our\nknowledge, our Spanish Common Voice recipe is the first public Spanish recipe\nfor wav2letter.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:25:50 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 11:37:09 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["C\u00e1mbara", "Guillermo", ""], ["Luque", "Jordi", ""], ["Farr\u00fas", "Mireia", ""]]}, {"id": "2009.01317", "submitter": "Zhiqiang Ma", "authors": "Zhiqiang Ma, Grace Bang, Chong Wang, Xiaomo Liu", "title": "Towards Earnings Call and Stock Price Movement", "comments": "Accepted by KDD 2020 MLF workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earnings calls are hosted by management of public companies to discuss the\ncompany's financial performance with analysts and investors. Information\ndisclosed during an earnings call is an essential source of data for analysts\nand investors to make investment decisions. Thus, we leverage earnings call\ntranscripts to predict future stock price dynamics. We propose to model the\nlanguage in transcripts using a deep learning framework, where an attention\nmechanism is applied to encode the text data into vectors for the\ndiscriminative network classifier to predict stock price movements. Our\nempirical experiments show that the proposed model is superior to the\ntraditional machine learning baselines and earnings call information can boost\nthe stock price prediction performance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 20:38:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Ma", "Zhiqiang", ""], ["Bang", "Grace", ""], ["Wang", "Chong", ""], ["Liu", "Xiaomo", ""]]}, {"id": "2009.01325", "submitter": "Ryan Lowe T.", "authors": "Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe,\n  Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano", "title": "Learning to summarize from human feedback", "comments": "NeurIPS 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As language models become more powerful, training and evaluation are\nincreasingly bottlenecked by the data and metrics used for a particular task.\nFor example, summarization models are often trained to predict human reference\nsummaries and evaluated using ROUGE, but both of these metrics are rough\nproxies for what we really care about---summary quality. In this work, we show\nthat it is possible to significantly improve summary quality by training a\nmodel to optimize for human preferences. We collect a large, high-quality\ndataset of human comparisons between summaries, train a model to predict the\nhuman-preferred summary, and use that model as a reward function to fine-tune a\nsummarization policy using reinforcement learning. We apply our method to a\nversion of the TL;DR dataset of Reddit posts and find that our models\nsignificantly outperform both human reference summaries and much larger models\nfine-tuned with supervised learning alone. Our models also transfer to CNN/DM\nnews articles, producing summaries nearly as good as the human reference\nwithout any news-specific fine-tuning. We conduct extensive analyses to\nunderstand our human feedback dataset and fine-tuned models We establish that\nour reward model generalizes to new datasets, and that optimizing our reward\nmodel results in better summaries than optimizing ROUGE according to humans. We\nhope the evidence from our paper motivates machine learning researchers to pay\ncloser attention to how their training loss affects the model behavior they\nactually want.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:54:41 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 22:19:53 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Stiennon", "Nisan", ""], ["Ouyang", "Long", ""], ["Wu", "Jeff", ""], ["Ziegler", "Daniel M.", ""], ["Lowe", "Ryan", ""], ["Voss", "Chelsea", ""], ["Radford", "Alec", ""], ["Amodei", "Dario", ""], ["Christiano", "Paul", ""]]}, {"id": "2009.01328", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "An Internal Cluster Validity Index Using a Distance-based Separability\n  Measure", "comments": "8 pages, 4 figures. Accepted by IEEE ICTAI 2020 (Long Paper & Oral\n  Presentation)", "journal-ref": "IEEE 32nd International Conference on Tools with Artificial\n  Intelligence (ICTAI), 2020, pp. 827-834", "doi": "10.1109/ICTAI50040.2020.00131", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To evaluate clustering results is a significant part of cluster analysis.\nThere are no true class labels for clustering in typical unsupervised learning.\nThus, a number of internal evaluations, which use predicted labels and data,\nhave been created. They are also named internal cluster validity indices\n(CVIs). Without true labels, to design an effective CVI is not simple because\nit is similar to create a clustering method. And, to have more CVIs is crucial\nbecause there is no universal CVI that can be used to measure all datasets, and\nno specific method for selecting a proper CVI for clusters without true labels.\nTherefore, to apply more CVIs to evaluate clustering results is necessary. In\nthis paper, we propose a novel CVI - called Distance-based Separability Index\n(DSI), based on a data separability measure. We applied the DSI and eight other\ninternal CVIs including early studies from Dunn (1974) to most recent studies\nCVDD (2019) as comparison. We used an external CVI as ground truth for\nclustering results of five clustering algorithms on 12 real and 97 synthetic\ndatasets. Results show DSI is an effective, unique, and competitive CVI to\nother compared CVIs. In addition, we summarized the general process to evaluate\nCVIs and created a new method - rank difference - to compare the results of\nCVIs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 20:20:29 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 21:22:03 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2009.01358", "submitter": "Aur\\'elien Serre", "authors": "Aur\\'elien Serre, Didier Ch\\'etelat, Andrea Lodi", "title": "Change Point Detection by Cross-Entropy Maximization", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many offline unsupervised change point detection algorithms rely on\nminimizing a penalized sum of segment-wise costs. We extend this framework by\nproposing to minimize a sum of discrepancies between segments. In particular,\nwe propose to select the change points so as to maximize the cross-entropy\nbetween successive segments, balanced by a penalty for introducing new change\npoints. We propose a dynamic programming algorithm to solve this problem and\nanalyze its complexity. Experiments on two challenging datasets demonstrate the\nadvantages of our method compared to three state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:45:13 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Serre", "Aur\u00e9lien", ""], ["Ch\u00e9telat", "Didier", ""], ["Lodi", "Andrea", ""]]}, {"id": "2009.01360", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Tian Zhou, Bharatbhushan Shetty, Brendan Kitts,\n  Shengjun Pan, Junwei Pan, Aaron Flores", "title": "Bid Shading in The Brave New World of First-Price Auctions", "comments": "In Proceedings of the 29th ACM International Conference on\n  Information and Knowledge Management (CIKM'20), October 19-23, 2020, Virtual\n  Event, Ireland", "journal-ref": null, "doi": "10.1145/3340531.3412689", "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online auctions play a central role in online advertising, and are one of the\nmain reasons for the industry's scalability and growth. With great changes in\nhow auctions are being organized, such as changing the second- to first-price\nauction type, advertisers and demand platforms are compelled to adapt to a new\nvolatile environment. Bid shading is a known technique for preventing\noverpaying in auction systems that can help maintain the strategy equilibrium\nin first-price auctions, tackling one of its greatest drawbacks. In this study,\nwe propose a machine learning approach of modeling optimal bid shading for\nnon-censored online first-price ad auctions. We clearly motivate the approach\nand extensively evaluate it in both offline and online settings on a major\ndemand side platform. The results demonstrate the superiority and robustness of\nthe new approach as compared to the existing approaches across a range of\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:48:21 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Zhou", "Tian", ""], ["Shetty", "Bharatbhushan", ""], ["Kitts", "Brendan", ""], ["Pan", "Shengjun", ""], ["Pan", "Junwei", ""], ["Flores", "Aaron", ""]]}, {"id": "2009.01362", "submitter": "Matthew Dowling", "authors": "Matthew Dowling, Yuan Zhao, Il Memming Park", "title": "Non-parametric generalized linear model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in statistical neuroscience is to model how neurons\nencode information by analyzing electrophysiological recordings. A popular and\nwidely-used approach is to fit the spike trains with an autoregressive point\nprocess model. These models are characterized by a set of convolutional\ntemporal filters, whose subsequent analysis can help reveal how neurons encode\nstimuli, interact with each other, and process information. In practice a\nsufficiently rich but small ensemble of temporal basis functions needs to be\nchosen to parameterize the filters. However, obtaining a satisfactory fit often\nrequires burdensome model selection and fine tuning the form of the basis\nfunctions and their temporal span. In this paper we propose a nonparametric\napproach for jointly inferring the filters and hyperparameters using the\nGaussian process framework. Our method is computationally efficient taking\nadvantage of the sparse variational approximation while being flexible and rich\nenough to characterize arbitrary filters in continuous time lag. Moreover, our\nmethod automatically learns the temporal span of the filter. For the particular\napplication in neuroscience, we designed priors for stimulus and history\nfilters useful for the spike trains. We compare and validate our method on\nsimulated and real neural spike train data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 21:54:53 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Dowling", "Matthew", ""], ["Zhao", "Yuan", ""], ["Park", "Il Memming", ""]]}, {"id": "2009.01366", "submitter": "Anubhav Reddy Nallabasannagari", "authors": "Anubhav Reddy Nallabasannagari, Madhu Reddiboina, Ryan Seltzer, Trevor\n  Zeffiro, Ajay Sharma, Mahendra Bhandari", "title": "All Data Inclusive, Deep Learning Models to Predict Critical Events in\n  the Medical Information Mart for Intensive Care III Database (MIMIC III)", "comments": "18 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive care clinicians need reliable clinical practice tools to preempt\nunexpected critical events that might harm their patients in intensive care\nunits (ICU), to pre-plan timely interventions, and to keep the patient's family\nwell informed. The conventional statistical models are built by curating only a\nlimited number of key variables, which means a vast unknown amount of\npotentially precious data remains unused. Deep learning models (DLMs) can be\nleveraged to learn from large complex datasets and construct predictive\nclinical tools. This retrospective study was performed using 42,818 hospital\nadmissions involving 35,348 patients, which is a subset of the MIMIC-III\ndataset. Natural language processing (NLP) techniques were applied to build\nDLMs to predict in-hospital mortality (IHM) and length of stay >=7 days (LOS).\nOver 75 million events across multiple data sources were processed, resulting\nin over 355 million tokens. DLMs for predicting IHM using data from all sources\n(AS) and chart data (CS) achieved an AUC-ROC of 0.9178 and 0.9029,\nrespectively, and PR-AUC of 0.6251 and 0.5701, respectively. DLMs for\npredicting LOS using AS and CS achieved an AUC-ROC of 0.8806 and 0.8642,\nrespectively, and PR-AUC of 0.6821 and 0.6575, respectively. The observed\nAUC-ROC difference between models was found to be significant for both IHM and\nLOS at p=0.05. The observed PR-AUC difference between the models was found to\nbe significant for IHM and statistically insignificant for LOS at p=0.05. In\nthis study, deep learning models were constructed using data combined from a\nvariety of sources in Electronic Health Records (EHRs) such as chart data,\ninput and output events, laboratory values, microbiology events, procedures,\nnotes, and prescriptions. It is possible to predict in-hospital mortality with\nmuch better confidence and higher reliability from models built using all\nsources of data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:12:18 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Nallabasannagari", "Anubhav Reddy", ""], ["Reddiboina", "Madhu", ""], ["Seltzer", "Ryan", ""], ["Zeffiro", "Trevor", ""], ["Sharma", "Ajay", ""], ["Bhandari", "Mahendra", ""]]}, {"id": "2009.01367", "submitter": "Nathan Tsoi", "authors": "Nathan Tsoi, Yofti Milkessa, Marynel V\\'azquez", "title": "A Heaviside Function Approximation for Neural Network Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network binary classifiers are often evaluated on metrics like\naccuracy and $F_1$-Score, which are based on confusion matrix values (True\nPositives, False Positives, False Negatives, and True Negatives). However,\nthese classifiers are commonly trained with a different loss, e.g. log loss.\nWhile it is preferable to perform training on the same loss as the evaluation\nmetric, this is difficult in the case of confusion matrix based metrics because\nset membership is a step function without a derivative useful for\nbackpropagation. To address this challenge, we propose an approximation of the\nstep function that adheres to the properties necessary for effective training\nof binary networks using confusion matrix based metrics. This approach allows\nfor end-to-end training of binary deep neural classifiers via batch gradient\ndescent. We demonstrate the flexibility of this approach in several\napplications with varying levels of class imbalance. We also demonstrate how\nthe approximation allows balancing between precision and recall in the\nappropriate ratio for the task at hand.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:13:26 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tsoi", "Nathan", ""], ["Milkessa", "Yofti", ""], ["V\u00e1zquez", "Marynel", ""]]}, {"id": "2009.01368", "submitter": "Biswadeep Chakraborty", "authors": "Biswadeep Chakraborty, Dinil Mon Divakaran, Ido Nevat, Gareth W.\n  Peters, Mohan Gurusamy", "title": "Cost-aware Feature Selection for IoT Device Classification", "comments": "33 pages, 9 figures", "journal-ref": "Internet of Things Journal 2021", "doi": "10.1109/JIOT.2021.3051480", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of IoT devices into different types is of paramount\nimportance, from multiple perspectives, including security and privacy aspects.\nRecent works have explored machine learning techniques for fingerprinting (or\nclassifying) IoT devices, with promising results. However, existing works have\nassumed that the features used for building the machine learning models are\nreadily available or can be easily extracted from the network traffic; in other\nwords, they do not consider the costs associated with feature extraction. In\nthis work, we take a more realistic approach, and argue that feature extraction\nhas a cost, and the costs are different for different features. We also take a\nstep forward from the current practice of considering the misclassification\nloss as a binary value, and make a case for different losses based on the\nmisclassification performance. Thereby, and more importantly, we introduce the\nnotion of risk for IoT device classification. We define and formulate the\nproblem of cost-aware IoT device classification. This being a combinatorial\noptimization problem, we develop a novel algorithm to solve it in a fast and\neffective way using the Cross-Entropy (CE) based stochastic optimization\ntechnique. Using traffic of real devices, we demonstrate the capability of the\nCE based algorithm in selecting features with minimal risk of misclassification\nwhile keeping the cost for feature extraction within a specified limit.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:16:11 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:45:18 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 18:48:57 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Chakraborty", "Biswadeep", ""], ["Divakaran", "Dinil Mon", ""], ["Nevat", "Ido", ""], ["Peters", "Gareth W.", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "2009.01369", "submitter": "Ayman Mukhaimar Mr", "authors": "Ayman Mukhaimar, Ruwan Tennakoon, Chow Yin Lai, Reza Hoseinnezhad,\n  Alireza Bab-Hadiashar", "title": "Robust Object Classification Approach using Spherical Harmonics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a robust spherical harmonics approach for the\nclassification of point cloud-based objects. Spherical harmonics have been used\nfor classification over the years, with several frameworks existing in the\nliterature. These approaches use variety of spherical harmonics based\ndescriptors to classify objects. We first investigated these frameworks\nrobustness against data augmentation, such as outliers and noise, as it has not\nbeen studied before. Then we propose a spherical convolution neural network\nframework for robust object classification. The proposed framework uses the\nvoxel grid of concentric spheres to learn features over the unit ball. Our\nproposed model learn features that are less sensitive to data augmentation due\nto the selected sampling strategy and the designed convolution operation. We\ntested our proposed model against several types of data augmentation, such as\nnoise and outliers. Our results show that the proposed model outperforms the\nstate of art networks in terms of robustness to data augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:29:06 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Mukhaimar", "Ayman", ""], ["Tennakoon", "Ruwan", ""], ["Lai", "Chow Yin", ""], ["Hoseinnezhad", "Reza", ""], ["Bab-Hadiashar", "Alireza", ""]]}, {"id": "2009.01371", "submitter": "Zhihong Pan", "authors": "Zhihong Pan, Baopu Li, Teng Xi, Yanwen Fan, Gang Zhang, Jingtuo Liu,\n  Junyu Han, Errui Ding", "title": "Real Image Super Resolution Via Heterogeneous Model Ensemble using\n  GP-NAS", "comments": "This is a manuscript related to our algorithm that won the ECCV AIM\n  2020 Real Image Super-Resolution Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With advancement in deep neural network (DNN), recent state-of-the-art (SOTA)\nimage superresolution (SR) methods have achieved impressive performance using\ndeep residual network with dense skip connections. While these models perform\nwell on benchmark dataset where low-resolution (LR) images are constructed from\nhigh-resolution (HR) references with known blur kernel, real image SR is more\nchallenging when both images in the LR-HR pair are collected from real cameras.\nBased on existing dense residual networks, a Gaussian process based neural\narchitecture search (GP-NAS) scheme is utilized to find candidate network\narchitectures using a large search space by varying the number of dense\nresidual blocks, the block size and the number of features. A suite of\nheterogeneous models with diverse network structure and hyperparameter are\nselected for model-ensemble to achieve outstanding performance in real image\nSR. The proposed method won the first place in all three tracks of the AIM 2020\nReal Image Super-Resolution Challenge.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 22:33:23 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 18:48:30 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Pan", "Zhihong", ""], ["Li", "Baopu", ""], ["Xi", "Teng", ""], ["Fan", "Yanwen", ""], ["Zhang", "Gang", ""], ["Liu", "Jingtuo", ""], ["Han", "Junyu", ""], ["Ding", "Errui", ""]]}, {"id": "2009.01395", "submitter": "E Zhenqian", "authors": "E Zhenqian and Gao Weiguo", "title": "A Partial Regularization Method for Network Compression", "comments": "made a mistake of submit the paper; I have updated the version of\n  arXiv:1912.05078", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved remarkable success relying on the\ndeveloping availability of GPUs and large-scale datasets with increasing\nnetwork depth and width. However, due to the expensive computation and\nintensive memory, researchers have concentrated on designing compression\nmethods in order to make them practical for constrained platforms. In this\npaper, we propose an approach of partial regularization rather than the\noriginal form of penalizing all parameters, which is said to be full\nregularization, to conduct model compression at a higher speed. It is\nreasonable and feasible according to the existence of the permutation invariant\nproperty of neural networks. Experimental results show that as we expected, the\ncomputational complexity is reduced by observing less running time in almost\nall situations. It should be owing to the fact that partial regularization\nmethod invovles a lower number of elements for calculation. Surprisingly, it\nhelps to improve some important metrics such as regression fitting results and\nclassification accuracy in both training and test phases on multiple datasets,\ntelling us that the pruned models have better performance and generalization\nability. What's more, we analyze the results and draw a conclusion that an\noptimal network structure must exist and depend on the input data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 00:38:27 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 02:51:03 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Zhenqian", "E", ""], ["Weiguo", "Gao", ""]]}, {"id": "2009.01398", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Garrett T. Kenyon", "title": "It's Hard for Neural Networks To Learn the Game of Life", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efforts to improve the learning abilities of neural networks have focused\nmostly on the role of optimization methods rather than on weight\ninitializations. Recent findings, however, suggest that neural networks rely on\nlucky random initial weights of subnetworks called \"lottery tickets\" that\nconverge quickly to a solution. To investigate how weight initializations\naffect performance, we examine small convolutional networks that are trained to\npredict n steps of the two-dimensional cellular automaton Conway's Game of\nLife, the update rules of which can be implemented efficiently in a 2n+1 layer\nconvolutional network. We find that networks of this architecture trained on\nthis task rarely converge. Rather, networks require substantially more\nparameters to consistently converge. In addition, near-minimal architectures\nare sensitive to tiny changes in parameters: changing the sign of a single\nweight can cause the network to fail to learn. Finally, we observe a critical\nvalue d_0 such that training minimal networks with examples in which cells are\nalive with probability d_0 dramatically increases the chance of convergence to\na solution. We conclude that training convolutional neural networks to learn\nthe input/output function represented by n steps of Game of Life exhibits many\ncharacteristics predicted by the lottery ticket hypothesis, namely, that the\nsize of the networks required to learn this function are often significantly\nlarger than the minimal network required to implement the function.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 00:47:08 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Springer", "Jacob M.", ""], ["Kenyon", "Garrett T.", ""]]}, {"id": "2009.01399", "submitter": "Jianping Kelvin Li", "authors": "Jianping Kelvin Li and Kwan-Liu Ma", "title": "P6: A Declarative Language for Integrating Machine Learning in Visual\n  Analytics", "comments": "Accepted for presentation at IEEE VIS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.HC cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present P6, a declarative language for building high performance visual\nanalytics systems through its support for specifying and integrating machine\nlearning and interactive visualization methods. As data analysis methods based\non machine learning and artificial intelligence continue to advance, a visual\nanalytics solution can leverage these methods for better exploiting large and\ncomplex data. However, integrating machine learning methods with interactive\nvisual analysis is challenging. Existing declarative programming libraries and\ntoolkits for visualization lack support for coupling machine learning methods.\nBy providing a declarative language for visual analytics, P6 can empower more\ndevelopers to create visual analytics applications that combine machine\nlearning and visualization methods for data analysis and problem solving.\nThrough a variety of example applications, we demonstrate P6's capabilities and\nshow the benefits of using declarative specifications to build visual analytics\nsystems. We also identify and discuss the research opportunities and challenges\nfor declarative visual analytics.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 00:58:02 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Li", "Jianping Kelvin", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2009.01411", "submitter": "Bowen Jing", "authors": "Bowen Jing, Stephan Eismann, Patricia Suriana, Raphael J.L. Townshend,\n  Ron Dror", "title": "Learning from Protein Structure with Geometric Vector Perceptrons", "comments": "Presented at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning on 3D structures of large biomolecules is emerging as a distinct\narea in machine learning, but there has yet to emerge a unifying network\narchitecture that simultaneously leverages the graph-structured and geometric\naspects of the problem domain. To address this gap, we introduce geometric\nvector perceptrons, which extend standard dense layers to operate on\ncollections of Euclidean vectors. Graph neural networks equipped with such\nlayers are able to perform both geometric and relational reasoning on efficient\nand natural representations of macromolecular structure. We demonstrate our\napproach on two important problems in learning from protein structure: model\nquality assessment and computational protein design. Our approach improves over\nexisting classes of architectures, including state-of-the-art graph-based and\nvoxel-based methods. We release our code at https://github.com/drorlab/gvp.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 01:54:25 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 15:30:18 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 02:35:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jing", "Bowen", ""], ["Eismann", "Stephan", ""], ["Suriana", "Patricia", ""], ["Townshend", "Raphael J. L.", ""], ["Dror", "Ron", ""]]}, {"id": "2009.01420", "submitter": "Jose Hugo Elsas", "authors": "J.H. Gaspar Elsas, N.A.G. Casaprima, I.F.M. Menezes", "title": "Accelerating engineering design by automatic selection of simulation\n  cases through Pool-Based Active Learning", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common workflow for many engineering design problems requires the\nevaluation of the design system to be investigated under a range of conditions.\nThese conditions usually involve a combination of several parameters. To\nperform a complete evaluation of a single candidate configuration, it may be\nnecessary to perform hundreds to thousands of simulations. This can be\ncomputationally very expensive, particularly if several configurations need to\nbe evaluated, as in the case of the mathematical optimization of a design\nproblem. Although the simulations are extremely complex, generally, there is a\nhigh degree of redundancy in them, as many of the cases vary only slightly from\none another. This redundancy can be exploited by omitting some simulations that\nare uninformative, thereby reducing the number of simulations required to\nobtain a reasonable approximation of the complete system. The decision of which\nsimulations are useful is made through the use of machine learning techniques,\nwhich allow us to estimate the results of \"yet-to-be-performed\" simulations\nfrom the ones that are already performed. In this study, we present the results\nof one such technique, namely active learning, to provide an approximate result\nof an entire offshore riser design simulation portfolio from a subset that is\n80% smaller than the original one. These results are expected to facilitate a\nsignificant speed-up in the offshore riser design.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 02:31:59 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 01:05:37 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Elsas", "J. H. Gaspar", ""], ["Casaprima", "N. A. G.", ""], ["Menezes", "I. F. M.", ""]]}, {"id": "2009.01431", "submitter": "Zhe Lin", "authors": "Zhe Lin, Sharad Sinha, Wei Zhang", "title": "Towards Efficient and Scalable Acceleration of Online Decision Tree\n  Learning on FPGA", "comments": "appear as a conference paper in FCCM 2019", "journal-ref": null, "doi": "10.1109/FCCM.2019.00032", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are machine learning models commonly used in various\napplication scenarios. In the era of big data, traditional decision tree\ninduction algorithms are not suitable for learning large-scale datasets due to\ntheir stringent data storage requirement. Online decision tree learning\nalgorithms have been devised to tackle this problem by concurrently training\nwith incoming samples and providing inference results. However, even the most\nup-to-date online tree learning algorithms still suffer from either high memory\nusage or high computational intensity with dependency and long latency, making\nthem challenging to implement in hardware. To overcome these difficulties, we\nintroduce a new quantile-based algorithm to improve the induction of the\nHoeffding tree, one of the state-of-the-art online learning models. The\nproposed algorithm is light-weight in terms of both memory and computational\ndemand, while still maintaining high generalization ability. A series of\noptimization techniques dedicated to the proposed algorithm have been\ninvestigated from the hardware perspective, including coarse-grained and\nfine-grained parallelism, dynamic and memory-based resource sharing, pipelining\nwith data forwarding. We further present a high-performance, hardware-efficient\nand scalable online decision tree learning system on a field-programmable gate\narray (FPGA) with system-level optimization techniques. Experimental results\nshow that our proposed algorithm outperforms the state-of-the-art Hoeffding\ntree learning method, leading to 0.05% to 12.3% improvement in inference\naccuracy. Real implementation of the complete learning system on the FPGA\ndemonstrates a 384x to 1581x speedup in execution time over the\nstate-of-the-art design.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 03:23:43 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lin", "Zhe", ""], ["Sinha", "Sharad", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.01432", "submitter": "Zhe Lin", "authors": "Zhe Lin, Sharad Sinha, Wei Zhang", "title": "An Ensemble Learning Approach for In-situ Monitoring of FPGA Dynamic\n  Power", "comments": "published as a journal (TCAD) paper in 2018", "journal-ref": null, "doi": "10.1109/TCAD.2018.2859248", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As field-programmable gate arrays become prevalent in critical application\ndomains, their power consumption is of high concern. In this paper, we present\nand evaluate a power monitoring scheme capable of accurately estimating the\nruntime dynamic power of FPGAs in a fine-grained timescale, in order to support\nemerging power management techniques. In particular, we describe a novel and\nspecialized ensemble model which can be decomposed into multiple customized\ndecision-tree-based base learners. To aid in model synthesis, a generic\ncomputer-aided design flow is proposed to generate samples, select features,\ntune hyperparameters and train the ensemble estimator. Besides this, a hardware\nrealization of the trained ensemble estimator is presented for on-chip\nreal-time power estimation. In the experiments, we first show that a single\ndecision tree model can achieve prediction error within 4.51% of a commercial\ngate-level power estimation tool, which is 2.41--6.07x lower than provided by\nthe commonly used linear model. More importantly, we study the extra gains in\ninference accuracy using the proposed ensemble model. Experimental results\nreveal that the ensemble monitoring method can further improve the accuracy of\npower predictions to within a maximum error of 1.90%. Moreover, the lookup\ntable (LUT) overhead of the ensemble monitoring hardware employing up to 64\nbase learners is within 1.22% of the target FPGA, indicating its light-weight\nand scalable characteristics.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 03:39:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lin", "Zhe", ""], ["Sinha", "Sharad", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.01433", "submitter": "Alejandro Parada-Mayorga", "authors": "Alejandro Parada-Mayorga and Alejandro Ribeiro", "title": "Algebraic Neural Networks: Stability to Deformations", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3084537", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algebraic neural networks (AlgNNs) with commutative algebras which\nunify diverse architectures such as Euclidean convolutional neural networks,\ngraph neural networks, and group neural networks under the umbrella of\nalgebraic signal processing. An AlgNN is a stacked layered information\nprocessing structure where each layer is conformed by an algebra, a vector\nspace and a homomorphism between the algebra and the space of endomorphisms of\nthe vector space. Signals are modeled as elements of the vector space and are\nprocessed by convolutional filters that are defined as the images of the\nelements of the algebra under the action of the homomorphism. We analyze\nstability of algebraic filters and AlgNNs to deformations of the homomorphism\nand derive conditions on filters that lead to Lipschitz stable operators. We\nconclude that stable algebraic filters have frequency responses -- defined as\neigenvalue domain representations -- whose derivative is inversely proportional\nto the frequency -- defined as eigenvalue magnitudes. It follows that for a\ngiven level of discriminability, AlgNNs are more stable than algebraic filters,\nthereby explaining their better empirical performance. This same phenomenon has\nbeen proven for Euclidean convolutional neural networks and graph neural\nnetworks. Our analysis shows that this is a deep algebraic property shared by a\nnumber of architectures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 03:41:38 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 19:04:39 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 22:14:54 GMT"}, {"version": "v4", "created": "Sat, 1 May 2021 05:10:35 GMT"}, {"version": "v5", "created": "Wed, 30 Jun 2021 23:17:55 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Parada-Mayorga", "Alejandro", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2009.01434", "submitter": "Zhe Lin", "authors": "Zhe Lin, Wei Zhang, Sharad Sinha", "title": "Decision Tree Based Hardware Power Monitoring for Run Time Dynamic Power\n  Management in FPGA", "comments": "published as a conference paper in FPL 2017", "journal-ref": null, "doi": "10.23919/FPL.2017.8056832", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained runtime power management techniques could be promising solutions\nfor power reduction. Therefore, it is essential to establish accurate power\nmonitoring schemes to obtain dynamic power variation in a short period (i.e.,\ntens or hundreds of clock cycles). In this paper, we leverage a\ndecision-tree-based power modeling approach to establish fine-grained hardware\npower monitoring on FPGA platforms. A generic and complete design flow is\ndeveloped to implement the decision tree power model which is capable of\nprecisely estimating dynamic power in a fine-grained manner. A flexible\narchitecture of the hardware power monitoring is proposed, which can be\ninstrumented in any RTL design for runtime power estimation, dispensing with\nthe need for extra power measurement devices. Experimental results of applying\nthe proposed model to benchmarks with different resource types reveal an\naverage error up to 4% for dynamic power estimation. Moreover, the overheads of\narea, power and performance incurred by the power monitoring circuitry are\nextremely low. Finally, we apply our power monitoring technique to the power\nmanagement using phase shedding with an on-chip multi-phase regulator as a\nproof of concept and the results demonstrate 14% efficiency enhancement for the\npower supply of the FPGA internal logic.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 03:46:12 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lin", "Zhe", ""], ["Zhang", "Wei", ""], ["Sinha", "Sharad", ""]]}, {"id": "2009.01444", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Sara Evensen and Chang Ge and Dongjin Choi and \\c{C}a\\u{g}atay\n  Demiralp", "title": "Data Programming by Demonstration: A Framework for Interactively\n  Learning Labeling Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DB cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data programming is a programmatic weak supervision approach to efficiently\ncurate large-scale labeled training data. Writing data programs (labeling\nfunctions) requires, however, both programming literacy and domain expertise.\nMany subject matter experts have neither programming proficiency nor time to\neffectively write data programs. Furthermore, regardless of one's expertise in\ncoding or machine learning, transferring domain expertise into labeling\nfunctions by enumerating rules and thresholds is not only time consuming but\nalso inherently difficult. Here we propose a new framework, data programming by\ndemonstration (DPBD), to generate labeling rules using interactive\ndemonstrations of users. DPBD aims to relieve the burden of writing labeling\nfunctions from users, enabling them to focus on higher-level semantics such as\nidentifying relevant signals for labeling tasks. We operationalize our\nframework with Ruler, an interactive system that synthesizes labeling rules for\ndocument classification by using span-level annotations of users on document\nexamples. We compare Ruler with conventional data programming through a user\nstudy conducted with 10 data scientists creating labeling functions for\nsentiment and spam classification tasks. We find that Ruler is easier to use\nand learn and offers higher overall satisfaction, while providing\ndiscriminative model performances comparable to ones achieved by conventional\ndata programming.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 04:25:08 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 01:44:22 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 22:44:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Evensen", "Sara", ""], ["Ge", "Chang", ""], ["Choi", "Dongjin", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "2009.01454", "submitter": "Enyan Dai", "authors": "Enyan Dai, Suhang Wang", "title": "Say No to the Discrimination: Learning Fair Graph Neural Networks with\n  Limited Sensitive Attribute Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved state-of-the-art performance in\nmodeling graphs. Despite its great success, as with many other models, GNNs\nhave the risk to inherit the bias from the training data. In addition, the bias\nof GNN can be magnified by the graph structures and message-passing mechanism\nof GNNs. The risk of discrimination limits the adoption of GNNs in sensitive\ndomains such as credit score estimation. Though extensive studies of fair\nclassification have been conducted on i.i.d data, methods to address the\nproblem of discrimination on non-i.i.d data are rather limited. Furthermore,\nthe practical scenario of sparse annotations in sensitive attributes is rarely\nconsidered in existing works. Therefore, we study the novel and important\nproblem of learning fair GNNs with limited sensitive information. We propose a\nnovel framework called FairGNN, which is able to reduce the bias of GNNs and\nmaintain high node classification accuracy by leveraging graph structured data\nand sensitive information. Theoretical analysis is conducted to show that\nFairGNN can ensure fairness under mild conditions given limited nodes with\nknown sensitive attributes. Experiments on real-world datasets demonstrated the\neffectiveness of the proposed framework in eliminating discrimination while\nmaintaining high node classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:17:30 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 02:51:34 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 22:03:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Dai", "Enyan", ""], ["Wang", "Suhang", ""]]}, {"id": "2009.01461", "submitter": "Sunghwan Moon", "authors": "Jae-Mo Kang and Sunghwan Moon", "title": "Error estimate for a universal function approximator of ReLU network\n  with a local connection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have shown high successful performance in a wide range of\ntasks, but further studies are needed to improve its performance. We analyze\nthe approximation error of the specific neural network architecture with a\nlocal connection and higher application than one with the full connection\nbecause the local-connected network can be used to explain diverse neural\nnetworks such as CNNs. Our error estimate depends on two parameters: one\ncontrolling the depth of the hidden layer, and the other, the width of the\nhidden layers.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:58:46 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kang", "Jae-Mo", ""], ["Moon", "Sunghwan", ""]]}, {"id": "2009.01462", "submitter": "Qi Sun", "authors": "Qi Sun, Hexin Dong, Zewei Chen, Weizhen Dian, Jiacheng Sun, Yitong\n  Sun, Zhenguo Li, Bin Dong", "title": "A Practical Layer-Parallel Training Algorithm for Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based algorithms for training ResNets typically require a forward\npass of the input data, followed by back-propagating the objective gradient to\nupdate parameters, which are time-consuming for deep ResNets. To break the\ndependencies between modules in both the forward and backward modes,\nauxiliary-variable methods such as the penalty and augmented Lagrangian (AL)\napproaches have attracted much interest lately due to their ability to exploit\nlayer-wise parallelism. However, we observe that large communication overhead\nand lacking data augmentation are two key challenges of these methods, which\nmay lead to low speedup ratio and accuracy drop across multiple compute\ndevices. Inspired by the optimal control formulation of ResNets, we propose a\nnovel serial-parallel hybrid training strategy to enable the use of data\naugmentation, together with downsampling filters to reduce the communication\ncost. The proposed strategy first trains the network parameters by solving a\nsuccession of independent sub-problems in parallel and then corrects the\nnetwork parameters through a full serial forward-backward propagation of data.\nSuch a strategy can be applied to most of the existing layer-parallel training\nmethods using auxiliary variables. As an example, we validate the proposed\nstrategy using penalty and AL methods on ResNet and WideResNet across MNIST,\nCIFAR-10 and CIFAR-100 datasets, achieving significant speedup over the\ntraditional layer-serial training methods while maintaining comparable\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:03:30 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 14:25:56 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Sun", "Qi", ""], ["Dong", "Hexin", ""], ["Chen", "Zewei", ""], ["Dian", "Weizhen", ""], ["Sun", "Jiacheng", ""], ["Sun", "Yitong", ""], ["Li", "Zhenguo", ""], ["Dong", "Bin", ""]]}, {"id": "2009.01468", "submitter": "Nicholas Wilkins", "authors": "Nicholas Wilkins, Beck Cordes Galbraith, Ifeoma Nwogu", "title": "Modeling Global Body Configurations in American Sign Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  American Sign Language (ASL) is the fourth most commonly used language in the\nUnited States and is the language most commonly used by Deaf people in the\nUnited States and the English-speaking regions of Canada. Unfortunately, until\nrecently, ASL received little research. This is due, in part, to its delayed\nrecognition as a language until William C. Stokoe's publication in 1960.\nLimited data has been a long-standing obstacle to ASL research and\ncomputational modeling. The lack of large-scale datasets has prohibited many\nmodern machine-learning techniques, such as Neural Machine Translation, from\nbeing applied to ASL. In addition, the modality required to capture sign\nlanguage (i.e. video) is complex in natural settings (as one must deal with\nbackground noise, motion blur, and the curse of dimensionality). Finally, when\ncompared with spoken languages, such as English, there has been limited\nresearch conducted into the linguistics of ASL.\n  We realize a simplified version of Liddell and Johnson's Movement-Hold (MH)\nModel using a Probabilistic Graphical Model (PGM). We trained our model on\nASLing, a dataset collected from three fluent ASL signers. We evaluate our PGM\nagainst other models to determine its ability to model ASL. Finally, we\ninterpret various aspects of the PGM and draw conclusions about ASL phonetics.\nThe main contributions of this paper are\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:20:10 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Wilkins", "Nicholas", ""], ["Galbraith", "Beck Cordes", ""], ["Nwogu", "Ifeoma", ""]]}, {"id": "2009.01476", "submitter": "Jordan Bishop", "authors": "Jordan T. Bishop, Marcus Gallagher", "title": "Optimality-based Analysis of XCSF Compaction in Discrete Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58115-2_33", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) are population-based predictive systems\nthat were originally envisioned as agents to act in reinforcement learning (RL)\nenvironments. These systems can suffer from population bloat and so are\namenable to compaction techniques that try to strike a balance between\npopulation size and performance. A well-studied LCS architecture is XCSF, which\nin the RL setting acts as a Q-function approximator. We apply XCSF to a\ndeterministic and stochastic variant of the FrozenLake8x8 environment from\nOpenAI Gym, with its performance compared in terms of function approximation\nerror and policy accuracy to the optimal Q-functions and policies produced by\nsolving the environments via dynamic programming. We then introduce a novel\ncompaction algorithm (Greedy Niche Mass Compaction - GNMC) and study its\noperation on XCSF's trained populations. Results show that given a suitable\nparametrisation, GNMC preserves or even slightly improves function\napproximation error while yielding a significant reduction in population size.\nReasonable preservation of policy accuracy also occurs, and we link this metric\nto the commonly used steps-to-goal metric in maze-like environments,\nillustrating how the metrics are complementary rather than competitive.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:31:43 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bishop", "Jordan T.", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2009.01492", "submitter": "Alexander Jung", "authors": "A. Jung", "title": "Explainable Empirical Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of modern machine learning methods in decision making\ncrucially depends on their interpretability or explainability. The human users\n(decision makers) of machine learning methods are often not only interested in\ngetting accurate predictions or projections. Rather, as a decision-maker, the\nuser also needs a convincing answer (or explanation) to the question of why a\nparticular prediction was delivered. Explainable machine learning might be a\nlegal requirement when used for decision making with an immediate effect on the\nhealth of human beings. As an example consider the computer vision of a\nself-driving car whose predictions are used to decide if to stop the car. We\nhave recently proposed an information-theoretic approach to construct\npersonalized explanations for predictions obtained from ML. This method was\nmodel-agnostic and only required some training samples of the model to be\nexplained along with a user feedback signal. This paper uses an\ninformation-theoretic measure for the quality of an explanation to learn\npredictors that are intrinsically explainable to a specific user. Our approach\nis not restricted to a particular hypothesis space, such as linear maps or\nshallow decision trees, whose predictor maps are considered as explainable by\ndefinition. Rather, we regularize an arbitrary hypothesis space using a\npersonalized measure for the explainability of a particular predictor.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 07:16:34 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Jung", "A.", ""]]}, {"id": "2009.01495", "submitter": "Ran Tian", "authors": "Ran Tian, Liting Sun, and Masayoshi Tomizuka", "title": "Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse\n  Reward Learning with Iterative Reasoning and Cumulative Prospect Theory", "comments": "Accepted by 2021 AAAI Conference on Artificial Intelligence", "journal-ref": "2021 AAAI Conference on Artificial Intelligence", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical game-theoretic approaches for multi-agent systems in both the\nforward policy design problem and the inverse reward learning problem often\nmake strong rationality assumptions: agents perfectly maximize expected\nutilities under uncertainties. Such assumptions, however, substantially\nmismatch with observed humans' behaviors such as satisficing with sub-optimal,\nrisk-seeking, and loss-aversion decisions. In this paper, we investigate the\nproblem of bounded risk-sensitive Markov Game (BRSMG) and its inverse reward\nlearning problem for modeling human realistic behaviors and learning human\nbehavioral models. Drawing on iterative reasoning models and cumulative\nprospect theory, we embrace that humans have bounded intelligence and maximize\nrisk-sensitive utilities in BRSMGs. Convergence analysis for both the forward\npolicy design and the inverse reward learning problems are established under\nthe BRSMG framework. We validate the proposed forward policy design and inverse\nreward learning algorithms in a navigation scenario. The results show that the\nbehaviors of agents demonstrate both risk-averse and risk-seeking\ncharacteristics. Moreover, in the inverse reward learning task, the proposed\nbounded risk-sensitive inverse learning algorithm outperforms a baseline\nrisk-neutral inverse learning algorithm by effectively recovering not only more\naccurate reward values but also the intelligence levels and the risk-measure\nparameters given demonstrations of agents' interactive behaviors.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 07:32:32 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 07:23:16 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 07:32:00 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 19:04:59 GMT"}, {"version": "v5", "created": "Sat, 19 Dec 2020 04:55:32 GMT"}, {"version": "v6", "created": "Sat, 13 Feb 2021 04:01:25 GMT"}, {"version": "v7", "created": "Sun, 21 Mar 2021 02:10:20 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Tian", "Ran", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2009.01502", "submitter": "Pengyuan Zhou", "authors": "Pengyuan Zhou, Xianfu Chen, Zhi Liu, Tristan Braud, Pan Hui, Jussi\n  Kangasharju", "title": "DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light\n  Control in the IoV", "comments": "Accepted by IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3035841", "report-no": null, "categories": "cs.MA cs.DC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Internet of Vehicles (IoV) enables real-time data exchange among vehicles\nand roadside units and thus provides a promising solution to alleviate traffic\njams in the urban area. Meanwhile, better traffic management via efficient\ntraffic light control can benefit the IoV as well by enabling a better\ncommunication environment and decreasing the network load. As such, IoV and\nefficient traffic light control can formulate a virtuous cycle. Edge computing,\nan emerging technology to provide low-latency computation capabilities at the\nedge of the network, can further improve the performance of this cycle.\nHowever, while the collected information is valuable, an efficient solution for\nbetter utilization and faster feedback has yet to be developed for\nedge-empowered IoV. To this end, we propose a Decentralized Reinforcement\nLearning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits\nthe ubiquity of the IoV to accelerate the collection of traffic data and its\ninterpretation towards alleviating congestion and providing better traffic\nlight control. DRLE operates within the coverage of the edge servers and uses\naggregated data from neighboring edge servers to provide city-scale traffic\nlight control. DRLE decomposes the highly complex problem of large area\ncontrol. into a decentralized multi-agent problem. We prove its global optima\nwith concrete mathematical reasoning. The proposed decentralized reinforcement\nlearning algorithm running at each edge node adapts the traffic lights in real\ntime. We conduct extensive evaluations and demonstrate the superiority of this\napproach over several state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 08:09:04 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 10:03:08 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhou", "Pengyuan", ""], ["Chen", "Xianfu", ""], ["Liu", "Zhi", ""], ["Braud", "Tristan", ""], ["Hui", "Pan", ""], ["Kangasharju", "Jussi", ""]]}, {"id": "2009.01512", "submitter": "Julien Tierny", "authors": "Harish Doraiswamy and Julien Tierny and Paulo J. S. Silva and Luis\n  Gustavo Nonato and Claudio Silva", "title": "TopoMap: A 0-dimensional Homology Preserving Projection of\n  High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional Projection is a fundamental tool for high-dimensional data\nanalytics and visualization. With very few exceptions, projection techniques\nare designed to map data from a high-dimensional space to a visual space so as\nto preserve some dissimilarity (similarity) measure, such as the Euclidean\ndistance for example. In fact, although adopting distinct mathematical\nformulations designed to favor different aspects of the data, most\nmultidimensional projection methods strive to preserve dissimilarity measures\nthat encapsulate geometric properties such as distances or the proximity\nrelation between data objects. However, geometric relations are not the only\ninteresting property to be preserved in a projection. For instance, the\nanalysis of particular structures such as clusters and outliers could be more\nreliably performed if the mapping process gives some guarantee as to\ntopological invariants such as connected components and loops. This paper\nintroduces TopoMap, a novel projection technique which provides topological\nguarantees during the mapping process. In particular, the proposed method\nperforms the mapping from a high-dimensional space to a visual space, while\npreserving the 0-dimensional persistence diagram of the Rips filtration of the\nhigh-dimensional data, ensuring that the filtrations generate the same\nconnected components when applied to the original as well as projected data.\nThe presented case studies show that the topological guarantee provided by\nTopoMap not only brings confidence to the visual analytic process but also can\nbe used to assist in the assessment of other projection methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 08:30:02 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Doraiswamy", "Harish", ""], ["Tierny", "Julien", ""], ["Silva", "Paulo J. S.", ""], ["Nonato", "Luis Gustavo", ""], ["Silva", "Claudio", ""]]}, {"id": "2009.01521", "submitter": "Steffen Herbold", "authors": "Steffen Herbold, Tobias Haar", "title": "Smoke Testing for Machine Learning: Simple Tests to Discover Severe\n  Defects", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is nowadays a standard technique for data analysis within\nsoftware applications. Software engineers need quality assurance techniques\nthat are suitable for these new kinds of systems. Within this article, we\ndiscuss the question whether standard software testing techniques that have\nbeen part of textbooks since decades are also useful for the testing of machine\nlearning software. Concretely, we try to determine generic smoke tests that can\nbe used to assert that basic functions can be executed without crashing. We\nfound that we can derive such tests using techniques similar to equivalence\nclasses and boundary value analysis. Moreover, we found that these concepts can\nalso be applied to hyperparameters, to further improve the quality of the smoke\ntests. Even though our approach is almost trivial, we were able to find bugs in\nall three machine learning libraries that we tested and severe bugs in two of\nthe three libraries. This demonstrates that common software testing techniques\nare still valid in the age of machine learning and that they are suitable to\nfind and prevent severe bugs, even in mature machine learning libraries.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 08:54:43 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Herbold", "Steffen", ""], ["Haar", "Tobias", ""]]}, {"id": "2009.01527", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky, Hyeryung Jang, Osvaldo Simeone", "title": "End-to-End Learning of Neuromorphic Wireless Systems for Low-Power Edge\n  Artificial Intelligence", "comments": "To be presented at Asilomar 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel \"all-spike\" low-power solution for remote\nwireless inference that is based on neuromorphic sensing, Impulse Radio (IR),\nand Spiking Neural Networks (SNNs). In the proposed system, event-driven\nneuromorphic sensors produce asynchronous time-encoded data streams that are\nencoded by an SNN, whose output spiking signals are pulse modulated via IR and\ntransmitted over general frequence-selective channels; while the receiver's\ninputs are obtained via hard detection of the received signals and fed to an\nSNN for classification. We introduce an end-to-end training procedure that\ntreats the cascade of encoder, channel, and decoder as a probabilistic\nSNN-based autoencoder that implements Joint Source-Channel Coding (JSCC). The\nproposed system, termed NeuroJSCC, is compared to conventional synchronous\nframe-based and uncoded transmissions in terms of latency and accuracy. The\nexperiments confirm that the proposed end-to-end neuromorphic edge architecture\nprovides a promising framework for efficient and low-latency remote sensing,\ncommunication, and inference.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 09:10:16 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2009.01534", "submitter": "Yossi Adi", "authors": "Shahar Segal, Yossi Adi, Benny Pinkas, Carsten Baum, Chaya Ganesh,\n  Joseph Keshet", "title": "Fairness in the Eyes of the Data: Certifying Machine-Learning Models", "comments": "Accepted to AIES-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that allows to certify the fairness degree of a model\nbased on an interactive and privacy-preserving test. The framework verifies any\ntrained model, regardless of its training process and architecture. Thus, it\nallows us to evaluate any deep learning model on multiple fairness definitions\nempirically. We tackle two scenarios, where either the test data is privately\navailable only to the tester or is publicly known in advance, even to the model\ncreator. We investigate the soundness of the proposed approach using\ntheoretical analysis and present statistical guarantees for the interactive\ntest. Finally, we provide a cryptographic technique to automate fairness\ntesting and certified inference with only black-box access to the model at hand\nwhile hiding the participants' sensitive data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 09:22:39 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 09:03:42 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 07:57:06 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Segal", "Shahar", ""], ["Adi", "Yossi", ""], ["Pinkas", "Benny", ""], ["Baum", "Carsten", ""], ["Ganesh", "Chaya", ""], ["Keshet", "Joseph", ""]]}, {"id": "2009.01554", "submitter": "Dilip Jagadeeshwarswamy Hiremath", "authors": "Dilip J. Hiremath, Martin Claus, Wilhelm Hasselbring, Willi Rath", "title": "Automated identification of metamorphic test scenarios for an\n  ocean-modeling application", "comments": "Shot paper:2 pages, 2020 IEEE International Conference On Artificial\n  Intelligence Testing (AITest)", "journal-ref": null, "doi": "10.1109/AITEST49225.2020.00016", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metamorphic testing seeks to validate software in the absence of test\noracles. Our application domain is ocean modeling, where test oracles often do\nnot exist, but where symmetries of the simulated physical systems are known. In\nthis short paper we present work in progress for automated generation of\nmetamorphic test scenarios using machine learning. Metamorphic testing may be\nexpressed as f(g(X))=h(f(X)) with f being the application under test, with\ninput data X, and with the metamorphic relation (g, h). Automatically generated\nmetamorphic relations can be used for constructing regression tests, and for\ncomparing different versions of the same software application. Here, we\nrestrict to h being the identity map. Then, the task of constructing tests\nmeans finding different g which we tackle using machine learning algorithms.\nThese algorithms typically minimize a cost function. As one possible g is\nalready known to be the identity map, for finding a second possible g, we\nconstruct the cost function to minimize for g being a metamorphic relation and\nto penalize for g being the identity map. After identifying the first\nmetamorphic relation, the procedure is repeated with a cost function rewarding\ng that are orthogonal to previously found metamorphic relations. For\nexperimental evaluation, two implementations of an ocean-modeling application\nwill be subjected to the proposed method with the objective of presenting the\nuse of metamorphic relations to test the implementations of the applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:03:56 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Hiremath", "Dilip J.", ""], ["Claus", "Martin", ""], ["Hasselbring", "Wilhelm", ""], ["Rath", "Willi", ""]]}, {"id": "2009.01555", "submitter": "Joerg Franke", "authors": "J\\\"org K.H. Franke, Gregor K\\\"ohler, Andr\\'e Biedenkapp, Frank Hutter", "title": "Sample-Efficient Automated Deep Reinforcement Learning", "comments": "In Proceedings of the International Conference on Learning\n  Representations (ICLR 2021), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in challenging problems across various domains,\napplying state-of-the-art deep reinforcement learning (RL) algorithms remains\nchallenging due to their sensitivity to the choice of hyperparameters. This\nsensitivity can partly be attributed to the non-stationarity of the RL problem,\npotentially requiring different hyperparameter settings at various stages of\nthe learning process. Additionally, in the RL setting, hyperparameter\noptimization (HPO) requires a large number of environment interactions,\nhindering the transfer of the successes in RL to real-world applications. In\nthis work, we tackle the issues of sample-efficient and dynamic HPO in RL. We\npropose a population-based automated RL (AutoRL) framework to meta-optimize\narbitrary off-policy RL algorithms. In this framework, we optimize the\nhyperparameters and also the neural architecture while simultaneously training\nthe agent. By sharing the collected experience across the population, we\nsubstantially increase the sample efficiency of the meta-optimization. We\ndemonstrate the capabilities of our sample-efficient AutoRL approach in a case\nstudy with the popular TD3 algorithm in the MuJoCo benchmark suite, where we\nreduce the number of environment interactions needed for meta-optimization by\nup to an order of magnitude compared to population-based training.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:04:06 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 09:49:51 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 14:43:36 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Franke", "J\u00f6rg K. H.", ""], ["K\u00f6hler", "Gregor", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Hutter", "Frank", ""]]}, {"id": "2009.01561", "submitter": "Zahra Dasht Bozorgi", "authors": "Zahra Dasht Bozorgi, Irene Teinemaa, Marlon Dumas, Marcello La Rosa,\n  Artem Polyvyanyy", "title": "Process Mining Meets Causal Machine Learning: Discovering Causal Rules\n  from Event Logs", "comments": "8 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to analyze an event log of a business process\nin order to generate case-level recommendations of treatments that maximize the\nprobability of a given outcome. Users classify the attributes in the event log\ninto controllable and non-controllable, where the former correspond to\nattributes that can be altered during an execution of the process (the possible\ntreatments). We use an action rule mining technique to identify treatments that\nco-occur with the outcome under some conditions. Since action rules are\ngenerated based on correlation rather than causation, we then use a causal\nmachine learning technique, specifically uplift trees, to discover subgroups of\ncases for which a treatment has a high causal effect on the outcome after\nadjusting for confounding variables. We test the relevance of this approach\nusing an event log of a loan application process and compare our findings with\nrecommendations manually produced by process mining experts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:10:30 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bozorgi", "Zahra Dasht", ""], ["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Polyvyanyy", "Artem", ""]]}, {"id": "2009.01564", "submitter": "Marc Hanussek", "authors": "Marc Hanussek, Matthias Blohm, Maximilien Kintz", "title": "Can AutoML outperform humans? An evaluation on popular OpenML datasets\n  using AutoML Benchmark", "comments": "To be published in AIRC 2020 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, Automated Machine Learning (AutoML) has gained much\nattention. With that said, the question arises whether AutoML can outperform\nresults achieved by human data scientists. This paper compares four AutoML\nframeworks on 12 different popular datasets from OpenML; six of them supervised\nclassification tasks and the other six supervised regression ones.\nAdditionally, we consider a real-life dataset from one of our recent projects.\nThe results show that the automated frameworks perform better or equal than the\nmachine learning community in 7 out of 12 OpenML tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:25:34 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:33:02 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Hanussek", "Marc", ""], ["Blohm", "Matthias", ""], ["Kintz", "Maximilien", ""]]}, {"id": "2009.01571", "submitter": "Pinkesh Badjatiya", "authors": "Anubha Kabra, Ayush Chopra, Nikaash Puri, Pinkesh Badjatiya, Sukriti\n  Verma, Piyush Gupta, Balaji K", "title": "MixBoost: Synthetic Oversampling with Boosted Mixup for Handling Extreme\n  Imbalance", "comments": "Work done as part of internship at MDSR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a classification model on a dataset where the instances of one class\noutnumber those of the other class is a challenging problem. Such imbalanced\ndatasets are standard in real-world situations such as fraud detection, medical\ndiagnosis, and computational advertising. We propose an iterative data\naugmentation method, MixBoost, which intelligently selects (Boost) and then\ncombines (Mix) instances from the majority and minority classes to generate\nsynthetic hybrid instances that have characteristics of both classes. We\nevaluate MixBoost on 20 benchmark datasets, show that it outperforms existing\napproaches, and test its efficacy through significance testing. We also present\nablation studies to analyze the impact of the different components of MixBoost.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:34:24 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kabra", "Anubha", ""], ["Chopra", "Ayush", ""], ["Puri", "Nikaash", ""], ["Badjatiya", "Pinkesh", ""], ["Verma", "Sukriti", ""], ["Gupta", "Piyush", ""], ["K", "Balaji", ""]]}, {"id": "2009.01573", "submitter": "Vasco Lopes Ferrinho", "authors": "Vasco Lopes, Lu\\'is A. Alexandre", "title": "Auto-Classifier: A Robust Defect Detector Based on an AutoML Head", "comments": "12 pages, 2 figures. Published in ICONIP2020, proceedings published\n  in the Springer's series of Lecture Notes in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approach for surface defect detection is the use of hand-crafted\nfeature-based methods. However, this falls short when conditions vary that\naffect extracted images. So, in this paper, we sought to determine how well\nseveral state-of-the-art Convolutional Neural Networks perform in the task of\nsurface defect detection. Moreover, we propose two methods: CNN-Fusion, that\nfuses the prediction of all the networks into a final one, and Auto-Classifier,\nwhich is a novel proposal that improves a Convolutional Neural Network by\nmodifying its classification component using AutoML. We carried out experiments\nto evaluate the proposed methods in the task of surface defect detection using\ndifferent datasets from DAGM2007. We show that the use of Convolutional Neural\nNetworks achieves better results than traditional methods, and also, that\nAuto-Classifier out-performs all other methods, by achieving 100% accuracy and\n100% AUC results throughout all the datasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:39:02 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lopes", "Vasco", ""], ["Alexandre", "Lu\u00eds A.", ""]]}, {"id": "2009.01591", "submitter": "Malik Tiomoko", "authors": "Malik Tiomoko, Romain Couillet and Hafiz Tiomoko", "title": "Large Dimensional Analysis and Improvement of Multi Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi Task Learning (MTL) efficiently leverages useful information contained\nin multiple related tasks to help improve the generalization performance of all\ntasks. This article conducts a large dimensional analysis of a simple but, as\nwe shall see, extremely powerful when carefully tuned, Least Square Support\nVector Machine (LSSVM) version of MTL, in the regime where the dimension $p$ of\nthe data and their number $n$ grow large at the same rate.\n  Under mild assumptions on the input data, the theoretical analysis of the\nMTL-LSSVM algorithm first reveals the \"sufficient statistics\" exploited by the\nalgorithm and their interaction at work. These results demonstrate, as a\nstriking consequence, that the standard approach to MTL-LSSVM is largely\nsuboptimal, can lead to severe effects of negative transfer but that these\nimpairments are easily corrected. These corrections are turned into an improved\nMTL-LSSVM algorithm which can only benefit from additional data, and the\ntheoretical performance of which is also analyzed.\n  As evidenced and theoretically sustained in numerous recent works, these\nlarge dimensional results are robust to broad ranges of data distributions,\nwhich our present experiments corroborate. Specifically, the article reports a\nsystematically close behavior between theoretical and empirical performances on\npopular datasets, which is strongly suggestive of the applicability of the\nproposed carefully tuned MTL-LSSVM method to real data. This fine-tuning is\nfully based on the theoretical analysis and does not in particular require any\ncross validation procedure. Besides, the reported performances on real datasets\nalmost systematically outperform much more elaborate and less intuitive\nstate-of-the-art multi-task and transfer learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 11:40:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tiomoko", "Malik", ""], ["Couillet", "Romain", ""], ["Tiomoko", "Hafiz", ""]]}, {"id": "2009.01592", "submitter": "Marvin Lerousseau", "authors": "Marvin Lerousseau, Eric Deutsh, Nikos Paragios", "title": "Multimodal brain tumor classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is a complex disease that provides various types of information\ndepending on the scale of observation. While most tumor diagnostics are\nperformed by observing histopathological slides, radiology images should yield\nadditional knowledge towards the efficacy of cancer diagnostics. This work\ninvestigates a deep learning method combining whole slide images and magnetic\nresonance images to classify tumors. In particular, our solution comprises a\npowerful, generic and modular architecture for whole slide image\nclassification. Experiments are prospectively conducted on the 2020\nComputational Precision Medicine challenge, in a 3-classes unbalanced\nclassification task. We report cross-validation (resp. validation)\nbalanced-accuracy, kappa and f1 of 0.913, 0.897 and 0.951 (resp. 0.91, 0.90 and\n0.94). For research purposes, including reproducibility and direct performance\ncomparisons, our finale submitted models are usable off-the-shelf in a Docker\nimage available at\nhttps://hub.docker.com/repository/docker/marvinler/cpm_2020_marvinler.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 11:41:50 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 16:05:22 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lerousseau", "Marvin", ""], ["Deutsh", "Eric", ""], ["Paragios", "Nikos", ""]]}, {"id": "2009.01630", "submitter": "Jiuniu Wang", "authors": "Jiuniu Wang, Wenjia Xu, Xingyu Fu, Yang Wei, Li Jin, Ziyan Chen,\n  Guangluan Xu, Yirong Wu", "title": "SRQA: Synthetic Reader for Factoid Question Answering", "comments": "arXiv admin note: text overlap with arXiv:1809.00676", "journal-ref": "Knowledge-Based Systems, Volume 193, 6 April 2020, 105415", "doi": "10.1016/j.knosys.2019.105415", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question answering system can answer questions from various fields and\nforms with deep neural networks, but it still lacks effective ways when facing\nmultiple evidences. We introduce a new model called SRQA, which means Synthetic\nReader for Factoid Question Answering. This model enhances the question\nanswering system in the multi-document scenario from three aspects: model\nstructure, optimization goal, and training method, corresponding to Multilayer\nAttention (MA), Cross Evidence (CE), and Adversarial Training (AT)\nrespectively. First, we propose a multilayer attention network to obtain a\nbetter representation of the evidences. The multilayer attention mechanism\nconducts interaction between the question and the passage within each layer,\nmaking the token representation of evidences in each layer takes the\nrequirement of the question into account. Second, we design a cross evidence\nstrategy to choose the answer span within more evidences. We improve the\noptimization goal, considering all the answers' locations in multiple evidences\nas training targets, which leads the model to reason among multiple evidences.\nThird, adversarial training is employed to high-level variables besides the\nword embedding in our model. A new normalization method is also proposed for\nadversarial perturbations so that we can jointly add perturbations to several\ntarget variables. As an effective regularization method, adversarial training\nenhances the model's ability to process noisy data. Combining these three\nstrategies, we enhance the contextual representation and locating ability of\nour model, which could synthetically extract the answer span from several\nevidences. We perform SRQA on the WebQA dataset, and experiments show that our\nmodel outperforms the state-of-the-art models (the best fuzzy score of our\nmodel is up to 78.56%, with an improvement of about 2%).\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:16:24 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Wang", "Jiuniu", ""], ["Xu", "Wenjia", ""], ["Fu", "Xingyu", ""], ["Wei", "Yang", ""], ["Jin", "Li", ""], ["Chen", "Ziyan", ""], ["Xu", "Guangluan", ""], ["Wu", "Yirong", ""]]}, {"id": "2009.01657", "submitter": "Jose Bermudez", "authors": "Jose David Bermudez Castro, Ricardo Rei, Jose E. Ruiz, Pedro\n  Achanccaray Diaz, Smith Arauco Canchumuni, Cristian Mu\\~noz Villalobos,\n  Felipe Borges Coelho, Leonardo Forero Mendoza, and Marco Aurelio C. Pacheco", "title": "A free web service for fast COVID-19 classification of chest X-Ray\n  images", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus outbreak became a major concern for society worldwide.\nTechnological innovation and ingenuity are essential to fight COVID-19 pandemic\nand bring us one step closer to overcome it. Researchers over the world are\nworking actively to find available alternatives in different fields, such as\nthe Healthcare System, pharmaceutic, health prevention, among others. With the\nrise of artificial intelligence (AI) in the last 10 years, IA-based\napplications have become the prevalent solution in different areas because of\nits higher capability, being now adopted to help combat against COVID-19. This\nwork provides a fast detection system of COVID-19 characteristics in X-Ray\nimages based on deep learning (DL) techniques. This system is available as a\nfree web deployed service for fast patient classification, alleviating the high\ndemand for standards method for COVID-19 diagnosis. It is constituted of two\ndeep learning models, one to differentiate between X-Ray and non-X-Ray images\nbased on Mobile-Net architecture, and another one to identify chest X-Ray\nimages with characteristics of COVID-19 based on the DenseNet architecture. For\nreal-time inference, it is provided a pair of dedicated GPUs, which reduce the\ncomputational time. The whole system can filter out non-chest X-Ray images, and\ndetect whether the X-Ray presents characteristics of COVID-19, highlighting the\nmost sensitive regions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 20:53:26 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Castro", "Jose David Bermudez", ""], ["Rei", "Ricardo", ""], ["Ruiz", "Jose E.", ""], ["Diaz", "Pedro Achanccaray", ""], ["Canchumuni", "Smith Arauco", ""], ["Villalobos", "Cristian Mu\u00f1oz", ""], ["Coelho", "Felipe Borges", ""], ["Mendoza", "Leonardo Forero", ""], ["Pacheco", "Marco Aurelio C.", ""]]}, {"id": "2009.01658", "submitter": "Amanda Howard", "authors": "Brandon Reyes, Amanda A. Howard, Paris Perdikaris, Alexandre M.\n  Tartakovsky", "title": "Learning Unknown Physics of non-Newtonian Fluids", "comments": null, "journal-ref": "Phys. Rev. Fluids 6, 073301 (2021)", "doi": "10.1103/PhysRevFluids.6.073301", "report-no": null, "categories": "physics.comp-ph cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the physics-informed neural network (PINN) method to learn\nviscosity models of two non-Newtonian systems (polymer melts and suspensions of\nparticles) using only velocity measurements. The PINN-inferred viscosity models\nagree with the empirical models for shear rates with large absolute values but\ndeviate for shear rates near zero where the analytical models have an\nunphysical singularity. Once a viscosity model is learned, we use the PINN\nmethod to solve the momentum conservation equation for non-Newtonian fluid flow\nusing only the boundary conditions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:41:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Reyes", "Brandon", ""], ["Howard", "Amanda A.", ""], ["Perdikaris", "Paris", ""], ["Tartakovsky", "Alexandre M.", ""]]}, {"id": "2009.01672", "submitter": "Han Xu", "authors": "Han Xu, Yaxin Li, Xiaorui Liu, Hui Liu, Jiliang Tang", "title": "Yet Meta Learning Can Adapt Fast, It Can Also Break Easily", "comments": "Meta Learning Robustnss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning algorithms have been widely applied in many tasks for efficient\nlearning, such as few-shot image classification and fast reinforcement\nlearning. During meta training, the meta learner develops a common learning\nstrategy, or experience, from a variety of learning tasks. Therefore, during\nmeta test, the meta learner can use the learned strategy to quickly adapt to\nnew tasks even with a few training samples. However, there is still a dark side\nabout meta learning in terms of reliability and robustness. In particular, is\nmeta learning vulnerable to adversarial attacks? In other words, would a\nwell-trained meta learner utilize its learned experience to build wrong or\nlikely useless knowledge, if an adversary unnoticeably manipulates the given\ntraining set? Without the understanding of this problem, it is extremely risky\nto apply meta learning in safety-critical applications. Thus, in this paper, we\nperform the initial study about adversarial attacks on meta learning under the\nfew-shot classification problem. In particular, we formally define key elements\nof adversarial attacks unique to meta learning and propose the first attacking\nalgorithm against meta learning under various settings. We evaluate the\neffectiveness of the proposed attacking strategy as well as the robustness of\nseveral representative meta learning algorithms. Experimental results\ndemonstrate that the proposed attacking strategy can easily break the meta\nlearner and meta learning is vulnerable to adversarial attacks. The\nimplementation of the proposed framework will be released upon the acceptance\nof this paper.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:03:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Xu", "Han", ""], ["Li", "Yaxin", ""], ["Liu", "Xiaorui", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""]]}, {"id": "2009.01674", "submitter": "Yanqiao Zhu", "authors": "Yanqiao Zhu and Yichen Xu and Feng Yu and Shu Wu and Liang Wang", "title": "CAGNN: Cluster-Aware Graph Neural Networks for Unsupervised Graph\n  Representation Learning", "comments": "21 pages, in submission to ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised graph representation learning aims to learn low-dimensional node\nembeddings without supervision while preserving graph topological structures\nand node attributive features. Previous graph neural networks (GNN) require a\nlarge number of labeled nodes, which may not be accessible in real-world graph\ndata. In this paper, we present a novel cluster-aware graph neural network\n(CAGNN) model for unsupervised graph representation learning using\nself-supervised techniques. In CAGNN, we perform clustering on the node\nembeddings and update the model parameters by predicting the cluster\nassignments. Moreover, we observe that graphs often contain inter-class edges,\nwhich mislead the GNN model to aggregate noisy information from neighborhood\nnodes. We further refine the graph topology by strengthening intra-class edges\nand reducing node connections between different classes based on cluster\nlabels, which better preserves cluster structures in the embedding space. We\nconduct comprehensive experiments on two benchmark tasks using real-world\ndatasets. The results demonstrate the superior performance of the proposed\nmodel over existing baseline methods. Notably, our model gains over 7%\nimprovements in terms of accuracy on node clustering over state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 13:57:18 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhu", "Yanqiao", ""], ["Xu", "Yichen", ""], ["Yu", "Feng", ""], ["Wu", "Shu", ""], ["Wang", "Liang", ""]]}, {"id": "2009.01675", "submitter": "Zihao Wang", "authors": "Zihao Wang, Herv\\'e Delingette", "title": "Quasi-symplectic Langevin Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a very popular and well-investigated\ngenerative model in neural learning research. To leverage VAE in practical\ntasks dealing with a massive dataset of large dimensions, it is required to\ndeal with the difficulty of building low variance evidence lower bounds (ELBO).\nMarkov Chain Monte Carlo (MCMC) is an effective approach to tighten the ELBO\nfor approximating the posterior distribution and Hamiltonian Variational\nAutoencoder (HVAE) is an effective MCMC inspired approach for constructing a\nlow-variance ELBO that is amenable to the reparameterization trick. The HVAE\nadapted the Hamiltonian dynamic flow into variational inference that\nsignificantly improves the performance of the posterior estimation. We propose\nin this work a Langevin dynamic flow-based inference approach by incorporating\nthe gradients information in the inference process through the Langevin dynamic\nwhich is a kind of MCMC based method similar to HVAE. Specifically, we employ a\nquasi-symplectic integrator to cope with the prohibit problem of the Hessian\ncomputing in naive Langevin flow. We show the theoretical and practical\neffectiveness of the proposed framework with other gradient flow-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:13:27 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:28:54 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 18:50:43 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 09:05:17 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Zihao", ""], ["Delingette", "Herv\u00e9", ""]]}, {"id": "2009.01696", "submitter": "Martin Zaefferer", "authors": "Tom Peetz, Sebastian Vogt, Martin Zaefferer, Thomas Bartz-Beielstein", "title": "Simulation of an Elevator Group Control Using Generative Adversarial\n  Networks and Related AI Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing new, innovative technologies is a crucial task for safety and\nacceptance. But how can new systems be tested if no historical real-world data\nexist? Simulation provides an answer to this important question. Classical\nsimulation tools such as event-based simulation are well accepted. But most of\nthese established simulation models require the specification of many\nparameters. Furthermore, simulation runs, e.g., CFD simulations, are very time\nconsuming. Generative Adversarial Networks (GANs) are powerful tools for\ngenerating new data for a variety of tasks. Currently, their most frequent\napplication domain is image generation. This article investigates the\napplicability of GANs for imitating simulations. We are comparing the\nsimulation output of a technical system with the output of a GAN. To exemplify\nthis approach, a well-known multi-car elevator system simulator was chosen. Our\nstudy demonstrates the feasibility of this approach. It also discusses pitfalls\nand technical problems that occurred during the implementation. Although we\nwere able to show that in principle, GANs can be used as substitutes for\nexpensive simulation runs, we also show that they cannot be used \"out of the\nbox\". Fine tuning is needed. We present a proof-of-concept, which can serve as\na starting point for further research.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:22:26 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Peetz", "Tom", ""], ["Vogt", "Sebastian", ""], ["Zaefferer", "Martin", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2009.01721", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Max-value Entropy Search for Multi-Objective Bayesian Optimization with\n  Constraints", "comments": "2 figure, 1 table. arXiv admin note: text overlap with\n  arXiv:2008.07029", "journal-ref": "Third Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constrained multi-objective blackbox optimization\nusing expensive function evaluations, where the goal is to approximate the true\nPareto set of solutions satisfying a set of constraints while minimizing the\nnumber of function evaluations. For example, in aviation power system design\napplications, we need to find the designs that trade-off total energy and the\nmass while satisfying specific thresholds for motor temperature and voltage of\ncells. This optimization requires performing expensive computational\nsimulations to evaluate designs. In this paper, we propose a new approach\nreferred as {\\em Max-value Entropy Search for Multi-objective Optimization with\nConstraints (MESMOC)} to solve this problem. MESMOC employs an output-space\nentropy based acquisition function to efficiently select the sequence of inputs\nfor evaluation to uncover high-quality pareto-set solutions while satisfying\nconstraints.\n  We apply MESMOC to two real-world engineering design applications to\ndemonstrate its effectiveness over state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:00:01 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 02:20:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2009.01726", "submitter": "Olivier Goudet Dr", "authors": "Mikael Escobar-Bach and Olivier Goudet", "title": "On the study of the Beran estimator for generalized censoring indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the analysis of time-to-event data, it is common to assume that\nonly partial information is given at hand. In the presence of right-censored\ndata with covariates, the conditional Kaplan-Meier estimator (also referred as\nthe Beran estimator) is known to propose a consistent estimate for the\nlifetimes conditional survival function. However, a necessary condition is the\nclear knowledge of whether each individual is censored or not, although, this\ninformation might be incomplete or even totally absent in practice. We thus\npropose a study on the Beran estimator when the censoring indicator is not\nclearly specified. From this, we provide a new estimator for the conditional\nsurvival function and establish its asymptotic normality under mild conditions.\nWe further study the supervised learning problem where the conditional survival\nfunction is to be predicted with no censorship indicators. To this aim, we\ninvestigate various approaches estimating the conditional expectation for the\ncensoring indicator. Along with the theoretical results, we illustrate how the\nestimators work for small samples by means of a simulation study and show their\npractical applicability with the analysis of synthetic data and the study of\nreal data for the prognosis of monoclonal gammopathy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:04:27 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Escobar-Bach", "Mikael", ""], ["Goudet", "Olivier", ""]]}, {"id": "2009.01730", "submitter": "Marco Huber", "authors": "Marco F. Huber", "title": "Bayesian Perceptron: Towards fully Bayesian Neural Networks", "comments": "Accepted for publication at the 59th IEEE Conference on Decision and\n  Control (CDC) 2020. v2: correction of typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (NNs) have become the de facto standard in machine\nlearning. They allow learning highly nonlinear transformations in a plethora of\napplications. However, NNs usually only provide point estimates without\nsystematically quantifying corresponding uncertainties. In this paper a novel\napproach towards fully Bayesian NNs is proposed, where training and predictions\nof a perceptron are performed within the Bayesian inference framework in\nclosed-form. The weights and the predictions of the perceptron are considered\nGaussian random variables. Analytical expressions for predicting the\nperceptron's output and for learning the weights are provided for commonly used\nactivation functions like sigmoid or ReLU. This approach requires no\ncomputationally expensive gradient calculations and further allows sequential\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:08:49 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 05:02:40 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Huber", "Marco F.", ""]]}, {"id": "2009.01742", "submitter": "Guanhua Fang", "authors": "Guanhua Fang and Owen G. Ward and Tian Zheng", "title": "Online Community Detection for Event Streams on Networks", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common goal in network modeling is to uncover the latent community\nstructure present among nodes. For many real-world networks, observed\nconnections consist of events arriving as streams, which are then aggregated to\nform edges, ignoring the temporal dynamic component. A natural way to take\naccount of this temporal dynamic component of interactions is to use point\nprocesses as the foundation of the network models for community detection.\nComputational complexity hampers the scalability of such approaches to large\nsparse networks. To circumvent this challenge, we propose a fast online\nvariational inference algorithm for learning the community structure underlying\ndynamic event arrivals on a network using continuous-time point process latent\nnetwork models. We provide regret bounds on the loss function of this\nprocedure, giving theoretical guarantees on performance. The proposed algorithm\nis illustrated, using both simulation studies and real data, to have comparable\nperformance in terms of community structure in terms of community recovery to\nnon-online variants. Our proposed framework can also be readily modified to\nincorporate other popular network structures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:39:55 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Fang", "Guanhua", ""], ["Ward", "Owen G.", ""], ["Zheng", "Tian", ""]]}, {"id": "2009.01745", "submitter": "Guido Carnevale", "authors": "Guido Carnevale, Francesco Farina, Ivano Notarnicola, Giuseppe\n  Notarstefano", "title": "Distributed Online Optimization via Gradient Tracking with Adaptive\n  Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a network of computing agents aiming to solve an online\noptimization problem in a distributed fashion, i.e., by means of local\ncomputation and communication, without any central coordinator. We propose the\ngradient tracking with adaptive momentum estimation (GTAdam) distributed\nalgorithm, which combines a gradient tracking mechanism with first and second\norder momentum estimates of the gradient. The algorithm is analyzed in the\nonline setting for strongly convex and smooth cost functions. We prove that the\naverage dynamic regret is bounded and that the convergence rate is linear. The\nalgorithm is tested on a time-varying classification problem, on a (moving)\ntarget localization problem and in a stochastic optimization setup from image\nclassification. In these numerical experiments from multi-agent learning,\nGTAdam outperforms state-of-the-art distributed optimization methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 15:20:21 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Carnevale", "Guido", ""], ["Farina", "Francesco", ""], ["Notarnicola", "Ivano", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "2009.01776", "submitter": "Jiawei Chen", "authors": "Jiawei Chen, Xu Tan, Jian Luan, Tao Qin, Tie-Yan Liu", "title": "HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-fidelity singing voices usually require higher sampling rate (e.g.,\n48kHz) to convey expression and emotion. However, higher sampling rate causes\nthe wider frequency band and longer waveform sequences and throws challenges\nfor singing voice synthesis (SVS) in both frequency and time domains.\nConventional SVS systems that adopt small sampling rate cannot well address the\nabove challenges. In this paper, we develop HiFiSinger, an SVS system towards\nhigh-fidelity singing voice. HiFiSinger consists of a FastSpeech based acoustic\nmodel and a Parallel WaveGAN based vocoder to ensure fast training and\ninference and also high voice quality. To tackle the difficulty of singing\nmodeling caused by high sampling rate (wider frequency band and longer\nwaveform), we introduce multi-scale adversarial training in both the acoustic\nmodel and vocoder to improve singing modeling. Specifically, 1) To handle the\nlarger range of frequencies caused by higher sampling rate, we propose a novel\nsub-frequency GAN (SF-GAN) on mel-spectrogram generation, which splits the full\n80-dimensional mel-frequency into multiple sub-bands and models each sub-band\nwith a separate discriminator. 2) To model longer waveform sequences caused by\nhigher sampling rate, we propose a multi-length GAN (ML-GAN) for waveform\ngeneration to model different lengths of waveform sequences with separate\ndiscriminators. 3) We also introduce several additional designs and findings in\nHiFiSinger that are crucial for high-fidelity voices, such as adding F0 (pitch)\nand V/UV (voiced/unvoiced flag) as acoustic features, choosing an appropriate\nwindow/hop size for mel-spectrogram, and increasing the receptive field in\nvocoder for long vowel modeling. Experiment results show that HiFiSinger\nsynthesizes high-fidelity singing voices with much higher quality: 0.32/0.44\nMOS gain over 48kHz/24kHz baseline and 0.83 MOS gain over previous SVS systems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:31:02 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chen", "Jiawei", ""], ["Tan", "Xu", ""], ["Luan", "Jian", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2009.01783", "submitter": "Shinjae Yoo", "authors": "Samuel Yen-Chi Chen, Shinjae Yoo, and Yao-Lung L. Fang", "title": "Quantum Long Short-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory (LSTM) is a kind of recurrent neural networks (RNN)\nfor sequence and temporal dependency data modeling and its effectiveness has\nbeen extensively established. In this work, we propose a hybrid\nquantum-classical model of LSTM, which we dub QLSTM. We demonstrate that the\nproposed model successfully learns several kinds of temporal data. In\nparticular, we show that for certain testing cases, this quantum version of\nLSTM converges faster, or equivalently, reaches a better accuracy, than its\nclassical counterpart. Due to the variational nature of our approach, the\nrequirements on qubit counts and circuit depth are eased, and our work thus\npaves the way toward implementing machine learning algorithms for sequence\nmodeling on noisy intermediate-scale quantum (NISQ) devices.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:41:09 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Yoo", "Shinjae", ""], ["Fang", "Yao-Lung L.", ""]]}, {"id": "2009.01786", "submitter": "Stefan Schonsheck", "authors": "Stefan C Schonsheck", "title": "Computational Analysis of Deformable Manifolds: from Geometric Modelling\n  to Deep Learning", "comments": "PhD Thesis, Versions of several chapters have previously appeard or\n  been submitted under different titles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leo Tolstoy opened his monumental novel Anna Karenina with the now famous\nwords: Happy families are all alike; every unhappy family is unhappy in its own\nway A similar notion also applies to mathematical spaces: Every flat space is\nalike; every unflat space is unflat in its own way. However, rather than being\na source of unhappiness, we will show that the diversity of non-flat spaces\nprovides a rich area of study. The genesis of the so-called big data era and\nthe proliferation of social and scientific databases of increasing size has led\nto a need for algorithms that can efficiently process, analyze and, even\ngenerate high dimensional data. However, the curse of dimensionality leads to\nthe fact that many classical approaches do not scale well with respect to the\nsize of these problems. One technique to avoid some of these ill-effects is to\nexploit the geometric structure of coherent data. In this thesis, we will\nexplore geometric methods for shape processing and data analysis. More\nspecifically, we will study techniques for representing manifolds and signals\nsupported on them through a variety of mathematical tools including, but not\nlimited to, computational differential geometry, variational PDE modeling, and\ndeep learning. First, we will explore non-isometric shape matching through\nvariational modeling. Next, we will use ideas from parallel transport on\nmanifolds to generalize convolution and convolutional neural networks to\ndeformable manifolds. Finally, we conclude by proposing a novel auto-regressive\nmodel for capturing the intrinsic geometry and topology of data. Throughout\nthis work, we will use the idea of computing correspondences as a though-line\nto both motivate our work and analyze our results.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:50:48 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Schonsheck", "Stefan C", ""]]}, {"id": "2009.01790", "submitter": "Ghadir Ayache", "authors": "Ghadir Ayache and Salim El Rouayheb", "title": "Private Weighted Random Walk Stochastic Gradient Descent", "comments": null, "journal-ref": "IEEE Journal on Selected Areas in Information Theory 2021", "doi": "10.1109/JSAIT.2021.3052975", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized learning setting in which data is distributed\nover nodes in a graph. The goal is to learn a global model on the distributed\ndata without involving any central entity that needs to be trusted. While\ngossip-based stochastic gradient descent (SGD) can be used to achieve this\nlearning objective, it incurs high communication and computation costs, since\nit has to wait for all the local models at all the nodes to converge. To speed\nup the convergence, we propose instead to study random walk based SGD in which\na global model is updated based on a random walk on the graph. We propose two\nalgorithms based on two types of random walks that achieve, in a decentralized\nway, uniform sampling and importance sampling of the data. We provide a\nnon-asymptotic analysis on the rate of convergence, taking into account the\nconstants related to the data and the graph. Our numerical results show that\nthe weighted random walk based algorithm has a better performance for\nhigh-variance data. Moreover, we propose a privacy-preserving random walk\nalgorithm that achieves local differential privacy based on a Gamma noise\nmechanism that we propose. We also give numerical results on the convergence of\nthis algorithm and show that it outperforms additive Laplace-based privacy\nmechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:52:13 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 10:10:25 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ayache", "Ghadir", ""], ["Rouayheb", "Salim El", ""]]}, {"id": "2009.01791", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston,\n  Nicolas Heess", "title": "Action and Perception as Divergence Minimization", "comments": "14 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a unified objective for action and perception of intelligent\nagents. Extending representation learning and control, we minimize the joint\ndivergence between the combined system of agent and environment and a target\ndistribution. Intuitively, such agents use perception to align their beliefs\nwith the world, and use actions to align the world with their beliefs.\nMinimizing the joint divergence to an expressive target maximizes the mutual\ninformation between the agent's representations and inputs, thus inferring\nrepresentations that are informative of past inputs and exploring future inputs\nthat are informative of the representations. This lets us explain intrinsic\nobjectives, such as representation learning, information gain, empowerment, and\nskill discovery from minimal assumptions. Moreover, interpreting the target\ndistribution as a latent variable model suggests powerful world models as a\npath toward highly adaptive agents that seek large niches in their\nenvironments, rendering task rewards optional. The framework provides a common\nlanguage for comparing a wide range of objectives, advances the understanding\nof latent variables for decision making, and offers a recipe for designing\nnovel objectives. We recommend deriving future agent objectives the joint\ndivergence to facilitate comparison, to point out the agent's target\ndistribution, and to identify the intrinsic objective terms needed to reach\nthat distribution.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:52:46 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:52:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hafner", "Danijar", ""], ["Ortega", "Pedro A.", ""], ["Ba", "Jimmy", ""], ["Parr", "Thomas", ""], ["Friston", "Karl", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.01797", "submitter": "Martin Mundt", "authors": "Martin Mundt, Yong Won Hong, Iuliia Pliushch, Visvanathan Ramesh", "title": "A Wholistic View of Continual Learning with Deep Neural Networks:\n  Forgotten Lessons and the Bridge to Active and Open World Learning", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning research is dominated by benchmark evaluation. A method\nis regarded as favorable if it empirically performs well on the dedicated test\nset. This mentality is seamlessly reflected in the resurfacing area of\ncontinual learning, where consecutively arriving sets of benchmark data are\ninvestigated. The core challenge is framed as protecting previously acquired\nrepresentations from being catastrophically forgotten due to the iterative\nparameter updates. However, comparison of individual methods is nevertheless\ntreated in isolation from real world application and typically judged by\nmonitoring accumulated test set performance. The closed world assumption\nremains predominant. It is assumed that during deployment a model is guaranteed\nto encounter data that stems from the same distribution as used for training.\nThis poses a massive challenge as neural networks are well known to provide\noverconfident false predictions on unknown instances and break down in the face\nof corrupted data. In this work we argue that notable lessons from open set\nrecognition, the identification of statistically deviating data outside of the\nobserved dataset, and the adjacent field of active learning, where data is\nincrementally queried such that the expected performance gain is maximized, are\nfrequently overlooked in the deep learning era. Based on these forgotten\nlessons, we propose a consolidated view to bridge continual learning, active\nlearning and open set recognition in deep neural networks. Our results show\nthat this not only benefits each individual paradigm, but highlights the\nnatural synergies in a common framework. We empirically demonstrate\nimprovements when alleviating catastrophic forgetting, querying data in active\nlearning, selecting task orders, while exhibiting robust open world application\nwhere previously proposed methods fail.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:56:36 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:57:41 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mundt", "Martin", ""], ["Hong", "Yong Won", ""], ["Pliushch", "Iuliia", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "2009.01798", "submitter": "John Mitros", "authors": "John Mitros and Arjun Pakrashi and Brian Mac Namee", "title": "Ramifications of Approximate Posterior Inference for Bayesian Deep\n  Learning in Adversarial and Out-of-Distribution Settings", "comments": "AROW@ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successful in diverse discriminative\nclassification tasks, although, they are poorly calibrated often assigning high\nprobability to misclassified predictions. Potential consequences could lead to\ntrustworthiness and accountability of the models when deployed in real\napplications, where predictions are evaluated based on their confidence scores.\nExisting solutions suggest the benefits attained by combining deep neural\nnetworks and Bayesian inference to quantify uncertainty over the models'\npredictions for ambiguous datapoints. In this work we propose to validate and\ntest the efficacy of likelihood based models in the task of out of distribution\ndetection (OoD). Across different datasets and metrics we show that Bayesian\ndeep learning models on certain occasions marginally outperform conventional\nneural networks and in the event of minimal overlap between in/out distribution\nclasses, even the best models exhibit a reduction in AUC scores in detecting\nOoD data. Preliminary investigations indicate the potential inherent role of\nbias due to choices of initialisation, architecture or activation functions. We\nhypothesise that the sensitivity of neural networks to unseen inputs could be a\nmulti-factor phenomenon arising from the different architectural design choices\noften amplified by the curse of dimensionality. Furthermore, we perform a study\nto find the effect of the adversarial noise resistance methods on in and\nout-of-distribution performance, as well as, also investigate adversarial noise\nrobustness of Bayesian deep learners.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:58:15 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 14:46:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Mitros", "John", ""], ["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "2009.01803", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai", "title": "Sparse Meta Networks for Sequential Adaptation and its Application to\n  Adaptive Language Modelling", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network requires a large amount of single-task data\nand involves a long time-consuming optimization phase. This is not scalable to\ncomplex, realistic environments with new unexpected changes. Humans can perform\nfast incremental learning on the fly and memory systems in the brain play a\ncritical role. We introduce Sparse Meta Networks -- a meta-learning approach to\nlearn online sequential adaptation algorithms for deep neural networks, by\nusing deep neural networks. We augment a deep neural network with a\nlayer-specific fast-weight memory. The fast-weights are generated sparsely at\neach time step and accumulated incrementally through time providing a useful\ninductive bias for online continual adaptation. We demonstrate strong\nperformance on a variety of sequential adaptation scenarios, from a simple\nonline reinforcement learning to a large scale adaptive language modelling.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:06:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""]]}, {"id": "2009.01807", "submitter": "Youzuo Lin", "authors": "Ren\\'an Rojas-G\\'omez, Jihyun Yang, Youzuo Lin, James Theiler, Brendt\n  Wohlberg", "title": "Physics-Consistent Data-driven Waveform Inversion with Adaptive Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2020.3022021", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Seismic full-waveform inversion (FWI) is a nonlinear computational imaging\ntechnique that can provide detailed estimates of subsurface geophysical\nproperties. Solving the FWI problem can be challenging due to its ill-posedness\nand high computational cost. In this work, we develop a new hybrid\ncomputational approach to solve FWI that combines physics-based models with\ndata-driven methodologies. In particular, we develop a data augmentation\nstrategy that can not only improve the representativity of the training set but\nalso incorporate important governing physics into the training process and\ntherefore improve the inversion accuracy. To validate the performance, we apply\nour method to synthetic elastic seismic waveform data generated from a\nsubsurface geologic model built on a carbon sequestration site at Kimberlina,\nCalifornia. We compare our physics-consistent data-driven inversion method to\nboth purely physics-based and purely data-driven approaches and observe that\nour method yields higher accuracy and greater generalization ability.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:12:55 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Rojas-G\u00f3mez", "Ren\u00e1n", ""], ["Yang", "Jihyun", ""], ["Lin", "Youzuo", ""], ["Theiler", "James", ""], ["Wohlberg", "Brendt", ""]]}, {"id": "2009.01816", "submitter": "Dimitris Perdios", "authors": "Dimitris Perdios, Manuel Vonlanthen, Florian Martinez, Marcel Arditi,\n  Jean-Philippe Thiran", "title": "CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement\n  Tracking", "comments": "11 pages, 4 figures. Animation and slideshow of Figure 4 are provided\n  as ancillary files. This version has been accepted for publication in the\n  IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.3046700", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to its capability of acquiring full-view frames at multiple kilohertz,\nultrafast ultrasound imaging unlocked the analysis of rapidly changing physical\nphenomena in the human body, with pioneering applications such as\nultrasensitive flow imaging in the cardiovascular system or shear-wave\nelastography. The accuracy achievable with these motion estimation techniques\nis strongly contingent upon two contradictory requirements: a high quality of\nconsecutive frames and a high frame rate. Indeed, the image quality can usually\nbe improved by increasing the number of steered ultrafast acquisitions, but at\nthe expense of a reduced frame rate and possible motion artifacts. To achieve\naccurate motion estimation at uncompromised frame rates and immune to motion\nartifacts, the proposed approach relies on single ultrafast acquisitions to\nreconstruct high-quality frames and on only two consecutive frames to obtain\n2-D displacement estimates. To this end, we deployed a convolutional neural\nnetwork-based image reconstruction method combined with a speckle tracking\nalgorithm based on cross-correlation. Numerical and in vivo experiments,\nconducted in the context of plane-wave imaging, demonstrate that the proposed\napproach is capable of estimating displacements in regions where the presence\nof side lobe and grating lobe artifacts prevents any displacement estimation\nwith a state-of-the-art technique that relies on conventional delay-and-sum\nbeamforming. The proposed approach may therefore unlock the full potential of\nultrafast ultrasound, in applications such as ultrasensitive cardiovascular\nmotion and flow analysis or shear-wave elastography.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:31:44 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 17:56:40 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Perdios", "Dimitris", ""], ["Vonlanthen", "Manuel", ""], ["Martinez", "Florian", ""], ["Arditi", "Marcel", ""], ["Thiran", "Jean-Philippe", ""]]}, {"id": "2009.01822", "submitter": "Amirhossein Hajavi", "authors": "Amirhossein Hajavi, Ali Etemad", "title": "Knowing What to Listen to: Early Attention for Deep Speech\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning techniques have considerably improved speech processing in\nrecent years. Speech representations extracted by deep learning models are\nbeing used in a wide range of tasks such as speech recognition, speaker\nrecognition, and speech emotion recognition. Attention models play an important\nrole in improving deep learning models. However current attention mechanisms\nare unable to attend to fine-grained information items. In this paper we\npropose the novel Fine-grained Early Frequency Attention (FEFA) for speech\nsignals. This model is capable of focusing on information items as small as\nfrequency bins. We evaluate the proposed model on two popular tasks of speaker\nrecognition and speech emotion recognition. Two widely used public datasets,\nVoxCeleb and IEMOCAP, are used for our experiments. The model is implemented on\ntop of several prominent deep models as backbone networks to evaluate its\nimpact on performance compared to the original networks and other related work.\nOur experiments show that by adding FEFA to different CNN architectures,\nperformance is consistently improved by substantial margins, even setting a new\nstate-of-the-art for the speaker recognition task. We also tested our model\nagainst different levels of added noise showing improvements in robustness and\nless sensitivity compared to the backbone networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:40:27 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "2009.01845", "submitter": "Stefano Carrazza", "authors": "Stavros Efthymiou, Sergi Ramos-Calderer, Carlos Bravo-Prieto, Adri\\'an\n  P\\'erez-Salinas, Diego Garc\\'ia-Mart\\'in, Artur Garcia-Saez, Jos\\'e Ignacio\n  Latorre, Stefano Carrazza", "title": "Qibo: a framework for quantum simulation with hardware acceleration", "comments": "15 pages, 12 figures, 5 tables,code available at\n  https://github.com/Quantum-TII/qibo", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Qibo, a new open-source software for fast evaluation of quantum\ncircuits and adiabatic evolution which takes full advantage of hardware\naccelerators. The growing interest in quantum computing and the recent\ndevelopments of quantum hardware devices motivates the development of new\nadvanced computational tools focused on performance and usage simplicity. In\nthis work we introduce a new quantum simulation framework that enables\ndevelopers to delegate all complicated aspects of hardware or platform\nimplementation to the library so they can focus on the problem and quantum\nalgorithms at hand. This software is designed from scratch with simulation\nperformance, code simplicity and user friendly interface as target goals. It\ntakes advantage of hardware acceleration such as multi-threading CPU, single\nGPU and multi-GPU devices.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:00:01 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Efthymiou", "Stavros", ""], ["Ramos-Calderer", "Sergi", ""], ["Bravo-Prieto", "Carlos", ""], ["P\u00e9rez-Salinas", "Adri\u00e1n", ""], ["Garc\u00eda-Mart\u00edn", "Diego", ""], ["Garcia-Saez", "Artur", ""], ["Latorre", "Jos\u00e9 Ignacio", ""], ["Carrazza", "Stefano", ""]]}, {"id": "2009.01865", "submitter": "Michael Lomnitz", "authors": "Michael Lomnitz, Zigfried Hampel-Arias, Nina Lopatina, Felipe A. Mejia", "title": "A general approach to bridge the reality-gap", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Employing machine learning models in the real world requires collecting large\namounts of data, which is both time consuming and costly to collect. A common\napproach to circumvent this is to leverage existing, similar data-sets with\nlarge amounts of labelled data. However, models trained on these canonical\ndistributions do not readily transfer to real-world ones. Domain adaptation and\ntransfer learning are often used to breach this \"reality gap\", though both\nrequire a substantial amount of real-world data. In this paper we discuss a\nmore general approach: we propose learning a general transformation to bring\narbitrary images towards a canonical distribution where we can naively apply\nthe trained machine learning models. This transformation is trained in an\nunsupervised regime, leveraging data augmentation to generate off-canonical\nexamples of images and training a Deep Learning model to recover their original\ncounterpart. We quantify the performance of this transformation using\npre-trained ImageNet classifiers, demonstrating that this procedure can recover\nhalf of the loss in performance on the distorted data-set. We then validate the\neffectiveness of this approach on a series of pre-trained ImageNet models on a\nreal world data set collected by printing and photographing images in different\nlighting conditions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:19:28 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Lomnitz", "Michael", ""], ["Hampel-Arias", "Zigfried", ""], ["Lopatina", "Nina", ""], ["Mejia", "Felipe A.", ""]]}, {"id": "2009.01867", "submitter": "Sheng Lin", "authors": "Sheng Lin, Chenghong Wang, Hongjia Li, Jieren Deng, Yanzhi Wang,\n  Caiwen Ding", "title": "ESMFL: Efficient and Secure Models for Federated Learning", "comments": "7 pages, 3 figures, accepted by NeurIPS Workshop 2020, SpicyFL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Deep Neural Networks are widely applied to various domains.\nHowever, massive data collection required for deep neural network reveals the\npotential privacy issues and also consumes large mounts of communication\nbandwidth. To address these problems, we propose a privacy-preserving method\nfor the federated learning distributed system, operated on Intel Software Guard\nExtensions, a set of instructions that increase the security of application\ncode and data. Meanwhile, the encrypted models make the transmission overhead\nlarger. Hence, we reduce the commutation cost by sparsification and it can\nachieve reasonable accuracy with different model architectures.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 18:27:32 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 19:45:00 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Lin", "Sheng", ""], ["Wang", "Chenghong", ""], ["Li", "Hongjia", ""], ["Deng", "Jieren", ""], ["Wang", "Yanzhi", ""], ["Ding", "Caiwen", ""]]}, {"id": "2009.01884", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, Alexandre Bolot, S\\'ebastien Gambs", "title": "Model extraction from counterfactual explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanation techniques refer to a posteriori methods that can be\nused to explain how black-box machine learning models produce their outcomes.\nAmong post-hoc explanation techniques, counterfactual explanations are becoming\none of the most popular methods to achieve this objective. In particular, in\naddition to highlighting the most important features used by the black-box\nmodel, they provide users with actionable explanations in the form of data\ninstances that would have received a different outcome. Nonetheless, by doing\nso, they also leak non-trivial information about the model itself, which raises\nprivacy issues. In this work, we demonstrate how an adversary can leverage the\ninformation provided by counterfactual explanations to build high-fidelity and\nhigh-accuracy model extraction attacks. More precisely, our attack enables the\nadversary to build a faithful copy of a target model by accessing its\ncounterfactual explanations. The empirical evaluation of the proposed attack on\nblack-box models trained on real-world datasets demonstrates that they can\nachieve high-fidelity and high-accuracy extraction even under low query\nbudgets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 19:02:55 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Bolot", "Alexandre", ""], ["Gambs", "S\u00e9bastien", ""]]}, {"id": "2009.01924", "submitter": "Nina Montana Brown Miss", "authors": "N. Montana Brown, Y. Fu, S. U. Saeed, A. Casamitjana, Z. M. C. Baum,\n  R. Delaunay, Q. Yang, A. Grimwood, Z. Min, E. Bonmati, T. Vercauteren, M. J.\n  Clarkson, and Y. Hu", "title": "Introduction to Medical Image Registration with DeepReg, Between Old and\n  New", "comments": "Submitted to MICCAI Educational Challenge 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document outlines a tutorial to get started with medical image\nregistration using the open-source package DeepReg. The basic concepts of\nmedical image registration are discussed, linking classical methods to newer\nmethods using deep learning. Two iterative, classical algorithms using\noptimisation and one learning-based algorithm using deep learning are coded\nstep-by-step using DeepReg utilities, all with real, open-accessible, medical\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 19:44:23 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:45:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Brown", "N. Montana", ""], ["Fu", "Y.", ""], ["Saeed", "S. U.", ""], ["Casamitjana", "A.", ""], ["Baum", "Z. M. C.", ""], ["Delaunay", "R.", ""], ["Yang", "Q.", ""], ["Grimwood", "A.", ""], ["Min", "Z.", ""], ["Bonmati", "E.", ""], ["Vercauteren", "T.", ""], ["Clarkson", "M. J.", ""], ["Hu", "Y.", ""]]}, {"id": "2009.01934", "submitter": "Arun Kumar Singh", "authors": "Arun Kumar Singh (1), Priyanka Singh (2) ((1) Indian Institute of\n  Technology Jammu, (2) Dhirubhai Ambani Institute of Information and\n  Communication Technology)", "title": "Detection of AI-Synthesized Speech Using Cepstral & Bispectral\n  Statistics", "comments": "6 Pages, 6 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital technology has made possible unimaginable applications come true. It\nseems exciting to have a handful of tools for easy editing and manipulation,\nbut it raises alarming concerns that can propagate as speech clones,\nduplicates, or maybe deep fakes. Validating the authenticity of a speech is one\nof the primary problems of digital audio forensics. We propose an approach to\ndistinguish human speech from AI synthesized speech exploiting the Bi-spectral\nand Cepstral analysis. Higher-order statistics have less correlation for human\nspeech in comparison to a synthesized speech. Also, Cepstral analysis revealed\na durable power component in human speech that is missing for a synthesized\nspeech. We integrate both these analyses and propose a machine learning model\nto detect AI synthesized speech.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 21:29:41 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 11:41:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Singh", "Arun Kumar", ""], ["Singh", "Priyanka", ""]]}, {"id": "2009.01947", "submitter": "Alan Kuhnle", "authors": "Alan Kuhnle", "title": "Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone\n  Submodular Maximization", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parallelizable algorithms for maximization of a submodular function,\nnot necessarily monotone, with respect to a cardinality constraint $k$. We\nimprove the best approximation factor achieved by an algorithm that has optimal\nadaptivity and query complexity, up to logarithmic factors in the size $n$ of\nthe ground set, from $0.039 - \\epsilon$ to $0.193 - \\epsilon$. We provide two\nalgorithms; the first has approximation ratio $1/6 - \\epsilon$, adaptivity $O(\n\\log n )$, and query complexity $O( n \\log k )$, while the second has\napproximation ratio $0.193 - \\epsilon$, adaptivity $O( \\log^2 n )$, and query\ncomplexity $O(n \\log k)$. Heuristic versions of our algorithms are empirically\nvalidated to use a low number of adaptive rounds and total queries while\nobtaining solutions with high objective value in comparison with\nstate-of-the-art approximation algorithms, including continuous algorithms that\nuse the multilinear extension.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 22:43:55 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:38:58 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 18:27:28 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kuhnle", "Alan", ""]]}, {"id": "2009.01956", "submitter": "Priyadarshini Panda", "authors": "Varigonda Pavan Teja, and Priyadarshini Panda", "title": "Compression-aware Continual Learning using Singular Value Decomposition", "comments": "13 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a compression based continual task learning method that can\ndynamically grow a neural network. Inspired from the recent model compression\ntechniques, we employ compression-aware training and perform low-rank weight\napproximations using singular value decomposition (SVD) to achieve network\ncompaction. By encouraging the network to learn low-rank weight filters, our\nmethod achieves compressed representations with minimal performance degradation\nwithout the need for costly fine-tuning. Specifically, we decompose the weight\nfilters using SVD and train the network on incremental tasks in its factorized\nform. Such a factorization allows us to directly impose sparsity-inducing\nregularizers over the singular values and allows us to use fewer number of\nparameters for each task. We further introduce a novel shared representational\nspace based learning between tasks. This promotes the incoming tasks to only\nlearn residual task-specific information on top of the previously learnt weight\nfilters and greatly helps in learning under fixed capacity constraints. Our\nmethod significantly outperforms prior continual learning approaches on three\nbenchmark datasets, demonstrating accuracy improvements of 10.3%, 12.3%, 15.6%\non 20-split CIFAR-100, miniImageNet and a 5-sequence dataset, respectively,\nover state-of-the-art. Further, our method yields compressed models that have\n~3.64x, 2.88x, 5.91x fewer number of parameters respectively, on the above\nmentioned datasets in comparison to baseline individual task models. Our source\ncode is available at https://github.com/pavanteja295/CACL.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:29:50 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 22:29:21 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Teja", "Varigonda Pavan", ""], ["Panda", "Priyadarshini", ""]]}, {"id": "2009.01959", "submitter": "Marcelo De Rezende Martins", "authors": "Marcelo de Rezende Martins and Marco A. Gerosa", "title": "CoNCRA: A Convolutional Neural Network Code Retrieval Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3422392.3422462", "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers routinely search for code using general-purpose search\nengines. However, these search engines cannot find code semantically unless it\nhas an accompanying description. We propose a technique for semantic code\nsearch: A Convolutional Neural Network approach to code retrieval (CoNCRA). Our\ntechnique aims to find the code snippet that most closely matches the\ndeveloper's intent, expressed in natural language. We evaluated our approach's\nefficacy on a dataset composed of questions and code snippets collected from\nStack Overflow. Our preliminary results showed that our technique, which\nprioritizes local interactions (words nearby), improved the state-of-the-art\n(SOTA) by 5% on average, retrieving the most relevant code snippets in the top\n3 (three) positions by almost 80% of the time. Therefore, our technique is\npromising and can improve the efficacy of semantic code retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:38:52 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Martins", "Marcelo de Rezende", ""], ["Gerosa", "Marco A.", ""]]}, {"id": "2009.01966", "submitter": "Akira Matsui", "authors": "Akira Matsui, Emilio Ferrara, Fred Morstatter, Andres Abeliuk, Aram\n  Galstyan", "title": "Leveraging Clickstream Trajectories to Reveal Low-Quality Workers in\n  Crowdsourced Forecasting Platforms", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdwork often entails tackling cognitively-demanding and time-consuming\ntasks. Crowdsourcing can be used for complex annotation tasks, from medical\nimaging to geospatial data, and such data powers sensitive applications, such\nas health diagnostics or autonomous driving. However, the existence and\nprevalence of underperforming crowdworkers is well-recognized, and can pose a\nthreat to the validity of crowdsourcing. In this study, we propose the use of a\ncomputational framework to identify clusters of underperforming workers using\nclickstream trajectories. We focus on crowdsourced geopolitical forecasting.\nThe framework can reveal different types of underperformers, such as workers\nwith forecasts whose accuracy is far from the consensus of the crowd, those who\nprovide low-quality explanations for their forecasts, and those who simply\ncopy-paste their forecasts from other users. Our study suggests that\nclickstream clustering and analysis are fundamental tools to diagnose the\nperformance of crowdworkers in platforms leveraging the wisdom of crowds.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 00:26:38 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Matsui", "Akira", ""], ["Ferrara", "Emilio", ""], ["Morstatter", "Fred", ""], ["Abeliuk", "Andres", ""], ["Galstyan", "Aram", ""]]}, {"id": "2009.01974", "submitter": "Wei-Lun Chao", "authors": "Hong-You Chen, Wei-Lun Chao", "title": "FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning aims to collaboratively train a strong global model by\naccessing users' locally trained models but not their own data. A crucial step\nis therefore to aggregate local models into a global model, which has been\nshown challenging when users have non-i.i.d. data. In this paper, we propose a\nnovel aggregation algorithm named FedBE, which takes a Bayesian inference\nperspective by sampling higher-quality global models and combining them via\nBayesian model Ensemble, leading to much robust aggregation. We show that an\neffective model distribution can be constructed by simply fitting a Gaussian or\nDirichlet distribution to the local models. Our empirical studies validate\nFedBE's superior performance, especially when users' data are not i.i.d. and\nwhen the neural networks go deeper. Moreover, FedBE is compatible with recent\nefforts in regularizing users' model training, making it an easily applicable\nmodule: you only need to replace the aggregation method but leave other parts\nof your federated learning algorithm intact.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 01:18:25 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 23:42:34 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 21:36:23 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chen", "Hong-You", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2009.01987", "submitter": "Mohammad Fasha", "authors": "Mohammad Fasha, Bassam Hammo, Nadim Obeid, Jabir Widian", "title": "A Hybrid Deep Learning Model for Arabic Text Recognition", "comments": "11 pages", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, Vol. 11, No. 8, 2020", "doi": "10.14569/issn.2156-5570", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic text recognition is a challenging task because of the cursive nature\nof Arabic writing system, its joint writing scheme, the large number of\nligatures and many other challenges. Deep Learning DL models achieved\nsignificant progress in numerous domains including computer vision and sequence\nmodelling. This paper presents a model that can recognize Arabic text that was\nprinted using multiple font types including fonts that mimic Arabic handwritten\nscripts. The proposed model employs a hybrid DL network that can recognize\nArabic printed text without the need for character segmentation. The model was\ntested on a custom dataset comprised of over two million word samples that were\ngenerated using 18 different Arabic font types. The objective of the testing\nprocess was to assess the model capability in recognizing a diverse set of\nArabic fonts representing a varied cursive styles. The model achieved good\nresults in recognizing characters and words and it also achieved promising\nresults in recognizing characters when it was tested on unseen data. The\nprepared model, the custom datasets and the toolkit for generating similar\ndatasets are made publicly available, these tools can be used to prepare models\nfor recognizing other font types as well as to further extend and enhance the\nperformance of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 02:49:17 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Fasha", "Mohammad", ""], ["Hammo", "Bassam", ""], ["Obeid", "Nadim", ""], ["Widian", "Jabir", ""]]}, {"id": "2009.01989", "submitter": "Minghui Qiu", "authors": "Cen Chen, Bingzhe Wu, Minghui Qiu, Li Wang, Jun Zhou", "title": "A Comprehensive Analysis of Information Leakage in Deep Transfer\n  Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer learning is widely used for transferring knowledge from a source\ndomain to the target domain where the labeled data is scarce. Recently, deep\ntransfer learning has achieved remarkable progress in various applications.\nHowever, the source and target datasets usually belong to two different\norganizations in many real-world scenarios, potential privacy issues in deep\ntransfer learning are posed. In this study, to thoroughly analyze the potential\nprivacy leakage in deep transfer learning, we first divide previous methods\ninto three categories. Based on that, we demonstrate specific threats that lead\nto unintentional privacy leakage in each category. Additionally, we also\nprovide some solutions to prevent these threats. To the best of our knowledge,\nour study is the first to provide a thorough analysis of the information\nleakage issues in deep transfer learning methods and provide potential\nsolutions to the issue. Extensive experiments on two public datasets and an\nindustry dataset are conducted to show the privacy leakage under different deep\ntransfer learning settings and defense solution effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 02:53:20 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Chen", "Cen", ""], ["Wu", "Bingzhe", ""], ["Qiu", "Minghui", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""]]}, {"id": "2009.02003", "submitter": "Ethan Fang", "authors": "Yining Wang, Yi Chen, Ethan X. Fang, Zhaoran Wang and Runze Li", "title": "Nearly Dimension-Independent Sparse Linear Bandit over Small Action\n  Spaces via Best Subset Selection", "comments": "54 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic contextual bandit problem under the high\ndimensional linear model. We focus on the case where the action space is finite\nand random, with each action associated with a randomly generated contextual\ncovariate. This setting finds essential applications such as personalized\nrecommendation, online advertisement, and personalized medicine. However, it is\nvery challenging as we need to balance exploration and exploitation. We propose\ndoubly growing epochs and estimating the parameter using the best subset\nselection method, which is easy to implement in practice. This approach\nachieves $ \\tilde{\\mathcal{O}}(s\\sqrt{T})$ regret with high probability, which\nis nearly independent in the ``ambient'' regression model dimension $d$. We\nfurther attain a sharper $\\tilde{\\mathcal{O}}(\\sqrt{sT})$ regret by using the\n\\textsc{SupLinUCB} framework and match the minimax lower bound of\nlow-dimensional linear stochastic bandit problems. Finally, we conduct\nextensive numerical experiments to demonstrate the applicability and robustness\nof our algorithms empirically.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 04:10:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Yi", ""], ["Fang", "Ethan X.", ""], ["Wang", "Zhaoran", ""], ["Li", "Runze", ""]]}, {"id": "2009.02009", "submitter": "Jaeseong Lee", "authors": "Jaeseong Lee, Duseok Kang and Soonhoi Ha", "title": "S3NAS: Fast NPU-aware Neural Architecture Search Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the application area of convolutional neural networks (CNN) is growing in\nembedded devices, it becomes popular to use a hardware CNN accelerator, called\nneural processing unit (NPU), to achieve higher performance per watt than CPUs\nor GPUs. Recently, automated neural architecture search (NAS) emerges as the\ndefault technique to find a state-of-the-art CNN architecture with higher\naccuracy than manually-designed architectures for image classification. In this\npaper, we present a fast NPU-aware NAS methodology, called S3NAS, to find a CNN\narchitecture with higher accuracy than the existing ones under a given latency\nconstraint. It consists of three steps: supernet design, Single-Path NAS for\nfast architecture exploration, and scaling. To widen the search space of the\nsupernet structure that consists of stages, we allow stages to have a different\nnumber of blocks and blocks to have parallel layers of different kernel sizes.\nFor a fast neural architecture search, we apply a modified Single-Path NAS\ntechnique to the proposed supernet structure. In this step, we assume a shorter\nlatency constraint than the required to reduce the search space and the search\ntime. The last step is to scale up the network maximally within the latency\nconstraint. For accurate latency estimation, an analytical latency estimator is\ndevised, based on a cycle-level NPU simulator that runs an entire CNN\nconsidering the memory access overhead accurately. With the proposed\nmethodology, we are able to find a network in 3 hours using TPUv3, which shows\n82.72% top-1 accuracy on ImageNet with 11.66 ms latency. Code are released at\nhttps://github.com/cap-lab/S3NAS\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 04:45:50 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Lee", "Jaeseong", ""], ["Kang", "Duseok", ""], ["Ha", "Soonhoi", ""]]}, {"id": "2009.02010", "submitter": "Sheng-Chun Kao", "authors": "Sheng-Chun Kao, Geonhwa Jeong, Tushar Krishna", "title": "ConfuciuX: Autonomous Hardware Resource Assignment for DNN Accelerators\n  using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN accelerators provide efficiency by leveraging reuse of\nactivations/weights/outputs during the DNN computations to reduce data movement\nfrom DRAM to the chip. The reuse is captured by the accelerator's dataflow.\nWhile there has been significant prior work in exploring and comparing various\ndataflows, the strategy for assigning on-chip hardware resources (i.e., compute\nand memory) given a dataflow that can optimize for performance/energy while\nmeeting platform constraints of area/power for DNN(s) of interest is still\nrelatively unexplored. The design-space of choices for balancing compute and\nmemory explodes combinatorially, as we show in this work (e.g., as large as\nO(10^(72)) choices for running \\mobilenet), making it infeasible to do\nmanual-tuning via exhaustive searches. It is also difficult to come up with a\nspecific heuristic given that different DNNs and layer types exhibit different\namounts of reuse.\n  In this paper, we propose an autonomous strategy called ConfuciuX to find\noptimized HW resource assignments for a given model and dataflow style.\nConfuciuX leverages a reinforcement learning method, REINFORCE, to guide the\nsearch process, leveraging a detailed HW performance cost model within the\ntraining loop to estimate rewards. We also augment the RL approach with a\ngenetic algorithm for further fine-tuning. ConfuciuX demonstrates the highest\nsample-efficiency for training compared to other techniques such as Bayesian\noptimization, genetic algorithm, simulated annealing, and other RL methods. It\nconverges to the optimized hardware configuration 4.7 to 24 times faster than\nalternate techniques.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 04:59:26 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Kao", "Sheng-Chun", ""], ["Jeong", "Geonhwa", ""], ["Krishna", "Tushar", ""]]}, {"id": "2009.02027", "submitter": "Han Yang", "authors": "Han Yang and Kaili Ma and James Cheng", "title": "Rethinking Graph Regularization for Graph Neural Networks", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph Laplacian regularization term is usually used in semi-supervised\nrepresentation learning to provide graph structure information for a model\n$f(X)$. However, with the recent popularity of graph neural networks (GNNs),\ndirectly encoding graph structure $A$ into a model, i.e., $f(A, X)$, has become\nthe more common approach. While we show that graph Laplacian regularization\nbrings little-to-no benefit to existing GNNs, and propose a simple but\nnon-trivial variant of graph Laplacian regularization, called\nPropagation-regularization (P-reg), to boost the performance of existing GNN\nmodels. We provide formal analyses to show that P-reg not only infuses extra\ninformation (that is not captured by the traditional graph Laplacian\nregularization) into GNNs, but also has the capacity equivalent to an\ninfinite-depth graph convolutional network. We demonstrate that P-reg can\neffectively boost the performance of existing GNN models on both node-level and\ngraph-level tasks across many different datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:04:51 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 15:52:58 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yang", "Han", ""], ["Ma", "Kaili", ""], ["Cheng", "James", ""]]}, {"id": "2009.02040", "submitter": "Hang Zhao", "authors": "Hang Zhao, Yujing Wang, Juanyong Duan, Congrui Huang, Defu Cao, Yunhai\n  Tong, Bixiong Xu, Jing Bai, Jie Tong, Qi Zhang", "title": "Multivariate Time-series Anomaly Detection via Graph Attention Network", "comments": "Accepted by ICDM 2020. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection on multivariate time-series is of great importance in both\ndata mining research and industrial applications. Recent approaches have\nachieved significant progress in this topic, but there is remaining\nlimitations. One major limitation is that they do not capture the relationships\nbetween different time-series explicitly, resulting in inevitable false alarms.\nIn this paper, we propose a novel self-supervised framework for multivariate\ntime-series anomaly detection to address this issue. Our framework considers\neach univariate time-series as an individual feature and includes two graph\nattention layers in parallel to learn the complex dependencies of multivariate\ntime-series in both temporal and feature dimensions. In addition, our approach\njointly optimizes a forecasting-based model and are construction-based model,\nobtaining better time-series representations through a combination of\nsingle-timestamp prediction and reconstruction of the entire time-series. We\ndemonstrate the efficacy of our model through extensive experiments. The\nproposed method outperforms other state-of-the-art models on three real-world\ndatasets. Further analysis shows that our method has good interpretability and\nis useful for anomaly diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:46:19 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Zhao", "Hang", ""], ["Wang", "Yujing", ""], ["Duan", "Juanyong", ""], ["Huang", "Congrui", ""], ["Cao", "Defu", ""], ["Tong", "Yunhai", ""], ["Xu", "Bixiong", ""], ["Bai", "Jing", ""], ["Tong", "Jie", ""], ["Zhang", "Qi", ""]]}, {"id": "2009.02043", "submitter": "Fredrik Olsson", "authors": "Fredrik Olsson, Magnus Sahlgren", "title": "Data Readiness for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document concerns data readiness in the context of machine learning and\nNatural Language Processing. It describes how an organization may proceed to\nidentify, make available, validate, and prepare data to facilitate automated\nanalysis methods. The contents of the document is based on the practical\nchallenges and frequently asked questions we have encountered in our work as an\napplied research institute with helping organizations and companies, both in\nthe public and private sectors, to use data in their business processes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:53:43 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:03:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Olsson", "Fredrik", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "2009.02051", "submitter": "Verena Haunschmid", "authors": "Verena Haunschmid, Ethan Manilow, Gerhard Widmer", "title": "Towards Musically Meaningful Explanations Using Source Separation", "comments": "6+2 pages, 4 figures; Submitted to International Society for Music\n  Information Retrieval Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are successfully applied in a wide variety of\nmusic information retrieval (MIR) tasks. Such models are usually considered\n\"black boxes\", meaning that their predictions are not interpretable. Prior work\non explainable models in MIR has generally used image processing tools to\nproduce explanations for DNN predictions, but these are not necessarily\nmusically meaningful, or can be listened to (which, arguably, is important in\nmusic). We propose audioLIME, a method based on Local Interpretable\nModel-agnostic Explanation (LIME), extended by a musical definition of\nlocality. LIME learns locally linear models on perturbations of an example that\nwe want to explain. Instead of extracting components of the spectrogram using\nimage segmentation as part of the LIME pipeline, we propose using source\nseparation. The perturbations are created by switching on/off sources which\nmakes our explanations listenable. We first validate audioLIME on a classifier\nthat was deliberately trained to confuse the true target with a spurious\nsignal, and show that this can easily be detected using our method. We then\nshow that it passes a sanity check that many available explanation methods\nfail. Finally, we demonstrate the general applicability of our (model-agnostic)\nmethod on a third-party music tagger.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 08:09:03 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Haunschmid", "Verena", ""], ["Manilow", "Ethan", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2009.02078", "submitter": "Heungseok Park", "authors": "Heungseok Park, Yoonsoo Nam, Ji-Hoon Kim, Jaegul Choo", "title": "HyperTendril: Visual Analytics for User-Driven Hyperparameter\n  Optimization of Deep Neural Networks", "comments": "Will be presented at IEEE VAST 2020 and published in IEEE\n  Transactions on Visualization and Computer Graphics", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030380", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To mitigate the pain of manually tuning hyperparameters of deep neural\nnetworks, automated machine learning (AutoML) methods have been developed to\nsearch for an optimal set of hyperparameters in large combinatorial search\nspaces. However, the search results of AutoML methods significantly depend on\ninitial configurations, making it a non-trivial task to find a proper\nconfiguration. Therefore, human intervention via a visual analytic approach\nbears huge potential in this task. In response, we propose HyperTendril, a\nweb-based visual analytics system that supports user-driven hyperparameter\ntuning processes in a model-agnostic environment. HyperTendril takes a novel\napproach to effectively steering hyperparameter optimization through an\niterative, interactive tuning procedure that allows users to refine the search\nspaces and the configuration of the AutoML method based on their own insights\nfrom given results. Using HyperTendril, users can obtain insights into the\ncomplex behaviors of various hyperparameter search algorithms and diagnose\ntheir configurations. In addition, HyperTendril supports variable importance\nanalysis to help the users refine their search spaces based on the analysis of\nrelative importance of different hyperparameters and their interaction effects.\nWe present the evaluation demonstrating how HyperTendril helps users steer\ntheir tuning processes via a longitudinal user study based on the analysis of\ninteraction logs and in-depth interviews while we deploy our system in a\nprofessional industrial environment.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 09:11:08 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 08:29:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Park", "Heungseok", ""], ["Nam", "Yoonsoo", ""], ["Kim", "Ji-Hoon", ""], ["Choo", "Jaegul", ""]]}, {"id": "2009.02085", "submitter": "Adrian Jarret", "authors": "Simon Brandeis, Adrian Jarret, Pierre Sevestre", "title": "About Graph Degeneracy, Representation Learning and Scalability", "comments": "Research project as part of CentraleSupelec final year engineering\n  degree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs or networks are a very convenient way to represent data with lots of\ninteraction. Recently, Machine Learning on Graph data has gained a lot of\ntraction. In particular, vertex classification and missing edge detection have\nvery interesting applications, ranging from drug discovery to recommender\nsystems. To achieve such tasks, tremendous work has been accomplished to learn\nembedding of nodes and edges into finite-dimension vector spaces. This task is\ncalled Graph Representation Learning. However, Graph Representation Learning\ntechniques often display prohibitive time and memory complexities, preventing\ntheir use in real-time with business size graphs. In this paper, we address\nthis issue by leveraging a degeneracy property of Graphs - the K-Core\nDecomposition. We present two techniques taking advantage of this decomposition\nto reduce the time and memory consumption of walk-based Graph Representation\nLearning algorithms. We evaluate the performances, expressed in terms of\nquality of embedding and computational resources, of the proposed techniques on\nseveral academic datasets. Our code is available at\nhttps://github.com/SBrandeis/kcore-embedding\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 09:39:43 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Brandeis", "Simon", ""], ["Jarret", "Adrian", ""], ["Sevestre", "Pierre", ""]]}, {"id": "2009.02095", "submitter": "Yunpeng Li", "authors": "Marco Tagliasacchi, Yunpeng Li, Karolis Misiunas, Dominik Roblek", "title": "SEANet: A Multi-modal Speech Enhancement Network", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the possibility of leveraging accelerometer data to perform speech\nenhancement in very noisy conditions. Although it is possible to only partially\nreconstruct user's speech from the accelerometer, the latter provides a strong\nconditioning signal that is not influenced from noise sources in the\nenvironment. Based on this observation, we feed a multi-modal input to SEANet\n(Sound EnhAncement Network), a wave-to-wave fully convolutional model, which\nadopts a combination of feature losses and adversarial losses to reconstruct an\nenhanced version of user's speech. We trained our model with data collected by\nsensors mounted on an earbud and synthetically corrupted by adding different\nkinds of noise sources to the audio signal. Our experimental results\ndemonstrate that it is possible to achieve very high quality results, even in\nthe case of interfering speech at the same level of loudness. A sample of the\noutput produced by our model is available at\nhttps://google-research.github.io/seanet/multimodal/speech.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 10:22:43 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:26:35 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Tagliasacchi", "Marco", ""], ["Li", "Yunpeng", ""], ["Misiunas", "Karolis", ""], ["Roblek", "Dominik", ""]]}, {"id": "2009.02098", "submitter": "Nijat Mehdiyev", "authors": "Nijat Mehdiyev and Peter Fettke", "title": "Explainable Artificial Intelligence for Process Mining: A General\n  Overview and Application of a Novel Local Explanation Approach for Predictive\n  Process Monitoring", "comments": "Manuscript submitted (10.07.2020) to the edited volume \"Interpretable\n  Artificial Intelligence: A perspective of Granular Computing\" (published by\n  Springer)", "journal-ref": null, "doi": "10.1007/978-3-030-64949-4_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contemporary process-aware information systems possess the capabilities\nto record the activities generated during the process execution. To leverage\nthese process specific fine-granular data, process mining has recently emerged\nas a promising research discipline. As an important branch of process mining,\npredictive business process management, pursues the objective to generate\nforward-looking, predictive insights to shape business processes. In this\nstudy, we propose a conceptual framework sought to establish and promote\nunderstanding of decision-making environment, underlying business processes and\nnature of the user characteristics for developing explainable business process\nprediction solutions. Consequently, with regard to the theoretical and\npractical implications of the framework, this study proposes a novel local\npost-hoc explanation approach for a deep learning classifier that is expected\nto facilitate the domain experts in justifying the model decisions. In contrary\nto alternative popular perturbation-based local explanation approaches, this\nstudy defines the local regions from the validation dataset by using the\nintermediate latent space representations learned by the deep neural networks.\nTo validate the applicability of the proposed explanation method, the real-life\nprocess log data delivered by the Volvo IT Belgium's incident management system\nare used.The adopted deep learning classifier achieves a good performance with\nthe Area Under the ROC Curve of 0.94. The generated local explanations are also\nvisualized and presented with relevant evaluation measures that are expected to\nincrease the users' trust in the black-box-model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 10:28:56 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 07:24:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Mehdiyev", "Nijat", ""], ["Fettke", "Peter", ""]]}, {"id": "2009.02110", "submitter": "Jose A. Gonzalez-Lopez", "authors": "Jose A. Gonzalez-Lopez, Alejandro Gomez-Alanis, Juan M.\n  Mart\\'in-Do\\~nas, Jos\\'e L. P\\'erez-C\\'ordoba, Angel M. Gomez", "title": "Silent Speech Interfaces for Speech Restoration: A Review", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3026579", "report-no": null, "categories": "eess.AS cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review summarises the status of silent speech interface (SSI) research.\nSSIs rely on non-acoustic biosignals generated by the human body during speech\nproduction to enable communication whenever normal verbal communication is not\npossible or not desirable. In this review, we focus on the first case and\npresent latest SSI research aimed at providing new alternative and augmentative\ncommunication methods for persons with severe speech disorders. SSIs can employ\na variety of biosignals to enable silent communication, such as\nelectrophysiological recordings of neural activity, electromyographic (EMG)\nrecordings of vocal tract movements or the direct tracking of articulator\nmovements using imaging techniques. Depending on the disorder, some sensing\ntechniques may be better suited than others to capture speech-related\ninformation. For instance, EMG and imaging techniques are well suited for\nlaryngectomised patients, whose vocal tract remains almost intact but are\nunable to speak after the removal of the vocal folds, but fail for severely\nparalysed individuals. From the biosignals, SSIs decode the intended message,\nusing automatic speech recognition or speech synthesis algorithms. Despite\nconsiderable advances in recent years, most present-day SSIs have only been\nvalidated in laboratory settings for healthy users. Thus, as discussed in this\npaper, a number of challenges remain to be addressed in future research before\nSSIs can be promoted to real-world applications. If these issues can be\naddressed successfully, future SSIs will improve the lives of persons with\nsevere speech impairments by restoring their communication capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 11:05:50 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 08:43:47 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 08:50:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gonzalez-Lopez", "Jose A.", ""], ["Gomez-Alanis", "Alejandro", ""], ["Mart\u00edn-Do\u00f1as", "Juan M.", ""], ["P\u00e9rez-C\u00f3rdoba", "Jos\u00e9 L.", ""], ["Gomez", "Angel M.", ""]]}, {"id": "2009.02113", "submitter": "Thomas Kober", "authors": "Vincent D. Warmerdam, Thomas Kober, Rachael Tatman", "title": "Going Beyond T-SNE: Exposing \\texttt{whatlies} in Text Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce whatlies, an open source toolkit for visually inspecting word\nand sentence embeddings. The project offers a unified and extensible API with\ncurrent support for a range of popular embedding backends including spaCy,\ntfhub, huggingface transformers, gensim, fastText and BytePair embeddings. The\npackage combines a domain specific language for vector arithmetic with\nvisualisation tools that make exploring word embeddings more intuitive and\nconcise. It offers support for many popular dimensionality reduction techniques\nas well as many interactive visualisations that can either be statically\nexported or shared via Jupyter notebooks. The project documentation is\navailable from https://rasahq.github.io/whatlies/.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 11:17:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Warmerdam", "Vincent D.", ""], ["Kober", "Thomas", ""], ["Tatman", "Rachael", ""]]}, {"id": "2009.02146", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona and Kenza Hamidouche and Mathieu Lauri\\`ere and Zongjun\n  Tan", "title": "Policy Optimization for Linear-Quadratic Zero-Sum Mean-Field Type Games", "comments": "arXiv admin note: text overlap with arXiv:2009.00578", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, zero-sum mean-field type games (ZSMFTG) with linear dynamics\nand quadratic utility are studied under infinite-horizon discounted utility\nfunction. ZSMFTG are a class of games in which two decision makers whose\nutilities sum to zero, compete to influence a large population of agents. In\nparticular, the case in which the transition and utility functions depend on\nthe state, the action of the controllers, and the mean of the state and the\nactions, is investigated. The game is analyzed and explicit expressions for the\nNash equilibrium strategies are derived. Moreover, two policy optimization\nmethods that rely on policy gradient are proposed for both model-based and\nsample-based frameworks. In the first case, the gradients are computed exactly\nusing the model whereas they are estimated using Monte-Carlo simulations in the\nsecond case. Numerical experiments show the convergence of the two players'\ncontrols as well as the utility function when the two algorithms are used in\ndifferent scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:49:08 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Hamidouche", "Kenza", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Tan", "Zongjun", ""]]}, {"id": "2009.02147", "submitter": "Yichao Wang", "authors": "Yichao Wang, Huifeng Guo, Ruiming Tang, Zhirong Liu, Xiuqiang He", "title": "A Practical Incremental Method to Train Deep CTR Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models in recommender systems are usually trained in the batch\nmode, namely iteratively trained on a fixed-size window of training data. Such\nbatch mode training of deep learning models suffers from low training\nefficiency, which may lead to performance degradation when the model is not\nproduced on time. To tackle this issue, incremental learning is proposed and\nhas received much attention recently. Incremental learning has great potential\nin recommender systems, as two consecutive window of training data overlap most\nof the volume. It aims to update the model incrementally with only the newly\nincoming samples from the timestamp when the model is updated last time, which\nis much more efficient than the batch mode training. However, most of the\nincremental learning methods focus on the research area of image recognition\nwhere new tasks or classes are learned over time. In this work, we introduce a\npractical incremental method to train deep CTR models, which consists of three\ndecoupled modules (namely, data, feature and model module). Our method can\nachieve comparable performance to the conventional batch mode training with\nmuch better training efficiency. We conduct extensive experiments on a public\nbenchmark and a private dataset to demonstrate the effectiveness of our\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:35:42 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wang", "Yichao", ""], ["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Liu", "Zhirong", ""], ["He", "Xiuqiang", ""]]}, {"id": "2009.02165", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Kei Uchizawa", "title": "A Generalization of Spatial Monte Carlo Integration", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01365", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial Monte Carlo integration (SMCI) is an extension of standard Monte\nCarlo integration and can approximate expectations on Markov random fields with\nhigh accuracy. SMCI was applied to pairwise Boltzmann machine (PBM) learning,\nwith superior results to those from some existing methods. The approximation\nlevel of SMCI can be changed, and it was proved that a higher-order\napproximation of SMCI is statistically more accurate than a lower-order\napproximation. However, SMCI as proposed in the previous studies suffers from a\nlimitation that prevents the application of a higher-order method to dense\nsystems.\n  This study makes two different contributions as follows. A generalization of\nSMCI (called generalized SMCI (GSMCI)) is proposed, which allows relaxation of\nthe above-mentioned limitation; moreover, a statistical accuracy bound of GSMCI\nis proved. This is the first contribution of this study. A new PBM learning\nmethod based on SMCI is proposed, which is obtained by combining SMCI and the\npersistent contrastive divergence. The proposed learning method greatly\nimproves the accuracy of learning. This is the second contribution of this\nstudy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:02:58 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 01:02:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Yasuda", "Muneki", ""], ["Uchizawa", "Kei", ""]]}, {"id": "2009.02183", "submitter": "Giacomo Nannicini", "authors": "Giacomo Nannicini", "title": "On the implementation of a global optimization method for mixed-variable\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the optimization algorithm implemented in the open-source\nderivative-free solver RBFOpt. The algorithm is based on the radial basis\nfunction method of Gutmann and the metric stochastic response surface method of\nRegis and Shoemaker. We propose several modifications aimed at generalizing and\nimproving these two algorithms: (i) the use of an extended space to represent\ncategorical variables in unary encoding; (ii) a refinement phase to locally\nimprove a candidate solution; (iii) interpolation models without the\nunisolvence condition, to both help deal with categorical variables, and\ninitiate the optimization before a uniquely determined model is possible; (iv)\na master-worker framework to allow asynchronous objective function evaluations\nin parallel. Numerical experiments show the effectiveness of these ideas.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:36:56 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 14:37:55 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 03:27:05 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 23:27:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Nannicini", "Giacomo", ""]]}, {"id": "2009.02186", "submitter": "Shreshth Tuli", "authors": "Shreshth Tuli, Shashikant Ilager, Kotagiri Ramamohanarao and Rajkumar\n  Buyya", "title": "Dynamic Scheduling for Stochastic Edge-Cloud Computing Environments\n  using A3C learning and Residual Recurrent Neural Networks", "comments": "Accepted in IEEE Transaction on Mobile Computing", "journal-ref": null, "doi": "10.1109/TMC.2020.3017079", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ubiquitous adoption of Internet-of-Things (IoT) based applications has\nresulted in the emergence of the Fog computing paradigm, which allows\nseamlessly harnessing both mobile-edge and cloud resources. Efficient\nscheduling of application tasks in such environments is challenging due to\nconstrained resource capabilities, mobility factors in IoT, resource\nheterogeneity, network hierarchy, and stochastic behaviors. xisting heuristics\nand Reinforcement Learning based approaches lack generalizability and quick\nadaptability, thus failing to tackle this problem optimally. They are also\nunable to utilize the temporal workload patterns and are suitable only for\ncentralized setups. However, Asynchronous-Advantage-Actor-Critic (A3C) learning\nis known to quickly adapt to dynamic scenarios with less data and Residual\nRecurrent Neural Network (R2N2) to quickly update model parameters. Thus, we\npropose an A3C based real-time scheduler for stochastic Edge-Cloud environments\nallowing decentralized learning, concurrently across multiple agents. We use\nthe R2N2 architecture to capture a large number of host and task parameters\ntogether with temporal patterns to provide efficient scheduling decisions. The\nproposed model is adaptive and able to tune different hyper-parameters based on\nthe application requirements. We explicate our choice of hyper-parameters\nthrough sensitivity analysis. The experiments conducted on real-world data set\nshow a significant improvement in terms of energy consumption, response time,\nService-Level-Agreement and running cost by 14.4%, 7.74%, 31.9%, and 4.64%,\nrespectively when compared to the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:36:34 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Tuli", "Shreshth", ""], ["Ilager", "Shashikant", ""], ["Ramamohanarao", "Kotagiri", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "2009.02188", "submitter": "Mohamed Ghalwash", "authors": "Mohamed Ghalwash, Zijun Yao, Prithwish Chakraborty, James Codella,\n  Daby Sow", "title": "Phenotypical Ontology Driven Framework for Multi-Task Learning", "comments": "To be appear on ACM CHIL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the large number of patients in Electronic Health Records (EHRs), the\nsubset of usable data for modeling outcomes of specific phenotypes are often\nimbalanced and of modest size. This can be attributed to the uneven coverage of\nmedical concepts in EHRs. In this paper, we propose OMTL, an Ontology-driven\nMulti-Task Learning framework, that is designed to overcome such data\nlimitations. The key contribution of our work is the effective use of knowledge\nfrom a predefined well-established medical relationship graph (ontology) to\nconstruct a novel deep learning network architecture that mirrors this\nontology. It can effectively leverage knowledge from a well-established medical\nrelationship graph (ontology) by constructing a deep learning network\narchitecture that mirrors this graph. This enables common representations to be\nshared across related phenotypes, and was found to improve the learning\nperformance. The proposed OMTL naturally allows for multitask learning of\ndifferent phenotypes on distinct predictive tasks. These phenotypes are tied\ntogether by their semantic distance according to the external medical ontology.\nUsing the publicly available MIMIC-III database, we evaluate OMTL and\ndemonstrate its efficacy on several real patient outcome predictions over\nstate-of-the-art multi-task learning schemes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:46:07 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Ghalwash", "Mohamed", ""], ["Yao", "Zijun", ""], ["Chakraborty", "Prithwish", ""], ["Codella", "James", ""], ["Sow", "Daby", ""]]}, {"id": "2009.02191", "submitter": "Jae Hyun Park", "authors": "Jae Hyun Park, Ji Sub Choi, Jong Hwan Ko", "title": "Dual Precision Deep Neural Network", "comments": "5 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-line Precision scalability of the deep neural networks(DNNs) is a critical\nfeature to support accuracy and complexity trade-off during the DNN inference.\nIn this paper, we propose dual-precision DNN that includes two different\nprecision modes in a single model, thereby supporting an on-line precision\nswitch without re-training. The proposed two-phase training process optimizes\nboth low- and high-precision modes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 02:56:51 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Park", "Jae Hyun", ""], ["Choi", "Ji Sub", ""], ["Ko", "Jong Hwan", ""]]}, {"id": "2009.02194", "submitter": "Georgios Pilikos", "authors": "Georgios Pilikos, Lars Horchens, Kees Joost Batenburg, Tristan van\n  Leeuwen, Felix Lucka", "title": "Fast ultrasonic imaging using end-to-end deep learning", "comments": "IEEE International Ultrasonics Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasonic imaging algorithms used in many clinical and industrial\napplications consist of three steps: A data pre-processing, an image formation\nand an image post-processing step. For efficiency, image formation often relies\non an approximation of the underlying wave physics. A prominent example is the\nDelay-And-Sum (DAS) algorithm used in reflectivity-based ultrasonic imaging.\nRecently, deep neural networks (DNNs) are being used for the data\npre-processing and the image post-processing steps separately. In this work, we\npropose a novel deep learning architecture that integrates all three steps to\nenable end-to-end training. We examine turning the DAS image formation method\ninto a network layer that connects data pre-processing layers with image\npost-processing layers that perform segmentation. We demonstrate that this\nintegrated approach clearly outperforms sequential approaches that are trained\nseparately. While network training and evaluation is performed only on\nsimulated data, we also showcase the potential of our approach on real data\nfrom a non-destructive testing scenario.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:53:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Pilikos", "Georgios", ""], ["Horchens", "Lars", ""], ["Batenburg", "Kees Joost", ""], ["van Leeuwen", "Tristan", ""], ["Lucka", "Felix", ""]]}, {"id": "2009.02207", "submitter": "Huy Nguyen", "authors": "Niklas Smedemark-Margulies and Paul Langton and Huy L. Nguyen", "title": "Fair and Useful Cohort Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As important decisions about the distribution of society's resources become\nincreasingly automated, it is essential to consider the measurement and\nenforcement of fairness in these decisions. In this work we build on the\nresults of Dwork and Ilvento ITCS'19, which laid the foundations for the study\nof fair algorithms under composition. In particular, we study the cohort\nselection problem, where we wish to use a fair classifier to select $k$\ncandidates from an arbitrarily ordered set of size $n>k$, while preserving\nindividual fairness and maximizing utility. We define a linear utility function\nto measure performance relative to the behavior of the original classifier. We\ndevelop a fair, utility-optimal $O(n)$-time cohort selection algorithm for the\noffline setting, and our primary result, a solution to the problem in the\nstreaming setting that keeps no more than $O(k)$ pending candidates at all\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 14:06:08 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Smedemark-Margulies", "Niklas", ""], ["Langton", "Paul", ""], ["Nguyen", "Huy L.", ""]]}, {"id": "2009.02216", "submitter": "Noa Fish", "authors": "Noa Fish, Lilach Perry, Amit Bermano, Daniel Cohen-Or", "title": "SketchPatch: Sketch Stylization via Seamless Patch-level Synthesis", "comments": "SIGGRAPH Asia 2020", "journal-ref": null, "doi": "10.1145/3414685.3417816", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of image-to-image translation is leveraged for the benefit of\nsketch stylization via transfer of geometric textural details. Lacking the\nnecessary volumes of data for standard training of translation systems, we\nadvocate for operation at the patch level, where a handful of stylized sketches\nprovide ample mining potential for patches featuring basic geometric\nprimitives. Operating at the patch level necessitates special consideration of\nfull sketch translation, as individual translation of patches with no regard to\nneighbors is likely to produce visible seams and artifacts at patch borders.\nAligned pairs of styled and plain primitives are combined to form input hybrids\ncontaining styled elements around the border and plain elements within, and\ngiven as input to a seamless translation (ST) generator, whose output patches\nare expected to reconstruct the fully styled patch. An adversarial addition\npromotes generalization and robustness to diverse geometries at inference time,\nforming a simple and effective system for arbitrary sketch stylization, as\ndemonstrated upon a variety of styles and sketches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 14:20:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Fish", "Noa", ""], ["Perry", "Lilach", ""], ["Bermano", "Amit", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2009.02251", "submitter": "Xiangyun Ding", "authors": "Xiangyun Ding, Wenjian Yu, Yuyang Xie, Shenghua Liu", "title": "Efficient Model-Based Collaborative Filtering with Fast Adaptive PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model-based collaborative filtering (CF) approach utilizing fast adaptive\nrandomized singular value decomposition (SVD) is proposed for the matrix\ncompletion problem in recommender system. Firstly, a fast adaptive PCA\nframeworkis presented which combines the fixed-precision randomized matrix\nfactorization algorithm [1] and accelerating skills for handling large sparse\ndata. Then, a novel termination mechanism for the adaptive PCA is proposed to\nautomatically determine a number of latent factors for achieving the near\noptimal prediction accuracy during the subsequent model-based CF. The resulted\nCF approach has good accuracy while inheriting high runtime efficiency.\nExperiments on real data show that, the proposed adaptive PCA is up to 2.7X and\n6.7X faster than the original fixed-precision SVD approach [1] and svds in\nMatlab repsectively, while preserving accuracy. The proposed model-based CF\napproach is able to efficiently process the MovieLens data with 20M ratings and\nexhibits more than 10X speedup over the regularized matrix factorization based\napproach [2] and the fast singular value thresholding approach [3] with\ncomparable or better accuracy. It also owns the advantage of parameter free.\nCompared with the deep-learning-based CF approach, the proposed approach is\nmuch more computationally efficient, with just marginal performance loss.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:32:14 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Ding", "Xiangyun", ""], ["Yu", "Wenjian", ""], ["Xie", "Yuyang", ""], ["Liu", "Shenghua", ""]]}, {"id": "2009.02252", "submitter": "Fabio Petroni", "authors": "Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid\n  Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin,\n  Jean Maillard, Vassilis Plachouras, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "KILT: a Benchmark for Knowledge Intensive Language Tasks", "comments": "accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging problems such as open-domain question answering, fact checking,\nslot filling and entity linking require access to large, external knowledge\nsources. While some models do well on individual tasks, developing general\nmodels is difficult as each task might require computationally expensive\nindexing of custom knowledge sources, in addition to dedicated infrastructure.\nTo catalyze research on models that condition on specific information in large\ntextual resources, we present a benchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia,\nreducing engineering turnaround through the re-use of components, as well as\naccelerating research into task-agnostic memory architectures. We test both\ntask-specific and general baselines, evaluating downstream performance in\naddition to the ability of the models to provide provenance. We find that a\nshared dense vector index coupled with a seq2seq model is a strong baseline,\noutperforming more tailor-made approaches for fact checking, open-domain\nquestion answering and dialogue, and yielding competitive results on entity\nlinking and slot filling, by generating disambiguated text. KILT data and code\nare available at https://github.com/facebookresearch/KILT.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:32:19 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 08:59:41 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 09:27:43 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 15:20:59 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Petroni", "Fabio", ""], ["Piktus", "Aleksandra", ""], ["Fan", "Angela", ""], ["Lewis", "Patrick", ""], ["Yazdani", "Majid", ""], ["De Cao", "Nicola", ""], ["Thorne", "James", ""], ["Jernite", "Yacine", ""], ["Karpukhin", "Vladimir", ""], ["Maillard", "Jean", ""], ["Plachouras", "Vassilis", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2009.02256", "submitter": "Wei Xu", "authors": "Xinyi Huang, Suphanut Jamonnak, Ye Zhao, Boyu Wang, Minh Hoai, Kevin\n  Yager, Wei Xu", "title": "Interactive Visual Study of Multiple Attributes Learning Model of X-Ray\n  Scattering Images", "comments": "IEEE SciVis Conference 2020", "journal-ref": "IEEE Transactions on Visualization & Computer Graphics 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing interactive visualization tools for deep learning are mostly applied\nto the training, debugging, and refinement of neural network models working on\nnatural images. However, visual analytics tools are lacking for the specific\napplication of x-ray image classification with multiple structural attributes.\nIn this paper, we present an interactive system for domain scientists to\nvisually study the multiple attributes learning models applied to x-ray\nscattering images. It allows domain scientists to interactively explore this\nimportant type of scientific images in embedded spaces that are defined on the\nmodel prediction output, the actual labels, and the discovered feature space of\nneural networks. Users are allowed to flexibly select instance images, their\nclusters, and compare them regarding the specified visual representation of\nattributes. The exploration is guided by the manifestation of model performance\nrelated to mutual relationships among attributes, which often affect the\nlearning accuracy and effectiveness. The system thus supports domain scientists\nto improve the training dataset and model, find questionable attributes labels,\nand identify outlier images or spurious data clusters. Case studies and\nscientists feedback demonstrate its functionalities and usefulness.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 00:38:45 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Huang", "Xinyi", ""], ["Jamonnak", "Suphanut", ""], ["Zhao", "Ye", ""], ["Wang", "Boyu", ""], ["Hoai", "Minh", ""], ["Yager", "Kevin", ""], ["Xu", "Wei", ""]]}, {"id": "2009.02258", "submitter": "Tiemo Bang", "authors": "Tiemo Bang (Technical University Darmstadt and SAP SE), Norman May\n  (SAP SE), Ilia Petrov (Reutlingen University), Carsten Binnig (Technical\n  University Darmstadt)", "title": "AnyDB: An Architecture-less DBMS for Any Workload", "comments": "Submitted to 11th Annual Conference on Innovative Data Systems\n  Research (CIDR 21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a radical new approach for scale-out distributed\nDBMSs. Instead of hard-baking an architectural model, such as a shared-nothing\narchitecture, into the distributed DBMS design, we aim for a new class of\nso-called architecture-less DBMSs. The main idea is that an architecture-less\nDBMS can mimic any architecture on a per-query basis on-the-fly without any\nadditional overhead for reconfiguration. Our initial results show that our\narchitecture-less DBMS AnyDB can provide significant speed-ups across varying\nworkloads compared to a traditional DBMS implementing a static architecture.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:38:27 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Bang", "Tiemo", "", "Technical University Darmstadt and SAP SE"], ["May", "Norman", "", "SAP SE"], ["Petrov", "Ilia", "", "Reutlingen University"], ["Binnig", "Carsten", "", "Technical\n  University Darmstadt"]]}, {"id": "2009.02267", "submitter": "Yongxin Liu", "authors": "Yongxin Liu, Jian Wang, Jianqiang Li, Houbing Song, Thomas Yang,\n  Shuteng Niu, Zhong Ming", "title": "Zero-Bias Deep Learning for Accurate Identification of Internet of\n  Things (IoT) Devices", "comments": "Accepted for publication by IEEE IoTJ on August, 2020. Data and codes\n  are hosted at: [1] Yongxin Liu, Jian Wang, Houbing Song, Shuteng Niu, Thomas\n  Yang, \"A 24-hour signal recording dataset with labels for cybersecurity and\n  IoT\", IEEE Dataport, 2020. [Online]. Available:\n  http://dx.doi.org/10.21227/gt9v-kz32. Accessed: Aug. 27, 2020", "journal-ref": "IEEE Internet of Things Journal, 2020", "doi": "10.1109/JIOT.2020.3018677", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) provides applications and services that would\notherwise not be possible. However, the open nature of IoT make it vulnerable\nto cybersecurity threats. Especially, identity spoofing attacks, where an\nadversary passively listens to existing radio communications and then mimic the\nidentity of legitimate devices to conduct malicious activities. Existing\nsolutions employ cryptographic signatures to verify the trustworthiness of\nreceived information. In prevalent IoT, secret keys for cryptography can\npotentially be disclosed and disable the verification mechanism.\nNon-cryptographic device verification is needed to ensure trustworthy IoT. In\nthis paper, we propose an enhanced deep learning framework for IoT device\nidentification using physical layer signals. Specifically, we enable our\nframework to report unseen IoT devices and introduce the zero-bias layer to\ndeep neural networks to increase robustness and interpretability. We have\nevaluated the effectiveness of the proposed framework using real data from\nADS-B (Automatic Dependent Surveillance-Broadcast), an application of IoT in\naviation. The proposed framework has the potential to be applied to accurate\nidentification of IoT devices in a variety of IoT applications and services.\nCodes and data are available in IEEE Dataport.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 20:50:48 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Liu", "Yongxin", ""], ["Wang", "Jian", ""], ["Li", "Jianqiang", ""], ["Song", "Houbing", ""], ["Yang", "Thomas", ""], ["Niu", "Shuteng", ""], ["Ming", "Zhong", ""]]}, {"id": "2009.02276", "submitter": "Jonas Geiping", "authors": "Jonas Geiping, Liam Fowl, W. Ronny Huang, Wojciech Czaja, Gavin\n  Taylor, Michael Moeller, Tom Goldstein", "title": "Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching", "comments": "First two authors contributed equally. Last two authors contributed\n  equally. 21 pages, 11 figures. Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Poisoning attacks modify training data to maliciously control a model\ntrained on such data. In this work, we focus on targeted poisoning attacks\nwhich cause a reclassification of an unmodified test image and as such breach\nmodel integrity. We consider a particularly malicious poisoning attack that is\nboth \"from scratch\" and \"clean label\", meaning we analyze an attack that\nsuccessfully works against new, randomly initialized models, and is nearly\nimperceptible to humans, all while perturbing only a small fraction of the\ntraining data. Previous poisoning attacks against deep neural networks in this\nsetting have been limited in scope and success, working only in simplified\nsettings or being prohibitively expensive for large datasets. The central\nmechanism of the new attack is matching the gradient direction of malicious\nexamples. We analyze why this works, supplement with practical considerations.\nand show its threat to real-world practitioners, finding that it is the first\npoisoning method to cause targeted misclassification in modern deep networks\ntrained from scratch on a full-sized, poisoned ImageNet dataset. Finally we\ndemonstrate the limitations of existing defensive strategies against such an\nattack, concluding that data poisoning is a credible threat, even for\nlarge-scale deep learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 16:17:54 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 15:58:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Geiping", "Jonas", ""], ["Fowl", "Liam", ""], ["Huang", "W. Ronny", ""], ["Czaja", "Wojciech", ""], ["Taylor", "Gavin", ""], ["Moeller", "Michael", ""], ["Goldstein", "Tom", ""]]}, {"id": "2009.02285", "submitter": "Liwei Hu", "authors": "Liwei Hu, Wenyong Wang, Yu Xiang, Jun Zhang", "title": "Flow Field Reconstructions with GANs based on Radial Basis Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear sparse data regression and generation have been a long-term\nchallenge, to cite the flow field reconstruction as a typical example. The huge\ncomputational cost of computational fluid dynamics (CFD) makes it much\nexpensive for large scale CFD data producing, which is the reason why we need\nsome cheaper ways to do this, of which the traditional reduced order models\n(ROMs) were promising but they couldn't generate a large number of full domain\nflow field data (FFD) to realize high-precision flow field reconstructions.\nMotivated by the problems of existing approaches and inspired by the success of\nthe generative adversarial networks (GANs) in the field of computer vision, we\nprove an optimal discriminator theorem that the optimal discriminator of a GAN\nis a radial basis function neural network (RBFNN) while dealing with nonlinear\nsparse FFD regression and generation. Based on this theorem, two radial basis\nfunction-based GANs (RBF-GAN and RBFC-GAN), for regression and generation\npurposes, are proposed. Three different datasets are applied to verify the\nfeasibility of our models. The results show that the performance of the RBF-GAN\nand the RBFC-GAN are better than that of GANs/cGANs by means of both the mean\nsquare error (MSE) and the mean square percentage error (MSPE). Besides,\ncompared with GANs/cGANs, the stability of the RBF-GAN and the RBFC-GAN improve\nby 34.62% and 72.31%, respectively. Consequently, our proposed models can be\nused to generate full domain FFD from limited and sparse datasets, to meet the\nrequirement of high-precision flow field reconstructions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:45:57 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Hu", "Liwei", ""], ["Wang", "Wenyong", ""], ["Xiang", "Yu", ""], ["Zhang", "Jun", ""]]}, {"id": "2009.02286", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Vulnerability of Face Recognition Systems Against Composite Face\n  Reconstruction Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rounding confidence score is considered trivial but a simple and effective\ncountermeasure to stop gradient descent based image reconstruction attacks.\nHowever, its capability in the face of more sophisticated reconstruction\nattacks is an uninvestigated research area. In this paper, we prove that, the\nface reconstruction attacks based on composite faces can reveal the\ninefficiency of rounding policy as countermeasure. We assume that, the attacker\ntakes advantage of face composite parts which helps the attacker to get access\nto the most important features of the face or decompose it to the independent\nsegments. Afterwards, decomposed segments are exploited as search parameters to\ncreate a search path to reconstruct optimal face. Face composition parts enable\nthe attacker to violate the privacy of face recognition models even with a\nblind search. However, we assume that, the attacker may take advantage of\nrandom search to reconstruct the target face faster. The algorithm is started\nwith random composition of face parts as initial face and confidence score is\nconsidered as fitness value. Our experiments show that, since the rounding\npolicy as countermeasure can't stop the random search process, current face\nrecognition systems are extremely vulnerable against such sophisticated\nattacks. To address this problem, we successfully test Face Detection Score\nFiltering (FDSF) as a countermeasure to protect the privacy of training data\nagainst proposed attack.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 03:37:51 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "2009.02293", "submitter": "Georgios Pilikos", "authors": "Georgios Pilikos, Lars Horchens, Kees Joost Batenburg, Tristan van\n  Leeuwen, Felix Lucka", "title": "Deep data compression for approximate ultrasonic image formation", "comments": "IEEE International Ultrasonics Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many ultrasonic imaging systems, data acquisition and image formation are\nperformed on separate computing devices. Data transmission is becoming a\nbottleneck, thus, efficient data compression is essential. Compression rates\ncan be improved by considering the fact that many image formation methods rely\non approximations of wave-matter interactions, and only use the corresponding\npart of the data. Tailored data compression could exploit this, but extracting\nthe useful part of the data efficiently is not always trivial. In this work, we\ntackle this problem using deep neural networks, optimized to preserve the image\nquality of a particular image formation method. The Delay-And-Sum (DAS)\nalgorithm is examined which is used in reflectivity-based ultrasonic imaging.\nWe propose a novel encoder-decoder architecture with vector quantization and\nformulate image formation as a network layer for end-to-end training.\nExperiments demonstrate that our proposed data compression tailored for a\nspecific image formation method obtains significantly better results as opposed\nto compression agnostic to subsequent imaging. We maintain high image quality\nat much higher compression rates than the theoretical lossless compression rate\nderived from the rank of the linear imaging operator. This demonstrates the\ngreat potential of deep ultrasonic data compression tailored for a specific\nimage formation method.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 16:43:12 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Pilikos", "Georgios", ""], ["Horchens", "Lars", ""], ["Batenburg", "Kees Joost", ""], ["van Leeuwen", "Tristan", ""], ["Lucka", "Felix", ""]]}, {"id": "2009.02296", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Said Ouala, Lucas Drumetz and Ronan Fablet", "title": "Variational Deep Learning for the Identification and Reconstruction of\n  Chaotic and Stochastic Dynamical Systems from Noisy and Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-driven recovery of the unknown governing equations of dynamical\nsystems has recently received an increasing interest. However, the\nidentification of governing equations remains challenging when dealing with\nnoisy and partial observations. Here, we address this challenge and investigate\nvariational deep learning schemes. Within the proposed framework, we jointly\nlearn an inference model to reconstruct the true states of the system and the\ngoverning laws of these states from series of noisy and partial data. In doing\nso, this framework bridges classical data assimilation and state-of-the-art\nmachine learning techniques. We also demonstrate that it generalises\nstate-of-the-art methods. Importantly, both the inference model and the\ngoverning model embed stochastic components to account for stochastic\nvariabilities, model errors, and reconstruction uncertainties. Various\nexperiments on chaotic and stochastic dynamical systems support the relevance\nof our scheme w.r.t. state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 16:48:00 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 16:32:35 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 22:27:28 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 17:28:05 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 17:00:08 GMT"}, {"version": "v6", "created": "Tue, 16 Feb 2021 16:58:18 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Nguyen", "Duong", ""], ["Ouala", "Said", ""], ["Drumetz", "Lucas", ""], ["Fablet", "Ronan", ""]]}, {"id": "2009.02302", "submitter": "Austin Xu", "authors": "Austin Xu and Mark A. Davenport", "title": "Simultaneous Preference and Metric Learning from Paired Comparisons", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular model of preference in the context of recommendation systems is the\nso-called \\emph{ideal point} model. In this model, a user is represented as a\nvector $\\mathbf{u}$ together with a collection of items $\\mathbf{x_1}, \\ldots,\n\\mathbf{x_N}$ in a common low-dimensional space. The vector $\\mathbf{u}$\nrepresents the user's \"ideal point,\" or the ideal combination of features that\nrepresents a hypothesized most preferred item. The underlying assumption in\nthis model is that a smaller distance between $\\mathbf{u}$ and an item\n$\\mathbf{x_j}$ indicates a stronger preference for $\\mathbf{x_j}$. In the vast\nmajority of the existing work on learning ideal point models, the underlying\ndistance has been assumed to be Euclidean. However, this eliminates any\npossibility of interactions between features and a user's underlying\npreferences. In this paper, we consider the problem of learning an ideal point\nrepresentation of a user's preferences when the distance metric is an unknown\nMahalanobis metric. Specifically, we present a novel approach to estimate the\nuser's ideal point $\\mathbf{u}$ and the Mahalanobis metric from paired\ncomparisons of the form \"item $\\mathbf{x_i}$ is preferred to item\n$\\mathbf{x_j}$.\" This can be viewed as a special case of a more general metric\nlearning problem where the location of some points are unknown a priori. We\nconduct extensive experiments on synthetic and real-world datasets to exhibit\nthe effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 16:59:35 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 00:31:42 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Xu", "Austin", ""], ["Davenport", "Mark A.", ""]]}, {"id": "2009.02316", "submitter": "Toktam Khatibi", "authors": "Toktam Khatibi, Ali Farahani, Hossein Sarmadian", "title": "Proposing a two-step Decision Support System (TPIS) based on Stacked\n  ensemble classifier for early and low cost (step-1) and final (step-2)\n  differential diagnosis of Mycobacterium Tuberculosis from non-tuberculosis\n  Pneumonia", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Mycobacterium Tuberculosis (TB) is an infectious bacterial\ndisease presenting similar symptoms to pneumonia; therefore, differentiating\nbetween TB and pneumonia is challenging. Therefore, the main aim of this study\nis proposing an automatic method for differential diagnosis of TB from\nPneumonia. Methods: In this study, a two-step decision support system named\nTPIS is proposed for differential diagnosis of TB from pneumonia based on\nstacked ensemble classifiers. The first step of our proposed model aims at\nearly diagnosis based on low-cost features including demographic\ncharacteristics and patient symptoms (including 18 features). TPIS second step\nmakes the final decision based on the meta features extracted in the first\nstep, the laboratory tests and chest radiography reports. This retrospective\nstudy considers 199 patient medical records for patients suffering from TB or\npneumonia, which has been registered in a hospital in Arak, Iran. Results:\nExperimental results show that TPIS outperforms the compared machine learning\nmethods for early differential diagnosis of pulmonary tuberculosis from\npneumonia with AUC of 90.26 and accuracy of 91.37 and final decision making\nwith AUC of 92.81 and accuracy of 93.89. Conclusions: The main advantage of\nearly diagnosis is beginning the treatment procedure for confidently diagnosed\npatients as soon as possible and preventing latency in treatment. Therefore,\nearly diagnosis reduces the maturation of late treatment of both diseases.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 17:47:41 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Khatibi", "Toktam", ""], ["Farahani", "Ali", ""], ["Sarmadian", "Hossein", ""]]}, {"id": "2009.02326", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi, Mohammad Samragh, Gregory Fields, Tara Javidi,\n  Farinaz Koushanfar", "title": "CLEANN: Accelerated Trojan Shield for Embedded Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3400302.3415671", "report-no": null, "categories": "cs.LG cs.AR cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose CLEANN, the first end-to-end framework that enables online\nmitigation of Trojans for embedded Deep Neural Network (DNN) applications. A\nTrojan attack works by injecting a backdoor in the DNN while training; during\ninference, the Trojan can be activated by the specific backdoor trigger. What\ndifferentiates CLEANN from the prior work is its lightweight methodology which\nrecovers the ground-truth class of Trojan samples without the need for labeled\ndata, model retraining, or prior assumptions on the trigger or the attack. We\nleverage dictionary learning and sparse approximation to characterize the\nstatistical behavior of benign data and identify Trojan triggers. CLEANN is\ndevised based on algorithm/hardware co-design and is equipped with specialized\nhardware to enable efficient real-time execution on resource-constrained\nembedded platforms. Proof of concept evaluations on CLEANN for the\nstate-of-the-art Neural Trojan attacks on visual benchmarks demonstrate its\ncompetitive advantage in terms of attack resiliency and execution overhead.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 05:29:38 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Samragh", "Mohammad", ""], ["Fields", "Gregory", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2009.02327", "submitter": "Haijun Yu", "authors": "Haijun Yu, Xinyuan Tian, Weinan E and Qianxiao Li", "title": "OnsagerNet: Learning Stable and Interpretable Dynamics using a\n  Generalized Onsager Principle", "comments": "37 pages, 17 figures", "journal-ref": null, "doi": "10.1017/S1743921320000629", "report-no": null, "categories": "math.DS cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a systematic method for learning stable and interpretable\ndynamical models using sampled trajectory data from physical processes based on\na generalized Onsager principle. The learned dynamics are autonomous ordinary\ndifferential equations parameterized by neural networks that retain clear\nphysical structure information, such as free energy, dissipation, conservative\ninteraction and external force. The neural network representations for the\nhidden dynamics are trained by minimizing the empirical risk based on an\nembedded Runge-Kutta method. For high dimensional problems with a low\ndimensional slow manifold, an autoencoder with isometric regularization is\nintroduced to find generalized coordinates on which we learn the Onsager\ndynamics. We apply the method to learn reduced order models for the\nRayleigh-B\\'{e}nard convection problem, where we obtain low dimensional\nautonomous equations that capture both qualitative and quantitative properties\nof the underlying dynamics. In particular, this validates the basic approach of\nLorenz, although we also discover that the dimension of the learned autonomous\nmodel required for faithful representation increases with the Rayleigh number.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 07:30:59 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 00:40:52 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yu", "Haijun", ""], ["Tian", "Xinyuan", ""], ["E", "Weinan", ""], ["Li", "Qianxiao", ""]]}, {"id": "2009.02365", "submitter": "Yuzhou Chen", "authors": "Yuzhou Chen, Yulia R. Gel, Konstantin Avrachenkov", "title": "LFGCN: Levitating over Graphs with Levy Flights", "comments": "To Appear in the 2020 IEEE International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to high utility in many applications, from social networks to blockchain\nto power grids, deep learning on non-Euclidean objects such as graphs and\nmanifolds, coined Geometric Deep Learning (GDL), continues to gain an ever\nincreasing interest. We propose a new L\\'evy Flights Graph Convolutional\nNetworks (LFGCN) method for semi-supervised learning, which casts the L\\'evy\nFlights into random walks on graphs and, as a result, allows both to accurately\naccount for the intrinsic graph topology and to substantially improve\nclassification performance, especially for heterogeneous graphs. Furthermore,\nwe propose a new preferential P-DropEdge method based on the Girvan-Newman\nargument. That is, in contrast to uniform removing of edges as in DropEdge,\nfollowing the Girvan-Newman algorithm, we detect network periphery structures\nusing information on edge betweenness and then remove edges according to their\nbetweenness centrality. Our experimental results on semi-supervised node\nclassification tasks demonstrate that the LFGCN coupled with P-DropEdge\naccelerates the training task, increases stability and further improves\npredictive accuracy of learned graph topology structure. Finally, in our case\nstudies we bring the machinery of LFGCN and other deep networks tools to\nanalysis of power grid networks - the area where the utility of GDL remains\nuntapped.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 19:13:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Chen", "Yuzhou", ""], ["Gel", "Yulia R.", ""], ["Avrachenkov", "Konstantin", ""]]}, {"id": "2009.02381", "submitter": "Zhi-Gang Liu", "authors": "Zhi-Gang Liu, Paul N. Whatmough, and Matthew Mattina", "title": "Sparse Systolic Tensor Array for Efficient CNN Hardware Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) inference on mobile devices demands\nefficient hardware acceleration of low-precision (INT8) general matrix\nmultiplication (GEMM). Exploiting data sparsity is a common approach to further\naccelerate GEMM for CNN inference, and in particular, structural sparsity has\nthe advantages of predictable load balancing and very low index overhead. In\nthis paper, we address a key architectural challenge with structural sparsity:\nhow to provide support for a range of sparsity levels while maintaining high\nutilization of the hardware. We describe a time unrolled formulation of\nvariable density-bound block (VDBB) sparsity that allows for a configurable\nnumber of non-zero elements per block, at constant utilization. We then\ndescribe a systolic array microarchitecture that implements this scheme, with\ntwo data reuse optimizations. Firstly, we increase reuse in both operands and\npartial products by increasing the number of MACs per PE. Secondly, we\nintroduce a novel approach of moving the IM2COL transform into the hardware,\nwhich allows us to achieve a 3x data bandwidth expansion just before the\noperands are consumed by the datapath, reducing the SRAM power consumption. The\noptimizations for weight sparsity, activation sparsity and data reuse are all\ninterrelated and therefore the optimal combination is not obvious. Therefore,\nwe perform an design space evaluation to find the pareto-optimal design\ncharacteristics. The resulting design achieves 16.8 TOPS/W in 16nm with modest\n50% model sparsity and scales with model sparsity up to 55.7TOPS/W at 87.5%. As\nwell as successfully demonstrating the variable DBB technique, this result\nsignificantly outperforms previously reported sparse CNN accelerators.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:17:42 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 21:43:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Liu", "Zhi-Gang", ""], ["Whatmough", "Paul N.", ""], ["Mattina", "Matthew", ""]]}, {"id": "2009.02383", "submitter": "Bonifaz Stuhr", "authors": "Bonifaz Stuhr, J\\\"urgen Brauer", "title": "Don't miss the Mismatch: Investigating the Objective Function Mismatch\n  for Unsupervised Representation Learning", "comments": "21 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding general evaluation metrics for unsupervised representation learning\ntechniques is a challenging open research question, which recently has become\nmore and more necessary due to the increasing interest in unsupervised methods.\nEven though these methods promise beneficial representation characteristics,\nmost approaches currently suffer from the objective function mismatch. This\nmismatch states that the performance on a desired target task can decrease when\nthe unsupervised pretext task is learned too long - especially when both tasks\nare ill-posed. In this work, we build upon the widely used linear evaluation\nprotocol and define new general evaluation metrics to quantitatively capture\nthe objective function mismatch and the more generic metrics mismatch. We\ndiscuss the usability and stability of our protocols on a variety of pretext\nand target tasks and study mismatches in a wide range of experiments. Thereby\nwe disclose dependencies of the objective function mismatch across several\npretext and target tasks with respect to the pretext model's representation\nsize, target model complexity, pretext and target augmentations as well as\npretext and target task types.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:21:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Stuhr", "Bonifaz", ""], ["Brauer", "J\u00fcrgen", ""]]}, {"id": "2009.02386", "submitter": "Ze Wang", "authors": "Ze Wang, Xiuyuan Cheng, Guillermo Sapiro, Qiang Qiu", "title": "ACDC: Weight Sharing in Atom-Coefficient Decomposed Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are known to be significantly\nover-parametrized, and difficult to interpret, train and adapt. In this paper,\nwe introduce a structural regularization across convolutional kernels in a CNN.\nIn our approach, each convolution kernel is first decomposed as 2D dictionary\natoms linearly combined by coefficients. The widely observed correlation and\nredundancy in a CNN hint a common low-rank structure among the decomposed\ncoefficients, which is here further supported by our empirical observations. We\nthen explicitly regularize CNN kernels by enforcing decomposed coefficients to\nbe shared across sub-structures, while leaving each sub-structure only its own\ndictionary atoms, a few hundreds of parameters typically, which leads to\ndramatic model reductions. We explore models with sharing across different\nsub-structures to cover a wide range of trade-offs between parameter reduction\nand expressiveness. Our proposed regularized network structures open the door\nto better interpreting, training and adapting deep models. We validate the\nflexibility and compatibility of our method by image classification experiments\non multiple datasets and underlying network structures, and show that CNNs now\nmaintain performance with dramatic reduction in parameters and computations,\ne.g., only 5\\% parameters are used in a ResNet-18 to achieve comparable\nperformance. Further experiments on few-shot classification show that faster\nand more robust task adaptation is obtained in comparison with models with\nstandard convolutions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:41:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Ze", ""], ["Cheng", "Xiuyuan", ""], ["Sapiro", "Guillermo", ""], ["Qiu", "Qiang", ""]]}, {"id": "2009.02388", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich", "title": "On Communication Compression for Distributed Optimization on\n  Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy gradient compression, with either unbiased or biased compressors, has\nbecome a key tool to avoid the communication bottleneck in centrally\ncoordinated distributed training of machine learning models. We analyze the\nperformance of two standard and general types of methods: (i) distributed\nquantized SGD (D-QSGD) with arbitrary unbiased quantizers and (ii) distributed\nSGD with error-feedback and biased compressors (D-EF-SGD) in the heterogeneous\n(non-iid) data setting. Our results indicate that D-EF-SGD is much less\naffected than D-QSGD by non-iid data, but both methods can suffer a slowdown if\ndata-skewness is high. We further study two alternatives that are not (or much\nless) affected by heterogenous data distributions: first, a recently proposed\nmethod that is effective on strongly convex problems, and secondly, we point\nout a more general approach that is applicable to linear compressors only but\neffective in all considered scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:48:08 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 09:41:09 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Stich", "Sebastian U.", ""]]}, {"id": "2009.02391", "submitter": "Recep Yusuf Bekci", "authors": "Recep Yusuf Bekci, Mehmet G\\\"um\\\"u\\c{s}", "title": "Visualizing the Loss Landscape of Actor Critic Methods with Applications\n  in Inventory Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous control is a widely applicable area of reinforcement learning. The\nmain players of this area are actor-critic methods that utilize policy\ngradients of neural approximators as a common practice. The focus of our study\nis to show the characteristics of the actor loss function which is the\nessential part of the optimization. We exploit low dimensional visualizations\nof the loss function and provide comparisons for loss landscapes of various\nalgorithms. Furthermore, we apply our approach to multi-store dynamic inventory\ncontrol, a notoriously difficult problem in supply chain operations, and\nexplore the shape of the loss function associated with the optimal policy. We\nmodelled and solved the problem using reinforcement learning while having a\nloss landscape in favor of optimality.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:52:05 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bekci", "Recep Yusuf", ""], ["G\u00fcm\u00fc\u015f", "Mehmet", ""]]}, {"id": "2009.02397", "submitter": "Javad Rahimipour Anaraki", "authors": "Javad Rahimipour Anaraki, Silvia Orlandi, Tom Chau", "title": "A Deep Learning Approach to Tongue Detection for Pediatric Population", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children with severe disabilities and complex communication needs face\nlimitations in the usage of access technology (AT) devices. Conventional ATs\n(e.g., mechanical switches) can be insufficient for nonverbal children and\nthose with limited voluntary motion control. Automatic techniques for the\ndetection of tongue gestures represent a promising pathway. Previous studies\nhave shown the robustness of tongue detection algorithms on adult participants,\nbut further research is needed to use these methods with children. In this\nstudy, a network architecture for tongue-out gesture recognition was\nimplemented and evaluated on videos recorded in a naturalistic setting when\nchildren were playing a video-game. A cascade object detector algorithm was\nused to detect the participants' faces, and an automated classification scheme\nfor tongue gesture detection was developed using a convolutional neural network\n(CNN). In evaluation experiments conducted, the network was trained using\nadults and children's images. The network classification accuracy was evaluated\nusing leave-one-subject-out cross-validation. Preliminary classification\nresults obtained from the analysis of videos of five typically developing\nchildren showed an accuracy of up to 99% in predicting tongue-out gestures.\nMoreover, we demonstrated that using only children data for training the\nclassifier yielded better performance than adult's one supporting the need for\npediatric tongue gesture datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 21:04:57 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 22:41:39 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 19:43:29 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Anaraki", "Javad Rahimipour", ""], ["Orlandi", "Silvia", ""], ["Chau", "Tom", ""]]}, {"id": "2009.02400", "submitter": "Pablo Andretta Jaskowiak", "authors": "Pablo Andretta Jaskowiak, Ivan Gesteira Costa, Ricardo Jos\\'e\n  Gabrielli Barreto Campello", "title": "The Area Under the ROC Curve as a Measure of Clustering Quality", "comments": "37 pages, 5 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Area Under the the Receiver Operating Characteristics (ROC) Curve,\nreferred to as AUC, is a well-known performance measure in the supervised\nlearning domain. Due to its compelling features, it has been employed in a\nnumber of studies to evaluate and compare the performance of different\nclassifiers. In this work, we explore AUC as a performance measure in the\nunsupervised learning domain, more specifically, in the context of cluster\nanalysis. In particular, we elaborate on the use of AUC as an internal/relative\nmeasure of clustering quality, which we refer to as Area Under the Curve for\nClustering (AUCC). We show that the AUCC of a given candidate clustering\nsolution has an expected value under a null model of random clustering\nsolutions, regardless of the size of the dataset and, more importantly,\nregardless of the number or the (im)balance of clusters under evaluation. In\naddition, we demonstrate that, in the context of internal/relative clustering\nvalidation, AUCC is actually a linear transformation of the Gamma criterion\nfrom Baker and Hubert (1975), for which we also formally derive a theoretical\nexpected value for chance clusterings. We also discuss the computational\ncomplexity of these criteria and show that, while an ordinary implementation of\nGamma can be computationally prohibitive and impractical for most real\napplications of cluster analysis, its equivalence with AUCC actually unveils a\ncomputationally much more efficient and practical algorithmic procedure. Our\ntheoretical findings are supported by experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 21:34:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Jaskowiak", "Pablo Andretta", ""], ["Costa", "Ivan Gesteira", ""], ["Campello", "Ricardo Jos\u00e9 Gabrielli Barreto", ""]]}, {"id": "2009.02406", "submitter": "Xinli Yu T", "authors": "Xinli Yu, Mohsen Malmir, Cynthia He, Yue Liu, Rex Wu", "title": "Video Moment Retrieval via Natural Language Queries", "comments": "needs internal approval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for video moment retrieval (VMR)\nthat achieves state of the arts (SOTA) performance on R@1 metrics and\nsurpassing the SOTA on the high IoU metric (R@1, IoU=0.7).\n  First, we propose to use a multi-head self-attention mechanism, and further a\ncross-attention scheme to capture video/query interaction and long-range query\ndependencies from video context. The attention-based methods can develop\nframe-to-query interaction and query-to-frame interaction at arbitrary\npositions and the multi-head setting ensures the sufficient understanding of\ncomplicated dependencies. Our model has a simple architecture, which enables\nfaster training and inference while maintaining .\n  Second, We also propose to use multiple task training objective consists of\nmoment segmentation task, start/end distribution prediction and start/end\nlocation regression task. We have verified that start/end prediction are noisy\ndue to annotator disagreement and joint training with moment segmentation task\ncan provide richer information since frames inside the target clip are also\nutilized as positive training examples.\n  Third, we propose to use an early fusion approach, which achieves better\nperformance at the cost of inference time. However, the inference time will not\nbe a problem for our model since our model has a simple architecture which\nenables efficient training and inference.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 22:06:34 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:49:04 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Yu", "Xinli", ""], ["Malmir", "Mohsen", ""], ["He", "Cynthia", ""], ["Liu", "Yue", ""], ["Wu", "Rex", ""]]}, {"id": "2009.02418", "submitter": "Tom Grimes", "authors": "Tom Grimes, Eric Church, William Pitts, Lynn Wood", "title": "Explanation of Unintended Radiated Emission Classification via LIME", "comments": "7 pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unintended radiated emissions arise during the use of electronic devices.\nIdentifying and mitigating the effects of these emissions is a key element of\nmodern power engineering and associated control systems. Signal processing of\nthe electrical system can identify the sources of these emissions. A dataset\nknown as Flaming Moes includes captured unintended radiated emissions from\nconsumer electronics. This dataset was analyzed to construct next-generation\nmethods for device identification. To this end, a neural network based on\napplying the ResNet-18 image classification architecture to the short time\nFourier transforms of short segments of voltage signatures was constructed.\nUsing this classifier, the 18 device classes and background class were\nidentified with close to 100 percent accuracy. By applying LIME to this\nclassifier and aggregating the results over many classifications for the same\ndevice, it was possible to determine the frequency bands used by the classifier\nto make decisions. Using ensembles of classifiers trained on very similar\ndatasets from the same parent data distribution, it was possible to recover\nrobust sets of features of device output useful for identification. The\nadditional understanding provided by the application of LIME enhances the\ntrainability, trustability, and transferability of URE analysis networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 23:14:50 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 16:37:29 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Grimes", "Tom", ""], ["Church", "Eric", ""], ["Pitts", "William", ""], ["Wood", "Lynn", ""]]}, {"id": "2009.02430", "submitter": "Drew Schmidt", "authors": "Drew Schmidt, Bronson Messer, M. Todd Young, Michael Matheson", "title": "Towards the Development of Entropy-Based Anomaly Detection in an\n  Astrophysics Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of AI and ML for scientific applications is currently a very exciting\nand dynamic field. Much of this excitement for HPC has focused on ML\napplications whose analysis and classification generate very large numbers of\nflops. Others seek to replace scientific simulations with data-driven surrogate\nmodels. But another important use case lies in the combination application of\nML to improve simulation accuracy. To that end, we present an anomaly problem\nwhich arises from a core-collapse supernovae simulation. We discuss strategies\nand early successes in applying anomaly detection techniques from machine\nlearning to this scientific simulation, as well as current challenges and\nfuture possibilities.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 01:43:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Schmidt", "Drew", ""], ["Messer", "Bronson", ""], ["Young", "M. Todd", ""], ["Matheson", "Michael", ""]]}, {"id": "2009.02436", "submitter": "Vasileios Charisopoulos", "authors": "Vasileios Charisopoulos, Austin R. Benson, Anil Damle", "title": "Communication-efficient distributed eigenspace estimation", "comments": "v2: Removes unnecessary assumption, fixes typo in Theorem 3. 39\n  pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed computing is a standard way to scale up machine learning and data\nscience algorithms to process large amounts of data. In such settings, avoiding\ncommunication amongst machines is paramount for achieving high performance.\nRather than distribute the computation of existing algorithms, a common\npractice for avoiding communication is to compute local solutions or parameter\nestimates on each machine and then combine the results; in many convex\noptimization problems, even simple averaging of local solutions can work well.\nHowever, these schemes do not work when the local solutions are not unique.\nSpectral methods are a collection of such problems, where solutions are\northonormal bases of the leading invariant subspace of an associated data\nmatrix, which are only unique up to rotation and reflections. Here, we develop\na communication-efficient distributed algorithm for computing the leading\ninvariant subspace of a data matrix. Our algorithm uses a novel alignment\nscheme that minimizes the Procrustean distance between local solutions and a\nreference solution, and only requires a single round of communication. For the\nimportant case of principal component analysis (PCA), we show that our\nalgorithm achieves a similar error rate to that of a centralized estimator. We\npresent numerical experiments demonstrating the efficacy of our proposed\nalgorithm for distributed PCA, as well as other problems where solutions\nexhibit rotational symmetry, such as node embeddings for graph data and\nspectral initialization for quadratic sensing.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 02:11:22 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 22:43:50 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Benson", "Austin R.", ""], ["Damle", "Anil", ""]]}, {"id": "2009.02437", "submitter": "Louise Gillian Bautista", "authors": "Louise Gillian C. Bautista and Prospero C. Naval Jr", "title": "GazeMAE: General Representations of Eye Movements using a Micro-Macro\n  Autoencoder", "comments": "Accepted to 25th International Conference on Pattern Recognition\n  (ICPR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye movements are intricate and dynamic events that contain a wealth of\ninformation about the subject and the stimuli. We propose an abstract\nrepresentation of eye movements that preserve the important nuances in gaze\nbehavior while being stimuli-agnostic. We consider eye movements as raw\nposition and velocity signals and train separate deep temporal convolutional\nautoencoders. The autoencoders learn micro-scale and macro-scale\nrepresentations that correspond to the fast and slow features of eye movements.\nWe evaluate the joint representations with a linear classifier fitted on\nvarious classification tasks. Our work accurately discriminates between gender\nand age groups, and outperforms previous works on biometrics and stimuli\nclasification. Further experiments highlight the validity and generalizability\nof this method, bringing eye tracking research closer to real-world\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 02:13:42 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 06:02:31 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bautista", "Louise Gillian C.", ""], ["Naval", "Prospero C.", "Jr"]]}, {"id": "2009.02439", "submitter": "Norman Tatro", "authors": "N. Joseph Tatro, Pin-Yu Chen, Payel Das, Igor Melnyk, Prasanna\n  Sattigeri, Rongjie Lai", "title": "Optimizing Mode Connectivity via Neuron Alignment", "comments": "Accepted to NeurIPS 2020, 24 pages, 9 figures, code available at\n  https://github.com/IBM/NeuronAlignment", "journal-ref": "Advances in Neural Information Processing Systems, Volume 33, 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss landscapes of deep neural networks are not well understood due to\ntheir high nonconvexity. Empirically, the local minima of these loss functions\ncan be connected by a learned curve in model space, along which the loss\nremains nearly constant; a feature known as mode connectivity. Yet, current\ncurve finding algorithms do not consider the influence of symmetry in the loss\nsurface created by model weight permutations. We propose a more general\nframework to investigate the effect of symmetry on landscape connectivity by\naccounting for the weight permutations of the networks being connected. To\napproximate the optimal permutation, we introduce an inexpensive heuristic\nreferred to as neuron alignment. Neuron alignment promotes similarity between\nthe distribution of intermediate activations of models along the curve. We\nprovide theoretical analysis establishing the benefit of alignment to mode\nconnectivity based on this simple heuristic. We empirically verify that the\npermutation given by alignment is locally optimal via a proximal alternating\nminimization scheme. Empirically, optimizing the weight permutation is critical\nfor efficiently learning a simple, planar, low-loss curve between networks that\nsuccessfully generalizes. Our alignment method can significantly alleviate the\nrecently identified robust loss barrier on the path connecting two adversarial\nrobust models and find more robust and accurate models on the path.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 02:25:23 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 23:56:40 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Tatro", "N. Joseph", ""], ["Chen", "Pin-Yu", ""], ["Das", "Payel", ""], ["Melnyk", "Igor", ""], ["Sattigeri", "Prasanna", ""], ["Lai", "Rongjie", ""]]}, {"id": "2009.02444", "submitter": "Zhenyu Wang", "authors": "Zhenyu Wang, Wei Xia, John H.L. Hansen", "title": "Cross-domain Adaptation with Discrepancy Minimization for\n  Text-independent Forensic Speaker Verification", "comments": "To appear in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forensic audio analysis for speaker verification offers unique challenges due\nto location/scenario uncertainty and diversity mismatch between reference and\nnaturalistic field recordings. The lack of real naturalistic forensic audio\ncorpora with ground-truth speaker identity represents a major challenge in this\nfield. It is also difficult to directly employ small-scale domain-specific data\nto train complex neural network architectures due to domain mismatch and loss\nin performance. Alternatively, cross-domain speaker verification for multiple\nacoustic environments is a challenging task which could advance research in\naudio forensics. In this study, we introduce a CRSS-Forensics audio dataset\ncollected in multiple acoustic environments. We pre-train a CNN-based network\nusing the VoxCeleb data, followed by an approach which fine-tunes part of the\nhigh-level network layers with clean speech from CRSS-Forensics. Based on this\nfine-tuned model, we align domain-specific distributions in the embedding space\nwith the discrepancy loss and maximum mean discrepancy (MMD). This maintains\neffective performance on the clean set, while simultaneously generalizes the\nmodel to other acoustic domains. From the results, we demonstrate that diverse\nacoustic environments affect the speaker verification performance, and that our\nproposed approach of cross-domain adaptation can significantly improve the\nresults in this scenario.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 02:54:33 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 16:53:21 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wang", "Zhenyu", ""], ["Xia", "Wei", ""], ["Hansen", "John H. L.", ""]]}, {"id": "2009.02455", "submitter": "Ashwin Raju", "authors": "Ashwin Raju, Zhanghexuan Ji, Chi Tung Cheng, Jinzheng Cai, Junzhou\n  Huang, Jing Xiao, Le Lu, ChienHung Liao, Adam P. Harrison", "title": "User-Guided Domain Adaptation for Rapid Annotation from User\n  Interactions: A Study on Pathological Liver Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mask-based annotation of medical images, especially for 3D data, is a\nbottleneck in developing reliable machine learning models. Using minimal-labor\nuser interactions (UIs) to guide the annotation is promising, but challenges\nremain on best harmonizing the mask prediction with the UIs. To address this,\nwe propose the user-guided domain adaptation (UGDA) framework, which uses\nprediction-based adversarial domain adaptation (PADA) to model the combined\ndistribution of UIs and mask predictions. The UIs are then used as anchors to\nguide and align the mask prediction. Importantly, UGDA can both learn from\nunlabelled data and also model the high-level semantic meaning behind different\nUIs. We test UGDA on annotating pathological livers using a clinically\ncomprehensive dataset of 927 patient studies. Using only extreme-point UIs, we\nachieve a mean (worst-case) performance of 96.1%(94.9%), compared to 93.0%\n(87.0%) for deep extreme points (DEXTR). Furthermore, we also show UGDA can\nretain this state-of-the-art performance even when only seeing a fraction of\navailable UIs, demonstrating an ability for robust and reliable UI-guided\nsegmentation with extremely minimal labor demands.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:24:58 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Raju", "Ashwin", ""], ["Ji", "Zhanghexuan", ""], ["Cheng", "Chi Tung", ""], ["Cai", "Jinzheng", ""], ["Huang", "Junzhou", ""], ["Xiao", "Jing", ""], ["Lu", "Le", ""], ["Liao", "ChienHung", ""], ["Harrison", "Adam P.", ""]]}, {"id": "2009.02461", "submitter": "Himel Dev", "authors": "Himel Dev and Hossein Hamooni", "title": "Profiling US Restaurants from Billions of Payment Card Transactions", "comments": "The 7th IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A payment card (such as debit or credit) is one of the most convenient\npayment methods for purchasing goods and services. Hundreds of millions of card\ntransactions take place across the globe every day, generating a massive volume\nof transaction data. The data render a holistic view of cardholder-merchant\ninteractions, containing insights that can benefit various applications, such\nas payment fraud detection and merchant recommendation. However, utilizing\nthese insights often requires additional information about merchants missing\nfrom the data owner's (i.e., payment company's) perspective. For example,\npayment companies do not know the exact type of product a merchant serves.\nCollecting merchant attributes from external sources for commercial purposes\ncan be expensive. Motivated by this limitation, we aim to infer latent merchant\nattributes from transaction data. As proof of concept, we concentrate on\nrestaurants and infer the cuisine types of restaurants from transactions. To\nthis end, we present a framework for inferring the cuisine types of restaurants\nfrom transaction data. Our proposed framework consists of three steps. In the\nfirst step, we generate cuisine labels for a limited number of restaurants via\nweak supervision. In the second step, we extract a wide variety of statistical\nfeatures and neural embeddings from the restaurant transactions. In the third\nstep, we use deep neural networks (DNNs) to infer the remaining restaurants'\ncuisine types. The proposed framework achieved a 76.2% accuracy in classifying\nthe US restaurants. To the best of our knowledge, this is the first framework\nto infer the cuisine types of restaurants by analyzing transaction data as the\nonly source.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:50:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Dev", "Himel", ""], ["Hamooni", "Hossein", ""]]}, {"id": "2009.02463", "submitter": "Chuanhao Li", "authors": "Chuanhao Li, Qingyun Wu and Hongning Wang", "title": "Unifying Clustered and Non-stationary Bandits", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-stationary bandits and online clustering of bandits lift the restrictive\nassumptions in contextual bandits and provide solutions to many important\nreal-world scenarios. Though the essence in solving these two problems overlaps\nconsiderably, they have been studied independently. In this paper, we connect\nthese two strands of bandit research under the notion of test of homogeneity,\nwhich seamlessly addresses change detection for non-stationary bandit and\ncluster identification for online clustering of bandit in a unified solution\nframework. Rigorous regret analysis and extensive empirical evaluations\ndemonstrate the value of our proposed solution, especially its flexibility in\nhandling various environment assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:58:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Li", "Chuanhao", ""], ["Wu", "Qingyun", ""], ["Wang", "Hongning", ""]]}, {"id": "2009.02467", "submitter": "Rafael De Araujo Monteiro Da Silva", "authors": "Rafael Monteiro", "title": "Binary Classification as a Phase Separation Process", "comments": "68 pages, 22 figures, 6 tables, supplementary material available on\n  git-hub. Abstract shortened, two figures changed, typos fixed, captions\n  improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.DS math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new binary classification model called Phase Separation Binary\nClassifier (PSBC). It consists of a discretization of a nonlinear\nreaction-diffusion equation coupled with an ODE, and is inspired by fluid\nbehavior, namely, on how binary fluids phase separate. Hence, parameters and\nhyperparameters have physical meaning, whose effects are carefully studied in\nseveral different scenarios. PSBC's coefficients are trainable weights, chosen\naccording to a minimization problem using Gradient Descent; optimization relies\non a classical Backpropagation with weight sharing. The model can be seen under\nthe framework of feedforward networks, and is endowed with a nonlinear\nactivation function that is linear in trainable weights but polynomial in other\nvariables, yielding a cost function that is also polynomial. In view of the\nmodel's connection with ODEs and parabolic PDEs, forward propagation amounts to\nan initial value problem. Thus, stability conditions are established using the\nconcept of Invariant regions. Interesting model compression properties are\nthoroughly discussed. We illustrate the classifier's qualities by applying it\nto the subset of numbers \"0\" and \"1\" of the classical MNIST database, where we\nare able to discern individuals with more than 94\\% accuracy, sometimes using\nless only about 10\\% of variables.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 05:47:05 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 02:17:29 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Monteiro", "Rafael", ""]]}, {"id": "2009.02472", "submitter": "Lei Cheng", "authors": "Lei Cheng, Zhongtao Chen, Qingjiang Shi, Yik-Chung Wu, and Sergios\n  Theodoridis", "title": "Towards Probabilistic Tensor Canonical Polyadic Decomposition 2.0:\n  Automatic Tensor Rank Learning Using Generalized Hyperbolic Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor rank learning for canonical polyadic decomposition (CPD) has long been\ndeemed as an essential but challenging problem. In particular, since the tensor\nrank controls the complexity of the CPD model, its inaccurate learning would\ncause overfitting to noise or underfitting to the signal sources, and even\ndestroy the interpretability of model parameters. However, the optimal\ndetermination of a tensor rank is known to be a non-deterministic\npolynomial-time hard (NP-hard) task. Rather than exhaustively searching for the\nbest tensor rank via trial-and-error experiments, Bayesian inference under the\nGaussian-gamma prior was introduced in the context of probabilistic CPD\nmodeling and it was shown to be an effective strategy for automatic tensor rank\ndetermination. This triggered flourishing research on other structured tensor\nCPDs with automatic tensor rank learning. As the other side of the coin, these\nresearch works also reveal that the Gaussian-gamma model does not perform well\nfor high-rank tensors or/and low signal-to-noise ratios (SNRs). To overcome\nthese drawbacks, in this paper, we introduce a more advanced generalized\nhyperbolic (GH) prior to the probabilistic CPD model, which not only includes\nthe Gaussian-gamma model as a special case, but also provides more\nflexibilities to adapt to different levels of sparsity. Based on this novel\nprobabilistic model, an algorithm is developed under the framework of\nvariational inference, where each update is obtained in a closed-form.\nExtensive numerical results, using synthetic data and real-world datasets,\ndemonstrate the excellent performance of the proposed method in learning both\nlow as well as high tensor ranks even for low SNR cases.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 06:07:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Cheng", "Lei", ""], ["Chen", "Zhongtao", ""], ["Shi", "Qingjiang", ""], ["Wu", "Yik-Chung", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "2009.02473", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Rupendra Nath Mitra, Inaam Ilahi, Junaid Qadir, and\n  Mahesh K. Marina", "title": "Examining Machine Learning for 5G and Beyond through an Adversarial Lens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spurred by the recent advances in deep learning to harness rich information\nhidden in large volumes of data and to tackle problems that are hard to\nmodel/solve (e.g., resource allocation problems), there is currently tremendous\nexcitement in the mobile networks domain around the transformative potential of\ndata-driven AI/ML based network automation, control and analytics for 5G and\nbeyond. In this article, we present a cautionary perspective on the use of\nAI/ML in the 5G context by highlighting the adversarial dimension spanning\nmultiple types of ML (supervised/unsupervised/RL) and support this through\nthree case studies. We also discuss approaches to mitigate this adversarial ML\nrisk, offer guidelines for evaluating the robustness of ML models, and call\nattention to issues surrounding ML oriented research in 5G more generally.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 06:30:26 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Usama", "Muhammad", ""], ["Mitra", "Rupendra Nath", ""], ["Ilahi", "Inaam", ""], ["Qadir", "Junaid", ""], ["Marina", "Mahesh K.", ""]]}, {"id": "2009.02476", "submitter": "Yun-Shiuan Chuang", "authors": "Yun-Shiuan Chuang, Xuezhou Zhang, Yuzhe Ma, Mark K. Ho, Joseph L.\n  Austerweil, Xiaojin Zhu", "title": "Using Machine Teaching to Investigate Human Assumptions when Teaching\n  Reinforcement Learners", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful teaching requires an assumption of how the learner learns - how\nthe learner uses experiences from the world to update their internal states. We\ninvestigate what expectations people have about a learner when they teach them\nin an online manner using rewards and punishment. We focus on a common\nreinforcement learning method, Q-learning, and examine what assumptions people\nhave using a behavioral experiment. To do so, we first establish a normative\nstandard, by formulating the problem as a machine teaching optimization\nproblem. To solve the machine teaching optimization problem, we use a deep\nlearning approximation method which simulates learners in the environment and\nlearns to predict how feedback affects the learner's internal states. What do\npeople assume about a learner's learning and discount rates when they teach\nthem an idealized exploration-exploitation task? In a behavioral experiment, we\nfind that people can teach the task to Q-learners in a relatively efficient and\neffective manner when the learner uses a small value for its discounting rate\nand a large value for its learning rate. However, they still are suboptimal. We\nalso find that providing people with real-time updates of how possible feedback\nwould affect the Q-learner's internal states weakly helps them teach. Our\nresults reveal how people teach using evaluative feedback and provide guidance\nfor how engineers should design machine agents in a manner that is intuitive\nfor people.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 06:32:38 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 21:54:58 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chuang", "Yun-Shiuan", ""], ["Zhang", "Xuezhou", ""], ["Ma", "Yuzhe", ""], ["Ho", "Mark K.", ""], ["Austerweil", "Joseph L.", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2009.02479", "submitter": "Jinhwan Park", "authors": "Wonyong Sung, Iksoo Choi, Jinhwan Park, Seokhyun Choi, Sungho Shin", "title": "S-SGD: Symmetrical Stochastic Gradient Descent with Weight Noise\n  Injection for Reaching Flat Minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient descent (SGD) method is most widely used for deep\nneural network (DNN) training. However, the method does not always converge to\na flat minimum of the loss surface that can demonstrate high generalization\ncapability. Weight noise injection has been extensively studied for finding\nflat minima using the SGD method. We devise a new weight-noise injection-based\nSGD method that adds symmetrical noises to the DNN weights. The training with\nsymmetrical noise evaluates the loss surface at two adjacent points, by which\nconvergence to sharp minima can be avoided. Fixed-magnitude symmetric noises\nare added to minimize training instability. The proposed method is compared\nwith the conventional SGD method and previous weight-noise injection algorithms\nusing convolutional neural networks for image classification. Particularly,\nperformance improvements in large batch training are demonstrated. This method\nshows superior performance compared with conventional SGD and weight-noise\ninjection methods regardless of the batch-size and learning rate scheduling\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 07:02:02 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Sung", "Wonyong", ""], ["Choi", "Iksoo", ""], ["Park", "Jinhwan", ""], ["Choi", "Seokhyun", ""], ["Shin", "Sungho", ""]]}, {"id": "2009.02491", "submitter": "Ying Zhao", "authors": "Fangfang Zhou, Yong Zhao, Wenjiang Chen, Yijing Tan, Yaqi Xu, Yi Chen,\n  Chao Liu, Ying Zhao", "title": "Reverse-engineering Bar Charts Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse-engineering bar charts extracts textual and numeric information from\nthe visual representations of bar charts to support application scenarios that\nrequire the underlying information. In this paper, we propose a neural\nnetwork-based method for reverse-engineering bar charts. We adopt a neural\nnetwork-based object detection model to simultaneously localize and classify\ntextual information. This approach improves the efficiency of textual\ninformation extraction. We design an encoder-decoder framework that integrates\nconvolutional and recurrent neural networks to extract numeric information. We\nfurther introduce an attention mechanism into the framework to achieve high\naccuracy and robustness. Synthetic and real-world datasets are used to evaluate\nthe effectiveness of the method. To the best of our knowledge, this work takes\nthe lead in constructing a complete neural network-based method of\nreverse-engineering bar charts.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 08:14:35 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhou", "Fangfang", ""], ["Zhao", "Yong", ""], ["Chen", "Wenjiang", ""], ["Tan", "Yijing", ""], ["Xu", "Yaqi", ""], ["Chen", "Yi", ""], ["Liu", "Chao", ""], ["Zhao", "Ying", ""]]}, {"id": "2009.02526", "submitter": "Riza Ozcelik", "authors": "Abdullatif K\\\"oksal, Hilal D\\\"onmez, R{\\i}za \\\"Oz\\c{c}elik, Elif\n  Ozkirimli, Arzucan \\\"Ozg\\\"ur", "title": "Vapur: A Search Engine to Find Related Protein-Compound Pairs in\n  COVID-19 Literature", "comments": "EMNLP 2020 - COVID-19 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coronavirus Disease of 2019 (COVID-19) created dire consequences globally and\ntriggered an intense scientific effort from different domains. The resulting\npublications created a huge text collection in which finding the studies\nrelated to a biomolecule of interest is challenging for general purpose search\nengines because the publications are rich in domain specific terminology. Here,\nwe present Vapur: an online COVID-19 search engine specifically designed to\nfind related protein - chemical pairs. Vapur is empowered with a\nrelation-oriented inverted index that is able to retrieve and group studies for\na query biomolecule with respect to its related entities. The inverted index of\nVapur is automatically created with a BioNLP pipeline and integrated with an\nonline user interface. The online interface is designed for the smooth\ntraversal of the current literature by domain researchers and is publicly\navailable at https://tabilab.cmpe.boun.edu.tr/vapur/ .\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 12:50:54 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 21:45:27 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 06:34:24 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["K\u00f6ksal", "Abdullatif", ""], ["D\u00f6nmez", "Hilal", ""], ["\u00d6z\u00e7elik", "R\u0131za", ""], ["Ozkirimli", "Elif", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "2009.02539", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Santu Rana, Huong Ha, Svetha Venkatesh", "title": "Sub-linear Regret Bounds for Bayesian Optimisation in Unknown Search\n  Spaces", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular method for efficient optimisation of\nexpensive black-box functions. Traditionally, BO assumes that the search space\nis known. However, in many problems, this assumption does not hold. To this\nend, we propose a novel BO algorithm which expands (and shifts) the search\nspace over iterations based on controlling the expansion rate thought a\nhyperharmonic series. Further, we propose another variant of our algorithm that\nscales to high dimensions. We show theoretically that for both our algorithms,\nthe cumulative regret grows at sub-linear rates. Our experiments with synthetic\nand real-world optimisation tasks demonstrate the superiority of our algorithms\nover the current state-of-the-art methods for Bayesian optimisation in unknown\nsearch space.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:24:40 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 00:26:20 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 00:31:27 GMT"}, {"version": "v4", "created": "Sun, 1 Nov 2020 12:38:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Ha", "Huong", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2009.02540", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir and Kumar Vijay Mishra", "title": "A Survey of Deep Learning Architectures for Intelligent Reflecting\n  Surfaces", "comments": "7 pages and 5 figures. This work has been submitted to the IEEE for\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflecting surfaces (IRSs) have recently received significant\nattention for wireless communications because it reduces the hardware\ncomplexity, physical size, weight, and cost of conventional large arrays.\nHowever, deployment of IRS entails dealing with multiple channel links between\nthe base station (BS) and the users. Further, the BS and IRS beamformers\nrequire a joint design, wherein the IRS elements must be rapidly reconfigured.\nData-driven techniques, such as deep learning (DL), are critical in addressing\nthese challenges. The lower computation time and model-free nature of DL makes\nit robust against the data imperfections and environmental changes. At the\nphysical layer, DL has been shown to be effective for IRS signal detection,\nchannel estimation and active/passive beamforming using architectures such as\nsupervised, unsupervised and reinforcement learning. This article provides a\nsynopsis of these techniques for designing DL-based IRS-assisted wireless\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:26:48 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 18:35:55 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 09:54:37 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Mishra", "Kumar Vijay", ""]]}, {"id": "2009.02542", "submitter": "Taufik Abrao PhD", "authors": "Jos\\'e Carlos Marinello, Taufik Abr\\~ao, Abolfazl Amiri, Elisabeth de\n  Carvalho, Petar Popovski", "title": "Antenna Selection for Improving Energy Efficiency in XL-MIMO Systems", "comments": "24 pages, 7 figures, 1 table and 22 references", "journal-ref": null, "doi": null, "report-no": "VT-2020-01622.R1", "categories": "eess.SP cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recently proposed extra-large scale massive multiple-input\nmultiple-output (XL-MIMO) systems, with some hundreds of antennas serving a\nsmaller number of users. Since the array length is of the same order as the\ndistance to the users, the long-term fading coefficients of a given user vary\nwith the different antennas at the base station (BS). Thus, the signal\ntransmitted by some antennas might reach the user with much more power than\nthat transmitted by some others. From a green perspective, it is not effective\nto simultaneously activate hundreds or even thousands of antennas, since the\npower-hungry radio frequency (RF) chains of the active antennas increase\nsignificantly the total energy consumption. Besides, a larger number of\nselected antennas increases the power required by linear processing, such as\nprecoding matrix computation, and short-term channel estimation. In this paper,\nwe propose four antenna selection (AS) approaches to be deployed in XL-MIMO\nsystems aiming at maximizing the total energy efficiency (EE). Besides,\nemploying some simplifying assumptions, we derive a closed-form analytical\nexpression for the EE of the XL-MIMO system, and propose a straightforward\niterative method to determine the optimal number of selected antennas able to\nmaximize it. The proposed AS schemes are based solely on long-term fading\nparameters, thus, the selected antennas set remains valid for a relatively\nlarge time/frequency intervals. Comparing the results, we find that the\ngenetic-algorithm based AS scheme usually achieves the best EE performance,\nalthough our proposed highest normalized received power AS scheme also achieves\nvery promising EE performance in a simple and straightforward way.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:43:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Marinello", "Jos\u00e9 Carlos", ""], ["Abr\u00e3o", "Taufik", ""], ["Amiri", "Abolfazl", ""], ["de Carvalho", "Elisabeth", ""], ["Popovski", "Petar", ""]]}, {"id": "2009.02553", "submitter": "Luo Luo", "authors": "Luo Luo, Cheng Chen, Guangzeng Xie, Haishan Ye", "title": "Revisiting Co-Occurring Directions: Sharper Analysis and Efficient\n  Algorithm for Sparse Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study the streaming model for approximate matrix multiplication (AMM). We\nare interested in the scenario that the algorithm can only take one pass over\nthe data with limited memory. The state-of-the-art deterministic sketching\nalgorithm for streaming AMM is the co-occurring directions (COD), which has\nmuch smaller approximation errors than randomized algorithms and outperforms\nother deterministic sketching methods empirically. In this paper, we provide a\ntighter error bound for COD whose leading term considers the potential\napproximate low-rank structure and the correlation of input matrices. We prove\nCOD is space optimal with respect to our improved error bound. We also propose\na variant of COD for sparse matrices with theoretical guarantees. The\nexperiments on real-world sparse datasets show that the proposed algorithm is\nmore efficient than baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 15:35:59 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 06:55:55 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Luo", "Luo", ""], ["Chen", "Cheng", ""], ["Xie", "Guangzeng", ""], ["Ye", "Haishan", ""]]}, {"id": "2009.02557", "submitter": "Hui Chen", "authors": "Pei Fang, Zhendong Cai, Hui Chen and QingJiang Shi", "title": "FLFE: A Communication-Efficient and Privacy-Preserving Federated Feature\n  Engineering Framework", "comments": "11pages, multi-party feature engineering problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is the process of using domain knowledge to extract\nfeatures from raw data via data mining techniques and is a key step to improve\nthe performance of machine learning algorithms. In the multi-party feature\nengineering scenario (features are stored in many different IoT devices),\ndirect and unlimited multivariate feature transformations will quickly exhaust\nmemory, power, and bandwidth of devices, not to mention the security of\ninformation threatened. Given this, we present a framework called FLFE to\nconduct privacy-preserving and communication-preserving multi-party feature\ntransformations. The framework pre-learns the pattern of the feature to\ndirectly judge the usefulness of the transformation on a feature. Explored the\nnew useful feature, the framework forsakes the encryption-based algorithm for\nthe well-designed feature exchange mechanism, which largely decreases the\ncommunication overhead under the premise of confidentiality. We made\nexperiments on datasets of both open-sourced and real-world thus validating the\ncomparable effectiveness of FLFE to evaluation-based approaches, along with the\nfar more superior efficacy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:08:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fang", "Pei", ""], ["Cai", "Zhendong", ""], ["Chen", "Hui", ""], ["Shi", "QingJiang", ""]]}, {"id": "2009.02560", "submitter": "Basheer Qolomany", "authors": "Basheer Qolomany, Kashif Ahmad, Ala Al-Fuqaha, Junaid Qadir", "title": "Particle Swarm Optimized Federated Learning For Industrial IoT and Smart\n  City Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the research on Federated Learning (FL) has focused on analyzing\nglobal optimization, privacy, and communication, with limited attention\nfocusing on analyzing the critical matter of performing efficient local\ntraining and inference at the edge devices. One of the main challenges for\nsuccessful and efficient training and inference on edge devices is the careful\nselection of parameters to build local Machine Learning (ML) models. To this\naim, we propose a Particle Swarm Optimization (PSO)-based technique to optimize\nthe hyperparameter settings for the local ML models in an FL environment. We\nevaluate the performance of our proposed technique using two case studies.\nFirst, we consider smart city services and use an experimental transportation\ndataset for traffic prediction as a proxy for this setting. Second, we consider\nIndustrial IoT (IIoT) services and use the real-time telemetry dataset to\npredict the probability that a machine will fail shortly due to component\nfailures. Our experiments indicate that PSO provides an efficient approach for\ntuning the hyperparameters of deep Long short-term memory (LSTM) models when\ncompared to the grid search method. Our experiments illustrate that the number\nof clients-server communication rounds to explore the landscape of\nconfigurations to find the near-optimal parameters are greatly reduced (roughly\nby two orders of magnitude needing only 2%--4% of the rounds compared to state\nof the art non-PSO-based approaches). We also demonstrate that utilizing the\nproposed PSO-based technique to find the near-optimal configurations for FL and\ncentralized learning models does not adversely affect the accuracy of the\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:20:47 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Qolomany", "Basheer", ""], ["Ahmad", "Kashif", ""], ["Al-Fuqaha", "Ala", ""], ["Qadir", "Junaid", ""]]}, {"id": "2009.02562", "submitter": "Ziwei Zhang", "authors": "Ziwei Zhang, Chenhao Niu, Peng Cui, Bo Zhang, Wei Cui, Wenwu Zhu", "title": "A Simple and General Graph Neural Network with Stochastic Message\n  Passing", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are emerging machine learning models on graphs.\nOne key property behind the expressiveness of existing GNNs is that the learned\nnode representations are permutation-equivariant. Though being a desirable\nproperty for certain tasks, however, permutation-equivariance prevents GNNs\nfrom being proximity-aware, i.e., preserving the walk-based proximities between\npairs of nodes, which is another critical property for graph analytical tasks.\nOn the other hand, some variants of GNNs are proposed to preserve node\nproximities, but they fail to maintain permutation-equivariance. How to empower\nGNNs to be proximity-aware while maintaining permutation-equivariance remains\nan open problem. In this paper, we propose Stochastic Message Passing (SMP), a\ngeneral and simple GNN to maintain both proximity-awareness and\npermutation-equivariance properties. Specifically, we augment the existing GNNs\nwith stochastic node representations learned to preserve node proximities.\nThough seemingly simple, we prove that such a mechanism can enable GNNs to\npreserve node proximities in theory while maintaining permutation-equivariance\nwith certain parametrization. Extensive experimental results demonstrate the\neffectiveness and efficiency of SMP for tasks including node classification and\nlink prediction.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:46:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhang", "Ziwei", ""], ["Niu", "Chenhao", ""], ["Cui", "Peng", ""], ["Zhang", "Bo", ""], ["Cui", "Wei", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2009.02564", "submitter": "Haochuan Jiang", "authors": "Haochuan Jiang, Agisilaos Chartsias, Xinheng Zhang, Giorgos\n  Papanastasiou, Scott Semple, Mark Dweck, David Semple, Rohan Dharmakumar,\n  Sotirios A. Tsaftaris", "title": "Semi-supervised Pathology Segmentation with Disentangled Representations", "comments": "12 Pages, 4 figures", "journal-ref": "MICCAI-2020 DART workshop", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated pathology segmentation remains a valuable diagnostic tool in\nclinical practice. However, collecting training data is challenging.\nSemi-supervised approaches by combining labelled and unlabelled data can offer\na solution to data scarcity. An approach to semi-supervised learning relies on\nreconstruction objectives (as self-supervision objectives) that learns in a\njoint fashion suitable representations for the task. Here, we propose\nAnatomy-Pathology Disentanglement Network (APD-Net), a pathology segmentation\nmodel that attempts to learn jointly for the first time: disentanglement of\nanatomy, modality, and pathology. The model is trained in a semi-supervised\nfashion with new reconstruction losses directly aiming to improve pathology\nsegmentation with limited annotations. In addition, a joint optimization\nstrategy is proposed to fully take advantage of the available annotations. We\nevaluate our methods with two private cardiac infarction segmentation datasets\nwith LGE-MRI scans. APD-Net can perform pathology segmentation with few\nannotations, maintain performance with different amounts of supervision, and\noutperform related deep learning methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:07:59 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Jiang", "Haochuan", ""], ["Chartsias", "Agisilaos", ""], ["Zhang", "Xinheng", ""], ["Papanastasiou", "Giorgos", ""], ["Semple", "Scott", ""], ["Dweck", "Mark", ""], ["Semple", "David", ""], ["Dharmakumar", "Rohan", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "2009.02565", "submitter": "Borneel Phukan", "authors": "Borneel Bikash Phukan, Amiya Ranjan Panda", "title": "An Efficient Technique for Image Captioning using Deep Neural Network", "comments": "5 pages, 10 figures, Under review by an internationally recognized\n  Scopus indexed journal 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the huge expansion of internet and trillions of gigabytes of data\ngenerated every single day, the needs for the development of various tools has\nbecome mandatory in order to maintain system adaptability to rapid changes. One\nof these tools is known as Image Captioning. Every entity in internet must be\nproperly identified and managed and therefore in the case of image data,\nautomatic captioning for identification is required. Similarly, content\ngeneration for missing labels, image classification and artificial languages\nall requires the process of Image Captioning. This paper discusses an efficient\nand unique way to perform automatic image captioning on individual image and\ndiscusses strategies to improve its performances and functionalities.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:11:44 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Phukan", "Borneel Bikash", ""], ["Panda", "Amiya Ranjan", ""]]}, {"id": "2009.02571", "submitter": "Rahul Dubey Dr", "authors": "Param Khakhar and, Rahul Kumar Dubey, Senior Member IEEE", "title": "The Integrity of Machine Learning Algorithms against Software Defect\n  Prediction", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increased computerization in recent years has resulted in the production\nof a variety of different software, however measures need to be taken to ensure\nthat the produced software isn't defective. Many researchers have worked in\nthis area and have developed different Machine Learning-based approaches that\npredict whether the software is defective or not. This issue can't be resolved\nsimply by using different conventional classifiers because the dataset is\nhighly imbalanced i.e the number of defective samples detected is extremely\nless as compared to the number of non-defective samples. Therefore, to address\nthis issue, certain sophisticated methods are required. The different methods\ndeveloped by the researchers can be broadly classified into Resampling based\nmethods, Cost-sensitive learning-based methods, and Ensemble Learning. Among\nthese methods. This report analyses the performance of the Online Sequential\nExtreme Learning Machine (OS-ELM) proposed by Liang et.al. against several\nclassifiers such as Logistic Regression, Support Vector Machine, Random Forest,\nand Na\\\"ive Bayes after oversampling the data. OS-ELM trains faster than\nconventional deep neural networks and it always converges to the globally\noptimal solution. A comparison is performed on the original dataset as well as\nthe over-sampled data set. The oversampling technique used is Cluster-based\nOver-Sampling with Noise Filtering. This technique is better than several\nstate-of-the-art techniques for oversampling. The analysis is carried out on 3\nprojects KC1, PC4 and PC3 carried out by the NASA group. The metrics used for\nmeasurement are recall and balanced accuracy. The results are higher for OS-ELM\nas compared to other classifiers in both scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:26:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["and", "Param Khakhar", ""], ["Dubey", "Rahul Kumar", ""], ["IEEE", "Senior Member", ""]]}, {"id": "2009.02572", "submitter": "Selim Firat Yilmaz", "authors": "Selim F. Yilmaz and Suleyman S. Kozat", "title": "PySAD: A Streaming Anomaly Detection Framework in Python", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PySAD is an open-source python framework for anomaly detection on streaming\ndata. PySAD serves various state-of-the-art methods for streaming anomaly\ndetection. The framework provides a complete set of tools to design anomaly\ndetection experiments ranging from projectors to probability calibrators. PySAD\nbuilds upon popular open-source frameworks such as PyOD and scikit-learn. We\nenforce software quality by enforcing compliance with PEP8 guidelines,\nfunctional testing and using continuous integration. The source code is\npublicly available on https://github.com/selimfirat/pysad.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:41:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2009.02590", "submitter": "Nasim Sonboli", "authors": "Nasim Sonboli, Robin Burke, Nicholas Mattei, Farzad Eskandanian, Tian\n  Gao", "title": "\"And the Winner Is...\": Dynamic Lotteries for Multi-group Fairness-Aware\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As recommender systems are being designed and deployed for an increasing\nnumber of socially-consequential applications, it has become important to\nconsider what properties of fairness these systems exhibit. There has been\nconsiderable research on recommendation fairness. However, we argue that the\nprevious literature has been based on simple, uniform and often uni-dimensional\nnotions of fairness assumptions that do not recognize the real-world\ncomplexities of fairness-aware applications. In this paper, we explicitly\nrepresent the design decisions that enter into the trade-off between accuracy\nand fairness across multiply-defined and intersecting protected groups,\nsupporting multiple fairness metrics. The framework also allows the recommender\nto adjust its performance based on the historical view of recommendations that\nhave been delivered over a time horizon, dynamically rebalancing between\nfairness concerns. Within this framework, we formulate lottery-based mechanisms\nfor choosing between fairness concerns, and demonstrate their performance in\ntwo recommendation domains.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 20:15:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Sonboli", "Nasim", ""], ["Burke", "Robin", ""], ["Mattei", "Nicholas", ""], ["Eskandanian", "Farzad", ""], ["Gao", "Tian", ""]]}, {"id": "2009.02594", "submitter": "Andrei Apostol", "authors": "Andrei Apostol, Maarten Stol, Patrick Forr\\'e", "title": "FlipOut: Uncovering Redundant Weights via Sign Flipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks, although achieving state-of-the-art results on many\ntasks, tend to have a large number of parameters, which increases training time\nand resource usage. This problem can be alleviated by pruning. Existing\nmethods, however, often require extensive parameter tuning or multiple cycles\nof pruning and retraining to convergence in order to obtain a favorable\naccuracy-sparsity trade-off. To address these issues, we propose a novel\npruning method which uses the oscillations around $0$ (i.e. sign flips) that a\nweight has undergone during training in order to determine its saliency. Our\nmethod can perform pruning before the network has converged, requires little\ntuning effort due to having good default values for its hyperparameters, and\ncan directly target the level of sparsity desired by the user. Our experiments,\nperformed on a variety of object classification architectures, show that it is\ncompetitive with existing methods and achieves state-of-the-art performance for\nlevels of sparsity of $99.6\\%$ and above for most of the architectures tested.\nFor reproducibility, we release our code publicly at\nhttps://github.com/AndreiXYZ/flipout.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 20:27:32 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Apostol", "Andrei", ""], ["Stol", "Maarten", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2009.02602", "submitter": "Ashkan Zehfroosh", "authors": "Ashkan Zehfroosh and Herbert G. Tanner", "title": "A Hybrid PAC Reinforcement Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a new hybrid probably approximately correct (PAC)\nreinforcement learning (RL) algorithm for Markov decision processes (MDPs) that\nintelligently maintains favorable features of its parents. The designed\nalgorithm, referred to as the Dyna-Delayed Q-learning (DDQ) algorithm, combines\nmodel-free and model-based learning approaches while outperforming both in most\ncases. The paper includes a PAC analysis of the DDQ algorithm and a derivation\nof its sample complexity. Numerical results are provided to support the claim\nregarding the new algorithm's sample efficiency compared to its parents as well\nas the best known model-free and model-based algorithms in application.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 21:32:42 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 05:24:39 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zehfroosh", "Ashkan", ""], ["Tanner", "Herbert G.", ""]]}, {"id": "2009.02604", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Jos\\'e Bento", "title": "Distributed Optimization, Averaging via ADMM, and Network Topology", "comments": "to appear in \"Proceedings of the IEEE\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing necessity for scalable optimization methods,\nespecially due to the explosion in the size of datasets and model complexity in\nmodern machine learning applications. Scalable solvers often distribute the\ncomputation over a network of processing units. For simple algorithms such as\ngradient descent the dependency of the convergence time with the topology of\nthis network is well-known. However, for more involved algorithms such as the\nAlternating Direction Methods of Multipliers (ADMM) much less is known. At the\nheart of many distributed optimization algorithms there exists a gossip\nsubroutine which averages local information over the network, and whose\nefficiency is crucial for the overall performance of the method. In this paper\nwe review recent research in this area and, with the goal of isolating such a\ncommunication exchange behaviour, we compare different algorithms when applied\nto a canonical distributed averaging consensus problem. We also show\ninteresting connections between ADMM and lifted Markov chains besides providing\nan explicitly characterization of its convergence and optimal parameter tuning\nin terms of spectral properties of the network. Finally, we empirically study\nthe connection between network topology and convergence rates for different\nalgorithms on a real world problem of sensor localization.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 21:44:39 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "2009.02605", "submitter": "Ashkan Zehfroosh", "authors": "Ashkan Zehfroosh and Herbert G. Tanner", "title": "PAC Reinforcement Learning Algorithm for General-Sum Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a theoretical framework for probably approximately\ncorrect (PAC) multi-agent reinforcement learning (MARL) algorithms for Markov\ngames. The paper offers an extension to the well-known Nash Q-learning\nalgorithm, using the idea of delayed Q-learning, in order to build a new PAC\nMARL algorithm for general-sum Markov games. In addition to guiding the design\nof a provably PAC MARL algorithm, the framework enables checking whether an\narbitrary MARL algorithm is PAC. Comparative numerical results demonstrate\nperformance and robustness.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 21:54:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zehfroosh", "Ashkan", ""], ["Tanner", "Herbert G.", ""]]}, {"id": "2009.02608", "submitter": "Haekyu Park", "authors": "Nilaksh Das, Haekyu Park, Zijie J. Wang, Fred Hohman, Robert Firstman,\n  Emily Rogers, Duen Horng Chau", "title": "Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural\n  Networks", "comments": "This paper is accepted at IEEE VIS'20 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are now commonly used in many domains. However,\nthey are vulnerable to adversarial attacks: carefully crafted perturbations on\ndata inputs that can fool a model into making incorrect predictions. Despite\nsignificant research on developing DNN attack and defense techniques, people\nstill lack an understanding of how such attacks penetrate a model's internals.\nWe present Bluff, an interactive system for visualizing, characterizing, and\ndeciphering adversarial attacks on vision-based neural networks. Bluff allows\npeople to flexibly visualize and compare the activation pathways for benign and\nattacked images, revealing mechanisms that adversarial attacks employ to\ninflict harm on a model. Bluff is open-sourced and runs in modern web browsers.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 22:08:35 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 02:38:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Das", "Nilaksh", ""], ["Park", "Haekyu", ""], ["Wang", "Zijie J.", ""], ["Hohman", "Fred", ""], ["Firstman", "Robert", ""], ["Rogers", "Emily", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2009.02609", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Richard J. Samworth", "title": "Isotonic regression with unknown permutations: Statistics, computation,\n  and adaptation", "comments": "Version v2 contains reorganized material, one figure, and expanded\n  discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by models for multiway comparison data, we consider the problem of\nestimating a coordinate-wise isotonic function on the domain $[0, 1]^d$ from\nnoisy observations collected on a uniform lattice, but where the design points\nhave been permuted along each dimension. While the univariate and bivariate\nversions of this problem have received significant attention, our focus is on\nthe multivariate case $d \\geq 3$. We study both the minimax risk of estimation\n(in empirical $L_2$ loss) and the fundamental limits of adaptation (quantified\nby the adaptivity index) to a family of piecewise constant functions. We\nprovide a computationally efficient Mirsky partition estimator that is minimax\noptimal while also achieving the smallest adaptivity index possible for\npolynomial time procedures. Thus, from a worst-case perspective and in sharp\ncontrast to the bivariate case, the latent permutations in the model do not\nintroduce significant computational difficulties over and above vanilla\nisotonic regression. On the other hand, the fundamental limits of adaptation\nare significantly different with and without unknown permutations: Assuming a\nhardness conjecture from average-case complexity theory, a\nstatistical-computational gap manifests in the former case. In a complementary\ndirection, we show that natural modifications of existing estimators fail to\nsatisfy at least one of the desiderata of optimal worst-case statistical\nperformance, computational efficiency, and fast adaptation. Along the way to\nshowing our results, we improve adaptation results in the special case $d = 2$\nand establish some properties of estimators for vanilla isotonic regression,\nboth of which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 22:17:51 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 13:58:37 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2009.02623", "submitter": "Zifeng Wang", "authors": "Zifeng Wang and Xi Chen and Rui Wen and Shao-Lun Huang and Ercan E.\n  Kuruoglu and Yefeng Zheng", "title": "Information Theoretic Counterfactual Learning from Missing-Not-At-Random\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning for dealing with missing-not-at-random data (MNAR) is\nan intriguing topic in the recommendation literature since MNAR data are\nubiquitous in modern recommender systems. Missing-at-random (MAR) data, namely\nrandomized controlled trials (RCTs), are usually required by most previous\ncounterfactual learning methods for debiasing learning. However, the execution\nof RCTs is extraordinarily expensive in practice. To circumvent the use of\nRCTs, we build an information-theoretic counterfactual variational information\nbottleneck (CVIB), as an alternative for debiasing learning without RCTs. By\nseparating the task-aware mutual information term in the original information\nbottleneck Lagrangian into factual and counterfactual parts, we derive a\ncontrastive information loss and an additional output confidence penalty, which\nfacilitates balanced learning between the factual and counterfactual domains.\nEmpirical evaluation on real-world datasets shows that our CVIB significantly\nenhances both shallow and deep models, which sheds light on counterfactual\nlearning in recommendation that goes beyond RCTs.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 01:22:47 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 13:54:54 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Zifeng", ""], ["Chen", "Xi", ""], ["Wen", "Rui", ""], ["Huang", "Shao-Lun", ""], ["Kuruoglu", "Ercan E.", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.02625", "submitter": "Zifeng Wang", "authors": "Zifeng Wang and Rui Wen and Xi Chen and Shilei Cao and Shao-Lun Huang\n  and Buyue Qian and Yefeng Zheng", "title": "Online Disease Self-diagnosis with Inductive Heterogeneous Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3449795", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Healthcare Graph Convolutional Network (HealGCN) to offer\ndisease self-diagnosis service for online users based on Electronic Healthcare\nRecords (EHRs). Two main challenges are focused in this paper for online\ndisease diagnosis: (1) serving cold-start users via graph convolutional\nnetworks and (2) handling scarce clinical description via a symptom retrieval\nsystem. To this end, we first organize the EHR data into a heterogeneous graph\nthat is capable of modeling complex interactions among users, symptoms and\ndiseases, and tailor the graph representation learning towards disease\ndiagnosis with an inductive learning paradigm. Then, we build a disease\nself-diagnosis system with a corresponding EHR Graph-based Symptom Retrieval\nSystem (GraphRet) that can search and provide a list of relevant alternative\nsymptoms by tracing the predefined meta-paths. GraphRet helps enrich the seed\nsymptom set through the EHR graph when confronting users with scarce\ndescriptions, hence yield better diagnosis accuracy. At last, we validate the\nsuperiority of our model on a large-scale EHR dataset.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 01:32:14 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 01:47:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Zifeng", ""], ["Wen", "Rui", ""], ["Chen", "Xi", ""], ["Cao", "Shilei", ""], ["Huang", "Shao-Lun", ""], ["Qian", "Buyue", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.02653", "submitter": "Jiang Lu", "authors": "Jiang Lu, Pinghua Gong, Jieping Ye, and Changshui Zhang", "title": "Learning from Very Few Samples: A Survey", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few sample learning (FSL) is significant and challenging in the field of\nmachine learning. The capability of learning and generalizing from very few\nsamples successfully is a noticeable demarcation separating artificial\nintelligence and human intelligence since humans can readily establish their\ncognition to novelty from just a single or a handful of examples whereas\nmachine learning algorithms typically entail hundreds or thousands of\nsupervised samples to guarantee generalization ability. Despite the long\nhistory dated back to the early 2000s and the widespread attention in recent\nyears with booming deep learning technologies, little surveys or reviews for\nFSL are available until now. In this context, we extensively review 300+ papers\nof FSL spanning from the 2000s to 2019 and provide a timely and comprehensive\nsurvey for FSL. In this survey, we review the evolution history as well as the\ncurrent progress on FSL, categorize FSL approaches into the generative model\nbased and discriminative model based kinds in principle, and emphasize\nparticularly on the meta learning based FSL approaches. We also summarize\nseveral recently emerging extensional topics of FSL and review the latest\nadvances on these topics. Furthermore, we highlight the important FSL\napplications covering many research hotspots in computer vision, natural\nlanguage processing, audio and speech, reinforcement learning and robotic, data\nanalysis, etc. Finally, we conclude the survey with a discussion on promising\ntrends in the hope of providing guidance and insights to follow-up researches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 06:13:09 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 14:21:57 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lu", "Jiang", ""], ["Gong", "Pinghua", ""], ["Ye", "Jieping", ""], ["Zhang", "Changshui", ""]]}, {"id": "2009.02661", "submitter": "Himanshu Buckchash", "authors": "Vipul Bansal, Himanshu Buckchash, Balasubramanian Raman", "title": "Computational Models for Academic Performance Estimation", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of students' performance for the completion of courses has been a\nmajor problem for both students and faculties during the work-from-home period\nin this COVID pandemic situation. To this end, this paper presents an in-depth\nanalysis of deep learning and machine learning approaches for the formulation\nof an automated students' performance estimation system that works on partially\navailable students' academic records. Our main contributions are (a) a large\ndataset with fifteen courses (shared publicly for academic research) (b)\nstatistical analysis and ablations on the estimation problem for this dataset\n(c) predictive analysis through deep learning approaches and comparison with\nother arts and machine learning algorithms. Unlike previous approaches that\nrely on feature engineering or logical function deduction, our approach is\nfully data-driven and thus highly generic with better performance across\ndifferent prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 07:31:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bansal", "Vipul", ""], ["Buckchash", "Himanshu", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "2009.02668", "submitter": "Jalaj Upadhyay", "authors": "Jalaj Upadhyay, Sarvagya Upadhyay", "title": "A Framework for Private Matrix Analysis", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study private matrix analysis in the sliding window model where only the\nlast $W$ updates to matrices are considered useful for analysis. We give first\nefficient $o(W)$ space differentially private algorithms for spectral\napproximation, principal component analysis, and linear regression. We also\ninitiate and show efficient differentially private algorithms for two important\nvariants of principal component analysis: sparse principal component analysis\nand non-negative principal component analysis. Prior to our work, no such\nresult was known for sparse and non-negative differentially private principal\ncomponent analysis even in the static data setting. These algorithms are\nobtained by identifying sufficient conditions on positive semidefinite matrices\nformed from streamed matrices. We also show a lower bound on space required to\ncompute low-rank approximation even if the algorithm gives multiplicative\napproximation and incurs additive error. This follows via reduction to a\ncertain communication complexity problem.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:01:59 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Upadhyay", "Jalaj", ""], ["Upadhyay", "Sarvagya", ""]]}, {"id": "2009.02695", "submitter": "Kohei Yoshikawa", "authors": "Kohei Yoshikawa, Shuichi Kawano", "title": "Multilinear Common Component Analysis via Kronecker Product\n  Representation", "comments": "35 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of extracting a common structure from multiple tensor\ndatasets. For this purpose, we propose multilinear common component analysis\n(MCCA) based on Kronecker products of mode-wise covariance matrices. MCCA\nconstructs a common basis represented by linear combinations of the original\nvariables which loses as little information of the multiple tensor datasets. We\nalso develop an estimation algorithm for MCCA that guarantees mode-wise global\nconvergence. Numerical studies are conducted to show the effectiveness of MCCA.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:03:17 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 08:06:05 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Yoshikawa", "Kohei", ""], ["Kawano", "Shuichi", ""]]}, {"id": "2009.02700", "submitter": "Karol Antczak PhD", "authors": "Karol Antczak", "title": "A Generative Adversarial Approach To ECG Synthesis And Denoising", "comments": "7 pages + 2 pages of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) are known to produce synthetic data\nthat are difficult to discern from real ones by humans. In this paper we\npresent an approach to use GAN to produce realistically looking ECG signals. We\nutilize them to train and evaluate a denoising autoencoder that achieves\nstate-of-the-art filtering quality for ECG signals. It is demonstrated that\ngenerated data improves the model performance compared to the model trained on\nreal data only. We also investigate an effect of transfer learning by reusing\ntrained discriminator network for denoising model.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:17:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Antczak", "Karol", ""]]}, {"id": "2009.02701", "submitter": "Yuhao Zhou", "authors": "Yuhao Zhou, Qing Ye, Hailun Zhang, Jiancheng Lv", "title": "HPSGD: Hierarchical Parallel SGD With Stale Gradients Featuring", "comments": "12 pages, 10 figures, ICONIP2020 under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While distributed training significantly speeds up the training process of\nthe deep neural network (DNN), the utilization of the cluster is relatively low\ndue to the time-consuming data synchronizing between workers. To alleviate this\nproblem, a novel Hierarchical Parallel SGD (HPSGD) strategy is proposed based\non the observation that the data synchronization phase can be paralleled with\nthe local training phase (i.e., Feed-forward and back-propagation).\nFurthermore, an improved model updating method is unitized to remedy the\nintroduced stale gradients problem, which commits updates to the replica (i.e.,\na temporary model that has the same parameters as the global model) and then\nmerges the average changes to the global model. Extensive experiments are\nconducted to demonstrate that the proposed HPSGD approach substantially boosts\nthe distributed DNN training, reduces the disturbance of the stale gradients\nand achieves better accuracy in given fixed wall-time.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:17:56 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 15:36:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhou", "Yuhao", ""], ["Ye", "Qing", ""], ["Zhang", "Hailun", ""], ["Lv", "Jiancheng", ""]]}, {"id": "2009.02704", "submitter": "Zhen Yuan", "authors": "Zhen Yuan, Esther Puyol-Anton, Haran Jogeesvaran, Catriona Reid, Baba\n  Inusa, Andrew P. King", "title": "Deep Learning for Automatic Spleen Length Measurement in Sickle Cell\n  Disease Patients", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sickle Cell Disease (SCD) is one of the most common genetic diseases in the\nworld. Splenomegaly (abnormal enlargement of the spleen) is frequent among\nchildren with SCD. If left untreated, splenomegaly can be life-threatening. The\ncurrent workflow to measure spleen size includes palpation, possibly followed\nby manual length measurement in 2D ultrasound imaging. However, this manual\nmeasurement is dependent on operator expertise and is subject to intra- and\ninter-observer variability. We investigate the use of deep learning to perform\nautomatic estimation of spleen length from ultrasound images. We investigate\ntwo types of approach, one segmentation-based and one based on direct length\nestimation, and compare the results against measurements made by human experts.\nOur best model (segmentation-based) achieved a percentage length error of\n7.42%, which is approaching the level of inter-observer variability\n(5.47%-6.34%). To the best of our knowledge, this is the first attempt to\nmeasure spleen size in a fully automated way from ultrasound images.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:47:49 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yuan", "Zhen", ""], ["Puyol-Anton", "Esther", ""], ["Jogeesvaran", "Haran", ""], ["Reid", "Catriona", ""], ["Inusa", "Baba", ""], ["King", "Andrew P.", ""]]}, {"id": "2009.02707", "submitter": "Bryan M. Li", "authors": "Bryan M. Li, Theoklitos Amvrosiadis, Nathalie Rochefort, Arno Onken", "title": "CalciumGAN: A Generative Adversarial Network Model for Synthesising\n  Realistic Calcium Imaging Data of Neuronal Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging has become a powerful and popular technique to monitor the\nactivity of large populations of neurons in vivo. However, for ethical\nconsiderations and despite recent technical developments, recordings are still\nconstrained to a limited number of trials and animals. This limits the amount\nof data available from individual experiments and hinders the development of\nanalysis techniques and models for more realistic size of neuronal populations.\nThe ability to artificially synthesize realistic neuronal calcium signals could\ngreatly alleviate this problem by scaling up the number of trials. Here we\npropose a Generative Adversarial Network (GAN) model to generate realistic\ncalcium signals as seen in neuronal somata with calcium imaging. To this end,\nwe adapt the WaveGAN architecture and train it with the Wasserstein distance.\nWe test the model on artificial data with known ground-truth and show that the\ndistribution of the generated signals closely resembles the underlying data\ndistribution. Then, we train the model on real calcium signals recorded from\nthe primary visual cortex of behaving mice and confirm that the deconvolved\nspike trains match the statistics of the recorded data. Together, these results\ndemonstrate that our model can successfully generate realistic calcium imaging\ndata, thereby providing the means to augment existing datasets of neuronal\nactivity for enhanced data exploration and modeling.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:58:11 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 03:58:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Li", "Bryan M.", ""], ["Amvrosiadis", "Theoklitos", ""], ["Rochefort", "Nathalie", ""], ["Onken", "Arno", ""]]}, {"id": "2009.02708", "submitter": "Diogo R. Ferreira", "authors": "Diogo R. Ferreira, Pedro J. Carvalho, Carlo Sozzi, Peter J. Lomas, JET\n  Contributors", "title": "Deep Learning for the Analysis of Disruption Precursors based on Plasma\n  Tomography", "comments": "(to appear)", "journal-ref": "Fusion Science and Technology, 2020", "doi": null, "report-no": null, "categories": "physics.plasm-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The JET baseline scenario is being developed to achieve high fusion\nperformance and sustained fusion power. However, with higher plasma current and\nhigher input power, an increase in pulse disruptivity is being observed.\nAlthough there is a wide range of possible disruption causes, the present\ndisruptions seem to be closely related to radiative phenomena such as impurity\naccumulation, core radiation, and radiative collapse. In this work, we focus on\nbolometer tomography to reconstruct the plasma radiation profile and, on top of\nit, we apply anomaly detection to identify the radiation patterns that precede\nmajor disruptions. The approach makes extensive use of machine learning. First,\nwe train a surrogate model for plasma tomography based on matrix\nmultiplication, which provides a fast method to compute the plasma radiation\nprofiles across the full extent of any given pulse. Then, we train a\nvariational autoencoder to reproduce the radiation profiles by encoding them\ninto a latent distribution and subsequently decoding them. As an anomaly\ndetector, the variational autoencoder struggles to reproduce unusual behaviors,\nwhich includes not only the actual disruptions but their precursors as well.\nThese precursors are identified based on an analysis of the anomaly score\nacross all baseline pulses in two recent campaigns at JET.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 11:06:52 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:27:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ferreira", "Diogo R.", ""], ["Carvalho", "Pedro J.", ""], ["Sozzi", "Carlo", ""], ["Lomas", "Peter J.", ""], ["Contributors", "JET", ""]]}, {"id": "2009.02709", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Olivier Fercoq and Joseph Salmon", "title": "Screening Rules and its Complexity for Active Set Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening rules were recently introduced as a technique for explicitly\nidentifying active structures such as sparsity, in optimization problem arising\nin machine learning. This has led to new methods of acceleration based on a\nsubstantial dimension reduction. We show that screening rules stem from a\ncombination of natural properties of subdifferential sets and optimality\nconditions, and can hence be understood in a unified way. Under mild\nassumptions, we analyze the number of iterations needed to identify the optimal\nactive set for any converging algorithm. We show that it only depends on its\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 11:10:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Fercoq", "Olivier", ""], ["Salmon", "Joseph", ""]]}, {"id": "2009.02713", "submitter": "T. Konstantin Rusch", "authors": "M. Longo, S. Mishra, T. K. Rusch, Ch. Schwab", "title": "Higher-order Quasi-Monte Carlo Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithmic approach and an error analysis leveraging\nQuasi-Monte Carlo points for training deep neural network (DNN) surrogates of\nData-to-Observable (DtO) maps in engineering design. Our analysis reveals\nhigher-order consistent, deterministic choices of training points in the input\ndata space for deep and shallow Neural Networks with holomorphic activation\nfunctions such as tanh. These novel training points are proved to facilitate\nhigher-order decay (in terms of the number of training samples) of the\nunderlying generalization error, with consistency error bounds that are free\nfrom the curse of dimensionality in the input data space, provided that DNN\nweights in hidden layers satisfy certain summability conditions. We present\nnumerical experiments for DtO maps from elliptic and parabolic PDEs with\nuncertain inputs that confirm the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 11:31:42 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Longo", "M.", ""], ["Mishra", "S.", ""], ["Rusch", "T. K.", ""], ["Schwab", "Ch.", ""]]}, {"id": "2009.02728", "submitter": "Kailash Budhathoki", "authors": "Kailash Budhathoki, Mario Boley and Jilles Vreeken", "title": "Discovering Reliable Causal Rules", "comments": "Poster presented in NeurIPS 2018 Workshop on Causal Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of deriving policies, or rules, that when enacted on a\ncomplex system, cause a desired outcome. Absent the ability to perform\ncontrolled experiments, such rules have to be inferred from past observations\nof the system's behaviour. This is a challenging problem for two reasons:\nFirst, observational effects are often unrepresentative of the underlying\ncausal effect because they are skewed by the presence of confounding factors.\nSecond, naive empirical estimations of a rule's effect have a high variance,\nand, hence, their maximisation can lead to random results.\n  To address these issues, first we measure the causal effect of a rule from\nobservational data---adjusting for the effect of potential confounders.\nImportantly, we provide a graphical criteria under which causal rule discovery\nis possible. Moreover, to discover reliable causal rules from a sample, we\npropose a conservative and consistent estimator of the causal effect, and\nderive an efficient and exact algorithm that maximises the estimator. On\nsynthetic data, the proposed estimator converges faster to the ground truth\nthan the naive estimator and recovers relevant causal rules even at small\nsample sizes. Extensive experiments on a variety of real-world datasets show\nthat the proposed algorithm is efficient and discovers meaningful rules.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:08:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 07:53:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Budhathoki", "Kailash", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "2009.02731", "submitter": "Nghi D. Q. Bui", "authors": "Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang", "title": "Self-Supervised Contrastive Learning for Code Retrieval and\n  Summarization via Semantic-Preserving Transformations", "comments": "Accepted at SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462840", "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Corder, a self-supervised contrastive learning framework for\nsource code model. Corder is designed to alleviate the need of labeled data for\ncode retrieval and code summarization tasks. The pre-trained model of Corder\ncan be used in two ways: (1) it can produce vector representation of code which\ncan be applied to code retrieval tasks that do not have labeled data; (2) it\ncan be used in a fine-tuning process for tasks that might still require label\ndata such as code summarization. The key innovation is that we train the source\ncode model by asking it to recognize similar and dissimilar code snippets\nthrough a contrastive learning objective. To do so, we use a set of\nsemantic-preserving transformation operators to generate code snippets that are\nsyntactically diverse but semantically equivalent. Through extensive\nexperiments, we have shown that the code models pretrained by Corder\nsubstantially outperform the other baselines for code-to-code retrieval,\ntext-to-code retrieval, and code-to-text summarization tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:31:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 05:38:39 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 12:12:51 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 11:46:56 GMT"}, {"version": "v5", "created": "Wed, 20 Jan 2021 09:49:11 GMT"}, {"version": "v6", "created": "Sun, 2 May 2021 19:25:45 GMT"}, {"version": "v7", "created": "Mon, 17 May 2021 18:01:27 GMT"}, {"version": "v8", "created": "Sun, 23 May 2021 12:10:55 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Yu", "Yijun", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "2009.02738", "submitter": "Chuanxi Chen", "authors": "Dengpan Ye, Chuanxi Chen, Changrui Liu, Hao Wang, Shunzhi Jiang", "title": "Detection Defense Against Adversarial Attacks with Saliency Map", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well established that neural networks are vulnerable to adversarial\nexamples, which are almost imperceptible on human vision and can cause the deep\nmodels misbehave. Such phenomenon may lead to severely inestimable consequences\nin the safety and security critical applications. Existing defenses are trend\nto harden the robustness of models against adversarial attacks, e.g.,\nadversarial training technology. However, these are usually intractable to\nimplement due to the high cost of re-training and the cumbersome operations of\naltering the model architecture or parameters. In this paper, we discuss the\nsaliency map method from the view of enhancing model interpretability, it is\nsimilar to introducing the mechanism of the attention to the model, so as to\ncomprehend the progress of object identification by the deep networks. We then\npropose a novel method combined with additional noises and utilize the\ninconsistency strategy to detect adversarial examples. Our experimental results\nof some representative adversarial attacks on common datasets including\nImageNet and popular models show that our method can detect all the attacks\nwith high detection success rate effectively. We compare it with the existing\nstate-of-the-art technique, and the experiments indicate that our method is\nmore general.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:57:17 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ye", "Dengpan", ""], ["Chen", "Chuanxi", ""], ["Liu", "Changrui", ""], ["Wang", "Hao", ""], ["Jiang", "Shunzhi", ""]]}, {"id": "2009.02743", "submitter": "Teodor Cotet", "authors": "Stefan Ruseti, Teodor-Mihai Cotet and Mihai Dascalu", "title": "Romanian Diacritics Restoration Using Recurrent Neural Networks", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diacritics restoration is a mandatory step for adequately processing Romanian\ntexts, and not a trivial one, as you generally need context in order to\nproperly restore a character. Most previous methods which were experimented for\nRomanian restoration of diacritics do not use neural networks. Among those that\ndo, there are no solutions specifically optimized for this particular language\n(i.e., they were generally designed to work on many different languages).\nTherefore we propose a novel neural architecture based on recurrent neural\nnetworks that can attend information at different levels of abstractions in\norder to restore diacritics.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 14:20:35 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ruseti", "Stefan", ""], ["Cotet", "Teodor-Mihai", ""], ["Dascalu", "Mihai", ""]]}, {"id": "2009.02752", "submitter": "Guohao Lan", "authors": "Dong Ma, Guohao Lan, Weitao Xu, Mahbub Hassan, Wen Hu", "title": "Simultaneous Energy Harvesting and Gait Recognition using Piezoelectric\n  Energy Harvester", "comments": "13 pages, 17 figures, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piezoelectric energy harvester, which generates electricity from stress or\nvibrations, is gaining increasing attention as a viable solution to extend\nbattery life in wearables. Recent research further reveals that, besides\ngenerating energy, PEH can also serve as a passive sensor to detect human gait\npower-efficiently because its stress or vibration patterns are significantly\ninfluenced by the gait. However, as PEHs are not designed for precise\nmeasurement of motion, achievable gait recognition accuracy remains low with\nconventional classification algorithms. The accuracy deteriorates further when\nthe generated electricity is stored simultaneously. To classify gait reliably\nwhile simultaneously storing generated energy, we make two distinct\ncontributions. First, we propose a preprocessing algorithm to filter out the\neffect of energy storage on PEH electricity signal. Second, we propose a long\nshort-term memory (LSTM) network-based classifier to accurately capture\ntemporal information in gait-induced electricity generation. We prototype the\nproposed gait recognition architecture in the form factor of an insole and\nevaluate its gait recognition as well as energy harvesting performance with 20\nsubjects. Our results show that the proposed architecture detects human gait\nwith 12% higher recall and harvests up to 127% more energy while consuming 38%\nless power compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:12:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ma", "Dong", ""], ["Lan", "Guohao", ""], ["Xu", "Weitao", ""], ["Hassan", "Mahbub", ""], ["Hu", "Wen", ""]]}, {"id": "2009.02755", "submitter": "Boris Lorbeer", "authors": "Boris Lorbeer, Max Botler", "title": "Anomaly Detection With Partitioning Overfitting Autoencoder Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose POTATOES (Partitioning OverfiTting AuTOencoder\nEnSemble), a new method for unsupervised outlier detection (UOD). More\nprecisely, given any autoencoder for UOD, this technique can be used to improve\nits accuracy while at the same time removing the burden of tuning its\nregularization. The idea is to not regularize at all, but to rather randomly\npartition the data into sufficiently many equally sized parts, overfit each\npart with its own autoencoder, and to use the maximum over all autoencoder\nreconstruction errors as the anomaly score. We apply our model to various\nrealistic datasets and show that if the set of inliers is dense enough, our\nmethod indeed improves the UOD performance of a given autoencoder\nsignificantly. For reproducibility, the code is made available on github so the\nreader can recreate the results in this paper as well as apply the method to\nother autoencoders and datasets.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:35:53 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 14:58:15 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 07:53:58 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 05:55:18 GMT"}, {"version": "v5", "created": "Wed, 28 Apr 2021 14:23:07 GMT"}, {"version": "v6", "created": "Sun, 4 Jul 2021 05:14:50 GMT"}, {"version": "v7", "created": "Fri, 9 Jul 2021 04:40:04 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lorbeer", "Boris", ""], ["Botler", "Max", ""]]}, {"id": "2009.02762", "submitter": "Yue Yang", "authors": "Yue Yang, Wencang Bao, Mohsen Ramezani, Zhe Xu", "title": "Real-time and Large-scale Fleet Allocation of Autonomous Taxis: A Case\n  Study in New York Manhattan Island", "comments": "Double-check the formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous taxis become a highly promising transportation mode,\nwhich helps relieve traffic congestion and avoid road accidents. However, it\nhinders the wide implementation of this service that traditional models fail to\nefficiently allocate the available fleet to deal with the imbalance of supply\n(autonomous taxis) and demand (trips), the poor cooperation of taxis, hardly\nsatisfied resource constraints, and on-line platform's requirements. To figure\nout such urgent problems from a global and more farsighted view, we employ a\nConstrained Multi-agent Markov Decision Processes (CMMDP) to model fleet\nallocation decisions, which can be easily split into sub-problems formulated as\na 'Dynamic assignment problem' combining both immediate rewards and future\ngains. We also leverage a Column Generation algorithm to guarantee the\nefficiency and optimality in a large scale. Through extensive experiments, the\nproposed approach not only achieves remarkable improvements over the\nstate-of-the-art benchmarks in terms of the individual's efficiency (arriving\nat 12.40%, 6.54% rise of income and utilization, respectively) and the\nplatform's profit (reaching 4.59% promotion) but also reveals a time-varying\nfleet adjustment policy to minimize the operation cost of the platform.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:00:15 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 01:46:34 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Yang", "Yue", ""], ["Bao", "Wencang", ""], ["Ramezani", "Mohsen", ""], ["Xu", "Zhe", ""]]}, {"id": "2009.02763", "submitter": "Hao Li", "authors": "Chang Wang, Jian Liang, Mingkai Huang, Bing Bai, Kun Bai, Hao Li", "title": "Hybrid Differentially Private Federated Learning on Vertically\n  Partitioned Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HDP-VFL, the first hybrid differentially private (DP) framework\nfor vertical federated learning (VFL) to demonstrate that it is possible to\njointly learn a generalized linear model (GLM) from vertically partitioned data\nwith only a negligible cost, w.r.t. training time, accuracy, etc., comparing to\nidealized non-private VFL. Our work builds on the recent advances in VFL-based\ncollaborative training among different organizations which rely on protocols\nlike Homomorphic Encryption (HE) and Secure Multi-Party Computation (MPC) to\nsecure computation and training. In particular, we analyze how VFL's\nintermediate result (IR) can leak private information of the training data\nduring communication and design a DP-based privacy-preserving algorithm to\nensure the data confidentiality of VFL participants. We mathematically prove\nthat our algorithm not only provides utility guarantees for VFL, but also\noffers multi-level privacy, i.e. DP w.r.t. IR and joint differential privacy\n(JDP) w.r.t. model weights. Experimental results demonstrate that our work,\nunder adequate privacy budgets, is quantitatively and qualitatively similar to\nGLMs, learned in idealized non-private VFL setting, rather than the increased\ncost in memory and processing time in most prior works based on HE or MPC. Our\ncodes will be released if this paper is accepted.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:06:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Chang", ""], ["Liang", "Jian", ""], ["Huang", "Mingkai", ""], ["Bai", "Bing", ""], ["Bai", "Kun", ""], ["Li", "Hao", ""]]}, {"id": "2009.02773", "submitter": "Zinan Lin", "authors": "Zinan Lin, Vyas Sekar, Giulia Fanti", "title": "Why Spectral Normalization Stabilizes GANs: Analysis and Improvements", "comments": "54 pages, 74 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral normalization (SN) is a widely-used technique for improving the\nstability and sample quality of Generative Adversarial Networks (GANs).\nHowever, there is currently limited understanding of why SN is effective. In\nthis work, we show that SN controls two important failure modes of GAN\ntraining: exploding and vanishing gradients. Our proofs illustrate a (perhaps\nunintentional) connection with the successful LeCun initialization. This\nconnection helps to explain why the most popular implementation of SN for GANs\nrequires no hyper-parameter tuning, whereas stricter implementations of SN have\npoor empirical performance out-of-the-box. Unlike LeCun initialization which\nonly controls gradient vanishing at the beginning of training, SN preserves\nthis property throughout training. Building on this theoretical understanding,\nwe propose a new spectral normalization technique: Bidirectional Scaled\nSpectral Normalization (BSSN), which incorporates insights from later\nimprovements to LeCun initialization: Xavier initialization and Kaiming\ninitialization. Theoretically, we show that BSSN gives better gradient control\nthan SN. Empirically, we demonstrate that it outperforms SN in sample quality\nand training stability on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:51:42 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 00:29:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Lin", "Zinan", ""], ["Sekar", "Vyas", ""], ["Fanti", "Giulia", ""]]}, {"id": "2009.02784", "submitter": "Seyedeh Niusha Alavi Foumani", "authors": "Seyedeh Niusha Alavi Foumani, Ce Guo, Wayne Luk", "title": "An FPGA Accelerated Method for Training Feed-forward Neural Networks\n  Using Alternating Direction Method of Multipliers and LSMR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we have successfully designed, implemented, deployed and\ntested a novel FPGA accelerated algorithm for neural network training. The\nalgorithm itself was developed in an independent study option. This training\nmethod is based on Alternating Direction Method of Multipliers algorithm, which\nhas strong parallel characteristics and avoids procedures such as matrix\ninversion that are problematic in hardware designs by employing LSMR. As an\nintermediate stage, we fully implemented the ADMM-LSMR method in C language for\nfeed-forward neural networks with a flexible number of layers and hidden size.\nWe demonstrated that the method can operate with fixed-point arithmetic without\ncompromising the accuracy. Next, we devised an FPGA accelerated version of the\nalgorithm using Intel FPGA SDK for OpenCL and performed extensive optimisation\nstages followed by successful deployment of the program on an Intel Arria 10 GX\nFPGA. The FPGA accelerated program showed up to 6 times speed up comparing to\nequivalent CPU implementation while achieving promising accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 17:33:03 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Foumani", "Seyedeh Niusha Alavi", ""], ["Guo", "Ce", ""], ["Luk", "Wayne", ""]]}, {"id": "2009.02791", "submitter": "Gourab Ghatak", "authors": "Gourab Ghatak", "title": "A Change-Detection Based Thompson Sampling Framework for Non-Stationary\n  Bandits", "comments": "Accepted for publication in IEEE Transactions on Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-stationary two-armed bandit framework and propose a\nchange-detection based Thompson sampling (TS) algorithm, named TS with\nchange-detection (TS-CD), to keep track of the dynamic environment. The\nnon-stationarity is modeled using a Poisson arrival process, which changes the\nmean of the rewards on each arrival. The proposed strategy compares the\nempirical mean of the recent rewards of an arm with the estimate of the mean of\nthe rewards from its history. It detects a change when the empirical mean\ndeviates from the mean estimate by a value larger than a threshold. Then, we\ncharacterize the lower bound on the duration of the time-window for which the\nbandit framework must remain stationary for TS-CD to successfully detect a\nchange when it occurs. Consequently, our results highlight an upper bound on\nthe parameter for the Poisson arrival process, for which the TS-CD achieves\nasymptotic regret optimality with high probability. Finally, we validate the\nefficacy of TS-CD by testing it for edge-control of radio access technique\n(RAT)-selection in a wireless network. Our results show that TS-CD not only\noutperforms the classical max-power RAT selection strategy but also other\nactively adaptive and passively adaptive bandit algorithms that are designed\nfor non-stationary environments.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 18:12:25 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ghatak", "Gourab", ""]]}, {"id": "2009.02799", "submitter": "Pietro Barbiero", "authors": "Giansalvo Cirrincione, Pietro Barbiero, Gabriele Ciravegna, Vincenzo\n  Randazzo", "title": "Gradient-based Competitive Learning: Theory", "comments": "18 pages. arXiv admin note: text overlap with arXiv:2008.09477", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been widely used for supervised learning and\nclassification/regression problems. Recently, a novel area of research has\napplied this paradigm to unsupervised tasks; indeed, a gradient-based approach\nextracts, efficiently and autonomously, the relevant features for handling\ninput data. However, state-of-the-art techniques focus mostly on algorithmic\nefficiency and accuracy rather than mimic the input manifold. On the contrary,\ncompetitive learning is a powerful tool for replicating the input distribution\ntopology. This paper introduces a novel perspective in this area by combining\nthese two techniques: unsupervised gradient-based and competitive learning. The\ntheory is based on the intuition that neural networks are able to learn\ntopological structures by working directly on the transpose of the input\nmatrix. At this purpose, the vanilla competitive layer and its dual are\npresented. The former is just an adaptation of a standard competitive layer for\ndeep clustering, while the latter is trained on the transposed matrix. Their\nequivalence is extensively proven both theoretically and experimentally.\nHowever, the dual layer is better suited for handling very high-dimensional\ndatasets. The proposed approach has a great potential as it can be generalized\nto a vast selection of topological learning tasks, such as non-stationary and\nhierarchical clustering; furthermore, it can also be integrated within more\ncomplex architectures such as autoencoders and generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 19:00:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Cirrincione", "Giansalvo", ""], ["Barbiero", "Pietro", ""], ["Ciravegna", "Gabriele", ""], ["Randazzo", "Vincenzo", ""]]}, {"id": "2009.02814", "submitter": "Akhil Mathur", "authors": "Akhil Mathur, Fahim Kawsar, Nadia Berthouze, Nicholas D. Lane", "title": "Libri-Adapt: A New Speech Dataset for Unsupervised Domain Adaptation", "comments": "5 pages, Published at IEEE ICASSP 2020", "journal-ref": "2020 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7439-7443", "doi": "10.1109/ICASSP40776.2020.9053074", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a new dataset, Libri-Adapt, to support unsupervised\ndomain adaptation research on speech recognition models. Built on top of the\nLibriSpeech corpus, Libri-Adapt contains English speech recorded on mobile and\nembedded-scale microphones, and spans 72 different domains that are\nrepresentative of the challenging practical scenarios encountered by ASR\nmodels. More specifically, Libri-Adapt facilitates the study of domain shifts\nin ASR models caused by a) different acoustic environments, b) variations in\nspeaker accents, c) heterogeneity in the hardware and platform software of the\nmicrophones, and d) a combination of the aforementioned three shifts. We also\nprovide a number of baseline results quantifying the impact of these domain\nshifts on the Mozilla DeepSpeech2 ASR model.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 20:47:20 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Mathur", "Akhil", ""], ["Kawsar", "Fahim", ""], ["Berthouze", "Nadia", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2009.02825", "submitter": "Seyedeh Niusha Alavi Foumani", "authors": "Seyedeh Niusha Alavi Foumani, Ce Guo, Wayne Luk", "title": "An Analysis of Alternating Direction Method of Multipliers for\n  Feed-forward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a hardware compatible neural network training\nalgorithm in which we used alternating direction method of multipliers (ADMM)\nand iterative least-square methods. The motive behind this approach was to\nconduct a method of training neural networks that is scalable and can be\nparallelised. These characteristics make this algorithm suitable for hardware\nimplementation. We have achieved 6.9\\% and 6.8\\% better accuracy comparing to\nSGD and Adam respectively, with a four-layer neural network with hidden size of\n28 on HIGGS dataset. Likewise, we could observe 21.0\\% and 2.2\\% accuracy\nimprovement comparing to SGD and Adam respectively, on IRIS dataset with a\nthree-layer neural network with hidden size of 8. This is while the use of\nmatrix inversion, which is challenging for hardware implementation, is avoided\nin this method. We assessed the impact of avoiding matrix inversion on ADMM\naccuracy and we observed that we can safely replace matrix inversion with\niterative least-square methods and maintain the desired performance. Also, the\ncomputational complexity of the implemented method is polynomial regarding\ndimensions of the input dataset and hidden size of the network.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 22:13:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Foumani", "Seyedeh Niusha Alavi", ""], ["Guo", "Ce", ""], ["Luk", "Wayne", ""]]}, {"id": "2009.02827", "submitter": "Po Yang Dr", "authors": "Po Yang, Jun Qi, Xulong Wang, Yun Yang", "title": "MFL_COVID19: Quantifying Country-based Factors affecting Case Fatality\n  Rate in Early Phase of COVID-19 Epidemic via Regularised Multi-task Feature\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent outbreak of COVID-19 has led a rapid global spread around the world.\nMany countries have implemented timely intensive suppression to minimize the\ninfections, but resulted in high case fatality rate (CFR) due to critical\ndemand of health resources. Other country-based factors such as sociocultural\nissues, ageing population etc., has also influenced practical effectiveness of\ntaking interventions to improve morality in early phase. To better understand\nthe relationship of these factors across different countries with COVID-19 CFR\nis of primary importance to prepare for potentially second wave of COVID-19\ninfections. In the paper, we propose a novel regularized multi-task learning\nbased factor analysis approach for quantifying country-based factors affecting\nCFR in early phase of COVID-19 epidemic. We formulate the prediction of CFR\nprogression as a ML regression problem with observed CFR and other\ncountries-based factors. In this formulation, all CFR related factors were\ncategorized into 6 sectors with 27 indicators. We proposed a hybrid feature\nselection method combining filter, wrapper and tree-based models to calibrate\ninitial factors for a preliminary feature interaction. Then we adopted two\ntypical single task model (Ridge and Lasso regression) and one state-of-the-art\nMTFL method (fused sparse group lasso) in our formulation. The fused sparse\ngroup Lasso (FSGL) method allows the simultaneous selection of a common set of\ncountry-based factors for multiple time points of COVID-19 epidemic and also\nenables incorporating temporal smoothness of each factor over the whole early\nphase period. Finally, we proposed one novel temporal voting feature selection\nscheme to balance the weight instability of multiple factors in our MTFL model.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 22:34:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yang", "Po", ""], ["Qi", "Jun", ""], ["Wang", "Xulong", ""], ["Yang", "Yun", ""]]}, {"id": "2009.02835", "submitter": "Denghui Zhang", "authors": "Denghui Zhang, Zixuan Yuan, Yanchi Liu, Zuohui Fu, Fuzhen Zhuang,\n  Pengyang Wang, Haifeng Chen, Hui Xiong", "title": "E-BERT: A Phrase and Product Knowledge Enhanced Language Model for\n  E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have achieved great success in a\nbroad range of natural language processing tasks. However, BERT cannot well\nsupport E-commerce related tasks due to the lack of two levels of domain\nknowledge, i.e., phrase-level and product-level. On one hand, many E-commerce\ntasks require an accurate understanding of domain phrases, whereas such\nfine-grained phrase-level knowledge is not explicitly modeled by BERT's\ntraining objective. On the other hand, product-level knowledge like product\nassociations can enhance the language modeling of E-commerce, but they are not\nfactual knowledge thus using them indiscriminately may introduce noise. To\ntackle the problem, we propose a unified pre-training framework, namely,\nE-BERT. Specifically, to preserve phrase-level knowledge, we introduce Adaptive\nHybrid Masking, which allows the model to adaptively switch from learning\npreliminary word knowledge to learning complex phrases, based on the fitting\nprogress of two modes. To utilize product-level knowledge, we introduce\nNeighbor Product Reconstruction, which trains E-BERT to predict a product's\nassociated neighbors with a denoising cross attention layer. Our investigation\nreveals promising results in four downstream tasks, i.e., review-based question\nanswering, aspect extraction, aspect sentiment classification, and product\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 00:15:36 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 23:00:16 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Zhang", "Denghui", ""], ["Yuan", "Zixuan", ""], ["Liu", "Yanchi", ""], ["Fu", "Zuohui", ""], ["Zhuang", "Fuzhen", ""], ["Wang", "Pengyang", ""], ["Chen", "Haifeng", ""], ["Xiong", "Hui", ""]]}, {"id": "2009.02845", "submitter": "Hui Li", "authors": "Yuqiu Qian, Conghui Tan, Danhao Ding, Hui Li, Nikos Mamoulis", "title": "Fast and Secure Distributed Nonnegative Matrix Factorization", "comments": "Published in IEEE Transactions on Knowledge and Data Engineering\n  (TKDE). This arXiv version includes the appendices with additional proofs", "journal-ref": null, "doi": "10.1109/TKDE.2020.2985964", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has been successfully applied in\nseveral data mining tasks. Recently, there is an increasing interest in the\nacceleration of NMF, due to its high cost on large matrices. On the other hand,\nthe privacy issue of NMF over federated data is worthy of attention, since NMF\nis prevalently applied in image and text analysis which may involve leveraging\nprivacy data (e.g, medical image and record) across several parties (e.g.,\nhospitals). In this paper, we study the acceleration and security problems of\ndistributed NMF. Firstly, we propose a distributed sketched alternating\nnonnegative least squares (DSANLS) framework for NMF, which utilizes a matrix\nsketching technique to reduce the size of nonnegative least squares subproblems\nwith a convergence guarantee. For the second problem, we show that DSANLS with\nmodification can be adapted to the security setting, but only for one or\nlimited iterations. Consequently, we propose four efficient distributed NMF\nmethods in both synchronous and asynchronous settings with a security\nguarantee. We conduct extensive experiments on several real datasets to show\nthe superiority of our proposed methods. The implementation of our methods is\navailable at https://github.com/qianyuqiu79/DSANLS.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 01:12:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Qian", "Yuqiu", ""], ["Tan", "Conghui", ""], ["Ding", "Danhao", ""], ["Li", "Hui", ""], ["Mamoulis", "Nikos", ""]]}, {"id": "2009.02857", "submitter": "Dongho Choi", "authors": "Dongho Choi", "title": "3D Room Layout Estimation Beyond the Manhattan World Assumption", "comments": "3rd Place @ ECCV 2020 Holistic Scene Structures for 3D Vision\n  Workshop Challenges Track 1; 6 pages with 3 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting 3D room layout from single image is a challenging task with many\napplications. In this paper, we propose a new training and post-processing\nmethod for 3D room layout estimation, built on a recent state-of-the-art 3D\nroom layout estimation model. Experimental results show our method outperforms\nstate-of-the-art approaches by a large margin in predicting visible room\nlayout. Our method has obtained the 3rd place in 2020 Holistic Scene Structures\nfor 3D Vision Workshop.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 02:14:29 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Choi", "Dongho", ""]]}, {"id": "2009.02859", "submitter": "Khanh Luong", "authors": "Khanh Luong and Richi Nayak", "title": "Learning Inter- and Intra-manifolds for Matrix Factorization-based\n  Multi-Aspect Data Clustering", "comments": "15 pages with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering on the data with multiple aspects, such as multi-view or\nmulti-type relational data, has become popular in recent years due to their\nwide applicability. The approach using manifold learning with the Non-negative\nMatrix Factorization (NMF) framework, that learns the accurate low-rank\nrepresentation of the multi-dimensional data, has shown effectiveness. We\npropose to include the inter-manifold in the NMF framework, utilizing the\ndistance information of data points of different data types (or views) to learn\nthe diverse manifold for data clustering. Empirical analysis reveals that the\nproposed method can find partial representations of various interrelated types\nand select useful features during clustering. Results on several datasets\ndemonstrate that the proposed method outperforms the state-of-the-art\nmulti-aspect data clustering methods in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 02:21:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Luong", "Khanh", ""], ["Nayak", "Richi", ""]]}, {"id": "2009.02874", "submitter": "Shankar Deka", "authors": "Shankar A. Deka and Du\\v{s}an M. Stipanovi\\'c and Claire J. Tomlin", "title": "Dynamically Computing Adversarial Perturbations for Recurrent Neural\n  Networks", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional and recurrent neural networks have been widely employed to\nachieve state-of-the-art performance on classification tasks. However, it has\nalso been noted that these networks can be manipulated adversarially with\nrelative ease, by carefully crafted additive perturbations to the input. Though\nseveral experimentally established prior works exist on crafting and defending\nagainst attacks, it is also desirable to have theoretical guarantees on the\nexistence of adversarial examples and robustness margins of the network to such\nexamples. We provide both in this paper. We focus specifically on recurrent\narchitectures and draw inspiration from dynamical systems theory to naturally\ncast this as a control problem, allowing us to dynamically compute adversarial\nperturbations at each timestep of the input sequence, thus resembling a\nfeedback controller. Illustrative examples are provided to supplement the\ntheoretical discussions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 03:37:03 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Deka", "Shankar A.", ""], ["Stipanovi\u0107", "Du\u0161an M.", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "2009.02880", "submitter": "Xiancai Tian", "authors": "Xiancai Tian, Chen Zhang, Baihua Zheng", "title": "Crowding Prediction of In-Situ Metro Passengers Using Smart Card Data", "comments": "11 pages, preprint for IEEE transactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The metro system is playing an increasingly important role in the urban\npublic transit network, transferring a massive human flow across space everyday\nin the city. In recent years, extensive research studies have been conducted to\nimprove the service quality of metro systems. Among them, crowd management has\nbeen a critical issue for both public transport agencies and train operators.\nIn this paper, by utilizing accumulated smart card data, we propose a\nstatistical model to predict in-situ passenger density, i.e., number of\non-board passengers between any two neighbouring stations, inside a closed\nmetro system. The proposed model performs two main tasks: i) forecasting\ntime-dependent Origin-Destination (OD) matrix by applying mature statistical\nmodels; and ii) estimating the travel time cost required by different parts of\nthe metro network via truncated normal mixture distributions with\nExpectation-Maximization (EM) algorithm. Based on the prediction results, we\nare able to provide accurate prediction of in-situ passenger density for a\nfuture time point. A case study using real smart card data in Singapore Mass\nRapid Transit (MRT) system demonstrate the efficacy and efficiency of our\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 04:07:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Tian", "Xiancai", ""], ["Zhang", "Chen", ""], ["Zheng", "Baihua", ""]]}, {"id": "2009.02895", "submitter": "Maryam Abdirad", "authors": "Maryam Abdirad, Jamal Shahrabi", "title": "Detecting Informal Organization Through Data Mining Techniques", "comments": "18 pages, 2 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main topics in human resources management is the subject of\ninformal organizations in the organization such that recognizing and managing\nsuch informal organizations play an important role in the organizations. Some\nmanagers are trying to recognize the relations between informal organizations\nand being a member of them by which they could assist the formal organization\ndevelopment. Methods of recognizing informal organizations are complicated and\noccasionally even impossible. This study aims to provide a method for\nrecognizing such organizations using data mining techniques. This study\nclassifies indices of human resources influencing the creation of informal\norganizations, including individual, social, and work characteristics of an\norganizations employees. Then, a questionnaire was designed and distributed\namong employees. A database was created from obtained data. Applied data mining\ntechniques in this study are factor analysis, clustering by K-means,\nclassification by decision trees, and finally association rule mining by GRI\nalgorithm. At the end, a model is presented that is applicable for recognizing\nthe similar characteristics between people for optimal recognition of informal\norganizations and usage of this information.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 05:42:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Abdirad", "Maryam", ""], ["Shahrabi", "Jamal", ""]]}, {"id": "2009.02903", "submitter": "Syed Anwar", "authors": "Sobia Yousaf, Syed Muhammad Anwar, Harish RaviPrakash, Ulas Bagci", "title": "Brain Tumor Survival Prediction using Radiomics Features", "comments": "Submitted to RNO Workshop at MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgery planning in patients diagnosed with brain tumor is dependent on their\nsurvival prognosis. A poor prognosis might demand for a more aggressive\ntreatment and therapy plan, while a favorable prognosis might enable a less\nrisky surgery plan. Thus, accurate survival prognosis is an important step in\ntreatment planning. Recently, deep learning approaches have been used\nextensively for brain tumor segmentation followed by the use of deep features\nfor prognosis. However, radiomics-based studies have shown more promise using\nengineered/hand-crafted features. In this paper, we propose a three-step\napproach for multi-class survival prognosis. In the first stage, we extract\nimage slices corresponding to tumor regions from multiple magnetic resonance\nimage modalities. We then extract radiomic features from these 2D slices.\nFinally, we train machine learning classifiers to perform the classification.\nWe evaluate our proposed approach on the publicly available BraTS 2019 data and\nachieve an accuracy of 76.5% and precision of 74.3% using the random forest\nclassifier, which to the best of our knowledge are the highest reported results\nyet. Further, we identify the most important features that contribute in\nimproving the prediction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:14:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yousaf", "Sobia", ""], ["Anwar", "Syed Muhammad", ""], ["RaviPrakash", "Harish", ""], ["Bagci", "Ulas", ""]]}, {"id": "2009.02905", "submitter": "Christian K\\\"ummerle", "authors": "Christian K\\\"ummerle, Claudio M. Verdun", "title": "Escaping Saddle Points in Ill-Conditioned Matrix Completion with a\n  Scalable Second Order Method", "comments": "15 pages, presented at the Workshop on \"Beyond first-order methods in\n  ML systems\" at the $37^th$ International Conference on Machine Learning\n  (ICML), Vienna, Austria, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an iterative algorithm for low-rank matrix completion that can be\ninterpreted as both an iteratively reweighted least squares (IRLS) algorithm\nand a saddle-escaping smoothing Newton method applied to a non-convex rank\nsurrogate objective. It combines the favorable data efficiency of previous IRLS\napproaches with an improved scalability by several orders of magnitude. Our\nmethod attains a local quadratic convergence rate already for a number of\nsamples that is close to the information theoretical limit. We show in\nnumerical experiments that unlike many state-of-the-art approaches, our\napproach is able to complete very ill-conditioned matrices with a condition\nnumber of up to $10^{10}$ from few samples.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:51:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["K\u00fcmmerle", "Christian", ""], ["Verdun", "Claudio M.", ""]]}, {"id": "2009.02909", "submitter": "Beomjo Shin", "authors": "Beomjo Shin, Junsu Cho, Hwanjo Yu, Seungjin Choi", "title": "Sparse Network Inversion for Key Instance Detection in Multiple Instance\n  Learning", "comments": "8 pages, 4 figures, in Proceedings of the 25th International\n  Conference on Pattern Recognition (ICPR-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Instance Learning (MIL) involves predicting a single label for a bag\nof instances, given positive or negative labels at bag-level, without accessing\nto label for each instance in the training phase. Since a positive bag contains\nboth positive and negative instances, it is often required to detect positive\ninstances (key instances) when a set of instances is categorized as a positive\nbag. The attention-based deep MIL model is a recent advance in both bag-level\nclassification and key instance detection (KID). However, if the positive and\nnegative instances in a positive bag are not clearly distinguishable, the\nattention-based deep MIL model has limited KID performance as the attention\nscores are skewed to few positive instances. In this paper, we present a method\nto improve the attention-based deep MIL model in the task of KID. The main idea\nis to use the neural network inversion to find which instances made\ncontribution to the bag-level prediction produced by the trained MIL model.\nMoreover, we incorporate a sparseness constraint into the neural network\ninversion, leading to the sparse network inversion which is solved by the\nproximal gradient method. Numerical experiments on an MNIST-based image MIL\ndataset and two real-world histopathology datasets verify the validity of our\nmethod, demonstrating the KID performance is significantly improved while the\nperformance of bag-level prediction is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:01:59 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 01:09:53 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Shin", "Beomjo", ""], ["Cho", "Junsu", ""], ["Yu", "Hwanjo", ""], ["Choi", "Seungjin", ""]]}, {"id": "2009.02913", "submitter": "Pietro Vischia", "authors": "Pietro Vischia", "title": "Unfolding by Folding: a resampling approach to the problem of matrix\n  inversion without actually inverting any matrix", "comments": "20 pages, 16 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix inversion problems are often encountered in experimental physics, and\nin particular in high-energy particle physics, under the name of unfolding. The\ntrue spectrum of a physical quantity is deformed by the presence of a detector,\nresulting in an observed spectrum. If we discretize both the true and observed\nspectra into histograms, we can model the detector response via a matrix.\nInferring a true spectrum starting from an observed spectrum requires therefore\ninverting the response matrix. Many methods exist in literature for this task,\nall starting from the observed spectrum and using a simulated true spectrum as\na guide to obtain a meaningful solution in cases where the response matrix is\nnot easily invertible.\n  In this Manuscript, I take a different approach to the unfolding problem.\nRather than inverting the response matrix and transforming the observed\ndistribution into the most likely parent distribution in generator space, I\nsample many distributions in generator space, fold them through the original\nresponse matrix, and pick the generator-level distribution that yields the\nfolded distribution closest to the data distribution. Regularization schemes\ncan be introduced to treat the case where non-diagonal response matrices result\nin high-frequency oscillations of the solution in true space, and the\nintroduced bias is studied.\n  The algorithm performs as well as traditional unfolding algorithms in cases\nwhere the inverse problem is well-defined in terms of the discretization of the\ntrue and smeared space, and outperforms them in cases where the inverse problem\nis ill-defined---when the number of truth-space bins is larger than that of\nsmeared-space bins. These advantages stem from the fact that the algorithm does\nnot technically invert any matrix and uses only the data distribution as a\nguide to choose the best solution.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:20:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Vischia", "Pietro", ""]]}, {"id": "2009.02931", "submitter": "Preslav Nakov", "authors": "Alex Nikolov, Giovanni Da San Martino, Ivan Koychev, and Preslav Nakov", "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "comments": "Check-worthiness; Fact-Checking; Veracity", "journal-ref": "CLEF-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 08:03:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Nikolov", "Alex", ""], ["Martino", "Giovanni Da San", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "2009.02955", "submitter": "Roy Mitz", "authors": "Roy Mitz, Yoel Shkolnisky", "title": "A perturbation based out-of-sample extension framework", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-sample extension is an important task in various kernel based\nnon-linear dimensionality reduction algorithms. In this paper, we derive a\nperturbation based extension framework by extending results from classical\nperturbation theory. We prove that our extension framework generalizes the\nwell-known Nystr{\\\"o}m method as well as some of its variants. We provide an\nerror analysis for our extension framework, and suggest new forms of extension\nunder this framework that take advantage of the structure of the kernel matrix.\nWe support our theoretical results numerically and demonstrate the advantages\nof our extension framework both on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:14:18 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Mitz", "Roy", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "2009.02961", "submitter": "Cemre Zor", "authors": "Sara Atito Ali Ahmed, Cemre Zor, Berrin Yanikoglu, Muhammad Awais,\n  Josef Kittler", "title": "Deep Convolutional Neural Network Ensembles using ECOC", "comments": "13 pages double column IEEE transactions style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have enhanced the performance of decision making systems\nin many applications including image understanding, and further gains can be\nachieved by constructing ensembles. However, designing an ensemble of deep\nnetworks is often not very beneficial since the time needed to train the\nnetworks is very high or the performance gain obtained is not very significant.\nIn this paper, we analyse error correcting output coding (ECOC) framework to be\nused as an ensemble technique for deep networks and propose different design\nstrategies to address the accuracy-complexity trade-off. We carry out an\nextensive comparative study between the introduced ECOC designs and the\nstate-of-the-art ensemble techniques such as ensemble averaging and gradient\nboosting decision trees. Furthermore, we propose a combinatory technique which\nis shown to achieve the highest classification performance amongst all.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:20:24 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:39:12 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ahmed", "Sara Atito Ali", ""], ["Zor", "Cemre", ""], ["Yanikoglu", "Berrin", ""], ["Awais", "Muhammad", ""], ["Kittler", "Josef", ""]]}, {"id": "2009.02967", "submitter": "Tiago Azevedo", "authors": "Tiago Azevedo, Ren\\'e de Jong, Matthew Mattina, Partha Maji", "title": "Stochastic-YOLO: Efficient Probabilistic Object Detection under Dataset\n  Shifts", "comments": "To appear in the Workshop on Machine Learning for Autonomous Driving\n  (ML4AD) at NeurIPS 2020. 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image classification tasks, the evaluation of models' robustness to\nincreased dataset shifts with a probabilistic framework is very well studied.\nHowever, object detection (OD) tasks pose other challenges for uncertainty\nestimation and evaluation. For example, one needs to evaluate both the quality\nof the label uncertainty (i.e., what?) and spatial uncertainty (i.e., where?)\nfor a given bounding box, but that evaluation cannot be performed with more\ntraditional average precision metrics (e.g., mAP). In this paper, we adapt the\nwell-established YOLOv3 architecture to generate uncertainty estimations by\nintroducing stochasticity in the form of Monte Carlo Dropout (MC-Drop), and\nevaluate it across different levels of dataset shift. We call this novel\narchitecture Stochastic-YOLO, and provide an efficient implementation to\neffectively reduce the burden of the MC-Drop sampling mechanism at inference\ntime. Finally, we provide some sensitivity analyses, while arguing that\nStochastic-YOLO is a sound approach that improves different components of\nuncertainty estimations, in particular spatial uncertainties.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:28:17 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 12:57:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Azevedo", "Tiago", ""], ["de Jong", "Ren\u00e9", ""], ["Mattina", "Matthew", ""], ["Maji", "Partha", ""]]}, {"id": "2009.02980", "submitter": "Guillaume Perez", "authors": "Guillaume Perez, Sebastian Ament, Carla Gomes, Michel Barlaud", "title": "Efficient Projection Algorithms onto the Weighted l1 Ball", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projected gradient descent has been proved efficient in many optimization and\nmachine learning problems. The weighted $\\ell_1$ ball has been shown effective\nin sparse system identification and features selection. In this paper we\npropose three new efficient algorithms for projecting any vector of finite\nlength onto the weighted $\\ell_1$ ball. The first two algorithms have a linear\nworst case complexity. The third one has a highly competitive performances in\npractice but the worst case has a quadratic complexity. These new algorithms\nare efficient tools for machine learning methods based on projected gradient\ndescent such as compress sensing, feature selection. We illustrate this\neffectiveness by adapting an efficient compress sensing algorithm to weighted\nprojections. We demonstrate the efficiency of our new algorithms on benchmarks\nusing very large vectors. For instance, it requires only 8 ms, on an Intel I7\n3rd generation, for projecting vectors of size $10^7$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:48:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Perez", "Guillaume", ""], ["Ament", "Sebastian", ""], ["Gomes", "Carla", ""], ["Barlaud", "Michel", ""]]}, {"id": "2009.02994", "submitter": "Sebastian Neumayer", "authors": "Paul Hagemann and Sebastian Neumayer", "title": "Stabilizing Invertible Neural Networks Using Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the properties of invertible neural networks, which\nprovide a way of solving inverse problems. Our main focus lies on investigating\nand controlling the Lipschitz constants of the corresponding inverse networks.\nWithout such an control, numerical simulations are prone to errors and not much\nis gained against traditional approaches. Fortunately, our analysis indicates\nthat changing the latent distribution from a standard normal one to a Gaussian\nmixture model resolves the issue of exploding Lipschitz constants. Indeed,\nnumerical simulations confirm that this modification leads to significantly\nimproved sampling quality in multimodal applications.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:20:43 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 20:00:49 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hagemann", "Paul", ""], ["Neumayer", "Sebastian", ""]]}, {"id": "2009.03001", "submitter": "Alberto Gutierrez-Torre", "authors": "Alberto Gutierrez-Torre, Josep Ll. Berral, David Buchaca, Marc\n  Guevara, Albert Soret, David Carrera", "title": "Improving Maritime Traffic Emission Estimations on Missing Data with\n  CRBMs", "comments": "12 pages, 7 figures. Postprint accepted manuscript, find the full\n  version at Engineering Applications of Artificial Intelligence\n  (https://doi.org/10.1016/j.engappai.2020.103793)", "journal-ref": "Engineering Applications of Artificial Intelligence Volume 94,\n  September 2020, 103793", "doi": "10.1016/j.engappai.2020.103793", "report-no": null, "categories": "cs.CY cs.CE cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maritime traffic emissions are a major concern to governments as they heavily\nimpact the Air Quality in coastal cities. Ships use the Automatic\nIdentification System (AIS) to continuously report position and speed among\nother features, and therefore this data is suitable to be used to estimate\nemissions, if it is combined with engine data. However, important ship features\nare often inaccurate or missing. State-of-the-art complex systems, like CALIOPE\nat the Barcelona Supercomputing Center, are used to model Air Quality. These\nsystems can benefit from AIS based emission models as they are very precise in\npositioning the pollution. Unfortunately, these models are sensitive to missing\nor corrupted data, and therefore they need data curation techniques to\nsignificantly improve the estimation accuracy. In this work, we propose a\nmethodology for treating ship data using Conditional Restricted Boltzmann\nMachines (CRBMs) plus machine learning methods to improve the quality of data\npassed to emission models. Results show that we can improve the default methods\nproposed to cover missing data. In our results, we observed that using our\nmethod the models boosted their accuracy to detect otherwise undetectable\nemissions. In particular, we used a real data-set of AIS data, provided by the\nSpanish Port Authority, to estimate that thanks to our method, the model was\nable to detect 45% of additional emissions, of additional emissions,\nrepresenting 152 tonnes of pollutants per week in Barcelona and propose new\nfeatures that may enhance emission modeling.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:32:43 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 09:04:42 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Gutierrez-Torre", "Alberto", ""], ["Berral", "Josep Ll.", ""], ["Buchaca", "David", ""], ["Guevara", "Marc", ""], ["Soret", "Albert", ""], ["Carrera", "David", ""]]}, {"id": "2009.03008", "submitter": "Tomer Weiss", "authors": "Tomer Weiss, Sanketh Vedula, Ortal Senouf, Oleg Michailovich, and\n  AlexBronstein", "title": "Towards learned optimal q-space sampling in diffusion MRI", "comments": "CDMRI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fiber tractography is an important tool of computational neuroscience that\nenables reconstructing the spatial connectivity and organization of white\nmatter of the brain. Fiber tractography takes advantage of diffusion Magnetic\nResonance Imaging (dMRI) which allows measuring the apparent diffusivity of\ncerebral water along different spatial directions. Unfortunately, collecting\nsuch data comes at the price of reduced spatial resolution and substantially\nelevated acquisition times, which limits the clinical applicability of dMRI.\nThis problem has been thus far addressed using two principal strategies. Most\nof the efforts have been extended towards improving the quality of signal\nestimation for any, yet fixed sampling scheme (defined through the choice of\ndiffusion-encoding gradients). On the other hand, optimization over the\nsampling scheme has also proven to be effective. Inspired by the previous\nresults, the present work consolidates the above strategies into a unified\nestimation framework, in which the optimization is carried out with respect to\nboth estimation model and sampling design {\\it concurrently}. The proposed\nsolution offers substantial improvements in the quality of signal estimation as\nwell as the accuracy of ensuing analysis by means of fiber tractography. While\nproving the optimality of the learned estimation models would probably need\nmore extensive evaluation, we nevertheless claim that the learned sampling\nschemes can be of immediate use, offering a way to improve the dMRI analysis\nwithout the necessity of deploying the neural network used for their\nestimation. We present a comprehensive comparative analysis based on the Human\nConnectome Project data. Code and learned sampling designs aviliable at\nhttps://github.com/tomer196/Learned_dMRI.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:46:12 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Weiss", "Tomer", ""], ["Vedula", "Sanketh", ""], ["Senouf", "Ortal", ""], ["Michailovich", "Oleg", ""], ["AlexBronstein", "", ""]]}, {"id": "2009.03009", "submitter": "Matin Hashemi", "authors": "Amir Amirinezhad, Saber Salehkaleybar, Matin Hashemi", "title": "Active Learning of Causal Structures with Deep Reinforcement Learning", "comments": "submitted for peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of experiment design to learn causal structures from\ninterventional data. We consider an active learning setting in which the\nexperimenter decides to intervene on one of the variables in the system in each\nstep and uses the results of the intervention to recover further causal\nrelationships among the variables. The goal is to fully identify the causal\nstructures with minimum number of interventions. We present the first deep\nreinforcement learning based solution for the problem of experiment design. In\nthe proposed method, we embed input graphs to vectors using a graph neural\nnetwork and feed them to another neural network which outputs a variable for\nperforming intervention in each step. Both networks are trained jointly via a\nQ-iteration algorithm. Experimental results show that the proposed method\nachieves competitive performance in recovering causal structures with respect\nto previous works, while significantly reducing execution time in dense graphs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:49:06 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Amirinezhad", "Amir", ""], ["Salehkaleybar", "Saber", ""], ["Hashemi", "Matin", ""]]}, {"id": "2009.03015", "submitter": "Sahar Abdelnabi", "authors": "Sahar Abdelnabi and Mario Fritz", "title": "Adversarial Watermarking Transformer: Towards Tracing Text Provenance\n  with Data Hiding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in natural language generation have introduced powerful\nlanguage models with high-quality output text. However, this raises concerns\nabout the potential misuse of such models for malicious purposes. In this\npaper, we study natural language watermarking as a defense to help better mark\nand trace the provenance of text. We introduce the Adversarial Watermarking\nTransformer (AWT) with a jointly trained encoder-decoder and adversarial\ntraining that, given an input text and a binary message, generates an output\ntext that is unobtrusively encoded with the given message. We further study\ndifferent training and inference strategies to achieve minimal changes to the\nsemantics and correctness of the input text.\n  AWT is the first end-to-end model to hide data in text by automatically\nlearning -- without ground truth -- word substitutions along with their\nlocations in order to encode the message. We empirically show that our model is\neffective in largely preserving text utility and decoding the watermark while\nhiding its presence against adversaries. Additionally, we demonstrate that our\nmethod is robust against a range of attacks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:01:24 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 12:21:27 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Abdelnabi", "Sahar", ""], ["Fritz", "Mario", ""]]}, {"id": "2009.03017", "submitter": "Pierre Alquier", "authors": "Pierre Alquier", "title": "Non-exponentially weighted aggregation: regret bounds for unbounded loss\n  functions", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, Proceedings of Machine Learning Research, 2021, vol. 139, pp.\n  207-218", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of online optimization with a general, possibly\nunbounded, loss function. It is well known that when the loss is bounded, the\nexponentially weighted aggregation strategy (EWA) leads to a regret in\n$\\sqrt{T}$ after $T$ steps. In this paper, we study a generalized aggregation\nstrategy, where the weights no longer depend exponentially on the losses. Our\nstrategy is based on Follow The Regularized Leader (FTRL): we minimize the\nexpected losses plus a regularizer, that is here a $\\phi$-divergence. When the\nregularizer is the Kullback-Leibler divergence, we obtain EWA as a special\ncase. Using alternative divergences enables unbounded losses, at the cost of a\nworst regret bound in some cases.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:09:08 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 11:19:03 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 03:33:25 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 04:08:10 GMT"}, {"version": "v5", "created": "Thu, 17 Jun 2021 09:27:00 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Alquier", "Pierre", ""]]}, {"id": "2009.03027", "submitter": "Alexander Malafeev", "authors": "Alexander Malafeev, Anneke Hertig-Godeschalk, David R. Schreier,\n  Jelena Skorucak, Johannes Mathis, Peter Achermann", "title": "Automatic detection of microsleep episodes with deep learning", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2021.564098", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brief fragments of sleep shorter than 15 s are defined as microsleep episodes\n(MSEs), often subjectively perceived as sleepiness. Their main characteristic\nis a slowing in frequency in the electroencephalogram (EEG), similar to stage\nN1 sleep according to standard criteria. The maintenance of wakefulness test\n(MWT) is often used in a clinical setting to assess vigilance. Scoring of the\nMWT in most sleep-wake centers is limited to classical definition of sleep\n(30-s epochs), and MSEs are mostly not considered in the absence of established\nscoring criteria defining MSEs but also because of the laborious work. We aimed\nfor automatic detection of MSEs with machine learning, i.e. with deep learning\nbased on raw EEG and EOG data as input. We analyzed MWT data of 76 patients.\nExperts visually scored wakefulness, and according to recently developed\nscoring criteria MSEs, microsleep episode candidates (MSEc), and episodes of\ndrowsiness (ED). We implemented segmentation algorithms based on convolutional\nneural networks (CNNs) and a combination of a CNN with a long-short term memory\n(LSTM) network. A LSTM network is a type of a recurrent neural network which\nhas a memory for past events and takes them into account. Data of 53 patients\nwere used for training of the classifiers, 12 for validation and 11 for\ntesting. Our algorithms showed a good performance close to human experts. The\ndetection was very good for wakefulness and MSEs and poor for MSEc and ED,\nsimilar to the low inter-expert reliability for these borderline segments. We\nprovide a proof of principle that it is feasible to reliably detect MSEs with\ndeep neuronal networks based on raw EEG and EOG data with a performance close\nto that of human experts. Code of algorithms (\nhttps://github.com/alexander-malafeev/microsleep-detection ) and data (\nhttps://zenodo.org/record/3251716 ) are available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:38:40 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 17:40:15 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Malafeev", "Alexander", ""], ["Hertig-Godeschalk", "Anneke", ""], ["Schreier", "David R.", ""], ["Skorucak", "Jelena", ""], ["Mathis", "Johannes", ""], ["Achermann", "Peter", ""]]}, {"id": "2009.03034", "submitter": "Minyoung Kim", "authors": "Minyoung Kim and Vladimir Pavlovic", "title": "Ordinal-Content VAE: Isolating Ordinal-Valued Content Factors in Deep\n  Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep representational learning, it is often desired to isolate a\nparticular factor (termed {\\em content}) from other factors (referred to as\n{\\em style}). What constitutes the content is typically specified by users\nthrough explicit labels in the data, while all unlabeled/unknown factors are\nregarded as style. Recently, it has been shown that such content-labeled data\ncan be effectively exploited by modifying the deep latent factor models (e.g.,\nVAE) such that the style and content are well separated in the latent\nrepresentations. However, the approach assumes that the content factor is\ncategorical-valued (e.g., subject ID in face image data, or digit class in the\nMNIST dataset). In certain situations, the content is ordinal-valued, that is,\nthe values the content factor takes are {\\em ordered} rather than categorical,\nmaking content-labeled VAEs, including the latent space they infer, suboptimal.\nIn this paper, we propose a novel extension of VAE that imposes a partially\nordered set (poset) structure in the content latent space, while simultaneously\nmaking it aligned with the ordinal content values. To this end, instead of the\niid Gaussian latent prior adopted in prior approaches, we introduce a\nconditional Gaussian spacing prior model. This model admits a tractable joint\nGaussian prior, but also effectively places negligible density values on the\ncontent latent configurations that violate the poset constraint. To evaluate\nthis model, we consider two specific ordinal structured problems: estimating a\nsubject's age in a face image and elucidating the calorie amount in a food meal\nimage. We demonstrate significant improvements in content-style separation over\nprevious non-ordinal approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:59:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kim", "Minyoung", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "2009.03077", "submitter": "Kazuharu Harada", "authors": "Kazuharu Harada and Hironori Fujisawa", "title": "Estimation of Structural Causal Model via Sparsely Mixing Independent\n  Component Analysis", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the causal structure from observational\ndata, especially when the structure is sparse. This type of problem is usually\nformulated as an inference of a directed acyclic graph (DAG) model. The linear\nnon-Gaussian acyclic model (LiNGAM) is one of the most successful DAG models,\nand various estimation methods have been developed. However, existing methods\nare not efficient for some reasons: (i) the sparse structure is not always\nincorporated in causal order estimation, and (ii) the whole information of the\ndata is not used in parameter estimation. To address {these issues}, we propose\na new estimation method for a linear DAG model with non-Gaussian noises. The\nproposed method is based on the log-likelihood of independent component\nanalysis (ICA) with two penalty terms related to the sparsity and the\nconsistency condition. The proposed method enables us to estimate the causal\norder and the parameters simultaneously. For stable and efficient optimization,\nwe propose some devices, such as a modified natural gradient. Numerical\nexperiments show that the proposed method outperforms existing methods,\nincluding LiNGAM and NOTEARS.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:08:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Harada", "Kazuharu", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "2009.03087", "submitter": "Josimar Chire Saire", "authors": "Josimar Edinson Chire Saire, Honorio Apaza Alanoca", "title": "Text Mining over Curriculum Vitae of Peruvian Professionals using\n  Official Scientific Site DINA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, Peruvian government started to invest and promote\nScience and Technology through Concytec(National Council of Science and\nTechnology). Many programs are oriented to support research projects, expenses\nfor paper presentation, organization of conferences/ events and more. Concytec\ncreated a National Directory of Researchers(DINA) where professionals can\ncreate and add curriculum vitae, Concytec can provide official title of\nResearcher following some criterion for the evaluation. The actual paper aims\nto conduct an exploratory analysis over the curriculum vitae of Peruvian\nProfessionals using Data Mining Approach to understand Peruvian context.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:16:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Saire", "Josimar Edinson Chire", ""], ["Alanoca", "Honorio Apaza", ""]]}, {"id": "2009.03091", "submitter": "Lenart Treven", "authors": "Luka Kolar, Rok \\v{S}ikonja, Lenart Treven", "title": "Iterative Correction of Sensor Degradation and a Bayesian Multi-Sensor\n  Data Fusion Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for inferring ground-truth signal from multiple\ndegraded signals, affected by different amounts of sensor exposure. The\nalgorithm learns a multiplicative degradation effect by performing iterative\ncorrections of two signals solely from the ratio between them. The degradation\nfunction d should be continuous, satisfy monotonicity, and d(0) = 1. We use\nsmoothed monotonic regression method, where we easily incorporate the\naforementioned criteria to the fitting part. We include theoretical analysis\nand prove convergence to the ground-truth signal for the noiseless measurement\nmodel. Lastly, we present an approach to fuse the noisy corrected signals using\nGaussian processes. We use sparse Gaussian processes that can be utilized for a\nlarge number of measurements together with a specialized kernel that enables\nthe estimation of noise values of all sensors. The data fusion framework\nnaturally handles data gaps and provides a simple and powerful method for\nobserving the signal trends on multiple timescales(long-term and short-term\nsignal properties). The viability of correction method is evaluated on a\nsynthetic dataset with known ground-truth signal.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:24:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kolar", "Luka", ""], ["\u0160ikonja", "Rok", ""], ["Treven", "Lenart", ""]]}, {"id": "2009.03094", "submitter": "Zhengxin Ye", "authors": "Zhengxin Joseph Ye and Bjorn W. Schuller", "title": "Capturing dynamics of post-earnings-announcement drift using genetic\n  algorithm-optimised supervised learning", "comments": "13 pages of main article plus 6 pages of data in appendix. 7 figures\n  and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Post-Earnings-Announcement Drift (PEAD) is one of the most studied\nstock market anomalies, the current literature is often limited in explaining\nthis phenomenon by a small number of factors using simpler regression methods.\nIn this paper, we use a machine learning based approach instead, and aim to\ncapture the PEAD dynamics using data from a large group of stocks and a wide\nrange of both fundamental and technical factors. Our model is built around the\nExtreme Gradient Boosting (XGBoost) and uses a long list of engineered input\nfeatures based on quarterly financial announcement data from 1,106 companies in\nthe Russell 1000 index between 1997 and 2018. We perform numerous experiments\non PEAD predictions and analysis and have the following contributions to the\nliterature. First, we show how Post-Earnings-Announcement Drift can be analysed\nusing machine learning methods and demonstrate such methods' prowess in\nproducing credible forecasting on the drift direction. It is the first time\nPEAD dynamics are studied using XGBoost. We show that the drift direction is in\nfact driven by different factors for stocks from different industrial sectors\nand in different quarters and XGBoost is effective in understanding the\nchanging drivers. Second, we show that an XGBoost well optimised by a Genetic\nAlgorithm can help allocate out-of-sample stocks to form portfolios with higher\npositive returns to long and portfolios with lower negative returns to short, a\nfinding that could be adopted in the process of developing market neutral\nstrategies. Third, we show how theoretical event-driven stock strategies have\nto grapple with ever changing market prices in reality, reducing their\neffectiveness. We present a tactic to remedy the difficulty of buying into a\nmoving market when dealing with PEAD signals.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:27:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ye", "Zhengxin Joseph", ""], ["Schuller", "Bjorn W.", ""]]}, {"id": "2009.03106", "submitter": "Jaewoo Lee", "authors": "Jaewoo Lee and Daniel Kifer", "title": "Scaling up Differentially Private Deep Learning with Fast Per-Example\n  Gradient Clipping", "comments": "To appear in PETS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on Renyi Differential Privacy has shown the feasibility of\napplying differential privacy to deep learning tasks. Despite their promise,\nhowever, differentially private deep networks often lag far behind their\nnon-private counterparts in accuracy, showing the need for more research in\nmodel architectures, optimizers, etc. One of the barriers to this expanded\nresearch is the training time -- often orders of magnitude larger than training\nnon-private networks. The reason for this slowdown is a crucial privacy-related\nstep called \"per-example gradient clipping\" whose naive implementation undoes\nthe benefits of batch training with GPUs. By analyzing the back-propagation\nequations we derive new methods for per-example gradient clipping that are\ncompatible with auto-differentiation (e.g., in PyTorch and TensorFlow) and\nprovide better GPU utilization. Our implementation in PyTorch showed\nsignificant training speed-ups (by factors of 54x - 94x for training various\nmodels with batch sizes of 128). These techniques work for a variety of\narchitectural choices including convolutional layers, recurrent networks,\nattention, residual blocks, etc.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:51:26 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Lee", "Jaewoo", ""], ["Kifer", "Daniel", ""]]}, {"id": "2009.03107", "submitter": "Tong Liu", "authors": "Tong Liu, Roberto Amadini, Jacopo Mauro, Maurizio Gabbrielli", "title": "sunny-as2: Enhancing SUNNY for Algorithm Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SUNNY is an Algorithm Selection (AS) technique originally tailored for\nConstraint Programming (CP). SUNNY enables to schedule, from a portfolio of\nsolvers, a subset of solvers to be run on a given CP problem. This approach has\nproved to be effective for CP problems, and its parallel version won many gold\nmedals in the Open category of the MiniZinc Challenge -- the yearly\ninternational competition for CP solvers. In 2015, the ASlib benchmarks were\nreleased for comparing AS systems coming from disparate fields (e.g., ASP, QBF,\nand SAT) and SUNNY was extended to deal with generic AS problems. This led to\nthe development of sunny-as2, an algorithm selector based on SUNNY for ASlib\nscenarios. A preliminary version of sunny-as2 was submitted to the Open\nAlgorithm Selection Challenge (OASC) in 2017, where it turned out to be the\nbest approach for the runtime minimization of decision problems. In this work,\nwe present the technical advancements of sunny-as2, including: (i)\nwrapper-based feature selection; (ii) a training approach combining feature\nselection and neighbourhood size configuration; (iii) the application of nested\ncross-validation. We show how sunny-as2 performance varies depending on the\nconsidered AS scenarios, and we discuss its strengths and weaknesses. Finally,\nwe also show how sunny-as2 improves on its preliminary version submitted to\nOASC.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:55:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Tong", ""], ["Amadini", "Roberto", ""], ["Mauro", "Jacopo", ""], ["Gabbrielli", "Maurizio", ""]]}, {"id": "2009.03136", "submitter": "Matthew Ciolino", "authors": "Josh Kalin, Matthew Ciolino, David Noever, Gerry Dozier", "title": "Black Box to White Box: Discover Model Characteristics Based on\n  Strategic Probing", "comments": "4 Pages, 3 Figure, IEEE Format, Ai4i 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning, White Box Adversarial Attacks rely on knowing underlying\nknowledge about the model attributes. This works focuses on discovering to\ndistrinct pieces of model information: the underlying architecture and primary\ntraining dataset. With the process in this paper, a structured set of input\nprobes and the output of the model become the training data for a deep\nclassifier. Two subdomains in Machine Learning are explored: image based\nclassifiers and text transformers with GPT-2. With image classification, the\nfocus is on exploring commonly deployed architectures and datasets available in\npopular public libraries. Using a single transformer architecture with multiple\nlevels of parameters, text generation is explored by fine tuning off different\ndatasets. Each dataset explored in image and text are distinguishable from one\nanother. Diversity in text transformer outputs implies further research is\nneeded to successfully classify architecture attribution in text domain.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:44:28 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kalin", "Josh", ""], ["Ciolino", "Matthew", ""], ["Noever", "David", ""], ["Dozier", "Gerry", ""]]}, {"id": "2009.03140", "submitter": "Shuai Wang", "authors": "Dan Liu, Shuai Wang, Zhigang Wen, Lei Cheng, Miaowen Wen, and\n  Yik-Chung Wu", "title": "Edge Learning with Unmanned Ground Vehicle: Joint Path, Energy and\n  Sample Size Planning", "comments": "16 pages, 6 figures, to appear in IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge learning (EL), which uses edge computing as a platform to execute\nmachine learning algorithms, is able to fully exploit the massive sensing data\ngenerated by Internet of Things (IoT). However, due to the limited transmit\npower at IoT devices, collecting the sensing data in EL systems is a\nchallenging task. To address this challenge, this paper proposes to integrate\nunmanned ground vehicle (UGV) with EL. With such a scheme, the UGV could\nimprove the communication quality by approaching various IoT devices. However,\ndifferent devices may transmit different data for different machine learning\njobs and a fundamental question is how to jointly plan the UGV path, the\ndevices' energy consumption, and the number of samples for different jobs? This\npaper further proposes a graph-based path planning model, a network energy\nconsumption model and a sample size planning model that characterizes F-measure\nas a function of the minority class sample size. With these models, the joint\npath, energy and sample size planning (JPESP) problem is formulated as a\nlarge-scale mixed integer nonlinear programming (MINLP) problem, which is\nnontrivial to solve due to the high-dimensional discontinuous variables related\nto UGV movement. To this end, it is proved that each IoT device should be\nserved only once along the path, thus the problem dimension is significantly\nreduced. Furthermore, to handle the discontinuous variables, a tabu search (TS)\nbased algorithm is derived, which converges in expectation to the optimal\nsolution to the JPESP problem. Simulation results under different task\nscenarios show that our optimization schemes outperform the fixed EL and the\nfull path EL schemes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:51:42 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Dan", ""], ["Wang", "Shuai", ""], ["Wen", "Zhigang", ""], ["Cheng", "Lei", ""], ["Wen", "Miaowen", ""], ["Wu", "Yik-Chung", ""]]}, {"id": "2009.03173", "submitter": "Zhenyue Qin", "authors": "Yang Liu and Zhenyue Qin and Saeed Anwar and Sabrina Caldwell and Tom\n  Gedeon", "title": "Are Deep Neural Architectures Losing Information? Invertibility Is\n  Indispensable", "comments": "ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever since the advent of AlexNet, designing novel deep neural architectures\nfor different tasks has consistently been a productive research direction.\nDespite the exceptional performance of various architectures in practice, we\nstudy a theoretical question: what is the condition for deep neural\narchitectures to preserve all the information of the input data? Identifying\nthe information lossless condition for deep neural architectures is important,\nbecause tasks such as image restoration require keep the detailed information\nof the input data as much as possible. Using the definition of mutual\ninformation, we show that: a deep neural architecture can preserve maximum\ndetails about the given data if and only if the architecture is invertible. We\nverify the advantages of our Invertible Restoring Autoencoder (IRAE) network by\ncomparing it with competitive models on three perturbed image restoration\ntasks: image denoising, jpeg image decompression and image inpainting.\nExperimental results show that IRAE consistently outperforms non-invertible\nones. Our model even contains far fewer parameters. Thus, it may be worthwhile\nto try replacing standard components of deep neural architectures, such as\nresidual blocks and ReLU, with their invertible counterparts. We believe our\nwork provides a unique perspective and direction for future deep learning\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:39:24 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 00:15:58 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Liu", "Yang", ""], ["Qin", "Zhenyue", ""], ["Anwar", "Saeed", ""], ["Caldwell", "Sabrina", ""], ["Gedeon", "Tom", ""]]}, {"id": "2009.03183", "submitter": "Vincent Grari", "authors": "Vincent Grari, Oualid El Hajouji, Sylvain Lamprier, Marcin Detyniecki", "title": "Learning Unbiased Representations via R\\'enyi Minimization", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant work has been done to include fairness\nconstraints in the training objective of machine learning algorithms. Many\nstate-of the-art algorithms tackle this challenge by learning a fair\nrepresentation which captures all the relevant information to predict the\noutput Y while not containing any information about a sensitive attribute S. In\nthis paper, we propose an adversarial algorithm to learn unbiased\nrepresentations via the Hirschfeld-Gebelein-Renyi (HGR) maximal correlation\ncoefficient. We leverage recent work which has been done to estimate this\ncoefficient by learning deep neural network transformations and use it as a\nminmax game to penalize the intrinsic bias in a multi dimensional latent\nrepresentation. Compared to other dependence measures, the HGR coefficient\ncaptures more information about the non-linear dependencies with the sensitive\nvariable, making the algorithm more efficient in mitigating bias in the\nrepresentation. We empirically evaluate and compare our approach and\ndemonstrate significant improvements over existing works in the field.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:48:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Grari", "Vincent", ""], ["Hajouji", "Oualid El", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2009.03184", "submitter": "Yanwei Fu", "authors": "Yanwei Fu, Feng Li, Wenxuan Wang, Haicheng Tang, Xuelin Qian, Mengwei\n  Gu, Xiangyang Xue", "title": "A New Screening Method for COVID-19 based on Ocular Feature Recognition\n  by Machine Learning Tools", "comments": "technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Coronavirus disease 2019 (COVID-19) has affected several million people.\nWith the outbreak of the epidemic, many researchers are devoting themselves to\nthe COVID-19 screening system. The standard practices for rapid risk screening\nof COVID-19 are the CT imaging or RT-PCR (real-time polymerase chain reaction).\nHowever, these methods demand professional efforts of the acquisition of CT\nimages and saliva samples, a certain amount of waiting time, and most\nimportantly prohibitive examination fee in some countries. Recently, some\nliteratures have shown that the COVID-19 patients usually accompanied by ocular\nmanifestations consistent with the conjunctivitis, including conjunctival\nhyperemia, chemosis, epiphora, or increased secretions. After more than four\nmonths study, we found that the confirmed cases of COVID-19 present the\nconsistent ocular pathological symbols; and we propose a new screening method\nof analyzing the eye-region images, captured by common CCD and CMOS cameras,\ncould reliably make a rapid risk screening of COVID-19 with very high accuracy.\nWe believe a system implementing such an algorithm should assist the triage\nmanagement or the clinical diagnosis. To further evaluate our algorithm and\napproved by the Ethics Committee of Shanghai public health clinic center of\nFudan University, we conduct a study of analyzing the eye-region images of 303\npatients (104 COVID-19, 131 pulmonary, and 68 ocular patients), as well as 136\nhealthy people. Remarkably, our results of COVID-19 patients in testing set\nconsistently present similar ocular pathological symbols; and very high testing\nresults have been achieved in terms of sensitivity and specificity. We hope\nthis study can be inspiring and helpful for encouraging more researches in this\ntopic.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 00:50:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fu", "Yanwei", ""], ["Li", "Feng", ""], ["Wang", "Wenxuan", ""], ["Tang", "Haicheng", ""], ["Qian", "Xuelin", ""], ["Gu", "Mengwei", ""], ["Xue", "Xiangyang", ""]]}, {"id": "2009.03192", "submitter": "Ulf-G. Mei{\\ss}ner", "authors": "Bastian Kaspschak and Ulf-G. Mei{\\ss}ner", "title": "A Neural Network Perturbation Theory Based on the Born Series", "comments": "29 pages, 4 figures, revised with more focus on neural network\n  perturbation theory, accepted for publication in Phys. Rev. Research", "journal-ref": "Phys. Rev. Research 3, 023223 (2021)", "doi": "10.1103/PhysRevResearch.3.023223", "report-no": null, "categories": "cs.LG nucl-th physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning using the eponymous deep neural networks (DNNs) has become an\nattractive approach towards various data-based problems of theoretical physics\nin the past decade. There has been a clear trend to deeper architectures\ncontaining increasingly more powerful and involved layers. Contrarily, Taylor\ncoefficients of DNNs still appear mainly in the light of interpretability\nstudies, where they are computed at most to first order. However, especially in\ntheoretical physics numerous problems benefit from accessing higher orders, as\nwell. This gap motivates a general formulation of neural network (NN) Taylor\nexpansions. Restricting our analysis to multilayer perceptrons (MLPs) and\nintroducing quantities we refer to as propagators and vertices, both depending\non the MLP's weights and biases, we establish a graph-theoretical approach.\nSimilarly to Feynman rules in quantum field theories, we can systematically\nassign diagrams containing propagators and vertices to the corresponding\npartial derivative. Examining this approach for S-wave scattering lengths of\nshallow potentials, we observe NNs to adapt their derivatives mainly to the\nleading order of the target function's Taylor expansion. To circumvent this\nproblem, we propose an iterative NN perturbation theory. During each iteration\nwe eliminate the leading order, such that the next-to-leading order can be\nfaithfully learned during the subsequent iteration. After performing two\niterations, we find that the first- and second-order Born terms are correctly\nadapted during the respective iterations. Finally, we combine both results to\nfind a proxy that acts as a machine-learned second-order Born approximation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:54:27 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 08:09:47 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kaspschak", "Bastian", ""], ["Mei\u00dfner", "Ulf-G.", ""]]}, {"id": "2009.03202", "submitter": "Shuaiqiang Liu", "authors": "Shuaiqiang Liu and Lech A. Grzelak and Cornelis W. Oosterlee", "title": "The Seven-League Scheme: Deep learning for large time step Monte Carlo\n  simulations of stochastic differential equations", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an accurate data-driven numerical scheme to solve Stochastic\nDifferential Equations (SDEs), by taking large time steps. The SDE\ndiscretization is built up by means of a polynomial chaos expansion method, on\nthe basis of accurately determined stochastic collocation (SC) points. By\nemploying an artificial neural network to learn these SC points, we can perform\nMonte Carlo simulations with large time steps. Error analysis confirms that\nthis data-driven scheme results in accurate SDE solutions in the sense of\nstrong convergence, provided the learning methodology is robust and accurate.\nWith a variant method called the compression-decompression collocation and\ninterpolation technique, we can drastically reduce the number of neural network\nfunctions that have to be learned, so that computational speed is enhanced.\nNumerical results show the high quality strong convergence error results, when\nusing large time steps, and the novel scheme outperforms some classical\nnumerical SDE discretizations. Some applications, here in financial option\nvaluation, are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:06:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:41:14 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 13:53:13 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 19:22:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Liu", "Shuaiqiang", ""], ["Grzelak", "Lech A.", ""], ["Oosterlee", "Cornelis W.", ""]]}, {"id": "2009.03207", "submitter": "James Grant", "authors": "James A. Grant, David S. Leslie", "title": "Learning to Rank under Multinomial Logit Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the optimal ordering of content is an important challenge in website\ndesign. The learning to rank (LTR) framework models this problem as a\nsequential problem of selecting lists of content and observing where users\ndecide to click. Most previous work on LTR assumes that the user considers each\nitem in the list in isolation, and makes binary choices to click or not on\neach. We introduce a multinomial logit (MNL) choice model to the LTR framework,\nwhich captures the behaviour of users who consider the ordered list of items as\na whole and make a single choice among all the items and a no-click option.\nUnder the MNL model, the user favours items which are either inherently more\nattractive, or placed in a preferable position within the list. We propose\nupper confidence bound algorithms to minimise regret in two settings - where\nthe position dependent parameters are known, and unknown. We present\ntheoretical analysis leading to an $\\Omega(\\sqrt{T})$ lower bound for the\nproblem, an $\\tilde{O}(\\sqrt{T})$ upper bound on regret for the known parameter\nversion. Our analyses are based on tight new concentration results for\nGeometric random variables, and novel functional inequalities for maximum\nlikelihood estimators computed on discrete data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:15:12 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Grant", "James A.", ""], ["Leslie", "David S.", ""]]}, {"id": "2009.03219", "submitter": "Petr \\v{S}koda", "authors": "Petr \\v{S}koda (1 and 2), Ond\\v{r}ej Podsztavek (2) and Pavel Tvrd\\'ik\n  (2) ((1) Astronomical Institute of the Czech Academy of Sciences, (2) Faculty\n  of Information Technology of the Czech Technical University in Prague)", "title": "Active deep learning method for the discovery of objects of interest in\n  large spectroscopic surveys", "comments": "To appear in Astronomy & Astrophysics Section 14- Catalogs and Data,\n  15 pages, 13 figures", "journal-ref": "A&A 643, A122 (2020)", "doi": "10.1051/0004-6361/201936090", "report-no": "ASU-9-20", "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current archives of the LAMOST telescope contain millions of\npipeline-processed spectra that have probably never been seen by human eyes.\nMost of the rare objects with interesting physical properties, however, can\nonly be identified by visual analysis of their characteristic spectral\nfeatures. A proper combination of interactive visualisation with modern machine\nlearning techniques opens new ways to discover such objects. We apply active\nlearning classification supported by deep convolutional networks to\nautomatically identify complex emission-line shapes in multi-million spectra\narchives.\n  We used the pool-based uncertainty sampling active learning driven by a\ncustom-designed deep convolutional neural network with 12 layers inspired by\nVGGNet, AlexNet, and ZFNet, but adapted for one-dimensional feature vectors.\nThe unlabelled pool set is represented by 4.1 million spectra from the LAMOST\nDR2 survey. The initial training of the network was performed on a labelled set\nof about 13000 spectra obtained in the region around H$\\alpha$ by the 2m Perek\ntelescope of the Ond\\v{r}ejov observatory, which mostly contains spectra of Be\nand related early-type stars. The differences between the Ond\\v{r}ejov\nintermediate-resolution and the LAMOST low-resolution spectrographs were\ncompensated for by Gaussian blurring.\n  After several iterations, the network was able to successfully identify\nemission-line stars with an error smaller than 6.5%. Using the technology of\nthe Virtual Observatory to visualise the results, we discovered 1013 spectra of\n948 new candidates of emission-line objects in addition to 664 spectra of 549\nobjects that are listed in SIMBAD and 2644 spectra of 2291 objects identified\nin an earlier paper of a Chinese group led by Wen Hou. The most interesting\nobjects with unusual spectral properties are discussed in detail.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:27:25 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["\u0160koda", "Petr", "", "1 and 2"], ["Podsztavek", "Ond\u0159ej", ""], ["Tvrd\u00edk", "Pavel", ""]]}, {"id": "2009.03228", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias and Francisco J. R. Ruiz and Sotirios\n  Nikoloutsopoulos and Alexandre Galashov", "title": "Information Theoretic Meta Learning with Gaussian Processes", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate meta learning using information theoretic concepts; namely,\nmutual information and the information bottleneck. The idea is to learn a\nstochastic representation or encoding of the task description, given by a\ntraining set, that is highly informative about predicting the validation set.\nBy making use of variational approximations to the mutual information, we\nderive a general and tractable framework for meta learning. This framework\nunifies existing gradient-based algorithms and also allows us to derive new\nalgorithms. In particular, we develop a memory-based algorithm that uses\nGaussian processes to obtain non-parametric encoding representations. We\ndemonstrate our method on a few-shot regression problem and on four few-shot\nclassification problems, obtaining competitive accuracy when compared to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:47:30 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 13:40:54 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 12:26:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Ruiz", "Francisco J. R.", ""], ["Nikoloutsopoulos", "Sotirios", ""], ["Galashov", "Alexandre", ""]]}, {"id": "2009.03231", "submitter": "Samyak Datta", "authors": "Samyak Datta, Oleksandr Maksymets, Judy Hoffman, Stefan Lee, Dhruv\n  Batra, Devi Parikh", "title": "Integrating Egocentric Localization for More Realistic Point-Goal\n  Navigation Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has presented embodied agents that can navigate to point-goal\ntargets in novel indoor environments with near-perfect accuracy. However, these\nagents are equipped with idealized sensors for localization and take\ndeterministic actions. This setting is practically sterile by comparison to the\ndirty reality of noisy sensors and actuations in the real world -- wheels can\nslip, motion sensors have error, actuations can rebound. In this work, we take\na step towards this noisy reality, developing point-goal navigation agents that\nrely on visual estimates of egomotion under noisy action dynamics. We find\nthese agents outperform naive adaptions of current point-goal agents to this\nsetting as well as those incorporating classic localization baselines. Further,\nour model conceptually divides learning agent dynamics or odometry (where am\nI?) from task-specific navigation policy (where do I want to go?). This enables\na seamless adaption to changing dynamics (a different robot or floor type) by\nsimply re-calibrating the visual odometry model -- circumventing the expense of\nre-training of the navigation policy. Our agent was the runner-up in the\nPointNav track of CVPR 2020 Habitat Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:52:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Datta", "Samyak", ""], ["Maksymets", "Oleksandr", ""], ["Hoffman", "Judy", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "2009.03238", "submitter": "Niharika Shimona D'Souza", "authors": "Niharika Shimona D'Souza, Mary Beth Nebel, Nicholas Wymbs, Stewart H.\n  Mostofsky, Archana Venkataraman", "title": "A Joint Network Optimization Framework to Predict Clinical Severity from\n  Resting State Functional MRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel optimization framework to predict clinical severity from\nresting state fMRI (rs-fMRI) data. Our model consists of two coupled terms. The\nfirst term decomposes the correlation matrices into a sparse set of\nrepresentative subnetworks that define a network manifold. These subnetworks\nare modeled as rank-one outer-products which correspond to the elemental\npatterns of co-activation across the brain; the subnetworks are combined via\npatient-specific non-negative coefficients. The second term is a linear\nregression model that uses the patient-specific coefficients to predict a\nmeasure of clinical severity. We validate our framework on two separate\ndatasets in a ten fold cross validation setting. The first is a cohort of\nfifty-eight patients diagnosed with Autism Spectrum Disorder (ASD). The second\ndataset consists of sixty three patients from a publicly available ASD\ndatabase. Our method outperforms standard semi-supervised frameworks, which\nemploy conventional graph theoretic and statistical representation learning\ntechniques to relate the rs-fMRI correlations to behavior. In contrast, our\njoint network optimization framework exploits the structure of the rs-fMRI\ncorrelation matrices to simultaneously capture group level effects and patient\nheterogeneity. Finally, we demonstrate that our proposed framework robustly\nidentifies clinically relevant networks characteristic of ASD.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:43:25 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["D'Souza", "Niharika Shimona", ""], ["Nebel", "Mary Beth", ""], ["Wymbs", "Nicholas", ""], ["Mostofsky", "Stewart H.", ""], ["Venkataraman", "Archana", ""]]}, {"id": "2009.03257", "submitter": "Leon Moonen", "authors": "Carl Martin Rosenberg and Leon Moonen", "title": "Improving Problem Identification via Automated Log Clustering using\n  Dimensionality Reduction", "comments": null, "journal-ref": "Published in ESEM'18, Proceedings of the 12th ACM/IEEE\n  International Symposium on Empirical Software Engineering and Measurement,\n  October 2018, Article: 16, pp. 1-10,", "doi": "10.1145/3239235.3239248", "report-no": null, "categories": "cs.SE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal: We consider the problem of automatically grouping logs of runs that\nfailed for the same underlying reasons, so that they can be treated more\neffectively, and investigate the following questions: (1) Does an approach\ndeveloped to identify problems in system logs generalize to identifying\nproblems in continuous deployment logs? (2) How does dimensionality reduction\naffect the quality of automated log clustering? (3) How does the criterion used\nfor merging clusters in the clustering algorithm affect clustering quality?\n  Method: We replicate and extend earlier work on clustering system log files\nto assess its generalization to continuous deployment logs. We consider the\noptional inclusion of one of these dimensionality reduction techniques:\nPrincipal Component Analysis (PCA), Latent Semantic Indexing (LSI), and\nNon-negative Matrix Factorization (NMF). Moreover, we consider three\nalternative cluster merge criteria (Single Linkage, Average Linkage, and\nWeighted Linkage), in addition to the Complete Linkage criterion used in\nearlier work. We empirically evaluate the 16 resulting configurations on\ncontinuous deployment logs provided by our industrial collaborator.\n  Results: Our study shows that (1) identifying problems in continuous\ndeployment logs via clustering is feasible, (2) including NMF significantly\nimproves overall accuracy and robustness, and (3) Complete Linkage performs\nbest of all merge criteria analyzed.\n  Conclusions: We conclude that problem identification via automated log\nclustering is improved by including dimensionality reduction, as it decreases\nthe pipeline's sensitivity to parameter choice, thereby increasing its\nrobustness for handling different inputs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:26:18 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Rosenberg", "Carl Martin", ""], ["Moonen", "Leon", ""]]}, {"id": "2009.03259", "submitter": "Yumeng Xue", "authors": "Rongzheng Bian, Yumeng Xue, Liang Zhou, Jian Zhang, Baoquan Chen,\n  Daniel Weiskopf, Yunhai Wang", "title": "Implicit Multidimensional Projection of Local Subspaces", "comments": null, "journal-ref": null, "doi": "10.1109/TVCG.2020.3030368", "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a visualization method to understand the effect of\nmultidimensional projection on local subspaces, using implicit function\ndifferentiation. Here, we understand the local subspace as the multidimensional\nlocal neighborhood of data points. Existing methods focus on the projection of\nmultidimensional data points, and the neighborhood information is ignored. Our\nmethod is able to analyze the shape and directional information of the local\nsubspace to gain more insights into the global structure of the data through\nthe perception of local structures. Local subspaces are fitted by\nmultidimensional ellipses that are spanned by basis vectors. An accurate and\nefficient vector transformation method is proposed based on analytical\ndifferentiation of multidimensional projections formulated as implicit\nfunctions. The results are visualized as glyphs and analyzed using a full set\nof specifically-designed interactions supported in our efficient web-based\nvisualization tool. The usefulness of our method is demonstrated using various\nmulti- and high-dimensional benchmark datasets. Our implicit differentiation\nvector transformation is evaluated through numerical comparisons; the overall\nmethod is evaluated through exploration examples and use cases.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:27:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bian", "Rongzheng", ""], ["Xue", "Yumeng", ""], ["Zhou", "Liang", ""], ["Zhang", "Jian", ""], ["Chen", "Baoquan", ""], ["Weiskopf", "Daniel", ""], ["Wang", "Yunhai", ""]]}, {"id": "2009.03268", "submitter": "Teng Liu", "authors": "Hong Shu, Teng Liu, Xingyu Mu, Dongpu Cao", "title": "Driving Tasks Transfer in Deep Reinforcement Learning for\n  Decision-making of Autonomous Vehicles", "comments": "10 pages 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge transfer is a promising concept to achieve real-time\ndecision-making for autonomous vehicles. This paper constructs a transfer deep\nreinforcement learning framework to transform the driving tasks in\ninter-section environments. The driving missions at the un-signalized\nintersection are cast into a left turn, right turn, and running straight for\nautomated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive\nthrough the intersection situation efficiently and safely. This objective\npromotes the studied vehicle to increase its speed and avoid crashing other\nvehicles. The decision-making pol-icy learned from one driving task is\ntransferred and evaluated in another driving mission. Simulation results reveal\nthat the decision-making strategies related to similar tasks are transferable.\nIt indicates that the presented control framework could reduce the time\nconsumption and realize online implementation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:34:01 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 14:16:31 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Shu", "Hong", ""], ["Liu", "Teng", ""], ["Mu", "Xingyu", ""], ["Cao", "Dongpu", ""]]}, {"id": "2009.03272", "submitter": "Vivek Subramanian", "authors": "Vivek Subramanian, Joshua Khani", "title": "Graph Convolutional Networks Reveal Neural Connections Encoding\n  Prosthetic Sensation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting stimulus features from neuronal ensembles is of great interest to\nthe development of neuroprosthetics that project sensory information directly\nto the brain via electrical stimulation. Machine learning strategies that\noptimize stimulation parameters as the subject learns to interpret the\nartificial input could improve device efficacy, increase prosthetic\nperformance, ensure stability of evoked sensations, and improve power\nconsumption by eliminating extraneous input. Recent advances extending deep\nlearning techniques to non-Euclidean graph data provide a novel approach to\ninterpreting neuronal spiking activity. For this study, we apply graph\nconvolutional networks (GCNs) to infer the underlying functional relationship\nbetween neurons that are involved in the processing of artificial sensory\ninformation. Data was collected from a freely behaving rat using a four\ninfrared (IR) sensor, ICMS-based neuroprosthesis to localize IR light sources.\nWe use GCNs to predict the stimulation frequency across four stimulating\nchannels in the prosthesis, which encode relative distance and directional\ninformation to an IR-emitting reward port. Our GCN model is able to achieve a\npeak performance of 73.5% on a modified ordinal regression performance metric\nin a multiclass classification problem consisting of 7 classes, where chance is\n14.3%. Additionally, the inferred adjacency matrix provides a adequate\nrepresentation of the underlying neural circuitry encoding the artificial\nsensation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 01:43:46 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Subramanian", "Vivek", ""], ["Khani", "Joshua", ""]]}, {"id": "2009.03288", "submitter": "Elisa Negrini", "authors": "Elisa Negrini, Giovanna Citti, Luca Capogna", "title": "System Identification Through Lipschitz Regularized Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use neural networks to learn governing equations from data.\nSpecifically we reconstruct the right-hand side of a system of ODEs $\\dot{x}(t)\n= f(t, x(t))$ directly from observed uniformly time-sampled data using a neural\nnetwork. In contrast with other neural network based approaches to this\nproblem, we add a Lipschitz regularization term to our loss function. In the\nsynthetic examples we observed empirically that this regularization results in\na smoother approximating function and better generalization properties when\ncompared with non-regularized models, both on trajectory and non-trajectory\ndata, especially in presence of noise. In contrast with sparse regression\napproaches, since neural networks are universal approximators, we don't need\nany prior knowledge on the ODE system. Since the model is applied component\nwise, it can handle systems of any dimension, making it usable for real-world\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:52:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Negrini", "Elisa", ""], ["Citti", "Giovanna", ""], ["Capogna", "Luca", ""]]}, {"id": "2009.03294", "submitter": "Tianle Cai", "authors": "Tianle Cai, Shengjie Luo, Keyulu Xu, Di He, Tie-Yan Liu, Liwei Wang", "title": "GraphNorm: A Principled Approach to Accelerating Graph Neural Network\n  Training", "comments": "ICML 2021, Code: https://github.com/lsj2408/GraphNorm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization is known to help the optimization of deep neural networks.\nCuriously, different architectures require specialized normalization methods.\nIn this paper, we study what normalization is effective for Graph Neural\nNetworks (GNNs). First, we adapt and evaluate the existing methods from other\ndomains to GNNs. Faster convergence is achieved with InstanceNorm compared to\nBatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm\nserves as a preconditioner for GNNs, but such preconditioning effect is weaker\nwith BatchNorm due to the heavy batch noise in graph datasets. Second, we show\nthat the shift operation in InstanceNorm results in an expressiveness\ndegradation of GNNs for highly regular graphs. We address this issue by\nproposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm\nconverge faster compared to GNNs using other normalization. GraphNorm also\nimproves the generalization of GNNs, achieving better performance on graph\nclassification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:55:21 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 03:53:02 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 09:35:15 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Cai", "Tianle", ""], ["Luo", "Shengjie", ""], ["Xu", "Keyulu", ""], ["He", "Di", ""], ["Liu", "Tie-Yan", ""], ["Wang", "Liwei", ""]]}, {"id": "2009.03298", "submitter": "Kamal Gupta", "authors": "Kamal Gupta and Susmija Jabbireddy and Ketul Shah and Abhinav\n  Shrivastava and Matthias Zwicker", "title": "Improved Modeling of 3D Shapes with Multi-view Depth Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple yet effective general-purpose framework for modeling 3D\nshapes by leveraging recent advances in 2D image generation using CNNs. Using\njust a single depth image of the object, we can output a dense multi-view depth\nmap representation of 3D objects. Our simple encoder-decoder framework,\ncomprised of a novel identity encoder and class-conditional viewpoint\ngenerator, generates 3D consistent depth maps. Our experimental results\ndemonstrate the two-fold advantage of our approach. First, we can directly\nborrow architectures that work well in the 2D image domain to 3D. Second, we\ncan effectively generate high-resolution 3D shapes with low computational\nmemory. Our quantitative evaluations show that our method is superior to\nexisting depth map methods for reconstructing and synthesizing 3D objects and\nis competitive with other representations, such as point clouds, voxel grids,\nand implicit functions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:58:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Gupta", "Kamal", ""], ["Jabbireddy", "Susmija", ""], ["Shah", "Ketul", ""], ["Shrivastava", "Abhinav", ""], ["Zwicker", "Matthias", ""]]}, {"id": "2009.03300", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika,\n  Dawn Song, Jacob Steinhardt", "title": "Measuring Massive Multitask Language Understanding", "comments": "ICLR 2021; the test and code is available at\n  https://github.com/hendrycks/test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new test to measure a text model's multitask accuracy. The test\ncovers 57 tasks including elementary mathematics, US history, computer science,\nlaw, and more. To attain high accuracy on this test, models must possess\nextensive world knowledge and problem solving ability. We find that while most\nrecent models have near random-chance accuracy, the very largest GPT-3 model\nimproves over random chance by almost 20 percentage points on average. However,\non every one of the 57 tasks, the best models still need substantial\nimprovements before they can reach expert-level accuracy. Models also have\nlopsided performance and frequently do not know when they are wrong. Worse,\nthey still have near-random accuracy on some socially important subjects such\nas morality and law. By comprehensively evaluating the breadth and depth of a\nmodel's academic and professional understanding, our test can be used to\nanalyze models across many tasks and to identify important shortcomings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:59:25 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 05:06:57 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:11 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Zou", "Andy", ""], ["Mazeika", "Mantas", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2009.03301", "submitter": "Maria Elli", "authors": "Jack Weast", "title": "Sensors, Safety Models and A System-Level Approach to Safe and Scalable\n  Automated Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering the accuracy of sensors in an automated vehicle (AV), it is\nnot sufficient to evaluate the performance of any given sensor in isolation.\nRather, the performance of any individual sensor must be considered in the\ncontext of the overall system design. Techniques like redundancy and different\nsensing modalities can reduce the chances of a sensing failure. Additionally,\nthe use of safety models is essential to understanding whether any particular\nsensing failure is relevant. Only when the entire system design is taken into\naccount can one properly understand the meaning of safety-relevant sensing\nfailures in an AV. In this paper, we will consider what should actually\nconstitute a sensing failure, how safety models play an important role in\nmitigating potential failures, how a system-level approach to safety will\ndeliver a safe and scalable AV, and what an acceptable sensing failure rate\nshould be considering the full picture of an AV's architecture.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:14:59 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Weast", "Jack", ""]]}, {"id": "2009.03303", "submitter": "L\\'eo Lebrat", "authors": "Rodrigo Santa Cruz, L\\'eo Lebrat, Pierrick Bourgeat, Vincent Dor\\'e,\n  Jason Dowling, Jurgen Fripp, Clinton Fookes, Olivier Salvado", "title": "Going deeper with brain morphometry using neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain morphometry from magnetic resonance imaging (MRI) is a consolidated\nbiomarker for many neurodegenerative diseases. Recent advances in this domain\nindicate that deep convolutional neural networks can infer morphometric\nmeasurements within a few seconds. Nevertheless, the accuracy of the devised\nmodel for insightful bio-markers (mean curvature and thickness) remains\nunsatisfactory. In this paper, we propose a more accurate and efficient neural\nnetwork model for brain morphometry named HerstonNet. More specifically, we\ndevelop a 3D ResNet-based neural network to learn rich features directly from\nMRI, design a multi-scale regression scheme by predicting morphometric measures\nat feature maps of different resolutions, and leverage a robust optimization\nmethod to avoid poor quality minima and reduce the prediction variance. As a\nresult, HerstonNet improves the existing approach by 24.30% in terms of\nintraclass correlation coefficient (agreement measure) to FreeSurfer\nsilver-standards while maintaining a competitive run-time.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 07:57:13 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Cruz", "Rodrigo Santa", ""], ["Lebrat", "L\u00e9o", ""], ["Bourgeat", "Pierrick", ""], ["Dor\u00e9", "Vincent", ""], ["Dowling", "Jason", ""], ["Fripp", "Jurgen", ""], ["Fookes", "Clinton", ""], ["Salvado", "Olivier", ""]]}, {"id": "2009.03323", "submitter": "\\'Alvaro Ribas", "authors": "\\'A. Ribas, C. C. Espaillat, E. Mac\\'ias, L. M. Sarro", "title": "Modeling protoplanetary disk SEDs with artificial neural networks:\n  Revisiting the viscous disk model and updated disk masses", "comments": "24 pages (including appendices), 13 figures. Accepted for publication\n  in Astronomy and Astrophysics", "journal-ref": "A&A 642, A171 (2020)", "doi": "10.1051/0004-6361/202038352", "report-no": null, "categories": "astro-ph.SR astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model the spectral energy distributions (SEDs) of 23 protoplanetary disks\nin the Taurus-Auriga star-forming region using detailed disk models and a\nBayesian approach. This is made possible by combining these models with\nartificial neural networks to drastically speed up their performance. Such a\nsetup allows us to confront $\\alpha$-disk models with observations while\naccounting for several uncertainties and degeneracies. Our results yield high\nviscosities and accretion rates for many sources, which is not consistent with\nrecent measurements of low turbulence levels in disks. This inconsistency could\nimply that viscosity is not the main mechanism for angular momentum transport\nin disks, and that alternatives such as disk winds play an important role in\nthis process. We also find that our SED-derived disk masses are systematically\nhigher than those obtained solely from (sub)mm fluxes, suggesting that part of\nthe disk emission could still be optically thick at (sub)mm wavelengths. This\neffect is particularly relevant for disk population studies and alleviates\nprevious observational tensions between the masses of protoplanetary disks and\nexoplanetary systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:00:02 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Ribas", "\u00c1.", ""], ["Espaillat", "C. C.", ""], ["Mac\u00edas", "E.", ""], ["Sarro", "L. M.", ""]]}, {"id": "2009.03349", "submitter": "Jithin Jagannath", "authors": "Jithin Jagannath, Anu Jagannath, Sean Furman, Tyler Gwin", "title": "Deep Learning and Reinforcement Learning for Autonomous Unmanned Aerial\n  Systems: Roadmap for Theory to Deployment", "comments": "Preprint of Book Chapter to be published in Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Systems (UAS) are being increasingly deployed for commercial,\ncivilian, and military applications. The current UAS state-of-the-art still\ndepends on a remote human controller with robust wireless links to perform\nseveral of these applications. The lack of autonomy restricts the domains of\napplication and tasks for which a UAS can be deployed. Enabling autonomy and\nintelligence to the UAS will help overcome this hurdle and expand its use\nimproving safety and efficiency. The exponential increase in computing\nresources and the availability of large amount of data in this digital era has\nled to the resurgence of machine learning from its last winter. Therefore, in\nthis chapter, we discuss how some of the advances in machine learning,\nspecifically deep learning and reinforcement learning can be leveraged to\ndevelop next-generation autonomous UAS. We first begin motivating this chapter\nby discussing the application, challenges, and opportunities of the current UAS\nin the introductory section. We then provide an overview of some of the key\ndeep learning and reinforcement learning techniques discussed throughout this\nchapter. A key area of focus that will be essential to enable autonomy to UAS\nis computer vision. Accordingly, we discuss how deep learning approaches have\nbeen used to accomplish some of the basic tasks that contribute to providing\nUAS autonomy. Then we discuss how reinforcement learning is explored for using\nthis information to provide autonomous control and navigation for UAS. Next, we\nprovide the reader with directions to choose appropriate simulation suites and\nhardware platforms that will help to rapidly prototype novel machine learning\nbased solutions for UAS. We additionally discuss the open problems and\nchallenges pertaining to each aspect of developing autonomous UAS solutions to\nshine light on potential research areas.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:10:16 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 00:32:11 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Jagannath", "Jithin", ""], ["Jagannath", "Anu", ""], ["Furman", "Sean", ""], ["Gwin", "Tyler", ""]]}, {"id": "2009.03352", "submitter": "Jin Cao", "authors": "Jin Cao and Dewei Zhong", "title": "A Fast Randomized Algorithm for Finding the Maximal Common Subsequences", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the common subsequences of $L$ multiple strings has many applications\nin the area of bioinformatics, computational linguistics, and information\nretrieval. A well-known result states that finding a Longest Common Subsequence\n(LCS) for $L$ strings is NP-hard, e.g., the computational complexity is\nexponential in $L$. In this paper, we develop a randomized algorithm, referred\nto as {\\em Random-MCS}, for finding a random instance of Maximal Common\nSubsequence ($MCS$) of multiple strings. A common subsequence is {\\em maximal}\nif inserting any character into the subsequence no longer yields a common\nsubsequence. A special case of MCS is LCS where the length is the longest. We\nshow the complexity of our algorithm is linear in $L$, and therefore is\nsuitable for large $L$. Furthermore, we study the occurrence probability for a\nsingle instance of MCS and demonstrate via both theoretical and experimental\nstudies that the longest subsequence from multiple runs of {\\em Random-MCS}\noften yields a solution to $LCS$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:12:58 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Cao", "Jin", ""], ["Zhong", "Dewei", ""]]}, {"id": "2009.03358", "submitter": "Jin Cao", "authors": "Jin Cao and Yibo Zhao and Linjun Zhang and Jason Li", "title": "A Lightweight Algorithm to Uncover Deep Relationships in Data Tables", "comments": "9 pages, 4 figures, paper presented on AutoML 2019 (The Third\n  International Workshop on Automation in Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data we collect today are in tabular form, with rows as records and\ncolumns as attributes associated with each record. Understanding the structural\nrelationship in tabular data can greatly facilitate the data science process.\nTraditionally, much of this relational information is stored in table schema\nand maintained by its creators, usually domain experts. In this paper, we\ndevelop automated methods to uncover deep relationships in a single data table\nwithout expert or domain knowledge. Our method can decompose a data table into\nlayers of smaller tables, revealing its deep structure. The key to our approach\nis a computationally lightweight forward addition algorithm that we developed\nto recursively extract the functional dependencies between table columns that\nare scalable to tables with many columns. With our solution, data scientists\nwill be provided with automatically generated, data-driven insights when\nexploring new data sets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:25:15 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Cao", "Jin", ""], ["Zhao", "Yibo", ""], ["Zhang", "Linjun", ""], ["Li", "Jason", ""]]}, {"id": "2009.03362", "submitter": "Rodrigo Rivera-Castro", "authors": "Rodrigo Rivera-Castro, Polina Pilyugina, Evgeny Burnaev", "title": "Topological Data Analysis for Portfolio Management of Cryptocurrencies", "comments": null, "journal-ref": "2019 International Conference on Data Mining Workshops (ICDMW)", "doi": "10.1109/ICDMW.2019.00044", "report-no": null, "categories": "q-fin.PM cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio management is essential for any investment decision. Yet,\ntraditional methods in the literature are ill-suited for the characteristics\nand dynamics of cryptocurrencies. This work presents a method to build an\ninvestment portfolio consisting of more than 1500 cryptocurrencies covering 6\nyears of market data. It is centred around Topological Data Analysis (TDA), a\nrecent approach to analyze data sets from the perspective of their topological\nstructure. This publication proposes a system combining persistence landscapes\nto identify suitable investment opportunities in cryptocurrencies. Using a\nnovel and comprehensive data set of cryptocurrency prices, this research shows\nthat the proposed system enables analysts to outperform a classic method from\nthe literature without requiring any feature engineering or domain knowledge in\nTDA. This work thus introduces TDA-based portfolio management of\ncryptocurrencies as a viable tool for the practitioner.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:30:36 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Pilyugina", "Polina", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.03376", "submitter": "Jingtao Ding", "authors": "Jingtao Ding, Yuhan Quan, Quanming Yao, Yong Li, Depeng Jin", "title": "Simplify and Robustify Negative Sampling for Implicit Collaborative\n  Filtering", "comments": "20 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative sampling approaches are prevalent in implicit collaborative\nfiltering for obtaining negative labels from massive unlabeled data. As two\nmajor concerns in negative sampling, efficiency and effectiveness are still not\nfully achieved by recent works that use complicate structures and overlook risk\nof false negative instances. In this paper, we first provide a novel\nunderstanding of negative instances by empirically observing that only a few\ninstances are potentially important for model learning, and false negatives\ntend to have stable predictions over many training iterations. Above findings\nmotivate us to simplify the model by sampling from designed memory that only\nstores a few important candidates and, more importantly, tackle the untouched\nfalse negative problem by favouring high-variance samples stored in memory,\nwhich achieves efficient sampling of true negatives with high-quality.\nEmpirical results on two synthetic datasets and three real-world datasets\ndemonstrate both robustness and superiorities of our negative sampling method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:08:26 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ding", "Jingtao", ""], ["Quan", "Yuhan", ""], ["Yao", "Quanming", ""], ["Li", "Yong", ""], ["Jin", "Depeng", ""]]}, {"id": "2009.03393", "submitter": "Stanislas Polu", "authors": "Stanislas Polu, Ilya Sutskever", "title": "Generative Language Modeling for Automated Theorem Proving", "comments": "15+5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of transformer-based language models to automated\ntheorem proving. This work is motivated by the possibility that a major\nlimitation of automated theorem provers compared to humans -- the generation of\noriginal mathematical terms -- might be addressable via generation from\nlanguage models. We present an automated prover and proof assistant, GPT-f, for\nthe Metamath formalization language, and analyze its performance. GPT-f found\nnew short proofs that were accepted into the main Metamath library, which is to\nour knowledge, the first time a deep-learning based system has contributed\nproofs that were adopted by a formal mathematics community.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:50:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Polu", "Stanislas", ""], ["Sutskever", "Ilya", ""]]}, {"id": "2009.03417", "submitter": "Kiran Tomlinson", "authors": "Kiran Tomlinson and Austin R. Benson", "title": "Learning Interpretable Feature Context Effects in Discrete Choice", "comments": "20 pages, 4 figures; updated results after bug fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outcomes of elections, product sales, and the structure of social\nconnections are all determined by the choices individuals make when presented\nwith a set of options, so understanding the factors that contribute to choice\nis crucial. Of particular interest are context effects, which occur when the\nset of available options influences a chooser's relative preferences, as they\nviolate traditional rationality assumptions yet are widespread in practice.\nHowever, identifying these effects from observed choices is challenging, often\nrequiring foreknowledge of the effect to be measured. In contrast, we provide a\nmethod for the automatic discovery of a broad class of context effects from\nobserved choice data. Our models are easier to train and more flexible than\nexisting models and also yield intuitive, interpretable, and statistically\ntestable context effects. Using our models, we identify new context effects in\nwidely used choice datasets and provide the first analysis of choice set\ncontext effects in social network growth.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 20:59:24 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 21:23:45 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tomlinson", "Kiran", ""], ["Benson", "Austin R.", ""]]}, {"id": "2009.03432", "submitter": "Gizem Sogancioglu", "authors": "Gizem So\\u{g}anc{\\i}o\\u{g}lu, Oxana Verkholyak, Heysem Kaya, Dmitrii\n  Fedotov, Tobias Cad\\`ee, Albert Ali Salah, Alexey Karpov", "title": "Is Everything Fine, Grandma? Acoustic and Linguistic Modeling for Robust\n  Elderly Speech Emotion Recognition", "comments": "5 pages, 1 figure, Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Acoustic and linguistic analysis for elderly emotion recognition is an\nunder-studied and challenging research direction, but essential for the\ncreation of digital assistants for the elderly, as well as unobtrusive\ntelemonitoring of elderly in their residences for mental healthcare purposes.\nThis paper presents our contribution to the INTERSPEECH 2020 Computational\nParalinguistics Challenge (ComParE) - Elderly Emotion Sub-Challenge, which is\ncomprised of two ternary classification tasks for arousal and valence\nrecognition. We propose a bi-modal framework, where these tasks are modeled\nusing state-of-the-art acoustic and linguistic features, respectively. In this\nstudy, we demonstrate that exploiting task-specific dictionaries and resources\ncan boost the performance of linguistic models, when the amount of labeled data\nis small. Observing a high mismatch between development and test set\nperformances of various models, we also propose alternative training and\ndecision fusion strategies to better estimate and improve the generalization\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 21:19:16 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["So\u011fanc\u0131o\u011flu", "Gizem", ""], ["Verkholyak", "Oxana", ""], ["Kaya", "Heysem", ""], ["Fedotov", "Dmitrii", ""], ["Cad\u00e8e", "Tobias", ""], ["Salah", "Albert Ali", ""], ["Karpov", "Alexey", ""]]}, {"id": "2009.03455", "submitter": "Rodrigo Rivera-Castro", "authors": "Ivan Maksimov, Rodrigo Rivera-Castro and Evgeny Burnaev", "title": "Addressing Cold Start in Recommender Systems with Hierarchical Graph\n  Neural Networks", "comments": "V2 with multiple changes", "journal-ref": "IEEE Big Data 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have become an essential instrument in a wide range of\nindustries to personalize the user experience. A significant issue that has\ncaptured both researchers' and industry experts' attention is the cold start\nproblem for new items. In this work, we present a graph neural network\nrecommender system using item hierarchy graphs and a bespoke architecture to\nhandle the cold start case for items. The experimental study on multiple\ndatasets and millions of users and interactions indicates that our method\nachieves better forecasting quality than the state-of-the-art with a comparable\ncomputational time.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 23:28:40 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 21:59:06 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Maksimov", "Ivan", ""], ["Rivera-Castro", "Rodrigo", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.03482", "submitter": "Tianjian Huang", "authors": "Tianjian Huang, Prajwal Singhania, Maziar Sanjabi, Pabitra Mitra and\n  Meisam Razaviyayn", "title": "Alternating Direction Method of Multipliers for Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization of the parameters of machine learning models, such as deep\nneural networks, requires solving constrained optimization problems, where the\nconstraint set is formed by the Cartesian product of many simple discrete sets.\nFor such optimization problems, we study the performance of the Alternating\nDirection Method of Multipliers for Quantization ($\\texttt{ADMM-Q}$) algorithm,\nwhich is a variant of the widely-used ADMM method applied to our discrete\noptimization problem. We establish the convergence of the iterates of\n$\\texttt{ADMM-Q}$ to certain $\\textit{stationary points}$. To the best of our\nknowledge, this is the first analysis of an ADMM-type method for problems with\ndiscrete variables/constraints. Based on our theoretical insights, we develop a\nfew variants of $\\texttt{ADMM-Q}$ that can handle inexact update rules, and\nhave improved performance via the use of \"soft projection\" and \"injecting\nrandomness to the algorithm\". We empirically evaluate the efficacy of our\nproposed approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 01:58:02 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 06:22:25 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Huang", "Tianjian", ""], ["Singhania", "Prajwal", ""], ["Sanjabi", "Maziar", ""], ["Mitra", "Pabitra", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2009.03488", "submitter": "Jintang Li", "authors": "Jintang Li, Tao Xie, Liang Chen, Fenfang Xie, Xiangnan He, Zibin Zheng", "title": "Adversarial Attack on Large Scale Graph", "comments": "Accepted by TKDE, the codes are availiable at\n  https://github.com/EdisonLeeeee/SGAttack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that graph neural networks (GNNs) are vulnerable\nagainst perturbations due to lack of robustness and can therefore be easily\nfooled. Currently, most works on attacking GNNs are mainly using gradient\ninformation to guide the attack and achieve outstanding performance. However,\nthe high complexity of time and space makes them unmanageable for large scale\ngraphs and becomes the major bottleneck that prevents the practical usage. We\nargue that the main reason is that they have to use the whole graph for\nattacks, resulting in the increasing time and space complexity as the data\nscale grows. In this work, we propose an efficient Simplified Gradient-based\nAttack (SGA) method to bridge this gap. SGA can cause the GNNs to misclassify\nspecific target nodes through a multi-stage attack framework, which needs only\na much smaller subgraph. In addition, we present a practical metric named\nDegree Assortativity Change (DAC) to measure the impacts of adversarial attacks\non graph data. We evaluate our attack method on four real-world graph networks\nby attacking several commonly used GNNs. The experimental results demonstrate\nthat SGA can achieve significant time and memory efficiency improvements while\nmaintaining competitive attack performance compared to state-of-art attack\ntechniques. Codes are available via: https://github.com/EdisonLeeeee/SGAttack.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 02:17:55 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 14:15:27 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Jintang", ""], ["Xie", "Tao", ""], ["Chen", "Liang", ""], ["Xie", "Fenfang", ""], ["He", "Xiangnan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2009.03506", "submitter": "Sheng Yu", "authors": "Yucong Lin, Keming Lu, Yulin Chen, Chuan Hong, Sheng Yu", "title": "High-throughput relation extraction algorithm development associating\n  knowledge articles and electronic health records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Medical relations are the core components of medical knowledge\ngraphs that are needed for healthcare artificial intelligence. However, the\nrequirement of expert annotation by conventional algorithm development\nprocesses creates a major bottleneck for mining new relations. In this paper,\nwe present Hi-RES, a framework for high-throughput relation extraction\nalgorithm development. We also show that combining knowledge articles with\nelectronic health records (EHRs) significantly increases the classification\naccuracy. Methods: We use relation triplets obtained from structured databases\nand semistructured webpages to label sentences from target corpora as positive\ntraining samples. Two methods are also provided for creating improved negative\nsamples by combining positive samples with na\\\"ive negative samples. We propose\na common model that summarizes sentence information using large-scale\npretrained language models and multi-instance attention, which then joins with\nthe concept embeddings trained from the EHRs for relation prediction. Results:\nWe apply the Hi-RES framework to develop classification algorithms for\ndisorder-disorder relations and disorder-location relations. Millions of\nsentences are created as training data. Using pretrained language models and\nEHR-based embeddings individually provides considerable accuracy increases over\nthose of previous models. Joining them together further tremendously increases\nthe accuracy to 0.947 and 0.998 for the two sets of relations, respectively,\nwhich are 10-17 percentage points higher than those of previous models.\nConclusion: Hi-RES is an efficient framework for achieving high-throughput and\naccurate relation extraction algorithm development.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 03:48:30 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Lin", "Yucong", ""], ["Lu", "Keming", ""], ["Chen", "Yulin", ""], ["Hong", "Chuan", ""], ["Yu", "Sheng", ""]]}, {"id": "2009.03509", "submitter": "Shikun Feng", "authors": "Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjin Wang, Yu\n  Sun", "title": "Masked Label Prediction: Unified Message Passing Model for\n  Semi-Supervised Classification", "comments": "7 pages, 3 figures and 8 tables; Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN) and label propagation algorithm (LPA) are both\nmessage passing algorithms, which have achieved superior performance in\nsemi-supervised classification. GNN performs feature propagation by a neural\nnetwork to make predictions, while LPA uses label propagation across graph\nadjacency matrix to get results. However, there is still no effective way to\ndirectly combine these two kinds of algorithms. To address this issue, we\npropose a novel Unified Message Passaging Model (UniMP) that can incorporate\nfeature and label propagation at both training and inference time. First, UniMP\nadopts a Graph Transformer network, taking feature embedding and label\nembedding as input information for propagation. Second, to train the network\nwithout overfitting in self-loop input label information, UniMP introduces a\nmasked label prediction strategy, in which some percentage of input label\ninformation are masked at random, and then predicted. UniMP conceptually\nunifies feature propagation and label propagation and is empirically powerful.\nIt obtains new state-of-the-art semi-supervised classification results in Open\nGraph Benchmark (OGB).\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 04:04:04 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 07:19:36 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 10:09:19 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 07:32:58 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 02:23:20 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Shi", "Yunsheng", ""], ["Huang", "Zhengjie", ""], ["Feng", "Shikun", ""], ["Zhong", "Hui", ""], ["Wang", "Wenjin", ""], ["Sun", "Yu", ""]]}, {"id": "2009.03510", "submitter": "Boyi Liu", "authors": "Boyi Liu, Bingjie Yan, Yize Zhou, Zhixuan Liang, Cheng-Zhong Xu", "title": "FedCM: A Real-time Contribution Measurement Method for Participants in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated Learning (FL) creates an ecosystem for multiple agents to\ncollaborate on building models with data privacy consideration. The method for\ncontribution measurement of each agent in the FL system is critical for fair\ncredits allocation but few are proposed. In this paper, we develop a real-time\ncontribution measurement method FedCM that is simple but powerful. The method\ndefines the impact of each agent, comprehensively considers the current round\nand the previous round to obtain the contribution rate of each agent with\nattention aggregation. Moreover, FedCM updates contribution every round, which\nenable it to perform in real-time. Real-time is not considered by the existing\napproaches, but it is critical for FL systems to allocate computing power,\ncommunication resources, etc. Compared to the state-of-the-art method, the\nexperimental results show that FedCM is more sensitive to data quantity and\ndata quality under the premise of real-time. Furthermore, we developed\nfederated learning open-source software based on FedCM. The software has been\napplied to identify COVID-19 based on medical images.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 04:05:10 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:03:54 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Liu", "Boyi", ""], ["Yan", "Bingjie", ""], ["Zhou", "Yize", ""], ["Liang", "Zhixuan", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "2009.03527", "submitter": "Yuanyu Wan", "authors": "Yuanyu Wan and Lijun Zhang", "title": "Approximate Multiplication of Sparse Matrices with Limited Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate matrix multiplication with limited space has received\never-increasing attention due to the emergence of large-scale applications.\nRecently, based on a popular matrix sketching algorithm---frequent directions,\nprevious work has introduced co-occuring directions (COD) to reduce the\napproximation error for this problem. Although it enjoys the space complexity\nof $O((m_x+m_y)\\ell)$ for two input matrices $X\\in\\mathbb{R}^{m_x\\times n}$ and\n$Y\\in\\mathbb{R}^{m_y\\times n}$ where $\\ell$ is the sketch size, its time\ncomplexity is $O\\left(n(m_x+m_y+\\ell)\\ell\\right)$, which is still very high for\nlarge input matrices. In this paper, we propose to reduce the time complexity\nby exploiting the sparsity of the input matrices. The key idea is to employ an\napproximate singular value decomposition (SVD) method which can utilize the\nsparsity, to reduce the number of QR decompositions required by COD. In this\nway, we develop sparse co-occuring directions, which reduces the time\ncomplexity to $\\widetilde{O}\\left((\\nnz(X)+\\nnz(Y))\\ell+n\\ell^2\\right)$ in\nexpectation while keeps the same space complexity as $O((m_x+m_y)\\ell)$, where\n$\\nnz(X)$ denotes the number of non-zero entries in $X$. Theoretical analysis\nreveals that the approximation error of our algorithm is almost the same as\nthat of COD. Furthermore, we empirically verify the efficiency and\neffectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 05:39:19 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Wan", "Yuanyu", ""], ["Zhang", "Lijun", ""]]}, {"id": "2009.03534", "submitter": "Hyungjun Kim", "authors": "Eunho Koo and Hyungjun Kim", "title": "Empirical Strategy for Stretching Probability Distribution in\n  Neural-network-based Regression", "comments": "13 pages, 4 figures, to be submitted to Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis under artificial neural networks, the prediction\nperformance depends on determining the appropriate weights between layers. As\nrandomly initialized weights are updated during back-propagation using the\ngradient descent procedure under a given loss function, the loss function\nstructure can affect the performance significantly. In this study, we\nconsidered the distribution error, i.e., the inconsistency of two distributions\n(those of the predicted values and label), as the prediction error, and\nproposed weighted empirical stretching (WES) as a novel loss function to\nincrease the overlap area of the two distributions. The function depends on the\ndistribution of a given label, thus, it is applicable to any distribution\nshape. Moreover, it contains a scaling hyperparameter such that the appropriate\nparameter value maximizes the common section of the two distributions. To test\nthe function capability, we generated ideal distributed curves (unimodal,\nskewed unimodal, bimodal, and skewed bimodal) as the labels, and used the\nFourier-extracted input data from the curves under a feedforward neural\nnetwork. In general, WES outperformed loss functions in wide use, and the\nperformance was robust to the various noise levels. The improved results in\nRMSE for the extreme domain (i.e., both tail regions of the distribution) are\nexpected to be utilized for prediction of abnormal events in non-linear complex\nsystems such as natural disaster and financial crisis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 06:08:14 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Koo", "Eunho", ""], ["Kim", "Hyungjun", ""]]}, {"id": "2009.03543", "submitter": "Alistair Shilton", "authors": "Alistair Shilton, Sunil Gupta, Santu Rana, Svetha Venkatesh", "title": "Sequential Subspace Search for Functional Bayesian Optimization\n  Incorporating Experimenter Intuition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for Bayesian functional optimisation - that is,\nfinding the function to optimise a process - guided by experimenter beliefs and\nintuitions regarding the expected characteristics (length-scale, smoothness,\ncyclicity etc.) of the optimal solution encoded into the covariance function of\na Gaussian Process. Our algorithm generates a sequence of finite-dimensional\nrandom subspaces of functional space spanned by a set of draws from the\nexperimenter's Gaussian Process. Standard Bayesian optimisation is applied on\neach subspace, and the best solution found used as a starting point (origin)\nfor the next subspace. Using the concept of effective dimensionality, we\nanalyse the convergence of our algorithm and provide a regret bound to show\nthat our algorithm converges in sub-linear time provided a finite effective\ndimension exists. We test our algorithm in simulated and real-world\nexperiments, namely blind function matching, finding the optimal\nprecipitation-strengthening function for an aluminium alloy, and learning rate\nschedule optimisation for deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 06:54:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Shilton", "Alistair", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2009.03566", "submitter": "Adi Hanuka", "authors": "Adi Hanuka, X. Huang, J. Shtalenkova, D. Kennedy, A. Edelen, V. R.\n  Lalchand, D. Ratner, and J. Duris", "title": "Physics-informed Gaussian Process for Online Optimization of Particle\n  Accelerators", "comments": null, "journal-ref": "Phys. Rev. Accel. Beams 24, 072802 (2021)", "doi": "10.1103/PhysRevAccelBeams.24.072802", "report-no": null, "categories": "physics.comp-ph cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional optimization is a critical challenge for operating\nlarge-scale scientific facilities. We apply a physics-informed Gaussian process\n(GP) optimizer to tune a complex system by conducting efficient global search.\nTypical GP models learn from past observations to make predictions, but this\nreduces their applicability to new systems where archive data is not available.\nInstead, here we use a fast approximate model from physics simulations to\ndesign the GP model. The GP is then employed to make inferences from sequential\nonline observations in order to optimize the system. Simulation and\nexperimental studies were carried out to demonstrate the method for online\ncontrol of a storage ring. We show that the physics-informed GP outperforms\ncurrent routinely used online optimizers in terms of convergence speed, and\nrobustness on this task. The ability to inform the machine-learning model with\nphysics may have wide applications in science.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:02:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Hanuka", "Adi", ""], ["Huang", "X.", ""], ["Shtalenkova", "J.", ""], ["Kennedy", "D.", ""], ["Edelen", "A.", ""], ["Lalchand", "V. R.", ""], ["Ratner", "D.", ""], ["Duris", "J.", ""]]}, {"id": "2009.03567", "submitter": "Manuel Camargo", "authors": "Manuel Camargo, Marlon Dumas, Oscar Gonzalez-Rojas", "title": "Discovering Generative Models from Event Logs: Data-driven Simulation vs\n  Deep Learning", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generative model is a statistical model that is able to generate new data\ninstances from previously observed ones. In the context of business processes,\na generative model creates new execution traces from a set of historical\ntraces, also known as an event log. Two families of generative process\nsimulation models have been developed in previous work: data-driven simulation\nmodels and deep learning models. Until now, these two approaches have evolved\nindependently and their relative performance has not been studied. This paper\nfills this gap by empirically comparing a data-driven simulation technique with\nmultiple deep learning techniques, which construct models are capable of\ngenerating execution traces with timestamped events. The study sheds light into\nthe relative strengths of both approaches and raises the prospect of developing\nhybrid approaches that combine these strengths.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:04:06 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Camargo", "Manuel", ""], ["Dumas", "Marlon", ""], ["Gonzalez-Rojas", "Oscar", ""]]}, {"id": "2009.03586", "submitter": "Aijun Zhang", "authors": "Zebin Yang and Aijun Zhang", "title": "Hyperparameter Optimization via Sequential Uniform Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization (HPO) plays a central role in the automated\nmachine learning (AutoML). It is a challenging task as the response surfaces of\nhyperparameters are generally unknown, hence essentially a global optimization\nproblem. This paper reformulates HPO as a computer experiment and proposes a\nnovel sequential uniform design (SeqUD) strategy with three-fold advantages: a)\nthe hyperparameter space is adaptively explored with evenly spread design\npoints, without the need of expensive meta-modeling and acquisition\noptimization; b) the batch-by-batch design points are sequentially generated\nwith parallel processing support; c) a new augmented uniform design algorithm\nis developed for the efficient real-time generation of follow-up design points.\nExtensive experiments are conducted on both global optimization tasks and HPO\napplications. The numerical results show that the proposed SeqUD strategy\noutperforms benchmark HPO methods, and it can be therefore a promising and\ncompetitive alternative to existing AutoML tools.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:55:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:12:26 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yang", "Zebin", ""], ["Zhang", "Aijun", ""]]}, {"id": "2009.03603", "submitter": "Peng Yang", "authors": "Hu Zhang, Peng Yang, Yanglong Yu, Mingjia Li, Ke Tang", "title": "Evolutionary Reinforcement Learning via Cooperative Coevolutionary\n  Negatively Correlated Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) have been successfully applied to optimize the\npolicies for Reinforcement Learning (RL) tasks due to their exploration\nability. The recently proposed Negatively Correlated Search (NCS) provides a\ndistinct parallel exploration search behavior and is expected to facilitate RL\nmore effectively. Considering that the commonly adopted neural policies usually\ninvolves millions of parameters to be optimized, the direct application of NCS\nto RL may face a great challenge of the large-scale search space. To address\nthis issue, this paper presents an NCS-friendly Cooperative Coevolution (CC)\nframework to scale-up NCS while largely preserving its parallel exploration\nsearch behavior. The issue of traditional CC that can deteriorate NCS is also\ndiscussed. Empirical studies on 10 popular Atari games show that the proposed\nmethod can significantly outperform three state-of-the-art deep RL methods with\n50% less computational time by effectively exploring a 1.7 million-dimensional\nsearch space.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 09:28:30 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhang", "Hu", ""], ["Yang", "Peng", ""], ["Yu", "Yanglong", ""], ["Li", "Mingjia", ""], ["Tang", "Ke", ""]]}, {"id": "2009.03614", "submitter": "Francisco Javier Bald\\'an", "authors": "Francisco J. Bald\\'an, Jos\\'e M. Ben\\'itez", "title": "Multivariable times series classification through an interpretable\n  representation", "comments": "26 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series classification is a task with increasing importance\ndue to the proliferation of new problems in various fields (economy, health,\nenergy, transport, crops, etc.) where a large number of information sources are\navailable. Direct extrapolation of methods that traditionally worked in\nunivariate environments cannot frequently be applied to obtain the best results\nin multivariate problems. This is mainly due to the inability of these methods\nto capture the relationships between the different variables that conform a\nmultivariate time series. The multivariate proposals published to date offer\ncompetitive results but are hard to interpret. In this paper we propose a time\nseries classification method that considers an alternative representation of\ntime series through a set of descriptive features taking into account the\nrelationships between the different variables of a multivariate time series. We\nhave applied traditional classification algorithms obtaining interpretable and\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 09:44:03 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bald\u00e1n", "Francisco J.", ""], ["Ben\u00edtez", "Jos\u00e9 M.", ""]]}, {"id": "2009.03622", "submitter": "Pablo Lanillos", "authors": "Otto van der Himst, Pablo Lanillos", "title": "Deep Active Inference for Partially Observable MDPs", "comments": "1st International Workshop on Active inference, European Conference\n  on Machine Learning (ECML/PCKDD 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-64919-7_8", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep active inference has been proposed as a scalable approach to perception\nand action that deals with large policy and state spaces. However, current\nmodels are limited to fully observable domains. In this paper, we describe a\ndeep active inference model that can learn successful policies directly from\nhigh-dimensional sensory inputs. The deep learning architecture optimizes a\nvariant of the expected free energy and encodes the continuous state\nrepresentation by means of a variational autoencoder. We show, in the OpenAI\nbenchmark, that our approach has comparable or better performance than deep\nQ-learning, a state-of-the-art deep reinforcement learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:02:40 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["van der Himst", "Otto", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2009.03632", "submitter": "Chris Dongjoo Kim", "authors": "Chris Dongjoo Kim, Jinseo Jeong, and Gunhee Kim", "title": "Imbalanced Continual Learning with Partitioning Reservoir Sampling", "comments": "Published to ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning from a sequential stream of data is a crucial challenge\nfor machine learning research. Most studies have been conducted on this topic\nunder the single-label classification setting along with an assumption of\nbalanced label distribution. This work expands this research horizon towards\nmulti-label classification. In doing so, we identify unanticipated adversity\ninnately existent in many multi-label datasets, the long-tailed distribution.\nWe jointly address the two independently solved problems, Catastropic\nForgetting and the long-tailed label distribution by first empirically showing\na new challenge of destructive forgetting of the minority concepts on the tail.\nThen, we curate two benchmark datasets, COCOseq and NUS-WIDEseq, that allow the\nstudy of both intra- and inter-task imbalances. Lastly, we propose a new\nsampling strategy for replay-based approach named Partitioning Reservoir\nSampling (PRS), which allows the model to maintain a balanced knowledge of both\nhead and tail classes. We publicly release the dataset and the code in our\nproject page.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:28:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Kim", "Chris Dongjoo", ""], ["Jeong", "Jinseo", ""], ["Kim", "Gunhee", ""]]}, {"id": "2009.03651", "submitter": "Sasho Nedelkoski", "authors": "Sasho Nedelkoski, Mihail Bogojeski, Odej Kao", "title": "Learning more expressive joint distributions in multimodal variational\n  methods", "comments": "12 pages, Accepted and presented at LOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data often are formed of multiple modalities, which jointly describe the\nobserved phenomena. Modeling the joint distribution of multimodal data requires\nlarger expressive power to capture high-level concepts and provide better data\nrepresentations. However, multimodal generative models based on variational\ninference are limited due to the lack of flexibility of the approximate\nposterior, which is obtained by searching within a known parametric family of\ndistributions. We introduce a method that improves the representational\ncapacity of multimodal variational methods using normalizing flows. It\napproximates the joint posterior with a simple parametric distribution and\nsubsequently transforms into a more complex one. Through several experiments,\nwe demonstrate that the model improves on state-of-the-art multimodal methods\nbased on variational inference on various computer vision tasks such as\ncolorization, edge and mask detection, and weakly supervised learning. We also\nshow that learning more powerful approximate joint distributions improves the\nquality of the generated samples. The code of our model is publicly available\nat https://github.com/SashoNedelkoski/BPFDMVM.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:45:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nedelkoski", "Sasho", ""], ["Bogojeski", "Mihail", ""], ["Kao", "Odej", ""]]}, {"id": "2009.03661", "submitter": "Rodrigo Rivera-Castro", "authors": "Rodrigo Rivera-Castro, Aleksandr Pletnev, Polina Pilyugina, Grecia\n  Diaz, Ivan Nazarov, Wanyi Zhu and Evgeny Burnaev", "title": "Topology-based Clusterwise Regression for User Segmentation and Demand\n  Forecasting", "comments": null, "journal-ref": "2019 IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA)", "doi": "10.1109/DSAA.2019.00048", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) is a recent approach to analyze data sets\nfrom the perspective of their topological structure. Its use for time series\ndata has been limited. In this work, a system developed for a leading provider\nof cloud computing combining both user segmentation and demand forecasting is\npresented. It consists of a TDA-based clustering method for time series\ninspired by a popular managerial framework for customer segmentation and\nextended to the case of clusterwise regression using matrix factorization\nmethods to forecast demand. Increasing customer loyalty and producing accurate\nforecasts remain active topics of discussion both for researchers and managers.\nUsing a public and a novel proprietary data set of commercial data, this\nresearch shows that the proposed system enables analysts to both cluster their\nuser base and plan demand at a granular level with significantly higher\naccuracy than a state of the art baseline. This work thus seeks to introduce\nTDA-based clustering of time series and clusterwise regression with matrix\nfactorization methods as viable tools for the practitioner.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:10:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Pletnev", "Aleksandr", ""], ["Pilyugina", "Polina", ""], ["Diaz", "Grecia", ""], ["Nazarov", "Ivan", ""], ["Zhu", "Wanyi", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.03667", "submitter": "Konstantinos Gavriil", "authors": "Konstantinos Gavriil, Ruslan Guseinov, Jes\\'us P\\'erez, Davide Pellis,\n  Paul Henderson, Florian Rist, Helmut Pottmann, Bernd Bickel", "title": "Computational Design of Cold Bent Glass Fa\\c{c}ades", "comments": null, "journal-ref": null, "doi": "10.1145/3414685.3417843", "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold bent glass is a promising and cost-efficient method for realizing doubly\ncurved glass fa\\c{c}ades. They are produced by attaching planar glass sheets to\ncurved frames and require keeping the occurring stress within safe limits.\nHowever, it is very challenging to navigate the design space of cold bent glass\npanels due to the fragility of the material, which impedes the form-finding for\npractically feasible and aesthetically pleasing cold bent glass fa\\c{c}ades. We\npropose an interactive, data-driven approach for designing cold bent glass\nfa\\c{c}ades that can be seamlessly integrated into a typical architectural\ndesign pipeline. Our method allows non-expert users to interactively edit a\nparametric surface while providing real-time feedback on the deformed shape and\nmaximum stress of cold bent glass panels. Designs are automatically refined to\nminimize several fairness criteria while maximal stresses are kept within glass\nlimits. We achieve interactive frame rates by using a differentiable Mixture\nDensity Network trained from more than a million simulations. Given a curved\nboundary, our regression model is capable of handling multistable\nconfigurations and accurately predicting the equilibrium shape of the panel and\nits corresponding maximal stress. We show predictions are highly accurate and\nvalidate our results with a physical realization of a cold bent glass surface.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:14:37 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Gavriil", "Konstantinos", ""], ["Guseinov", "Ruslan", ""], ["P\u00e9rez", "Jes\u00fas", ""], ["Pellis", "Davide", ""], ["Henderson", "Paul", ""], ["Rist", "Florian", ""], ["Pottmann", "Helmut", ""], ["Bickel", "Bernd", ""]]}, {"id": "2009.03671", "submitter": "Haocong Rao", "authors": "Haocong Rao, Siqi Wang, Xiping Hu, Mingkui Tan, Yi Guo, Jun Cheng,\n  Xinwang Liu, and Bin Hu", "title": "A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D\n  Skeleton Based Person Re-Identification", "comments": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (T-PAMI). Journal version of\n  https://www.ijcai.org/proceedings/2020/0125 (IJCAI 2020). Codes are available\n  at https://github.com/Kali-Hac/Locality-Awareness-SGE. arXiv admin note: text\n  overlap with arXiv:2008.09435", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3092833", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (Re-ID) via gait features within 3D skeleton\nsequences is a newly-emerging topic with several advantages. Existing solutions\neither rely on hand-crafted descriptors or supervised gait representation\nlearning. This paper proposes a self-supervised gait encoding approach that can\nleverage unlabeled skeleton data to learn gait representations for person\nRe-ID. Specifically, we first create self-supervision by learning to\nreconstruct unlabeled skeleton sequences reversely, which involves richer\nhigh-level semantics to obtain better gait representations. Other pretext tasks\nare also explored to further improve self-supervised learning. Second, inspired\nby the fact that motion's continuity endows adjacent skeletons in one skeleton\nsequence and temporally consecutive skeleton sequences with higher correlations\n(referred as locality in 3D skeleton data), we propose a locality-aware\nattention mechanism and a locality-aware contrastive learning scheme, which aim\nto preserve locality-awareness on intra-sequence level and inter-sequence level\nrespectively during self-supervised learning. Last, with context vectors\nlearned by our locality-aware attention mechanism and contrastive learning\nscheme, a novel feature named Constrastive Attention-based Gait Encodings\n(CAGEs) is designed to represent gait effectively. Empirical evaluations show\nthat our approach significantly outperforms skeleton-based counterparts by\n15-40% Rank-1 accuracy, and it even achieves superior performance to numerous\nmulti-modal methods with extra RGB or depth information. Our codes are\navailable at https://github.com/Kali-Hac/Locality-Awareness-SGE.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:06:04 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 13:38:43 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 02:37:09 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rao", "Haocong", ""], ["Wang", "Siqi", ""], ["Hu", "Xiping", ""], ["Tan", "Mingkui", ""], ["Guo", "Yi", ""], ["Cheng", "Jun", ""], ["Liu", "Xinwang", ""], ["Hu", "Bin", ""]]}, {"id": "2009.03681", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Hamdi Amroun, Mehdi Ammi", "title": "Energy Expenditure Estimation Through Daily Activity Recognition Using a\n  Smart-phone", "comments": null, "journal-ref": "2018 IEEE 4th World Forum on Internet of Things (WF-IoT)", "doi": "10.1109/WF-IoT.2018.8355097", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a 3-step system that estimates the real-time energy\nexpenditure of an individual in a non-intrusive way. First, using the user's\nsmart-phone's sensors, we build a Decision Tree model to recognize his physical\nactivity (\\textit{running}, \\textit{standing}, ...). Then, we use the detected\nphysical activity, the time and the user's speed to infer his daily activity\n(\\textit{watching TV}, \\textit{going to the bathroom}, ...) through the use of\na reinforcement learning environment, the Partially Observable Markov Decision\nProcess framework. Once the daily activities are recognized, we translate this\ninformation into energy expenditure using the compendium of physical\nactivities. By successfully detecting 8 physical activities at 90\\%, we reached\nan overall accuracy of 80\\% in recognizing 17 different daily activities. This\nresult leads us to estimate the energy expenditure of the user with a mean\nerror of 26\\% of the expected estimation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:26:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Amroun", "Hamdi", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03714", "submitter": "Zhao Zhang", "authors": "Yan Zhang, Zhao Zhang, Yang Wang, Zheng Zhang, Li Zhang, Shuicheng\n  Yan, Meng Wang", "title": "Dual-constrained Deep Semi-Supervised Coupled Factorization Network with\n  Enriched Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization is usually powerful for learning the\n\"shallow\" parts-based representation, but it clearly fails to discover deep\nhierarchical information within both the basis and representation spaces. In\nthis paper, we technically propose a new enriched prior based Dual-constrained\nDeep Semi-Supervised Coupled Factorization Network, called DS2CF-Net, for\nlearning the hierarchical coupled representations. To ex-tract hidden deep\nfeatures, DS2CF-Net is modeled as a deep-structure and geometrical\nstructure-constrained neural network. Specifically, DS2CF-Net designs a deep\ncoupled factorization architecture using multi-layers of linear\ntransformations, which coupled updates the bases and new representations in\neach layer. To improve the discriminating ability of learned deep\nrepresentations and deep coefficients, our network clearly considers enriching\nthe supervised prior by the joint deep coefficients-regularized label\nprediction, and incorporates enriched prior information as additional label and\nstructure constraints. The label constraint can enable the samples of the same\nlabel to have the same coordinate in the new feature space, while the structure\nconstraint forces the coefficient matrices in each layer to be block-diagonal\nso that the enhanced prior using the self-expressive label propagation are more\naccurate. Our network also integrates the adaptive dual-graph learning to\nretain the local manifold structures of both the data manifold and feature\nmanifold by minimizing the reconstruction errors in each layer. Extensive\nexperiments on several real databases demonstrate that our DS2CF-Net can obtain\nstate-of-the-art performance for representation learning and clustering.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:10:21 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhang", "Yan", ""], ["Zhang", "Zhao", ""], ["Wang", "Yang", ""], ["Zhang", "Zheng", ""], ["Zhang", "Li", ""], ["Yan", "Shuicheng", ""], ["Wang", "Meng", ""]]}, {"id": "2009.03715", "submitter": "Amir Mirzaeinia", "authors": "Amir Mirzaeinnia, Mehdi Mirzaeinia, Abdelmounaam Rezgui", "title": "Latency and Throughput Optimization in Modern Networks: A Comprehensive\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern applications are highly sensitive to communication delays and\nthroughput. This paper surveys major attempts on reducing latency and\nincreasing the throughput. These methods are surveyed on different networks and\nsurroundings such as wired networks, wireless networks, application layer\ntransport control, Remote Direct Memory Access, and machine learning based\ntransport control.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:17:26 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Mirzaeinnia", "Amir", ""], ["Mirzaeinia", "Mehdi", ""], ["Rezgui", "Abdelmounaam", ""]]}, {"id": "2009.03717", "submitter": "Zhiqiang Zhong", "authors": "Zhiqiang Zhong, Cheng-Te Li, and Jun Pang", "title": "Hierarchical Message-Passing Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have become a promising approach to machine\nlearning with graphs. Since existing GNN models are based on flat\nmessage-passing mechanisms, two limitations need to be tackled. One is costly\nin encoding global information on the graph topology. The other is failing to\nmodel meso- and macro-level semantics hidden in the graph, such as the\nknowledge of institutes and research areas in an academic collaboration\nnetwork. To deal with these two issues, we propose a novel Hierarchical\nMessage-Passing Graph Neural Networks framework. The main idea is to generate a\nhierarchical structure that re-organises all nodes in a graph into multi-level\nclusters, along with intra- and inter-level edge connections. The derived\nhierarchy not only creates shortcuts connecting far-away nodes so that global\ninformation can be efficiently accessed via message passing but also\nincorporates meso- and macro-level semantics into the learning of node\nembedding. We present the first model to implement this hierarchical\nmessage-passing mechanism, termed Hierarchical Community-aware Graph Neural\nNetwork (HC-GNN), based on hierarchical communities detected from the graph.\nExperiments conducted on eight datasets under transductive, inductive, and\nfew-shot settings exhibit that HC-GNN can outperform state-of-the-art GNN\nmodels in network analysis tasks, including node classification, link\nprediction, and community detection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:11:07 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhong", "Zhiqiang", ""], ["Li", "Cheng-Te", ""], ["Pang", "Jun", ""]]}, {"id": "2009.03727", "submitter": "Takumi Ishiyama", "authors": "Takumi Ishiyama, Takuya Suzuki, Hayato Yamana", "title": "Highly Accurate CNN Inference Using Approximate Activation Functions\n  over Homomorphic Encryption", "comments": "Accepted at 7th International Workshop on Privacy and Security of Big\n  Data in conjunction with 2020 IEEE International Conference on Big Data (IEEE\n  BigData 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, cloud-based machine learning as a service (MLaaS) has\nattracted considerable attention. However, when handling sensitive data, such\nas financial and medical data, a privacy issue emerges, because the cloud\nserver can access clients' raw data. A common method of handling sensitive data\nin the cloud uses homomorphic encryption, which allows computation over\nencrypted data without decryption. Previous research usually adopted a\nlow-degree polynomial mapping function, such as the square function, for data\nclassification. However, this technique results in low classification accuracy.\nIn this study, we seek to improve the classification accuracy for inference\nprocessing in a convolutional neural network (CNN) while using homomorphic\nencryption. We adopt an activation function that approximates Google's Swish\nactivation function while using a fourth-order polynomial. We also adopt batch\nnormalization to normalize the inputs for the Swish function to fit the input\nrange to minimize the error. We implemented CNN inference labeling over\nhomomorphic encryption using the Microsoft's Simple Encrypted Arithmetic\nLibrary for the Cheon-Kim-Kim-Song (CKKS) scheme. The experimental evaluations\nconfirmed classification accuracies of 99.22% and 80.48% for MNIST and\nCIFAR-10, respectively, which entails 0.04% and 4.11% improvements,\nrespectively, over previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:20:59 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 15:09:48 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ishiyama", "Takumi", ""], ["Suzuki", "Takuya", ""], ["Yamana", "Hayato", ""]]}, {"id": "2009.03730", "submitter": "Patrick Stiller", "authors": "Patrick Stiller and Friedrich Bethke and Maximilian B\\\"ohme and\n  Richard Pausch and Sunna Torge and Alexander Debus and Jan Vorberger and\n  Michael Bussmann and Nico Hoffmann", "title": "Large-scale Neural Solvers for Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving partial differential equations (PDE) is an indispensable part of many\nbranches of science as many processes can be modelled in terms of PDEs.\nHowever, recent numerical solvers require manual discretization of the\nunderlying equation as well as sophisticated, tailored code for distributed\ncomputing. Scanning the parameters of the underlying model significantly\nincreases the runtime as the simulations have to be cold-started for each\nparameter configuration. Machine Learning based surrogate models denote\npromising ways for learning complex relationship among input, parameter and\nsolution. However, recent generative neural networks require lots of training\ndata, i.e. full simulation runs making them costly. In contrast, we examine the\napplicability of continuous, mesh-free neural solvers for partial differential\nequations, physics-informed neural networks (PINNs) solely requiring\ninitial/boundary values and validation points for training but no simulation\ndata. The induced curse of dimensionality is approached by learning a domain\ndecomposition that steers the number of neurons per unit volume and\nsignificantly improves runtime. Distributed training on large-scale cluster\nsystems also promises great utilization of large quantities of GPUs which we\nassess by a comprehensive evaluation study. Finally, we discuss the accuracy of\nGatedPINN with respect to analytical solutions -- as well as state-of-the-art\nnumerical solvers, such as spectral solvers.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:26:51 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Stiller", "Patrick", ""], ["Bethke", "Friedrich", ""], ["B\u00f6hme", "Maximilian", ""], ["Pausch", "Richard", ""], ["Torge", "Sunna", ""], ["Debus", "Alexander", ""], ["Vorberger", "Jan", ""], ["Bussmann", "Michael", ""], ["Hoffmann", "Nico", ""]]}, {"id": "2009.03732", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Moun\\^im A. El Yacoubi, Mehdi Ammi", "title": "Enhancing the Interpretability of Deep Models in Heathcare Through\n  Attention: Application to Glucose Forecasting for Diabetic People", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of deep learning in healthcare is hindered by their \"black box\"\nnature. In this paper, we explore the RETAIN architecture for the task of\nglusose forecasting for diabetic people. By using a two-level attention\nmechanism, the recurrent-neural-network-based RETAIN model is interpretable. We\nevaluate the RETAIN model on the type-2 IDIAB and the type-1 OhioT1DM datasets\nby comparing its statistical and clinical performances against two deep models\nand three models based on decision trees. We show that the RETAIN model offers\na very good compromise between accuracy and interpretability, being almost as\naccurate as the LSTM and FCN models while remaining interpretable. We show the\nusefulness of its interpretable nature by analyzing the contribution of each\nvariable to the final prediction. It revealed that signal values older than one\nhour are not used by the RETAIN model for the 30-minutes ahead of time\nprediction of glucose. Also, we show how the RETAIN model changes its behavior\nupon the arrival of an event such as carbohydrate intakes or insulin infusions.\nIn particular, it showed that the patient's state before the event is\nparticularily important for the prediction. Overall the RETAIN model, thanks to\nits interpretability, seems to be a very promissing model for regression or\nclassification tasks in healthcare.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:27:52 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Yacoubi", "Moun\u00eem A. El", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03756", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and Tanveer Ahmed and Anwar Haque and Abdallah Shami", "title": "Machine Learning Towards Enabling Spectrum-as-a-Service Dynamic Sharing", "comments": "6 pages, 2 figures, Accepted and presented in 2020 IEEE Canadian\n  Conference On Electrical And Computer Engineering (CCECE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth in wireless broadband users, devices, and novel applications has\nled to a significant increase in the demand for new radio frequency spectrum.\nThis is expected to grow even further given the projection that the global\ntraffic per year will reach 4.8 zettabytes by 2022. Moreover, it is projected\nthat the number of Internet users will reach 4.8 billion and the number of\nconnected devices will be close 28.5 billion devices. However, due to the\nspectrum being mostly allocated and divided, providing more spectrum to expand\nexisting services or offer new ones has become more challenging. To address\nthis, spectrum sharing has been proposed as a potential solution to improve\nspectrum utilization efficiency. Adopting effective and efficient spectrum\nsharing mechanisms is in itself a challenging task given the multitude of\nlevels and techniques that can be integrated to enable it. To that end, this\npaper provides an overview of the different spectrum sharing levels and\ntechniques that have been proposed in the literature. Moreover, it discusses\nthe potential of adopting dynamic sharing mechanisms by offering\nSpectrum-as-a-Service architecture. Furthermore, it describes the potential\nrole of machine learning models in facilitating the automated and efficient\ndynamic sharing of the spectrum and offering Spectrum-as-a-Service.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:41:02 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Ahmed", "Tanveer", ""], ["Haque", "Anwar", ""], ["Shami", "Abdallah", ""]]}, {"id": "2009.03771", "submitter": "Lanfranco Zanzi", "authors": "Lanfranco Zanzi, Vincenzo Sciancalepore, Andres Garcia-Saavedra, Hans\n  D. Schotten, Xavier Costa-Perez", "title": "LACO: A Latency-Driven Network Slicing Orchestration in Beyond-5G\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2020.3027963", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Slicing is expected to become a game changer in the upcoming 5G\nnetworks and beyond, enlarging the telecom business ecosystem through\nstill-unexplored vertical industry profits. This implies that heterogeneous\nservice level agreements (SLAs) must be guaranteed per slice given the\nmultitude of predefined requirements. In this paper, we pioneer a novel radio\nslicing orchestration solution that simultaneously provides-latency and\nthroughput guarantees in a multi-tenancy environment. Leveraging on a solid\nmathematical framework, we exploit the exploration-vs-exploitation paradigm by\nmeans of a multi-armed-bandit-based(MAB) orchestrator, LACO, that makes\nadaptive resource slicing decisions with no prior knowledge on the traffic\ndemand or channel quality statistics. As opposed to traditional MAB methods\nthat are blind to the underlying system, LACO relies on system structure\ninformation to expedite decisions. After a preliminary simulations campaign\nempirically proving the validness of our solution, we provide a robust\nimplementation of LACO using off-the-shelf equipment to fully emulate realistic\nnetwork conditions:near-optimal results within affordable computational time\nare measured when LACO is in place.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:50:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zanzi", "Lanfranco", ""], ["Sciancalepore", "Vincenzo", ""], ["Garcia-Saavedra", "Andres", ""], ["Schotten", "Hans D.", ""], ["Costa-Perez", "Xavier", ""]]}, {"id": "2009.03779", "submitter": "Edward Raff", "authors": "Edward Raff, Richard Zak, Gary Lopez Munoz, William Fleming, Hyrum S.\n  Anderson, Bobby Filar, Charles Nicholas, James Holt", "title": "Automatic Yara Rule Generation Using Biclustering", "comments": "to be published in the 13th ACM Workshop on Artificial Intelligence\n  and Security (AISec)", "journal-ref": null, "doi": "10.1145/3411508.3421372", "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yara rules are a ubiquitous tool among cybersecurity practitioners and\nanalysts. Developing high-quality Yara rules to detect a malware family of\ninterest can be labor- and time-intensive, even for expert users. Few tools\nexist and relatively little work has been done on how to automate the\ngeneration of Yara rules for specific families. In this paper, we leverage\nlarge n-grams ($n \\geq 8$) combined with a new biclustering algorithm to\nconstruct simple Yara rules more effectively than currently available software.\nOur method, AutoYara, is fast, allowing for deployment on low-resource\nequipment for teams that deploy to remote networks. Our results demonstrate\nthat AutoYara can help reduce analyst workload by producing rules with useful\ntrue-positive rates while maintaining low false-positive rates, sometimes\nmatching or even outperforming human analysts. In addition, real-world testing\nby malware analysts indicates AutoYara could reduce analyst time spent\nconstructing Yara rules by 44-86%, allowing them to spend their time on the\nmore advanced malware that current tools can't handle. Code will be made\navailable at https://github.com/NeuromorphicComputationResearchProgram .\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 02:02:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Raff", "Edward", ""], ["Zak", "Richard", ""], ["Munoz", "Gary Lopez", ""], ["Fleming", "William", ""], ["Anderson", "Hyrum S.", ""], ["Filar", "Bobby", ""], ["Nicholas", "Charles", ""], ["Holt", "James", ""]]}, {"id": "2009.03782", "submitter": "Sara Hahner", "authors": "Sara Hahner, Rodrigo Iza-Teran, Jochen Garcke", "title": "Analysis and Prediction of Deforming 3D Shapes using Oriented Bounding\n  Boxes and LSTM Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequences of complex 3D shapes in time we present a general approach to\ndetect patterns for their analysis and to predict the deformation by making use\nof structural components of the complex shape. We incorporate long short-term\nmemory (LSTM) layers into an autoencoder to create low dimensional\nrepresentations that allow the detection of patterns in the data and\nadditionally detect the temporal dynamics in the deformation behavior. This is\nachieved with two decoders, one for reconstruction and one for prediction of\nfuture time steps of the sequence. In a preprocessing step the components of\nthe studied object are converted to oriented bounding boxes which capture the\nimpact of plastic deformation and allow reducing the dimensionality of the data\ndescribing the structure. The architecture is tested on the results of 196 car\ncrash simulations of a model with 133 different components, where material\nproperties are varied. In the latent representation we can detect patterns in\nthe plastic deformation for the different components. The predicted bounding\nboxes give an estimate of the final simulation result and their quality is\nimproved in comparison to different baselines.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:07:32 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hahner", "Sara", ""], ["Iza-Teran", "Rodrigo", ""], ["Garcke", "Jochen", ""]]}, {"id": "2009.03792", "submitter": "Nanyu Li", "authors": "Nanyu Li, Yujuan Si, Di Wang, Tong Liu, Jinrun Yu", "title": "ECG Beats Fast Classification Base on Sparse Dictionaries", "comments": "27 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction plays an important role in Electrocardiogram (ECG) Beats\nclassification system. Compared to other popular methods, VQ method performs\nwell in feature extraction from ECG with advantages of dimensionality\nreduction. In VQ method, a set of dictionaries corresponding to segments of ECG\nbeats is trained, and VQ codes are used to represent each heartbeat. However,\nin practice, VQ codes optimized by k-means or k-means++ exist large\nquantization errors, which results in VQ codes for two heartbeats of the same\ntype being very different. So the essential differences between different types\nof heartbeats cannot be representative well. On the other hand, VQ uses too\nmuch data during codebook construction, which limits the speed of dictionary\nlearning. In this paper, we propose a new method to improve the speed and\naccuracy of VQ method. To reduce the computation of codebook construction, a\nset of sparse dictionaries corresponding to wave segments of ECG beats is\nconstructed. After initialized, sparse dictionaries are updated efficiently by\nFeature-sign and Lagrange dual algorithm. Based on those dictionaries, a set of\ncodes can be computed to represent original ECG beats.Experimental results show\nthat features extracted from ECG by our method are more efficient and\nseparable. The accuracy of our method is higher than other methods with less\ntime consumption of feature extraction\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:38:46 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Li", "Nanyu", ""], ["Si", "Yujuan", ""], ["Wang", "Di", ""], ["Liu", "Tong", ""], ["Yu", "Jinrun", ""]]}, {"id": "2009.03816", "submitter": "Qing Ye", "authors": "Qing Ye, Yuxuan Han, Yanan sun and JIancheng Lv", "title": "PSO-PS: Parameter Synchronization with Particle Swarm Optimization for\n  Distributed Training of Deep Neural Networks", "comments": "7pages", "journal-ref": "IJCNN2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter updating is an important stage in parallelism-based distributed\ndeep learning. Synchronous methods are widely used in distributed training the\nDeep Neural Networks (DNNs). To reduce the communication and synchronization\noverhead of synchronous methods, decreasing the synchronization frequency\n(e.g., every $n$ mini-batches) is a straightforward approach. However, it often\nsuffers from poor convergence. In this paper, we propose a new algorithm of\nintegrating Particle Swarm Optimization (PSO) into the distributed training\nprocess of DNNs to automatically compute new parameters. In the proposed\nalgorithm, a computing work is encoded by a particle, the weights of DNNs and\nthe training loss are modeled by the particle attributes. At each\nsynchronization stage, the weights are updated by PSO from the sub weights\ngathered from all workers, instead of averaging the weights or the gradients.\nTo verify the performance of the proposed algorithm, the experiments are\nperformed on two commonly used image classification benchmarks: MNIST and\nCIFAR10, and compared with the peer competitors at multiple different\nsynchronization configurations. The experimental results demonstrate the\ncompetitiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:18:32 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ye", "Qing", ""], ["Han", "Yuxuan", ""], ["sun", "Yanan", ""], ["Lv", "JIancheng", ""]]}, {"id": "2009.03821", "submitter": "Pratheek Upadhyaya", "authors": "Pratheek S. Upadhyaya, Vijay K. Shah, and Jeffrey H. Reed", "title": "Cross-layer Band Selection and Routing Design for Diverse Band-aware DSA\n  Networks", "comments": "To be published in the proceedings of IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As several new spectrum bands are opening up for shared use, a new paradigm\nof \\textit{Diverse Band-aware Dynamic Spectrum Access} (d-DSA) has emerged.\nd-DSA equips a secondary device with software defined radios (SDRs) and utilize\nwhitespaces (or idle channels) in \\textit{multiple bands}, including but not\nlimited to TV, LTE, Citizen Broadband Radio Service (CBRS), unlicensed ISM. In\nthis paper, we propose a decentralized, online multi-agent reinforcement\nlearning based cross-layer BAnd selection and Routing Design (BARD) for such\nd-DSA networks. BARD not only harnesses whitespaces in multiple spectrum bands,\nbut also accounts for unique electro-magnetic characteristics of those bands to\nmaximize the desired quality of service (QoS) requirements of heterogeneous\nmessage packets; while also ensuring no harmful interference to the primary\nusers in the utilized band. Our extensive experiments demonstrate that BARD\noutperforms the baseline dDSAaR algorithm in terms of message delivery ratio,\nhowever, at a relatively higher network latency, for varying number of primary\nand secondary users. Furthermore, BARD greatly outperforms its single-band DSA\nvariants in terms of both the metrics in all considered scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:33:08 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Upadhyaya", "Pratheek S.", ""], ["Shah", "Vijay K.", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2009.03825", "submitter": "Neil Yorke-Smith", "authors": "T\\'omas Thorbjarnarson and Neil Yorke-Smith", "title": "On Training Neural Networks with Mixed Integer Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown potential in using Mixed Integer Programming (MIP)\nsolvers to optimize certain aspects of neural networks (NN). However little\nresearch has gone into training NNs with solvers. State of the art methods to\ntrain NNs are typically gradient-based and require significant data,\ncomputation on GPUs and extensive hyper-parameter tuning. In contrast, training\nwith MIP solvers should not require GPUs or hyper-parameter tuning but can\nlikely not handle large amounts of data. This work builds on recent advances\nthat train binarized NNs using MIP solvers. We go beyond current work by\nformulating new MIP models to increase the amount of data that can be used and\nto train non-binary integer-valued networks. Our results show that comparable\nresults to using gradient descent can be achieved when minimal data is\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:45:44 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:40:58 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 12:58:36 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Thorbjarnarson", "T\u00f3mas", ""], ["Yorke-Smith", "Neil", ""]]}, {"id": "2009.03831", "submitter": "Joon Kwon", "authors": "Joon Kwon", "title": "Refined approachability algorithms and application to regret\n  minimization with global costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blackwell's approachability is a framework where two players, the Decision\nMaker and the Environment, play a repeated game with vector-valued payoffs. The\ngoal of the Decision Maker is to make the average payoff converge to a given\nset called the target. When this is indeed possible, simple algorithms which\nguarantee the convergence are known. This abstract tool was successfully used\nfor the construction of optimal strategies in various repeated games, but also\nfound several applications in online learning. By extending an approach\nproposed by (Abernethy et al., 2011), we construct and analyze a class of\nFollow the Regularized Leader algorithms (FTRL) for Blackwell's approachability\nwhich are able to minimize not only the Euclidean distance to the target set\n(as it is often the case in the context of Blackwell's approachability) but a\nwide range of distance-like quantities. This flexibility enables us to apply\nthese algorithms to closely minimize the quantity of interest in various online\nlearning problems. In particular, for regret minimization with $\\ell_p$ global\ncosts, we obtain the first bounds with explicit dependence in $p$ and the\ndimension $d$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:54:08 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 14:47:33 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 14:03:13 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kwon", "Joon", ""]]}, {"id": "2009.03836", "submitter": "Mohammed Sharafath Abdul Hameed", "authors": "Mohammed Sharafath Abdul Hameed, Andreas Schwung", "title": "Reinforcement Learning on Job Shop Scheduling Problems Using Graph\n  Networks", "comments": "8 pages, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel approach for job shop scheduling problems using\ndeep reinforcement learning. To account for the complexity of production\nenvironment, we employ graph neural networks to model the various relations\nwithin production environments. Furthermore, we cast the JSSP as a distributed\noptimization problem in which learning agents are individually assigned to\nresources which allows for higher flexibility with respect to changing\nproduction environments. The proposed distributed RL agents used to optimize\nproduction schedules for single resources are running together with a\nco-simulation framework of the production environment to obtain the required\namount of data. The approach is applied to a multi-robot environment and a\ncomplex production scheduling benchmark environment. The initial results\nunderline the applicability and performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:05:04 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hameed", "Mohammed Sharafath Abdul", ""], ["Schwung", "Andreas", ""]]}, {"id": "2009.03855", "submitter": "Daniel Furelos-Blanco", "authors": "Daniel Furelos-Blanco, Mark Law, Anders Jonsson, Krysia Broda and\n  Alessandra Russo", "title": "Induction and Exploitation of Subgoal Automata for Reinforcement\n  Learning", "comments": "Published in the Journal of Artificial Intelligence Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research, 70, 1031-1116 (2021)", "doi": "10.1613/jair.1.12372", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present ISA, an approach for learning and exploiting\nsubgoals in episodic reinforcement learning (RL) tasks. ISA interleaves\nreinforcement learning with the induction of a subgoal automaton, an automaton\nwhose edges are labeled by the task's subgoals expressed as propositional logic\nformulas over a set of high-level events. A subgoal automaton also consists of\ntwo special states: a state indicating the successful completion of the task,\nand a state indicating that the task has finished without succeeding. A\nstate-of-the-art inductive logic programming system is used to learn a subgoal\nautomaton that covers the traces of high-level events observed by the RL agent.\nWhen the currently exploited automaton does not correctly recognize a trace,\nthe automaton learner induces a new automaton that covers that trace. The\ninterleaving process guarantees the induction of automata with the minimum\nnumber of states, and applies a symmetry breaking mechanism to shrink the\nsearch space whilst remaining complete. We evaluate ISA in several gridworld\nand continuous state space problems using different RL algorithms that leverage\nthe automaton structures. We provide an in-depth empirical analysis of the\nautomaton learning performance in terms of the traces, the symmetry breaking\nand specific restrictions imposed on the final learnable automaton. For each\nclass of RL problem, we show that the learned automata can be successfully\nexploited to learn policies that reach the goal, achieving an average reward\ncomparable to the case where automata are not learned but handcrafted and given\nbeforehand.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:42:55 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 15:25:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Furelos-Blanco", "Daniel", ""], ["Law", "Mark", ""], ["Jonsson", "Anders", ""], ["Broda", "Krysia", ""], ["Russo", "Alessandra", ""]]}, {"id": "2009.03859", "submitter": "Ghazal Fazelnia Ph.D.", "authors": "Greg Benton, Ghazal Fazelnia, Alice Wang, Ben Carterette", "title": "Trajectory Based Podcast Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Podcast recommendation is a growing area of research that presents new\nchallenges and opportunities. Individuals interact with podcasts in a way that\nis distinct from most other media; and primary to our concerns is distinct from\nmusic consumption. We show that successful and consistent recommendations can\nbe made by viewing users as moving through the podcast library sequentially.\nRecommendations for future podcasts are then made using the trajectory taken\nfrom their sequential behavior. Our experiments provide evidence that user\nbehavior is confined to local trends, and that listening patterns tend to be\nfound over short sequences of similar types of shows. Ultimately, our approach\ngives a450%increase in effectiveness over a collaborative filtering baseline.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:49:12 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Benton", "Greg", ""], ["Fazelnia", "Ghazal", ""], ["Wang", "Alice", ""], ["Carterette", "Ben", ""]]}, {"id": "2009.03863", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Sandeep Kumar, Shilpak Banerjee, Ashish Kumar Pandey", "title": "TanhSoft -- a family of activation functions combining Tanh and Softplus", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning at its core, contains functions that are composition of a\nlinear transformation with a non-linear function known as activation function.\nIn past few years, there is an increasing interest in construction of novel\nactivation functions resulting in better learning. In this work, we propose a\nfamily of novel activation functions, namely TanhSoft, with four undetermined\nhyper-parameters of the form\ntanh({\\alpha}x+{\\beta}e^{{\\gamma}x})ln({\\delta}+e^x) and tune these\nhyper-parameters to obtain activation functions which are shown to outperform\nseveral well known activation functions. For instance, replacing ReLU with\nxtanh(0.6e^x)improves top-1 classification accuracy on CIFAR-10 by 0.46% for\nDenseNet-169 and 0.7% for Inception-v3 while with tanh(0.87x)ln(1 +e^x) top-1\nclassification accuracy on CIFAR-100 improves by 1.24% for DenseNet-169 and\n2.57% for SimpleNet model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:59:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Biswas", "Koushik", ""], ["Kumar", "Sandeep", ""], ["Banerjee", "Shilpak", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2009.03864", "submitter": "Arun Lakshmanan", "authors": "Aditya Gahlawat, Arun Lakshmanan, Lin Song, Andrew Patterson, Zhuohuan\n  Wu, Naira Hovakimyan, Evangelos Theodorou", "title": "$\\mathcal{RL}_1$-$\\mathcal{GP}$: Safe Simultaneous Learning and Control", "comments": "Submitted to the Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present $\\mathcal{RL}_1$-$\\mathcal{GP}$, a control framework that enables\nsafe simultaneous learning and control for systems subject to uncertainties.\nThe two main constituents are Riemannian energy $\\mathcal{L}_1$\n($\\mathcal{RL}_1$) control and Bayesian learning in the form of Gaussian\nprocess (GP) regression. The $\\mathcal{RL}_1$ controller ensures that control\nobjectives are met while providing safety certificates. Furthermore,\n$\\mathcal{RL}_1$-$\\mathcal{GP}$ incorporates any available data into a GP model\nof uncertainties, which improves performance and enables the motion planner to\nachieve optimality safely. This way, the safe operation of the system is always\nguaranteed, even during the learning transients. We provide a few illustrative\nexamples for the safe learning and control of planar quadrotor systems in a\nvariety of environments.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:02:00 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Gahlawat", "Aditya", ""], ["Lakshmanan", "Arun", ""], ["Song", "Lin", ""], ["Patterson", "Andrew", ""], ["Wu", "Zhuohuan", ""], ["Hovakimyan", "Naira", ""], ["Theodorou", "Evangelos", ""]]}, {"id": "2009.03871", "submitter": "Simone Foti", "authors": "Simone Foti, Bongjin Koo, Thomas Dowrick, Joao Ramalhinho, Moustafa\n  Allam, Brian Davidson, Danail Stoyanov and Matthew J. Clarkson", "title": "Intraoperative Liver Surface Completion with Graph Convolutional VAE", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-60365-6_19", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a method based on geometric deep learning to predict\nthe complete surface of the liver, given a partial point cloud of the organ\nobtained during the surgical laparoscopic procedure. We introduce a new data\naugmentation technique that randomly perturbs shapes in their frequency domain\nto compensate the limited size of our dataset. The core of our method is a\nvariational autoencoder (VAE) that is trained to learn a latent space for\ncomplete shapes of the liver. At inference time, the generative part of the\nmodel is embedded in an optimisation procedure where the latent representation\nis iteratively updated to generate a model that matches the intraoperative\npartial point cloud. The effect of this optimisation is a progressive non-rigid\ndeformation of the initially generated shape. Our method is qualitatively\nevaluated on real data and quantitatively evaluated on synthetic data. We\ncompared with a state-of-the-art rigid registration algorithm, that our method\noutperformed in visible areas.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:19:31 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 18:28:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Foti", "Simone", ""], ["Koo", "Bongjin", ""], ["Dowrick", "Thomas", ""], ["Ramalhinho", "Joao", ""], ["Allam", "Moustafa", ""], ["Davidson", "Brian", ""], ["Stoyanov", "Danail", ""], ["Clarkson", "Matthew J.", ""]]}, {"id": "2009.03873", "submitter": "Joshua Cardosi", "authors": "Joshua D. Cardosi, Herman Shen, Jonathan I. Groner, Megan Armstrong,\n  Henry Xiang", "title": "Machine Intelligence for Outcome Predictions of Trauma Patients During\n  Emergency Department Care", "comments": "23 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trauma mortality results from a multitude of non-linear dependent risk\nfactors including patient demographics, injury characteristics, medical care\nprovided, and characteristics of medical facilities; yet traditional approach\nattempted to capture these relationships using rigid regression models. We\nhypothesized that a transfer learning based machine learning algorithm could\ndeeply understand a trauma patient's condition and accurately identify\nindividuals at high risk for mortality without relying on restrictive\nregression model criteria. Anonymous patient visit data were obtained from\nyears 2007-2014 of the National Trauma Data Bank. Patients with incomplete\nvitals, unknown outcome, or missing demographics data were excluded. All\npatient visits occurred in U.S. hospitals, and of the 2,007,485 encounters that\nwere retrospectively examined, 8,198 resulted in mortality (0.4%). The machine\nintelligence model was evaluated on its sensitivity, specificity, positive and\nnegative predictive value, and Matthews Correlation Coefficient. Our model\nachieved similar performance in age-specific comparison models and generalized\nwell when applied to all ages simultaneously. While testing for confounding\nfactors, we discovered that excluding fall-related injuries boosted performance\nfor adult trauma patients; however, it reduced performance for children. The\nmachine intelligence model described here demonstrates similar performance to\ncontemporary machine intelligence models without requiring restrictive\nregression model criteria or extensive medical expertise.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:26:34 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:50:57 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Cardosi", "Joshua D.", ""], ["Shen", "Herman", ""], ["Groner", "Jonathan I.", ""], ["Armstrong", "Megan", ""], ["Xiang", "Henry", ""]]}, {"id": "2009.03887", "submitter": "Albert Gural", "authors": "Albert Gural, Phillip Nadeau, Mehul Tikekar, Boris Murmann", "title": "Low-Rank Training of Deep Neural Networks for Emerging Memory Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of neural networks for solving difficult decision tasks\nhas incentivized incorporating smart decision making \"at the edge.\" However,\nthis work has traditionally focused on neural network inference, rather than\ntraining, due to memory and compute limitations, especially in emerging\nnon-volatile memory systems, where writes are energetically costly and reduce\nlifespan. Yet, the ability to train at the edge is becoming increasingly\nimportant as it enables real-time adaptability to device drift and\nenvironmental variation, user customization, and federated learning across\ndevices. In this work, we address two key challenges for training on edge\ndevices with non-volatile memory: low write density and low auxiliary memory.\nWe present a low-rank training scheme that addresses these challenges while\nmaintaining computational efficiency. We then demonstrate the technique on a\nrepresentative convolutional neural network across several adaptation problems,\nwhere it out-performs standard SGD both in accuracy and in number of weight\nwrites.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:59:56 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 03:06:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gural", "Albert", ""], ["Nadeau", "Phillip", ""], ["Tikekar", "Mehul", ""], ["Murmann", "Boris", ""]]}, {"id": "2009.03892", "submitter": "Yihao Hu", "authors": "Yihao Hu, Tong Zhao, Zhiliang Xu, Lizhen Lin", "title": "Neural Time-Dependent Partial Differential Equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) play a crucial role in studying a vast\nnumber of problems in science and engineering. Numerically solving nonlinear\nand/or high-dimensional PDEs is often a challenging task. Inspired by the\ntraditional finite difference and finite elements methods and emerging\nadvancements in machine learning, we propose a sequence deep learning framework\ncalled Neural-PDE, which allows to automatically learn governing rules of any\ntime-dependent PDE system from existing data by using a bidirectional LSTM\nencoder, and predict the next n time steps data. One critical feature of our\nproposed framework is that the Neural-PDE is able to simultaneously learn and\nsimulate the multiscale variables.We test the Neural-PDE by a range of examples\nfrom one-dimensional PDEs to a high-dimensional and nonlinear complex fluids\nmodel. The results show that the Neural-PDE is capable of learning the initial\nconditions, boundary conditions and differential operators without the\nknowledge of the specific form of a PDE system.In our experiments the\nNeural-PDE can efficiently extract the dynamics within 20 epochs training, and\nproduces accurate predictions. Furthermore, unlike the traditional machine\nlearning approaches in learning PDE such as CNN and MLP which require vast\nparameters for model precision, Neural-PDE shares parameters across all time\nsteps, thus considerably reduces the computational complexity and leads to a\nfast learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:46:00 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hu", "Yihao", ""], ["Zhao", "Tong", ""], ["Xu", "Zhiliang", ""], ["Lin", "Lizhen", ""]]}, {"id": "2009.03937", "submitter": "Alessandro Morandini", "authors": "Andrea De Simone, Alessandro Morandini", "title": "Nonparametric Density Estimation from Markov Chains", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "SISSA 22/2020/FISI", "categories": "stat.ME cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new nonparametric density estimator inspired by Markov Chains,\nand generalizing the well-known Kernel Density Estimator (KDE). Our estimator\npresents several benefits with respect to the usual ones and can be used\nstraightforwardly as a foundation in all density-based algorithms. We prove the\nconsistency of our estimator and we find it typically outperforms KDE in\nsituations of large sample size and high dimensionality. We also employ our\ndensity estimator to build a local outlier detector, showing very promising\nresults when applied to some realistic datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 18:33:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["De Simone", "Andrea", ""], ["Morandini", "Alessandro", ""]]}, {"id": "2009.03947", "submitter": "Shervin Minaee", "authors": "Meysam Asgari-Chenaghlu, Narjes Nikzad-Khasmakhi, Shervin Minaee", "title": "Covid-Transformer: Detecting COVID-19 Trending Topics on Twitter Using\n  Universal Sentence Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel corona-virus disease (also known as COVID-19) has led to a\npandemic, impacting more than 200 countries across the globe. With its global\nimpact, COVID-19 has become a major concern of people almost everywhere, and\ntherefore there are a large number of tweets coming out from every corner of\nthe world, about COVID-19 related topics. In this work, we try to analyze the\ntweets and detect the trending topics and major concerns of people on Twitter,\nwhich can enable us to better understand the situation, and devise better\nplanning. More specifically we propose a model based on the universal sentence\nencoder to detect the main topics of Tweets in recent months. We used universal\nsentence encoder in order to derive the semantic representation and the\nsimilarity of tweets. We then used the sentence similarity and their\nembeddings, and feed them to K-means clustering algorithm to group similar\ntweets (in semantic sense). After that, the cluster summary is obtained using a\ntext summarization algorithm based on deep learning, which can uncover the\nunderlying topics of each cluster. Through experimental results, we show that\nour model can detect very informative topics, by processing a large number of\ntweets on sentence level (which can preserve the overall meaning of the\ntweets). Since this framework has no restriction on specific data distribution,\nit can be used to detect trending topics from any other social media and any\nother context rather than COVID-19. Experimental results show superiority of\nour proposed approach to other baselines, including TF-IDF, and latent\nDirichlet allocation (LDA).\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:00:38 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 19:36:33 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 21:10:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Asgari-Chenaghlu", "Meysam", ""], ["Nikzad-Khasmakhi", "Narjes", ""], ["Minaee", "Shervin", ""]]}, {"id": "2009.03979", "submitter": "Hengrui Luo", "authors": "Leland Wilkinson, Hengrui Luo", "title": "A Distance-preserving Matrix Sketch", "comments": "46 pages, 11 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing very large matrices involves many formidable problems. Various\npopular solutions to these problems involve sampling, clustering, projection,\nor feature selection to reduce the size and complexity of the original task. An\nimportant aspect of these methods is how to preserve relative distances between\npoints in the higher-dimensional space after reducing rows and columns to fit\nin a lower dimensional space. This aspect is important because conclusions\nbased on faulty visual reasoning can be harmful. Judging dissimilar points as\nsimilar or similar points as dissimilar on the basis of a visualization can\nlead to false conclusions. To ameliorate this bias and to make visualizations\nof very large datasets feasible, we introduce two new algorithms that\nrespectively select a subset of rows and columns of a rectangular matrix. This\nselection is designed to preserve relative distances as closely as possible. We\ncompare our matrix sketch to more traditional alternatives on a variety of\nartificial and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 20:15:14 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:51:23 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wilkinson", "Leland", ""], ["Luo", "Hengrui", ""]]}, {"id": "2009.03983", "submitter": "Amir Mosavi Prof", "authors": "Narjes Nabipour, Amir Mosavi, Alireza Baghban, Shahaboddin\n  Shamshirband, Imre Felde", "title": "Extreme learning machine-based model for Solubility estimation of\n  hydrocarbon gases in electrolyte solutions", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Calculating hydrocarbon components solubility of natural gases is known as\none of the important issues for operational works in petroleum and chemical\nengineering. In this work, a novel solubility estimation tool has been proposed\nfor hydrocarbon gases including methane, ethane, propane, and butane in aqueous\nelectrolyte solutions based on extreme learning machine (ELM) algorithm.\nComparing the ELM outputs with a comprehensive real databank which has 1175\nsolubility points concluded to R-squared values of 0.985 and 0.987 for training\nand testing phases respectively. Furthermore, the visual comparison of\nestimated and actual hydrocarbon solubility led to confirm the ability of the\nproposed solubility model. Additionally, sensitivity analysis has been employed\non the input variables of the model to identify their impacts on hydrocarbon\nsolubility. Such a comprehensive and reliable study can help engineers and\nscientists to successfully determine the important thermodynamic properties\nwhich are key factors in optimizing and designing different industrial units\nsuch as refineries and petrochemical plants.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:23:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Nabipour", "Narjes", ""], ["Mosavi", "Amir", ""], ["Baghban", "Alireza", ""], ["Shamshirband", "Shahaboddin", ""], ["Felde", "Imre", ""]]}, {"id": "2009.03986", "submitter": "Jianji Wang", "authors": "Jianji Wang, Qi Liu, Shupei Zhang, Nanning Zheng, Fei-Yue Wang", "title": "Conditional Uncorrelation and Efficient Non-approximate Subset Selection\n  in Sparse Regression", "comments": "17 pages, 0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $m$ $d$-dimensional responsors and $n$ $d$-dimensional predictors,\nsparse regression finds at most $k$ predictors for each responsor for linear\napproximation, $1\\leq k \\leq d-1$. The key problem in sparse regression is\nsubset selection, which usually suffers from high computational cost. Recent\nyears, many improved approximate methods of subset selection have been\npublished. However, less attention has been paid on the non-approximate method\nof subset selection, which is very necessary for many questions in data\nanalysis. Here we consider sparse regression from the view of correlation, and\npropose the formula of conditional uncorrelation. Then an efficient\nnon-approximate method of subset selection is proposed in which we do not need\nto calculate any coefficients in regression equation for candidate predictors.\nBy the proposed method, the computational complexity is reduced from\n$O(\\frac{1}{6}{k^3}+mk^2+mkd)$ to $O(\\frac{1}{6}{k^3}+\\frac{1}{2}mk^2)$ for\neach candidate subset in sparse regression. Because the dimension $d$ is\ngenerally the number of observations or experiments and large enough, the\nproposed method can greatly improve the efficiency of non-approximate subset\nselection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 20:32:26 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 10:00:18 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Jianji", ""], ["Liu", "Qi", ""], ["Zhang", "Shupei", ""], ["Zheng", "Nanning", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "2009.03993", "submitter": "Michel Gr\\'ediac", "authors": "S. Boukhtache, K. Abdelouahab, F. Berry, B. Blaysat, M. Grediac, F.\n  Sur", "title": "When Deep Learning Meets Digital Image Correlation", "comments": "35 pages, 25 figures. Accepted for publication in Optics and Lasers\n  in Engineering on July 9, 2020", "journal-ref": null, "doi": "10.1016/j.optlaseng.2020.106308", "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) constitute a class of Deep Learning\nmodels which have been used in the recent past to resolve many problems in\ncomputer vision, in particular optical flow estimation. Measuring displacement\nand strain fields can be regarded as a particular case of this problem.\nHowever, it seems that CNNs have never been used so far to perform such\nmeasurements. This work is aimed at implementing a CNN able to retrieve\ndisplacement and strain fields from pairs of reference and deformed images of a\nflat speckled surface, as Digital Image Correlation (DIC) does. This paper\nexplains how a CNN called StrainNet can be developed to reach this goal, and\nhow specific ground truth datasets are elaborated to train this CNN. The main\nresult is that StrainNet successfully performs such measurements, and that it\nachieves competing results in terms of metrological performance and computing\ntime. The conclusion is that CNNs like StrainNet offer a viable alternative to\nDIC, especially for real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:26:05 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Boukhtache", "S.", ""], ["Abdelouahab", "K.", ""], ["Berry", "F.", ""], ["Blaysat", "B.", ""], ["Grediac", "M.", ""], ["Sur", "F.", ""]]}, {"id": "2009.03998", "submitter": "Tai-Xiang Jiang", "authors": "Guangjing Song, Michael K. Ng, Tai-Xiang Jiang", "title": "Tangent Space Based Alternating Projections for Nonnegative Low Rank\n  Matrix Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new alternating projection method to compute\nnonnegative low rank matrix approximation for nonnegative matrices. In the\nnonnegative low rank matrix approximation method, the projection onto the\nmanifold of fixed rank matrices can be expensive as the singular value\ndecomposition is required. We propose to use the tangent space of the point in\nthe manifold to approximate the projection onto the manifold in order to reduce\nthe computational cost. We show that the sequence generated by the alternating\nprojections onto the tangent spaces of the fixed rank matrices manifold and the\nnonnegative matrix manifold, converge linearly to a point in the intersection\nof the two manifolds where the convergent point is sufficiently close to\noptimal solutions. This convergence result based inexact projection onto the\nmanifold is new and is not studied in the literature. Numerical examples in\ndata clustering, pattern recognition and hyperspectral data analysis are given\nto demonstrate that the performance of the proposed method is better than that\nof nonnegative matrix factorization methods in terms of computational time and\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:25:16 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Song", "Guangjing", ""], ["Ng", "Michael K.", ""], ["Jiang", "Tai-Xiang", ""]]}, {"id": "2009.04003", "submitter": "Toryn Schafer", "authors": "Toryn L. J. Schafer, Christopher K. Wikle and Mevin B. Hooten", "title": "Bayesian Inverse Reinforcement Learning for Collective Animal Movement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based methods allow for defining simple rules that generate complex\ngroup behaviors. The governing rules of such models are typically set a priori\nand parameters are tuned from observed behavior trajectories. Instead of making\nsimplifying assumptions across all anticipated scenarios, inverse reinforcement\nlearning provides inference on the short-term (local) rules governing long term\nbehavior policies by using properties of a Markov decision process. We use the\ncomputationally efficient linearly-solvable Markov decision process to learn\nthe local rules governing collective movement for a simulation of the self\npropelled-particle (SPP) model and a data application for a captive guppy\npopulation. The estimation of the behavioral decision costs is done in a\nBayesian framework with basis function smoothing. We recover the true costs in\nthe SPP simulation and find the guppies value collective movement more than\ntargeted movement toward shelter.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 21:33:52 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Schafer", "Toryn L. J.", ""], ["Wikle", "Christopher K.", ""], ["Hooten", "Mevin B.", ""]]}, {"id": "2009.04004", "submitter": "Achyut Mani Tripathi", "authors": "Achyut Mani Tripathi, Ashish Mishra", "title": "Fuzzy Unique Image Transformation: Defense Against Adversarial Attacks\n  On Deep COVID-19 Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early identification of COVID-19 using a deep model trained on Chest X-Ray\nand CT images has gained considerable attention from researchers to speed up\nthe process of identification of active COVID-19 cases. These deep models act\nas an aid to hospitals that suffer from the unavailability of specialists or\nradiologists, specifically in remote areas. Various deep models have been\nproposed to detect the COVID-19 cases, but few works have been performed to\nprevent the deep models against adversarial attacks capable of fooling the deep\nmodel by using a small perturbation in image pixels. This paper presents an\nevaluation of the performance of deep COVID-19 models against adversarial\nattacks. Also, it proposes an efficient yet effective Fuzzy Unique Image\nTransformation (FUIT) technique that downsamples the image pixels into an\ninterval. The images obtained after the FUIT transformation are further\nutilized for training the secure deep model that preserves high accuracy of the\ndiagnosis of COVID-19 cases and provides reliable defense against the\nadversarial attacks. The experiments and results show the proposed model\nprevents the deep model against the six adversarial attacks and maintains high\naccuracy to classify the COVID-19 cases from the Chest X-Ray image and CT image\nDatasets. The results also recommend that a careful inspection is required\nbefore practically applying the deep models to diagnose the COVID-19 cases.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 21:35:24 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Tripathi", "Achyut Mani", ""], ["Mishra", "Ashish", ""]]}, {"id": "2009.04013", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Olga Ohrimenko, Rachel Cummings", "title": "Attribute Privacy: Framework and Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the privacy of training data is a growing concern since many machine\nlearning models are trained on confidential and potentially sensitive data.\nMuch attention has been devoted to methods for protecting individual privacy\nduring analyses of large datasets. However in many settings, global properties\nof the dataset may also be sensitive (e.g., mortality rate in a hospital rather\nthan presence of a particular patient in the dataset). In this work, we depart\nfrom individual privacy to initiate the study of attribute privacy, where a\ndata owner is concerned about revealing sensitive properties of a whole dataset\nduring analysis. We propose definitions to capture \\emph{attribute privacy} in\ntwo relevant cases where global attributes may need to be protected: (1)\nproperties of a specific dataset and (2) parameters of the underlying\ndistribution from which dataset is sampled. We also provide two efficient\nmechanisms and one inefficient mechanism that satisfy attribute privacy for\nthese settings. We base our results on a novel use of the Pufferfish framework\nto account for correlations across attributes in the data, thus addressing \"the\nchallenging problem of developing Pufferfish instantiations and algorithms for\ngeneral aggregate secrets\" that was left open by \\cite{kifer2014pufferfish}.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 22:38:57 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 23:23:04 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zhang", "Wanrong", ""], ["Ohrimenko", "Olga", ""], ["Cummings", "Rachel", ""]]}, {"id": "2009.04016", "submitter": "George Zerveas", "authors": "George Zerveas, Ruochen Zhang, Leila Kim, Carsten Eickhoff", "title": "Brown University at TREC Deep Learning 2019", "comments": null, "journal-ref": "Proceedings of the Twenty-Eighth Text REtrieval Conference, TREC\n  2019, Gaithersburg, Maryland, USA, November 13-15, 2019. NIST Special\n  Publication 1250, National Institute of Standards and Technology (NIST) 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Brown University's submission to the TREC 2019 Deep\nLearning track. We followed a 2-phase method for producing a ranking of\npassages for a given input query: In the the first phase, the user's query is\nexpanded by appending 3 queries generated by a transformer model which was\ntrained to rephrase an input query into semantically similar queries. The\nexpanded query can exhibit greater similarity in surface form and vocabulary\noverlap with the passages of interest and can therefore serve as enriched input\nto any downstream information retrieval method. In the second phase, we use a\nBERT-based model pre-trained for language modeling but fine-tuned for query -\ndocument relevance prediction to compute relevance scores for a set of 1000\ncandidate passages per query and subsequently obtain a ranking of passages by\nsorting them based on the predicted relevance scores. According to the results\npublished in the official Overview of the TREC Deep Learning Track 2019, our\nteam ranked 3rd in the passage retrieval task (including full ranking and\nre-ranking), and 2nd when considering only re-ranking submissions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 22:54:03 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zerveas", "George", ""], ["Zhang", "Ruochen", ""], ["Kim", "Leila", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2009.04023", "submitter": "Wai Tong Chung", "authors": "Wai Tong Chung, Aashwin Ananda Mishra, Nikolaos Perakis, Matthias Ihme", "title": "Data-assisted combustion simulations with dynamic submodel assignment\n  using random forests", "comments": "Accepted version; 23 pages, 12 figures", "journal-ref": "Combustion and Flame 227 (2021) 172-185", "doi": "10.1016/j.combustflame.2020.12.041", "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this investigation, we outline a data-assisted approach that employs\nrandom forest classifiers for local and dynamic combustion submodel assignment\nin turbulent-combustion simulations. This method is applied in simulations of a\nsingle-element GOX/GCH4 rocket combustor; a priori as well as a posteriori\nassessments are conducted to (i) evaluate the accuracy and adjustability of the\nclassifier for targeting different quantities-of-interest (QoIs), and (ii)\nassess improvements, resulting from the data-assisted combustion model\nassignment, in predicting target QoIs during simulation runtime. Results from\nthe a priori study show that random forests, trained with local flow properties\nas input variables and combustion model errors as training labels, assign three\ndifferent combustion models - finite-rate chemistry (FRC), flamelet progress\nvariable (FPV) model, and inert mixing (IM) - with reasonable classification\nperformance even when targeting multiple QoIs. Applications in a posteriori\nstudies demonstrate improved predictions from data-assisted simulations, in\ntemperature and CO mass fraction, when compared with monolithic FPV\ncalculations. These results demonstrate that this data-driven framework holds\npromise for the dynamic combustion submodel assignment in reacting flow\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 23:06:22 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 23:36:26 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 20:24:28 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chung", "Wai Tong", ""], ["Mishra", "Aashwin Ananda", ""], ["Perakis", "Nikolaos", ""], ["Ihme", "Matthias", ""]]}, {"id": "2009.04045", "submitter": "Ganesh Sivaraman", "authors": "Ganesh Sivaraman, Leighanne Gallington, Anand Narayanan\n  Krishnamoorthy, Marius Stan, Gabor Csanyi, Alvaro Vazquez-Mayagoitia, Chris\n  J. Benmore", "title": "An Experimentally Driven Automated Machine Learned lnter-Atomic\n  Potential for a Refractory Oxide", "comments": null, "journal-ref": "Phys. Rev. Lett. 126, 156002 (2021)", "doi": "10.1103/PhysRevLett.126.156002", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the structure and properties of refractory oxides are critical\nfor high temperature applications. In this work, a combined experimental and\nsimulation approach uses an automated closed loop via an active-learner, which\nis initialized by X-ray and neutron diffraction measurements, and sequentially\nimproves a machine-learning model until the experimentally predetermined phase\nspace is covered. A multi-phase potential is generated for a canonical example\nof the archetypal refractory oxide, HfO2, by drawing a minimum number of\ntraining configurations from room temperature to the liquid state at ~2900oC.\nThe method significantly reduces model development time and human effort.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 00:35:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sivaraman", "Ganesh", ""], ["Gallington", "Leighanne", ""], ["Krishnamoorthy", "Anand Narayanan", ""], ["Stan", "Marius", ""], ["Csanyi", "Gabor", ""], ["Vazquez-Mayagoitia", "Alvaro", ""], ["Benmore", "Chris J.", ""]]}, {"id": "2009.04053", "submitter": "Junxiang Wang", "authors": "Junxiang Wang, Zheng Chai, Yue Cheng, Liang Zhao", "title": "Tunable Subnetwork Splitting for Model-parallelism of Neural Network\n  Training", "comments": "ICML 2020 Workshop on \"Beyond first-order methods in ML systems\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating minimization methods have recently been proposed as alternatives\nto the gradient descent for deep neural network optimization. Alternating\nminimization methods can typically decompose a deep neural network into\nlayerwise subproblems, which can then be optimized in parallel. Despite the\nsignificant parallelism, alternating minimization methods are rarely explored\nin training deep neural networks because of the severe accuracy degradation. In\nthis paper, we analyze the reason and propose to achieve a compelling trade-off\nbetween parallelism and accuracy by a reformulation called Tunable Subnetwork\nSplitting Method (TSSM), which can tune the decomposition granularity of deep\nneural networks. Two methods gradient splitting Alternating Direction Method of\nMultipliers (gsADMM) and gradient splitting Alternating Minimization (gsAM) are\nproposed to solve the TSSM formulation. Experiments on five benchmark datasets\nshow that our proposed TSSM can achieve significant speedup without observable\nloss of training accuracy. The code has been released at\nhttps://github.com/xianggebenben/TSSM.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 01:05:12 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 21:18:59 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Wang", "Junxiang", ""], ["Chai", "Zheng", ""], ["Cheng", "Yue", ""], ["Zhao", "Liang", ""]]}, {"id": "2009.04057", "submitter": "Gongbo Liang", "authors": "Gongbo Liang, Yu Zhang, Xiaoqin Wang, Nathan Jacobs", "title": "Improved Trainable Calibration Method for Neural Networks on Medical\n  Imaging Classification", "comments": "Accepted to the 31th British Machine Vision Conference (BMVC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that deep neural networks can achieve super-human\nperformance in a wide range of image classification tasks in the medical\nimaging domain. However, these works have primarily focused on classification\naccuracy, ignoring the important role of uncertainty quantification.\nEmpirically, neural networks are often miscalibrated and overconfident in their\npredictions. This miscalibration could be problematic in any automatic\ndecision-making system, but we focus on the medical field in which neural\nnetwork miscalibration has the potential to lead to significant treatment\nerrors. We propose a novel calibration approach that maintains the overall\nclassification accuracy while significantly improving model calibration. The\nproposed approach is based on expected calibration error, which is a common\nmetric for quantifying miscalibration. Our approach can be easily integrated\ninto any classification task as an auxiliary loss term, thus not requiring an\nexplicit training round for calibration. We show that our approach reduces\ncalibration error significantly across various architectures and datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 01:25:53 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Liang", "Gongbo", ""], ["Zhang", "Yu", ""], ["Wang", "Xiaoqin", ""], ["Jacobs", "Nathan", ""]]}, {"id": "2009.04063", "submitter": "Mahmoud Elmohr", "authors": "Mahmoud Khalafalla, Mahmoud A. Elmohr, Catherine Gebotys", "title": "Going Deep: Using deep learning techniques with simplified mathematical\n  models against XOR BR and TBR PUFs (Attacks and Countermeasures)", "comments": "To appear in proceedings of 2020 IEEE International Symposium on\n  Hardware Oriented Security and Trust (HOST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to the study of PUFs vulnerability against modeling\nattacks by evaluating the security of XOR BR PUFs, XOR TBR PUFs, and obfuscated\narchitectures of XOR BR PUF using a simplified mathematical model and deep\nlearning (DL) techniques. Obtained results show that DL modeling attacks could\neasily break the security of 4-input XOR BR PUFs and 4-input XOR TBR PUFs with\nmodeling accuracy $\\sim$ 99%. Similar attacks were executed using single-layer\nneural networks (NN) and support vector machines (SVM) with polynomial kernel\nand the obtained results showed that single NNs failed to break the PUF\nsecurity. Furthermore, SVM results confirmed the same modeling accuracy\nreported in previous research ($\\sim$ 50%). For the first time, this research\nempirically shows that DL networks can be used as powerful modeling techniques\nagainst these complex PUF architectures for which previous conventional machine\nlearning techniques had failed. Furthermore, a detailed scalability analysis is\nconducted on the DL networks with respect to PUFs' stage size and complexity.\nThe analysis shows that the number of layers and hidden neurons inside every\nlayer has a linear relationship with PUFs' stage size, which agrees with the\ntheoretical findings in deep learning. Consequently, A new obfuscated\narchitecture is introduced as a first step to counter DL modeling attacks and\nit showed significant resistance against such attacks (16% - 40% less\naccuracy). This research provides an important step towards prioritizing the\nefforts to introduce new PUF architectures that are more secure and\ninvulnerable to modeling attacks. Moreover, it triggers future discussions on\nthe removal of influential bits and the level of obfuscation needed to confirm\nthat a specific PUF architecture is resistant against powerful DL modeling\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 01:41:57 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Khalafalla", "Mahmoud", ""], ["Elmohr", "Mahmoud A.", ""], ["Gebotys", "Catherine", ""]]}, {"id": "2009.04067", "submitter": "Liangrui Pan", "authors": "Liangrui Pan, Pronthep Pipitsunthonsan, Peng Zhang, Chalongrat\n  Daengngam, Apidach Booranawong, Mitcham Chongcheawchamnan", "title": "Noise Reduction Technique for Raman Spectrum using Deep Learning Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a normal indoor environment, Raman spectrum encounters noise often conceal\nspectrum peak, leading to difficulty in spectrum interpretation. This paper\nproposes deep learning (DL) based noise reduction technique for Raman\nspectroscopy. The proposed DL network is developed with several training and\ntest sets of noisy Raman spectrum. The proposed technique is applied to denoise\nand compare the performance with different wavelet noise reduction methods.\nOutput signal-to-noise ratio (SNR), root-mean-square error (RMSE) and mean\nabsolute percentage error (MAPE) are the performance evaluation index. It is\nshown that output SNR of the proposed noise reduction technology is 10.24 dB\ngreater than that of the wavelet noise reduction method while the RMSE and the\nMAPE are 292.63 and 10.09, which are much better than the proposed technique.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 01:51:32 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Pan", "Liangrui", ""], ["Pipitsunthonsan", "Pronthep", ""], ["Zhang", "Peng", ""], ["Daengngam", "Chalongrat", ""], ["Booranawong", "Apidach", ""], ["Chongcheawchamnan", "Mitcham", ""]]}, {"id": "2009.04070", "submitter": "Junghyun (Tony) Koo", "authors": "Junghyun Koo, Jie Hwan Lee, Jaewoo Pyo, Yujin Jo, Kyogu Lee", "title": "Exploiting Multi-Modal Features From Pre-trained Networks for\n  Alzheimer's Dementia Recognition", "comments": "In the Proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting and accessing a large amount of medical data is very\ntime-consuming and laborious, not only because it is difficult to find specific\npatients but also because it is required to resolve the confidentiality of a\npatient's medical records. On the other hand, there are deep learning models,\ntrained on easily collectible, large scale datasets such as Youtube or\nWikipedia, offering useful representations. It could therefore be very\nadvantageous to utilize the features from these pre-trained networks for\nhandling a small amount of data at hand. In this work, we exploit various\nmulti-modal features extracted from pre-trained networks to recognize\nAlzheimer's Dementia using a neural network, with a small dataset provided by\nthe ADReSS Challenge at INTERSPEECH 2020. The challenge regards to discern\npatients suspicious of Alzheimer's Dementia by providing acoustic and textual\ndata. With the multi-modal features, we modify a Convolutional Recurrent Neural\nNetwork based structure to perform classification and regression tasks\nsimultaneously and is capable of computing conversations with variable lengths.\nOur test results surpass baseline's accuracy by 18.75%, and our validation\nresult for the regression task shows the possibility of classifying 4 classes\nof cognitive impairment with an accuracy of 78.70%.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:08:47 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:15:18 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Koo", "Junghyun", ""], ["Lee", "Jie Hwan", ""], ["Pyo", "Jaewoo", ""], ["Jo", "Yujin", ""], ["Lee", "Kyogu", ""]]}, {"id": "2009.04075", "submitter": "Markos Georgopoulos", "authors": "Markos Georgopoulos, Grigorios Chrysos, Maja Pantic, Yannis Panagakis", "title": "Multilinear Latent Conditioning for Generating Unseen Attribute\n  Combinations", "comments": "published at International Conference on Machine Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models rely on their inductive bias to facilitate\ngeneralization, especially for problems with high dimensional data, like\nimages. However, empirical studies have shown that variational autoencoders\n(VAE) and generative adversarial networks (GAN) lack the generalization ability\nthat occurs naturally in human perception. For example, humans can visualize a\nwoman smiling after only seeing a smiling man. On the contrary, the standard\nconditional VAE (cVAE) is unable to generate unseen attribute combinations. To\nthis end, we extend cVAE by introducing a multilinear latent conditioning\nframework that captures the multiplicative interactions between the attributes.\nWe implement two variants of our model and demonstrate their efficacy on MNIST,\nFashion-MNIST and CelebA. Altogether, we design a novel conditioning framework\nthat can be used with any architecture to synthesize unseen attribute\ncombinations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:23:13 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Georgopoulos", "Markos", ""], ["Chrysos", "Grigorios", ""], ["Pantic", "Maja", ""], ["Panagakis", "Yannis", ""]]}, {"id": "2009.04076", "submitter": "Omid Bazgir", "authors": "Omid Bazgir, Souparno Ghosh, Ranadip Pal", "title": "Investigation of REFINED CNN ensemble learning for anti-cancer drug\n  sensitivity prediction", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btab336", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-cancer drug sensitivity prediction using deep learning models for\nindividual cell line is a significant challenge in personalized medicine.\nREFINED (REpresentation of Features as Images with NEighborhood Dependencies)\nCNN (Convolutional Neural Network) based models have shown promising results in\ndrug sensitivity prediction. The primary idea behind REFINED CNN is\nrepresenting high dimensional vectors as compact images with spatial\ncorrelations that can benefit from convolutional neural network architectures.\nHowever, the mapping from a vector to a compact 2D image is not unique due to\nvariations in considered distance measures and neighborhoods. In this article,\nwe consider predictions based on ensembles built from such mappings that can\nimprove upon the best single REFINED CNN model prediction. Results illustrated\nusing NCI60 and NCIALMANAC databases shows that the ensemble approaches can\nprovide significant performance improvement as compared to individual models.\nWe further illustrate that a single mapping created from the amalgamation of\nthe different mappings can provide performance similar to stacking ensemble but\nwith significantly lower computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:27:29 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 04:15:28 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bazgir", "Omid", ""], ["Ghosh", "Souparno", ""], ["Pal", "Ranadip", ""]]}, {"id": "2009.04077", "submitter": "Habib Ben Abdallah", "authors": "Habib Ben Abdallah, Christopher J. Henry, Sheela Ramanna", "title": "1-Dimensional polynomial neural networks for audio signal related\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to being extremely non-linear, modern problems require millions\nif not billions of parameters to solve or at least to get a good approximation\nof the solution, and neural networks are known to assimilate that complexity by\ndeepening and widening their topology in order to increase the level of\nnon-linearity needed for a better approximation. However, compact topologies\nare always preferred to deeper ones as they offer the advantage of using less\ncomputational units and less parameters. This compacity comes at the price of\nreduced non-linearity and thus, of limited solution search space. We propose\nthe 1-Dimensional Polynomial Neural Network (1DPNN) model that uses automatic\npolynomial kernel estimation for 1-Dimensional Convolutional Neural Networks\n(1DCNNs) and that introduces a high degree of non-linearity from the first\nlayer which can compensate the need for deep and/or wide topologies. We show\nthat this non-linearity introduces more computational complexity but enables\nthe model to yield better results than a regular 1DCNN that has the same number\nof training parameters on various classification and regression problems\nrelated to audio signals. The experiments were conducted on three publicly\navailable datasets and demonstrate that the proposed model can achieve a much\nfaster convergence than a 1DCNN on the tackled regression problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:29:53 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Abdallah", "Habib Ben", ""], ["Henry", "Christopher J.", ""], ["Ramanna", "Sheela", ""]]}, {"id": "2009.04078", "submitter": "Liangrui Pan", "authors": "Liangrui Pan, Pronthep Pipitsunthonsan, Chalongrat Daengngam,\n  Sittiporn Channumsin, Suwat Sreesawet, Mitchai Chongcheawchamnan", "title": "Method for classifying a noisy Raman spectrum based on a wavelet\n  transform and a deep neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new framework based on a wavelet transform and deep\nneural network for identifying noisy Raman spectrum since, in practice, it is\nrelatively difficult to classify the spectrum under baseline noise and additive\nwhite Gaussian noise environments. The framework consists of two main engines.\nWavelet transform is proposed as the framework front-end for transforming 1-D\nnoise Raman spectrum to two-dimensional data. This two-dimensional data will be\nfed to the framework back-end which is a classifier. The optimum classifier is\nchosen by implementing several traditional machine learning (ML) and deep\nlearning (DL) algorithms, and then we investigated their classification\naccuracy and robustness performances. The four MLs we choose included a Naive\nBayes (NB), a Support Vector Machine (SVM), a Random Forest (RF) and a\nK-Nearest Neighbor (KNN) where a deep convolution neural network (DCNN) was\nchosen for a DL classifier. Noise-free, Gaussian noise, baseline noise, and\nmixed-noise Raman spectrums were applied to train and validate the ML and DCNN\nmodels. The optimum back-end classifier was obtained by testing the ML and DCNN\nmodels with several noisy Raman spectrums (10-30 dB noise power). Based on the\nsimulation, the accuracy of the DCNN classifier is 9% higher than the NB\nclassifier, 3.5% higher than the RF classifier, 1% higher than the KNN\nclassifier, and 0.5% higher than the SVM classifier. In terms of robustness to\nthe mixed noise scenarios, the framework with DCNN back-end showed superior\nperformance than the other ML back-ends. The DCNN back-end achieved 90%\naccuracy at 3 dB SNR while NB, SVM, RF, and K-NN back-ends required 27 dB, 22\ndB, 27 dB, and 23 dB SNR, respectively. In addition, in the low-noise test data\nset, the F-measure score of the DCNN back-end exceeded 99.1% while the\nF-measure scores of the other ML engines were below 98.7%.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:31:23 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Pan", "Liangrui", ""], ["Pipitsunthonsan", "Pronthep", ""], ["Daengngam", "Chalongrat", ""], ["Channumsin", "Sittiporn", ""], ["Sreesawet", "Suwat", ""], ["Chongcheawchamnan", "Mitchai", ""]]}, {"id": "2009.04088", "submitter": "Manuel David Morales", "authors": "Manuel D. Morales, Javier M. Antelis, Claudia Moreno, Alexander I.\n  Nesterov", "title": "Deep learning for gravitational-wave data analysis: A resampling\n  white-box approach", "comments": "29 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG gr-qc physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we apply Convolutional Neural Networks (CNNs) to detect\ngravitational wave (GW) signals of compact binary coalescences, using\nsingle-interferometer data from LIGO detectors. As novel contribution, we\nadopted a resampling white-box approach to advance towards a statistical\nunderstanding of uncertainties intrinsic to CNNs in GW data analysis.\nResampling is performed by repeated $k$-fold cross-validation experiments, and\nfor a white-box approach, behavior of CNNs is mathematically described in\ndetail. Through a Morlet wavelet transform, strain time series are converted to\ntime-frequency images, which in turn are reduced before generating input\ndatasets. Moreover, to reproduce more realistic experimental conditions, we\nworked only with data of non-Gaussian noise and hardware injections, removing\nfreedom to set signal-to-noise ratio (SNR) values in GW templates by hand.\nAfter hyperparameter adjustments, we found that resampling smooths\nstochasticity of mini-batch stochastic gradient descend by reducing mean\naccuracy perturbations in a factor of $3.6$. CNNs were quite precise to detect\nnoise but not sensitive enough to recall GW signals, meaning that CNNs are\nbetter for noise reduction than generation of GW triggers. However, applying a\npost-analysis, we found that for GW signals of SNR $\\geq 21.80$ with H1 data\nand SNR $\\geq 26.80$ with L1 data, CNNs could remain as tentative alternatives\nfor detecting GW signals. Besides, with receiving operating characteristic\ncurves we found that CNNs show much better performances than those of Naive\nBayes and Support Vector Machines models and, with a significance level of\n$5\\%$, we estimated that predictions of CNNs are significant different from\nthose of a random classifier. Finally, we elucidated that performance of CNNs\nis highly class dependent because of the distribution of probabilistic scores\noutputted by the softmax layer.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 03:28:57 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Morales", "Manuel D.", ""], ["Antelis", "Javier M.", ""], ["Moreno", "Claudia", ""], ["Nesterov", "Alexander I.", ""]]}, {"id": "2009.04104", "submitter": "Wei Hu", "authors": "Xinze Lyu and Guangyao Li and Jiacheng Huang and Wei Hu", "title": "Rule-Guided Graph Neural Networks for Recommender Systems", "comments": "Accepted in the 19th International Semantic Web Conference (ISWC\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To alleviate the cold start problem caused by collaborative filtering in\nrecommender systems, knowledge graphs (KGs) are increasingly employed by many\nmethods as auxiliary resources. However, existing work incorporated with KGs\ncannot capture the explicit long-range semantics between users and items\nmeanwhile consider various connectivity between items. In this paper, we\npropose RGRec, which combines rule learning and graph neural networks (GNNs)\nfor recommendation. RGRec first maps items to corresponding entities in KGs and\nadds users as new entities. Then, it automatically learns rules to model the\nexplicit long-range semantics, and captures the connectivity between entities\nby aggregation to better encode various information. We show the effectiveness\nof RGRec on three real-world datasets. Particularly, the combination of rule\nlearning and GNNs achieves substantial improvement compared to methods only\nusing either of them.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 05:00:02 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lyu", "Xinze", ""], ["Li", "Guangyao", ""], ["Huang", "Jiacheng", ""], ["Hu", "Wei", ""]]}, {"id": "2009.04108", "submitter": "Punit Rathore", "authors": "Punit Rathore, Ali Zonoozi, Omid Geramifard, Tan Kian Lee", "title": "Understanding the Dynamics of Drivers' Locations for Passengers Pickup\n  Performance: A Case Study", "comments": "Submitted to IEEE Transactions on Inelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of e-hailing taxi services, a growing number of scholars\nhave attempted to analyze the taxi trips data to gain insights from drivers'\nand passengers' flow patterns and understand different dynamics of urban public\ntransportation. Existing studies are limited to passengers' location analysis\ne.g., pick-up and drop-off points, in the context of maximizing the profits or\nbetter managing the resources for service providers. Moreover, taxi drivers'\nlocations at the time of pick-up requests and their pickup performance in the\nspatial-temporal domain have not been explored. In this paper, we analyze\ndrivers' and passengers' locations at the time of booking request in the\ncontext of drivers' pick-up performances. To facilitate our analysis, we\nimplement a modified and extended version of a co-clustering technique, called\nsco-iVAT, to obtain useful clusters and co-clusters from big relational data,\nderived from booking records of Grab ride-hailing service in Singapore. We also\nexplored the possibility of predicting timely pickup for a given booking\nrequest, without using entire trajectories data. Finally, we devised two\nscoring mechanisms to compute pickup performance score for all driver\ncandidates for a booking request. These scores could be integrated into a\nbooking assignment model to prioritize top-performing drivers for passenger\npickups.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 05:07:03 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Rathore", "Punit", ""], ["Zonoozi", "Ali", ""], ["Geramifard", "Omid", ""], ["Lee", "Tan Kian", ""]]}, {"id": "2009.04110", "submitter": "Asim Khan", "authors": "Asim Khan, Umair Nawaz, Anwaar Ulhaq and Randall W. Robinson", "title": "Real-time Plant Health Assessment Via Implementing Cloud-based Scalable\n  Transfer Learning On AWS DeepLens", "comments": "10 Pages, 12 Figures and 6 Tables", "journal-ref": null, "doi": "10.1371/journal.pone.0243243", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Agriculture sector, control of plant leaf diseases is crucial as it\ninfluences the quality and production of plant species with an impact on the\neconomy of any country. Therefore, automated identification and classification\nof plant leaf disease at an early stage is essential to reduce economic loss\nand to conserve the specific species. Previously, to detect and classify plant\nleaf disease, various Machine Learning models have been proposed; however, they\nlack usability due to hardware incompatibility, limited scalability and\ninefficiency in practical usage. Our proposed DeepLens Classification and\nDetection Model (DCDM) approach deal with such limitations by introducing\nautomated detection and classification of the leaf diseases in fruits (apple,\ngrapes, peach and strawberry) and vegetables (potato and tomato) via scalable\ntransfer learning on AWS SageMaker and importing it on AWS DeepLens for\nreal-time practical usability. Cloud integration provides scalability and\nubiquitous access to our approach. Our experiments on extensive image data set\nof healthy and unhealthy leaves of fruits and vegetables showed an accuracy of\n98.78% with a real-time diagnosis of plant leaves diseases. We used forty\nthousand images for the training of deep learning model and then evaluated it\non ten thousand images. The process of testing an image for disease diagnosis\nand classification using AWS DeepLens on average took 0.349s, providing disease\ninformation to the user in less than a second.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 05:23:34 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 16:58:20 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Khan", "Asim", ""], ["Nawaz", "Umair", ""], ["Ulhaq", "Anwaar", ""], ["Robinson", "Randall W.", ""]]}, {"id": "2009.04120", "submitter": "SeongUk Park", "authors": "SeongUk Park, KiYoon Yoo, Nojun Kwak", "title": "On the Orthogonality of Knowledge Distillation with Other Techniques:\n  From an Ensemble Perspective", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To put a state-of-the-art neural network to practical use, it is necessary to\ndesign a model that has a good trade-off between the resource consumption and\nperformance on the test set. Many researchers and engineers are developing\nmethods that enable training or designing a model more efficiently. Developing\nan efficient model includes several strategies such as network architecture\nsearch, pruning, quantization, knowledge distillation, utilizing cheap\nconvolution, regularization, and also includes any craft that leads to a better\nperformance-resource trade-off. When combining these technologies together, it\nwould be ideal if one source of performance improvement does not conflict with\nothers. We call this property as the orthogonality in model efficiency. In this\npaper, we focus on knowledge distillation and demonstrate that knowledge\ndistillation methods are orthogonal to other efficiency-enhancing methods both\nanalytically and empirically. Analytically, we claim that knowledge\ndistillation functions analogous to a ensemble method, bootstrap aggregating.\nThis analytical explanation is provided from the perspective of implicit data\naugmentation property of knowledge distillation. Empirically, we verify\nknowledge distillation as a powerful apparatus for practical deployment of\nefficient neural network, and also introduce ways to integrate it with other\nmethods effectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 06:14:59 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 14:52:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Park", "SeongUk", ""], ["Yoo", "KiYoon", ""], ["Kwak", "Nojun", ""]]}, {"id": "2009.04126", "submitter": "Se Jung Kwon", "authors": "Dongsoo Lee, Se Jung Kwon, Byeongwook Kim, Yongkweon Jeon, Baeseong\n  Park and Jeongin Yun", "title": "FleXOR: Trainable Fractional Quantization", "comments": "Neurips 2020 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization based on the binary codes is gaining attention because each\nquantized bit can be directly utilized for computations without dequantization\nusing look-up tables. Previous attempts, however, only allow for integer\nnumbers of quantization bits, which ends up restricting the search space for\ncompression ratio and accuracy. In this paper, we propose an encryption\nalgorithm/architecture to compress quantized weights so as to achieve\nfractional numbers of bits per weight. Decryption during inference is\nimplemented by digital XOR-gate networks added into the neural network model\nwhile XOR gates are described by utilizing $\\tanh(x)$ for backward propagation\nto enable gradient calculations. We perform experiments using MNIST, CIFAR-10,\nand ImageNet to show that inserting XOR gates learns quantization/encrypted bit\ndecisions through training and obtains high accuracy even for fractional sub\n1-bit weights. As a result, our proposed method yields smaller size and higher\nmodel accuracy compared to binary neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 06:26:27 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 06:54:36 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Yun", "Jeongin", ""]]}, {"id": "2009.04131", "submitter": "Linyi Li", "authors": "Linyi Li, Xiangyu Qi, Tao Xie, Bo Li", "title": "SoK: Certified Robustness for Deep Neural Networks", "comments": "14 pages for the main text; code available at\n  https://github.com/AI-secure/VeriGauge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Great advancement in deep neural networks (DNNs) has led to state-of-the-art\nperformance on a wide range of tasks. However, recent studies have shown that\nDNNs are vulnerable to adversarial attacks, which have brought great concerns\nwhen deploying these models to safety-critical applications such as autonomous\ndriving. Different defense approaches have been proposed against adversarial\nattacks, including: 1) empirical defenses, which can be adaptively attacked\nagain without providing robustness certification; and 2) certifiably robust\napproaches, which consist of robustness verification providing the lower bound\nof robust accuracy against any attacks under certain conditions and\ncorresponding robust training approaches. In this paper, we focus on these\ncertifiably robust approaches and provide the first work to perform large-scale\nsystematic analysis of different robustness verification and training\napproaches. In particular, we 1) provide a taxonomy for the robustness\nverification and training approaches, as well as discuss the detailed\nmethodologies for representative algorithms, 2) reveal the fundamental\nconnections among these approaches, 3) discuss current research progresses,\ntheoretical barriers, main challenges, and several promising future directions\nfor certified defenses for DNNs, and 4) provide an open-sourced unified\nplatform to evaluate 20+ representative verification and corresponding robust\ntraining approaches on a wide range of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 07:00:55 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 05:04:49 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Li", "Linyi", ""], ["Qi", "Xiangyu", ""], ["Xie", "Tao", ""], ["Li", "Bo", ""]]}, {"id": "2009.04142", "submitter": "Ofir Lindenbaum", "authors": "Ofir Lindenbaum, Amir Sagiv, Gal Mishne, Ronen Talmon", "title": "Kernel-based parameter estimation of dynamical systems with unknown\n  observation functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A low-dimensional dynamical system is observed in an experiment as a\nhigh-dimensional signal; for example, a video of a chaotic pendulums system.\nAssuming that we know the dynamical model up to some unknown parameters, can we\nestimate the underlying system's parameters by measuring its time-evolution\nonly once? The key information for performing this estimation lies in the\ntemporal inter-dependencies between the signal and the model. We propose a\nkernel-based score to compare these dependencies. Our score generalizes a\nmaximum likelihood estimator for a linear model to a general nonlinear setting\nin an unknown feature space. We estimate the system's underlying parameters by\nmaximizing the proposed score. We demonstrate the accuracy and efficiency of\nthe method using two chaotic dynamical systems - the double pendulum and the\nLorenz '63 model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 07:29:11 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 11:07:09 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 09:44:55 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lindenbaum", "Ofir", ""], ["Sagiv", "Amir", ""], ["Mishne", "Gal", ""], ["Talmon", "Ronen", ""]]}, {"id": "2009.04153", "submitter": "Minghui Qiu", "authors": "Mengli Cheng, Minghui Qiu, Xing Shi, Jun Huang, Wei Lin", "title": "One-shot Text Field Labeling using Attention and Belief Propagation for\n  Structure Information Extraction", "comments": "9 pages", "journal-ref": "ACMMM 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structured information extraction from document images usually consists of\nthree steps: text detection, text recognition, and text field labeling. While\ntext detection and text recognition have been heavily studied and improved a\nlot in literature, text field labeling is less explored and still faces many\nchallenges. Existing learning based methods for text labeling task usually\nrequire a large amount of labeled examples to train a specific model for each\ntype of document. However, collecting large amounts of document images and\nlabeling them is difficult and sometimes impossible due to privacy issues.\nDeploying separate models for each type of document also consumes a lot of\nresources. Facing these challenges, we explore one-shot learning for the text\nfield labeling task. Existing one-shot learning methods for the task are mostly\nrule-based and have difficulty in labeling fields in crowded regions with few\nlandmarks and fields consisting of multiple separate text regions. To alleviate\nthese problems, we proposed a novel deep end-to-end trainable approach for\none-shot text field labeling, which makes use of attention mechanism to\ntransfer the layout information between document images. We further applied\nconditional random field on the transferred layout information for the\nrefinement of field labeling. We collected and annotated a real-world one-shot\nfield labeling dataset with a large variety of document types and conducted\nextensive experiments to examine the effectiveness of the proposed model. To\nstimulate research in this direction, the collected dataset and the one-shot\nmodel will be released1.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 08:11:34 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Cheng", "Mengli", ""], ["Qiu", "Minghui", ""], ["Shi", "Xing", ""], ["Huang", "Jun", ""], ["Lin", "Wei", ""]]}, {"id": "2009.04160", "submitter": "Mihaela Breaban", "authors": "Radu Miron, Cosmin Moisii, Mihaela Breaban", "title": "Revealing Lung Affections from CTs. A Comparative Analysis of Various\n  Deep Learning Approaches for Dealing with Volumetric Data", "comments": "ImageClef2020 Tuberculosis task", "journal-ref": "Working Notes of CLEF 2020 - Conference and Labs of the Evaluation\n  Forum Thessaloniki, Greece, September22-25, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper presents and comparatively analyses several deep learning\napproaches to automatically detect tuberculosis related lesions in lung CTs, in\nthe context of the ImageClef 2020 Tuberculosis task. Three classes of methods,\ndifferent with respect to the way the volumetric data is given as input to\nneural network-based classifiers are discussed and evaluated. All these come\nwith a rich experimental analysis comprising a variety of neural network\narchitectures, various segmentation algorithms and data augmentation schemes.\nThe reported work belongs to the SenticLab.UAIC team, which obtained the best\nresults in the competition.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 08:34:18 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Miron", "Radu", ""], ["Moisii", "Cosmin", ""], ["Breaban", "Mihaela", ""]]}, {"id": "2009.04172", "submitter": "Helena Cuesta", "authors": "Helena Cuesta, Brian McFee, Emilia G\\'omez", "title": "Multiple F0 Estimation in Vocal Ensembles using Convolutional Neural\n  Networks", "comments": "Accepted to the 21st International Society for Music Information\n  Retrieval (ISMIR) Conference (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the extraction of multiple F0 values from polyphonic and\na cappella vocal performances using convolutional neural networks (CNNs). We\naddress the major challenges of ensemble singing, i.e., all melodic sources are\nvocals and singers sing in harmony. We build upon an existing architecture to\nproduce a pitch salience function of the input signal, where the harmonic\nconstant-Q transform (HCQT) and its associated phase differentials are used as\nan input representation. The pitch salience function is subsequently\nthresholded to obtain a multiple F0 estimation output. For training, we build a\ndataset that comprises several multi-track datasets of vocal quartets with F0\nannotations. This work proposes and evaluates a set of CNNs for this task in\ndiverse scenarios and data configurations, including recordings with additional\nreverb. Our models outperform a state-of-the-art method intended for the same\nmusic genre when evaluated with an increased F0 resolution, as well as a\ngeneral-purpose method for multi-F0 estimation. We conclude with a discussion\non future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 09:11:49 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Cuesta", "Helena", ""], ["McFee", "Brian", ""], ["G\u00f3mez", "Emilia", ""]]}, {"id": "2009.04197", "submitter": "Jian Hu", "authors": "Jian Hu, Seth Austin Harding, Haibin Wu, Siyue Hu, Shih-wei Liao", "title": "QR-MIX: Distributional Value Function Factorisation for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "There are some experimental errors and experimental unfairness in\n  this paper that will seriously affect the later studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cooperative Multi-Agent Reinforcement Learning (MARL) and under the\nsetting of Centralized Training with Decentralized Execution (CTDE), agents\nobserve and interact with their environment locally and independently. With\nlocal observation and random sampling, the randomness in rewards and\nobservations leads to randomness in long-term returns. Existing methods such as\nValue Decomposition Network (VDN) and QMIX estimate the value of long-term\nreturns as a scalar that does not contain the information of randomness. Our\nproposed model QR-MIX introduces quantile regression, modeling joint\nstate-action values as a distribution, combining QMIX with Implicit Quantile\nNetwork (IQN). However, the monotonicity in QMIX limits the expression of joint\nstate-action value distribution and may lead to incorrect estimation results in\nnon-monotonic cases. Therefore, we proposed a flexible loss function to\napproximate the monotonicity found in QMIX. Our model is not only more tolerant\nof the randomness of returns, but also more tolerant of the randomness of\nmonotonic constraints. The experimental results demonstrate that QR-MIX\noutperforms the previous state-of-the-art method QMIX in the StarCraft\nMulti-Agent Challenge (SMAC) environment.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:28:44 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 06:19:53 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 13:19:11 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 08:10:48 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 12:37:48 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Hu", "Jian", ""], ["Harding", "Seth Austin", ""], ["Wu", "Haibin", ""], ["Hu", "Siyue", ""], ["Liao", "Shih-wei", ""]]}, {"id": "2009.04227", "submitter": "Tabea Kossen", "authors": "Tabea Kossen, Pooja Subramaniam, Vince I. Madai, Anja Hennemuth,\n  Kristian Hildebrand, Adam Hilbert, Jan Sobesky, Michelle Livne, Ivana\n  Galinovic, Ahmed A. Khalil, Jochen B. Fiebach and Dietmar Frey", "title": "Anonymization of labeled TOF-MRA images for brain vessel segmentation\n  using generative adversarial networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Anonymization and data sharing are crucial for privacy protection and\nacquisition of large datasets for medical image analysis. This is a big\nchallenge, especially for neuroimaging. Here, the brain's unique structure\nallows for re-identification and thus requires non-conventional anonymization.\nGenerative adversarial networks (GANs) have the potential to provide anonymous\nimages while preserving predictive properties. Analyzing brain vessel\nsegmentation, we trained 3 GANs on time-of-flight (TOF) magnetic resonance\nangiography (MRA) patches for image-label generation: 1) Deep convolutional\nGAN, 2) Wasserstein-GAN with gradient penalty (WGAN-GP) and 3) WGAN-GP with\nspectral normalization (WGAN-GP-SN). The generated image-labels from each GAN\nwere used to train a U-net for segmentation and tested on real data. Moreover,\nwe applied our synthetic patches using transfer learning on a second dataset.\nFor an increasing number of up to 15 patients we evaluated the model\nperformance on real data with and without pre-training. The performance for all\nmodels was assessed by the Dice Similarity Coefficient (DSC) and the 95th\npercentile of the Hausdorff Distance (95HD). Comparing the 3 GANs, the U-net\ntrained on synthetic data generated by the WGAN-GP-SN showed the highest\nperformance to predict vessels (DSC/95HD 0.82/28.97) benchmarked by the U-net\ntrained on real data (0.89/26.61). The transfer learning approach showed\nsuperior performance for the same GAN compared to no pre-training, especially\nfor one patient only (0.91/25.68 vs. 0.85/27.36). In this work, synthetic\nimage-label pairs retained generalizable information and showed good\nperformance for vessel segmentation. Besides, we showed that synthetic patches\ncan be used in a transfer learning approach with independent data. This paves\nthe way to overcome the challenges of scarce data and anonymization in medical\nimaging.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 11:30:58 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:33:31 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 17:27:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kossen", "Tabea", ""], ["Subramaniam", "Pooja", ""], ["Madai", "Vince I.", ""], ["Hennemuth", "Anja", ""], ["Hildebrand", "Kristian", ""], ["Hilbert", "Adam", ""], ["Sobesky", "Jan", ""], ["Livne", "Michelle", ""], ["Galinovic", "Ivana", ""], ["Khalil", "Ahmed A.", ""], ["Fiebach", "Jochen B.", ""], ["Frey", "Dietmar", ""]]}, {"id": "2009.04238", "submitter": "Jason T. L. Wang", "authors": "Yasser Abduallah, Jason T. L. Wang, Yang Nie, Chang Liu, Haimin Wang", "title": "DeepSun: Machine-Learning-as-a-Service for Solar Flare Prediction", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar flare prediction plays an important role in understanding and\nforecasting space weather. The main goal of the Helioseismic and Magnetic\nImager (HMI), one of the instruments on NASA's Solar Dynamics Observatory, is\nto study the origin of solar variability and characterize the Sun's magnetic\nactivity. HMI provides continuous full-disk observations of the solar vector\nmagnetic field with high cadence data that lead to reliable predictive\ncapability; yet, solar flare prediction effort utilizing these data is still\nlimited. In this paper, we present a machine-learning-as-a-service (MLaaS)\nframework, called DeepSun, for predicting solar flares on the Web based on\nHMI's data products. Specifically, we construct training data by utilizing the\nphysical parameters provided by the Space-weather HMI Active Region Patches\n(SHARP) and categorize solar flares into four classes, namely B, C, M, X,\naccording to the X-ray flare catalogs available at the National Centers for\nEnvironmental Information (NCEI). Thus, the solar flare prediction problem at\nhand is essentially a multi-class (i.e., four-class) classification problem.\nThe DeepSun system employs several machine learning algorithms to tackle this\nmulti-class prediction problem and provides an application programming\ninterface (API) for remote programming users. To our knowledge, DeepSun is the\nfirst MLaaS tool capable of predicting solar flares through the Internet.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 03:41:50 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Abduallah", "Yasser", ""], ["Wang", "Jason T. L.", ""], ["Nie", "Yang", ""], ["Liu", "Chang", ""], ["Wang", "Haimin", ""]]}, {"id": "2009.04239", "submitter": "Jon Cockayne", "authors": "Jon Cockayne and Andrew B. Duncan", "title": "Probabilistic Gradients for Fast Calibration of Differential Equation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration of large-scale differential equation models to observational or\nexperimental data is a widespread challenge throughout applied sciences and\nengineering. A crucial bottleneck in state-of-the art calibration methods is\nthe calculation of local sensitivities, i.e. derivatives of the loss function\nwith respect to the estimated parameters, which often necessitates several\nnumerical solves of the underlying system of partial or ordinary differential\nequations. In this paper we present a new probabilistic approach to computing\nlocal sensitivities. The proposed method has several advantages over classical\nmethods. Firstly, it operates within a constrained computational budget and\nprovides a probabilistic quantification of uncertainty incurred in the\nsensitivities from this constraint. Secondly, information from previous\nsensitivity estimates can be recycled in subsequent computations, reducing the\noverall computational effort for iterative gradient-based calibration methods.\nThe methodology presented is applied to two challenging test problems and\ncompared against classical methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:35:09 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 08:08:35 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cockayne", "Jon", ""], ["Duncan", "Andrew B.", ""]]}, {"id": "2009.04278", "submitter": "Victor Manuel Martinez Alvarez", "authors": "Victor M. Martinez Alvarez and Rare\\c{s} Ro\\c{s}ca and Cristian G.\n  F\\u{a}lcu\\c{t}escu", "title": "DyNODE: Neural Ordinary Differential Equations for Dynamics Modeling in\n  Continuous Control", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach (DyNODE) that captures the underlying dynamics of\na system by incorporating control in a neural ordinary differential equation\nframework. We conduct a systematic evaluation and comparison of our method and\nstandard neural network architectures for dynamics modeling. Our results\nindicate that a simple DyNODE architecture when combined with an actor-critic\nreinforcement learning (RL) algorithm that uses model predictions to improve\nthe critic's target values, outperforms canonical neural networks, both in\nsample efficiency and predictive performance across a diverse range of\ncontinuous tasks that are frequently used to benchmark RL algorithms. This\napproach provides a new avenue for the development of models that are more\nsuited to learn the evolution of dynamical systems, particularly useful in the\ncontext of model-based reinforcement learning. To assist related work, we have\nmade code available at https://github.com/vmartinezalvarez/DyNODE .\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 12:56:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Alvarez", "Victor M. Martinez", ""], ["Ro\u015fca", "Rare\u015f", ""], ["F\u0103lcu\u0163escu", "Cristian G.", ""]]}, {"id": "2009.04284", "submitter": "Hung Tuan  Nguyen Mr.", "authors": "Hung Tuan Nguyen, Tsubasa Nakamura, Cuong Tuan Nguyen and Masaki\n  Nakagawa", "title": "Online trajectory recovery from offline handwritten Japanese kanji\n  characters", "comments": "9 pages, ICPR2020 (reviewing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, it is straightforward to render an offline handwriting image from\nan online handwriting pattern. However, it is challenging to reconstruct an\nonline handwriting pattern given an offline handwriting image, especially for\nmultiple-stroke character as Japanese kanji. The multiple-stroke character\nrequires not only point coordinates but also stroke orders whose difficulty is\nexponential growth by the number of strokes. Besides, several crossed and touch\npoints might increase the difficulty of the recovered task. We propose a deep\nneural network-based method to solve the recovered task using a large online\nhandwriting database. Our proposed model has two main components: Convolutional\nNeural Network-based encoder and Long Short-Term Memory Network-based decoder\nwith an attention layer. The encoder focuses on feature extraction while the\ndecoder refers to the extracted features and generates the time-sequences of\ncoordinates. We also demonstrate the effect of the attention layer to guide the\ndecoder during the reconstruction. We evaluate the performance of the proposed\nmethod by both visual verification and handwritten character recognition.\nAlthough the visual verification reveals some problems, the recognition\nexperiments demonstrate the effect of trajectory recovery in improving the\naccuracy of offline handwritten character recognition when online recognition\nfor the recovered trajectories are combined.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 13:05:50 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Nguyen", "Hung Tuan", ""], ["Nakamura", "Tsubasa", ""], ["Nguyen", "Cuong Tuan", ""], ["Nakagawa", "Masaki", ""]]}, {"id": "2009.04292", "submitter": "Chien-Liang Liu", "authors": "Bin Xiao, Chien-Liang Liu, Wen-Hoar Hsaio", "title": "Proxy Network for Few Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of a few examples for each class to train a predictive model that can\nbe generalized to novel classes is a crucial and valuable research direction in\nartificial intelligence. This work addresses this problem by proposing a\nfew-shot learning (FSL) algorithm called proxy network under the architecture\nof meta-learning. Metric-learning based approaches assume that the data points\nwithin the same class should be close, whereas the data points in the different\nclasses should be separated as far as possible in the embedding space. We\nconclude that the success of metric-learning based approaches lies in the data\nembedding, the representative of each class, and the distance metric. In this\nwork, we propose a simple but effective end-to-end model that directly learns\nproxies for class representative and distance metric from data simultaneously.\nWe conduct experiments on CUB and mini-ImageNet datasets in 1-shot-5-way and\n5-shot-5-way scenarios, and the experimental results demonstrate the\nsuperiority of our proposed method over state-of-the-art methods. Besides, we\nprovide a detailed analysis of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 13:28:07 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Xiao", "Bin", ""], ["Liu", "Chien-Liang", ""], ["Hsaio", "Wen-Hoar", ""]]}, {"id": "2009.04298", "submitter": "Max Christl", "authors": "Max Christl", "title": "Vision-Based Autonomous Drone Control using Supervised Learning in\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited power and computational resources, absence of high-end sensor\nequipment and GPS-denied environments are challenges faced by autonomous micro\nareal vehicles (MAVs). We address these challenges in the context of autonomous\nnavigation and landing of MAVs in indoor environments and propose a\nvision-based control approach using Supervised Learning. To achieve this, we\ncollected data samples in a simulation environment which were labelled\naccording to the optimal control command determined by a path planning\nalgorithm. Based on these data samples, we trained a Convolutional Neural\nNetwork (CNN) that maps low resolution image and sensor input to high-level\ncontrol commands. We have observed promising results in both obstructed and\nnon-obstructed simulation environments, showing that our model is capable of\nsuccessfully navigating a MAV towards a landing platform. Our approach requires\nshorter training times than similar Reinforcement Learning approaches and can\npotentially overcome the limitations of manual data collection faced by\ncomparable Supervised Learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 13:45:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Christl", "Max", ""]]}, {"id": "2009.04323", "submitter": "Quan Wang", "authors": "Quan Wang, Ignacio Lopez Moreno, Mert Saglam, Kevin Wilson, Alan\n  Chiao, Renjie Liu, Yanzhang He, Wei Li, Jason Pelecanos, Marily Nika,\n  Alexander Gruenstein", "title": "VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce VoiceFilter-Lite, a single-channel source separation model that\nruns on the device to preserve only the speech signals from a target user, as\npart of a streaming speech recognition system. Delivering such a model presents\nnumerous challenges: It should improve the performance when the input signal\nconsists of overlapped speech, and must not hurt the speech recognition\nperformance under all other acoustic conditions. Besides, this model must be\ntiny, fast, and perform inference in a streaming fashion, in order to have\nminimal impact on CPU, memory, battery and latency. We propose novel techniques\nto meet these multi-faceted requirements, including using a new asymmetric\nloss, and adopting adaptive runtime suppression strength. We also show that\nsuch a model can be quantized as a 8-bit integer model and run in realtime.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:26:56 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wang", "Quan", ""], ["Moreno", "Ignacio Lopez", ""], ["Saglam", "Mert", ""], ["Wilson", "Kevin", ""], ["Chiao", "Alan", ""], ["Liu", "Renjie", ""], ["He", "Yanzhang", ""], ["Li", "Wei", ""], ["Pelecanos", "Jason", ""], ["Nika", "Marily", ""], ["Gruenstein", "Alexander", ""]]}, {"id": "2009.04324", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes, Loucas Pillaud-Vivien, Francis Bach, Alessandro Rudi", "title": "Overcoming the curse of dimensionality with Laplacian regularization in\n  semi-supervised learning", "comments": "40 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As annotations of data can be scarce in large-scale practical problems,\nleveraging unlabelled examples is one of the most important aspects of machine\nlearning. This is the aim of semi-supervised learning. To benefit from the\naccess to unlabelled data, it is natural to diffuse smoothly knowledge of\nlabelled data to unlabelled one. This induces to the use of Laplacian\nregularization. Yet, current implementations of Laplacian regularization suffer\nfrom several drawbacks, notably the well-known curse of dimensionality. In this\npaper, we provide a statistical analysis to overcome those issues, and unveil a\nlarge body of spectral filtering methods that exhibit desirable behaviors. They\nare implemented through (reproducing) kernel methods, for which we provide\nrealistic computational guidelines in order to make our method usable with\nlarge amounts of data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:28:54 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 18:05:58 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 09:26:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Cabannes", "Vivien", ""], ["Pillaud-Vivien", "Loucas", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2009.04346", "submitter": "Joberto Martins Prof. Dr.", "authors": "Eliseu M. Oliveira and Rafael F. Reale and Joberto S. B. Martins", "title": "A Methodological Approach to Model CBR-based Systems", "comments": "pp 1-16, 3 figures", "journal-ref": "Journal of Computer and Communications, September 2020, ISSN\n  Online: 2327-5227", "doi": "10.4236/jcc.2020.89001", "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has been used in various areas to support system\noptimization and find solutions where the complexity makes it challenging to\nuse algorithmic and heuristics. Case-based Reasoning (CBR) is an AI technique\nintensively exploited in domains like management, medicine, design,\nconstruction, retail and smart grid. CBR is a technique for problem-solving and\ncaptures new knowledge by using past experiences. One of the main CBR\ndeployment challenges is the target system modeling process. This paper\npresents a straightforward methodological approach to model CBR-based\napplications using the concepts of abstract and concrete models. Splitting the\nmodeling process with two models facilitates the allocation of expertise\nbetween the application domain and the CBR technology. The methodological\napproach intends to facilitate the CBR modeling process and to foster CBR use\nin various areas outside computer science.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:09:56 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Oliveira", "Eliseu M.", ""], ["Reale", "Rafael F.", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "2009.04350", "submitter": "Muhammad Aneeq Uz Zaman", "authors": "Muhammad Aneeq uz Zaman, Kaiqing Zhang, Erik Miehling, and Tamer\n  Ba\\c{s}ar", "title": "Reinforcement Learning in Non-Stationary Discrete-Time Linear-Quadratic\n  Mean-Field Games", "comments": "To appear in CDC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.GT cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study large population multi-agent reinforcement learning\n(RL) in the context of discrete-time linear-quadratic mean-field games\n(LQ-MFGs). Our setting differs from most existing work on RL for MFGs, in that\nwe consider a non-stationary MFG over an infinite horizon. We propose an\nactor-critic algorithm to iteratively compute the mean-field equilibrium (MFE)\nof the LQ-MFG. There are two primary challenges: i) the non-stationarity of the\nMFG induces a linear-quadratic tracking problem, which requires solving a\nbackwards-in-time (non-causal) equation that cannot be solved by standard\n(causal) RL algorithms; ii) Many RL algorithms assume that the states are\nsampled from the stationary distribution of a Markov chain (MC), that is, the\nchain is already mixed, an assumption that is not satisfied for real data\nsources. We first identify that the mean-field trajectory follows linear\ndynamics, allowing the problem to be reformulated as a linear quadratic\nGaussian problem. Under this reformulation, we propose an actor-critic\nalgorithm that allows samples to be drawn from an unmixed MC. Finite-sample\nconvergence guarantees for the algorithm are then provided. To characterize the\nperformance of our algorithm in multi-agent RL, we have developed an error\nbound with respect to the Nash equilibrium of the finite-population game.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:17:52 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:41:17 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 15:41:33 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zaman", "Muhammad Aneeq uz", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2009.04362", "submitter": "Matthew Walter", "authors": "Jacopo Tani and Andrea F. Daniele and Gianmarco Bernasconi and Amaury\n  Camus and Aleksandar Petrov and Anthony Courchesne and Bhairav Mehta and\n  Rohit Suri and Tomasz Zaluska and Matthew R. Walter and Emilio Frazzoli and\n  Liam Paull and Andrea Censi", "title": "Integrated Benchmarking and Design for Reproducible and Accessible\n  Evaluation of Robotic Agents", "comments": "IROS 2020; Code available at https://github.com/duckietown", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As robotics matures and increases in complexity, it is more necessary than\never that robot autonomy research be reproducible. Compared to other sciences,\nthere are specific challenges to benchmarking autonomy, such as the complexity\nof the software stacks, the variability of the hardware and the reliance on\ndata-driven techniques, amongst others. In this paper, we describe a new\nconcept for reproducible robotics research that integrates development and\nbenchmarking, so that reproducibility is obtained \"by design\" from the\nbeginning of the research/development processes. We first provide the overall\nconceptual objectives to achieve this goal and then a concrete instance that we\nhave built: the DUCKIENet. One of the central components of this setup is the\nDuckietown Autolab, a remotely accessible standardized setup that is itself\nalso relatively low-cost and reproducible. When evaluating agents, careful\ndefinition of interfaces allows users to choose among local versus remote\nevaluation using simulation, logs, or remote automated hardware setups. We\nvalidate the system by analyzing the repeatability of experiments conducted\nusing the infrastructure and show that there is low variance across different\nrobot hardware and across different remote labs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:31:29 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Tani", "Jacopo", ""], ["Daniele", "Andrea F.", ""], ["Bernasconi", "Gianmarco", ""], ["Camus", "Amaury", ""], ["Petrov", "Aleksandar", ""], ["Courchesne", "Anthony", ""], ["Mehta", "Bhairav", ""], ["Suri", "Rohit", ""], ["Zaluska", "Tomasz", ""], ["Walter", "Matthew R.", ""], ["Frazzoli", "Emilio", ""], ["Paull", "Liam", ""], ["Censi", "Andrea", ""]]}, {"id": "2009.04372", "submitter": "Hakan G\\\"okcesu", "authors": "Kaan Gokcesu, Hakan Gokcesu", "title": "A Generalized Online Algorithm for Translation and Scale Invariant\n  Prediction with Expert Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to create a completely online algorithmic framework for\nprediction with expert advice that is translation-free and scale-free of the\nexpert losses. Our goal is to create a generalized algorithm that is suitable\nfor use in a wide variety of applications. For this purpose, we study the\nexpected regret of our algorithm against a generic competition class in the\nsequential prediction by expert advice problem, where the expected regret\nmeasures the difference between the losses of our prediction algorithm and the\nlosses of the 'best' expert selection strategy in the competition. We design\nour algorithm using the universal prediction perspective to compete against a\nspecified class of expert selection strategies, which is not necessarily a\nfixed expert selection. The class of expert selection strategies that we want\nto compete against is purely determined by the specific application at hand and\nis left generic, which makes our generalized algorithm suitable for use in many\ndifferent problems. We show that no preliminary knowledge about the loss\nsequence is required by our algorithm and its performance bounds, which are\nsecond order, expressed in terms of sums of squared losses. Our regret bounds\nare stable under arbitrary scalings and translations of the losses.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:45:28 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Gokcesu", "Kaan", ""], ["Gokcesu", "Hakan", ""]]}, {"id": "2009.04373", "submitter": "Huan Li", "authors": "Huan Li, Zhouchen Lin, Yongchun Fang", "title": "Variance Reduced EXTRA and DIGing and Their Optimal Acceleration for\n  Strongly Convex Decentralized Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study stochastic decentralized optimization for the problem of training\nmachine learning models with large-scale distributed data. We extend the widely\nused EXTRA and DIGing methods with variance reduction (VR), and propose two\nmethods: VR-EXTRA and VR-DIGing. The proposed VR-EXTRA requires the time of\n$O((\\kappa_s+n)\\log\\frac{1}{\\epsilon})$ stochastic gradient evaluations and\n$O((\\kappa_b+\\kappa_c)\\log\\frac{1}{\\epsilon})$ communication rounds to reach\nprecision $\\epsilon$, where $\\kappa_s$ and $\\kappa_b$ are the stochastic\ncondition number and batch condition number for strongly convex and smooth\nproblems, respectively, $\\kappa_c$ is the condition number of the communication\nnetwork, and $n$ is the sample size on each distributed node. The proposed\nVR-DIGing has a little higher communication cost of\n$O((\\kappa_b+\\kappa_c^2)\\log\\frac{1}{\\epsilon})$. Our stochastic gradient\ncomputation complexities are the same as the ones of single-machine VR methods,\nsuch as SAG, SAGA, and SVRG, and our communication complexities keep the same\nas those of EXTRA and DIGing, respectively. To further speed up the\nconvergence, we also propose the accelerated VR-EXTRA and VR-DIGing with both\nthe optimal $O((\\sqrt{n\\kappa_s}+n)\\log\\frac{1}{\\epsilon})$ stochastic gradient\ncomputation complexity and $O(\\sqrt{\\kappa_b\\kappa_c}\\log\\frac{1}{\\epsilon})$\ncommunication complexity. Our stochastic gradient computation complexity is\nalso the same as the ones of single-machine accelerated VR methods, such as\nKatyusha, and our communication complexity keeps the same as those of\naccelerated full batch decentralized methods, such as MSDA.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:48:44 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 13:09:53 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Huan", ""], ["Lin", "Zhouchen", ""], ["Fang", "Yongchun", ""]]}, {"id": "2009.04381", "submitter": "Mark Collier", "authors": "Mark Collier, Efi Kokiopoulou, Andrea Gesmundo, Jesse Berent", "title": "Routing Networks with Co-training for Continual Learning", "comments": "Presented at ICML Workshop on Continual Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core challenge with continual learning is catastrophic forgetting, the\nphenomenon that when neural networks are trained on a sequence of tasks they\nrapidly forget previously learned tasks. It has been observed that catastrophic\nforgetting is most severe when tasks are dissimilar to each other. We propose\nthe use of sparse routing networks for continual learning. For each input,\nthese network architectures activate a different path through a network of\nexperts. Routing networks have been shown to learn to route similar tasks to\noverlapping sets of experts and dissimilar tasks to disjoint sets of experts.\nIn the continual learning context this behaviour is desirable as it minimizes\ninterference between dissimilar tasks while allowing positive transfer between\nrelated tasks. In practice, we find it is necessary to develop a new training\nmethod for routing networks, which we call co-training which avoids poorly\ninitialized experts when new tasks are presented. When combined with a small\nepisodic memory replay buffer, sparse routing networks with co-training\noutperform densely connected networks on the MNIST-Permutations and\nMNIST-Rotations benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:58:51 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Collier", "Mark", ""], ["Kokiopoulou", "Efi", ""], ["Gesmundo", "Andrea", ""], ["Berent", "Jesse", ""]]}, {"id": "2009.04382", "submitter": "Rui Gao", "authors": "Rui Gao", "title": "Finite-Sample Guarantees for Wasserstein Distributionally Robust\n  Optimization: Breaking the Curse of Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distributionally robust optimization (DRO) aims to find robust\nand generalizable solutions by hedging against data perturbations in\nWasserstein distance. Despite its recent empirical success in operations\nresearch and machine learning, existing performance guarantees for generic loss\nfunctions are either overly conservative due to the curse of dimensionality, or\nplausible only in large sample asymptotics. In this paper, we develop a\nnon-asymptotic framework for analyzing the out-of-sample performance for\nWasserstein robust learning and the generalization bound for its related\nLipschitz and gradient regularization problems. To the best of our knowledge,\nthis gives the first finite-sample guarantee for generic Wasserstein DRO\nproblems without suffering from the curse of dimensionality. Our results\nhighlight the bias-variation trade-off intrinsic in the Wasserstein DRO, which\nbalances between the empirical mean of the loss and the variation of the loss,\nmeasured by the Lipschitz norm or the gradient norm of the loss. Our analysis\nis based on two novel methodological developments that are of independent\ninterest: 1) a new concentration inequality controlling the decay rate of large\ndeviation probabilities by the variation of the loss and, 2) a localized\nRademacher complexity theory based on the variation of the loss.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:02:57 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 11:01:13 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Gao", "Rui", ""]]}, {"id": "2009.04383", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Mukund Telukunta and Venkata Sriram Siddhardh Nadendla", "title": "On the Identification of Fair Auditors to Evaluate Recommender Systems\n  based on a Novel Non-Comparative Fairness Notion", "comments": "10 pages, Accepted to FAccTRec-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-support systems are information systems that offer support to\npeople's decisions in various applications such as judiciary, real-estate and\nbanking sectors. Lately, these support systems have been found to be\ndiscriminatory in the context of many practical deployments. In an attempt to\nevaluate and mitigate these biases, algorithmic fairness literature has been\nnurtured using notions of comparative justice, which relies primarily on\ncomparing two/more individuals or groups within the society that is supported\nby such systems. However, such a fairness notion is not very useful in the\nidentification of fair auditors who are hired to evaluate latent biases within\ndecision-support systems. As a solution, we introduce a paradigm shift in\nalgorithmic fairness via proposing a new fairness notion based on the principle\nof non-comparative justice. Assuming that the auditor makes fairness\nevaluations based on some (potentially unknown) desired properties of the\ndecision-support system, the proposed fairness notion compares the system's\noutcome with that of the auditor's desired outcome. We show that the proposed\nfairness notion also provides guarantees in terms of comparative fairness\nnotions by proving that any system can be deemed fair from the perspective of\ncomparative fairness (e.g. individual fairness and statistical parity) if it is\nnon-comparatively fair with respect to an auditor who has been deemed fair with\nrespect to the same fairness notions. We also show that the converse holds true\nin the context of individual fairness. A brief discussion is also presented\nregarding how our fairness notion can be used to identify fair and reliable\nauditors, and how we can use them to quantify biases in decision-support\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:04:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Telukunta", "Mukund", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2009.04390", "submitter": "Dayeol Lee", "authors": "Dayeol Lee, Dmitrii Kuvaiskii, Anjo Vahldiek-Oberwagner, Mona Vij", "title": "Privacy-Preserving Machine Learning in Untrusted Clouds Made Simple", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practical framework to deploy privacy-preserving machine\nlearning (PPML) applications in untrusted clouds based on a trusted execution\nenvironment (TEE). Specifically, we shield unmodified PyTorch ML applications\nby running them in Intel SGX enclaves with encrypted model parameters and\nencrypted input data to protect the confidentiality and integrity of these\nsecrets at rest and during runtime. We use the open-source Graphene library OS\nwith transparent file encryption and SGX-based remote attestation to minimize\nporting effort and seamlessly provide file protection and attestation. Our\napproach is completely transparent to the machine learning application: the\ndeveloper and the end-user do not need to modify the ML application in any way.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:16:06 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lee", "Dayeol", ""], ["Kuvaiskii", "Dmitrii", ""], ["Vahldiek-Oberwagner", "Anjo", ""], ["Vij", "Mona", ""]]}, {"id": "2009.04392", "submitter": "Christian Ewert", "authors": "Christian Ewert and David K\\\"ugler and Anastasia Yendiki and Martin\n  Reuter", "title": "Learning Anatomical Segmentations for Tractography from Diffusion MRI", "comments": "Christian Ewert and David K\\\"ugler contributed equally. Accepted at\n  MICCAI 2020 International Workshop on Computational Diffusion MRI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches for diffusion MRI have so far focused primarily on\nvoxel-based segmentation of lesions or white-matter fiber tracts. A drawback of\nrepresenting tracts as volumetric labels, rather than sets of streamlines, is\nthat it precludes point-wise analyses of microstructural or geometric features\nalong a tract. Traditional tractography pipelines, which do allow such\nanalyses, can benefit from detailed whole-brain segmentations to guide tract\nreconstruction. Here, we introduce fast, deep learning-based segmentation of\n170 anatomical regions directly on diffusion-weighted MR images, removing the\ndependency of conventional segmentation methods on T 1-weighted images and slow\npre-processing pipelines. Working natively in diffusion space avoids non-linear\ndistortions and registration errors across modalities, as well as interpolation\nartifacts. We demonstrate consistent segmentation results between 0 .70 and 0\n.87 Dice depending on the tissue type. We investigate various combinations of\ndiffusion-derived inputs and show generalization across different numbers of\ngradient directions. Finally, integrating our approach to provide anatomical\npriors for tractography pipelines, such as TRACULA, removes hours of\npre-processing time and permits processing even in the absence of high-quality\nT 1-weighted scans, without degrading the quality of the resulting tract\nestimates.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:20:02 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Ewert", "Christian", ""], ["K\u00fcgler", "David", ""], ["Yendiki", "Anastasia", ""], ["Reuter", "Martin", ""]]}, {"id": "2009.04395", "submitter": "Juanyong Duan", "authors": "Yuanxiang Ying, Juanyong Duan, Chunlei Wang, Yujing Wang, Congrui\n  Huang, Bixiong Xu", "title": "Automated Model Selection for Time-Series Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series anomaly detection is a popular topic in both academia and\nindustrial fields. Many companies need to monitor thousands of temporal signals\nfor their applications and services and require instant feedback and alerts for\npotential incidents in time. The task is challenging because of the complex\ncharacteristics of time-series, which are messy, stochastic, and often without\nproper labels. This prohibits training supervised models because of lack of\nlabels and a single model hardly fits different time series. In this paper, we\npropose a solution to address these issues. We present an automated model\nselection framework to automatically find the most suitable detection model\nwith proper parameters for the incoming data. The model selection layer is\nextensible as it can be updated without too much effort when a new detector is\navailable to the service. Finally, we incorporate a customized tuning algorithm\nto flexibly filter anomalies to meet customers' criteria. Experiments on\nreal-world datasets show the effectiveness of our solution.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:23:43 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Ying", "Yuanxiang", ""], ["Duan", "Juanyong", ""], ["Wang", "Chunlei", ""], ["Wang", "Yujing", ""], ["Huang", "Congrui", ""], ["Xu", "Bixiong", ""]]}, {"id": "2009.04404", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele, Bram Steenwinckel, Pieter Bonte, Michael Weyns,\n  Heiko Paulheim, Petar Ristoski, Filip De Turck, Femke Ongenae", "title": "Walk Extraction Strategies for Node Embeddings with RDF2Vec in Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As KGs are symbolic constructs, specialized techniques have to be applied in\norder to make them compatible with data mining techniques. RDF2Vec is an\nunsupervised technique that can create task-agnostic numerical representations\nof the nodes in a KG by extending successful language modelling techniques. The\noriginal work proposed the Weisfeiler-Lehman (WL) kernel to improve the quality\nof the representations. However, in this work, we show both formally and\nempirically that the WL kernel does little to improve walk embeddings in the\ncontext of a single KG. As an alternative to the WL kernel, we propose five\ndifferent strategies to extract information complementary to basic random\nwalks. We compare these walks on several benchmark datasets to show that the\n\\emph{n-gram} strategy performs best on average on node classification tasks\nand that tuning the walk strategy can result in improved predictive\nperformances.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:26:31 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Steenwinckel", "Bram", ""], ["Bonte", "Pieter", ""], ["Weyns", "Michael", ""], ["Paulheim", "Heiko", ""], ["Ristoski", "Petar", ""], ["De Turck", "Filip", ""], ["Ongenae", "Femke", ""]]}, {"id": "2009.04413", "submitter": "Ziqiao Wang", "authors": "Ziqiao Wang, Yongyi Mao, Hongyu Guo, Richong Zhang", "title": "On SkipGram Word Embedding Models with Negative Sampling: Unified\n  Framework and Impact of Noise Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SkipGram word embedding models with negative sampling, or SGN in short, is an\nelegant family of word embedding models. In this paper, we formulate a\nframework for word embedding, referred to as Word-Context Classification (WCC),\nthat generalizes SGN to a wide family of models. The framework, utilizing some\n\"noise examples\", is justified through a theoretical analysis. The impact of\nnoise distribution on the learning of the WCC embedding models is studied\nexperimentally, suggesting that the best noise distribution is in fact the data\ndistribution, in terms of both the embedding performance and the speed of\nconvergence during training. Along our way, we discover several novel embedding\nmodels that outperform the existing WCC models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 02:11:51 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wang", "Ziqiao", ""], ["Mao", "Yongyi", ""], ["Guo", "Hongyu", ""], ["Zhang", "Richong", ""]]}, {"id": "2009.04416", "submitter": "Karl Cobbe", "authors": "Karl Cobbe, Jacob Hilton, Oleg Klimov, John Schulman", "title": "Phasic Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Phasic Policy Gradient (PPG), a reinforcement learning framework\nwhich modifies traditional on-policy actor-critic methods by separating policy\nand value function training into distinct phases. In prior methods, one must\nchoose between using a shared network or separate networks to represent the\npolicy and value function. Using separate networks avoids interference between\nobjectives, while using a shared network allows useful features to be shared.\nPPG is able to achieve the best of both worlds by splitting optimization into\ntwo phases, one that advances training and one that distills features. PPG also\nenables the value function to be more aggressively optimized with a higher\nlevel of sample reuse. Compared to PPO, we find that PPG significantly improves\nsample efficiency on the challenging Procgen Benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:52:53 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Cobbe", "Karl", ""], ["Hilton", "Jacob", ""], ["Klimov", "Oleg", ""], ["Schulman", "John", ""]]}, {"id": "2009.04426", "submitter": "Felipe Del Rio", "authors": "Pablo Messina, Manuel Cartagena, Patricio Cerda-Mardini, Felipe del\n  Rio and Denis Parra", "title": "CuratorNet: Visually-aware Recommendation of Art Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are several visually-aware recommendation models in domains\nlike fashion or even movies, the art domain lacks thesame level of research\nattention, despite the recent growth of the online artwork market. To reduce\nthis gap, in this article we introduceCuratorNet, a neural network architecture\nfor visually-aware recommendation of art images. CuratorNet is designed at the\ncore withthe goal of maximizing generalization: the network has a fixed set of\nparameters that only need to be trained once, and thereafter themodel is able\nto generalize to new users or items never seen before, without further\ntraining. This is achieved by leveraging visualcontent: items are mapped to\nitem vectors through visual embeddings, and users are mapped to user vectors by\naggregating the visualcontent of items they have consumed. Besides the model\narchitecture, we also introduce novel triplet sampling strategies to build\natraining set for rank learning in the art domain, resulting in more effective\nlearning than naive random sampling. With an evaluationover a real-world\ndataset of physical paintings, we show that CuratorNet achieves the best\nperformance among several baselines,including the state-of-the-art model VBPR.\nCuratorNet is motivated and evaluated in the art domain, but its architecture\nand trainingscheme could be adapted to recommend images in other areas\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:22:17 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:35:08 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Messina", "Pablo", ""], ["Cartagena", "Manuel", ""], ["Cerda-Mardini", "Patricio", ""], ["del Rio", "Felipe", ""], ["Parra", "Denis", ""]]}, {"id": "2009.04441", "submitter": "Diego Antognini", "authors": "Kirtan Padh, Diego Antognini, Emma Lejal Glaude, Boi Faltings, Claudiu\n  Musat", "title": "Addressing Fairness in Classification with a Model-Agnostic\n  Multi-Objective Algorithm", "comments": "Accepted at UAI 2021. 14 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of fairness in classification is to learn a classifier that does not\ndiscriminate against groups of individuals based on sensitive attributes, such\nas race and gender. One approach to designing fair algorithms is to use\nrelaxations of fairness notions as regularization terms or in a constrained\noptimization problem. We observe that the hyperbolic tangent function can\napproximate the indicator function. We leverage this property to define a\ndifferentiable relaxation that approximates fairness notions provably better\nthan existing relaxations. In addition, we propose a model-agnostic\nmulti-objective architecture that can simultaneously optimize for multiple\nfairness notions and multiple sensitive attributes and supports all statistical\nparity-based notions of fairness. We use our relaxation with the\nmulti-objective architecture to learn fair classifiers. Experiments on public\ndatasets show that our method suffers a significantly lower loss of accuracy\nthan current debiasing algorithms relative to the unconstrained model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:40:24 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:17:00 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 12:39:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Padh", "Kirtan", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.04442", "submitter": "Ruiyuan Lin", "authors": "Ruiyuan Lin, Zhiruo Zhou, Suya You, Raghuveer Rao and C.-C. Jay Kuo", "title": "From Two-Class Linear Discriminant Analysis to Interpretable Multilayer\n  Perceptron Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A closed-form solution exists in two-class linear discriminant analysis\n(LDA), which discriminates two Gaussian-distributed classes in a\nmulti-dimensional feature space. In this work, we interpret the multilayer\nperceptron (MLP) as a generalization of a two-class LDA system so that it can\nhandle an input composed by multiple Gaussian modalities belonging to multiple\nclasses. Besides input layer $l_{in}$ and output layer $l_{out}$, the MLP of\ninterest consists of two intermediate layers, $l_1$ and $l_2$. We propose a\nfeedforward design that has three stages: 1) from $l_{in}$ to $l_1$: half-space\npartitionings accomplished by multiple parallel LDAs, 2) from $l_1$ to $l_2$:\nsubspace isolation where one Gaussian modality is represented by one neuron, 3)\nfrom $l_2$ to $l_{out}$: class-wise subspace mergence, where each Gaussian\nmodality is connected to its target class. Through this process, we present an\nautomatic MLP design that can specify the network architecture (i.e., the layer\nnumber and the neuron number at a layer) and all filter weights in a\nfeedforward one-pass fashion. This design can be generalized to an arbitrary\ndistribution by leveraging the Gaussian mixture model (GMM). Experiments are\nconducted to compare the performance of the traditional backpropagation-based\nMLP (BP-MLP) and the new feedforward MLP (FF-MLP).\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:43:39 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lin", "Ruiyuan", ""], ["Zhou", "Zhiruo", ""], ["You", "Suya", ""], ["Rao", "Raghuveer", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2009.04446", "submitter": "Ryohei Hisano", "authors": "Wenning Zhang, Ryohei Hisano, Takaaki Ohnishi, Takayuki Mizuno", "title": "Nondiagonal Mixture of Dirichlet Network Distributions for Analyzing a\n  Stock Ownership Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block modeling is widely used in studies on complex networks. The cornerstone\nmodel is the stochastic block model (SBM), widely used over the past decades.\nHowever, the SBM is limited in analyzing complex networks as the model is, in\nessence, a random graph model that cannot reproduce the basic properties of\nmany complex networks, such as sparsity and heavy-tailed degree distribution.\nIn this paper, we provide an edge exchangeable block model that incorporates\nsuch basic features and simultaneously infers the latent block structure of a\ngiven complex network. Our model is a Bayesian nonparametric model that\nflexibly estimates the number of blocks and takes into account the possibility\nof unseen nodes. Using one synthetic dataset and one real-world stock ownership\ndataset, we show that our model outperforms state-of-the-art SBMs for held-out\nlink prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 05:56:10 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 12:10:41 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Wenning", ""], ["Hisano", "Ryohei", ""], ["Ohnishi", "Takaaki", ""], ["Mizuno", "Takayuki", ""]]}, {"id": "2009.04447", "submitter": "Jie Bu", "authors": "Jie Bu, M. Maruf, Arka Daw", "title": "Beyond Observed Connections : Link Injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed the \\textit{link injection}, a novel method that\nhelps any differentiable graph machine learning models to go beyond observed\nconnections from the input data in an end-to-end learning fashion. It finds out\n(weak) connections in favor of the current task that is not present in the\ninput data via a parametric link injection layer. We evaluate our method on\nboth node classification and link prediction tasks using a series of\nstate-of-the-art graph convolution networks. Results show that the link\ninjection helps a variety of models to achieve better performances on both\napplications. Further empirical analysis shows a great potential of this method\nin efficiently exploiting unseen connections from the injected links.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:22:23 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Bu", "Jie", ""], ["Maruf", "M.", ""], ["Daw", "Arka", ""]]}, {"id": "2009.04450", "submitter": "Micol Marchetti-Bowick", "authors": "Lingyao Zhang, Po-Hsun Su, Jerrick Hoang, Galen Clark Haynes, Micol\n  Marchetti-Bowick", "title": "Map-Adaptive Goal-Based Trajectory Prediction", "comments": "Published at CoRL 2020", "journal-ref": "Conference on Robot Learning (CoRL) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for multi-modal, long-term vehicle trajectory\nprediction. Our approach relies on using lane centerlines captured in rich maps\nof the environment to generate a set of proposed goal paths for each vehicle.\nUsing these paths -- which are generated at run time and therefore dynamically\nadapt to the scene -- as spatial anchors, we predict a set of goal-based\ntrajectories along with a categorical distribution over the goals. This\napproach allows us to directly model the goal-directed behavior of traffic\nactors, which unlocks the potential for more accurate long-term prediction. Our\nexperimental results on both a large-scale internal driving dataset and on the\npublic nuScenes dataset show that our model outperforms state-of-the-art\napproaches for vehicle trajectory prediction over a 6-second horizon. We also\nempirically demonstrate that our model is better able to generalize to road\nscenes from a completely new city than existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:57:01 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 23:20:43 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhang", "Lingyao", ""], ["Su", "Po-Hsun", ""], ["Hoang", "Jerrick", ""], ["Haynes", "Galen Clark", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "2009.04459", "submitter": "Fajilatun Nahar", "authors": "Fajilatun Nahar, Kat Agres, Balamurali BT and Dorien Herremans", "title": "A dataset and classification model for Malay, Hindi, Tamil and Chinese\n  music", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new dataset, with musical excepts from the three\nmain ethnic groups in Singapore: Chinese, Malay and Indian (both Hindi and\nTamil). We use this new dataset to train different classification models to\ndistinguish the origin of the music in terms of these ethnic groups. The\nclassification models were optimized by exploring the use of different musical\nfeatures as the input. Both high level features, i.e., musically meaningful\nfeatures, as well as low level features, i.e., spectrogram based features, were\nextracted from the audio files so as to optimize the performance of the\ndifferent classification models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 06:17:20 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 05:29:59 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nahar", "Fajilatun", ""], ["Agres", "Kat", ""], ["BT", "Balamurali", ""], ["Herremans", "Dorien", ""]]}, {"id": "2009.04462", "submitter": "Jian Pei", "authors": "Jian Pei", "title": "A Survey on Data Pricing: from Economics to Data Science", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2021", "doi": "10.1109/TKDE.2020.3045927", "report-no": null, "categories": "econ.TH cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data are invaluable. How can we assess the value of data objectively,\nsystematically and quantitatively? Pricing data, or information goods in\ngeneral, has been studied and practiced in dispersed areas and principles, such\nas economics, marketing, electronic commerce, data management, data mining and\nmachine learning. In this article, we present a unified, interdisciplinary and\ncomprehensive overview of this important direction. We examine various\nmotivations behind data pricing, understand the economics of data pricing and\nreview the development and evolution of pricing models according to a series of\nfundamental principles. We discuss both digital products and data products. We\nalso consider a series of challenges and directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:31:38 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 23:10:46 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pei", "Jian", ""]]}, {"id": "2009.04465", "submitter": "Aaron Voelker", "authors": "Peter Blouw, Gurshaant Malik, Benjamin Morcos, Aaron R. Voelker, and\n  Chris Eliasmith", "title": "Hardware Aware Training for Efficient Keyword Spotting on General\n  Purpose and Specialized Hardware", "comments": "5 pages, TinyML Research Symposium '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) provides a critical user interface for many mobile and\nedge applications, including phones, wearables, and cars. As KWS systems are\ntypically 'always on', maximizing both accuracy and power efficiency are\ncentral to their utility. In this work we use hardware aware training (HAT) to\nbuild new KWS neural networks based on the Legendre Memory Unit (LMU) that\nachieve state-of-the-art (SotA) accuracy and low parameter counts. This allows\nthe neural network to run efficiently on standard hardware (212$\\mu$W). We also\ncharacterize the power requirements of custom designed accelerator hardware\nthat achieves SotA power efficiency of 8.79$\\mu$W, beating general purpose low\npower hardware (a microcontroller) by 24x and special purpose ASICs by 16x.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:06:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:49:23 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 03:10:09 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Blouw", "Peter", ""], ["Malik", "Gurshaant", ""], ["Morcos", "Benjamin", ""], ["Voelker", "Aaron R.", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2009.04485", "submitter": "Edward A. Fox", "authors": "Saurabh Chakravarty and Satvik Chekuri and Maanav Mehrotra and Edward\n  A. Fox", "title": "Aspect Classification for Legal Depositions", "comments": "19 pages, 3 figures, 11 tables, detailed version of shorter paper\n  being submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attorneys and others have a strong interest in having a digital library with\nsuitable services (e.g., summarizing, searching, and browsing) to help them\nwork with large corpora of legal depositions. Their needs often involve\nunderstanding the semantics of such documents. That depends in part on the role\nof the deponent, e.g., plaintiff, defendant, law enforcement personnel, expert,\netc. In the case of tort litigation associated with property and casualty\ninsurance claims, such as relating to an injury, it is important to know not\nonly about liability, but also about events, accidents, physical conditions,\nand treatments.\n  We hypothesize that a legal deposition consists of various aspects that are\ndiscussed as part of the deponent testimony. Accordingly, we developed an\nontology of aspects in a legal deposition for accident and injury cases. Using\nthat, we have developed a classifier that can identify portions of text for\neach of the aspects of interest. Doing so was complicated by the peculiarities\nof this genre, e.g., that deposition transcripts generally consist of data in\nthe form of question-answer (QA) pairs. Accordingly, our automated system\nstarts with pre-processing, and then transforms the QA pairs into a canonical\nform made up of declarative sentences. Classifying the declarative sentences\nthat are generated, according to the aspect, can then help with downstream\ntasks such as summarization, segmentation, question-answering, and information\nretrieval.\n  Our methods have achieved a classification F1 score of 0.83. Having the\naspects classified with a good accuracy will help in choosing QA pairs that can\nbe used as candidate summary sentences, and to generate an informative summary\nfor legal professionals or insurance claim agents. Our methodology could be\nextended to legal depositions of other kinds, and to aid services like\nsearching.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:00:15 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chakravarty", "Saurabh", ""], ["Chekuri", "Satvik", ""], ["Mehrotra", "Maanav", ""], ["Fox", "Edward A.", ""]]}, {"id": "2009.04488", "submitter": "Vincent Su", "authors": "Vincent Paul Su", "title": "Variational Preparation of the Sachdev-Ye-Kitaev Thermofield Double", "comments": "20 pages, 8 figures; v2 references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an algorithm for preparing the thermofield double (TFD) state of\nthe Sachdev-Ye-Kitaev model without the need for an auxiliary bath. Following\nprevious work, the TFD can be cast as the approximate ground state of a\nHamiltonian, $H_{\\text{TFD}}$. Using variational quantum circuits, we propose\nand implement a gradient-based algorithm for learning parameters that find this\nground state, an application of the variational quantum eigensolver.\nConcretely, we find quantum circuits that prepare the ground state of\n$H_{\\text{TFD}}$ for the $q=4$ SYK model up to $N=12$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:01:54 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 19:06:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Su", "Vincent Paul", ""]]}, {"id": "2009.04519", "submitter": "Laura Schaposnik", "authors": "Vishaal Ram, Laura P. Schaposnik, Nikos Konstantinou, Eliz Volkan,\n  Marietta Papadatou-Pastou, Banu Manav, Domicele Jonauskaite, Christine Mohr", "title": "Extrapolating continuous color emotions through deep learning", "comments": "To appear in Physical Review R. (8 pages, 13 figures)", "journal-ref": "Physical Review RESEARCH 2, 033350 (2020)", "doi": "10.1103/PhysRevResearch.2.033350", "report-no": null, "categories": "q-bio.QM cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By means of an experimental dataset, we use deep learning to implement an RGB\nextrapolation of emotions associated to color, and do a mathematical study of\nthe results obtained through this neural network. In particular, we see that\nmales typically associate a given emotion with darker colors while females with\nbrighter colors. A similar trend was observed with older people and\nassociations to lighter colors. Moreover, through our classification matrix, we\nidentify which colors have weak associations to emotions and which colors are\ntypically confused with other colors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 02:08:29 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ram", "Vishaal", ""], ["Schaposnik", "Laura P.", ""], ["Konstantinou", "Nikos", ""], ["Volkan", "Eliz", ""], ["Papadatou-Pastou", "Marietta", ""], ["Manav", "Banu", ""], ["Jonauskaite", "Domicele", ""], ["Mohr", "Christine", ""]]}, {"id": "2009.04521", "submitter": "David Vigouroux", "authors": "Thomas Fel (ANITI), David Vigouroux, R\\'emi Cad\\`ene, Thomas Serre\n  (ANITI)", "title": "How good is your explanation? Algorithmic stability measures to assess\n  the qualityof explanations for deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of methods have been proposed to explain howdeep neural networks\nreach a decision but comparativelylittle effort has been made to ensure that\nthe explanationsproduced by these methods are objectively relevant.\nWhiledesirable properties for a good explanation are easy to come,objective\nmeasures have been harder to derive. Here, we pro-pose two new measures to\nevaluate explanations borrowedfrom the field of algorithmic stability: relative\nconsistencyReCo and mean generalizability MeGe. We conduct severalexperiments\non multiple image datasets and network archi-tectures to demonstrate the\nbenefits of the proposed measuresover representative methods. We show that\npopular fidelitymeasures are not sufficient to guarantee good\nexplanations.Finally, we show empirically that 1-Lipschitz networks pro-vide\ngeneral and consistent explanations, regardless of theexplanation method used,\nmaking them a relevant directionfor explainability.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 08:02:29 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 10:03:53 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Fel", "Thomas", "", "ANITI"], ["Vigouroux", "David", "", "ANITI"], ["Cad\u00e8ne", "R\u00e9mi", "", "ANITI"], ["Serre", "Thomas", "", "ANITI"]]}, {"id": "2009.04522", "submitter": "Caiqing Jian", "authors": "Caiqing Jian, Xinyu Cheng, Jian Zhang, Lihui Wang", "title": "Scalar Coupling Constant Prediction Using Graph Embedding Local\n  Attention Encoder", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalar coupling constant (SCC) plays a key role in the analysis of\nthree-dimensional structure of organic matter, however, the traditional SCC\nprediction using quantum mechanical calculations is very time-consuming. To\ncalculate SCC efficiently and accurately, we proposed a graph embedding local\nself-attention encoder (GELAE) model, in which, a novel invariant structure\nrepresentation of the coupling system in terms of bond length, bond angle and\ndihedral angle was presented firstly, and then a local self-attention module\nembedded with the adjacent matrix of a graph was designed to extract\neffectively the features of coupling systems, finally, with a modified\nclassification loss function, the SCC was predicted. To validate the\nsuperiority of the proposed method, we conducted a series of comparison\nexperiments using different structure representations, different attention\nmodules, and different losses. The experimental results demonstrate that,\ncompared to the traditional chemical bond structure representations, the\nrotation and translation invariant structure representations proposed in this\nwork can improve the SCC prediction accuracy; with the graph embedded local\nself-attention, the mean absolute error (MAE) of the prediction model in the\nvalidation set decreases from 0.1603 Hz to 0.1067 Hz; using the classification\nbased loss function instead of the scaled regression loss, the MAE of the\npredicted SCC can be decreased to 0.0963 HZ, which is close to the quantum\nchemistry standard on CHAMPS dataset.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 02:53:03 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Jian", "Caiqing", ""], ["Cheng", "Xinyu", ""], ["Zhang", "Jian", ""], ["Wang", "Lihui", ""]]}, {"id": "2009.04524", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Moun\\^im A. El Yacoubi, Mehdi Ammi", "title": "Interpreting Deep Glucose Predictive Models for Diabetic People Using\n  RETAIN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in the biomedical field through the use of deep learning is hindered\nby the lack of interpretability of the models. In this paper, we study the\nRETAIN architecture for the forecasting of future glucose values for diabetic\npeople. Thanks to its two-level attention mechanism, the RETAIN model is\ninterpretable while remaining as efficient as standard neural networks. We\nevaluate the model on a real-world type-2 diabetic population and we compare it\nto a random forest model and a LSTM-based recurrent neural network. Our results\nshow that the RETAIN model outperforms the former and equals the latter on\ncommon accuracy metrics and clinical acceptability metrics, thereby proving its\nlegitimacy in the context of glucose level forecasting. Furthermore, we propose\ntools to take advantage of the RETAIN interpretable nature. As informative for\nthe patients as for the practitioners, it can enhance the understanding of the\npredictions made by the model and improve the design of future glucose\npredictive models.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:20:15 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["De Bois", "Maxime", ""], ["Yacoubi", "Moun\u00eem A. El", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.04525", "submitter": "Enrui Zhang", "authors": "Enrui Zhang, Minglang Yin, George Em Karniadakis", "title": "Physics-Informed Neural Networks for Nonhomogeneous Material\n  Identification in Elasticity Imaging", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.soft eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply Physics-Informed Neural Networks (PINNs) for solving identification\nproblems of nonhomogeneous materials. We focus on the problem with a background\nin elasticity imaging, where one seeks to identify the nonhomogeneous\nmechanical properties of soft tissue based on the full-field displacement\nmeasurements under quasi-static loading. In our model, we apply two independent\nneural networks, one for approximating the solution of the corresponding\nforward problem, and the other for approximating the unknown material parameter\nfield. As a proof of concept, we validate our model on a prototypical plane\nstrain problem for incompressible hyperelastic tissue. The results show that\nthe PINNs are effective in accurately recovering the unknown distribution of\nmechanical properties. By employing two neural networks in our model, we extend\nthe capability of material identification of PINNs to include nonhomogeneous\nmaterial parameter fields, which enables more flexibility of PINNs in\nrepresenting complex material properties.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 23:37:36 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Zhang", "Enrui", ""], ["Yin", "Minglang", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2009.04532", "submitter": "Mohammad Abuzar Shaikh", "authors": "Mohammad Abuzar Shaikh, Tiehang Duan, Mihir Chauhan, Sargur Srihari", "title": "Attention based Writer Independent Handwriting Verification", "comments": "7 pages, 6 figures, Published in 2020 17th International Conference\n  on Frontiers in Handwriting Recognition (ICFHR)", "journal-ref": null, "doi": "10.1109/ICFHR2020.2020.00074", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of writer verification is to provide a likelihood score for whether\nthe queried and known handwritten image samples belong to the same writer or\nnot. Such a task calls for the neural network to make it's outcome\ninterpretable, i.e. provide a view into the network's decision making process.\nWe implement and integrate cross-attention and soft-attention mechanisms to\ncapture the highly correlated and salient points in feature space of 2D inputs.\nThe attention maps serve as an explanation premise for the network's output\nlikelihood score. The attention mechanism also allows the network to focus more\non relevant areas of the input, thus improving the classification performance.\nOur proposed approach achieves a precision of 86\\% for detecting intra-writer\ncases in CEDAR cursive \"AND\" dataset. Furthermore, we generate meaningful\nexplanations for the provided decision by extracting attention maps from\nmultiple levels of the network.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:28:16 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 13:56:44 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 00:59:36 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Shaikh", "Mohammad Abuzar", ""], ["Duan", "Tiehang", ""], ["Chauhan", "Mihir", ""], ["Srihari", "Sargur", ""]]}, {"id": "2009.04534", "submitter": "Swetha Mandava", "authors": "Swetha Mandava, Szymon Migacz, Alex Fit Florea", "title": "Pay Attention when Required", "comments": "9 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models consist of interleaved feed-forward blocks - that\ncapture content meaning, and relatively more expensive self-attention blocks -\nthat capture context meaning. In this paper, we explored trade-offs and\nordering of the blocks to improve upon the current Transformer architecture and\nproposed PAR Transformer. It needs 35% lower compute time than Transformer-XL\nachieved by replacing ~63% of the self-attention blocks with feed-forward\nblocks, and retains the perplexity on WikiText-103 language modelling\nbenchmark. We further validated our results on text8 and enwiki8 datasets, as\nwell as on the BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:39:15 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 07:41:58 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 04:03:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mandava", "Swetha", ""], ["Migacz", "Szymon", ""], ["Florea", "Alex Fit", ""]]}, {"id": "2009.04535", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Sebastian Me\\v{z}nar, Nada Lavra\\v{c}, Bla\\v{z} \\v{S}krlj", "title": "SNoRe: Scalable Unsupervised Learning of Symbolic Node Representations", "comments": "Accepted to IEEEAccess", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3039541", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from complex real-life networks is a lively research area, with\nrecent advances in learning information-rich, low-dimensional network node\nrepresentations. However, state-of-the-art methods are not necessarily\ninterpretable and are therefore not fully applicable to sensitive settings in\nbiomedical or user profiling tasks, where explicit bias detection is highly\nrelevant. The proposed SNoRe (Symbolic Node Representations) algorithm is\ncapable of learning symbolic, human-understandable representations of\nindividual network nodes, based on the similarity of neighborhood hashes which\nserve as features. SNoRe's interpretable features are suitable for direct\nexplanation of individual predictions, which we demonstrate by coupling it with\nthe widely used instance explanation tool SHAP to obtain nomograms representing\nthe relevance of individual features for a given classification. To our\nknowledge, this is one of the first such attempts in a structural node\nembedding setting. In the experimental evaluation on eleven real-life datasets,\nSNoRe proved to be competitive to strong baselines, such as variational graph\nautoencoders, node2vec and LINE. The vectorized implementation of SNoRe scales\nto large networks, making it suitable for contemporary network learning and\nanalysis tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:13:21 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 13:34:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Me\u017enar", "Sebastian", ""], ["Lavra\u010d", "Nada", ""], ["\u0160krlj", "Bla\u017e", ""]]}, {"id": "2009.04536", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "Improving Investment Suggestions for Peer-to-Peer (P2P) Lending via\n  Integrating Credit Scoring into Profit Scoring", "comments": null, "journal-ref": null, "doi": "10.1145/3374135.3385272", "report-no": null, "categories": "q-fin.RM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the peer-to-peer (P2P) lending market, lenders lend the money to the\nborrowers through a virtual platform and earn the possible profit generated by\nthe interest rate. From the perspective of lenders, they want to maximize the\nprofit while minimizing the risk. Therefore, many studies have used machine\nlearning algorithms to help the lenders identify the \"best\" loans for making\ninvestments. The studies have mainly focused on two categories to guide the\nlenders' investments: one aims at minimizing the risk of investment (i.e., the\ncredit scoring perspective) while the other aims at maximizing the profit\n(i.e., the profit scoring perspective). However, they have all focused on one\ncategory only and there is seldom research trying to integrate the two\ncategories together. Motivated by this, we propose a two-stage framework that\nincorporates the credit information into a profit scoring modeling. We\nconducted the empirical experiment on a real-world P2P lending data from the US\nP2P market and used the Light Gradient Boosting Machine (lightGBM) algorithm in\nthe two-stage framework. Results show that the proposed two-stage method could\nidentify more profitable loans and thereby provide better investment guidance\nto the investors compared to the existing one-stage profit scoring alone\napproach. Therefore, the proposed framework serves as an innovative perspective\nfor making investment decisions in P2P lending.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:41:23 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "2009.04543", "submitter": "Dongxiao Zhang", "authors": "Rui Xu, Dongxiao Zhang, Miao Rong, and Nanzhe Wang", "title": "Weak Form Theory-guided Neural Network (TgNN-wf) for Deep Learning of\n  Subsurface Single and Two-phase Flow", "comments": "35 pages, 10 figures, and 6 tables", "journal-ref": "Journal of Computational Physics, 110318, 2021", "doi": "10.1016/j.jcp.2021.110318", "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are widely used as surrogate models in\ngeophysical applications; incorporating theoretical guidance into DNNs has\nimproved the generalizability. However, most of such approaches define the loss\nfunction based on the strong form of conservation laws (via partial\ndifferential equations, PDEs), which is subject to deteriorated accuracy when\nthe PDE has high order derivatives or the solution has strong discontinuities.\nHerein, we propose a weak form theory-guided neural network (TgNN-wf), which\nincorporates the weak form formulation of the PDE into the loss function\ncombined with data constraint and initial and boundary conditions\nregularizations to tackle the aforementioned difficulties. In the weak form,\nhigh order derivatives in the PDE can be transferred to the test functions by\nperforming integration-by-parts, which reduces computational error. We use\ndomain decomposition with locally defined test functions, which captures local\ndiscontinuity effectively. Two numerical cases demonstrate the superiority of\nthe proposed TgNN-wf over the strong form TgNN, including the hydraulic head\nprediction for unsteady-state 2D single-phase flow problems and the saturation\nprofile prediction for 1D two-phase flow problems. Results show that TgNN-wf\nconsistently has higher accuracy than TgNN, especially when strong\ndiscontinuity in the solution is present. TgNN-wf also trains faster than TgNN\nwhen the number of integration subdomains is not too large (<10,000). Moreover,\nTgNN-wf is more robust to noises. Thus, the proposed TgNN-wf paves the way for\nwhich a variety of deep learning problems in the small data regime can be\nsolved more accurately and efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 06:10:30 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:53:43 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Xu", "Rui", ""], ["Zhang", "Dongxiao", ""], ["Rong", "Miao", ""], ["Wang", "Nanzhe", ""]]}, {"id": "2009.04544", "submitter": "Levi McClenny", "authors": "Levi McClenny, Ulisses Braga-Neto", "title": "Self-Adaptive Physics-Informed Neural Networks using a Soft Attention\n  Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-Informed Neural Networks (PINNs) have emerged recently as a promising\napplication of deep neural networks to the numerical solution of nonlinear\npartial differential equations (PDEs). However, the original PINN algorithm is\nknown to suffer from stability and accuracy problems in cases where the\nsolution has sharp spatio-temporal transitions. These stiff PDEs require an\nunreasonably large number of collocation points to be solved accurately. It has\nbeen recognized that adaptive procedures are needed to force the neural network\nto fit accurately the stubborn spots in the solution of stiff PDEs. To\naccomplish this, previous approaches have used fixed weights hard-coded over\nregions of the solution deemed to be important. In this paper, we propose a\nfundamentally new method to train PINNs adaptively, where the adaptation\nweights are fully trainable, so the neural network learns by itself which\nregions of the solution are difficult and is forced to focus on them, which is\nreminiscent of soft multiplicative-mask attention mechanism used in computer\nvision. The basic idea behind these Self-Adaptive PINNs is to make the weights\nincrease where the corresponding loss is higher, which is accomplished by\ntraining the network to simultaneously minimize the losses and maximize the\nweights, i.e., to find a saddle point in the cost surface. We show that this is\nformally equivalent to solving a PDE-constrained optimization problem using a\npenalty-based method, though in a way where the monotonically-nondecreasing\npenalty coefficients are trainable. Numerical experiments with an Allen-Cahn\nstiff PDE, the Self-Adaptive PINN outperformed other state-of-the-art PINN\nalgorithms in L2 error by a wide margin, while using a smaller number of\ntraining epochs. An Appendix contains additional results with Burger's and\nHelmholtz PDEs, which confirmed the trends observed in the Allen-Cahn\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 04:07:52 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 06:05:45 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["McClenny", "Levi", ""], ["Braga-Neto", "Ulisses", ""]]}, {"id": "2009.04549", "submitter": "Daniel Dunlavy", "authors": "Scott Heidbrink, Kathryn N. Rodhouse, Daniel M. Dunlavy", "title": "Multimodal Deep Learning for Flaw Detection in Software Programs", "comments": "13 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": "SAND2020-9429R", "categories": "cs.LG cs.AI cs.CR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of multiple deep learning models for detecting flaws in\nsoftware programs. Current, standard approaches for flaw detection rely on a\nsingle representation of a software program (e.g., source code or a program\nbinary). We illustrate that, by using techniques from multimodal deep learning,\nwe can simultaneously leverage multiple representations of software programs to\nimprove flaw detection over single representation analyses. Specifically, we\nadapt three deep learning models from the multimodal learning literature for\nuse in flaw detection and demonstrate how these models outperform traditional\ndeep learning models. We present results on detecting software flaws using the\nJuliet Test Suite and Linux Kernel.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:15:11 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Heidbrink", "Scott", ""], ["Rodhouse", "Kathryn N.", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "2009.04550", "submitter": "Zichao Li", "authors": "Nicolas Fraiman, Zichao Li", "title": "Biclustering with Alternating K-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is the task of simultaneously clustering the rows and columns of\nthe data matrix into different subgroups such that the rows and columns within\na subgroup exhibit similar patterns. In this paper, we consider the case of\nproducing exclusive row and column biclusters. We provide a new formulation of\nthe biclustering problem based on the idea of minimizing the empirical\nclustering risk. We develop and prove a consistency result with respect to the\nempirical clustering risk. Since the optimization problem is combinatorial in\nnature, finding the global minimum is computationally intractable. In light of\nthis fact, we propose a simple and novel algorithm that finds a local minimum\nby alternating the use of an adapted version of the k-means clustering\nalgorithm between columns and rows. We evaluate and compare the performance of\nour algorithm to other related biclustering methods on both simulated data and\nreal-world gene expression data sets. The results demonstrate that our\nalgorithm is able to detect meaningful structures in the data and outperform\nother competing biclustering methods in various settings and situations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:15:24 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Fraiman", "Nicolas", ""], ["Li", "Zichao", ""]]}, {"id": "2009.04559", "submitter": "Yan Wang", "authors": "Yan Wang, Xuelei Sherry Ni", "title": "Developing and Improving Risk Models using Machine-learning Based\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1145/3299815.3314478", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this study is to develop a good risk model for classifying\nbusiness delinquency by simultaneously exploring several machine learning based\nmethods including regularization, hyper-parameter optimization, and model\nensembling algorithms. The rationale under the analyses is firstly to obtain\ngood base binary classifiers (include Logistic Regression ($LR$), K-Nearest\nNeighbors ($KNN$), Decision Tree ($DT$), and Artificial Neural Networks\n($ANN$)) via regularization and appropriate settings of hyper-parameters. Then\ntwo model ensembling algorithms including bagging and boosting are performed on\nthe good base classifiers for further model improvement. The models are\nevaluated using accuracy, Area Under the Receiver Operating Characteristic\nCurve (AUC of ROC), recall, and F1 score via repeating 10-fold cross-validation\n10 times. The results show the optimal base classifiers along with the\nhyper-parameter settings are $LR$ without regularization, $KNN$ by using 9\nnearest neighbors, $DT$ by setting the maximum level of the tree to be 7, and\n$ANN$ with three hidden layers. Bagging on $KNN$ with $K$ valued 9 is the\noptimal model we can get for risk classification as it reaches the average\naccuracy, AUC, recall, and F1 score valued 0.90, 0.93, 0.82, and 0.89,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:38:00 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Yan", ""], ["Ni", "Xuelei Sherry", ""]]}, {"id": "2009.04568", "submitter": "Bhavya Ghai", "authors": "Bhavya Ghai, Q. Vera Liao, Yunfeng Zhang, Klaus Mueller", "title": "Active Learning++: Incorporating Annotator's Rationale using Local Model\n  Explanation", "comments": "Accepted at Workshop on Data Science with Human in the Loop (DaSH) @\n  ACM SIGKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new active learning (AL) framework, Active Learning++, which can\nutilize an annotator's labels as well as its rationale. Annotators can provide\ntheir rationale for choosing a label by ranking input features based on their\nimportance for a given query. To incorporate this additional input, we modified\nthe disagreement measure for a bagging-based Query by Committee (QBC) sampling\nstrategy. Instead of weighing all committee models equally to select the next\ninstance, we assign higher weight to the committee model with higher agreement\nwith the annotator's ranking. Specifically, we generated a feature\nimportance-based local explanation for each committee model. The similarity\nscore between feature rankings provided by the annotator and the local model\nexplanation is used to assign a weight to each corresponding committee model.\nThis approach is applicable to any kind of ML model using model-agnostic\ntechniques to generate local explanation such as LIME. With a simulation study,\nwe show that our framework significantly outperforms a QBC based vanilla AL\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:07:33 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Ghai", "Bhavya", ""], ["Liao", "Q. Vera", ""], ["Zhang", "Yunfeng", ""], ["Mueller", "Klaus", ""]]}, {"id": "2009.04570", "submitter": "Eric Hall", "authors": "S{\\o}ren Taverniers and Eric J. Hall and Markos A. Katsoulakis and\n  Daniel M. Tartakovsky", "title": "Mutual Information for Explainable Deep Learning of Multiscale Systems", "comments": "27 pages, 8 figures. Added additional examples", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110551", "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely completion of design cycles for complex systems ranging from consumer\nelectronics to hypersonic vehicles relies on rapid simulation-based\nprototyping. The latter typically involves high-dimensional spaces of possibly\ncorrelated control variables (CVs) and quantities of interest (QoIs) with\nnon-Gaussian and possibly multimodal distributions. We develop a\nmodel-agnostic, moment-independent global sensitivity analysis (GSA) that\nrelies on differential mutual information to rank the effects of CVs on QoIs.\nThe data requirements of this information-theoretic approach to GSA are met by\nreplacing computationally intensive components of the physics-based model with\na deep neural network surrogate. Subsequently, the GSA is used to explain the\nnetwork predictions, and the surrogate is deployed to close design loops.\nViewed as an uncertainty quantification method for interrogating the surrogate,\nthis framework is compatible with a wide variety of black-box models. We\ndemonstrate that the surrogate-driven mutual information GSA provides useful\nand distinguishable rankings on two applications of interest in energy storage.\nConsequently, our information-theoretic GSA provides an \"outer loop\" for\naccelerated product design by identifying the most and least sensitive input\ndirections and performing subsequent optimization over appropriately reduced\nparameter subspaces.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:26:21 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 10:04:18 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Taverniers", "S\u00f8ren", ""], ["Hall", "Eric J.", ""], ["Katsoulakis", "Markos A.", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "2009.04575", "submitter": "M. Sadegh Talebi", "authors": "Mohammad Sadegh Talebi, Anders Jonsson, Odalric-Ambrym Maillard", "title": "Improved Exploration in Factored Average-Reward MDPs", "comments": "23 pages. To appear in Proceedings of the 24th International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a regret minimization task under the average-reward criterion in\nan unknown Factored Markov Decision Process (FMDP). More specifically, we\nconsider an FMDP where the state-action space $\\mathcal X$ and the state-space\n$\\mathcal S$ admit the respective factored forms of $\\mathcal X =\n\\otimes_{i=1}^n \\mathcal X_i$ and $\\mathcal S=\\otimes_{i=1}^m \\mathcal S_i$,\nand the transition and reward functions are factored over $\\mathcal X$ and\n$\\mathcal S$. Assuming known factorization structure, we introduce a novel\nregret minimization strategy inspired by the popular UCRL2 strategy, called\nDBN-UCRL, which relies on Bernstein-type confidence sets defined for individual\nelements of the transition function. We show that for a generic factorization\nstructure, DBN-UCRL achieves a regret bound, whose leading term strictly\nimproves over existing regret bounds in terms of the dependencies on the size\nof $\\mathcal S_i$'s and the involved diameter-related terms. We further show\nthat when the factorization structure corresponds to the Cartesian product of\nsome base MDPs, the regret of DBN-UCRL is upper bounded by the sum of regret of\nthe base MDPs. We demonstrate, through numerical experiments on standard\nenvironments, that DBN-UCRL enjoys substantially improved regret empirically\nover existing algorithms that have frequentist regret guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 21:15:01 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 11:04:41 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 13:01:24 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Talebi", "Mohammad Sadegh", ""], ["Jonsson", "Anders", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "2009.04587", "submitter": "Aadesh Neupane", "authors": "Aadesh Neupane", "title": "A brief history on Homomorphic learning: A privacy-focused approach to\n  machine learning", "comments": "A CS611 class project paper to trace the history of privacy focused\n  machine learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cryptography and data science research grew exponential with the internet\nboom. Legacy encryption techniques force users to make a trade-off between\nusability, convenience, and security. Encryption makes valuable data\ninaccessible, as it needs to be decrypted each time to perform any operation.\nBillions of dollars could be saved, and millions of people could benefit from\ncryptography methods that don't compromise between usability, convenience, and\nsecurity. Homomorphic encryption is one such paradigm that allows running\narbitrary operations on encrypted data. It enables us to run any sophisticated\nmachine learning algorithm without access to the underlying raw data. Thus,\nhomomorphic learning provides the ability to gain insights from sensitive data\nthat has been neglected due to various governmental and organization privacy\nrules.\n  In this paper, we trace back the ideas of homomorphic learning formally posed\nby Ronald L. Rivest and Len Alderman as \"Can we compute upon encrypted data?\"\nin their 1978 paper. Then we gradually follow the ideas sprouting in the\nbrilliant minds of Shafi Goldwasser, Kristin Lauter, Dan Bonch, Tomas Sander,\nDonald Beaver, and Craig Gentry to address that vital question. It took more\nthan 30 years of collective effort to finally find the answer \"yes\" to that\nimportant question.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 21:57:47 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 02:14:16 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Neupane", "Aadesh", ""]]}, {"id": "2009.04591", "submitter": "Peng Liu", "authors": "Ying Chen, Peng Liu, Chung Piaw Teo", "title": "Regularised Text Logistic Regression: Key Word Detection and Sentiment\n  Classification for Online Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online customer reviews have become important for managers and executives in\nthe hospitality and catering industry who wish to obtain a comprehensive\nunderstanding of their customers' demands and expectations. We propose a\nRegularized Text Logistic (RTL) regression model to perform text analytics and\nsentiment classification on unstructured text data, which automatically\nidentifies a set of statistically significant and operationally insightful word\nfeatures, and achieves satisfactory predictive classification accuracy. We\napply the RTL model to two online review datasets, Restaurant and Hotel, from\nTripAdvisor. Our results demonstrate satisfactory classification performance\ncompared with alternative classifiers with a highest true positive rate of\n94.9%. Moreover, RTL identifies a small set of word features, corresponding to\n3% for Restaurant and 20% for Hotel, which boosts working efficiency by\nallowing managers to drill down into a much smaller set of important customer\nreviews. We also develop the consistency, sparsity and oracle property of the\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 22:37:53 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chen", "Ying", ""], ["Liu", "Peng", ""], ["Teo", "Chung Piaw", ""]]}, {"id": "2009.04595", "submitter": "Manie Tadayon", "authors": "Manie Tadayon, Greg Pottie", "title": "tsBNgen: A Python Library to Generate Time Series Data from an Arbitrary\n  Dynamic Bayesian Network Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data is widely used in various domains. This is because many modern\nalgorithms require lots of data for efficient training, and data collection and\nlabeling usually are a time-consuming process and are prone to errors.\nFurthermore, some real-world data, due to its nature, is confidential and\ncannot be shared. Bayesian networks are a type of probabilistic graphical model\nwidely used to model the uncertainties in real-world processes. Dynamic\nBayesian networks are a special class of Bayesian networks that model temporal\nand time series data. In this paper, we introduce the tsBNgen, a Python library\nto generate time series and sequential data based on an arbitrary dynamic\nBayesian network. The package, documentation, and examples can be downloaded\nfrom https://github.com/manitadayon/tsBNgen.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 23:10:40 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Tadayon", "Manie", ""], ["Pottie", "Greg", ""]]}, {"id": "2009.04598", "submitter": "Charlene Yang", "authors": "Yunsong Wang, Charlene Yang, Steven Farrell, Yan Zhang, Thorsten\n  Kurth, Samuel Williams", "title": "Time-Based Roofline for Deep Learning Performance Analysis", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning applications are usually very compute-intensive and require a\nlong run time for training and inference. This has been tackled by researchers\nfrom both hardware and software sides, and in this paper, we propose a\nRoofline-based approach to performance analysis to facilitate the optimization\nof these applications. This approach is an extension of the Roofline model\nwidely used in traditional high-performance computing applications, and it\nincorporates both compute/bandwidth complexity and run time in its formulae to\nprovide insights into deep learning-specific characteristics. We take two sets\nof representative kernels, 2D convolution and long short-term memory, to\nvalidate and demonstrate the use of this new approach, and investigate how\narithmetic intensity, cache locality, auto-tuning, kernel launch overhead, and\nTensor Core usage can affect performance. Compared to the common ad-hoc\napproach, this study helps form a more systematic way to analyze code\nperformance and identify optimization opportunities for deep learning\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 23:29:04 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:11:36 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 21:51:45 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Yunsong", ""], ["Yang", "Charlene", ""], ["Farrell", "Steven", ""], ["Zhang", "Yan", ""], ["Kurth", "Thorsten", ""], ["Williams", "Samuel", ""]]}, {"id": "2009.04607", "submitter": "Runzhe Wan", "authors": "Runzhe Wan, Xinyu Zhang, Rui Song", "title": "Multi-Objective Reinforcement Learning for Infectious Disease Control\n  with Application to COVID-19 Spread", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Severe infectious diseases such as the novel coronavirus (COVID-19) pose a\nhuge threat to public health. Stringent control measures, such as school\nclosures and stay-at-home orders, while having significant effects, also bring\nhuge economic losses. A crucial question for policymakers around the world is\nhow to make the trade-off and implement the appropriate interventions. In this\nwork, we propose a Multi-Objective Reinforcement Learning framework to\nfacilitate the data-driven decision making and minimize the long-term overall\ncost. Specifically, at each decision point, a Bayesian epidemiological model is\nfirst learned as the environment model, and then we use the proposed\nmodel-based multi-objective planning algorithm to find a set of Pareto-optimal\npolicies. This framework, combined with the prediction bands for each policy,\nprovides a real-time decision support tool for policymakers. The application is\ndemonstrated with the spread of COVID-19 in China.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 23:55:27 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:34:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wan", "Runzhe", ""], ["Zhang", "Xinyu", ""], ["Song", "Rui", ""]]}, {"id": "2009.04614", "submitter": "Kun Fang", "authors": "Kun Fang, Xiaolin Huang, Fanghui Liu and Jie Yang", "title": "End-to-end Kernel Learning via Generative Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features enable researchers to build feature map to learn the\nspectral distribution of the underlying kernel. Current distribution-based\nmethods follow a two-stage scheme: they first learn and optimize the feature\nmap by solving the kernel alignment problem, then learn a linear classifier on\nthe features. However, since the ideal kernel in kernel alignment problem is\nnot necessarily optimal in classification tasks, the generalization performance\nof the random features learned in this two-stage manner can perhaps be further\nimproved. To address this issue, we propose an end-to-end, one-stage kernel\nlearning approach, called generative random Fourier features, which jointly\nlearns the features and the classifier. A generative network is involved to\nimplicitly learn and to sample from the distribution of the latent kernel.\nRandom features are then built via the generative weights and followed by a\nlinear classifier parameterized as a full-connected layer. We jointly train the\ngenerative network and the classifier by solving the empirical risk\nminimization problem for a one-stage solution. Straightly minimizing the loss\nbetween predictive and true labels brings better generalization performance.\nBesides, this end-to-end strategy allows us to increase the depth of features,\nresulting in multi-layer architecture and exhibiting strong linear-separable\npattern. Empirical results demonstrate the superiority of our method in\nclassification tasks over other two-stage kernel learning methods. Finally, we\ninvestigate the robustness of proposed method in defending adversarial attacks,\nwhich shows that the randomization and resampling mechanism associated with the\nlearned distribution can alleviate the performance decrease brought by\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 00:27:39 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Fang", "Kun", ""], ["Huang", "Xiaolin", ""], ["Liu", "Fanghui", ""], ["Yang", "Jie", ""]]}, {"id": "2009.04631", "submitter": "Oluwaseun Aribido", "authors": "Oluwaseun Joseph Aribido, Ghassan AlRegib and Mohamed Deriche", "title": "Self-Supervised Annotation of Seismic Images using Latent Space\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating seismic data is expensive, laborious and subjective due to the\nnumber of years required for seismic interpreters to attain proficiency in\ninterpretation. In this paper, we develop a framework to automate annotating\npixels of a seismic image to delineate geological structural elements given\nimage-level labels assigned to each image. Our framework factorizes the latent\nspace of a deep encoder-decoder network by projecting the latent space to\nlearned sub-spaces. Using constraints in the pixel space, the seismic image is\nfurther factorized to reveal confidence values on pixels associated with the\ngeological element of interest. Details of the annotated image are provided for\nanalysis and qualitative comparison is made with similar frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 01:54:45 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 02:30:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aribido", "Oluwaseun Joseph", ""], ["AlRegib", "Ghassan", ""], ["Deriche", "Mohamed", ""]]}, {"id": "2009.04647", "submitter": "Mauricio Arango", "authors": "Mauricio Arango, Lyudmil Pelov", "title": "COVID-19 Pandemic Cyclic Lockdown Optimization Using Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the use of reinforcement learning (RL) to optimize cyclic\nlockdowns, which is one of the methods available for control of the COVID-19\npandemic. The problem is structured as an optimal control system for tracking a\nreference value, corresponding to the maximum usage level of a critical\nresource, such as ICU beds. However, instead of using conventional optimal\ncontrol methods, RL is used to find optimal control policies. A framework was\ndeveloped to calculate optimal cyclic lockdown timings using an RL-based on-off\ncontroller. The RL-based controller is implemented as an RL agent that\ninteracts with an epidemic simulator, implemented as an extended SEIR epidemic\nmodel. The RL agent learns a policy function that produces an optimal sequence\nof open/lockdown decisions such that goals specified in the RL reward function\nare optimized. Two concurrent goals were used: the first one is a public health\ngoal that minimizes overshoots of ICU bed usage above an ICU bed threshold, and\nthe second one is a socio-economic goal that minimizes the time spent under\nlockdowns. It is assumed that cyclic lockdowns are considered as a temporary\nalternative to extended lockdowns when a region faces imminent danger of\noverpassing resource capacity limits and when imposing an extended lockdown\nwould cause severe social and economic consequences due to lack of necessary\neconomic resources to support its affected population during an extended\nlockdown.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:51:02 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Arango", "Mauricio", ""], ["Pelov", "Lyudmil", ""]]}, {"id": "2009.04651", "submitter": "Donlapark Ponnoprat", "authors": "Donlapark Ponnoprat", "title": "Universal consistency of Wasserstein $k$-NN classifier", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance provides a notion of dissimilarities between\nprobability measures, which has recent applications in learning of structured\ndata with varying size such as images and text documents. In this work, we\nanalyze the $k$-nearest neighbor classifier ($k$-NN) under the Wasserstein\ndistance and establish the universal consistency on families of distributions.\nUsing previous known results on the consistency of the $k$-NN classifier on\ninfinite dimensional metric spaces, it suffices to show that the families is a\ncountable union of finite dimension sets. As a result, we show that the $k$-NN\nclassifier is universally consistent on spaces of finitely supported measures,\nthe space of Gaussian measures, and the space of measures with finite wavelet\ndensities. In addition, we give a counterexample to show that the universal\nconsistency does not hold on $\\mathcal{W}_p((0,1))$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 03:05:05 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 07:51:21 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 18:39:18 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ponnoprat", "Donlapark", ""]]}, {"id": "2009.04661", "submitter": "Mike Teodorescu", "authors": "Lily Morse, Mike H.M. Teodorescu, Yazeed Awwad, Gerald Kane", "title": "A Framework for Fairer Machine Learning in Organizations", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in adoption of machine learning tools by organizations\nrisks of unfairness abound, especially when human decision processes in\noutcomes of socio-economic importance such as hiring, housing, lending, and\nadmissions are automated. We reveal sources of unfair machine learning, review\nfairness criteria, and provide a framework which, if implemented, would enable\nan organization to both avoid implementing an unfair machine learning model,\nbut also to avoid the common situation that as an algorithm learns with more\ndata it can become unfair over time. Issues of behavioral ethics in machine\nlearning implementations by organizations have not been thoroughly addressed in\nthe literature, because many of the necessary concepts are dispersed across\nthree literatures: ethics, machine learning, and management. Further, tradeoffs\nbetween fairness criteria in machine learning have not been addressed with\nregards to organizations. We advance the research by introducing an organizing\nframework for selecting and implementing fair algorithms in organizations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 04:07:10 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Morse", "Lily", ""], ["Teodorescu", "Mike H. M.", ""], ["Awwad", "Yazeed", ""], ["Kane", "Gerald", ""]]}, {"id": "2009.04674", "submitter": "Hengrui Wang", "authors": "Hengrui Wang, Yubo Zhang, Mingzhi Chen, Tong Yang", "title": "Spectral Clustering with Smooth Tiny Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most prominent clustering approaches. The\ndistance-based similarity is the most widely used method for spectral\nclustering. However, people have already noticed that this is not suitable for\nmulti-scale data, as the distance varies a lot for clusters with different\ndensities. State of the art(ROSC and CAST ) addresses this limitation by taking\nthe reachability similarity of objects into account. However, we observe that\nin real-world scenarios, data in the same cluster tend to present in a smooth\nmanner, and previous algorithms never take this into account. Based on this\nobservation, we propose a novel clustering algorithm, which con-siders the\nsmoothness of data for the first time. We first divide objects into a great\nmany tiny clusters. Our key idea is to cluster tiny clusters, whose centers\nconstitute smooth graphs. Theoretical analysis and experimental results show\nthat our clustering algorithm significantly outperforms state of the art.\nAlthough in this paper, we singly focus on multi-scale situations, the idea of\ndata smoothness can certainly be extended to any clustering algorithms\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 05:21:20 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wang", "Hengrui", ""], ["Zhang", "Yubo", ""], ["Chen", "Mingzhi", ""], ["Yang", "Tong", ""]]}, {"id": "2009.04681", "submitter": "Adora DSouza", "authors": "Axel Wism\\\"uller, Adora M. DSouza and Anas Z. Abidin", "title": "Large-scale nonlinear Granger causality: A data-driven, multivariate\n  approach to recovering directed networks from short time-series data", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To gain insight into complex systems it is a key challenge to infer nonlinear\ncausal directional relations from observational time-series data. Specifically,\nestimating causal relationships between interacting components in large systems\nwith only short recordings over few temporal observations remains an important,\nyet unresolved problem. Here, we introduce a large-scale Nonlinear Granger\nCausality (lsNGC) approach for inferring directional, nonlinear, multivariate\ncausal interactions between system components from short high-dimensional\ntime-series recordings. By modeling interactions with nonlinear state-space\ntransformations from limited observational data, lsNGC identifies casual\nrelations with no explicit a priori assumptions on functional interdependence\nbetween component time-series in a computationally efficient manner.\nAdditionally, our method provides a mathematical formulation revealing\nstatistical significance of inferred causal relations. We extensively study the\nability of lsNGC to recovering network structure from two-node to thirty-four\nnode chaotic time-series systems. Our results suggest that lsNGC captures\nmeaningful interactions from limited observational data, where it performs\nfavorably when compared to traditionally used methods. Finally, we demonstrate\nthe applicability of lsNGC to estimating causality in large, real-world systems\nby inferring directional nonlinear, multivariate causal relationships among a\nlarge number of relatively short time-series acquired from functional Magnetic\nResonance Imaging (fMRI) data of the human brain.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 06:27:57 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wism\u00fcller", "Axel", ""], ["DSouza", "Adora M.", ""], ["Abidin", "Anas Z.", ""]]}, {"id": "2009.04695", "submitter": "Diego Antognini", "authors": "Blagoj Mitrevski, Milena Filipovic, Diego Antognini, Emma Lejal\n  Glaude, Boi Faltings, Claudiu Musat", "title": "Momentum-based Gradient Methods in Multi-objective Recommender Systems", "comments": "Under review. 8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective gradient methods are becoming the standard for solving\nmulti-objective problems. Among others, they show promising results in\ndeveloping multi-objective recommender systems with both correlated and\nuncorrelated objectives. Classic multi-gradient descent usually relies on the\ncombination of the gradients, not including the computation of first and second\nmoments of the gradients. This leads to a brittle behavior and misses important\nareas in the solution space.\n  In this work, we create a multi-objective Adamize method that leverage the\nbenefits of the Adam optimizer in single-objective problems. This corrects and\nstabilizes the gradients of every objective before calculating a common\ngradient descent vector that optimizes all the objectives simultaneously. We\nevaluate the benefits of Multi-objective Adamize on two multi-objective\nrecommender systems and for three different objective combinations, both\ncorrelated or uncorrelated. We report significant improvements, measured with\nthree different Pareto front metrics: hypervolume, coverage, and spacing.\nFinally, we show that the Adamized Pareto front strictly dominates the previous\none on multiple objective pairs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:12:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Mitrevski", "Blagoj", ""], ["Filipovic", "Milena", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.04709", "submitter": "Ricardo Bigolin Lanfredi", "authors": "Ricardo Bigolin Lanfredi, Joyce D. Schroeder, Tolga Tasdizen", "title": "Quantifying the Preferential Direction of the Model Gradient in\n  Adversarial Training With Projected Gradient Descent", "comments": "v3: new counting of Tables and Figures in the SM; fixed typo in eq.\n  of Lemma 1; new evaluation of linearity of models; new evaluation of\n  correlation of alignment metrics and robustness for a fixed training method;\n  new citations to python libraries; changed range of some graphs to simplify\n  the axes' digits; new comment about the difference of input gradient in\n  proposed and baseline metric; editing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, especially projected gradient descent (PGD), has been a\nsuccessful approach for improving robustness against adversarial attacks. After\nadversarial training, gradients of models with respect to their inputs have a\npreferential direction. However, the direction of alignment is not\nmathematically well established, making it difficult to evaluate\nquantitatively. We propose a novel definition of this direction as the\ndirection of the vector pointing toward the closest point of the support of the\nclosest inaccurate class in decision space. To evaluate the alignment with this\ndirection after adversarial training, we apply a metric that uses generative\nadversarial networks to produce the smallest residual needed to change the\nclass present in the image. We show that PGD-trained models have a higher\nalignment than the baseline according to our definition, that our metric\npresents higher alignment values than a competing metric formulation, and that\nenforcing this alignment increases the robustness of models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:48:42 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 07:58:22 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 23:49:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lanfredi", "Ricardo Bigolin", ""], ["Schroeder", "Joyce D.", ""], ["Tasdizen", "Tolga", ""]]}, {"id": "2009.04719", "submitter": "Fatme Hachem", "authors": "Maria Luisa Damiani, Andrea Acquaviva, Fatima Hachem, Matteo Rossini", "title": "Learning Behavioral Representations of Human Mobility", "comments": "ACM SIGSPATIAL 2020: 28th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems.November 2020 Seattle, Washington,\n  USA", "journal-ref": null, "doi": "10.1145/3397536.3422255", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the suitability of state-of-the-art\nrepresentation learning methods to the analysis of behavioral similarity of\nmoving individuals, based on CDR trajectories. The core of the contribution is\na novel methodological framework, mob2vec, centered on the combined use of a\nrecent symbolic trajectory segmentation method for the removal of noise, a\nnovel trajectory generalization method incorporating behavioral information,\nand an unsupervised technique for the learning of vector representations from\nsequential data. Mob2vec is the result of an empirical study conducted on real\nCDR data through an extensive experimentation. As a result, it is shown that\nmob2vec generates vector representations of CDR trajectories in low dimensional\nspaces which preserve the similarity of the mobility behavior of individuals.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:15:16 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 10:32:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Damiani", "Maria Luisa", ""], ["Acquaviva", "Andrea", ""], ["Hachem", "Fatima", ""], ["Rossini", "Matteo", ""]]}, {"id": "2009.04722", "submitter": "Qingbo Yin", "authors": "Liran Shen, Meng Joo Er, Qingbo Yin", "title": "Population structure-learned classifier for high-dimension\n  low-sample-size class-imbalanced problem", "comments": "41 pages,10 Figures,10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Classification on high-dimension low-sample-size data (HDLSS) is a\nchallenging problem and it is common to have class-imbalanced data in most\napplication fields. We term this as Imbalanced HDLSS (IHDLSS). Recent\ntheoretical results reveal that the classification criterion and tolerance\nsimilarity are crucial to HDLSS, which emphasizes the maximization of\nwithin-class variance on the premise of class separability. Based on this idea,\na novel linear binary classifier, termed Population Structure-learned\nClassifier (PSC), is proposed. The proposed PSC can obtain better\ngeneralization performance on IHDLSS by maximizing the sum of inter-class\nscatter matrix and intra-class scatter matrix on the premise of class\nseparability and assigning different intercept values to majority and minority\nclasses. The salient features of the proposed approach are: (1) It works well\non IHDLSS; (2) The inverse of high dimensional matrix can be solved in low\ndimensional space; (3) It is self-adaptive in determining the intercept term\nfor each class; (4) It has the same computational complexity as the SVM. A\nseries of evaluations are conducted on one simulated data set and eight\nreal-world benchmark data sets on IHDLSS on gene analysis. Experimental results\ndemonstrate that the PSC is superior to the state-of-art methods in IHDLSS.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:33:39 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Shen", "Liran", ""], ["Er", "Meng Joo", ""], ["Yin", "Qingbo", ""]]}, {"id": "2009.04746", "submitter": "Soha Sadat Mahdi", "authors": "Soha Sadat Mahdi (1), Nele Nauwelaers (1), Philip Joris (1), Giorgos\n  Bouritsas (2), Shunwang Gong (2), Sergiy Bokhnyak (3), Susan Walsh (4), Mark\n  D. Shriver (5), Michael Bronstein (2,3,6), Peter Claes (1,7). ((1) KU Leuven,\n  ESAT/PSI - UZ Leuven, MIRC, (2) Imperial College London, Department of\n  Computing, (3) USI Lugano, Institute of Computational Science, (4) Indiana\n  University-Purdue University-Indianapolis, Department of Biology, (5) Penn\n  State University, Department of Anthropology, (6) Twitter, (7) KU Leuven,\n  Department of Human Genetics)", "title": "3D Facial Matching by Spiral Convolutional Metric Learning and a\n  Biometric Fusion-Net of Demographic Properties", "comments": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020). Mahdi and Nauwelaers contributed equally and are ordered\n  alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition is a widely accepted biometric verification tool, as the\nface contains a lot of information about the identity of a person. In this\nstudy, a 2-step neural-based pipeline is presented for matching 3D facial shape\nto multiple DNA-related properties (sex, age, BMI and genomic background). The\nfirst step consists of a triplet loss-based metric learner that compresses\nfacial shape into a lower dimensional embedding while preserving information\nabout the property of interest. Most studies in the field of metric learning\nhave only focused on 2D Euclidean data. In this work, geometric deep learning\nis employed to learn directly from 3D facial meshes. To this end, spiral\nconvolutions are used along with a novel mesh-sampling scheme that retains\nuniformly sampled 3D points at different levels of resolution. The second step\nis a multi-biometric fusion by a fully connected neural network. The network\ntakes an ensemble of embeddings and property labels as input and returns\ngenuine and imposter scores. Since embeddings are accepted as an input, there\nis no need to train classifiers for the different properties and available data\ncan be used more efficiently. Results obtained by a 10-fold cross-validation\nfor biometric verification show that combining multiple properties leads to\nstronger biometric systems. Furthermore, the proposed neural-based pipeline\noutperforms a linear baseline, which consists of principal component analysis,\nfollowed by classification with linear support vector machines and a Naive\nBayes-based score-fuser.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:31:47 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:44:31 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mahdi", "Soha Sadat", ""], ["Nauwelaers", "Nele", ""], ["Joris", "Philip", ""], ["Bouritsas", "Giorgos", ""], ["Gong", "Shunwang", ""], ["Bokhnyak", "Sergiy", ""], ["Walsh", "Susan", ""], ["Shriver", "Mark D.", ""], ["Bronstein", "Michael", ""], ["Claes", "Peter", ""], [".", "", ""]]}, {"id": "2009.04756", "submitter": "Daniel Jung", "authors": "Andreas Lundgren and Daniel Jung", "title": "Data-Driven Open Set Fault Classification and Fault Size Estimation\n  Using Quantitative Fault Diagnosis Analysis", "comments": "Preprint, 10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven fault classification is complicated by imbalanced training data\nand unknown fault classes. Fault diagnosis of dynamic systems is done by\ndetecting changes in time-series data, for example residuals, caused by faults\nor system degradation. Different fault classes can result in similar residual\noutputs, especially for small faults which can be difficult to distinguish from\nnominal system operation. Analyzing how easy it is to distinguish data from\ndifferent fault classes is crucial during the design process of a diagnosis\nsystem to evaluate if classification performance requirements can be met. Here,\na data-driven model of different fault classes is used based on the\nKullback-Leibler divergence. This is used to develop a framework for\nquantitative fault diagnosis performance analysis and open set fault\nclassification. A data-driven fault classification algorithm is proposed which\ncan handle unknown faults and also estimate the fault size using training data\nfrom known fault scenarios. To illustrate the usefulness of the proposed\nmethods, data have been collected from an engine test bench to illustrate the\ndesign process of a data-driven diagnosis system, including quantitative fault\ndiagnosis analysis and evaluation of the developed open set fault\nclassification algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:53:13 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Lundgren", "Andreas", ""], ["Jung", "Daniel", ""]]}, {"id": "2009.04765", "submitter": "Damian Pascual", "authors": "Nicolas Affolter, Beni Egressy, Damian Pascual, Roger Wattenhofer", "title": "Brain2Word: Decoding Brain Activity for Language Generation", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain decoding, understood as the process of mapping brain activities to the\nstimuli that generated them, has been an active research area in the last\nyears. In the case of language stimuli, recent studies have shown that it is\npossible to decode fMRI scans into an embedding of the word a subject is\nreading. However, such word embeddings are designed for natural language\nprocessing tasks rather than for brain decoding. Therefore, they limit our\nability to recover the precise stimulus. In this work, we propose to directly\nclassify an fMRI scan, mapping it to the corresponding word within a fixed\nvocabulary. Unlike existing work, we evaluate on scans from previously unseen\nsubjects. We argue that this is a more realistic setup and we present a model\nthat can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1\nand 13.59% Top-5 accuracy in this challenging task, significantly outperforming\nall the considered competitive baselines. Furthermore, we use the decoded words\nto guide language generation with the GPT-2 model. This way, we advance the\nquest for a system that translates brain activities into coherent text.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 10:47:36 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 08:05:08 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 08:07:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Affolter", "Nicolas", ""], ["Egressy", "Beni", ""], ["Pascual", "Damian", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2009.04777", "submitter": "Pawe{\\l} Wawrzy\\'nski", "authors": "Marcin Szulc, Jakub {\\L}yskawa, Pawe{\\l} Wawrzy\\'nski", "title": "A framework for reinforcement learning with autocorrelated actions", "comments": "The 27th International Conference on Neural Information Processing\n  (ICONIP2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject of this paper is reinforcement learning. Policies are considered\nhere that produce actions based on states and random elements autocorrelated in\nsubsequent time instants. Consequently, an agent learns from experiments that\nare distributed over time and potentially give better clues to policy\nimprovement. Also, physical implementation of such policies, e.g. in robotics,\nis less problematic, as it avoids making robots shake. This is in opposition to\nmost RL algorithms which add white noise to control causing unwanted shaking of\nthe robots. An algorithm is introduced here that approximately optimizes the\naforementioned policy. Its efficiency is verified for four simulated learning\ncontrol problems (Ant, HalfCheetah, Hopper, and Walker2D) against three other\nmethods (PPO, SAC, ACER). The algorithm outperforms others in three of these\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:23:09 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Szulc", "Marcin", ""], ["\u0141yskawa", "Jakub", ""], ["Wawrzy\u0144ski", "Pawe\u0142", ""]]}, {"id": "2009.04796", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, Tao Lin, V\\'eronique Masson, \\'Elisa Fromont, Alexandre\n  Termier", "title": "XCM: An Explainable Convolutional Neural Network for Multivariate Time\n  Series Classification", "comments": "Another machine learning method for multivariate time series\n  classification providing faithful explanations is presented in\n  arXiv:2005.03645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present XCM, an eXplainable Convolutional neural network for Multivariate\ntime series classification. XCM is a new compact convolutional neural network\nwhich extracts information relative to the observed variables and time directly\nfrom the input data. Thus, XCM architecture enables a good generalization\nability on both small and large datasets, while allowing the full exploitation\nof a faithful post-hoc model-specific explainability method (Gradient-weighted\nClass Activation Mapping) by precisely identifying the observed variables and\ntimestamps of the input data that are important for predictions. Our evaluation\nfirstly shows that XCM outperforms the state-of-the-art multivariate time\nseries classifiers on both the large and small public UEA datasets.\nFurthermore, following the illustration of the performance and explainability\nof XCM on a synthetic dataset, we present how XCM can outperform the current\nmost accurate state-of-the-art algorithm on a real-world application while\nenhancing explainability by providing faithful and more informative\nexplanations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:55:53 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 10:10:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Fauvel", "Kevin", ""], ["Lin", "Tao", ""], ["Masson", "V\u00e9ronique", ""], ["Fromont", "\u00c9lisa", ""], ["Termier", "Alexandre", ""]]}, {"id": "2009.04806", "submitter": "Alexander Wang", "authors": "Alexander Wang, Mengye Ren, Richard S. Zemel", "title": "SketchEmbedNet: Learning Novel Concepts by Imitating Drawings", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketch drawings capture the salient information of visual concepts. Previous\nwork has shown that neural networks are capable of producing sketches of\nnatural objects drawn from a small number of classes. While earlier approaches\nfocus on generation quality or retrieval, we explore properties of image\nrepresentations learned by training a model to produce sketches of images. We\nshow that this generative, class-agnostic model produces informative embeddings\nof images from novel examples, classes, and even novel datasets in a few-shot\nsetting. Additionally, we find that these learned representations exhibit\ninteresting structure and compositionality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:43:28 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 17:15:39 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 18:51:51 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 19:45:09 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Wang", "Alexander", ""], ["Ren", "Mengye", ""], ["Zemel", "Richard S.", ""]]}, {"id": "2009.04822", "submitter": "Daniele Gammelli", "authors": "Daniele Gammelli, Kasper Pryds Rolsted, Dario Pacino, Filipe Rodrigues", "title": "Generalized Multi-Output Gaussian Process Censored Regression", "comments": "7 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When modelling censored observations, a typical approach in current\nregression methods is to use a censored-Gaussian (i.e. Tobit) model to describe\nthe conditional output distribution. In this paper, as in the case of missing\ndata, we argue that exploiting correlations between multiple outputs can enable\nmodels to better address the bias introduced by censored data. To do so, we\nintroduce a heteroscedastic multi-output Gaussian process model which combines\nthe non-parametric flexibility of GPs with the ability to leverage information\nfrom correlated outputs under input-dependent noise conditions. To address the\nresulting inference intractability, we further devise a variational bound to\nthe marginal log-likelihood suitable for stochastic optimization. We\nempirically evaluate our model against other generative models for censored\ndata on both synthetic and real world tasks and further show how it can be\ngeneralized to deal with arbitrary likelihood functions. Results show how the\nadded flexibility allows our model to better estimate the underlying\nnon-censored (i.e. true) process under potentially complex censoring dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:46:29 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Gammelli", "Daniele", ""], ["Rolsted", "Kasper Pryds", ""], ["Pacino", "Dario", ""], ["Rodrigues", "Filipe", ""]]}, {"id": "2009.04825", "submitter": "Kamal Berahmand", "authors": "Saman Forouzandeh, Mehrdad Rostami, Kamal Berahmand", "title": "Presentation a Trust Walker for rating prediction in Recommender System\n  with Biased Random Walk: Effects of H-index Centrality, Similarity in Items\n  and Friends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of recommender systems has increased dramatically to assist online\nsocial network users in the decision-making process and selecting appropriate\nitems. On the other hand, due to many different items, users cannot score a\nwide range of them, and usually, there is a scattering problem for the matrix\ncreated for users. To solve the problem, the trust-based recommender systems\nare applied to predict the score of the desired item for the user. Various\ncriteria have been considered to define trust, and the degree of trust between\nusers is usually calculated based on these criteria. In this regard, it is\nimpossible to obtain the degree of trust for all users because of the large\nnumber of them in social networks. Also, for this problem, researchers use\ndifferent modes of the Random Walk algorithm to randomly visit some users,\nstudy their behavior, and gain the degree of trust between them. In the present\nstudy, a trust-based recommender system is presented that predicts the score of\nitems that the target user has not rated, and if the item is not found, it\noffers the user the items dependent on that item that are also part of the\nuser's interests. In a trusted network, by weighting the edges between the\nnodes, the degree of trust is determined, and a TrustWalker is developed, which\nuses the Biased Random Walk (BRW) algorithm to move between the nodes. The\nweight of the edges is effective in the selection of random steps. The\nimplementation and evaluation of the present research method have been carried\nout on three datasets named Epinions, Flixster, and FilmTrust; the results\nreveal the high efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:52:57 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Forouzandeh", "Saman", ""], ["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""]]}, {"id": "2009.04861", "submitter": "Ole-Christoffer Granmo", "authors": "K. Darshana Abeyrathna, Bimal Bhattarai, Morten Goodwin, Saeed Gorji,\n  Ole-Christoffer Granmo, Lei Jiao, Rupsa Saha, Rohan K. Yadav", "title": "Massively Parallel and Asynchronous Tsetlin Machine Architecture\n  Supporting Almost Constant-Time Scaling", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using logical clauses to represent patterns, Tsetlin Machines (TMs) have\nrecently obtained competitive performance in terms of accuracy, memory\nfootprint, energy, and learning speed on several benchmarks. Each TM clause\nvotes for or against a particular class, with classification resolved using a\nmajority vote. While the evaluation of clauses is fast, being based on binary\noperators, the voting makes it necessary to synchronize the clause evaluation,\nimpeding parallelization. In this paper, we propose a novel scheme for\ndesynchronizing the evaluation of clauses, eliminating the voting bottleneck.\nIn brief, every clause runs in its own thread for massive native parallelism.\nFor each training example, we keep track of the class votes obtained from the\nclauses in local voting tallies. The local voting tallies allow us to detach\nthe processing of each clause from the rest of the clauses, supporting\ndecentralized learning. This means that the TM most of the time will operate on\noutdated voting tallies. We evaluated the proposed parallelization across\ndiverse learning tasks and it turns out that our decentralized TM learning\nalgorithm copes well with working on outdated data, resulting in no significant\nloss in learning accuracy. Furthermore, we show that the proposed approach\nprovides up to 50 times faster learning. Finally, learning time is almost\nconstant for reasonable clause amounts (employing from 20 to 7,000 clauses on a\nTesla V100 GPU). For sufficiently large clause numbers, computation time\nincreases approximately proportionally. Our parallel and asynchronous\narchitecture thus allows processing of massive datasets and operating with more\nclauses for higher accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:48:33 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 18:24:26 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 18:53:48 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 15:17:34 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Bhattarai", "Bimal", ""], ["Goodwin", "Morten", ""], ["Gorji", "Saeed", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""], ["Saha", "Rupsa", ""], ["Yadav", "Rohan K.", ""]]}, {"id": "2009.04872", "submitter": "Yang Zou", "authors": "Yang Zou, Zhikun Zhang, Michael Backes, Yang Zhang", "title": "Privacy Analysis of Deep Learning in the Wild: Membership Inference\n  Attacks against Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While being deployed in many critical applications as core components,\nmachine learning (ML) models are vulnerable to various security and privacy\nattacks. One major privacy attack in this domain is membership inference, where\nan adversary aims to determine whether a target data sample is part of the\ntraining set of a target ML model. So far, most of the current membership\ninference attacks are evaluated against ML models trained from scratch.\nHowever, real-world ML models are typically trained following the transfer\nlearning paradigm, where a model owner takes a pretrained model learned from a\ndifferent dataset, namely teacher model, and trains her own student model by\nfine-tuning the teacher model with her own data.\n  In this paper, we perform the first systematic evaluation of membership\ninference attacks against transfer learning models. We adopt the strategy of\nshadow model training to derive the data for training our membership inference\nclassifier. Extensive experiments on four real-world image datasets show that\nmembership inference can achieve effective performance. For instance, on the\nCIFAR100 classifier transferred from ResNet20 (pretrained with Caltech101), our\nmembership inference achieves $95\\%$ attack AUC. Moreover, we show that\nmembership inference is still effective when the architecture of target model\nis unknown. Our results shed light on the severity of membership risks stemming\nfrom machine learning models in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:14:22 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Zou", "Yang", ""], ["Zhang", "Zhikun", ""], ["Backes", "Michael", ""], ["Zhang", "Yang", ""]]}, {"id": "2009.04875", "submitter": "Alexandre Galashov", "authors": "Alexandre Galashov, Jakub Sygnowski, Guillaume Desjardins, Jan\n  Humplik, Leonard Hasenclever, Rae Jeong, Yee Whye Teh, Nicolas Heess", "title": "Importance Weighted Policy Learning and Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to exploit prior experience to solve novel problems rapidly is a\nhallmark of biological learning systems and of great practical importance for\nartificial ones. In the meta reinforcement learning literature much recent work\nhas focused on the problem of optimizing the learning process itself. In this\npaper we study a complementary approach which is conceptually simple, general,\nmodular and built on top of recent improvements in off-policy learning. The\nframework is inspired by ideas from the probabilistic inference literature and\ncombines robust off-policy learning with a behavior prior, or default behavior\nthat constrains the space of solutions and serves as a bias for exploration; as\nwell as a representation for the value function, both of which are easily\nlearned from a number of training tasks in a multi-task scenario. Our approach\nachieves competitive adaptation performance on hold-out tasks compared to meta\nreinforcement learning baselines and can scale to complex sparse-reward\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:16:58 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 13:21:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Galashov", "Alexandre", ""], ["Sygnowski", "Jakub", ""], ["Desjardins", "Guillaume", ""], ["Humplik", "Jan", ""], ["Hasenclever", "Leonard", ""], ["Jeong", "Rae", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.04877", "submitter": "Hung Tuan Nguyen Dr.", "authors": "Hung Tuan Nguyen, Cuong Tuan Nguyen, Takeya Ino, Bipin Indurkhya,\n  Masaki Nakagawa", "title": "Text-independent writer identification using convolutional neural\n  network", "comments": "12 pages", "journal-ref": "Pattern Recognition Letters, Volume 121, 2019, Pages 104-112", "doi": "10.1016/j.patrec.2018.07.022", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The text-independent approach to writer identification does not require the\nwriter to write some predetermined text. Previous research on text-independent\nwriter identification has been based on identifying writer-specific features\ndesigned by experts. However, in the last decade, deep learning methods have\nbeen successfully applied to learn features from data automatically. We propose\nhere an end-to-end deep-learning method for text-independent writer\nidentification that does not require prior identification of features. A\nConvolutional Neural Network (CNN) is trained initially to extract local\nfeatures, which represent characteristics of individual handwriting in the\nwhole character images and their sub-regions. Randomly sampled tuples of images\nfrom the training set are used to train the CNN and aggregate the extracted\nlocal features of images from the tuples to form global features. For every\ntraining epoch, the process of randomly sampling tuples is repeated, which is\nequivalent to a large number of training patterns being prepared for training\nthe CNN for text-independent writer identification. We conducted experiments on\nthe JEITA-HP database of offline handwritten Japanese character patterns. With\n200 characters, our method achieved an accuracy of 99.97% to classify 100\nwriters. Even when using 50 characters for 100 writers or 100 characters for\n400 writers, our method achieved accuracy levels of 92.80% or 93.82%,\nrespectively. We conducted further experiments on the Firemaker and IAM\ndatabases of offline handwritten English text. Using only one page per writer\nto train, our method achieved over 91.81% accuracy to classify 900 writers.\nOverall, we achieved a better performance than the previously published best\nresult based on handcrafted features and clustering algorithms, which\ndemonstrates the effectiveness of our method for handwritten English text also.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:18:03 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Nguyen", "Hung Tuan", ""], ["Nguyen", "Cuong Tuan", ""], ["Ino", "Takeya", ""], ["Indurkhya", "Bipin", ""], ["Nakagawa", "Masaki", ""]]}, {"id": "2009.04891", "submitter": "Nithin Holla", "authors": "Nithin Holla, Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova", "title": "Meta-Learning with Sparse Experience Replay for Lifelong Language\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning requires models that can continuously learn from sequential\nstreams of data without suffering catastrophic forgetting due to shifts in data\ndistributions. Deep learning models have thrived in the non-sequential learning\nparadigm; however, when used to learn a sequence of tasks, they fail to retain\npast knowledge and learn incrementally. We propose a novel approach to lifelong\nlearning of language tasks based on meta-learning with sparse experience replay\nthat directly optimizes to prevent forgetting. We show that under the realistic\nsetting of performing a single pass on a stream of tasks and without any task\nidentifiers, our method obtains state-of-the-art results on lifelong text\nclassification and relation extraction. We analyze the effectiveness of our\napproach and further demonstrate its low computational and space complexity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:36:38 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 16:07:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Holla", "Nithin", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2009.04893", "submitter": "Lisa Schneider", "authors": "Lisa Schneider, Annika Niemann, Oliver Beuing, Bernhard Preim and\n  Sylvia Saalfeld", "title": "MedMeshCNN -- Enabling MeshCNN for Medical Surface Models", "comments": "7 pages, 7 figures, 1 table, Submitted to Computer Methods and\n  Programs in Biomedicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and objective: MeshCNN is a recently proposed Deep Learning\nframework that drew attention due to its direct operation on irregular,\nnon-uniform 3D meshes. On selected benchmarking datasets, it outperformed\nstate-of-the-art methods within classification and segmentation tasks.\nEspecially, the medical domain provides a large amount of complex 3D surface\nmodels that may benefit from processing with MeshCNN. However, several\nlimitations prevent outstanding performances of MeshCNN on highly diverse\nmedical surface models. Within this work, we propose MedMeshCNN as an expansion\nfor complex, diverse, and fine-grained medical data. Methods: MedMeshCNN\nfollows the functionality of MeshCNN with a significantly increased memory\nefficiency that allows retaining patient-specific properties during the\nsegmentation process. Furthermore, it enables the segmentation of pathological\nstructures that often come with highly imbalanced class distributions. Results:\nWe tested the performance of MedMeshCNN on a complex part segmentation task of\nintracranial aneurysms and their surrounding vessel structures and reached a\nmean Intersection over Union of 63.24\\%. The pathological aneurysm is segmented\nwith an Intersection over Union of 71.4\\%. Conclusions: These results\ndemonstrate that MedMeshCNN enables the application of MeshCNN on complex,\nfine-grained medical surface meshes. The imbalanced class distribution deriving\nfrom the pathological finding is considered by MedMeshCNN and patient-specific\nproperties are mostly retained during the segmentation process.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:40:28 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Schneider", "Lisa", ""], ["Niemann", "Annika", ""], ["Beuing", "Oliver", ""], ["Preim", "Bernhard", ""], ["Saalfeld", "Sylvia", ""]]}, {"id": "2009.04899", "submitter": "Jingyuan Xia", "authors": "Jingyuan Xia, Jun-Jie Huang, and Imad Jaimoukha", "title": "Meta-learning for Multi-variable Non-convex Optimization Problems:\n  Iterating Non-optimums Makes Optimum Possible", "comments": "15 pages, 8 figures, update content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to address the problem of solving a non-convex\noptimization problem over an intersection of multiple variable sets. This kind\nof problems is typically solved by using an alternating minimization (AM)\nstrategy which splits the overall problem into a set of sub-problems\ncorresponding to each variable, and then iteratively performs minimization over\neach sub-problem using a fixed updating rule. However, due to the intrinsic\nnon-convexity of the overall problem, the optimization can usually be trapped\ninto bad local minimum even when each sub-problem can be globally optimized at\neach iteration. To tackle this problem, we propose a meta-learning based Global\nScope Optimization (GSO) method. It adaptively generates optimizers for\nsub-problems via meta-learners and constantly updates these meta-learners with\nrespect to the global loss information of the overall problem. Therefore, the\nsub-problems are optimized with the objective of minimizing the global loss\nspecifically. We evaluate the proposed model on a number of simulations,\nincluding solving bi-linear inverse problems: matrix completion, and non-linear\nproblems: Gaussian mixture models. The experimental results show that our\nproposed approach outperforms AM-based methods in standard settings, and is\nable to achieve effective optimization in some challenging cases while other\nmethods would typically fail.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:45:00 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 11:55:47 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 16:37:35 GMT"}, {"version": "v4", "created": "Fri, 25 Jun 2021 02:54:45 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Xia", "Jingyuan", ""], ["Huang", "Jun-Jie", ""], ["Jaimoukha", "Imad", ""]]}, {"id": "2009.04923", "submitter": "Theodoros Tsiligkaridis", "authors": "Theodoros Tsiligkaridis, Jay Roberts", "title": "Second Order Optimization for Adversarial Robustness and\n  Interpretability", "comments": "7 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are easily fooled by small perturbations known as\nadversarial attacks. Adversarial Training (AT) is a technique aimed at learning\nfeatures robust to such attacks and is widely regarded as a very effective\ndefense. However, the computational cost of such training can be prohibitive as\nthe network size and input dimensions grow. Inspired by the relationship\nbetween robustness and curvature, we propose a novel regularizer which\nincorporates first and second order information via a quadratic approximation\nto the adversarial loss. The worst case quadratic loss is approximated via an\niterative scheme. It is shown that using only a single iteration in our\nregularizer achieves stronger robustness than prior gradient and curvature\nregularization schemes, avoids gradient obfuscation, and, with additional\niterations, achieves strong robustness with significantly lower training time\nthan AT. Further, it retains the interesting facet of AT that networks learn\nfeatures which are well-aligned with human perception. We demonstrate\nexperimentally that our method produces higher quality human-interpretable\nfeatures than other geometric regularization techniques. These robust features\nare then used to provide human-friendly explanations to model predictions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:05:14 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Tsiligkaridis", "Theodoros", ""], ["Roberts", "Jay", ""]]}, {"id": "2009.04925", "submitter": "Amro Alabsi Aljundi", "authors": "Taha Atahan Akyildiz, Amro Alabsi Aljundi, Kamer Kaya", "title": "Understanding Coarsening for Embedding Large-Scale Graphs", "comments": "10 pages, 6 figures, submitted to 2020 IEEE International Conference\n  on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant portion of the data today, e.g, social networks, web\nconnections, etc., can be modeled by graphs. A proper analysis of graphs with\nMachine Learning (ML) algorithms has the potential to yield far-reaching\ninsights into many areas of research and industry. However, the irregular\nstructure of graph data constitutes an obstacle for running ML tasks on graphs\nsuch as link prediction, node classification, and anomaly detection. Graph\nembedding is a compute-intensive process of representing graphs as a set of\nvectors in a d-dimensional space, which in turn makes it amenable to ML tasks.\nMany approaches have been proposed in the literature to improve the performance\nof graph embedding, e.g., using distributed algorithms, accelerators, and\npre-processing techniques. Graph coarsening, which can be considered a\npre-processing step, is a structural approximation of a given, large graph with\na smaller one. As the literature suggests, the cost of embedding significantly\ndecreases when coarsening is employed. In this work, we thoroughly analyze the\nimpact of the coarsening quality on the embedding performance both in terms of\nspeed and accuracy. Our experiments with a state-of-the-art, fast graph\nembedding tool show that there is an interplay between the coarsening decisions\ntaken and the embedding quality.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:06:33 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Akyildiz", "Taha Atahan", ""], ["Aljundi", "Amro Alabsi", ""], ["Kaya", "Kamer", ""]]}, {"id": "2009.04950", "submitter": "Bingjia Wang", "authors": "Bingjia Wang, Alec Koppel and Vikram Krishnamurthy", "title": "A Markov Decision Process Approach to Active Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning, we fit a single statistical model to a given data\nset, assuming that the data is associated with a singular task, which yields\nwell-tuned models for specific use, but does not adapt well to new contexts. By\ncontrast, in meta-learning, the data is associated with numerous tasks, and we\nseek a model that may perform well on all tasks simultaneously, in pursuit of\ngreater generalization. One challenge in meta-learning is how to exploit\nrelationships between tasks and classes, which is overlooked by commonly used\nrandom or cyclic passes through data. In this work, we propose actively\nselecting samples on which to train by discerning covariates inside and between\nmeta-training sets. Specifically, we cast the problem of selecting a sample\nfrom a number of meta-training sets as either a multi-armed bandit or a Markov\nDecision Process (MDP), depending on how one encapsulates correlation across\ntasks. We develop scheduling schemes based on Upper Confidence Bound (UCB),\nGittins Index and tabular Markov Decision Problems (MDPs) solved with linear\nprogramming, where the reward is the scaled statistical accuracy to ensure it\nis a time-invariant function of state and action. Across a variety of\nexperimental contexts, we observe significant reductions in sample complexity\nof active selection scheme relative to cyclic or i.i.d. sampling, demonstrating\nthe merit of exploiting covariates in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:45:34 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wang", "Bingjia", ""], ["Koppel", "Alec", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "2009.04965", "submitter": "Meng-Jiun Chiou", "authors": "Meng-Jiun Chiou, Roger Zimmermann, Jiashi Feng", "title": "Visual Relationship Detection with Visual-Linguistic Knowledge from\n  Multimodal Representations", "comments": "Published in IEEE Access", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3069041", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual relationship detection aims to reason over relationships among salient\nobjects in images, which has drawn increasing attention over the past few\nyears. Inspired by human reasoning mechanisms, it is believed that external\nvisual commonsense knowledge is beneficial for reasoning visual relationships\nof objects in images, which is however rarely considered in existing methods.\nIn this paper, we propose a novel approach named Relational Visual-Linguistic\nBidirectional Encoder Representations from Transformers (RVL-BERT), which\nperforms relational reasoning with both visual and language commonsense\nknowledge learned via self-supervised pre-training with multimodal\nrepresentations. RVL-BERT also uses an effective spatial module and a novel\nmask attention module to explicitly capture spatial information among the\nobjects. Moreover, our model decouples object detection from visual\nrelationship recognition by taking in object names directly, enabling it to be\nused on top of any object detection system. We show through quantitative and\nqualitative experiments that, with the transferred knowledge and novel modules,\nRVL-BERT achieves competitive results on two challenging visual relationship\ndetection datasets. The source code is available at\nhttps://github.com/coldmanck/RVL-BERT.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:15:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:01:49 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 07:48:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chiou", "Meng-Jiun", ""], ["Zimmermann", "Roger", ""], ["Feng", "Jiashi", ""]]}, {"id": "2009.04968", "submitter": "Dimas Munoz", "authors": "Dimas Munoz Montesinos", "title": "Modern Methods for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synthetic text generation is challenging and has limited success. Recently, a\nnew architecture, called Transformers, allow machine learning models to\nunderstand better sequential data, such as translation or summarization. BERT\nand GPT-2, using Transformers in their cores, have shown a great performance in\ntasks such as text classification, translation and NLI tasks. In this article,\nwe analyse both algorithms and compare their output quality in text generation\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:17:10 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Montesinos", "Dimas Munoz", ""]]}, {"id": "2009.04979", "submitter": "Alan Kuhnle", "authors": "Alan Kuhnle", "title": "Quick Streaming Algorithms for Maximization of Monotone Submodular\n  Functions in Linear Time", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of monotone, submodular maximization over a ground\nset of size $n$ subject to cardinality constraint $k$. For this problem, we\nintroduce the first deterministic algorithms with linear time complexity; these\nalgorithms are streaming algorithms. Our single-pass algorithm obtains a\nconstant ratio in $\\lceil n / c \\rceil + c$ oracle queries, for any $c \\ge 1$.\nIn addition, we propose a deterministic, multi-pass streaming algorithm with a\nconstant number of passes that achieves nearly the optimal ratio with linear\nquery and time complexities. We prove a lower bound that implies no\nconstant-factor approximation exists using $o(n)$ queries, even if queries to\ninfeasible sets are allowed. An empirical analysis demonstrates that our\nalgorithms require fewer queries (often substantially less than $n$) yet still\nachieve better objective value than the current state-of-the-art algorithms,\nincluding single-pass, multi-pass, and non-streaming algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:35:54 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:50:49 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 17:49:18 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kuhnle", "Alan", ""]]}, {"id": "2009.04984", "submitter": "Junlong Li", "authors": "Junlong Li, Zhuosheng Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Task-specific Objectives of Pre-trained Language Models for Dialogue\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Language Models (PrLMs) have been widely used as backbones in\nlots of Natural Language Processing (NLP) tasks. The common process of\nutilizing PrLMs is first pre-training on large-scale general corpora with\ntask-independent LM training objectives, then fine-tuning on task datasets with\ntask-specific training objectives. Pre-training in a task-independent way\nenables the models to learn language representations, which is universal to\nsome extent, but fails to capture crucial task-specific features in the\nmeantime. This will lead to an incompatibility between pre-training and\nfine-tuning. To address this issue, we introduce task-specific pre-training on\nin-domain task-related corpora with task-specific objectives. This procedure is\nplaced between the original two stages to enhance the model understanding\ncapacity of specific tasks. In this work, we focus on Dialogue-related Natural\nLanguage Processing (DrNLP) tasks and design a Dialogue-Adaptive Pre-training\nObjective (DAPO) based on some important qualities for assessing dialogues\nwhich are usually ignored by general LM pre-training objectives. PrLMs with\nDAPO on a large in-domain dialogue corpus are then fine-tuned for downstream\nDrNLP tasks. Experimental results show that models with DAPO surpass those with\ngeneral LM pre-training objectives and other strong baselines on downstream\nDrNLP tasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:46:46 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Li", "Junlong", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.04985", "submitter": "Julian Alberto Palladino", "authors": "Julian Alberto Palladino, Diego Fernandez Slezak and Enzo Ferrante", "title": "Unsupervised Domain Adaptation via CycleGAN for White Matter\n  Hyperintensity Segmentation in Multicenter MR Images", "comments": "Accepted for publication in the International Seminar on Medical\n  Information Processing and Analysis (SIPAIM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation of white matter hyperintensities in magnetic resonance\nimages is of paramount clinical and research importance. Quantification of\nthese lesions serve as a predictor for risk of stroke, dementia and mortality.\nDuring the last years, convolutional neural networks (CNN) specifically\ntailored for biomedical image segmentation have outperformed all previous\ntechniques in this task. However, they are extremely data-dependent, and\nmaintain a good performance only when data distribution between training and\ntest datasets remains unchanged. When such distribution changes but we still\naim at performing the same task, we incur in a domain adaptation problem (e.g.\nusing a different MR machine or different acquisition parameters for training\nand test data). In this work, we explore the use of cycle-consistent\nadversarial networks (CycleGAN) to perform unsupervised domain adaptation on\nmulticenter MR images with brain lesions. We aim at learning a mapping function\nto transform volumetric MR images between domains, which are characterized by\ndifferent medical centers and MR machines with varying brand, model and\nconfiguration parameters. Our experiments show that CycleGAN allows us to\nreduce the Jensen-Shannon divergence between MR domains, enabling automatic\nsegmentation with CNN models on domains where no labeled data was available.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:48:19 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Palladino", "Julian Alberto", ""], ["Slezak", "Diego Fernandez", ""], ["Ferrante", "Enzo", ""]]}, {"id": "2009.04991", "submitter": "Sheshank Shankar", "authors": "Sheshank Shankar, Rishank Kanaparti, Ayush Chopra, Rohan Sukumaran,\n  Parth Patwa, Myungsun Kang, Abhishek Singh, Kevin P. McPherson, Ramesh Raskar", "title": "Proximity Sensing: Modeling and Understanding Noisy RSSI-BLE Signals and\n  Other Mobile Sensor Data for Digital Contact Tracing", "comments": "Accepted to IEEE/ICACT' 2021: International Conference on Advanced\n  Communication Technology. Also presented at the Machine Learning for Mobile\n  Health workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we await a vaccine, social-distancing via efficient contact tracing has\nemerged as the primary health strategy to dampen the spread of COVID-19. To\nenable efficient digital contact tracing, we present a novel system to estimate\npair-wise individual proximity, via a joint model of Bluetooth Low Energy (BLE)\nsignals with other on-device sensors (accelerometer, magnetometer, gyroscope).\nWe explore multiple ways of interpreting the sensor data stream (time-series,\nhistogram, etc) and use several statistical and deep learning methods to learn\nrepresentations for sensing proximity. We report the normalized Decision Cost\nFunction (nDCF) metric and analyze the differential impact of the various input\nsignals, as well as discuss various challenges associated with this task.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 03:01:52 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 18:09:01 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 20:07:30 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Shankar", "Sheshank", ""], ["Kanaparti", "Rishank", ""], ["Chopra", "Ayush", ""], ["Sukumaran", "Rohan", ""], ["Patwa", "Parth", ""], ["Kang", "Myungsun", ""], ["Singh", "Abhishek", ""], ["McPherson", "Kevin P.", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2009.05014", "submitter": "Ekdeep Singh Lubana", "authors": "Ekdeep Singh Lubana, Puja Trivedi, Conrad Hougen, Robert P. Dick,\n  Alfred O. Hero", "title": "OrthoReg: Robust Network Pruning Using Orthonormality Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning in Convolutional Neural Networks (CNNs) has been extensively\ninvestigated in recent years. To determine the impact of pruning a group of\nfilters on a network's accuracy, state-of-the-art pruning methods consistently\nassume filters of a CNN are independent. This allows the importance of a group\nof filters to be estimated as the sum of importances of individual filters.\nHowever, overparameterization in modern networks results in highly correlated\nfilters that invalidate this assumption, thereby resulting in incorrect\nimportance estimates. To address this issue, we propose OrthoReg, a principled\nregularization strategy that enforces orthonormality on a network's filters to\nreduce inter-filter correlation, thereby allowing reliable, efficient\ndetermination of group importance estimates, improved trainability of pruned\nnetworks, and efficient, simultaneous pruning of large groups of filters. When\nused for iterative pruning on VGG-13, MobileNet-V1, and ResNet-34, OrthoReg\nconsistently outperforms five baseline techniques, including the\nstate-of-the-art, on CIFAR-100 and Tiny-ImageNet. For the recently proposed\nEarly-Bird Ticket hypothesis, which claims networks become amenable to pruning\nearly-on in training and can be pruned after a few epochs to minimize training\nexpenditure, we find OrthoReg significantly outperforms prior work. Code\navailable at https://github.com/EkdeepSLubana/OrthoReg.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:21:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Lubana", "Ekdeep Singh", ""], ["Trivedi", "Puja", ""], ["Hougen", "Conrad", ""], ["Dick", "Robert P.", ""], ["Hero", "Alfred O.", ""]]}, {"id": "2009.05019", "submitter": "Aparna Khare", "authors": "Aparna Khare, Srinivas Parthasarathy, Shiva Sundaram", "title": "Multi-modal embeddings using multi-task learning for emotion recognition", "comments": "To appear in Interspeech,2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1827", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General embeddings like word2vec, GloVe and ELMo have shown a lot of success\nin natural language tasks. The embeddings are typically extracted from models\nthat are built on general tasks such as skip-gram models and natural language\ngeneration. In this paper, we extend the work from natural language\nunderstanding to multi-modal architectures that use audio, visual and textual\ninformation for machine learning tasks. The embeddings in our network are\nextracted using the encoder of a transformer model trained using multi-task\ntraining. We use person identification and automatic speech recognition as the\ntasks in our embedding generation framework. We tune and evaluate the\nembeddings on the downstream task of emotion recognition and demonstrate that\non the CMU-MOSEI dataset, the embeddings can be used to improve over previous\nstate of the art results.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:33:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Khare", "Aparna", ""], ["Parthasarathy", "Srinivas", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2009.05023", "submitter": "Md Motiur Rahman Sagar", "authors": "Md Motiur Rahman Sagar, Martin Dyrba", "title": "Learning Shape Features and Abstractions in 3D Convolutional Neural\n  Networks for Detecting Alzheimer's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks - especially Convolutional Neural Network (ConvNet) has\nbecome the state-of-the-art for image classification, pattern recognition and\nvarious computer vision tasks. ConvNet has a huge potential in medical domain\nfor analyzing medical data to diagnose diseases in an efficient way. Based on\nextracted features by ConvNet model from MRI data, early diagnosis is very\ncrucial for preventing progress and treating the Alzheimer's disease. Despite\nhaving the ability to deliver great performance, absence of interpretability of\nthe model's decision can lead to misdiagnosis which can be life threatening. In\nthis thesis, learned shape features and abstractions by 3D ConvNets for\ndetecting Alzheimer's disease were investigated using various visualization\ntechniques. How changes in network structures, used filters sizes and filters\nshapes affects the overall performance and learned features of the model were\nalso inspected. LRP relevance map of different models revealed which parts of\nthe brain were more relevant for the classification decision. Comparing the\nlearned filters by Activation Maximization showed how patterns were encoded in\ndifferent layers of the network. Finally, transfer learning from a\nconvolutional autoencoder was implemented to check whether increasing the\nnumber of training samples with patches of input to extract the low-level\nfeatures improves learned features and the model performance.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:41:03 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Sagar", "Md Motiur Rahman", ""], ["Dyrba", "Martin", ""]]}, {"id": "2009.05027", "submitter": "Ois\\'in Carroll Mr.", "authors": "Ois\\'in Carroll, Joeran Beel", "title": "Finite Group Equivariant Neural Networks for Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games such as go, chess and checkers have multiple equivalent game states,\ni.e. multiple board positions where symmetrical and opposite moves should be\nmade. These equivalences are not exploited by current state of the art neural\nagents which instead must relearn similar information, thereby wasting\ncomputing time. Group equivariant CNNs in existing work create networks which\ncan exploit symmetries to improve learning, however, they lack the\nexpressiveness to correctly reflect the move embeddings necessary for games. We\nintroduce Finite Group Neural Networks (FGNNs), a method for creating agents\nwith an innate understanding of these board positions. FGNNs are shown to\nimprove the performance of networks playing checkers (draughts), and can be\neasily adapted to other games and learning problems. Additionally, FGNNs can be\ncreated from existing network architectures. These include, for the first time,\nthose with skip connections and arbitrary layer types. We demonstrate that an\nequivariant version of U-Net (FGNN-U-Net) outperforms the unmodified network in\nimage segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:46:09 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Carroll", "Ois\u00edn", ""], ["Beel", "Joeran", ""]]}, {"id": "2009.05041", "submitter": "David Bau iii", "authors": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou,\n  Antonio Torralba", "title": "Understanding the Role of Individual Units in a Deep Neural Network", "comments": "Proceedings of the National Academy of Sciences 2020. Code at\n  https://github.com/davidbau/dissect/ and website at\n  https://dissect.csail.mit.edu/", "journal-ref": null, "doi": "10.1073/pnas.1907375117", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks excel at finding hierarchical representations that solve\ncomplex tasks over large data sets. How can we humans understand these learned\nrepresentations? In this work, we present network dissection, an analytic\nframework to systematically identify the semantics of individual hidden units\nwithin image classification and image generation networks. First, we analyze a\nconvolutional neural network (CNN) trained on scene classification and discover\nunits that match a diverse set of object concepts. We find evidence that the\nnetwork has learned many object classes that play crucial roles in classifying\nscene classes. Second, we use a similar analytic method to analyze a generative\nadversarial network (GAN) model trained to generate scenes. By analyzing\nchanges made when small sets of units are activated or deactivated, we find\nthat objects can be added and removed from the output scenes while adapting to\nthe context. Finally, we apply our analytic framework to understanding\nadversarial attacks and to semantic image editing.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:59:10 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 18:58:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bau", "David", ""], ["Zhu", "Jun-Yan", ""], ["Strobelt", "Hendrik", ""], ["Lapedriza", "Agata", ""], ["Zhou", "Bolei", ""], ["Torralba", "Antonio", ""]]}, {"id": "2009.05076", "submitter": "Yingjun Dong", "authors": "Yingjun Dong, Neil G. MacLaren, Yiding Cao, Francis J. Yammarino,\n  Shelley D. Dionne, Michael D. Mumford, Shane Connelly, Hiroki Sayama, and\n  Gregory A. Ruark", "title": "Speaker Diarization Using Stereo Audio Channels: Preliminary Study on\n  Utterance Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization is one of the actively researched topics in audio signal\nprocessing and machine learning. Utterance clustering is a critical part of a\nspeaker diarization task. In this study, we aim to improve the performance of\nutterance clustering by processing multichannel (stereo) audio signals. We\ngenerated processed audio signals by combining left- and right-channel audio\nsignals in a few different ways and then extracted embedded features (also\ncalled d-vectors) from those processed audio signals. We applied the Gaussian\nmixture model (GMM) for supervised utterance clustering. In the training phase,\nwe used a parameter sharing GMM to train the model for each speaker. In the\ntesting phase, we selected the speaker with the maximum likelihood as the\ndetected speaker. Results of experiments with real audio recordings of\nmulti-person discussion sessions showed that our proposed method that used\nmultichannel audio signals achieved significantly better performance than a\nconventional method with mono audio signals.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:25:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Dong", "Yingjun", ""], ["MacLaren", "Neil G.", ""], ["Cao", "Yiding", ""], ["Yammarino", "Francis J.", ""], ["Dionne", "Shelley D.", ""], ["Mumford", "Michael D.", ""], ["Connelly", "Shane", ""], ["Sayama", "Hiroki", ""], ["Ruark", "Gregory A.", ""]]}, {"id": "2009.05079", "submitter": "Miheer Dewaskar", "authors": "Miheer Dewaskar, John Palowitch, Mark He, Michael I. Love, Andrew\n  Nobel", "title": "Finding Stable Groups of Cross-Correlated Features in Multi-View data", "comments": "22 pages, 5 figures. R package: https://github.com/miheerdew/cbce", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data, in which data of different types are obtained from a common\nset of samples, is now common in many scientific problems. An important problem\nin the analysis of multi-view data is identifying interactions between groups\nof features from different data types. A bimodule is a pair $(A,B)$ of feature\nsets from two different data types such that the aggregate cross-correlation\nbetween the features in $A$ and those in $B$ is large. A bimodule $(A,B)$ is\nstable if $A$ coincides with the set of features having significant aggregate\ncorrelation with the features in $B$, and vice-versa. At the population level,\nstable bimodules correspond to connected components of the cross-correlation\nnetwork, which is the bipartite graph whose edges are pairs of features with\nnon-zero cross-correlations.\n  We develop an iterative, testing-based procedure, called BSP, to identify\nstable bimodules in two moderate- to high-dimensional data sets. BSP relies on\npermutation-based p-values for sums of squared cross-correlations. We\nefficiently approximate the p-values using tail probabilities of gamma\ndistributions that are fit using analytical estimates of the permutation\nmoments of the test statistic. Our moment estimates depend on the eigenvalues\nof the intra-correlation matrices of $A$ and $B$ and as a result, the\nsignificance of observed cross-correlations accounts for the correlations\nwithin each data type.\n  We carry out a thorough simulation study to assess the performance of BSP,\nand present an extended application of BSP to the problem of expression\nquantitative trait loci (eQTL) analysis using recent data from the GTEx\nproject. In addition, we apply BSP to climatology data in order to identify\nregions in North America where annual temperature variation affects\nprecipitation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:27:35 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Dewaskar", "Miheer", ""], ["Palowitch", "John", ""], ["He", "Mark", ""], ["Love", "Michael I.", ""], ["Nobel", "Andrew", ""]]}, {"id": "2009.05094", "submitter": "Sayera Dhaubhadel", "authors": "Sayera Dhaubhadel, Jamaludin Mohd-Yusof, Kumkum Ganguly, Gopinath\n  Chennupati, Sunil Thulasidasan, Nicolas Hengartner, Brent J. Mumphrey, Eric\n  B. Durban, Jennifer A. Doherty, Mireille Lemieux, Noah Schaefferkoetter,\n  Georgia Tourassi, Linda Coyle, Lynne Penberthy, Benjamin McMahon, and Tanmoy\n  Bhattacharya", "title": "Why I'm not Answering: Understanding Determinants of Classification of\n  an Abstaining Classifier for Cancer Pathology Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe deployment of deep learning systems in critical real world applications\nrequires models to make few mistakes, and only under predictable circumstances.\nDevelopment of such a model is not yet possible, in general. In this work, we\naddress this problem with an abstaining classifier tuned to have $>$95%\naccuracy, and identify the determinants of abstention with LIME (the Local\nInterpretable Model-agnostic Explanations method). Essentially, we are training\nour model to learn the attributes of pathology reports that are likely to lead\nto incorrect classifications, albeit at the cost of reduced sensitivity. We\ndemonstrate our method in a multitask setting to classify cancer pathology\nreports from the NCI SEER cancer registries on six tasks of greatest\nimportance. For these tasks, we reduce the classification error rate by factors\nof 2-5 by abstaining on 25-45% of the reports. For the specific case of cancer\nsite, we are able to identify metastasis and reports involving lymph nodes as\nresponsible for many of the classification mistakes, and that the extent and\ntypes of mistakes vary systematically with cancer site (eg. breast, lung, and\nprostate). When combining across three of the tasks, our model classifies 50%\nof the reports with an accuracy greater than 95% for three of the six tasks and\ngreater than 85% for all six tasks on the retained samples. By using this\ninformation, we expect to define work flows that incorporate machine learning\nonly in the areas where it is sufficiently robust and accurate, saving human\nattention to areas where it is required.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:56:41 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 19:56:55 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 17:05:18 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 03:04:16 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Dhaubhadel", "Sayera", ""], ["Mohd-Yusof", "Jamaludin", ""], ["Ganguly", "Kumkum", ""], ["Chennupati", "Gopinath", ""], ["Thulasidasan", "Sunil", ""], ["Hengartner", "Nicolas", ""], ["Mumphrey", "Brent J.", ""], ["Durban", "Eric B.", ""], ["Doherty", "Jennifer A.", ""], ["Lemieux", "Mireille", ""], ["Schaefferkoetter", "Noah", ""], ["Tourassi", "Georgia", ""], ["Coyle", "Linda", ""], ["Penberthy", "Lynne", ""], ["McMahon", "Benjamin", ""], ["Bhattacharya", "Tanmoy", ""]]}, {"id": "2009.05096", "submitter": "Shervin Minaee", "authors": "Shakib Yazdani, Shervin Minaee, Rahele Kafieh, Narges Saeedizadeh,\n  Milan Sonka", "title": "COVID CT-Net: Predicting Covid-19 From Chest CT Images Using Attentional\n  Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel corona-virus disease (COVID-19) pandemic has caused a major\noutbreak in more than 200 countries around the world, leading to a severe\nimpact on the health and life of many people globally. As of Aug 25th of 2020,\nmore than 20 million people are infected, and more than 800,000 death are\nreported. Computed Tomography (CT) images can be used as a as an alternative to\nthe time-consuming \"reverse transcription polymerase chain reaction (RT-PCR)\"\ntest, to detect COVID-19. In this work we developed a deep learning framework\nto predict COVID-19 from CT images. We propose to use an attentional\nconvolution network, which can focus on the infected areas of chest, enabling\nit to perform a more accurate prediction. We trained our model on a dataset of\nmore than 2000 CT images, and report its performance in terms of various\npopular metrics, such as sensitivity, specificity, area under the curve, and\nalso precision-recall curve, and achieve very promising results. We also\nprovide a visualization of the attention maps of the model for several test\nimages, and show that our model is attending to the infected regions as\nintended. In addition to developing a machine learning modeling framework, we\nalso provide the manual annotation of the potentionally infected regions of\nchest, with the help of a board-certified radiologist, and make that publicly\navailable for other researchers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:00:51 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Yazdani", "Shakib", ""], ["Minaee", "Shervin", ""], ["Kafieh", "Rahele", ""], ["Saeedizadeh", "Narges", ""], ["Sonka", "Milan", ""]]}, {"id": "2009.05097", "submitter": "Nutta Homdee", "authors": "Nutta Homdee, John Lach", "title": "Actionable Interpretation of Machine Learning Models for Sequential\n  Data: Dementia-related Agitation Use Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown successes for complex learning problems in which\ndata/parameters can be multidimensional and too complex for a first-principles\nbased analysis. Some applications that utilize machine learning require human\ninterpretability, not just to understand a particular result (classification,\ndetection, etc.) but also for humans to take action based on that result.\nBlack-box machine learning model interpretation has been studied, but recent\nwork has focused on validation and improving model performance. In this work,\nan actionable interpretation of black-box machine learning models is presented.\nThe proposed technique focuses on the extraction of actionable measures to help\nusers make a decision or take an action. Actionable interpretation can be\nimplemented in most traditional black-box machine learning models. It uses the\nalready trained model, used training data, and data processing techniques to\nextract actionable items from the model outcome and its time-series inputs. An\nimplementation of the actionable interpretation is shown with a use case:\ndementia-related agitation prediction and the ambient environment. It is shown\nthat actionable items can be extracted, such as the decreasing of in-home light\nlevel, which is triggering an agitation episode. This use case of actionable\ninterpretation can help dementia caregivers take action to intervene and\nprevent agitation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:04:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Homdee", "Nutta", ""], ["Lach", "John", ""]]}, {"id": "2009.05102", "submitter": "Chenglizhao Chen", "authors": "Xuehao Wang, Shuai Li, Chenglizhao Chen, Yuming Fang, Aimin Hao, Hong\n  Qin", "title": "Data-Level Recombination and Lightweight Fusion Scheme for RGB-D Salient\n  Object Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2020.3037470", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing RGB-D salient object detection methods treat depth information as an\nindependent component to complement its RGB part, and widely follow the\nbi-stream parallel network architecture. To selectively fuse the CNNs features\nextracted from both RGB and depth as a final result, the state-of-the-art\n(SOTA) bi-stream networks usually consist of two independent subbranches; i.e.,\none subbranch is used for RGB saliency and the other aims for depth saliency.\nHowever, its depth saliency is persistently inferior to the RGB saliency\nbecause the RGB component is intrinsically more informative than the depth\ncomponent. The bi-stream architecture easily biases its subsequent fusion\nprocedure to the RGB subbranch, leading to a performance bottleneck. In this\npaper, we propose a novel data-level recombination strategy to fuse RGB with D\n(depth) before deep feature extraction, where we cyclically convert the\noriginal 4-dimensional RGB-D into \\textbf{D}GB, R\\textbf{D}B and RG\\textbf{D}.\nThen, a newly lightweight designed triple-stream network is applied over these\nnovel formulated data to achieve an optimal channel-wise complementary fusion\nstatus between the RGB and D, achieving a new SOTA performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:13:05 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Wang", "Xuehao", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Fang", "Yuming", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2009.05135", "submitter": "Sarah Ostadabbas", "authors": "Amirreza Farnoosh, Bahar Azari, Sarah Ostadabbas", "title": "Deep Switching Auto-Regressive Factorization:Application to Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep switching auto-regressive factorization (DSARF), a deep\ngenerative model for spatio-temporal data with the capability to unravel\nrecurring patterns in the data and perform robust short- and long-term\npredictions. Similar to other factor analysis methods, DSARF approximates high\ndimensional data by a product between time dependent weights and spatially\ndependent factors. These weights and factors are in turn represented in terms\nof lower dimensional latent variables that are inferred using stochastic\nvariational inference. DSARF is different from the state-of-the-art techniques\nin that it parameterizes the weights in terms of a deep switching vector\nauto-regressive likelihood governed with a Markovian prior, which is able to\ncapture the non-linear inter-dependencies among weights to characterize\nmultimodal temporal dynamics. This results in a flexible hierarchical deep\ngenerative factor analysis model that can be extended to (i) provide a\ncollection of potentially interpretable states abstracted from the process\ndynamics, and (ii) perform short- and long-term vector time series prediction\nin a complex multi-relational setting. Our extensive experiments, which include\nsimulated data and real data from a wide range of applications such as climate\nchange, weather forecasting, traffic, infectious disease spread and nonlinear\nphysical systems attest the superior performance of DSARF in terms of long- and\nshort-term prediction error, when compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 20:15:59 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Farnoosh", "Amirreza", ""], ["Azari", "Bahar", ""], ["Ostadabbas", "Sarah", ""]]}, {"id": "2009.05138", "submitter": "Negin Golrezaei", "authors": "Negin Golrezaei, Vahideh Manshadi, Jon Schneider, Shreyas Sekar", "title": "Learning Product Rankings Robust to Fake Users", "comments": "65 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many online platforms, customers' decisions are substantially influenced\nby product rankings as most customers only examine a few top-ranked products.\nConcurrently, such platforms also use the same data corresponding to customers'\nactions to learn how these products must be ranked or ordered. These\ninteractions in the underlying learning process, however, may incentivize\nsellers to artificially inflate their position by employing fake users, as\nexemplified by the emergence of click farms. Motivated by such fraudulent\nbehavior, we study the ranking problem of a platform that faces a mixture of\nreal and fake users who are indistinguishable from one another. We first show\nthat existing learning algorithms---that are optimal in the absence of fake\nusers---may converge to highly sub-optimal rankings under manipulation by fake\nusers. To overcome this deficiency, we develop efficient learning algorithms\nunder two informational environments: in the first setting, the platform is\naware of the number of fake users, and in the second setting, it is agnostic to\nthe number of fake users. For both these environments, we prove that our\nalgorithms converge to the optimal ranking, while being robust to the\naforementioned fraudulent behavior; we also present worst-case performance\nguarantees for our methods, and show that they significantly outperform\nexisting algorithms. At a high level, our work employs several novel approaches\nto guarantee robustness such as: (i) constructing product-ordering graphs that\nencode the pairwise relationships between products inferred from the customers'\nactions; and (ii) implementing multiple levels of learning with a judicious\namount of bi-directional cross-learning between levels.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 20:26:02 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Golrezaei", "Negin", ""], ["Manshadi", "Vahideh", ""], ["Schneider", "Jon", ""], ["Sekar", "Shreyas", ""]]}, {"id": "2009.05139", "submitter": "Ali Beikmohammadi", "authors": "Ali Beikmohammadi, Karim Faez, Ali Motallebi", "title": "SWP-Leaf NET: a novel multistage approach for plant leaf identification\n  based on deep learning", "comments": "38 pages, 16 figures, 5 tables, submitted to Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern scientific and technological advances are allowing botanists to use\ncomputer vision-based approaches for plant identification tasks. These\napproaches have their own challenges. Leaf classification is a computer-vision\ntask performed for the automated identification of plant species, a serious\nchallenge due to variations in leaf morphology, including its size, texture,\nshape, and venation. Researchers have recently become more inclined toward deep\nlearning-based methods rather than conventional feature-based methods due to\nthe popularity and successful implementation of deep learning methods in image\nanalysis, object recognition, and speech recognition. In this paper, a\nbotanist's behavior was modeled in leaf identification by proposing a\nhighly-efficient method of maximum behavioral resemblance developed through\nthree deep learning-based models. Different layers of the three models were\nvisualized to ensure that the botanist's behavior was modeled accurately. The\nfirst and second models were designed from scratch.Regarding the third model,\nthe pre-trained architecture MobileNetV2 was employed along with the\ntransfer-learning technique. The proposed method was evaluated on two\nwell-known datasets: Flavia and MalayaKew. According to a comparative analysis,\nthe suggested approach was more accurate than hand-crafted feature extraction\nmethods and other deep learning techniques in terms of 99.67% and 99.81%\naccuracy. Unlike conventional techniques that have their own specific\ncomplexities and depend on datasets, the proposed method required no\nhand-crafted feature extraction, and also increased accuracy and\ndistributability as compared with other deep learning techniques. It was\nfurther considerably faster than other methods because it used shallower\nnetworks with fewer parameters and did not use all three models recurrently.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 20:28:57 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Beikmohammadi", "Ali", ""], ["Faez", "Karim", ""], ["Motallebi", "Ali", ""]]}, {"id": "2009.05147", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen, Luke E. Richards, Gaoussou Youssouf Kebe, Edward\n  Raff, Kasra Darvish, Frank Ferraro, Cynthia Matuszek", "title": "Practical Cross-modal Manifold Alignment for Grounded Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cross-modality manifold alignment procedure that leverages\ntriplet loss to jointly learn consistent, multi-modal embeddings of\nlanguage-based concepts of real-world items. Our approach learns these\nembeddings by sampling triples of anchor, positive, and negative data points\nfrom RGB-depth images and their natural language descriptions. We show that our\napproach can benefit from, but does not require, post-processing steps such as\nProcrustes analysis, in contrast to some of our baselines which require it for\nreasonable performance. We demonstrate the effectiveness of our approach on two\ndatasets commonly used to develop robotic-based grounded language learning\nsystems, where our approach outperforms four baselines, including a\nstate-of-the-art approach, across five evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 04:16:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Richards", "Luke E.", ""], ["Kebe", "Gaoussou Youssouf", ""], ["Raff", "Edward", ""], ["Darvish", "Kasra", ""], ["Ferraro", "Frank", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "2009.05148", "submitter": "Sabarish Vadarevu", "authors": "Sabarish Vadarevu and Vijay Karamcheti", "title": "A new heuristic algorithm for fast k-segmentation", "comments": "10 pages, 10 figures, 5 tables, and 1 pseudo-code. Submitted to IEEE\n  BigData 2020. Supplementary material (200 segmented videos) at\n  https://figshare.com/articles/media/7-segmentation of 200 scenes from\n  BDD100k/12859493/1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-segmentation of a video stream is used to partition it into $k$\npiecewise-linear segments, so that each linear segment has a meaningful\ninterpretation. Such segmentation may be used to summarize large videos using a\nsmall set of images, to identify anomalies within segments and change points\nbetween segments, and to select critical subsets for training machine learning\nmodels. Exact and approximate segmentation methods for $k$-segmentation exist\nin the literature. Each of these algorithms occupies a different spot in the\ntrade-off between computational complexity and accuracy. A novel heuristic\nalgorithm is proposed in this paper to improve upon existing methods. It is\nempirically found to provide accuracies competitive with exact methods at a\nfraction of the computational expense.\n  The new algorithm is inspired by Lloyd's algorithm for K-Means and Lloyd-Max\nalgorithm for scalar quantization, and is called the LM algorithm for\nconvenience. It works by iteratively minimizing a cost function from any given\ninitialisation; the commonly used $L_2$ cost is chosen in this paper. While the\ngreedy minimization makes the algorithm sensitive to initialisation, the\nability to converge from any initial guess to a local optimum allows the\nalgorithm to be integrated into other existing algorithms. Three variants of\nthe algorithm are tested over a large number of synthetic datasets, one being a\nstandalone LM implementation, and two others that combine with existing\nalgorithms. One of the latter two -- LM-enhanced-Bottom-Up segmentation -- is\nfound to have the best accuracy and the lowest computational complexity among\nall algorithms. This variant of LM can provide $k$-segmentations over data sets\nwith up to a million image frames within several seconds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 04:50:17 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Vadarevu", "Sabarish", ""], ["Karamcheti", "Vijay", ""]]}, {"id": "2009.05152", "submitter": "Zhixuan Xu", "authors": "Zhixuan Xu, Minghui Qian, Xiaowei Huang, and Jie Meng", "title": "CasGCN: Predicting future cascade growth based on information diffusion\n  graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sudden bursts of information cascades can lead to unexpected consequences\nsuch as extreme opinions, changes in fashion trends, and uncontrollable spread\nof rumors. It has become an important problem on how to effectively predict a\ncascade' size in the future, especially for large-scale cascades on social\nmedia platforms such as Twitter and Weibo. However, existing methods are\ninsufficient in dealing with this challenging prediction problem. Conventional\nmethods heavily rely on either hand crafted features or unrealistic\nassumptions. End-to-end deep learning models, such as recurrent neural\nnetworks, are not suitable to work with graphical inputs directly and cannot\nhandle structural information that is embedded in the cascade graphs. In this\npaper, we propose a novel deep learning architecture for cascade growth\nprediction, called CasGCN, which employs the graph convolutional network to\nextract structural features from a graphical input, followed by the application\nof the attention mechanism on both the extracted features and the temporal\ninformation before conducting cascade size prediction. We conduct experiments\non two real-world cascade growth prediction scenarios (i.e., retweet popularity\non Sina Weibo and academic paper citations on DBLP), with the experimental\nresults showing that CasGCN enjoys a superior performance over several baseline\nmethods, particularly when the cascades are of large scale.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 21:20:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Xu", "Zhixuan", ""], ["Qian", "Minghui", ""], ["Huang", "Xiaowei", ""], ["Meng", "Jie", ""]]}, {"id": "2009.05158", "submitter": "Hailey James", "authors": "Hailey James, Otkrist Gupta, Dan Raviv", "title": "OCR Graph Features for Manipulation Detection in Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting manipulations in digital documents is becoming increasingly\nimportant for information verification purposes. Due to the proliferation of\nimage editing software, altering key information in documents has become widely\naccessible. Nearly all approaches in this domain rely on a procedural approach,\nusing carefully generated features and a hand-tuned scoring system, rather than\na data-driven and generalizable approach. We frame this issue as a graph\ncomparison problem using the character bounding boxes, and propose a model that\nleverages graph features using OCR (Optical Character Recognition). Our model\nrelies on a data-driven approach to detect alterations by training a random\nforest classifier on the graph-based OCR features. We evaluate our algorithm's\nforgery detection performance on dataset constructed from real business\ndocuments with slight forgery imperfections. Our proposed model dramatically\noutperforms the most closely-related document manipulation detection model on\nthis task.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 21:50:45 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 15:52:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["James", "Hailey", ""], ["Gupta", "Otkrist", ""], ["Raviv", "Dan", ""]]}, {"id": "2009.05160", "submitter": "Amir Atapour Abarghouei", "authors": "Amir Atapour-Abarghouei, Stephen Bonner, Andrew Stephen McGough", "title": "Rank over Class: The Untapped Potential of Ranking in Natural Language\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has long been a staple in natural language processing\nwith applications spanning across sentiment analysis, online content tagging,\nrecommender systems and spam detection. However, text classification, by\nnature, suffers from a variety of issues stemming from dataset imbalance, text\nambiguity, subjectivity and the lack of linguistic context in the data. In this\npaper, we explore the use of text ranking, commonly used in information\nretrieval, to carry out challenging classification-based tasks. We propose a\nnovel end-to-end ranking approach consisting of a Transformer network\nresponsible for producing representations for a pair of text sequences, which\nare in turn passed into a context aggregating network outputting ranking scores\nused to determine an ordering to the sequences based on some notion of\nrelevance. We perform numerous experiments on publicly-available datasets and\ninvestigate the possibility of applying our ranking approach to certain\nproblems often addressed using classification. In an experiment on a\nheavily-skewed sentiment analysis dataset, converting ranking results to\nclassification labels yields an approximately 22% improvement over\nstate-of-the-art text classification, demonstrating the efficacy of text\nranking over text classification in certain scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:18:57 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 11:34:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Atapour-Abarghouei", "Amir", ""], ["Bonner", "Stephen", ""], ["McGough", "Andrew Stephen", ""]]}, {"id": "2009.05169", "submitter": "Micha{\\l} Pietruszka", "authors": "Micha{\\l} Pietruszka, {\\L}ukasz Borchmann, {\\L}ukasz Garncarek", "title": "Sparsifying Transformer Models with Trainable Representation Pooling", "comments": "Provided formal overview. Reevaluated with Google Research script", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to sparsify attention in the Transformer model by\nlearning to select the most-informative token representations during the\ntraining process, thus focusing on task-specific parts of the input. A\nreduction of quadratic time and memory complexity to sublinear was achieved due\nto a robust trainable top-k operator. For example, our experiments on a\nchallenging summarization task of long documents show that our method is over 3\ntimes faster and up to 16 times more memory efficient while significantly\noutperforming both dense and state-of-the-art sparse transformer models. The\nmethod can be effortlessly applied to many models used in NLP and CV,\nsimultaneously with other improvements.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:49:39 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 16:49:01 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 22:34:47 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Pietruszka", "Micha\u0142", ""], ["Borchmann", "\u0141ukasz", ""], ["Garncarek", "\u0141ukasz", ""]]}, {"id": "2009.05176", "submitter": "Mario Michael Krell", "authors": "Mario Michael Krell and Bilal Wehbe", "title": "A First Step Towards Distribution Invariant Regression Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Regression evaluation has been performed for decades. Some metrics have been\nidentified to be robust against shifting and scaling of the data but\nconsidering the different distributions of data is much more difficult to\naddress (imbalance problem) even though it largely impacts the comparability\nbetween evaluations on different datasets. In classification, it has been\nstated repeatedly that performance metrics like the F-Measure and Accuracy are\nhighly dependent on the class distribution and that comparisons between\ndifferent datasets with different distributions are impossible. We show that\nthe same problem exists in regression. The distribution of odometry parameters\nin robotic applications can for example largely vary between different\nrecording sessions. Here, we need regression algorithms that either perform\nequally well for all function values, or that focus on certain boundary regions\nlike high speed. This has to be reflected in the evaluation metric. We propose\nthe modification of established regression metrics by weighting with the\ninverse distribution of function values $Y$ or the samples $X$ using an\nautomatically tuned Gaussian kernel density estimator. We show on synthetic and\nrobotic data in reproducible experiments that classical metrics behave wrongly,\nwhereas our new metrics are less sensitive to changing distributions,\nespecially when correcting by the marginal distribution in $X$. Our new\nevaluation concept enables the comparison of results between different datasets\nwith different distributions. Furthermore, it can reveal overfitting of a\nregression algorithm to overrepresented target values. As an outcome,\nnon-overfitting regression algorithms will be more likely chosen due to our\ncorrected metrics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 23:40:46 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Krell", "Mario Michael", ""], ["Wehbe", "Bilal", ""]]}, {"id": "2009.05188", "submitter": "Mark Cartwright", "authors": "Mark Cartwright, Jason Cramer, Ana Elisa Mendez Mendez, Yu Wang,\n  Ho-Hsiang Wu, Vincent Lostanlen, Magdalena Fuentes, Graham Dove, Charlie\n  Mydlarz, Justin Salamon, Oded Nov, and Juan Pablo Bello", "title": "SONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SONYC-UST-V2, a dataset for urban sound tagging with\nspatiotemporal information. This dataset is aimed for the development and\nevaluation of machine listening systems for real-world urban noise monitoring.\nWhile datasets of urban recordings are available, this dataset provides the\nopportunity to investigate how spatiotemporal metadata can aid in the\nprediction of urban sound tags. SONYC-UST-V2 consists of 18510 audio recordings\nfrom the \"Sounds of New York City\" (SONYC) acoustic sensor network, including\nthe timestamp of audio acquisition and location of the sensor. The dataset\ncontains annotations by volunteers from the Zooniverse citizen science\nplatform, as well as a two-stage verification with our team. In this article,\nwe describe our data collection procedure and propose evaluation metrics for\nmultilabel classification of urban sound tags. We report the results of a\nsimple baseline model that exploits spatiotemporal information.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 01:19:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Cartwright", "Mark", ""], ["Cramer", "Jason", ""], ["Mendez", "Ana Elisa Mendez", ""], ["Wang", "Yu", ""], ["Wu", "Ho-Hsiang", ""], ["Lostanlen", "Vincent", ""], ["Fuentes", "Magdalena", ""], ["Dove", "Graham", ""], ["Mydlarz", "Charlie", ""], ["Salamon", "Justin", ""], ["Nov", "Oded", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "2009.05197", "submitter": "Aravind Sankar", "authors": "Aravind Sankar, Junting Wang, Adit Krishnan, Hari Sundaram", "title": "Beyond Localized Graph Neural Networks: An Attributed Motif\n  Regularization Framework", "comments": "To appear at ICDM 2020 (IEEE International Conference on Data Mining)", "journal-ref": null, "doi": "10.1109/ICDM50108.2020.00056", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present InfoMotif, a new semi-supervised, motif-regularized, learning\nframework over graphs. We overcome two key limitations of message passing in\npopular graph neural networks (GNNs): localization (a k-layer GNN cannot\nutilize features outside the k-hop neighborhood of the labeled training nodes)\nand over-smoothed (structurally indistinguishable) representations. We propose\nthe concept of attributed structural roles of nodes based on their occurrence\nin different network motifs, independent of network proximity. Two nodes share\nattributed structural roles if they participate in topologically similar motif\ninstances over co-varying sets of attributes. Further, InfoMotif achieves\narchitecture independence by regularizing the node representations of arbitrary\nGNNs via mutual information maximization. Our training curriculum dynamically\nprioritizes multiple motifs in the learning process without relying on\ndistributional assumptions in the underlying graph or the learning task. We\nintegrate three state-of-the-art GNNs in our framework, to show significant\ngains (3-10% accuracy) across six diverse, real-world datasets. We see stronger\ngains for nodes with sparse training labels and diverse attributes in local\nneighborhood structures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:03:09 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sankar", "Aravind", ""], ["Wang", "Junting", ""], ["Krishnan", "Adit", ""], ["Sundaram", "Hari", ""]]}, {"id": "2009.05199", "submitter": "Daniel Nemirovsky", "authors": "Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, Abhishek Gupta", "title": "CounteRGAN: Generating Realistic Counterfactuals with Residual\n  Generative Adversarial Nets", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of machine learning models in various industries has led to\ngrowing demands for model interpretability and for the ability to provide\nmeaningful recourse to users. For example, patients hoping to improve their\ndiagnoses or loan applicants seeking to increase their chances of approval.\nCounterfactuals can help in this regard by identifying input perturbations that\nwould result in more desirable prediction outcomes. Meaningful counterfactuals\nshould be able to achieve the desired outcome, but also be realistic,\nactionable, and efficient to compute. Current approaches achieve desired\noutcomes with moderate actionability but are severely limited in terms of\nrealism and latency. To tackle these limitations, we apply Generative\nAdversarial Nets (GANs) toward counterfactual search. We also introduce a novel\nResidual GAN (RGAN) that helps to improve counterfactual realism and\nactionability compared to regular GANs. The proposed CounteRGAN method utilizes\nan RGAN and a target classifier to produce counterfactuals capable of providing\nmeaningful recourse. Evaluations on two popular datasets highlight how the\nCounteRGAN is able to overcome the limitations of existing methods, including\nlatency improvements of >50x to >90,000x, making meaningful recourse available\nin real-time and applicable to a wide range of domains.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:08:19 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 06:25:33 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Nemirovsky", "Daniel", ""], ["Thiebaut", "Nicolas", ""], ["Xu", "Ye", ""], ["Gupta", "Abhishek", ""]]}, {"id": "2009.05204", "submitter": "Qi Zhu", "authors": "Qi Zhu, Yidan Xu, Haonan Wang, Chao Zhang, Jiawei Han, Carl Yang", "title": "Transfer Learning of Graph Neural Networks with Ego-graph Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been shown with superior performance in\nvarious applications, but training dedicated GNNs can be costly for large-scale\ngraphs. Some recent work started to study the pre-training of GNNs. However,\nnone of them provide theoretical insights into the design of their frameworks,\nor clear requirements and guarantees towards the transferability of GNNs. In\nthis work, we establish a theoretically grounded and practically useful\nframework for the transfer learning of GNNs. Firstly, we propose a novel view\ntowards the essential graph information and advocate the capturing of it as the\ngoal of transferable GNN training, which motivates the design of Ours, a novel\nGNN framework based on ego-graph information maximization to analytically\nachieve this goal. Secondly, we specify the requirement of structure-respecting\nnode features as the GNN input, and derive a rigorous bound of GNN\ntransferability based on the difference between the local graph Laplacians of\nthe source and target graphs. Finally, we conduct controlled synthetic\nexperiments to directly justify our theoretical conclusions. Extensive\nexperiments on real-world networks towards role identification show consistent\nresults in the rigorously analyzed setting of direct-transfering, while those\ntowards large-scale relation prediction show promising results in the more\ngeneralized and practical setting of transfering with fine-tuning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:31:18 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Zhu", "Qi", ""], ["Xu", "Yidan", ""], ["Wang", "Haonan", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""], ["Yang", "Carl", ""]]}, {"id": "2009.05224", "submitter": "Jihoon Chung Mr", "authors": "Jihoon Chung, Cheng-hsin Wuu, Hsuan-ru Yang, Yu-Wing Tai, Chi-Keung\n  Tang", "title": "HAA500: Human-Centric Atomic Action Dataset with Curated Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We contribute HAA500, a manually annotated human-centric atomic action\ndataset for action recognition on 500 classes with over 591k labeled frames.\nUnlike existing atomic action datasets, where coarse-grained atomic actions\nwere labeled with action-verbs, e.g., \"Throw\", HAA500 contains fine-grained\natomic actions where only consistent actions fall under the same label, e.g.,\n\"Baseball Pitching\" vs \"Free Throw in Basketball\", to minimize ambiguities in\naction classification. HAA500 has been carefully curated to capture the\nmovement of human figures with less spatio-temporal label noises to greatly\nenhance the training of deep neural networks. The advantages of HAA500 include:\n1) human-centric actions with a high average of 69.7% detectable joints for the\nrelevant human poses; 2) each video captures the essential elements of an\natomic action without irrelevant frames; 3) fine-grained atomic action classes.\nOur extensive experiments validate the benefits of human-centric and atomic\ncharacteristics of HAA, which enables the trained model to improve prediction\nby attending to atomic human poses. We detail the HAA500 dataset statistics and\ncollection methodology, and compare quantitatively with existing action\nrecognition datasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 04:18:41 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Chung", "Jihoon", ""], ["Wuu", "Cheng-hsin", ""], ["Yang", "Hsuan-ru", ""], ["Tai", "Yu-Wing", ""], ["Tang", "Chi-Keung", ""]]}, {"id": "2009.05226", "submitter": "Jiyue Wang", "authors": "Ji-Yue Wang, Pei Zhang, Wen-feng Pang, Jie Li", "title": "Extending Label Smoothing Regularization with Self-Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the strong correlation between the Label Smoothing\nRegularization(LSR) and Knowledge distillation(KD), we propose an algorithm\nLsrKD for training boost by extending the LSR method to the KD regime and\napplying a softer temperature. Then we improve the LsrKD by a Teacher\nCorrection(TC) method, which manually sets a constant larger proportion for the\nright class in the uniform distribution teacher. To further improve the\nperformance of LsrKD, we develop a self-distillation method named Memory-replay\nKnowledge Distillation (MrKD) that provides a knowledgeable teacher to replace\nthe uniform distribution one in LsrKD. The MrKD method penalizes the KD loss\nbetween the current model's output distributions and its copies' on the\ntraining trajectory. By preventing the model learning so far from its\nhistorical output distribution space, MrKD can stabilize the learning and find\na more robust minimum. Our experiments show that LsrKD can improve LSR\nperformance consistently at no cost, especially on several deep neural networks\nwhere LSR is ineffectual. Also, MrKD can significantly improve single model\ntraining. The experiment results confirm that the TC can help LsrKD and MrKD to\nboost training, especially on the networks they are failed. Overall, LsrKD,\nMrKD, and their TC variants are comparable to or outperform the LSR method,\nsuggesting the broad applicability of these KD methods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 04:23:34 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Wang", "Ji-Yue", ""], ["Zhang", "Pei", ""], ["Pang", "Wen-feng", ""], ["Li", "Jie", ""]]}, {"id": "2009.05236", "submitter": "Yuke Wang", "authors": "Yuke Wang, Boyuan Feng, Xueqiao Peng, Yufei Ding", "title": "Optimizing Convolutional Neural Network Architecture via Information\n  Field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNN architecture design has attracted tremendous attention of improving model\naccuracy or reducing model complexity. However, existing works either introduce\nrepeated training overhead in the search process or lack an interpretable\nmetric to guide the design. To clear the hurdles, we propose Information Field\n(IF), an explainable and easy-to-compute metric, to estimate the quality of a\nCNN architecture and guide the search process of designs. To validate the\neffectiveness of IF, we build a static optimizer to improve the CNN\narchitectures at both the stage level and the kernel level. Our optimizer not\nonly provides a clear and reproducible procedure but also mitigates unnecessary\ntraining efforts in the architecture search process. Experiments show that the\nmodels generated by our optimizer can achieve up to 5.47% accuracy improvement\nand up to 65.38% parameters deduction, compared with state-of-the-art CNN\nstructures like MobileNet and ResNet.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 05:14:34 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Wang", "Yuke", ""], ["Feng", "Boyuan", ""], ["Peng", "Xueqiao", ""], ["Ding", "Yufei", ""]]}, {"id": "2009.05240", "submitter": "DongNyeong Heo", "authors": "DongNyeong Heo, Stanislav Lange, Hee-Gon Kim and Heeyoul Choi", "title": "Graph Neural Network based Service Function Chaining for Automatic\n  Network Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networking (SDN) and the network function virtualization\n(NFV) led to great developments in software based control technology by\ndecreasing expenditures. Service function chaining (SFC) is an important\ntechnology to find efficient paths in network servers to process all of the\nrequested virtualized network functions (VNF). However, SFC is challenging\nsince it has to maintain high Quality of Service (QoS) even for complicated\nsituations. Although some works have been conducted for such tasks with\nhigh-level intelligent models like deep neural networks (DNNs), those\napproaches are not efficient in utilizing the topology information of networks\nand cannot be applied to networks with dynamically changing topology since\ntheir models assume that the topology is fixed. In this paper, we propose a new\nneural network architecture for SFC, which is based on graph neural network\n(GNN) considering the graph-structured properties of network topology. The\nproposed SFC model consists of an encoder and a decoder, where the encoder\nfinds the representation of the network topology, and then the decoder\nestimates probabilities of neighborhood nodes and their probabilities to\nprocess a VNF. In the experiments, our proposed architecture outperformed\nprevious performances of DNN based baseline model. Moreover, the GNN based\nmodel can be applied to a new network topology without re-designing and\nre-training.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 06:01:27 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Heo", "DongNyeong", ""], ["Lange", "Stanislav", ""], ["Kim", "Hee-Gon", ""], ["Choi", "Heeyoul", ""]]}, {"id": "2009.05241", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Yuheng Zhang, Ruoxi Jia", "title": "Improving Robustness to Model Inversion Attacks via Mutual Information\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies defense mechanisms against model inversion (MI) attacks --\na type of privacy attacks aimed at inferring information about the training\ndata distribution given the access to a target machine learning model. Existing\ndefense mechanisms rely on model-specific heuristics or noise injection. While\nbeing able to mitigate attacks, existing methods significantly hinder model\nperformance. There remains a question of how to design a defense mechanism that\nis applicable to a variety of models and achieves better utility-privacy\ntradeoff. In this paper, we propose the Mutual Information Regularization based\nDefense (MID) against MI attacks. The key idea is to limit the information\nabout the model input contained in the prediction, thereby limiting the ability\nof an adversary to infer the private training attributes from the model\nprediction. Our defense principle is model-agnostic and we present tractable\napproximations to the regularizer for linear regression, decision trees, and\nneural networks, which have been successfully attacked by prior work if not\nattached with any defenses. We present a formal study of MI attacks by devising\na rigorous game-based definition and quantifying the associated information\nleakage. Our theoretical analysis sheds light on the inefficacy of DP in\ndefending against MI attacks, which has been empirically observed in several\nprior works. Our experiments demonstrate that MID leads to state-of-the-art\nperformance for a variety of MI attacks, target models and datasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 06:02:44 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:35:57 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Wang", "Tianhao", ""], ["Zhang", "Yuheng", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2009.05244", "submitter": "Shao-Yuan Lo", "authors": "Shao-Yuan Lo, Vishal M. Patel", "title": "Defending Against Multiple and Unforeseen Adversarial Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness of deep neural networks has been actively\ninvestigated. However, most existing defense approaches are limited to a\nspecific type of adversarial perturbations. Specifically, they often fail to\noffer resistance to multiple attack types simultaneously, i.e., they lack\nmulti-perturbation robustness. Furthermore, compared to image recognition\nproblems, the adversarial robustness of video recognition models is relatively\nunexplored. While several studies have proposed how to generate adversarial\nvideos, only a handful of approaches about the defense strategies have been\npublished in the literature. In this paper, we propose one of the first defense\nstrategies against multiple types of adversarial videos for video recognition.\nThe proposed method, referred to as MultiBN, performs adversarial training on\nmultiple adversarial video types using multiple independent batch normalization\n(BN) layers with a learning-based BN selection module. With a multiple BN\nstructure, each BN brach is responsible for learning the distribution of a\nsingle perturbation type and thus provides more precise distribution\nestimations. This mechanism benefits dealing with multiple perturbation types.\nThe BN selection module detects the attack type of an input video and sends it\nto the corresponding BN branch, making MultiBN fully automatic and allow\nend-to-end training. Compared to present adversarial training approaches, the\nproposed MultiBN exhibits stronger multi-perturbation robustness against\ndifferent and even unforeseen adversarial video types, ranging from Lp-bounded\nattacks and physically realizable attacks. This holds true on different\ndatasets and target models. Moreover, we conduct an extensive analysis to study\nthe properties of the multiple BN structure.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 06:07:14 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 01:18:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lo", "Shao-Yuan", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2009.05257", "submitter": "Charlene Yang", "authors": "Charlene Yang, Yunsong Wang, Steven Farrell, Thorsten Kurth, Samuel\n  Williams", "title": "Hierarchical Roofline Performance Analysis for Deep Learning\n  Applications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a practical methodology for collecting performance data\nnecessary to conduct hierarchical Roofline analysis on NVIDIA GPUs. It\ndiscusses the extension of the Empirical Roofline Toolkit for broader support\nof a range of data precisions and Tensor Core support and introduces a Nsight\nCompute based method to accurately collect application performance information.\nThis methodology allows for automated machine characterization and application\ncharacterization for Roofline analysis across the entire memory hierarchy on\nNVIDIA GPUs, and it is validated by a complex deep learning application used\nfor climate image segmentation. We use two versions of the code, in TensorFlow\nand PyTorch respectively, to demonstrate the use and effectiveness of this\nmethodology. We highlight how the application utilizes the compute and memory\ncapabilities on the GPU and how the implementation and performance differ in\ntwo deep learning frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 07:16:55 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:14:16 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 21:57:58 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 02:52:41 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yang", "Charlene", ""], ["Wang", "Yunsong", ""], ["Farrell", "Steven", ""], ["Kurth", "Thorsten", ""], ["Williams", "Samuel", ""]]}, {"id": "2009.05261", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "End-to-end Learning for OFDM: From Neural Receivers to Pilotless\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have demonstrated that end-to-end learning enables\nsignificant shaping gains over additive white Gaussian noise (AWGN) channels.\nHowever, its benefits have not yet been quantified over realistic wireless\nchannel models. This work aims to fill this gap by exploring the gains of\nend-to-end learning over a frequency- and time-selective fading channel using\northogonal frequency division multiplexing (OFDM). With imperfect channel\nknowledge at the receiver, the shaping gains observed on AWGN channels vanish.\nNonetheless, we identify two other sources of performance improvements. The\nfirst comes from a neural network (NN)-based receiver operating over a large\nnumber of subcarriers and OFDM symbols which allows to significantly reduce the\nnumber of orthogonal pilots without loss of bit error rate (BER). The second\ncomes from entirely eliminating orthognal pilots by jointly learning a neural\nreceiver together with either superimposed pilots (SIPs), linearly combined\nwith conventional quadrature amplitude modulation (QAM), or an optimized\nconstellation geometry. The learned geometry works for a wide range of\nsignal-to-noise ratios (SNRs), Doppler and delay spreads, has zero mean and\ndoes hence not contain any form of superimposed pilots. Both schemes achieve\nthe same BER as the pilot-based baseline with around 7% higher throughput.\nThus, we believe that a jointly learned transmitter and receiver are a very\ninteresting component for beyond-5G communication systems which could remove\nthe need and associated control overhead for demodulation reference signals\n(DMRSs).\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 07:33:00 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 14:43:39 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 06:26:37 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "2009.05265", "submitter": "Aditya Tandon", "authors": "Aditya Tandon, Aiiad Albeshri, Vijey Thayananthan, Wadee Alhalabi,\n  Filippo Radicchi and Santo Fortunato", "title": "Community detection in networks using graph embeddings", "comments": "16 pages, 13 figures", "journal-ref": "Phys. Rev. E 103, 022316 (2021)", "doi": "10.1103/PhysRevE.103.022316", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding methods are becoming increasingly popular in the machine\nlearning community, where they are widely used for tasks such as node\nclassification and link prediction. Embedding graphs in geometric spaces should\naid the identification of network communities as well, because nodes in the\nsame community should be projected close to each other in the geometric space,\nwhere they can be detected via standard data clustering algorithms. In this\npaper, we test the ability of several graph embedding techniques to detect\ncommunities on benchmark graphs. We compare their performance against that of\ntraditional community detection algorithms. We find that the performance is\ncomparable, if the parameters of the embedding techniques are suitably chosen.\nHowever, the optimal parameter set varies with the specific features of the\nbenchmark graphs, like their size, whereas popular community detection\nalgorithms do not require any parameter. So it is not possible to indicate\nbeforehand good parameter sets for the analysis of real networks. This finding,\nalong with the high computational cost of embedding a network and grouping the\npoints, suggests that, for community detection, current embedding techniques do\nnot represent an improvement over network clustering algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 07:49:21 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 21:45:23 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Tandon", "Aditya", ""], ["Albeshri", "Aiiad", ""], ["Thayananthan", "Vijey", ""], ["Alhalabi", "Wadee", ""], ["Radicchi", "Filippo", ""], ["Fortunato", "Santo", ""]]}, {"id": "2009.05266", "submitter": "Yiming Li", "authors": "Yiming Li, Da Sun Handason Tam, Siyue Xie, Xiaxin Liu, Qiu Fang Ying,\n  Wing Cheong Lau, Dah Ming Chiu, Shou Zhi Chen", "title": "GTEA: Representation Learning for Temporal Interaction Graphs via Edge\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of representation learning for temporal interaction\ngraphs where a network of entities with complex interactions over an extended\nperiod of time is modeled as a graph with a rich set of node and edge\nattributes. In particular, an edge between a node-pair within the graph\ncorresponds to a multi-dimensional time-series. To fully capture and model the\ndynamics of the network, we propose GTEA, a framework of representation\nlearning for temporal interaction graphs with per-edge time-based aggregation.\nUnder GTEA, a Graph Neural Network (GNN) is integrated with a state-of-the-art\nsequence model, such as LSTM, Transformer and their time-aware variants. The\nsequence model generates edge embeddings to encode temporal interaction\npatterns between each pair of nodes, while the GNN-based backbone learns the\ntopological dependencies and relationships among different nodes. GTEA also\nincorporates a sparsity-inducing self-attention mechanism to distinguish and\nfocus on the more important neighbors of each node during the aggregation\nprocess. By capturing temporal interactive dynamics together with\nmulti-dimensional node and edge attributes in a network, GTEA can learn\nfine-grained representations for a temporal interaction graph to enable or\nfacilitate other downstream data analytic tasks. Experimental results show that\nGTEA outperforms state-of-the-art schemes including GraphSAGE, APPNP, and TGAT\nby delivering higher accuracy (100.00%, 98.51%, 98.05% ,79.90%) and macro-F1\nscore (100.00%, 98.51%, 96.68% ,79.90%) over four large-scale real-world\ndatasets for binary/ multi-class node classification.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 07:52:05 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 08:43:48 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Li", "Yiming", ""], ["Tam", "Da Sun Handason", ""], ["Xie", "Siyue", ""], ["Liu", "Xiaxin", ""], ["Ying", "Qiu Fang", ""], ["Lau", "Wing Cheong", ""], ["Chiu", "Dah Ming", ""], ["Chen", "Shou Zhi", ""]]}, {"id": "2009.05273", "submitter": "Nunzio Alexandro Letizia Mr", "authors": "Nunzio A. Letizia, Andrea M. Tonello", "title": "Capacity-Approaching Autoencoders for Communications", "comments": "10 pages, 7 figures, 30 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autoencoder concept has fostered the reinterpretation and the design of\nmodern communication systems. It consists of an encoder, a channel, and a\ndecoder block which modify their internal neural structure in an end-to-end\nlearning fashion. However, the current approach to train an autoencoder relies\non the use of the cross-entropy loss function. This approach can be prone to\noverfitting issues and often fails to learn an optimal system and signal\nrepresentation (code). In addition, less is known about the autoencoder ability\nto design channel capacity-approaching codes, i.e., codes that maximize the\ninput-output information under a certain power constraint. The task being even\nmore formidable for an unknown channel for which the capacity is unknown and\ntherefore it has to be learnt.\n  In this paper, we address the challenge of designing capacity-approaching\ncodes by incorporating the presence of the communication channel into a novel\nloss function for the autoencoder training. In particular, we exploit the\nmutual information between the transmitted and received signals as a\nregularization term in the cross-entropy loss function, with the aim of\ncontrolling the amount of information stored. By jointly maximizing the mutual\ninformation and minimizing the cross-entropy, we propose a methodology that a)\ncomputes an estimate of the channel capacity and b) constructs an optimal coded\nsignal approaching it. Several simulation results offer evidence of the\npotentiality of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:19:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Letizia", "Nunzio A.", ""], ["Tonello", "Andrea M.", ""]]}, {"id": "2009.05277", "submitter": "Shujaat Khan", "authors": "Shujaat Khan, Muhammad Usman, Abdul Wahab", "title": "AFP-SRC: Identification of Antifreeze Proteins Using Sparse\n  Representation Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Species living in the extreme cold environment fight against the harsh\nconditions using antifreeze proteins (AFPs), that manipulates the freezing\nmechanism of water in more than one way. This amazing nature of AFP turns out\nto be extremely useful in several industrial and medical applications. The lack\nof similarity in their structure and sequence makes their prediction an arduous\ntask and identifying them experimentally in the wet-lab is time-consuming and\nexpensive. In this research, we propose a computational framework for the\nprediction of AFPs which is essentially based on a sample-specific\nclassification method using the sparse reconstruction. A linear model and an\nover-complete dictionary matrix of known AFPs are used to predict a sparse\nclass-label vector that provides a sample-association score. Delta-rule is\napplied for the reconstruction of two pseudo-samples using lower and upper\nparts of the sample-association vector and based on the minimum recovery score,\nclass labels are assigned. We compare our approach with contemporary methods on\na standard dataset and the proposed method is found to outperform in terms of\nBalanced accuracy and Youden's index. The MATLAB implementation of the proposed\nmethod is available at the author's GitHub page\n(\\{https://github.com/Shujaat123/AFP-SRC}{https://github.com/Shujaat123/AFP-SRC}).\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:24:50 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 07:01:30 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Khan", "Shujaat", ""], ["Usman", "Muhammad", ""], ["Wahab", "Abdul", ""]]}, {"id": "2009.05283", "submitter": "David Berend", "authors": "Yushi Cao, David Berend, Palina Tolmach, Guy Amit, Moshe Levy, Yang\n  Liu, Asaf Shabtai, Yuval Elovici", "title": "Out-of-distribution detection and generalization to enhance fairness in\n  age prediction", "comments": "15 pages, 8 Figures, pre-print, adjusted title and content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based facial recognition systems have experienced increased\nmedia attention due to exhibiting unfair behavior. Large enterprises, such as\nIBM, shut down their facial recognition and age prediction systems as a\nconsequence. Age prediction is an especially difficult application with the\nissue of fairness remaining an open research problem (e.g. predicting age for\ndifferent ethnicity equally accurate). One of the main causes of unfair\nbehavior in age prediction methods lies in the distribution and diversity of\nthe training data. In this work, we present two novel approaches for dataset\ncuration and data augmentation in order to increase fairness through\ndistribution aware curation and increase diversity through distribution aware\naugmentation. To achieve this, we created an out-of-distribution technique\nwhich is used to select the data most relevant to the deep neural network's\n(DNN) task when balancing the data among age, ethnicity, and gender. Our\napproach shows promising results. Our best-trained DNN model outperformed all\nacademic and industrial baselines in terms of fairness by up to 4.92 times.\nWhen it comes to generalization, the increase in diversity also enhanced the\nDNN's performance, outperforming state-of-the-art approaches of prior research\non the Age Estimation Benchmark dataset AFAD by 30.40% and the Amazon AWS and\nMicrosoft Azure public cloud systems by 31.88% and 10.95%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:32:36 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 01:14:56 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 05:52:51 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 13:02:48 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Cao", "Yushi", ""], ["Berend", "David", ""], ["Tolmach", "Palina", ""], ["Amit", "Guy", ""], ["Levy", "Moshe", ""], ["Liu", "Yang", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2009.05303", "submitter": "Weijian Chen", "authors": "Weijian Chen, Fuli Feng, Qifan Wang, Xiangnan He, Chonggang Song,\n  Guohui Ling, Yongdong Zhang", "title": "CatGCN: Graph Convolutional Networks with Categorical Node Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on Graph Convolutional Networks (GCNs) reveal that the initial\nnode representations (i.e., the node representations before the first-time\ngraph convolution) largely affect the final model performance. However, when\nlearning the initial representation for a node, most existing work linearly\ncombines the embeddings of node features, without considering the interactions\namong the features (or feature embeddings). We argue that when the node\nfeatures are categorical, e.g., in many real-world applications like user\nprofiling and recommender system, feature interactions usually carry important\nsignals for predictive analytics. Ignoring them will result in suboptimal\ninitial node representation and thus weaken the effectiveness of the follow-up\ngraph convolution. In this paper, we propose a new GCN model named CatGCN,\nwhich is tailored for graph learning when the node features are categorical.\nSpecifically, we integrate two ways of explicit interaction modeling into the\nlearning of initial node representation, i.e., local interaction modeling on\neach pair of node features and global interaction modeling on an artificial\nfeature graph. We then refine the enhanced initial node representations with\nthe neighborhood aggregation-based graph convolution. We train CatGCN in an\nend-to-end fashion and demonstrate it on semi-supervised node classification.\nExtensive experiments on three tasks of user profiling (the prediction of user\nage, city, and purchase level) from Tencent and Alibaba datasets validate the\neffectiveness of CatGCN, especially the positive effect of performing feature\ninteraction modeling before graph convolution.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 09:25:17 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 07:41:55 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Chen", "Weijian", ""], ["Feng", "Fuli", ""], ["Wang", "Qifan", ""], ["He", "Xiangnan", ""], ["Song", "Chonggang", ""], ["Ling", "Guohui", ""], ["Zhang", "Yongdong", ""]]}, {"id": "2009.05322", "submitter": "Aditya Lahiri", "authors": "Aditya Lahiri, Narayanan Unny Edakunni", "title": "Accurate and Intuitive Contextual Explanations using Linear Model Trees", "comments": "KDD Workshop on ML in Finance 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing use of complex machine learning models in critical\napplications within the finance domain, explaining the decisions of the model\nhas become a necessity. With applications spanning from credit scoring to\ncredit marketing, the impact of these models is undeniable. Among the multiple\nways in which one can explain the decisions of these complicated models, local\npost hoc model agnostic explanations have gained massive adoption. These\nmethods allow one to explain each prediction independent of the modelling\ntechnique that was used while training. As explanations, they either give\nindividual feature attributions or provide sufficient rules that represent\nconditions for a prediction to be made. The current state of the art methods\nuse rudimentary methods to generate synthetic data around the point to be\nexplained. This is followed by fitting simple linear models as surrogates to\nobtain a local interpretation of the prediction. In this paper, we seek to\nsignificantly improve on both, the method used to generate the explanations and\nthe nature of explanations produced. We use a Generative Adversarial Network\nfor synthetic data generation and train a piecewise linear model in the form of\nLinear Model Trees to be used as the surrogate model.In addition to individual\nfeature attributions, we also provide an accompanying context to our\nexplanations by leveraging the structure and property of our surrogate model.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 10:13:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Lahiri", "Aditya", ""], ["Edakunni", "Narayanan Unny", ""]]}, {"id": "2009.05326", "submitter": "Francesco Da Ros", "authors": "Francesco Da Ros, Uiara Celine de Moura, and Metodi P. Yankov", "title": "Machine learning-based EDFA Gain Model Generalizable to Multiple\n  Physical Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a neural-network based erbium-doped fiber amplifier (EDFA) gain\nmodel built from experimental measurements. The model shows low gain-prediction\nerror for both the same device used for training (MSE $\\leq$ 0.04 dB$^2$) and\ndifferent physical units of the same make (generalization MSE $\\leq$ 0.06\ndB$^2$).\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 10:23:56 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Da Ros", "Francesco", ""], ["de Moura", "Uiara Celine", ""], ["Yankov", "Metodi P.", ""]]}, {"id": "2009.05346", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo and Yang Gao", "title": "Disentangling Neural Architectures and Weights: A Case Study in\n  Supervised Classification", "comments": "22 pages and 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The history of deep learning has shown that human-designed problem-specific\nnetworks can greatly improve the classification performance of general neural\nmodels. In most practical cases, however, choosing the optimal architecture for\na given task remains a challenging problem. Recent architecture-search methods\nare able to automatically build neural models with strong performance but fail\nto fully appreciate the interaction between neural architecture and weights.\nThis work investigates the problem of disentangling the role of the neural\nstructure and its edge weights, by showing that well-trained architectures may\nnot need any link-specific fine-tuning of the weights. We compare the\nperformance of such weight-free networks (in our case these are binary networks\nwith {0, 1}-valued weights) with random, weight-agnostic, pruned and standard\nfully connected networks. To find the optimal weight-agnostic network, we use a\nnovel and computationally efficient method that translates the hard\narchitecture-search problem into a feasible optimization problem.More\nspecifically, we look at the optimal task-specific architectures as the optimal\nconfiguration of binary networks with {0, 1}-valued weights, which can be found\nthrough an approximate gradient descent strategy. Theoretical convergence\nguarantees of the proposed algorithm are obtained by bounding the error in the\ngradient approximation and its practical performance is evaluated on two\nreal-world data sets. For measuring the structural similarities between\ndifferent architectures, we use a novel spectral approach that allows us to\nunderline the intrinsic differences between real-valued networks and\nweight-free architectures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:22:22 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Colombo", "Nicolo", ""], ["Gao", "Yang", ""]]}, {"id": "2009.05348", "submitter": "Metodi Yankov", "authors": "Metodi P. Yankov, Uiara Celine de Moura, Francesco Da Ros", "title": "Power Evolution Prediction and Optimization in a Multi-span System Based\n  on Component-wise System Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascades of a machine learning-based EDFA gain model trained on a single\nphysical device and a fully differentiable stimulated Raman scattering fiber\nmodel are used to predict and optimize the power profile at the output of an\nexperimental multi-span fully-loaded C-band optical communication system.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:26:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Yankov", "Metodi P.", ""], ["de Moura", "Uiara Celine", ""], ["Da Ros", "Francesco", ""]]}, {"id": "2009.05353", "submitter": "Gabriel Dahia", "authors": "Gabriel Dahia, Maur\\'icio Pamplona Segundo", "title": "Meta Learning for Few-Shot One-class Classification", "comments": null, "journal-ref": null, "doi": "10.3390/ai2020012", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that can perform one-class classification given only a\nsmall number of examples from the target class and none from the others. We\nformulate the learning of meaningful features for one-class classification as a\nmeta-learning problem in which the meta-training stage repeatedly simulates\none-class classification, using the classification loss of the chosen algorithm\nto learn a feature representation. To learn these representations, we require\nonly multiclass data from similar tasks. We show how the Support Vector Data\nDescription method can be used with our method, and also propose a simpler\nvariant based on Prototypical Networks that obtains comparable performance,\nindicating that learning feature representations directly from data may be more\nimportant than which one-class algorithm we choose. We validate our approach by\nadapting few-shot classification datasets to the few-shot one-class\nclassification scenario, obtaining similar results to the state-of-the-art of\ntraditional one-class classification, and that improves upon that of one-class\nclassification baselines employed in the few-shot setting. Our code is\navailable at https://github.com/gdahia/meta_occ\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:35:28 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 12:13:17 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Dahia", "Gabriel", ""], ["Segundo", "Maur\u00edcio Pamplona", ""]]}, {"id": "2009.05359", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil K Seth, Christopher L Buckley", "title": "Activation Relaxation: A Local Dynamical Approximation to\n  Backpropagation in the Brain", "comments": "initial upload; revised version (updated abstract, related work)\n  28-09-20; 05/10/20: revised for ICLR submission; 10/10/20: minor revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation of error algorithm (backprop) has been instrumental in\nthe recent success of deep learning. However, a key question remains as to\nwhether backprop can be formulated in a manner suitable for implementation in\nneural circuitry. The primary challenge is to ensure that any candidate\nformulation uses only local information, rather than relying on global signals\nas in standard backprop. Recently several algorithms for approximating backprop\nusing only local signals have been proposed. However, these algorithms\ntypically impose other requirements which challenge biological plausibility:\nfor example, requiring complex and precise connectivity schemes, or multiple\nsequential backwards phases with information being stored across phases. Here,\nwe propose a novel algorithm, Activation Relaxation (AR), which is motivated by\nconstructing the backpropagation gradient as the equilibrium point of a\ndynamical system. Our algorithm converges rapidly and robustly to the correct\nbackpropagation gradients, requires only a single type of computational unit,\nutilises only a single parallel backwards relaxation phase, and can operate on\narbitrary computation graphs. We illustrate these properties by training deep\nneural networks on visual classification tasks, and describe simplifications to\nthe algorithm which remove further obstacles to neurobiological implementation\n(for example, the weight-transport problem, and the use of nonlinear\nderivatives), while preserving performance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:56:34 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 10:37:05 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 21:19:22 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 18:21:01 GMT"}, {"version": "v5", "created": "Sat, 10 Oct 2020 14:16:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil K", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2009.05369", "submitter": "Franz G\\\"otz-Hahn", "authors": "Franz G\\\"otz-Hahn and Vlad Hosu and Dietmar Saupe", "title": "Critical analysis on the reproducibility of visual quality assessment\n  using deep features", "comments": "27 pages, 8 figures, PLOS ONE journal. arXiv admin note: text overlap\n  with arXiv:2005.04400", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data used to train supervised machine learning models are commonly split into\nindependent training, validation, and test sets. This paper illustrates that\ncomplex data leakage cases have occurred in the no-reference image and video\nquality assessment literature. Recently, papers in several journals reported\nperformance results well above the best in the field. However, our analysis\nshows that information from the test set was inappropriately used in the\ntraining process in different ways and that the claimed performance results\ncannot be achieved. When correcting for the data leakage, the performances of\nthe approaches drop even below the state-of-the-art by a large margin.\nAdditionally, we investigate end-to-end variations to the discussed approaches,\nwhich do not improve upon the original.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:51:18 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 09:28:44 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 10:59:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["G\u00f6tz-Hahn", "Franz", ""], ["Hosu", "Vlad", ""], ["Saupe", "Dietmar", ""]]}, {"id": "2009.05383", "submitter": "Alexander Wong", "authors": "Hayden Gunraj, Linda Wang, and Alexander Wong", "title": "COVIDNet-CT: A Tailored Deep Convolutional Neural Network Design for\n  Detection of COVID-19 Cases from Chest CT Images", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease 2019 (COVID-19) pandemic continues to have a\ntremendous impact on patients and healthcare systems around the world. In the\nfight against this novel disease, there is a pressing need for rapid and\neffective screening tools to identify patients infected with COVID-19, and to\nthis end CT imaging has been proposed as one of the key screening methods which\nmay be used as a complement to RT-PCR testing, particularly in situations where\npatients undergo routine CT scans for non-COVID-19 related reasons, patients\nwith worsening respiratory status or developing complications that require\nexpedited care, and patients suspected to be COVID-19-positive but have\nnegative RT-PCR test results. Motivated by this, in this study we introduce\nCOVIDNet-CT, a deep convolutional neural network architecture that is tailored\nfor detection of COVID-19 cases from chest CT images via a machine-driven\ndesign exploration approach. Additionally, we introduce COVIDx-CT, a benchmark\nCT image dataset derived from CT imaging data collected by the China National\nCenter for Bioinformation comprising 104,009 images across 1,489 patient cases.\nFurthermore, in the interest of reliability and transparency, we leverage an\nexplainability-driven performance validation strategy to investigate the\ndecision-making behaviour of COVIDNet-CT, and in doing so ensure that\nCOVIDNet-CT makes predictions based on relevant indicators in CT images. Both\nCOVIDNet-CT and the COVIDx-CT dataset are available to the general public in an\nopen-source and open access manner as part of the COVID-Net initiative. While\nCOVIDNet-CT is not yet a production-ready screening solution, we hope that\nreleasing the model and dataset will encourage researchers, clinicians, and\ncitizen data scientists alike to leverage and build upon them.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:49:55 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Gunraj", "Hayden", ""], ["Wang", "Linda", ""], ["Wong", "Alexander", ""]]}, {"id": "2009.05400", "submitter": "Awais Ahmed Mr", "authors": "Yasir Nadeem, Awais Ahmed", "title": "Machine Learning and Data Science approach towards trend and predictors\n  analysis of CDC Mortality Data for the USA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on mortality is an active area of research for any country where\nthe conclusions are driven from the provided data and conditions. The domain\nknowledge is an essential but not a mandatory skill (though some knowledge is\nstill required) in order to derive conclusions based on data intuition using\nmachine learning and data science practices. The purpose of conducting this\nproject was to derive conclusions based on the statistics from the provided\ndataset and predict label(s) of the dataset using supervised or unsupervised\nlearning algorithms. The study concluded (based on a sample) life expectancy\nregardless of gender, and their central tendencies; Marital status of the\npeople also affected how frequent deaths were for each of them. The study also\nhelped in finding out that due to more categorical and numerical data, anomaly\ndetection or under-sampling could be a viable solution since there are\npossibilities of more class labels than the other(s). The study shows that\nmachine learning predictions aren't as viable for the data as it might be\napparent.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:46:57 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nadeem", "Yasir", ""], ["Ahmed", "Awais", ""]]}, {"id": "2009.05403", "submitter": "J\\'er\\'emy Scheurer", "authors": "J\\'er\\'emy Scheurer, Claudio Ferrari, Luis Berenguer Todo Bom,\n  Michaela Beer, Werner Kempf, Luis Haug", "title": "Semantic Segmentation of Histopathological Slides for the Classification\n  of Cutaneous Lymphoma and Eczema", "comments": "Submitted to\n  https://link.springer.com/chapter/10.1007/978-3-030-52791-4_3", "journal-ref": "Papie\\.z B., Namburete A., Yaqub M., Noble J. (eds) Medical Image\n  Understanding and Analysis. MIUA 2020. Communications in Computer and\n  Information Science, vol 1248. Springer, Cham", "doi": "10.1007/978-3-030-52791-4_3", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mycosis fungoides (MF) is a rare, potentially life threatening skin disease,\nwhich in early stages clinically and histologically strongly resembles Eczema,\na very common and benign skin condition. In order to increase the survival\nrate, one needs to provide the appropriate treatment early on. To this end, one\ncrucial step for specialists is the evaluation of histopathological slides\n(glass slides), or Whole Slide Images (WSI), of the patients' skin tissue. We\nintroduce a deep learning aided diagnostics tool that brings a two-fold value\nto the decision process of pathologists. First, our algorithm accurately\nsegments WSI into regions that are relevant for an accurate diagnosis,\nachieving a Mean-IoU of 69% and a Matthews Correlation score of 83% on a novel\ndataset. Additionally, we also show that our model is competitive with the\nstate of the art on a reference dataset. Second, using the segmentation map and\nthe original image, we are able to predict if a patient has MF or Eczema. We\ncreated two models that can be applied in different stages of the diagnostic\npipeline, potentially eliminating life-threatening mistakes. The classification\noutcome is considerably more interpretable than using only the WSI as the\ninput, since it is also based on the segmentation map. Our segmentation model,\nwhich we call EU-Net, extends a classical U-Net with an EfficientNet-B7 encoder\nwhich was pre-trained on the Imagenet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:49:38 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Scheurer", "J\u00e9r\u00e9my", ""], ["Ferrari", "Claudio", ""], ["Bom", "Luis Berenguer Todo", ""], ["Beer", "Michaela", ""], ["Kempf", "Werner", ""], ["Haug", "Luis", ""]]}, {"id": "2009.05407", "submitter": "Taeheon Lee", "authors": "Taeheon Lee, Jeonghwan Hwang, Honggu Lee", "title": "TRIER: Template-Guided Neural Networks for Robust and Interpretable\n  Sleep Stage Identification from EEG Recordings", "comments": "10 pages, 5 figures, written in cikm format", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks often obtain sub-optimal representations during training,\nwhich degrade robustness as well as classification performances. This is a\nsevere problem in applying deep learning to bio-medical domains, since models\nare vulnerable to being harmed by irregularities and scarcities in data. In\nthis study, we propose a pre-training technique that handles this challenge in\nsleep staging tasks. Inspired by conventional methods that experienced\nphysicians have used to classify sleep states from the existence of\ncharacteristic waveform shapes, or template patterns, our method introduces a\ncosine similarity based convolutional neural network to extract representative\nwaveforms from training data. Afterwards, these features guide a model to\nconstruct representations based on template patterns. Through extensive\nexperiments, we demonstrated that guiding a neural network with template\npatterns is an effective approach for sleep staging, since (1) classification\nperformances are significantly enhanced and (2) robustness in several aspects\nare improved. Last but not least, interpretations on models showed that notable\nfeatures exploited by trained experts are correctly addressed during prediction\nin the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 01:58:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Lee", "Taeheon", ""], ["Hwang", "Jeonghwan", ""], ["Lee", "Honggu", ""]]}, {"id": "2009.05418", "submitter": "Calum Hand", "authors": "James Hook, Calum Hand, Emma Whitfield", "title": "Bayesian Screening: Multi-test Bayesian Optimization Applied to in\n  silico Material Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present new multi-test Bayesian optimization models and algorithms for use\nin large scale material screening applications. Our screening problems are\ndesigned around two tests, one expensive and one cheap. This paper differs from\nother recent work on multi-test Bayesian optimization through use of a flexible\nmodel that allows for complex, non-linear relationships between the cheap and\nexpensive test scores. This additional modeling flexibility is essential in the\nmaterial screening applications which we describe. We demonstrate the power of\nour new algorithms on a family of synthetic toy problems as well as on real\ndata from two large scale screening studies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:07:51 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Hook", "James", ""], ["Hand", "Calum", ""], ["Whitfield", "Emma", ""]]}, {"id": "2009.05423", "submitter": "Ningyi Liao", "authors": "Shufan Wang, Ningyi Liao, Liyao Xiang, Nanyang Ye, Quanshi Zhang", "title": "Achieving Adversarial Robustness via Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning has been known to produce compact models without much\naccuracy degradation. However, how the pruning process affects a network's\nrobustness and the working mechanism behind remain unresolved. In this work, we\ntheoretically prove that the sparsity of network weights is closely associated\nwith model robustness. Through experiments on a variety of adversarial pruning\nmethods, we find that weights sparsity will not hurt but improve robustness,\nwhere both weights inheritance from the lottery ticket and adversarial training\nimprove model robustness in network pruning. Based on these findings, we\npropose a novel adversarial training method called inverse weights inheritance,\nwhich imposes sparse weights distribution on a large network by inheriting\nweights from a small network, thereby improving the robustness of the large\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:15:43 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Wang", "Shufan", ""], ["Liao", "Ningyi", ""], ["Xiang", "Liyao", ""], ["Ye", "Nanyang", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2009.05436", "submitter": "Lei Liu", "authors": "Lei Liu, Wentao Lei, Yongfang Luo, Cheng Feng, Xiang Wan, Li Liu", "title": "Semi-Supervised Active Learning for COVID-19 Lung Ultrasound\n  Multi-symptom Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is a non-invasive yet effective medical diagnostic imaging\ntechnique for the COVID-19 global pandemic. However, due to complex feature\nbehaviors and expensive annotations of US images, it is difficult to apply\nArtificial Intelligence (AI) assisting approaches for lung's multi-symptom\n(multi-label) classification. To overcome these difficulties, we propose a\nnovel semi-supervised Two-Stream Active Learning (TSAL) method to model\ncomplicated features and reduce labeling costs in an iterative procedure. The\ncore component of TSAL is the multi-label learning mechanism, in which label\ncorrelations information is used to design multi-label margin (MLM) strategy\nand confidence validation for automatically selecting informative samples and\nconfident labels. On this basis, a multi-symptom multi-label (MSML)\nclassification network is proposed to learn discriminative features of lung\nsymptoms, and a human-machine interaction is exploited to confirm the final\nannotations that are used to fine-tune MSML with progressively labeled data.\nMoreover, a novel lung US dataset named COVID19-LUSMS is built, currently\ncontaining 71 clinical patients with 6,836 images sampled from 678 videos.\nExperimental evaluations show that TSAL using only 20% data can achieve\nsuperior performance to the baseline and the state-of-the-art. Qualitatively,\nvisualization of both attention map and sample distribution confirms the good\nconsistency with the clinic knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:45:34 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 08:47:52 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Liu", "Lei", ""], ["Lei", "Wentao", ""], ["Luo", "Yongfang", ""], ["Feng", "Cheng", ""], ["Wan", "Xiang", ""], ["Liu", "Li", ""]]}, {"id": "2009.05438", "submitter": "Ghada El-Khawaga", "authors": "Ghada Elkhawaga, Mervat Abuelkheir, Sherif I. Barakat, Alaa M. Riad\n  and Manfred Reichert", "title": "CONDA-PM -- A Systematic Review and Framework for Concept Drift Analysis\n  in Process Mining", "comments": "45 pages, 11 tables, 13 figures", "journal-ref": "Algorithms 2020, 13(7), 161", "doi": "10.3390/a13070161", "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business processes evolve over time to adapt to changing business\nenvironments. This requires continuous monitoring of business processes to gain\ninsights into whether they conform to the intended design or deviate from it.\nThe situation when a business process changes while being analysed is denoted\nas Concept Drift. Its analysis is concerned with studying how a business\nprocess changes, in terms of detecting and localising changes and studying the\neffects of the latter. Concept drift analysis is crucial to enable early\ndetection and management of changes, that is, whether to promote a change to\nbecome part of an improved process, or to reject the change and make decisions\nto mitigate its effects. Despite its importance, there exists no comprehensive\nframework for analysing concept drift types, affected process perspectives, and\ngranularity levels of a business process. This article proposes the CONcept\nDrift Analysis in Process Mining (CONDA-PM) framework describing phases and\nrequirements of a concept drift analysis approach. CONDA-PM was derived from a\nSystematic Literature Review (SLR) of current approaches analysing concept\ndrift. We apply the CONDA-PM framework on current approaches to concept drift\nanalysis and evaluate their maturity. Applying CONDA-PM framework highlights\nareas where research is needed to complement existing efforts.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:39:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Elkhawaga", "Ghada", ""], ["Abuelkheir", "Mervat", ""], ["Barakat", "Sherif I.", ""], ["Riad", "Alaa M.", ""], ["Reichert", "Manfred", ""]]}, {"id": "2009.05440", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Joy Arulraj, Calton Pu, Joao Ferreira", "title": "ODIN: Automated Drift Detection and Recovery in Video Analytics", "comments": null, "journal-ref": "PVLDB, 13(11):2453-2465, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computer vision have led to a resurgence of interest in\nvisual data analytics. Researchers are developing systems for effectively and\nefficiently analyzing visual data at scale. A significant challenge that these\nsystems encounter lies in the drift in real-world visual data. For instance, a\nmodel for self-driving vehicles that is not trained on images containing snow\ndoes not work well when it encounters them in practice. This drift phenomenon\nlimits the accuracy of models employed for visual data analytics. In this\npaper, we present a visual data analytics system, called ODIN, that\nautomatically detects and recovers from drift. ODIN uses adversarial\nautoencoders to learn the distribution of high-dimensional images. We present\nan unsupervised algorithm for detecting drift by comparing the distributions of\nthe given data against that of previously seen data. When ODIN detects drift,\nit invokes a drift recovery algorithm to deploy specialized models tailored\ntowards the novel data points. These specialized models outperform their\nnon-specialized counterpart on accuracy, performance, and memory footprint.\nLastly, we present a model selection algorithm for picking an ensemble of\nbest-fit specialized models to process a given input. We evaluate the efficacy\nand efficiency of ODIN on high-resolution dashboard camera videos captured\nunder diverse environments from the Berkeley DeepDrive dataset. We demonstrate\nthat ODIN's models deliver 6x higher throughput, 2x higher accuracy, and 6x\nsmaller memory footprint compared to a baseline system without automated drift\ndetection and recovery.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 12:13:40 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Suprem", "Abhijit", ""], ["Arulraj", "Joy", ""], ["Pu", "Calton", ""], ["Ferreira", "Joao", ""]]}, {"id": "2009.05451", "submitter": "Aysu Can", "authors": "Aysu Ezen-Can", "title": "A Comparison of LSTM and BERT for Small Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in the NLP field showed that transfer learning helps with\nachieving state-of-the-art results for new tasks by tuning pre-trained models\ninstead of starting from scratch. Transformers have made a significant\nimprovement in creating new state-of-the-art results for many NLP tasks\nincluding but not limited to text classification, text generation, and sequence\nlabeling. Most of these success stories were based on large datasets. In this\npaper we focus on a real-life scenario that scientists in academia and industry\nface frequently: given a small dataset, can we use a large pre-trained model\nlike BERT and get better results than simple models? To answer this question,\nwe use a small dataset for intent classification collected for building\nchatbots and compare the performance of a simple bidirectional LSTM model with\na pre-trained BERT model. Our experimental results show that bidirectional LSTM\nmodels can achieve significantly higher results than a BERT model for a small\ndataset and these simple models get trained in much less time than tuning the\npre-trained counterparts. We conclude that the performance of a model is\ndependent on the task and the data, and therefore before making a model choice,\nthese factors should be taken into consideration instead of directly choosing\nthe most popular model.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:01:14 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ezen-Can", "Aysu", ""]]}, {"id": "2009.05473", "submitter": "Jean-Baptiste Courbot", "authors": "Jean-Baptiste Courbot and Bruno Colicchio", "title": "Boosting the Sliding Frank-Wolfe solver for 3D deconvolution", "comments": "in Proceedings of iTWIST'20, Paper-ID: 08, Nantes, France, December,\n  2-4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of gridless sparse optimization, the Sliding Frank Wolfe\nalgorithm recently introduced has shown interesting analytical and practical\nproperties. Nevertheless, is application to large data, such as in the case of\n3D deconvolution, is computationally heavy. In this paper, we investigate a\nstrategy for leveraging this burden, in order to make this method more\ntractable for 3D deconvolution. We show that a boosted SFW can achieve the same\nresults in a significantly reduced amount of time.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:48:38 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Courbot", "Jean-Baptiste", ""], ["Colicchio", "Bruno", ""]]}, {"id": "2009.05474", "submitter": "Antonio Emanuele Cin\\`a", "authors": "Antonio Emanuele Cin\\`a, Alessandro Torcinovich, Marcello Pelillo", "title": "A Black-box Adversarial Attack for Poisoning Clustering", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms play a fundamental role as tools in decision-making and\nsensible automation processes. Due to the widespread use of these applications,\na robustness analysis of this family of algorithms against adversarial noise\nhas become imperative. To the best of our knowledge, however, only a few works\nhave currently addressed this problem. In an attempt to fill this gap, in this\nwork, we propose a black-box adversarial attack for crafting adversarial\nsamples to test the robustness of clustering algorithms. We formulate the\nproblem as a constrained minimization program, general in its structure and\ncustomizable by the attacker according to her capability constraints. We do not\nassume any information about the internal structure of the victim clustering\nalgorithm, and we allow the attacker to query it as a service only. In the\nabsence of any derivative information, we perform the optimization with a\ncustom approach inspired by the Abstract Genetic Algorithm (AGA). In the\nexperimental part, we demonstrate the sensibility of different single and\nensemble clustering algorithms against our crafted adversarial samples on\ndifferent scenarios. Furthermore, we perform a comparison of our algorithm with\na state-of-the-art approach showing that we are able to reach or even\noutperform its performance. Finally, to highlight the general nature of the\ngenerated noise, we show that our attacks are transferable even against\nsupervised algorithms such as SVMs, random forests and neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:19:31 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Cin\u00e0", "Antonio Emanuele", ""], ["Torcinovich", "Alessandro", ""], ["Pelillo", "Marcello", ""]]}, {"id": "2009.05475", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau, R\\'emi Pich\\'e-Taillefer, R\\'emi Tachet\n  des Combes, Ioannis Mitliagkas", "title": "Adversarial score matching and improved sampling for image generation", "comments": "Code at\n  https://github.com/AlexiaJM/AdversarialConsistentScoreMatching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising Score Matching with Annealed Langevin Sampling (DSM-ALS) has\nrecently found success in generative modeling. The approach works by first\ntraining a neural network to estimate the score of a distribution, and then\nusing Langevin dynamics to sample from the data distribution assumed by the\nscore network. Despite the convincing visual quality of samples, this method\nappears to perform worse than Generative Adversarial Networks (GANs) under the\nFr\\'echet Inception Distance, a standard metric for generative models.\n  We show that this apparent gap vanishes when denoising the final Langevin\nsamples using the score network. In addition, we propose two improvements to\nDSM-ALS: 1) Consistent Annealed Sampling as a more stable alternative to\nAnnealed Langevin Sampling, and 2) a hybrid training formulation, composed of\nboth Denoising Score Matching and adversarial objectives. By combining these\ntwo techniques and exploring different network architectures, we elevate score\nmatching methods and obtain results competitive with state-of-the-art image\ngeneration on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:49:53 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 19:47:12 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""], ["Pich\u00e9-Taillefer", "R\u00e9mi", ""], ["Combes", "R\u00e9mi Tachet des", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "2009.05478", "submitter": "Long Feng", "authors": "Long Feng and Junhui Wang", "title": "Projected Robust PCA with Application to Smooth Image Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most high-dimensional matrix recovery problems are studied under the\nassumption that the target matrix has certain intrinsic structures. For image\ndata related matrix recovery problems, approximate low-rankness and smoothness\nare the two most commonly imposed structures. For approximately low-rank matrix\nrecovery, the robust principal component analysis (PCA) is well-studied and\nproved to be effective. For smooth matrix problem, 2d fused Lasso and other\ntotal variation based approaches have played a fundamental role. Although both\nlow-rankness and smoothness are key assumptions for image data analysis, the\ntwo lines of research, however, have very limited interaction. Motivated by\ntaking advantage of both features, we in this paper develop a framework named\nprojected robust PCA (PRPCA), under which the low-rank matrices are projected\nonto a space of smooth matrices. Consequently, a large class of image matrices\ncan be decomposed as a low-rank and smooth component plus a sparse component. A\nkey advantage of this decomposition is that the dimension of the core low-rank\ncomponent can be significantly reduced. Consequently, our framework is able to\naddress a problematic bottleneck of many low-rank matrix problems: singular\nvalue decomposition (SVD) on large matrices. Theoretically, we provide explicit\nstatistical recovery guarantees of PRPCA and include classical robust PCA as a\nspecial case.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 11:23:30 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 12:45:27 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Feng", "Long", ""], ["Wang", "Junhui", ""]]}, {"id": "2009.05483", "submitter": "Francesco Alesiani", "authors": "Francesco Alesiani, Shujian Yu, Ammar Shaker and Wenzhe Yin", "title": "Towards Interpretable Multi-Task Learning Using Bilevel Programming", "comments": "Manuscript accepted at ECML PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable Multi-Task Learning can be expressed as learning a sparse graph\nof the task relationship based on the prediction performance of the learned\nmodels. Since many natural phenomenon exhibit sparse structures, enforcing\nsparsity on learned models reveals the underlying task relationship. Moreover,\ndifferent sparsification degrees from a fully connected graph uncover various\ntypes of structures, like cliques, trees, lines, clusters or fully disconnected\ngraphs. In this paper, we propose a bilevel formulation of multi-task learning\nthat induces sparse graphs, thus, revealing the underlying task relationships,\nand an efficient method for its computation. We show empirically how the\ninduced sparse graph improves the interpretability of the learned models and\ntheir relationship on synthetic and real data, without sacrificing\ngeneralization performance. Code at https://bit.ly/GraphGuidedMTL\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:04:27 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Alesiani", "Francesco", ""], ["Yu", "Shujian", ""], ["Shaker", "Ammar", ""], ["Yin", "Wenzhe", ""]]}, {"id": "2009.05484", "submitter": "Laura Nenzi", "authors": "Luca Bortolussi, Giuseppe Maria Gallo and Laura Nenzi", "title": "A kernel function for Signal Temporal Logic formulae", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how to define a kernel for Signal Temporal Logic (STL) formulae.\nSuch a kernel allows us to embed the space of formulae into a Hilbert space,\nand opens up the use of kernel-based machine learning algorithms in the context\nof STL. We show an application of this idea to a regression problem in formula\nspace for probabilistic models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:06:25 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Bortolussi", "Luca", ""], ["Gallo", "Giuseppe Maria", ""], ["Nenzi", "Laura", ""]]}, {"id": "2009.05487", "submitter": "Timo Freiesleben", "authors": "Timo Freiesleben", "title": "Counterfactual Explanations & Adversarial Examples -- Common Grounds,\n  Essential Differences, and Potential Transfers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The same optimization problem underlies counterfactual explanations (CEs) and\nadversarial examples (AEs). While this is well known, the relationship between\nthe two at the conceptual level remains unclear. The present paper provides\nexactly the missing conceptual link. We compare CEs and AEs with respect to\ntheir philosophical basis, aims, and modeling techniques. We argue that CEs are\na more general object-class than AEs. In particular, we introduce the\nconceptual distinction between feasible and contesting CEs and show that AEs\ncorrespond to the latter.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:09:12 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 10:05:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Freiesleben", "Timo", ""]]}, {"id": "2009.05501", "submitter": "Divish Rengasamy", "authors": "Divish Rengasamy, Benjamin Rothwell, Grazziela Figueredo", "title": "Towards a More Reliable Interpretation of Machine Learning Outputs for\n  Safety-Critical Systems using Feature Importance Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When machine learning supports decision-making in safety-critical systems, it\nis important to verify and understand the reasons why a particular output is\nproduced. Although feature importance calculation approaches assist in\ninterpretation, there is a lack of consensus regarding how features' importance\nis quantified, which makes the explanations offered for the outcomes mostly\nunreliable. A possible solution to address the lack of agreement is to combine\nthe results from multiple feature importance quantifiers to reduce the variance\nof estimates. Our hypothesis is that this will lead to more robust and\ntrustworthy interpretations of the contribution of each feature to machine\nlearning predictions. To assist test this hypothesis, we propose an extensible\nFramework divided in four main parts: (i) traditional data pre-processing and\npreparation for predictive machine learning models; (ii) predictive machine\nlearning; (iii) feature importance quantification and (iv) feature importance\ndecision fusion using an ensemble strategy. We also introduce a novel fusion\nmetric and compare it to the state-of-the-art. Our approach is tested on\nsynthetic data, where the ground truth is known. We compare different fusion\napproaches and their results for both training and test sets. We also\ninvestigate how different characteristics within the datasets affect the\nfeature importance ensembles studied. Results show that our feature importance\nensemble Framework overall produces 15% less feature importance error compared\nto existing methods. Additionally, results reveal that different levels of\nnoise in the datasets do not affect the feature importance ensembles' ability\nto accurately quantify feature importance, whereas the feature importance\nquantification error increases with the number of features and number of\northogonal informative features.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:51:52 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Rengasamy", "Divish", ""], ["Rothwell", "Benjamin", ""], ["Figueredo", "Grazziela", ""]]}, {"id": "2009.05502", "submitter": "Johannes Knittel", "authors": "Johannes Knittel, Andres Lalama, Steffen Koch, and Thomas Ertl", "title": "Visual Neural Decomposition to Explain Multivariate Data Sets", "comments": "To appear in IEEE Transactions on Visualization and Computer Graphics\n  and IEEE VIS 2020 (VAST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigating relationships between variables in multi-dimensional data sets\nis a common task for data analysts and engineers. More specifically, it is\noften valuable to understand which ranges of which input variables lead to\nparticular values of a given target variable. Unfortunately, with an increasing\nnumber of independent variables, this process may become cumbersome and\ntime-consuming due to the many possible combinations that have to be explored.\nIn this paper, we propose a novel approach to visualize correlations between\ninput variables and a target output variable that scales to hundreds of\nvariables. We developed a visual model based on neural networks that can be\nexplored in a guided way to help analysts find and understand such\ncorrelations. First, we train a neural network to predict the target from the\ninput variables. Then, we visualize the inner workings of the resulting model\nto help understand relations within the data set. We further introduce a new\nregularization term for the backpropagation algorithm that encourages the\nneural network to learn representations that are easier to interpret visually.\nWe apply our method to artificial and real-world data sets to show its utility.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:53:37 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Knittel", "Johannes", ""], ["Lalama", "Andres", ""], ["Koch", "Steffen", ""], ["Ertl", "Thomas", ""]]}, {"id": "2009.05516", "submitter": "Andreas Groll", "authors": "Alexander Gerharz, Andreas Groll, Gunther Schauberger", "title": "Deducing neighborhoods of classes from a fitted model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays world the request for very complex models for huge data sets is\nrising steadily. The problem with these models is that by raising the\ncomplexity of the models, it gets much harder to interpret them. The growing\nfield of \\emph{interpretable machine learning} tries to make up for the lack of\ninterpretability in these complex (or even blackbox-)models by using specific\ntechniques that can help to understand those models better. In this article a\nnew kind of interpretable machine learning method is presented, which can help\nto understand the partitioning of the feature space into predicted classes in a\nclassification model using quantile shifts. To illustrate in which situations\nthis quantile shift method (QSM) could become beneficial, it is applied to a\ntheoretical medical example and a real data example. Basically, real data\npoints (or specific points of interest) are used and the changes of the\nprediction after slightly raising or decreasing specific features are observed.\nBy comparing the predictions before and after the manipulations, under certain\nconditions the observed changes in the predictions can be interpreted as\nneighborhoods of the classes with regard to the manipulated features.\nChordgraphs are used to visualize the observed changes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 16:35:53 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:47:20 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Gerharz", "Alexander", ""], ["Groll", "Andreas", ""], ["Schauberger", "Gunther", ""]]}, {"id": "2009.05524", "submitter": "Arthur Guez", "authors": "Mehdi Mirza, Andrew Jaegle, Jonathan J. Hunt, Arthur Guez, Saran\n  Tunyasuvunakool, Alistair Muldal, Th\\'eophane Weber, Peter Karkus,\n  S\\'ebastien Racani\\`ere, Lars Buesing, Timothy Lillicrap, Nicolas Heess", "title": "Physically Embedded Planning Problems: New Challenges for Reinforcement\n  Learning", "comments": "17 pages + appendix. Updated text and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in deep reinforcement learning (RL) has produced algorithms\ncapable of mastering challenging games such as Go, chess, or shogi. In these\nworks the RL agent directly observes the natural state of the game and controls\nthat state directly with its actions. However, when humans play such games,\nthey do not just reason about the moves but also interact with their physical\nenvironment. They understand the state of the game by looking at the physical\nboard in front of them and modify it by manipulating pieces using touch and\nfine-grained motor control. Mastering complicated physical systems with\nabstract goals is a central challenge for artificial intelligence, but it\nremains out of reach for existing RL algorithms. To encourage progress towards\nthis goal we introduce a set of physically embedded planning problems and make\nthem publicly available. We embed challenging symbolic tasks (Sokoban,\ntic-tac-toe, and Go) in a physics engine to produce a set of tasks that require\nperception, reasoning, and motor control over long time horizons. Although\nexisting RL algorithms can tackle the symbolic versions of these tasks, we find\nthat they struggle to master even the simplest of their physically embedded\ncounterparts. As a first step towards characterizing the space of solution to\nthese tasks, we introduce a strong baseline that uses a pre-trained expert game\nplayer to provide hints in the abstract space to an RL agent's policy while\ntraining it on the full sensorimotor control task. The resulting agent solves\nmany of the tasks, underlining the need for methods that bridge the gap between\nabstract planning and embodied control. See illustrating video at\nhttps://youtu.be/RwHiHlym_1k.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 16:56:33 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:28:38 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Mirza", "Mehdi", ""], ["Jaegle", "Andrew", ""], ["Hunt", "Jonathan J.", ""], ["Guez", "Arthur", ""], ["Tunyasuvunakool", "Saran", ""], ["Muldal", "Alistair", ""], ["Weber", "Th\u00e9ophane", ""], ["Karkus", "Peter", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Buesing", "Lars", ""], ["Lillicrap", "Timothy", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.05527", "submitter": "Huy Phan", "authors": "Huy Phan, Lam Pham, Philipp Koch, Ngoc Q. K. Duong, Ian McLoughlin,\n  Alfred Mertins", "title": "On Multitask Loss Function for Audio Event Detection and Localization", "comments": "Accepted for publication in DCASE 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio event localization and detection (SELD) have been commonly tackled\nusing multitask models. Such a model usually consists of a multi-label event\nclassification branch with sigmoid cross-entropy loss for event activity\ndetection and a regression branch with mean squared error loss for\ndirection-of-arrival estimation. In this work, we propose a multitask\nregression model, in which both (multi-label) event detection and localization\nare formulated as regression problems and use the mean squared error loss\nhomogeneously for model training. We show that the common combination of\nheterogeneous loss functions causes the network to underfit the data whereas\nthe homogeneous mean squared error loss leads to better convergence and\nperformance. Experiments on the development and validation sets of the DCASE\n2020 SELD task demonstrate that the proposed system also outperforms the DCASE\n2020 SELD baseline across all the detection and localization metrics, reducing\nthe overall SELD error (the combined metric) by approximately 10% absolute.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 16:59:03 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Phan", "Huy", ""], ["Pham", "Lam", ""], ["Koch", "Philipp", ""], ["Duong", "Ngoc Q. K.", ""], ["McLoughlin", "Ian", ""], ["Mertins", "Alfred", ""]]}, {"id": "2009.05530", "submitter": "Jonathan Brophy", "authors": "Jonathan Brophy and Daniel Lowd", "title": "TREX: Tree-Ensemble Representer-Point Explanations", "comments": "11 pages, 7 figures, and 4 tables. Submitted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we identify the training examples that contribute most to the\nprediction of a tree ensemble? In this paper, we introduce TREX, an explanation\nsystem that provides instance-attribution explanations for tree ensembles, such\nas random forests and gradient boosted trees. TREX builds on the representer\npoint framework previously developed for explaining deep neural networks. Since\ntree ensembles are non-differentiable, we define a kernel that captures the\nstructure of the specific tree ensemble. By using this kernel in kernel\nlogistic regression or a support vector machine, TREX builds a surrogate model\nthat approximates the original tree ensemble. The weights in the kernel\nexpansion of the surrogate model are used to define the global or local\nimportance of each training example.\n  Our experiments show that TREX's surrogate model accurately approximates the\ntree ensemble; its global importance weights are more effective in dataset\ndebugging than the previous state-of-the-art; its explanations identify the\nmost influential samples better than alternative methods under the remove and\nretrain evaluation framework; it runs orders of magnitude faster than\nalternative methods; and its local explanations can identify and explain errors\ndue to domain mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:06:40 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 04:57:03 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Brophy", "Jonathan", ""], ["Lowd", "Daniel", ""]]}, {"id": "2009.05537", "submitter": "Lichao Sun", "authors": "Lichao Sun, Lingjuan Lyu", "title": "Federated Model Distillation with Noise-Free Differential Privacy", "comments": "accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional federated learning directly averages model weights, which is\nonly possible for collaboration between models with homogeneous architectures.\nSharing prediction instead of weight removes this obstacle and eliminates the\nrisk of white-box inference attacks in conventional federated learning.\nHowever, the predictions from local models are sensitive and would leak\ntraining data privacy to the public. To address this issue, one naive approach\nis adding the differentially private random noise to the predictions, which\nhowever brings a substantial trade-off between privacy budget and model\nperformance. In this paper, we propose a novel framework called FEDMD-NFDP,\nwhich applies a Noise-Free Differential Privacy (NFDP) mechanism into a\nfederated model distillation framework. Our extensive experimental results on\nvarious datasets validate that FEDMD-NFDP can deliver not only comparable\nutility and communication efficiency but also provide a noise-free differential\nprivacy guarantee. We also demonstrate the feasibility of our FEDMD-NFDP by\nconsidering both IID and non-IID setting, heterogeneous model architectures,\nand unlabelled public datasets from a different distribution.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:19:56 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 11:16:47 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sun", "Lichao", ""], ["Lyu", "Lingjuan", ""]]}, {"id": "2009.05566", "submitter": "Muhammad Muqsit Nawaz", "authors": "Muqsit Nawaz, Aditya Gulati, Kunlong Liu, Vishwajeet Agrawal,\n  Prabhanjan Ananth and Trinabh Gupta", "title": "Accelerating 2PC-based ML with Limited Trusted Hardware", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design, implementation, and evaluation of Otak, a\nsystem that allows two non-colluding cloud providers to run machine learning\n(ML) inference without knowing the inputs to inference. Prior work for this\nproblem mostly relies on advanced cryptography such as two-party secure\ncomputation (2PC) protocols that provide rigorous guarantees but suffer from\nhigh resource overhead. Otak improves efficiency via a new 2PC protocol that\n(i) tailors recent primitives such as function and homomorphic secret sharing\nto ML inference, and (ii) uses trusted hardware in a limited capacity to\nbootstrap the protocol. At the same time, Otak reduces trust assumptions on\ntrusted hardware by running a small code inside the hardware, restricting its\nuse to a preprocessing step, and distributing trust over heterogeneous trusted\nhardware platforms from different vendors. An implementation and evaluation of\nOtak demonstrates that its CPU and network overhead converted to a dollar\namount is 5.4$-$385$\\times$ lower than state-of-the-art 2PC-based works.\nBesides, Otak's trusted computing base (code inside trusted hardware) is only\n1,300 lines of code, which is 14.6$-$29.2$\\times$ lower than the code-size in\nprior trusted hardware-based works.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:53:13 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nawaz", "Muqsit", ""], ["Gulati", "Aditya", ""], ["Liu", "Kunlong", ""], ["Agrawal", "Vishwajeet", ""], ["Ananth", "Prabhanjan", ""], ["Gupta", "Trinabh", ""]]}, {"id": "2009.05567", "submitter": "Jonathan Brophy", "authors": "Jonathan Brophy and Daniel Lowd", "title": "Machine Unlearning for Random Forests", "comments": "29 pages, 5 figures, 9 tables, and 3 algorithms. Accepted at ICML\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responding to user data deletion requests, removing noisy examples, or\ndeleting corrupted training data are just a few reasons for wanting to delete\ninstances from a machine learning (ML) model. However, efficiently removing\nthis data from an ML model is generally difficult. In this paper, we introduce\ndata removal-enabled (DaRE) forests, a variant of random forests that enables\nthe removal of training data with minimal retraining. Model updates for each\nDaRE tree in the forest are exact, meaning that removing instances from a DaRE\nmodel yields exactly the same model as retraining from scratch on updated data.\n  DaRE trees use randomness and caching to make data deletion efficient. The\nupper levels of DaRE trees use random nodes, which choose split attributes and\nthresholds uniformly at random. These nodes rarely require updates because they\nonly minimally depend on the data. At the lower levels, splits are chosen to\ngreedily optimize a split criterion such as Gini index or mutual information.\nDaRE trees cache statistics at each node and training data at each leaf, so\nthat only the necessary subtrees are updated as data is removed. For numerical\nattributes, greedy nodes optimize over a random subset of thresholds, so that\nthey can maintain statistics while approximating the optimal threshold. By\nadjusting the number of thresholds considered for greedy nodes, and the number\nof random nodes, DaRE trees can trade off between more accurate predictions and\nmore efficient updates.\n  In experiments on 13 real-world datasets and one synthetic dataset, we find\nDaRE forests delete data orders of magnitude faster than retraining from\nscratch while sacrificing little to no predictive power.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:53:20 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 22:04:44 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Brophy", "Jonathan", ""], ["Lowd", "Daniel", ""]]}, {"id": "2009.05603", "submitter": "Dumitru-Clementin Cercel", "authors": "Andrei-Marius Avram, Dumitru-Clementin Cercel, Costin-Gabriel Chiru", "title": "UPB at SemEval-2020 Task 6: Pretrained Language Models for Definition\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents our contribution in the context of the 6th task of\nSemEval-2020: Extracting Definitions from Free Text in Textbooks (DeftEval).\nThis competition consists of three subtasks with different levels of\ngranularity: (1) classification of sentences as definitional or\nnon-definitional,(2) labeling of definitional sentences, and (3) relation\nclassification. We use various pretrained language models (i.e., BERT, XLNet,\nRoBERTa, SciBERT, and ALBERT) to solve each of the three subtasks of the\ncompetition. Specifically, for each language model variant, we experiment by\nboth freezing its weights and fine-tuning them. We also explore a multi-task\narchitecture that was trained to jointly predict the outputs for the second and\nthe third subtasks. Our best performing model evaluated on the DeftEval dataset\nobtains the 32nd place for the first subtask and the 37th place for the second\nsubtask. The code is available for further research at:\nhttps://github.com/avramandrei/DeftEval.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:36:22 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 19:33:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Avram", "Andrei-Marius", ""], ["Cercel", "Dumitru-Clementin", ""], ["Chiru", "Costin-Gabriel", ""]]}, {"id": "2009.05604", "submitter": "Yanmin Gong", "authors": "Rui Hu, Yanmin Gong", "title": "Trading Data For Learning: Incentive Mechanism For On-Device Federated\n  Learning", "comments": "Accepted by IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning rests on the notion of training a global model\ndistributedly on various devices. Under this setting, users' devices perform\ncomputations on their own data and then share the results with the cloud server\nto update the global model. A fundamental issue in such systems is to\neffectively incentivize user participation. The users suffer from privacy\nleakage of their local data during the federated model training process.\nWithout well-designed incentives, self-interested users will be unwilling to\nparticipate in federated learning tasks and contribute their private data. To\nbridge this gap, in this paper, we adopt the game theory to design an effective\nincentive mechanism, which selects users that are most likely to provide\nreliable data and compensates for their costs of privacy leakage. We formulate\nour problem as a two-stage Stackelberg game and solve the game's equilibrium.\nEffectiveness of the proposed mechanism is demonstrated by extensive\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:37:58 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hu", "Rui", ""], ["Gong", "Yanmin", ""]]}, {"id": "2009.05613", "submitter": "Rohan Chitnis", "authors": "Tom Silver, Rohan Chitnis, Aidan Curtis, Joshua Tenenbaum, Tomas\n  Lozano-Perez, Leslie Pack Kaelbling", "title": "Planning with Learned Object Importance in Large Problem Instances using\n  Graph Neural Networks", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world planning problems often involve hundreds or even thousands of\nobjects, straining the limits of modern planners. In this work, we address this\nchallenge by learning to predict a small set of objects that, taken together,\nwould be sufficient for finding a plan. We propose a graph neural network\narchitecture for predicting object importance in a single inference pass, thus\nincurring little overhead while greatly reducing the number of objects that\nmust be considered by the planner. Our approach treats the planner and\ntransition model as black boxes, and can be used with any off-the-shelf\nplanner. Empirically, across classical planning, probabilistic planning, and\nrobotic task and motion planning, we find that our method results in planning\nthat is significantly faster than several baselines, including other partial\ngrounding strategies and lifted planners. We conclude that learning to predict\na sufficient set of objects for a planning problem is a simple, powerful, and\ngeneral mechanism for planning in large instances. Video:\nhttps://youtu.be/FWsVJc2fvCE Code: https://git.io/JIsqX\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:55:08 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 19:58:17 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Silver", "Tom", ""], ["Chitnis", "Rohan", ""], ["Curtis", "Aidan", ""], ["Tenenbaum", "Joshua", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "2009.05617", "submitter": "Michele Tufano", "authors": "Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, Neel\n  Sundaresan", "title": "Unit Test Case Generation with Transformers and Focal Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated unit test case generation tools facilitate test-driven development\nand support developers by suggesting tests intended to identify flaws in their\ncode. Existing approaches are usually guided by the test coverage criteria,\ngenerating synthetic test cases that are often difficult for developers to read\nor understand. In this paper we propose AthenaTest, an approach that aims to\ngenerate unit test cases by learning from real-world focal methods and\ndeveloper-written testcases. We formulate unit test case generation as a\nsequence-to-sequence learning task, adopting a two-step training procedure\nconsisting of denoising pretraining on a large unsupervised Java corpus, and\nsupervised finetuning for a downstream translation task of generating unit\ntests. We investigate the impact of natural language and source code\npretraining, as well as the focal context information surrounding the focal\nmethod. Both techniques provide improvements in terms of validation loss, with\npretraining yielding 25% relative improvement and focal context providing\nadditional 11.1% improvement. We also introduce Methods2Test, the largest\npublicly available supervised parallel corpus of unit test case methods and\ncorresponding focal methods in Java, which comprises 780K test cases mined from\n91K open-source repositories from GitHub. We evaluate AthenaTest on five\ndefects4j projects, generating 25K passing test cases covering 43.7% of the\nfocal methods with only 30 attempts. We execute the test cases, collect test\ncoverage information, and compare them with test cases generated by EvoSuite\nand GPT-3, finding that our approach outperforms GPT-3 and has comparable\ncoverage w.r.t. EvoSuite. Finally, we survey professional developers on their\npreference in terms of readability, understandability, and testing\neffectiveness of the generated tests, showing overwhelmingly preference towards\nAthenaTest.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:57:36 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 23:11:01 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Tufano", "Michele", ""], ["Drain", "Dawn", ""], ["Svyatkovskiy", "Alexey", ""], ["Deng", "Shao Kun", ""], ["Sundaresan", "Neel", ""]]}, {"id": "2009.05618", "submitter": "Shujian Yu", "authors": "Shujian Yu, Francesco Alesiani, Ammar Shaker, Wenzhe Yin", "title": "Learning an Interpretable Graph Structure in Multi-Task Learning", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology to jointly perform multi-task learning and\ninfer intrinsic relationship among tasks by an interpretable and sparse graph.\nUnlike existing multi-task learning methodologies, the graph structure is not\nassumed to be known a priori or estimated separately in a preprocessing step.\nInstead, our graph is learned simultaneously with model parameters of each\ntask, thus it reflects the critical relationship among tasks in the specific\nprediction problem. We characterize graph structure with its weighted adjacency\nmatrix and show that the overall objective can be optimized alternatively until\nconvergence. We also show that our methodology can be simply extended to a\nnonlinear form by being embedded into a multi-head radial basis function\nnetwork (RBFN). Extensive experiments, against six state-of-the-art\nmethodologies, on both synthetic data and real-world applications suggest that\nour methodology is able to reduce generalization error, and, at the same time,\nreveal a sparse graph over tasks that is much easier to interpret.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:58:14 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yu", "Shujian", ""], ["Alesiani", "Francesco", ""], ["Shaker", "Ammar", ""], ["Yin", "Wenzhe", ""]]}, {"id": "2009.05634", "submitter": "Michele Tufano", "authors": "Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Neel Sundaresan", "title": "Generating Accurate Assert Statements for Unit Test Cases using\n  Pretrained Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unit testing represents the foundational basis of the software testing\npyramid, beneath integration and end-to-end testing. Automated software testing\nresearchers have proposed a variety of techniques to assist developers in this\ntime-consuming task. In this paper we present an approach to support developers\nin writing unit test cases by generating accurate and useful assert statements.\nOur approach is based on a state-of-the-art transformer model initially\npretrained on an English textual corpus. This semantically rich model is then\ntrained in a semi-supervised fashion on a large corpus of source code. Finally,\nwe finetune this model on the task of generating assert statements for unit\ntests. The resulting model is able to generate accurate assert statements for a\ngiven method under test. In our empirical evaluation, the model was able to\npredict the exact assert statements written by developers in 62% of the cases\nin the first attempt. The results show 80% relative improvement for top-1\naccuracy over the previous RNN-based approach in the literature. We also show\nthe substantial impact of the pretraining process on the performances of our\nmodel, as well as comparing it with assert auto-completion task. Finally, we\ndemonstrate how our approach can be used to augment EvoSuite test cases, with\nadditional asserts leading to improved test coverage.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 19:35:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Tufano", "Michele", ""], ["Drain", "Dawn", ""], ["Svyatkovskiy", "Alexey", ""], ["Sundaresan", "Neel", ""]]}, {"id": "2009.05636", "submitter": "C. Bayan Bruss", "authors": "Jason Wittenbach, Brian d'Alessandro, C. Bayan Bruss", "title": "Machine Learning for Temporal Data in Finance: Challenges and\n  Opportunities", "comments": "KDD '20 ML in Finance Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal data are ubiquitous in the financial services (FS) industry --\ntraditional data like economic indicators, operational data such as bank\naccount transactions, and modern data sources like website clickstreams -- all\nof these occur as a time-indexed sequence. But machine learning efforts in FS\noften fail to account for the temporal richness of these data, even in cases\nwhere domain knowledge suggests that the precise temporal patterns between\nevents should contain valuable information. At best, such data are often\ntreated as uniform time series, where there is a sequence but no sense of exact\ntiming. At worst, rough aggregate features are computed over a pre-selected\nwindow so that static sample-based approaches can be applied (e.g. number of\nopen lines of credit in the previous year or maximum credit utilization over\nthe previous month). Such approaches are at odds with the deep learning\nparadigm which advocates for building models that act directly on raw or\nlightly processed data and for leveraging modern optimization techniques to\ndiscover optimal feature transformations en route to solving the modeling task\nat hand. Furthermore, a full picture of the entity being modeled (customer,\ncompany, etc.) might only be attainable by examining multiple data streams that\nunfold across potentially vastly different time scales. In this paper, we\nexamine the different types of temporal data found in common FS use cases,\nreview the current machine learning approaches in this area, and finally assess\nchallenges and opportunities for researchers working at the intersection of\nmachine learning for temporal data and applications in FS.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 19:39:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wittenbach", "Jason", ""], ["d'Alessandro", "Brian", ""], ["Bruss", "C. Bayan", ""]]}, {"id": "2009.05647", "submitter": "Murad Tukan", "authors": "Murad Tukan and Alaa Maalouf and Matan Weksler and Dan Feldman", "title": "Compressed Deep Networks: Goodbye SVD, Hello Robust Low-Rank\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common technique for compressing a neural network is to compute the\n$k$-rank $\\ell_2$ approximation $A_{k,2}$ of the matrix\n$A\\in\\mathbb{R}^{n\\times d}$ that corresponds to a fully connected layer (or\nembedding layer). Here, $d$ is the number of the neurons in the layer, $n$ is\nthe number in the next one, and $A_{k,2}$ can be stored in $O((n+d)k)$ memory\ninstead of $O(nd)$.\n  This $\\ell_2$-approximation minimizes the sum over every entry to the power\nof $p=2$ in the matrix $A - A_{k,2}$, among every matrix\n$A_{k,2}\\in\\mathbb{R}^{n\\times d}$ whose rank is $k$. While it can be computed\nefficiently via SVD, the $\\ell_2$-approximation is known to be very sensitive\nto outliers (\"far-away\" rows). Hence, machine learning uses e.g. Lasso\nRegression, $\\ell_1$-regularization, and $\\ell_1$-SVM that use the\n$\\ell_1$-norm.\n  This paper suggests to replace the $k$-rank $\\ell_2$ approximation by\n$\\ell_p$, for $p\\in [1,2]$. We then provide practical and provable\napproximation algorithms to compute it for any $p\\geq1$, based on modern\ntechniques in computational geometry.\n  Extensive experimental results on the GLUE benchmark for compressing BERT,\nDistilBERT, XLNet, and RoBERTa confirm this theoretical advantage. For example,\nour approach achieves $28\\%$ compression of RoBERTa's embedding layer with only\n$0.63\\%$ additive drop in the accuracy (without fine-tuning) in average over\nall tasks in GLUE, compared to $11\\%$ drop using the existing\n$\\ell_2$-approximation. Open code is provided for reproducing and extending our\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:21:42 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 12:24:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tukan", "Murad", ""], ["Maalouf", "Alaa", ""], ["Weksler", "Matan", ""], ["Feldman", "Dan", ""]]}, {"id": "2009.05651", "submitter": "Shyam Thombre", "authors": "Shivani Shimpi, Shyam Thombre, Snehal Reddy, Ritik Sharma, Srijan\n  Singh", "title": "Multimodal Depression Severity Prediction from medical bio-markers using\n  Machine Learning Tools and Technologies", "comments": "The paper content has one major problem in a section that is needs\n  more attention and some work, and is agreed by all authors. The change is\n  necessary in terms of correctness and completeness of the paper. Hence,\n  requesting for the withdrawal to allow for the changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Depression has been a leading cause of mental-health illnesses across the\nworld. While the loss of lives due to unmanaged depression is a subject of\nattention, so is the lack of diagnostic tests and subjectivity involved. Using\nbehavioural cues to automate depression diagnosis and stage prediction in\nrecent years has relatively increased. However, the absence of labelled\nbehavioural datasets and a vast amount of possible variations prove to be a\nmajor challenge in accomplishing the task. This paper proposes a novel Custom\nCM Ensemble approach and focuses on a paradigm of a cross-platform smartphone\napplication that takes multimodal inputs from a user through a series of\npre-defined questions, sends it to the Cloud ML architecture and conveys back a\ndepression quotient, representative of its severity. Our app estimates the\nseverity of depression based on a multi-class classification model by utilizing\nthe language, audio, and visual modalities. The given approach attempts to\ndetect, emphasize, and classify the features of a depressed person based on the\nlow-level descriptors for verbal and visual features, and context of the\nlanguage features when prompted with a question. The model achieved a precision\nvalue of 0.88 and an accuracy of 91.56%. Further optimization reveals the\nintramodality and intermodality relevance through the selection of the most\ninfluential features within each modality for decision making.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:44:28 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 06:42:24 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Shimpi", "Shivani", ""], ["Thombre", "Shyam", ""], ["Reddy", "Snehal", ""], ["Sharma", "Ritik", ""], ["Singh", "Srijan", ""]]}, {"id": "2009.05660", "submitter": "Matthew Sotoudeh", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "Abstract Neural Networks", "comments": "Extended version of conference paper at the 27th Static Analysis\n  Symposium (SAS 2020). Code is available at\n  https://github.com/95616ARG/abstract_neural_networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are rapidly being applied to safety-critical\ndomains such as drone and airplane control, motivating techniques for verifying\nthe safety of their behavior. Unfortunately, DNN verification is NP-hard, with\ncurrent algorithms slowing exponentially with the number of nodes in the DNN.\nThis paper introduces the notion of Abstract Neural Networks (ANNs), which can\nbe used to soundly overapproximate DNNs while using fewer nodes. An ANN is like\na DNN except weight matrices are replaced by values in a given abstract domain.\nWe present a framework parameterized by the abstract domain and activation\nfunctions used in the DNN that can be used to construct a corresponding ANN. We\npresent necessary and sufficient conditions on the DNN activation functions for\nthe constructed ANN to soundly over-approximate the given DNN. Prior work on\nDNN abstraction was restricted to the interval domain and ReLU activation\nfunction. Our framework can be instantiated with other abstract domains such as\noctagons and polyhedra, as well as other activation functions such as Leaky\nReLU, Sigmoid, and Hyperbolic Tangent.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:17:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "2009.05665", "submitter": "Qiyao Wang", "authors": "Aniruddha Rajendra Rao, Qiyao Wang, Haiyan Wang, Hamed Khorasgani,\n  Chetan Gupta", "title": "Spatio-Temporal Functional Neural Networks", "comments": "Accepted by 2020 IEEE International Conference on Data Science and\n  Advanced Analytics (DSAA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explosive growth in spatio-temporal data and its wide range of applications\nhave attracted increasing interests of researchers in the statistical and\nmachine learning fields. The spatio-temporal regression problem is of paramount\nimportance from both the methodology development and real-world application\nperspectives. Given the observed spatially encoded time series covariates and\nreal-valued response data samples, the goal of spatio-temporal regression is to\nleverage the temporal and spatial dependencies to build a mapping from\ncovariates to response with minimized prediction error. Prior arts, including\nthe convolutional Long Short-Term Memory (CovLSTM) and variations of the\nfunctional linear models, cannot learn the spatio-temporal information in a\nsimple and efficient format for proper model building. In this work, we propose\ntwo novel extensions of the Functional Neural Network (FNN), a temporal\nregression model whose effectiveness and superior performance over alternative\nsequential models have been proven by many researchers. The effectiveness of\nthe proposed spatio-temporal FNNs in handling varying spatial correlations is\ndemonstrated in comprehensive simulation studies. The proposed models are then\ndeployed to solve a practical and challenging precipitation prediction problem\nin the meteorology field.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:32:35 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Wang", "Qiyao", ""], ["Wang", "Haiyan", ""], ["Khorasgani", "Hamed", ""], ["Gupta", "Chetan", ""]]}, {"id": "2009.05668", "submitter": "Li Yang", "authors": "Li Yang, Zhezhi He, Junshan Zhang, Deliang Fan", "title": "KSM: Fast Multiple Task Adaption via Kernel-wise Soft Mask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) could forget the knowledge about earlier tasks\nwhen learning new tasks, and this is known as \\textit{catastrophic forgetting}.\nWhile recent continual learning methods are capable of alleviating the\ncatastrophic problem on toy-sized datasets, some issues still remain to be\ntackled when applying them in real-world problems. Recently, the fast\nmask-based learning method (e.g. piggyback \\cite{mallya2018piggyback}) is\nproposed to address these issues by learning only a binary element-wise mask in\na fast manner, while keeping the backbone model fixed. However, the binary mask\nhas limited modeling capacity for new tasks. A more recent work\n\\cite{hung2019compacting} proposes a compress-grow-based method (CPG) to\nachieve better accuracy for new tasks by partially training backbone model, but\nwith order-higher training cost, which makes it infeasible to be deployed into\npopular state-of-the-art edge-/mobile-learning. The primary goal of this work\nis to simultaneously achieve fast and high-accuracy multi task adaption in\ncontinual learning setting. Thus motivated, we propose a new training method\ncalled \\textit{kernel-wise Soft Mask} (KSM), which learns a kernel-wise hybrid\nbinary and real-value soft mask for each task, while using the same backbone\nmodel. Such a soft mask can be viewed as a superposition of a binary mask and a\nproperly scaled real-value tensor, which offers a richer representation\ncapability without low-level kernel support to meet the objective of low\nhardware overhead. We validate KSM on multiple benchmark datasets against\nrecent state-of-the-art methods (e.g. Piggyback, Packnet, CPG, etc.), which\nshows good improvement in both accuracy and training cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:48:39 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yang", "Li", ""], ["He", "Zhezhi", ""], ["Zhang", "Junshan", ""], ["Fan", "Deliang", ""]]}, {"id": "2009.05669", "submitter": "Daniel Gibney", "authors": "Jason W. Bentley, Daniel Gibney, Gary Hoppenworth, Sumit Kumar Jha", "title": "Quantifying Membership Inference Vulnerability via Generalization Gap\n  and Other Model Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how a target model's generalization gap leads directly to an\neffective deterministic black box membership inference attack (MIA). This\nprovides an upper bound on how secure a model can be to MIA based on a simple\nmetric. Moreover, this attack is shown to be optimal in the expected sense\ngiven access to only certain likely obtainable metrics regarding the network's\ntraining and performance. Experimentally, this attack is shown to be comparable\nin accuracy to state-of-art MIAs in many cases.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:53:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bentley", "Jason W.", ""], ["Gibney", "Daniel", ""], ["Hoppenworth", "Gary", ""], ["Jha", "Sumit Kumar", ""]]}, {"id": "2009.05673", "submitter": "Jeff Heaton Ph.D.", "authors": "Jeff Heaton", "title": "Applications of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning is a group of exciting new technologies for neural networks.\nThrough a combination of advanced training techniques and neural network\narchitectural components, it is now possible to create neural networks that can\nhandle tabular data, images, text, and audio as both input and output. Deep\nlearning allows a neural network to learn hierarchies of information in a way\nthat is like the function of the human brain. This course will introduce the\nstudent to classic neural network structures, Convolution Neural Networks\n(CNN), Long Short-Term Memory (LSTM), Gated Recurrent Neural Networks (GRU),\nGeneral Adversarial Networks (GAN), and reinforcement learning. Application of\nthese architectures to computer vision, time series, security, natural language\nprocessing (NLP), and data generation will be covered. High-Performance\nComputing (HPC) aspects will demonstrate how deep learning can be leveraged\nboth on graphical processing units (GPUs), as well as grids. Focus is primarily\nupon the application of deep learning to problems, with some introduction to\nmathematical foundations. Readers will use the Python programming language to\nimplement deep learning using Google TensorFlow and Keras. It is not necessary\nto know Python prior to this book; however, familiarity with at least one\nprogramming language is assumed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:09:10 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 23:11:56 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Heaton", "Jeff", ""]]}, {"id": "2009.05683", "submitter": "Sumit Mukherjee", "authors": "Xiyang Liu, Yixi Xu, Shruti Tople, Sumit Mukherjee, Juan Lavista\n  Ferres", "title": "MACE: A Flexible Framework for Membership Privacy Estimation in\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we formally study the membership privacy risk of generative\nmodels and propose a membership privacy estimation framework. We formulate the\nmembership privacy risk as a statistical divergence between training samples\nand hold-out samples, and propose sample-based methods to estimate this\ndivergence. Unlike previous works, our proposed metric and estimators make\nrealistic and flexible assumptions. First, we offer a generalizable metric as\nan alternative to accuracy for imbalanced datasets. Second, our estimators are\ncapable of estimating the membership privacy risk given any scalar or vector\nvalued attributes from the learned model, while prior work require access to\nspecific attributes. This allows our framework to provide data-driven\ncertificates for trained generative models in terms of membership privacy risk.\nFinally, we show a connection to differential privacy, which allows our\nproposed estimators to be used to understand the privacy budget 'epsilon'\nneeded for differentially private generative models. We demonstrate the utility\nof our framework through experimental demonstrations on different generative\nmodels using various model attributes yielding some new insights about\nmembership leakage and vulnerabilities of models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 23:15:05 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 00:26:30 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 17:03:58 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Liu", "Xiyang", ""], ["Xu", "Yixi", ""], ["Tople", "Shruti", ""], ["Mukherjee", "Sumit", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "2009.05686", "submitter": "Tenavi Nakamura-Zimmerer", "authors": "Tenavi Nakamura-Zimmerer, Qi Gong, Wei Kang", "title": "QRnet: optimal regulator design with LQR-augmented neural networks", "comments": "Added IEEE accepted manuscript with copyright notice", "journal-ref": "IEEE Control Systems Letters 5 (2021) 1303-1308", "doi": "10.1109/LCSYS.2020.3034415", "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new computational method for designing optimal\nregulators for high-dimensional nonlinear systems. The proposed approach\nleverages physics-informed machine learning to solve high-dimensional\nHamilton-Jacobi-Bellman equations arising in optimal feedback control.\nConcretely, we augment linear quadratic regulators with neural networks to\nhandle nonlinearities. We train the augmented models on data generated without\ndiscretizing the state space, enabling application to high-dimensional\nproblems. We use the proposed method to design a candidate optimal regulator\nfor an unstable Burgers' equation, and through this example, demonstrate\nimproved robustness and accuracy compared to existing neural network\nformulations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 23:50:17 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 18:39:17 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Nakamura-Zimmerer", "Tenavi", ""], ["Gong", "Qi", ""], ["Kang", "Wei", ""]]}, {"id": "2009.05697", "submitter": "Yuxuan Cai", "authors": "Yuxuan Cai, Hongjia Li, Geng Yuan, Wei Niu, Yanyu Li, Xulong Tang, Bin\n  Ren, Yanzhi Wang", "title": "YOLObile: Real-Time Object Detection on Mobile Devices via\n  Compression-Compilation Co-Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development and wide utilization of object detection techniques\nhave aroused attention on both accuracy and speed of object detectors. However,\nthe current state-of-the-art object detection works are either\naccuracy-oriented using a large model but leading to high latency or\nspeed-oriented using a lightweight model but sacrificing accuracy. In this\nwork, we propose YOLObile framework, a real-time object detection on mobile\ndevices via compression-compilation co-design. A novel block-punched pruning\nscheme is proposed for any kernel size. To improve computational efficiency on\nmobile devices, a GPU-CPU collaborative scheme is adopted along with advanced\ncompiler-assisted optimizations. Experimental results indicate that our pruning\nscheme achieves 14$\\times$ compression rate of YOLOv4 with 49.0 mAP. Under our\nYOLObile framework, we achieve 17 FPS inference speed using GPU on Samsung\nGalaxy S20. By incorporating our proposed GPU-CPU collaborative scheme, the\ninference speed is increased to 19.1 FPS, and outperforms the original YOLOv4\nby 5$\\times$ speedup. Source code is at:\n\\url{https://github.com/nightsnack/YOLObile}.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:41:08 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 15:55:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cai", "Yuxuan", ""], ["Li", "Hongjia", ""], ["Yuan", "Geng", ""], ["Niu", "Wei", ""], ["Li", "Yanyu", ""], ["Tang", "Xulong", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2009.05700", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Information-Theoretic Multi-Objective Bayesian Optimization with\n  Continuous Approximations", "comments": null, "journal-ref": "Workshop on machine learning for engineering modeling, simulation\n  and design @ NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications involve black-box optimization of multiple\nobjectives using continuous function approximations that trade-off accuracy and\nresource cost of evaluation. For example, in rocket launching research, we need\nto find designs that trade-off return-time and angular distance using\ncontinuous-fidelity simulators (e.g., varying tolerance parameter to trade-off\nsimulation time and accuracy) for design evaluations. The goal is to\napproximate the optimal Pareto set by minimizing the cost for evaluations. In\nthis paper, we propose a novel approach referred to as information-Theoretic\nMulti-Objective Bayesian Optimization with Continuous Approximations (iMOCA)}\nto solve this problem. The key idea is to select the sequence of input and\nfunction approximations for multiple objectives which maximize the information\ngain per unit cost for the optimal Pareto front. Our experiments on diverse\nsynthetic and real-world benchmarks show that iMOCA significantly improves over\nexisting single-fidelity methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:46:03 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 17:33:38 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 01:46:09 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2009.05702", "submitter": "Haruki Nishimura", "authors": "Haruki Nishimura and Boris Ivanovic and Adrien Gaidon and Marco Pavone\n  and Mac Schwager", "title": "Risk-Sensitive Sequential Action Control with Multi-Modal Human\n  Trajectory Forecasting for Safe Crowd-Robot Interaction", "comments": "To appear in 2020 IEEE/RSJ IROS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel online framework for safe crowd-robot interaction\nbased on risk-sensitive stochastic optimal control, wherein the risk is modeled\nby the entropic risk measure. The sampling-based model predictive control\nrelies on mode insertion gradient optimization for this risk measure as well as\nTrajectron++, a state-of-the-art generative model that produces multimodal\nprobabilistic trajectory forecasts for multiple interacting agents. Our modular\napproach decouples the crowd-robot interaction into learning-based prediction\nand model-based control, which is advantageous compared to end-to-end policy\nlearning methods in that it allows the robot's desired behavior to be specified\nat run time. In particular, we show that the robot exhibits diverse interaction\nbehavior by varying the risk sensitivity parameter. A simulation study and a\nreal-world experiment show that the proposed online framework can accomplish\nsafe and efficient navigation while avoiding collisions with more than 50\nhumans in the scene.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 02:02:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Nishimura", "Haruki", ""], ["Ivanovic", "Boris", ""], ["Gaidon", "Adrien", ""], ["Pavone", "Marco", ""], ["Schwager", "Mac", ""]]}, {"id": "2009.05708", "submitter": "Thippa Reddy Gadekallu", "authors": "Mohan Krishna Kagita, Navod Thilakarathne, Thippa Reddy Gadekallu,\n  Praveen Kumar Reddy Maddikunta, Saurabh Singh", "title": "A Review on Cyber Crimes on the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) devices are rapidly becoming universal. The success\nof IoT cannot be ignored in the scenario today, along with its attacks and\nthreats on IoT devices and facilities are also increasing day by day. Cyber\nattacks become a part of IoT and affecting the life and society of users, so\nsteps must be taken to defend cyber seriously. Cybercrimes threaten the\ninfrastructure of governments and businesses globally and can damage the users\nin innumerable ways. With the global cybercrime damages predicted to cost up to\n6 trillion dollars annually on the global economy by cyber crime. Estimated of\n328 Million Dollar annual losses with the cyber attacks in Australia itself.\nVarious steps are taken to slow down these attacks but unfortunately not able\nto achieve success properly. Therefor secure IoT is the need of this time and\nunderstanding of attacks and threats in IoT structure should be studied. The\nreasons for cyber-attacks can be Countries having week cyber securities,\nCybercriminals use new technologies to attack, Cybercrime is possible with\nservices and other business schemes. MSP (Managed Service Providers) face\ndifferent difficulties in fighting with Cyber-crime. They have to ensure that\nsecurity of the customer as well as their security in terms of their servers,\ndevices, and systems. Hence, they must use effective, fast, and easily usable\nantivirus and antimalware tools.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 02:56:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kagita", "Mohan Krishna", ""], ["Thilakarathne", "Navod", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Singh", "Saurabh", ""]]}, {"id": "2009.05738", "submitter": "Tim De Jong", "authors": "Tim De Jong (Statistics Netherlands), Stefano Bromuri (Open\n  Universiteit Nederland), Xi Chang (Open Universiteit Nederland), Marc\n  Debusschere (Statbel), Natalie Rosenski (Destatis), Clara Schartner\n  (Destatis), Katharina Strauch (IT.NRW), Marion Boehmer (IT.NRW), Lyana Curier\n  (Statistics Netherlands)", "title": "Monitoring Spatial Sustainable Development: semi-automated analysis of\n  Satellite and Aerial Images for Energy Transition and Sustainability\n  Indicators", "comments": "81 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents the results of the DeepSolaris project that was carried\nout under the ESS action 'Merging Geostatistics and Geospatial Information in\nMember States'. During the project several deep learning algorithms were\nevaluated to detect solar panels in remote sensing data. The aim of the project\nwas to evaluate whether deep learning models could be developed, that worked\nacross different member states in the European Union. Two remote sensing data\nsources were considered: aerial images on the one hand, and satellite images on\nthe other. Two flavours of deep learning models were evaluated: classification\nmodels and object detection models. For the evaluation of the deep learning\nmodels we used a cross-site evaluation approach: the deep learning models where\ntrained in one geographical area and then evaluated on a different geographical\narea, previously unseen by the algorithm. The cross-site evaluation was\nfurthermore carried out twice: deep learning models trained on he Netherlands\nwere evaluated on Germany and vice versa. While the deep learning models were\nable to detect solar panels successfully, false detection remained a problem.\nMoreover, model performance decreased dramatically when evaluated in a\ncross-border fashion. Hence, training a model that performs reliably across\ndifferent countries in the European Union is a challenging task. That being\nsaid, the models detected quite a share of solar panels not present in current\nsolar panel registers and therefore can already be used as-is to help reduced\nmanual labor in checking these registers.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 07:09:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["De Jong", "Tim", "", "Statistics Netherlands"], ["Bromuri", "Stefano", "", "Open\n  Universiteit Nederland"], ["Chang", "Xi", "", "Open Universiteit Nederland"], ["Debusschere", "Marc", "", "Statbel"], ["Rosenski", "Natalie", "", "Destatis"], ["Schartner", "Clara", "", "Destatis"], ["Strauch", "Katharina", "", "IT.NRW"], ["Boehmer", "Marion", "", "IT.NRW"], ["Curier", "Lyana", "", "Statistics Netherlands"]]}, {"id": "2009.05739", "submitter": "Ze Cheng", "authors": "Ze Cheng, Juncheng Li, Chenxu Wang, Jixuan Gu, Hao Xu, Xinjian Li,\n  Florian Metze", "title": "Revisiting Factorizing Aggregated Posterior in Learning Disentangled\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning disentangled representations, one of the promising\nmethods is to factorize aggregated posterior by penalizing the total\ncorrelation of sampled latent variables. However, this well-motivated strategy\nhas a blind spot: there is a disparity between the sampled latent\nrepresentation and its corresponding mean representation. In this paper, we\nprovide a theoretical explanation that low total correlation of sampled\nrepresentation cannot guarantee low total correlation of the mean\nrepresentation. Indeed, we prove that for the multivariate normal\ndistributions, the mean representation with arbitrarily high total correlation\ncan have a corresponding sampled representation with bounded total correlation.\nWe also propose a method to eliminate this disparity. Experiments show that our\nmodel can learn a mean representation with much lower total correlation, hence\na factorized mean representation. Moreover, we offer a detailed explanation of\nthe limitations of factorizing aggregated posterior: factor disintegration. Our\nwork indicates a potential direction for future research of disentangled\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 07:31:30 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 05:14:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Cheng", "Ze", ""], ["Li", "Juncheng", ""], ["Wang", "Chenxu", ""], ["Gu", "Jixuan", ""], ["Xu", "Hao", ""], ["Li", "Xinjian", ""], ["Metze", "Florian", ""]]}, {"id": "2009.05752", "submitter": "Hazrat Ali", "authors": "Faizan Munawar, Shoaib Azmat, Talha Iqbal, Christer Gr\\\"onlund, Hazrat\n  Ali", "title": "Segmentation of Lungs in Chest X-Ray Image Using Generative Adversarial\n  Networks", "comments": "Volume 8, August 2020, Pages 153535 - 153545", "journal-ref": "in IEEE Access, vol. 8, pp. 153535-153545, 2020", "doi": "10.1109/ACCESS.2020.3017915", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chest X-ray (CXR) is a low-cost medical imaging technique. It is a common\nprocedure for the identification of many respiratory diseases compared to MRI,\nCT, and PET scans. This paper presents the use of generative adversarial\nnetworks (GAN) to perform the task of lung segmentation on a given CXR. GANs\nare popular to generate realistic data by learning the mapping from one domain\nto another. In our work, the generator of the GAN is trained to generate a\nsegmented mask of a given input CXR. The discriminator distinguishes between a\nground truth and the generated mask, and updates the generator through the\nadversarial loss measure. The objective is to generate masks for the input CXR,\nwhich are as realistic as possible compared to the ground truth masks. The\nmodel is trained and evaluated using four different discriminators referred to\nas D1, D2, D3, and D4, respectively. Experimental results on three different\nCXR datasets reveal that the proposed model is able to achieve a dice-score of\n0.9740, and IOU score of 0.943, which are better than other reported\nstate-of-the art results.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 08:54:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Munawar", "Faizan", ""], ["Azmat", "Shoaib", ""], ["Iqbal", "Talha", ""], ["Gr\u00f6nlund", "Christer", ""], ["Ali", "Hazrat", ""]]}, {"id": "2009.05783", "submitter": "Gadekallu Thippa Reddy", "authors": "N Deepa, Mohammad Zubair Khan, Prabadevi B, Durai Raj Vincent P M,\n  Praveen Kumar Reddy Maddikunta, Thippa Reddy Gadekallu", "title": "Multiclass Model for Agriculture development using Multivariate\n  Statistical method", "comments": "in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3028595", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mahalanobis taguchi system (MTS) is a multi-variate statistical method\nextensively used for feature selection and binary classification problems. The\ncalculation of orthogonal array and signal-to-noise ratio in MTS makes the\nalgorithm complicated when more number of factors are involved in the\nclassification problem. Also the decision is based on the accuracy of normal\nand abnormal observations of the dataset. In this paper, a multiclass model\nusing Improved Mahalanobis Taguchi System (IMTS) is proposed based on normal\nobservations and Mahalanobis distance for agriculture development. Twenty-six\ninput factors relevant to crop cultivation have been identified and clustered\ninto six main factors for the development of the model. The multiclass model is\ndeveloped with the consideration of the relative importance of the factors. An\nobjective function is defined for the classification of three crops, namely\npaddy, sugarcane and groundnut. The classification results are verified against\nthe results obtained from the agriculture experts working in the field. The\nproposed classifier provides 100% accuracy, recall, precision and 0% error rate\nwhen compared with other traditional classifier models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 13:09:52 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 13:53:21 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Deepa", "N", ""], ["Khan", "Mohammad Zubair", ""], ["B", "Prabadevi", ""], ["M", "Durai Raj Vincent P", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Gadekallu", "Thippa Reddy", ""]]}, {"id": "2009.05786", "submitter": "Haoqing Wang", "authors": "Haoqing Wang, Zhi-Hong Deng", "title": "Few-shot Learning with LSSVM Base Learner and Transductive Modules", "comments": "9 pages,3 figures,3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of meta-learning approaches for few-shot learning generally\ndepends on three aspects: features suitable for comparison, the classifier (\nbase learner ) suitable for low-data scenarios, and valuable information from\nthe samples to classify. In this work, we make improvements for the last two\naspects: 1) although there are many effective base learners, there is a\ntrade-off between generalization performance and computational overhead, so we\nintroduce multi-class least squares support vector machine as our base learner\nwhich obtains better generation than existing ones with less computational\noverhead; 2) further, in order to utilize the information from the query\nsamples, we propose two simple and effective transductive modules which modify\nthe support set using the query samples, i.e., adjusting the support samples\nbasing on the attention mechanism and adding the prototypes of the query set\nwith pseudo labels to the support set as the pseudo support samples. These two\nmodules significantly improve the few-shot classification accuracy, especially\nfor the difficult 1-shot setting. Our model, denoted as FSLSTM (Few-Shot\nlearning with LSsvm base learner and Transductive Modules), achieves\nstate-of-the-art performance on miniImageNet and CIFAR-FS few-shot learning\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 13:16:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Haoqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "2009.05805", "submitter": "Ragunathan Mariappan", "authors": "Ragunathan Mariappan, Vaibhav Rajan", "title": "Multi-way Spectral Clustering of Augmented Multi-view Data through Deep\n  Collective Matrix Tri-factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the first deep learning based architecture for collective matrix\ntri-factorization (DCMTF) of arbitrary collections of matrices, also known as\naugmented multi-view data. DCMTF can be used for multi-way spectral clustering\nof heterogeneous collections of relational data matrices to discover latent\nclusters in each input matrix, across both dimensions, as well as the strengths\nof association across clusters. The source code for DCMTF is available on our\npublic repository: https://bitbucket.org/cdal/dcmtf_generic\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 14:41:00 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mariappan", "Ragunathan", ""], ["Rajan", "Vaibhav", ""]]}, {"id": "2009.05818", "submitter": "Tiago Botari T.B.", "authors": "Tiago Botari, Frederik Hvilsh{\\o}j, Rafael Izbicki, Andre C. P. L. F.\n  de Carvalho", "title": "MeLIME: Meaningful Local Explanation for Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art machine learning algorithms induce black-box models,\npreventing their application in many sensitive domains. Hence, many\nmethodologies for explaining machine learning models have been proposed to\naddress this problem. In this work, we introduce strategies to improve local\nexplanations taking into account the distribution of the data used to train the\nblack-box models. We show that our approach, MeLIME, produces more meaningful\nexplanations compared to other techniques over different ML models, operating\non various types of data. MeLIME generalizes the LIME method, allowing more\nflexible perturbation sampling and the use of different local interpretable\nmodels. Additionally, we introduce modifications to standard training\nalgorithms of local interpretable models fostering more robust explanations,\neven allowing the production of counterfactual examples. To show the strengths\nof the proposed approach, we include experiments on tabular data, images, and\ntext; all showing improved explanations. In particular, MeLIME generated more\nmeaningful explanations on the MNIST dataset than methods such as\nGuidedBackprop, SmoothGrad, and Layer-wise Relevance Propagation. MeLIME is\navailable on https://github.com/tiagobotari/melime.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 16:06:58 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Botari", "Tiago", ""], ["Hvilsh\u00f8j", "Frederik", ""], ["Izbicki", "Rafael", ""], ["de Carvalho", "Andre C. P. L. F.", ""]]}, {"id": "2009.05835", "submitter": "Alexander Wong", "authors": "Alexander Wong, Xiao Yu Wang, and Andrew Hryniowski", "title": "How Much Can We Really Trust You? Towards Simple, Interpretable Trust\n  Quantification Metrics for Deep Neural Networks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical step to building trustworthy deep neural networks is trust\nquantification, where we ask the question: How much can we trust a deep neural\nnetwork? In this study, we take a step towards simple, interpretable metrics\nfor trust quantification by introducing a suite of metrics for assessing the\noverall trustworthiness of deep neural networks based on their behaviour when\nanswering a set of questions. We conduct a thought experiment and explore two\nkey questions about trust in relation to confidence: 1) How much trust do we\nhave in actors who give wrong answers with great confidence? and 2) How much\ntrust do we have in actors who give right answers hesitantly? Based on insights\ngained, we introduce the concept of question-answer trust to quantify\ntrustworthiness of an individual answer based on confident behaviour under\ncorrect and incorrect answer scenarios, and the concept of trust density to\ncharacterize the distribution of overall trust for an individual answer\nscenario. We further introduce the concept of trust spectrum for representing\noverall trust with respect to the spectrum of possible answer scenarios across\ncorrectly and incorrectly answered questions. Finally, we introduce\nNetTrustScore, a scalar metric summarizing overall trustworthiness. The suite\nof metrics aligns with past social psychology studies that study the\nrelationship between trust and confidence. Leveraging these metrics, we\nquantify the trustworthiness of several well-known deep neural network\narchitectures for image recognition to get a deeper understanding of where\ntrust breaks down. The proposed metrics are by no means perfect, but the hope\nis to push the conversation towards better metrics to help guide practitioners\nand regulators in producing, deploying, and certifying deep learning solutions\nthat can be trusted to operate in real-world, mission-critical scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:37:36 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 02:45:36 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 15:08:50 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wong", "Alexander", ""], ["Wang", "Xiao Yu", ""], ["Hryniowski", "Andrew", ""]]}, {"id": "2009.05837", "submitter": "Usman Khan", "authors": "Ran Xin, Shi Pu, Angelia Nedi\\'c, and Usman A. Khan", "title": "A general framework for decentralized optimization with first-order\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization to minimize a finite sum of functions over a\nnetwork of nodes has been a significant focus within control and signal\nprocessing research due to its natural relevance to optimal control and signal\nestimation problems. More recently, the emergence of sophisticated computing\nand large-scale data science needs have led to a resurgence of activity in this\narea. In this article, we discuss decentralized first-order gradient methods,\nwhich have found tremendous success in control, signal processing, and machine\nlearning problems, where such methods, due to their simplicity, serve as the\nfirst method of choice for many complex inference and training tasks. In\nparticular, we provide a general framework of decentralized first-order methods\nthat is applicable to undirected and directed communication networks alike, and\nshow that much of the existing work on optimization and consensus can be\nrelated explicitly to this framework. We further extend the discussion to\ndecentralized stochastic first-order methods that rely on stochastic gradients\nat each node and describe how local variance reduction schemes, previously\nshown to have promise in the centralized settings, are able to improve the\nperformance of decentralized methods when combined with what is known as\ngradient tracking. We motivate and demonstrate the effectiveness of the\ncorresponding methods in the context of machine learning and signal processing\nproblems that arise in decentralized environments.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:52:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xin", "Ran", ""], ["Pu", "Shi", ""], ["Nedi\u0107", "Angelia", ""], ["Khan", "Usman A.", ""]]}, {"id": "2009.05838", "submitter": "Amit Surana", "authors": "Amit Surana, Kishore Reddy, Matthew Siopis", "title": "Guided Policy Search Based Control of a High Dimensional Advanced\n  Manufacturing Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply guided policy search (GPS) based reinforcement\nlearning framework for a high dimensional optimal control problem arising in an\nadditive manufacturing process. The problem comprises of controlling the\nprocess parameters so that layer-wise deposition of material leads to desired\ngeometric characteristics of the resulting part surface while minimizing the\nmaterial deposited. A realistic simulation model of the deposition process\nalong with carefully selected set of guiding distributions generated based on\niterative Linear Quadratic Regulator is used to train a neural network policy\nusing GPS. A closed loop control based on the trained policy and in-situ\nmeasurement of the deposition profile is tested experimentally, and shows\npromising performance.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:58:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Surana", "Amit", ""], ["Reddy", "Kishore", ""], ["Siopis", "Matthew", ""]]}, {"id": "2009.05847", "submitter": "Arash Hooshmand", "authors": "Arash Hooshmand", "title": "Machine Learning Against Cancer: Accurate Diagnosis of Cancer by Machine\n  Learning Classification of the Whole Genome Sequencing Data", "comments": "29 pages, 3 figures, 45 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can precisely identify different cancer tumors at any stage\nby classifying cancerous and healthy samples based on their genomic profile. We\nhave developed novel methods of MLAC (Machine Learning Against Cancer)\nachieving perfect results with perfect precision, sensitivity, and specificity.\nWe have used the whole genome sequencing data acquired by next-generation RNA\nsequencing techniques in The Cancer Genome Atlas and Genotype-Tissue Expression\nprojects for cancerous and healthy tissues respectively. Moreover, we have\nshown that unsupervised machine learning clustering has great potential to be\nused for cancer diagnosis. Indeed, a creative way to work with data and general\nalgorithms has resulted in perfect classification i.e. all precision,\nsensitivity, and specificity are equal to 1 for most of the different tumor\ntypes even with a modest amount of data, and the same method works well on a\nseries of cancers and results in great clustering of cancerous and healthy\nsamples too. Our system can be used in practice because once the classifier is\ntrained, it can be used to classify any new sample of new potential patients.\nOne advantage of our work is that the aforementioned perfect precision and\nrecall are obtained on samples of all stages including very early stages of\ncancer; therefore, it is a promising tool for diagnosis of cancers in early\nstages. Another advantage of our novel model is that it works with normalized\nvalues of RNA sequencing data, hence people's private sensitive medical data\nwill remain hidden, protected, and safe. This type of analysis will be\nwidespread and economical in the future and people can even learn to receive\ntheir RNA sequencing data and do their own preliminary cancer studies\nthemselves which have the potential to help the healthcare systems. It is a\ngreat step forward toward good health that is the main base of sustainable\nsocieties.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 18:51:47 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hooshmand", "Arash", ""]]}, {"id": "2009.05859", "submitter": "Young-Ho Kim", "authors": "Young-Ho Kim, Jarrod Collins, Zhongyu Li, Ponraj Chinnadurai, Ankur\n  Kapoor, C. Huie Lin, Tommaso Mansi", "title": "Towards Automatic Manipulation of Intra-cardiac Echocardiography\n  Catheter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intra-cardiac Echocardiography (ICE) is a powerful imaging modality for\nguiding electrophysiology and structural heart interventions. ICE provides\nreal-time observation of anatomy, catheters, and emergent complications.\nHowever, this increased reliance on intraprocedural imaging creates a high\ncognitive demand on physicians who can often serve as interventionalist and\nimager. We present a robotic manipulator for ICE catheters to assist physicians\nwith imaging and serve as a platform for developing processes for procedural\nautomation. Herein, we introduce two application modules towards these goals:\n(1) a view recovery process that allows physicians to save views during\nintervention and automatically return with the push of a button and (2) a\ndata-driven approach to compensate kinematic model errors that result from\nnon-linear behaviors in catheter bending, providing more precise control of the\ncatheter tip. View recovery is validated by repeated catheter positioning in\ncardiac phantom and animal experiments with position- and image-based analysis.\nWe present a simplified calibration approach for error compensation and verify\nwith complex rotation of the catheter in benchtop and phantom experiments under\nvarying realistic curvature conditions. Results support that a robotic\nmanipulator for ICE can provide an efficient and reproducible tool, potentially\nreducing execution time and promoting greater utilization of ICE imaging.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 20:14:49 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 15:18:07 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 22:16:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kim", "Young-Ho", ""], ["Collins", "Jarrod", ""], ["Li", "Zhongyu", ""], ["Chinnadurai", "Ponraj", ""], ["Kapoor", "Ankur", ""], ["Lin", "C. Huie", ""], ["Mansi", "Tommaso", ""]]}, {"id": "2009.05866", "submitter": "Nicholas Capel", "authors": "Nicholas Capel, Naifu Zhang", "title": "Extended Radial Basis Function Controller for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been attempts in reinforcement learning to exploit a priori\nknowledge about the structure of the system. This paper proposes a hybrid\nreinforcement learning controller which dynamically interpolates a model-based\nlinear controller and an arbitrary differentiable policy. The linear controller\nis designed based on local linearised model knowledge, and stabilises the\nsystem in a neighbourhood about an operating point. The coefficients of\ninterpolation between the two controllers are determined by a scaled distance\nfunction measuring the distance between the current state and the operating\npoint. The overall hybrid controller is proven to maintain the stability\nguarantee around the neighborhood of the operating point and still possess the\nuniversal function approximation property of the arbitrary non-linear policy.\nLearning has been done on both model-based (PILCO) and model-free (DDPG)\nframeworks. Simulation experiments performed in OpenAI gym demonstrate\nstability and robustness of the proposed hybrid controller. This paper thus\nintroduces a principled method allowing for the direct importing of control\nmethodology into reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 20:56:48 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 06:44:17 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Capel", "Nicholas", ""], ["Zhang", "Naifu", ""]]}, {"id": "2009.05870", "submitter": "Anru R. Zhang", "authors": "Yuetian Luo and Anru R. Zhang", "title": "Open Problem: Average-Case Hardness of Hypergraphic Planted Clique\n  Detection", "comments": "Published at Proceedings of Conference on Learning Theory, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We note the significance of hypergraphic planted clique (HPC) detection in\nthe investigation of computational hardness for a range of tensor problems. We\nask if more evidence for the computational hardness of HPC detection can be\ndeveloped. In particular, we conjecture if it is possible to establish the\nequivalence of the computational hardness between HPC and PC detection.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 21:55:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Luo", "Yuetian", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2009.05872", "submitter": "Yanmin Gong", "authors": "Zhidong Gao, Rui Hu, Yanmin Gong", "title": "Certified Robustness of Graph Classification against Topology Attack\n  with Randomized Smoothing", "comments": "Accepted to IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification has practical applications in diverse fields. Recent\nstudies show that graph-based machine learning models are especially vulnerable\nto adversarial perturbations due to the non i.i.d nature of graph data. By\nadding or deleting a small number of edges in the graph, adversaries could\ngreatly change the graph label predicted by a graph classification model. In\nthis work, we propose to build a smoothed graph classification model with\ncertified robustness guarantee. We have proven that the resulting graph\nclassification model would output the same prediction for a graph under $l_0$\nbounded adversarial perturbation. We also evaluate the effectiveness of our\napproach under graph convolutional network (GCN) based multi-class graph\nclassification model.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 22:18:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Gao", "Zhidong", ""], ["Hu", "Rui", ""], ["Gong", "Yanmin", ""]]}, {"id": "2009.05880", "submitter": "Abolfazl Zargari", "authors": "Abolfazl Zargari Khuzani, Najmeh Mashhadi, Morteza Heidari, Donya\n  Khaledyan", "title": "An approach to human iris recognition using quantitative analysis of\n  image features and machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Iris pattern is a unique biological feature for each individual, making\nit a valuable and powerful tool for human identification. In this paper, an\nefficient framework for iris recognition is proposed in four steps. (1) Iris\nsegmentation (using a relative total variation combined with Coarse Iris\nLocalization), (2) feature extraction (using Shape&density, FFT, GLCM, GLDM,\nand Wavelet), (3) feature reduction (employing Kernel-PCA) and (4)\nclassification (applying multi-layer neural network) to classify 2000 iris\nimages of CASIA-Iris-Interval dataset obtained from 200 volunteers. The results\nconfirm that the proposed scheme can provide a reliable prediction with an\naccuracy of up to 99.64%.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 23:23:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Khuzani", "Abolfazl Zargari", ""], ["Mashhadi", "Najmeh", ""], ["Heidari", "Morteza", ""], ["Khaledyan", "Donya", ""]]}, {"id": "2009.05886", "submitter": "Dylan Slack", "authors": "Gavin Kerrigan and Dylan Slack and Jens Tuyls", "title": "Differentially Private Language Models Benefit from Public Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language modeling is a keystone task in natural language processing. When\ntraining a language model on sensitive information, differential privacy (DP)\nallows us to quantify the degree to which our private data is protected.\nHowever, training algorithms which enforce differential privacy often lead to\ndegradation in model quality. We study the feasibility of learning a language\nmodel which is simultaneously high-quality and privacy preserving by tuning a\npublic base model on a private corpus. We find that DP fine-tuning boosts the\nperformance of language models in the private domain, making the training of\nsuch models possible.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 00:50:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:04:43 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kerrigan", "Gavin", ""], ["Slack", "Dylan", ""], ["Tuyls", "Jens", ""]]}, {"id": "2009.05901", "submitter": "Kuang Gong", "authors": "Nuobei Xie, Kuang Gong, Ning Guo, Zhixing Qin, Jianan Cui, Zhifang Wu,\n  Huafeng Liu, Quanzheng Li", "title": "Clinically Translatable Direct Patlak Reconstruction from Dynamic PET\n  with Motion Correction Using Convolutional Neural Network", "comments": "Accepted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patlak model is widely used in 18F-FDG dynamic positron emission tomography\n(PET) imaging, where the estimated parametric images reveal important\nbiochemical and physiology information. Because of better noise modeling and\nmore information extracted from raw sinogram, direct Patlak reconstruction\ngains its popularity over the indirect approach which utilizes reconstructed\ndynamic PET images alone. As the prerequisite of direct Patlak methods, raw\ndata from dynamic PET are rarely stored in clinics and difficult to obtain. In\naddition, the direct reconstruction is time-consuming due to the bottleneck of\nmultiple-frame reconstruction. All of these impede the clinical adoption of\ndirect Patlak reconstruction.In this work, we proposed a data-driven framework\nwhich maps the dynamic PET images to the high-quality motion-corrected direct\nPatlak images through a convolutional neural network. For the patient motion\nduring the long period of dynamic PET scan, we combined the correction with the\nbackward/forward projection in direct reconstruction to better fit the\nstatistical model. Results based on fifteen clinical 18F-FDG dynamic brain PET\ndatasets demonstrates the superiority of the proposed framework over Gaussian,\nnonlocal mean and BM4D denoising, regarding the image bias and\ncontrast-to-noise ratio.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:51:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xie", "Nuobei", ""], ["Gong", "Kuang", ""], ["Guo", "Ning", ""], ["Qin", "Zhixing", ""], ["Cui", "Jianan", ""], ["Wu", "Zhifang", ""], ["Liu", "Huafeng", ""], ["Li", "Quanzheng", ""]]}, {"id": "2009.05907", "submitter": "Yucheng Hang", "authors": "Yucheng Hang, Qingmin Liao, Wenming Yang, Yupeng Chen, Jie Zhou", "title": "Attention Cube Network for Image Restoration", "comments": "Accepted by the 28th ACM International Conference on Multimedia (ACM\n  MM 2020); Code is available at https://github.com/YCHang686/A-CubeNet", "journal-ref": null, "doi": "10.1145/3394171.3413564", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep convolutional neural network (CNN) have been widely used in\nimage restoration and obtained great success. However, most of existing methods\nare limited to local receptive field and equal treatment of different types of\ninformation. Besides, existing methods always use a multi-supervised method to\naggregate different feature maps, which can not effectively aggregate\nhierarchical feature information. To address these issues, we propose an\nattention cube network (A-CubeNet) for image restoration for more powerful\nfeature expression and feature correlation learning. Specifically, we design a\nnovel attention mechanism from three dimensions, namely spatial dimension,\nchannel-wise dimension and hierarchical dimension. The adaptive spatial\nattention branch (ASAB) and the adaptive channel attention branch (ACAB)\nconstitute the adaptive dual attention module (ADAM), which can capture the\nlong-range spatial and channel-wise contextual information to expand the\nreceptive field and distinguish different types of information for more\neffective feature representations. Furthermore, the adaptive hierarchical\nattention module (AHAM) can capture the long-range hierarchical contextual\ninformation to flexibly aggregate different feature maps by weights depending\non the global context. The ADAM and AHAM cooperate to form an \"attention in\nattention\" structure, which means AHAM's inputs are enhanced by ASAB and ACAB.\nExperiments demonstrate the superiority of our method over state-of-the-art\nimage restoration methods in both quantitative comparison and visual analysis.\nCode is available at https://github.com/YCHang686/A-CubeNet.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 03:42:14 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 03:35:45 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 11:32:04 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hang", "Yucheng", ""], ["Liao", "Qingmin", ""], ["Yang", "Wenming", ""], ["Chen", "Yupeng", ""], ["Zhou", "Jie", ""]]}, {"id": "2009.05908", "submitter": "Anderson Tavares", "authors": "Anderson R. Tavares, Pedro Avelar, Jo\\~ao M. Flach, Marcio Nicolau,\n  Luis C. Lamb, Moshe Vardi", "title": "Understanding Boolean Function Learnability on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational learning theory states that many classes of boolean formulas\nare learnable in polynomial time. This paper addresses the understudied subject\nof how, in practice, such formulas can be learned by deep neural networks.\nSpecifically, we analyse boolean formulas associated with the decision version\nof combinatorial optimisation problems, model sampling benchmarks, and random\n3-CNFs with varying degrees of constrainedness. Our extensive experiments\nindicate that: (i) regardless of the combinatorial optimisation problem,\nrelatively small and shallow neural networks are very good approximators of the\nassociated formulas; (ii) smaller formulas seem harder to learn, possibly due\nto the fewer positive (satisfying) examples available; and (iii) interestingly,\nunderconstrained 3-CNF formulas are more challenging to learn than\noverconstrained ones. Source code and relevant datasets are publicly available\n(https://github.com/machine-reasoning-ufrgs/mlbf).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 03:49:20 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 19:50:28 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Tavares", "Anderson R.", ""], ["Avelar", "Pedro", ""], ["Flach", "Jo\u00e3o M.", ""], ["Nicolau", "Marcio", ""], ["Lamb", "Luis C.", ""], ["Vardi", "Moshe", ""]]}, {"id": "2009.05923", "submitter": "Jiaqi Zeng", "authors": "Jiaqi Zeng, Pengtao Xie", "title": "Contrastive Self-supervised Learning for Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is a widely studied problem and has broad applications.\nIn many real-world problems, the number of labeled graphs available for\ntraining classification models is limited, which renders these models prone to\noverfitting. To address this problem, we propose two approaches based on\ncontrastive self-supervised learning (CSSL) to alleviate overfitting. In the\nfirst approach, we use CSSL to pretrain graph encoders on widely-available\nunlabeled graphs without relying on human-provided labels, then finetune the\npretrained encoders on labeled graphs. In the second approach, we develop a\nregularizer based on CSSL, and solve the supervised classification task and the\nunsupervised CSSL task simultaneously. To perform CSSL on graphs, given a\ncollection of original graphs, we perform data augmentation to create augmented\ngraphs out of the original graphs. An augmented graph is created by\nconsecutively applying a sequence of graph alteration operations. A contrastive\nloss is defined to learn graph encoders by judging whether two augmented graphs\nare from the same original graph. Experiments on various graph classification\ndatasets demonstrate the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 05:12:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zeng", "Jiaqi", ""], ["Xie", "Pengtao", ""]]}, {"id": "2009.05931", "submitter": "Weiwei Wang", "authors": "Weiwei Wang, Wiebke Eberhardt, Stefano Bromuri", "title": "That looks interesting! Personalizing Communication and Segmentation\n  with Random Forest Node Embeddings", "comments": "32 pages, 8 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicating effectively with customers is a challenge for many marketers,\nbut especially in a context that is both pivotal to individual long-term\nfinancial well-being and difficult to understand: pensions. Around the world,\nparticipants are reluctant to consider their pension in advance, it leads to a\nlack of preparation of their pension retirement [1], [2]. In order to engage\nparticipants to obtain information on their expected pension benefits,\npersonalizing the pension providers' email communication is a first and crucial\nstep. We describe a machine learning approach to model email newsletters to fit\nparticipants' interests. The data for the modeling and analysis is collected\nfrom newsletters sent by a large Dutch pension provider of the Netherlands and\nis divided into two parts. The first part comprises 2,228,000 customers whereas\nthe second part comprises the data of a pilot study, which took place in July\n2018 with 465,711 participants. In both cases, our algorithm extracts features\nfrom continuous and categorical data using random forests, and then calculates\nnode embeddings of the decision boundaries of the random forest. We illustrate\nthe algorithm's effectiveness for the classification task, and how it can be\nused to perform data mining tasks. In order to confirm that the result is valid\nfor more than one data set, we also illustrate the properties of our algorithm\nin benchmark data sets concerning churning. In the data sets considered, the\nproposed modeling demonstrates competitive performance with respect to other\nstate of the art approaches based on random forests, achieving the best Area\nUnder the Curve (AUC) in the pension data set (0.948). For the descriptive\npart, the algorithm can identify customer segmentations that can be used by\nmarketing departments to better target their communication towards their\ncustomers.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 06:14:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Weiwei", ""], ["Eberhardt", "Wiebke", ""], ["Bromuri", "Stefano", ""]]}, {"id": "2009.05940", "submitter": "Takuma Yoneda", "authors": "Takuma Yoneda, Matthew R. Walter, Jason Naradowsky", "title": "Pow-Wow: A Dataset and Study on Collaborative Communication in Pommerman", "comments": "Accepted at LaReL workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent learning, agents must coordinate with each other in order to\nsucceed. For humans, this coordination is typically accomplished through the\nuse of language. In this work we perform a controlled study of human language\nuse in a competitive team-based game, and search for useful lessons for\nstructuring communication protocol between autonomous agents. We construct\nPow-Wow, a new dataset for studying situated goal-directed human communication.\nUsing the Pommerman game environment, we enlisted teams of humans to play\nagainst teams of AI agents, recording their observations, actions, and\ncommunications. We analyze the types of communications which result in\neffective game strategies, annotate them accordingly, and present corpus-level\nstatistical analysis of how trends in communications affect game outcomes.\nBased on this analysis, we design a communication policy for learning agents,\nand show that agents which utilize communication achieve higher win-rates\nagainst baseline systems than those which do not.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 07:11:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yoneda", "Takuma", ""], ["Walter", "Matthew R.", ""], ["Naradowsky", "Jason", ""]]}, {"id": "2009.05949", "submitter": "Fangke Ye", "authors": "Fangke Ye, Jisheng Zhao, Vivek Sarkar", "title": "Advanced Graph-Based Deep Learning for Probabilistic Type Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamically typed languages such as JavaScript and Python have emerged as the\nmost popular programming languages in use. Important benefits can accrue from\nincluding type annotations in dynamically typed programs. This approach to\ngradual typing is exemplified by the TypeScript programming system which allows\nprogrammers to specify partially typed programs, and then uses static analysis\nto infer the remaining types. However, in general, the effectiveness of static\ntype inference is limited and depends on the complexity of the program's\nstructure and the initial type annotations. As a result, there is a strong\nmotivation for new approaches that can advance the state of the art in\nstatically predicting types in dynamically typed programs, and that do so with\nacceptable performance for use in interactive programming environments.\nPrevious work has demonstrated the promise of probabilistic type inference\nusing deep learning. In this paper, we advance past work by introducing a range\nof graph neural network (GNN) models that operate on a novel type flow graph\n(TFG) representation. The TFG represents an input program's elements as graph\nnodes connected with syntax edges and data flow edges, and our GNN models are\ntrained to predict the type labels in the TFG for a given input program. We\nstudy different design choices for our GNN models for the 100 most common types\nin our evaluation dataset, and show that our best two GNN configurations for\naccuracy achieve a top-1 accuracy of 87.76% and 86.89% respectively,\noutperforming the two most closely related deep learning type inference\napproaches from past work -- DeepTyper with a top-1 accuracy of 84.62% and\nLambdaNet with a top-1 accuracy of 79.45%. Further, the average inference\nthroughputs of those two configurations are 353.8 and 1,303.9 files/second,\ncompared to 186.7 files/second for DeepTyper and 1,050.3 files/second for\nLambdaNet.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 08:13:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ye", "Fangke", ""], ["Zhao", "Jisheng", ""], ["Sarkar", "Vivek", ""]]}, {"id": "2009.05965", "submitter": "Khanh-Hung Tran", "authors": "Khanh-Hung Tran, Fred-Maurice Ngole-Mboula and Jean-Luc Starck", "title": "Manifold attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning in general and Deep Learning in particular has gained much\ninterest in the recent decade and has shown significant performance\nimprovements for many Computer Vision or Natural Language Processing tasks. In\norder to deal with databases which have just a small amount of training samples\nor to deal with models which have large amount of parameters, the\nregularization is indispensable. In this paper, we enforce the manifold\npreservation (manifold learning) from the original data into latent\npresentation by using \"manifold attack\". The later is inspired in a fashion of\nadversarial learning : finding virtual points that distort mostly the manifold\npreservation then using these points as supplementary samples to train the\nmodel. We show that our approach of regularization provides improvements for\nthe accuracy rate and for the robustness to adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:39:32 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:17:34 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Tran", "Khanh-Hung", ""], ["Ngole-Mboula", "Fred-Maurice", ""], ["Starck", "Jean-Luc", ""]]}, {"id": "2009.05986", "submitter": "Aviv Rosenberg", "authors": "Aviv Rosenberg and Yishay Mansour", "title": "Oracle-Efficient Reinforcement Learning in Factored MDPs with Unknown\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study provably-efficient reinforcement learning in non-episodic factored\nMarkov decision processes (FMDPs). All previous regret minimization algorithms\nin this setting made the strong assumption that the factored structure of the\nFMDP is known to the learner in advance. In this paper, we provide the first\nalgorithm that learns the structure of the FMDP while minimizing the regret.\nOur algorithm is based on the optimism in face of uncertainty principle,\ncombined with a simple statistical method for structure learning, and can be\nimplemented efficiently given oracle-access to an FMDP planner. In addition, we\ngive a variant of our algorithm that remains efficient even when the oracle is\nlimited to non-factored actions, which is the case with almost all existing\napproximate planners. Finally, we also provide a novel lower bound for the\nknown structure case that matches the best known regret bound of Chen et al.\n(2020).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 12:30:35 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 13:33:45 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 13:03:06 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Rosenberg", "Aviv", ""], ["Mansour", "Yishay", ""]]}, {"id": "2009.05990", "submitter": "Nived Rajaraman", "authors": "Nived Rajaraman, Lin F. Yang, Jiantao Jiao, Kannan Ramachandran", "title": "Toward the Fundamental Limits of Imitation Learning", "comments": "45 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to mimic the behavior of an expert policy in a\nsequential decision-making problem given only demonstrations. In this paper, we\nfocus on understanding the minimax statistical limits of IL in episodic Markov\nDecision Processes (MDPs). We first consider the setting where the learner is\nprovided a dataset of $N$ expert trajectories ahead of time, and cannot\ninteract with the MDP. Here, we show that the policy which mimics the expert\nwhenever possible is in expectation $\\lesssim \\frac{|\\mathcal{S}| H^2 \\log\n(N)}{N}$ suboptimal compared to the value of the expert, even when the expert\nfollows an arbitrary stochastic policy. Here $\\mathcal{S}$ is the state space,\nand $H$ is the length of the episode. Furthermore, we establish a suboptimality\nlower bound of $\\gtrsim |\\mathcal{S}| H^2 / N$ which applies even if the expert\nis constrained to be deterministic, or if the learner is allowed to actively\nquery the expert at visited states while interacting with the MDP for $N$\nepisodes. To our knowledge, this is the first algorithm with suboptimality\nhaving no dependence on the number of actions, under no additional assumptions.\nWe then propose a novel algorithm based on minimum-distance functionals in the\nsetting where the transition model is given and the expert is deterministic.\nThe algorithm is suboptimal by $\\lesssim \\min \\{ H \\sqrt{|\\mathcal{S}| / N} ,\\\n|\\mathcal{S}| H^{3/2} / N \\}$, showing that knowledge of transition improves\nthe minimax rate by at least a $\\sqrt{H}$ factor.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 12:45:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rajaraman", "Nived", ""], ["Yang", "Lin F.", ""], ["Jiao", "Jiantao", ""], ["Ramachandran", "Kannan", ""]]}, {"id": "2009.06002", "submitter": "Takashi Takekawa", "authors": "Takashi Takekawa", "title": "Clustering of non-Gaussian data by variational Bayes for normal inverse\n  Gaussian mixture models", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models, typically Gaussian mixtures, are well known and widely\nused as model-based clustering. In practical situations, there are many\nnon-Gaussian data that are heavy-tailed and/or asymmetric. Normal inverse\nGaussian (NIG) distributions are normal-variance mean which mixing densities\nare inverse Gaussian distributions and can be used for both haavy-tail and\nasymmetry. For NIG mixture models, both expectation-maximization method and\nvariational Bayesian (VB) algorithms have been proposed. However, the existing\nVB algorithm for NIG mixture have a disadvantage that the shape of the mixing\ndensity is limited. In this paper, we propose another VB algorithm for NIG\nmixture that improves on the shortcomings. We also propose an extension of\nDirichlet process mixture models to overcome the difficulty in determining the\nnumber of clusters in finite mixture models. We evaluated the performance with\nartificial data and found that it outperformed Gaussian mixtures and existing\nimplementations for NIG mixtures, especially for highly non-normative data.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:13:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Takekawa", "Takashi", ""]]}, {"id": "2009.06005", "submitter": "Sudipta Paul Ms.", "authors": "Sudipta Paul, Poushali Sengupta and Subhankar Mishra", "title": "FLaPS: Federated Learning and Privately Scaling", "comments": "5 figures, 8 tables, Accepted to the SLICE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a distributed learning process where the model\n(weights and checkpoints) is transferred to the devices that posses data rather\nthan the classical way of transferring and aggregating the data centrally. In\nthis way, sensitive data does not leave the user devices. FL uses the FedAvg\nalgorithm, which is trained in the iterative model averaging way, on the\nnon-iid and unbalanced distributed data, without depending on the data\nquantity. Some issues with the FL are, 1) no scalability, as the model is\niteratively trained over all the devices, which amplifies with device drops; 2)\nsecurity and privacy trade-off of the learning process still not robust enough\nand 3) overall communication efficiency and the cost are higher. To mitigate\nthese challenges we present Federated Learning and Privately Scaling (FLaPS)\narchitecture, which improves scalability as well as the security and privacy of\nthe system. The devices are grouped into clusters which further gives better\nprivacy scaled turn around time to finish a round of training. Therefore, even\nif a device gets dropped in the middle of training, the whole process can be\nstarted again after a definite amount of time. The data and model both are\ncommunicated using differentially private reports with iterative shuffling\nwhich provides a better privacy-utility trade-off. We evaluated FLaPS on MNIST,\nCIFAR10, and TINY-IMAGENET-200 dataset using various CNN models. Experimental\nresults prove FLaPS to be an improved, time and privacy scaled environment\nhaving better and comparable after-learning-parameters with respect to the\ncentral and FL models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:20:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Paul", "Sudipta", ""], ["Sengupta", "Poushali", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2009.06010", "submitter": "Changyang She", "authors": "Changyang She and Chengjian Sun and Zhouyou Gu and Yonghui Li and\n  Chenyang Yang and H. Vincent Poor and Branka Vucetic", "title": "A Tutorial on Ultra-Reliable and Low-Latency Communications in 6G:\n  Integrating Domain Knowledge into Deep Learning", "comments": "This work has been accepted by Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the key communication scenarios in the 5th and also the 6th\ngeneration (6G) of mobile communication networks, ultra-reliable and\nlow-latency communications (URLLC) will be central for the development of\nvarious emerging mission-critical applications. State-of-the-art mobile\ncommunication systems do not fulfill the end-to-end delay and overall\nreliability requirements of URLLC. In particular, a holistic framework that\ntakes into account latency, reliability, availability, scalability, and\ndecision making under uncertainty is lacking. Driven by recent breakthroughs in\ndeep neural networks, deep learning algorithms have been considered as\npromising ways of developing enabling technologies for URLLC in future 6G\nnetworks. This tutorial illustrates how domain knowledge (models, analytical\ntools, and optimization frameworks) of communications and networking can be\nintegrated into different kinds of deep learning algorithms for URLLC. We first\nprovide some background of URLLC and review promising network architectures and\ndeep learning frameworks for 6G. To better illustrate how to improve learning\nalgorithms with domain knowledge, we revisit model-based analytical tools and\ncross-layer optimization frameworks for URLLC. Following that, we examine the\npotential of applying supervised/unsupervised deep learning and deep\nreinforcement learning in URLLC and summarize related open problems. Finally,\nwe provide simulation and experimental results to validate the effectiveness of\ndifferent learning algorithms and discuss future directions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:53:01 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 06:51:24 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["She", "Changyang", ""], ["Sun", "Chengjian", ""], ["Gu", "Zhouyou", ""], ["Li", "Yonghui", ""], ["Yang", "Chenyang", ""], ["Poor", "H. Vincent", ""], ["Vucetic", "Branka", ""]]}, {"id": "2009.06011", "submitter": "Berry Weinstein", "authors": "Berry Weinstein, Shai Fine, Yacov Hel-Or", "title": "Margin-Based Regularization and Selective Sampling in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new margin-based regularization formulation, termed multi-margin\nregularization (MMR), for deep neural networks (DNNs). The MMR is inspired by\nprinciples that were applied in margin analysis of shallow linear classifiers,\ne.g., support vector machine (SVM). Unlike SVM, MMR is continuously scaled by\nthe radius of the bounding sphere (i.e., the maximal norm of the feature vector\nin the data), which is constantly changing during training. We empirically\ndemonstrate that by a simple supplement to the loss function, our method\nachieves better results on various classification tasks across domains. Using\nthe same concept, we also derive a selective sampling scheme and demonstrate\naccelerated training of DNNs by selecting samples according to a minimal margin\nscore (MMS). This score measures the minimal amount of displacement an input\nshould undergo until its predicted classification is switched. We evaluate our\nproposed methods on three image classification tasks and six language text\nclassification tasks. Specifically, we show improved empirical results on\nCIFAR10, CIFAR100 and ImageNet using state-of-the-art convolutional neural\nnetworks (CNNs) and BERT-BASE architecture for the MNLI, QQP, QNLI, MRPC, SST-2\nand RTE benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:06:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Weinstein", "Berry", ""], ["Fine", "Shai", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2009.06027", "submitter": "Mohammad Hadi", "authors": "Mohammad Abdul Hadi and Fatemeh H Fard", "title": "ReviewViz: Assisting Developers Perform Empirical Study on Energy\n  Consumption Related Reviews for Mobile Applications", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": "10.1145/3387905.3388605", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Improving the energy efficiency of mobile applications is a topic that has\ngained a lot of attention recently. It has been addressed in a number of ways\nsuch as identifying energy bugs and developing a catalog of energy patterns.\nPrevious work shows that users discuss the battery-related issues (energy\ninefficiency or energy consumption) of the apps in their reviews. However,\nthere is no work that addresses the automatic extraction of battery-related\nissues from users' feedback. In this paper, we report on a visualization tool\nthat is developed to empirically study machine learning algorithms and text\nfeatures to automatically identify the energy consumption specific reviews with\nthe highest accuracy. Other than the common machine learning algorithms, we\nutilize deep learning models with different word embeddings to compare the\nresults. Furthermore, to help the developers extract the main topics that are\ndiscussed in the reviews, two states of the art topic modeling algorithms are\napplied. The visualizations of the topics represent the keywords that are\nextracted for each topic along with a comparison with the results of string\nmatching. The developed web-browser based interactive visualization tool is a\nnovel framework developed with the intention of giving the app developers\ninsights about running time and accuracy of machine learning and deep learning\nmodels as well as extracted topics. The tool makes it easier for the developers\nto traverse through the extensive result set generated by the text\nclassification and topic modeling algorithms. The dynamic-data structure used\nfor the tool stores the baseline-results of the discussed approaches and is\nupdated when applied on new datasets. The tool is open-sourced to replicate the\nresearch results.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:47:46 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 00:26:10 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Hadi", "Mohammad Abdul", ""], ["Fard", "Fatemeh H", ""]]}, {"id": "2009.06078", "submitter": "Andreas Groll", "authors": "Tobias Markus Krabel, Thi Ngoc Tien Tran, Andreas Groll, Daniel Horn,\n  Carsten Jentsch", "title": "Random boosting and random^2 forests -- A random tree depth injection\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The induction of additional randomness in parallel and sequential ensemble\nmethods has proven to be worthwhile in many aspects. In this manuscript, we\npropose and examine a novel random tree depth injection approach suitable for\nsequential and parallel tree-based approaches including Boosting and Random\nForests. The resulting methods are called \\emph{Random Boost} and\n\\emph{Random$^2$ Forest}. Both approaches serve as valuable extensions to the\nexisting literature on the gradient boosting framework and random forests. A\nMonte Carlo simulation, in which tree-shaped data sets with different numbers\nof final partitions are built, suggests that there are several scenarios where\n\\emph{Random Boost} and \\emph{Random$^2$ Forest} can improve the prediction\nperformance of conventional hierarchical boosting and random forest approaches.\nThe new algorithms appear to be especially successful in cases where there are\nmerely a few high-order interactions in the generated data. In addition, our\nsimulations suggest that our random tree depth injection approach can improve\ncomputation time by up to 40%, while at the same time the performance losses in\nterms of prediction accuracy turn out to be minor or even negligible in most\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 20:14:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Krabel", "Tobias Markus", ""], ["Tran", "Thi Ngoc Tien", ""], ["Groll", "Andreas", ""], ["Horn", "Daniel", ""], ["Jentsch", "Carsten", ""]]}, {"id": "2009.06086", "submitter": "Yuanyi Zhong", "authors": "Yuanyi Zhong, Yuan Zhou, Jian Peng", "title": "Efficient Competitive Self-Play Policy Optimization", "comments": "18 pages (10 for main text, 2 for reference, 8 for appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning from self-play has recently reported many successes.\nSelf-play, where the agents compete with themselves, is often used to generate\ntraining data for iterative policy improvement. In previous work, heuristic\nrules are designed to choose an opponent for the current learner. Typical rules\ninclude choosing the latest agent, the best agent, or a random historical\nagent. However, these rules may be inefficient in practice and sometimes do not\nguarantee convergence even in the simplest matrix games. In this paper, we\npropose a new algorithmic framework for competitive self-play reinforcement\nlearning in two-player zero-sum games. We recognize the fact that the Nash\nequilibrium coincides with the saddle point of the stochastic payoff function,\nwhich motivates us to borrow ideas from classical saddle point optimization\nliterature. Our method trains several agents simultaneously, and intelligently\ntakes each other as opponent based on simple adversarial rules derived from a\nprincipled perturbation-based saddle optimization method. We prove\ntheoretically that our algorithm converges to an approximate equilibrium with\nhigh probability in convex-concave games under standard assumptions. Beyond the\ntheory, we further show the empirical superiority of our method over baseline\nmethods relying on the aforementioned opponent-selection heuristics in matrix\ngames, grid-world soccer, Gomoku, and simulated robot sumo, with neural net\npolicy function approximators.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:01:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhong", "Yuanyi", ""], ["Zhou", "Yuan", ""], ["Peng", "Jian", ""]]}, {"id": "2009.06087", "submitter": "Alessandro Daniele", "authors": "Alessandro Daniele, Luciano Serafini", "title": "Neural Networks Enhancement through Prior Logical Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent past, there has been a growing interest in Neural-Symbolic\nIntegration frameworks, i.e., hybrid systems that integrate connectionist and\nsymbolic approaches: on the one hand, neural networks show remarkable abilities\nto learn from a large amount of data in presence of noise, on the other, pure\nsymbolic methods can perform reasoning as well as learning from few samples. By\ncombining the two paradigms, it should be possible to obtain a system that can\nboth learn from data and apply inference over some background knowledge. Here\nwe propose KENN (Knowledge Enhanced Neural Networks), a Neural-Symbolic\narchitecture that injects prior knowledge, codified in a set of universally\nquantified FOL clauses, into a neural network model. In KENN, clauses are used\nto generate a new final layer of the neural network which modifies the initial\npredictions based on the knowledge. Among the advantages of this strategy,\nthere is the possibility to include additional learnable parameters, the clause\nweights, each of which represents the strength of a specific clause. We\nevaluated KENN on two standard datasets for multi-label classification, showing\nthat the injection of clauses, automatically extracted from the training data,\nsensibly improves the performances. In a further experiment with manually\ncurated knowledge, KENN outperformed state-of-the-art methods on the VRD\nDataset, where the task is to classify relationships between detected objects\nin images. Finally, to evaluate how KENN deals with relational data, we tested\nit with different learning configurations on Citeseer, a standard dataset for\nCollective Classification. The obtained results show that KENN is capable of\nincreasing the performances of the underlying neural network even in the\npresence of relational data obtaining results in line with other methods that\ncombine learning with logic.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:12:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Daniele", "Alessandro", ""], ["Serafini", "Luciano", ""]]}, {"id": "2009.06107", "submitter": "Samuel Hopkins", "authors": "Matthew Brennan and Guy Bresler and Samuel B. Hopkins and Jerry Li and\n  Tselil Schramm", "title": "Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent", "comments": "Version 3 fixes typos and adds note on presentation at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers currently use a number of approaches to predict and substantiate\ninformation-computation gaps in high-dimensional statistical estimation\nproblems. A prominent approach is to characterize the limits of restricted\nmodels of computation, which on the one hand yields strong computational lower\nbounds for powerful classes of algorithms and on the other hand helps guide the\ndevelopment of efficient algorithms. In this paper, we study two of the most\npopular restricted computational models, the statistical query framework and\nlow-degree polynomials, in the context of high-dimensional hypothesis testing.\nOur main result is that under mild conditions on the testing problem, the two\nclasses of algorithms are essentially equivalent in power. As corollaries, we\nobtain new statistical query lower bounds for sparse PCA, tensor PCA and\nseveral variants of the planted clique problem.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:18 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:28:15 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 17:06:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Hopkins", "Samuel B.", ""], ["Li", "Jerry", ""], ["Schramm", "Tselil", ""]]}, {"id": "2009.06108", "submitter": "Tongxin Zhou", "authors": "Tongxin Zhou, Yingfei Wang, Lu (Lucy) Yan, Yong Tan", "title": "Spoiled for Choice? Personalized Recommendation for Healthcare\n  Decisions: A Multi-Armed Bandit Approach", "comments": "39 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online healthcare communities provide users with various healthcare\ninterventions to promote healthy behavior and improve adherence. When faced\nwith too many intervention choices, however, individuals may find it difficult\nto decide which option to take, especially when they lack the experience or\nknowledge to evaluate different options. The choice overload issue may\nnegatively affect users' engagement in health management. In this study, we\ntake a design-science perspective to propose a recommendation framework that\nhelps users to select healthcare interventions. Taking into account that users'\nhealth behaviors can be highly dynamic and diverse, we propose a multi-armed\nbandit (MAB)-driven recommendation framework, which enables us to adaptively\nlearn users' preference variations while promoting recommendation diversity in\nthe meantime. To better adapt an MAB to the healthcare context, we synthesize\ntwo innovative model components based on prominent health theories. The first\ncomponent is a deep-learning-based feature engineering procedure, which is\ndesigned to learn crucial recommendation contexts in regard to users'\nsequential health histories, health-management experiences, preferences, and\nintrinsic attributes of healthcare interventions. The second component is a\ndiversity constraint, which structurally diversifies recommendations in\ndifferent dimensions to provide users with well-rounded support. We apply our\napproach to an online weight management context and evaluate it rigorously\nthrough a series of experiments. Our results demonstrate that each of the\ndesign components is effective and that our recommendation design outperforms a\nwide range of state-of-the-art recommendation systems. Our study contributes to\nthe research on the application of business intelligence and has implications\nfor multiple stakeholders, including online healthcare platforms, policymakers,\nand users.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhou", "Tongxin", "", "Lucy"], ["Wang", "Yingfei", "", "Lucy"], ["Lu", "", "", "Lucy"], ["Yan", "", ""], ["Tan", "Yong", ""]]}, {"id": "2009.06111", "submitter": "Viet Anh Nguyen", "authors": "Jose Blanchet and Yang Kang and Jose Luis Montiel Olea and Viet Anh\n  Nguyen and Xuhui Zhang", "title": "Machine Learning's Dropout Training is Distributionally Robust Optimal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows that dropout training in Generalized Linear Models is the\nminimax solution of a two-player, zero-sum game where an adversarial nature\ncorrupts a statistician's covariates using a multiplicative nonparametric\nerrors-in-variables model. In this game, nature's least favorable distribution\nis dropout noise, where nature independently deletes entries of the covariate\nvector with some fixed probability $\\delta$. This result implies that dropout\ntraining indeed provides out-of-sample expected loss guarantees for\ndistributions that arise from multiplicative perturbations of in-sample data.\nIn addition to the decision-theoretic analysis, the paper makes two more\ncontributions. First, there is a concrete recommendation on how to select the\ntuning parameter $\\delta$ to guarantee that, as the sample size grows large,\nthe in-sample loss after dropout training exceeds the true population loss with\nsome pre-specified probability. Second, the paper provides a novel,\nparallelizable, Unbiased Multi-Level Monte Carlo algorithm to speed-up the\nimplementation of dropout training. Our algorithm has a much smaller\ncomputational cost compared to the naive implementation of dropout, provided\nthe number of data points is much smaller than the dimension of the covariate\nvector.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:13:28 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 05:29:05 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Blanchet", "Jose", ""], ["Kang", "Yang", ""], ["Olea", "Jose Luis Montiel", ""], ["Nguyen", "Viet Anh", ""], ["Zhang", "Xuhui", ""]]}, {"id": "2009.06112", "submitter": "Xinran Wang", "authors": "Xinran Wang, Yu Xiang, Jun Gao, Jie Ding", "title": "Information Laundering for Model Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose information laundering, a novel framework for\nenhancing model privacy. Unlike data privacy that concerns the protection of\nraw data information, model privacy aims to protect an already-learned model\nthat is to be deployed for public use. The private model can be obtained from\ngeneral learning methods, and its deployment means that it will return a\ndeterministic or random response for a given input query. An\ninformation-laundered model consists of probabilistic components that\ndeliberately maneuver the intended input and output for queries to the model,\nso the model's adversarial acquisition is less likely. Under the proposed\nframework, we develop an information-theoretic principle to quantify the\nfundamental tradeoffs between model utility and privacy leakage and derive the\noptimal design.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:24:08 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Wang", "Xinran", ""], ["Xiang", "Yu", ""], ["Gao", "Jun", ""], ["Ding", "Jie", ""]]}, {"id": "2009.06114", "submitter": "Peipei Xu", "authors": "Peipei Xu and Wenjie Ruan and Xiaowei Huang", "title": "Towards the Quantification of Safety Risks in Deep Neural Networks", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety concerns on the deep neural networks (DNNs) have been raised when they\nare applied to critical sectors. In this paper, we define safety risks by\nrequesting the alignment of the network's decision with human perception. To\nenable a general methodology for quantifying safety risks, we define a generic\nsafety property and instantiate it to express various safety risks. For the\nquantification of risks, we take the maximum radius of safe norm balls, in\nwhich no safety risk exists. The computation of the maximum safe radius is\nreduced to the computation of their respective Lipschitz metrics - the\nquantities to be computed. In addition to the known adversarial example,\nreachability example, and invariant example, in this paper we identify a new\nclass of risk - uncertainty example - on which humans can tell easily but the\nnetwork is unsure. We develop an algorithm, inspired by derivative-free\noptimization techniques and accelerated by tensor-based parallelization on\nGPUs, to support efficient computation of the metrics. We perform evaluations\non several benchmark neural networks, including ACSC-Xu, MNIST, CIFAR-10, and\nImageNet networks. The experiments show that, our method can achieve\ncompetitive performance on safety quantification in terms of the tightness and\nthe efficiency of computation. Importantly, as a generic approach, our method\ncan work with a broad class of safety risks and without restrictions on the\nstructure of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:30:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xu", "Peipei", ""], ["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2009.06116", "submitter": "Jannis Born", "authors": "Jannis Born, Nina Wiedemann, Gabriel Br\\\"andle, Charlotte Buhre,\n  Bastian Rieck, Karsten Borgwardt", "title": "Accelerating COVID-19 Differential Diagnosis with Explainable Ultrasound\n  Image Analysis", "comments": "8 pages, 4 figures", "journal-ref": "Applied Sciences 2021 (special issue on: \"Fighting COVID-19:\n  Emerging Techniques and Aid Systems for Prevention, Forecasting and\n  Diagnosis\")", "doi": "10.3390/app11020672", "report-no": null, "categories": "cs.CV cs.DB cs.DL cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Controlling the COVID-19 pandemic largely hinges upon the existence of fast,\nsafe, and highly-available diagnostic tools. Ultrasound, in contrast to CT or\nX-Ray, has many practical advantages and can serve as a globally-applicable\nfirst-line examination technique. We provide the largest publicly available\nlung ultrasound (US) dataset for COVID-19 consisting of 106 videos from three\nclasses (COVID-19, bacterial pneumonia, and healthy controls); curated and\napproved by medical experts. On this dataset, we perform an in-depth study of\nthe value of deep learning methods for differential diagnosis of COVID-19. We\npropose a frame-based convolutional neural network that correctly classifies\nCOVID-19 US videos with a sensitivity of 0.98+-0.04 and a specificity of\n0.91+-08 (frame-based sensitivity 0.93+-0.05, specificity 0.87+-0.07). We\nfurther employ class activation maps for the spatio-temporal localization of\npulmonary biomarkers, which we subsequently validate for human-in-the-loop\nscenarios in a blindfolded study with medical experts. Aiming for scalability\nand robustness, we perform ablation studies comparing mobile-friendly, frame-\nand video-based architectures and show reliability of the best model by\naleatoric and epistemic uncertainty estimates. We hope to pave the road for a\ncommunity effort toward an accessible, efficient and interpretable screening\nmethod and we have started to work on a clinical validation of the proposed\nmethod. Data and code are publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:52:03 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Born", "Jannis", ""], ["Wiedemann", "Nina", ""], ["Br\u00e4ndle", "Gabriel", ""], ["Buhre", "Charlotte", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "2009.06117", "submitter": "Kiran Vodrahalli", "authors": "Christos Papadimitriou, Kiran Vodrahalli, Mihalis Yannakakis", "title": "The Platform Design Problem", "comments": "updated with more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.LG cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-line firms deploy suites of software platforms, where each platform is\ndesigned to interact with users during a certain activity, such as browsing,\nchatting, socializing, emailing, driving, etc. The economic and incentive\nstructure of this exchange, as well as its algorithmic nature, have not been\nexplored to our knowledge. We model this interaction as a Stackelberg game\nbetween a Designer and one or more Agents. We model an Agent as a Markov chain\nwhose states are activities; we assume that the Agent's utility is a linear\nfunction of the steady-state distribution of this chain. The Designer may\ndesign a platform for each of these activities/states; if a platform is adopted\nby the Agent, the transition probabilities of the Markov chain are affected,\nand so is the objective of the Agent. The Designer's utility is a linear\nfunction of the steady state probabilities of the accessible states minus the\ndevelopment cost of the platforms. The underlying optimization problem of the\nAgent -- how to choose the states for which to adopt the platform -- is an MDP.\nIf this MDP has a simple yet plausible structure (the transition probabilities\nfrom one state to another only depend on the target state and the recurrent\nprobability of the current state) the Agent's problem can be solved by a greedy\nalgorithm. The Designer's optimization problem (designing a custom suite for\nthe Agent so as to optimize, through the Agent's optimum reaction, the\nDesigner's revenue), is NP-hard to approximate within any finite ratio;\nhowever, the special case, while still NP-hard, has an FPTAS. These results\ngeneralize from a single Agent to a distribution of Agents with finite support,\nas well as to the setting where the Designer must find the best response to the\nexisting strategies of other Designers. We discuss other implications of our\nresults and directions of future research.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:53:19 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:14:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Papadimitriou", "Christos", ""], ["Vodrahalli", "Kiran", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "2009.06125", "submitter": "Chao Ma", "authors": "Chao Ma, Lei Wu, Weinan E", "title": "A Qualitative Study of the Dynamic Behavior of Adaptive Gradient\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic behavior of RMSprop and Adam algorithms is studied through a\ncombination of careful numerical experiments and theoretical explanations.\nThree types of qualitative features are observed in the training loss curve:\nfast initial convergence, oscillations and large spikes. The sign gradient\ndescent (signGD) algorithm, which is the limit of Adam when taking the learning\nrate to $0$ while keeping the momentum parameters fixed, is used to explain the\nfast initial convergence. For the late phase of Adam, three different types of\nqualitative patterns are observed depending on the choice of the\nhyper-parameters: oscillations, spikes and divergence. In particular, Adam\nconverges faster and smoother when the values of the two momentum factors are\nclose to each other.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 00:33:48 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ma", "Chao", ""], ["Wu", "Lei", ""], ["E", "Weinan", ""]]}, {"id": "2009.06129", "submitter": "Kuang Gong", "authors": "Jianan Cui, Kuang Gong, Paul Han, Huafeng Liu, Quanzheng Li", "title": "Super Resolution of Arterial Spin Labeling MR Imaging Using Unsupervised\n  Multi-Scale Generative Adversarial Network", "comments": "Accepted to 2020 MICCAI MLMI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arterial spin labeling (ASL) magnetic resonance imaging (MRI) is a powerful\nimaging technology that can measure cerebral blood flow (CBF) quantitatively.\nHowever, since only a small portion of blood is labeled compared to the whole\ntissue volume, conventional ASL suffers from low signal-to-noise ratio (SNR),\npoor spatial resolution, and long acquisition time. In this paper, we proposed\na super-resolution method based on a multi-scale generative adversarial network\n(GAN) through unsupervised training. The network only needs the low-resolution\n(LR) ASL image itself for training and the T1-weighted image as the anatomical\nprior. No training pairs or pre-training are needed. A low-pass filter guided\nitem was added as an additional loss to suppress the noise interference from\nthe LR ASL image. After the network was trained, the super-resolution (SR)\nimage was generated by supplying the upsampled LR ASL image and corresponding\nT1-weighted image to the generator of the last layer. Performance of the\nproposed method was evaluated by comparing the peak signal-to-noise ratio\n(PSNR) and structural similarity index (SSIM) using normal-resolution (NR) ASL\nimage (5.5 min acquisition) and high-resolution (HR) ASL image (44 min\nacquisition) as the ground truth. Compared to the nearest, linear, and spline\ninterpolation methods, the proposed method recovers more detailed structure\ninformation, reduces the image noise visually, and achieves the highest PSNR\nand SSIM when using HR ASL image as the ground-truth.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 01:05:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Cui", "Jianan", ""], ["Gong", "Kuang", ""], ["Han", "Paul", ""], ["Liu", "Huafeng", ""], ["Li", "Quanzheng", ""]]}, {"id": "2009.06132", "submitter": "Chao Ma", "authors": "Zhong Li and Chao Ma and Lei Wu", "title": "Complexity Measures for Neural Networks with General Activation\n  Functions Using Path-based Norms", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple approach is proposed to obtain complexity controls for neural\nnetworks with general activation functions. The approach is motivated by\napproximating the general activation functions with one-dimensional ReLU\nnetworks, which reduces the problem to the complexity controls of ReLU\nnetworks. Specifically, we consider two-layer networks and deep residual\nnetworks, for which path-based norms are derived to control complexities. We\nalso provide preliminary analyses of the function spaces induced by these norms\nand a priori estimates of the corresponding regularized estimators.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 01:15:11 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Zhong", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "2009.06172", "submitter": "Nicholas Smith", "authors": "Nicholas Smith", "title": "The Shooting Regressor; Randomized Gradient-Based Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble method is introduced that utilizes randomization and loss\nfunction gradients to compute a prediction. Multiple weakly-correlated\nestimators approximate the gradient at randomly sampled points on the error\nsurface and are aggregated into a final solution. A scaling parameter is\ndescribed that controls a trade-off between ensemble correlation and precision.\nNumerical methods for estimating optimal values of the parameter are described.\nEmpirical results are computed over a popular dataset. Inferential statistics\non these results show that the method is capable of outperforming existing\ntechniques in terms of increased accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 03:20:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Smith", "Nicholas", ""]]}, {"id": "2009.06182", "submitter": "Matt Wand", "authors": "M.P. Wand and J.C.F. Yu", "title": "Density Estimation via Bayesian Inference Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain how effective automatic probability density function estimates can\nbe constructed using contemporary Bayesian inference engines such as those\nbased on no-U-turn sampling and expectation propagation. Extensive simulation\nstudies demonstrate that the proposed density estimates have excellent\ncomparative performance and scale well to very large sample sizes due a binning\nstrategy. Moreover, the approach is fully Bayesian and all estimates are\naccompanied by pointwise credible intervals. An accompanying package in the R\nlanguage facilitates easy use of the new density estimates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:07:51 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:09:13 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 23:17:00 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Wand", "M. P.", ""], ["Yu", "J. C. F.", ""]]}, {"id": "2009.06190", "submitter": "Tao Zhang", "authors": "Tao Zhang, Tianqing Zhu, Mengde Han, Jing Li, Wanlei Zhou, Philip S.\n  Yu", "title": "Fairness Constraints in Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness in machine learning has received considerable attention. However,\nmost studies on fair learning focus on either supervised learning or\nunsupervised learning. Very few consider semi-supervised settings. Yet, in\nreality, most machine learning tasks rely on large datasets that contain both\nlabeled and unlabeled data. One of key issues with fair learning is the balance\nbetween fairness and accuracy. Previous studies arguing that increasing the\nsize of the training set can have a better trade-off. We believe that\nincreasing the training set with unlabeled data may achieve the similar result.\nHence, we develop a framework for fair semi-supervised learning, which is\nformulated as an optimization problem. This includes classifier loss to\noptimize accuracy, label propagation loss to optimize unlabled data prediction,\nand fairness constraints over labeled and unlabeled data to optimize the\nfairness level. The framework is conducted in logistic regression and support\nvector machines under the fairness metrics of disparate impact and disparate\nmistreatment. We theoretically analyze the source of discrimination in\nsemi-supervised learning via bias, variance and noise decomposition. Extensive\nexperiments show that our method is able to achieve fair semi-supervised\nlearning, and reach a better trade-off between accuracy and fairness than fair\nsupervised learning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:25:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Tianqing", ""], ["Han", "Mengde", ""], ["Li", "Jing", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2009.06192", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Johannes Rausch, Ce Zhang, Ruoxi Jia, Dawn Song", "title": "A Principled Approach to Data Valuation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a popular technique to train machine learning (ML)\nmodels on decentralized data sources. In order to sustain long-term\nparticipation of data owners, it is important to fairly appraise each data\nsource and compensate data owners for their contribution to the training\nprocess. The Shapley value (SV) defines a unique payoff scheme that satisfies\nmany desiderata for a data value notion. It has been increasingly used for\nvaluing training data in centralized learning. However, computing the SV\nrequires exhaustively evaluating the model performance on every subset of data\nsources, which incurs prohibitive communication cost in the federated setting.\nBesides, the canonical SV ignores the order of data sources during training,\nwhich conflicts with the sequential nature of FL. This paper proposes a variant\nof the SV amenable to FL, which we call the federated Shapley value. The\nfederated SV preserves the desirable properties of the canonical SV while it\ncan be calculated without incurring extra communication cost and is also able\nto capture the effect of participation order on data value. We conduct a\nthorough empirical study of the federated SV on a range of tasks, including\nnoisy label detection, adversarial participant detection, and data\nsummarization on different benchmark datasets, and demonstrate that it can\nreflect the real utility of data sources for FL and has the potential to\nenhance system robustness, security, and efficiency. We also report and analyze\n\"failure cases\" and hope to stimulate future research.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 04:37:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Tianhao", ""], ["Rausch", "Johannes", ""], ["Zhang", "Ce", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "2009.06200", "submitter": "Bruno Adriano D.Eng.", "authors": "Bruno Adriano, Naoto Yokoya, Junshi Xia, Hiroyuki Miura, Wen Liu,\n  Masashi Matsuoka, Shunichi Koshimura", "title": "Learning from Multimodal and Multitemporal Earth Observation Data for\n  Building Damage Mapping", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earth observation technologies, such as optical imaging and synthetic\naperture radar (SAR), provide excellent means to monitor ever-growing urban\nenvironments continuously. Notably, in the case of large-scale disasters (e.g.,\ntsunamis and earthquakes), in which a response is highly time-critical, images\nfrom both data modalities can complement each other to accurately convey the\nfull damage condition in the disaster's aftermath. However, due to several\nfactors, such as weather and satellite coverage, it is often uncertain which\ndata modality will be the first available for rapid disaster response efforts.\nHence, novel methodologies that can utilize all accessible EO datasets are\nessential for disaster management. In this study, we have developed a global\nmultisensor and multitemporal dataset for building damage mapping. We included\nbuilding damage characteristics from three disaster types, namely, earthquakes,\ntsunamis, and typhoons, and considered three building damage categories. The\nglobal dataset contains high-resolution optical imagery and\nhigh-to-moderate-resolution multiband SAR data acquired before and after each\ndisaster. Using this comprehensive dataset, we analyzed five data modality\nscenarios for damage mapping: single-mode (optical and SAR datasets),\ncross-modal (pre-disaster optical and post-disaster SAR datasets), and mode\nfusion scenarios. We defined a damage mapping framework for the semantic\nsegmentation of damaged buildings based on a deep convolutional neural network\nalgorithm. We compare our approach to another state-of-the-art baseline model\nfor damage mapping. The results indicated that our dataset, together with a\ndeep learning network, enabled acceptable predictions for all the data modality\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:04:19 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Adriano", "Bruno", ""], ["Yokoya", "Naoto", ""], ["Xia", "Junshi", ""], ["Miura", "Hiroyuki", ""], ["Liu", "Wen", ""], ["Matsuoka", "Masashi", ""], ["Koshimura", "Shunichi", ""]]}, {"id": "2009.06202", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Risk Bounds for Robust Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that certain loss functions can render deep-learning\npipelines robust against flaws in the data. In this paper, we support these\nempirical findings with statistical theory. We especially show that\nempirical-risk minimization with unbounded, Lipschitz-continuous loss\nfunctions, such as the least-absolute deviation loss, Huber loss, Cauchy loss,\nand Tukey's biweight loss, can provide efficient prediction under minimal\nassumptions on the data. More generally speaking, our paper provides\ntheoretical evidence for the benefits of robust loss functions in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:06:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "2009.06211", "submitter": "Fangda Gu", "authors": "Fangda Gu, Heng Chang, Wenwu Zhu, Somayeh Sojoudi, Laurent El Ghaoui", "title": "Implicit Graph Neural Networks", "comments": "Accepted by NeurIPS 2020 at:\n  https://papers.nips.cc/paper/2020/hash/8b5c8441a8ff8e151b191c53c1842a38-Abstract.html", "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)\n  11984-11995", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) are widely used deep learning models that learn\nmeaningful representations from graph-structured data. Due to the finite nature\nof the underlying recurrent structure, current GNN methods may struggle to\ncapture long-range dependencies in underlying graphs. To overcome this\ndifficulty, we propose a graph learning framework, called Implicit Graph Neural\nNetworks (IGNN), where predictions are based on the solution of a fixed-point\nequilibrium equation involving implicitly defined \"state\" vectors. We use the\nPerron-Frobenius theory to derive sufficient conditions that ensure\nwell-posedness of the framework. Leveraging implicit differentiation, we derive\na tractable projected gradient descent method to train the framework.\nExperiments on a comprehensive range of tasks show that IGNNs consistently\ncapture long-range dependencies and outperform the state-of-the-art GNN models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:04:55 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 19:17:06 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 07:21:32 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Gu", "Fangda", ""], ["Chang", "Heng", ""], ["Zhu", "Wenwu", ""], ["Sojoudi", "Somayeh", ""], ["Ghaoui", "Laurent El", ""]]}, {"id": "2009.06215", "submitter": "Feng Zhu", "authors": "Feng Zhu, Yan Wang, Chaochao Chen, Guanfeng Liu, Mehmet Orgun, Jia Wu", "title": "A Deep Framework for Cross-Domain and Cross-System Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Domain Recommendation (CDR) and Cross-System Recommendations (CSR) are\ntwo of the promising solutions to address the long-standing data sparsity\nproblem in recommender systems. They leverage the relatively richer\ninformation, e.g., ratings, from the source domain or system to improve the\nrecommendation accuracy in the target domain or system. Therefore, finding an\naccurate mapping of the latent factors across domains or systems is crucial to\nenhancing recommendation accuracy. However, this is a very challenging task\nbecause of the complex relationships between the latent factors of the source\nand target domains or systems. To this end, in this paper, we propose a Deep\nframework for both Cross-Domain and Cross-System Recommendations, called\nDCDCSR, based on Matrix Factorization (MF) models and a fully connected Deep\nNeural Network (DNN). Specifically, DCDCSR first employs the MF models to\ngenerate user and item latent factors and then employs the DNN to map the\nlatent factors across domains or systems. More importantly, we take into\naccount the rating sparsity degrees of individual users and items in different\ndomains or systems and use them to guide the DNN training process for utilizing\nthe rating data more effectively. Extensive experiments conducted on three\nreal-world datasets demonstrate that DCDCSR framework outperforms the\nstate-of-the-art CDR and CSR approaches in terms of recommendation accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:11:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhu", "Feng", ""], ["Wang", "Yan", ""], ["Chen", "Chaochao", ""], ["Liu", "Guanfeng", ""], ["Orgun", "Mehmet", ""], ["Wu", "Jia", ""]]}, {"id": "2009.06218", "submitter": "Jing Ji", "authors": "Fanglan Zheng, Erihe, Kun Li, Jiang Tian, Xiaojia Xiang", "title": "A Vertical Federated Learning Method for Interpretable Scorecard and Its\n  Application in Credit Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of big data and artificial intelligence in many fields, the\napplications of big data driven models are expected in financial risk\nmanagement especially credit scoring and rating. Under the premise of data\nprivacy protection, we propose a projected gradient-based method in the\nvertical federated learning framework for the traditional scorecard, which is\nbased on logistic regression with bounded constraints, namely FL-LRBC. The\nlatter enables multiple agencies to jointly train an optimized scorecard model\nin a single training session. It leads to the formation of the model with\npositive coefficients, while the time-consuming parameter-tuning process can be\navoided. Moreover, the performance in terms of both AUC and the\nKolmogorov-Smirnov (KS) statistics is significantly improved due to data\nenrichment using FL-LRBC. At present, FL-LRBC has already been applied to\ncredit business in a China nation-wide financial holdings group.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:26:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zheng", "Fanglan", ""], ["Erihe", "", ""], ["Li", "Kun", ""], ["Tian", "Jiang", ""], ["Xiang", "Xiaojia", ""]]}, {"id": "2009.06224", "submitter": "Yuanyuan Shi", "authors": "Yuanyuan Shi, Baosen Zhang", "title": "Multi-Agent Reinforcement Learning in Cournot Games", "comments": "IEEE Conference on Decision and Control (CDC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the interaction of strategic agents in continuous\naction Cournot games with limited information feedback. Cournot game is the\nessential market model for many socio-economic systems where agents learn and\ncompete without the full knowledge of the system or each other. We consider the\ndynamics of the policy gradient algorithm, which is a widely adopted continuous\ncontrol reinforcement learning algorithm, in concave Cournot games. We prove\nthe convergence of policy gradient dynamics to the Nash equilibrium when the\nprice function is linear or the number of agents is two. This is the first\nresult (to the best of our knowledge) on the convergence property of learning\nalgorithms with continuous action spaces that do not fall in the no-regret\nclass.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:53:21 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shi", "Yuanyuan", ""], ["Zhang", "Baosen", ""]]}, {"id": "2009.06227", "submitter": "Pierre-Alexandre Murena", "authors": "Mustafa Mert Celikok, Pierre-Alexandre Murena, Samuel Kaski", "title": "Teaching to Learn: Sequential Teaching of Agents with Inner States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequential machine teaching, a teacher's objective is to provide the\noptimal sequence of inputs to sequential learners in order to guide them\ntowards the best model. In this paper we extend this setting from current\nstatic one-data-set analyses to learners which change their learning algorithm\nor latent state to improve during learning, and to generalize to new datasets.\nWe introduce a multi-agent formulation in which learners' inner state may\nchange with the teaching interaction, which affects the learning performance in\nfuture tasks. In order to teach such learners, we propose an optimal control\napproach that takes the future performance of the learner after teaching into\naccount. This provides tools for modelling learners having inner states, and\nmachine teaching of meta-learning algorithms. Furthermore, we distinguish\nmanipulative teaching, which can be done by effectively hiding data and also\nused for indoctrination, from more general education which aims to help the\nlearner become better at generalization and learning in new datasets in the\nabsence of a teacher.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:03:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Celikok", "Mustafa Mert", ""], ["Murena", "Pierre-Alexandre", ""], ["Kaski", "Samuel", ""]]}, {"id": "2009.06228", "submitter": "Yijue Wang", "authors": "Yijue Wang, Jieren Deng, Dan Guo, Chenghong Wang, Xianrui Meng, Hang\n  Liu, Caiwen Ding, Sanguthevar Rajasekaran", "title": "SAPAG: A Self-Adaptive Privacy Attack From Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning such as federated learning or collaborative learning\nenables model training on decentralized data from users and only collects local\ngradients, where data is processed close to its sources for data privacy. The\nnature of not centralizing the training data addresses the privacy issue of\nprivacy-sensitive data. Recent studies show that a third party can reconstruct\nthe true training data in the distributed machine learning system through the\npublicly-shared gradients. However, existing reconstruction attack frameworks\nlack generalizability on different Deep Neural Network (DNN) architectures and\ndifferent weight distribution initialization, and can only succeed in the early\ntraining phase. To address these limitations, in this paper, we propose a more\ngeneral privacy attack from gradient, SAPAG, which uses a Gaussian kernel based\nof gradient difference as a distance measure. Our experiments demonstrate that\nSAPAG can construct the training data on different DNNs with different weight\ninitializations and on DNNs in any training phases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:04:02 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Yijue", ""], ["Deng", "Jieren", ""], ["Guo", "Dan", ""], ["Wang", "Chenghong", ""], ["Meng", "Xianrui", ""], ["Liu", "Hang", ""], ["Ding", "Caiwen", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "2009.06231", "submitter": "Jun Yin", "authors": "Jun Yin, Qian Li, Shaowu Liu, Zhiang Wu, Guandong Xu", "title": "Leveraging Multi-level Dependency of Relational Sequences for Social\n  Spammer Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent research has shed light on the development of the\nrelation-dependent but content-independent framework for social spammer\ndetection. This is largely because the relation among users is difficult to be\naltered when spammers attempt to conceal their malicious intents. Our study\ninvestigates the spammer detection problem in the context of multi-relation\nsocial networks, and makes an attempt to fully exploit the sequences of\nheterogeneous relations for enhancing the detection accuracy. Specifically, we\npresent the Multi-level Dependency Model (MDM). The MDM is able to exploit\nuser's long-term dependency hidden in their relational sequences along with\nshort-term dependency. Moreover, MDM fully considers short-term relational\nsequences from the perspectives of individual-level and union-level, due to the\nfact that the type of short-term sequences is multi-folds. Experimental results\non a real-world multi-relational social network demonstrate the effectiveness\nof our proposed MDM on multi-relational social spammer detection.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:11:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yin", "Jun", ""], ["Li", "Qian", ""], ["Liu", "Shaowu", ""], ["Wu", "Zhiang", ""], ["Xu", "Guandong", ""]]}, {"id": "2009.06237", "submitter": "Jinho Lee", "authors": "Kanghyun Choi, Deokki Hong, Hojae Yoon, Joonsang Yu, Youngsok Kim,\n  Jinho Lee", "title": "DANCE: Differentiable Accelerator/Network Co-Exploration", "comments": "Accepted to DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the ever-increasing computational demand of the DNN execution,\nrecent neural architecture search (NAS) algorithms consider hardware cost\nmetrics into account, such as GPU latency. To further pursue a fast, efficient\nexecution, DNN-specialized hardware accelerators are being designed for\nmultiple purposes, which far-exceeds the efficiency of the GPUs. However, those\nhardware-related metrics have been proven to exhibit non-linear relationships\nwith the network architectures. Therefore it became a chicken-and-egg problem\nto optimize the network against the accelerator, or to optimize the accelerator\nagainst the network. In such circumstances, this work presents DANCE, a\ndifferentiable approach towards the co-exploration of the hardware accelerator\nand network architecture design. At the heart of DANCE is a differentiable\nevaluator network. By modeling the hardware evaluation software with a neural\nnetwork, the relation between the accelerator architecture and the hardware\nmetrics becomes differentiable, allowing the search to be performed with\nbackpropagation. Compared to the naive existing approaches, our method performs\nco-exploration in a significantly shorter time, while achieving superior\naccuracy and hardware cost metrics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:43:27 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 12:14:17 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 04:41:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Choi", "Kanghyun", ""], ["Hong", "Deokki", ""], ["Yoon", "Hojae", ""], ["Yu", "Joonsang", ""], ["Kim", "Youngsok", ""], ["Lee", "Jinho", ""]]}, {"id": "2009.06288", "submitter": "Javier Juan-Albarrac\\'in", "authors": "Javier Juan-Albarrac\\'in", "title": "Unsupervised learning for vascular heterogeneity assessment of\n  glioblastoma based on magnetic resonance imaging: The Hemodynamic Tissue\n  Signature", "comments": "PhD thesis. Supervisors: Juan M. Garc\\'ia-G\\'omez and Elies\n  Fuster-Garcia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis focuses on the research and development of the Hemodynamic Tissue\nSignature (HTS) method: an unsupervised machine learning approach to describe\nthe vascular heterogeneity of glioblastomas by means of perfusion MRI analysis.\nThe HTS builds on the concept of habitats. An habitat is defined as a\nsub-region of the lesion with a particular MRI profile describing a specific\nphysiological behavior. The HTS method delineates four habitats within the\nglioblastoma: the High Angiogenic Tumor (HAT) habitat, as the most perfused\nregion of the enhancing tumor; the Low Angiogenic Tumor (LAT) habitat, as the\nregion of the enhancing tumor with a lower angiogenic profile; the potentially\nInfiltrated Peripheral Edema (IPE) habitat, as the non-enhancing region\nadjacent to the tumor with elevated perfusion indexes; and the Vasogenic\nPeripheral Edema (VPE) habitat, as the remaining edema of the lesion with the\nlowest perfusion profile.\n  The results of this thesis have been published in ten scientific\ncontributions, including top-ranked journals and conferences in the areas of\nMedical Informatics, Statistics and Probability, Radiology & Nuclear Medicine,\nMachine Learning and Data Mining and Biomedical Engineering. An industrial\npatent registered in Spain (ES201431289A), Europe (EP3190542A1) and EEUU\n(US20170287133A1) was also issued, summarizing the efforts of the thesis to\ngenerate tangible assets besides the academic revenue obtained from research\npublications. Finally, the methods, technologies and original ideas conceived\nin this thesis led to the foundation of ONCOANALYTICS CDX, a company framed\ninto the business model of companion diagnostics for pharmaceutical compounds,\nthought as a vehicle to facilitate the industrialization of the ONCOhabitats\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 09:35:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Juan-Albarrac\u00edn", "Javier", ""]]}, {"id": "2009.06292", "submitter": "Murat Kirtay", "authors": "Murat Kirtay and Guido Schillaci and Verena V. Hafner", "title": "A Multisensory Learning Architecture for Rotation-invariant Object\n  Recognition", "comments": "The manuscript consists of 8 pages with 6 figures and two results\n  tables. Additionally, we provide a dedicated website to reach the dataset\n  that we employed for this study: http://www.robotmultimodal.com/datasets/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a multisensory machine learning architecture for object\nrecognition by employing a novel dataset that was constructed with the iCub\nrobot, which is equipped with three cameras and a depth sensor. The proposed\narchitecture combines convolutional neural networks to form representations\n(i.e., features) for grayscaled color images and a multi-layer perceptron\nalgorithm to process depth data. To this end, we aimed to learn joint\nrepresentations of different modalities (e.g., color and depth) and employ them\nfor recognizing objects. We evaluate the performance of the proposed\narchitecture by benchmarking the results obtained with the models trained\nseparately with the input of different sensors and a state-of-the-art data\nfusion technique, namely decision level fusion. The results show that our\narchitecture improves the recognition accuracy compared with the models that\nuse inputs from a single modality and decision level multimodal fusion method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 09:39:48 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kirtay", "Murat", ""], ["Schillaci", "Guido", ""], ["Hafner", "Verena V.", ""]]}, {"id": "2009.06303", "submitter": "Pengqian Yu", "authors": "Pengqian Yu, Achintya Kundu, Laura Wynter, Shiau Hong Lim", "title": "Fed+: A Unified Approach to Robust Personalized Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of methods for robust, personalized federated learning,\ncalled Fed+, that unifies many federated learning algorithms. The principal\nadvantage of this class of methods is to better accommodate the real-world\ncharacteristics found in federated training, such as the lack of IID data\nacross parties, the need for robustness to outliers or stragglers, and the\nrequirement to perform well on party-specific datasets. We achieve this through\na problem formulation that allows the central server to employ robust ways of\naggregating the local models while keeping the structure of local computation\nintact. Without making any statistical assumption on the degree of\nheterogeneity of local data across parties, we provide convergence guarantees\nfor Fed+ for convex and non-convex loss functions and robust aggregation. The\nFed+ theory is also equipped to handle heterogeneous computing environments\nincluding stragglers without additional assumptions; specifically, the\nconvergence results cover the general setting where the number of local update\nsteps across parties can vary. We demonstrate the benefits of Fed+ through\nextensive experiments across standard benchmark datasets as well as on a\nchallenging real-world problem in financial portfolio management where the\nheterogeneity of party-level data can lead to training failure in standard\nfederated learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 10:04:30 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 03:24:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yu", "Pengqian", ""], ["Kundu", "Achintya", ""], ["Wynter", "Laura", ""], ["Lim", "Shiau Hong", ""]]}, {"id": "2009.06304", "submitter": "Qi Tan", "authors": "Qi Tan, Yang Liu, Jiming Liu", "title": "Demystifying Deep Learning in Predictive Spatio-Temporal Analytics: An\n  Information-Theoretic Framework", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3015215", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved incredible success over the past years, especially\nin various challenging predictive spatio-temporal analytics (PSTA) tasks, such\nas disease prediction, climate forecast, and traffic prediction, where\nintrinsic dependency relationships among data exist and generally manifest at\nmultiple spatio-temporal scales. However, given a specific PSTA task and the\ncorresponding dataset, how to appropriately determine the desired configuration\nof a deep learning model, theoretically analyze the model's learning behavior,\nand quantitatively characterize the model's learning capacity remains a\nmystery. In order to demystify the power of deep learning for PSTA, in this\npaper, we provide a comprehensive framework for deep learning model design and\ninformation-theoretic analysis. First, we develop and demonstrate a novel\ninteractively- and integratively-connected deep recurrent neural network\n(I$^2$DRNN) model. I$^2$DRNN consists of three modules: an Input module that\nintegrates data from heterogeneous sources; a Hidden module that captures the\ninformation at different scales while allowing the information to flow\ninteractively between layers; and an Output module that models the integrative\neffects of information from various hidden layers to generate the output\npredictions. Second, to theoretically prove that our designed model can learn\nmulti-scale spatio-temporal dependency in PSTA tasks, we provide an\ninformation-theoretic analysis to examine the information-based learning\ncapacity (i-CAP) of the proposed model. Third, to validate the I$^2$DRNN model\nand confirm its i-CAP, we systematically conduct a series of experiments\ninvolving both synthetic datasets and real-world PSTA tasks. The experimental\nresults show that the I$^2$DRNN model outperforms both classical and\nstate-of-the-art models, and is able to capture meaningful multi-scale\nspatio-temporal dependency.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 10:05:14 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:21:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tan", "Qi", ""], ["Liu", "Yang", ""], ["Liu", "Jiming", ""]]}, {"id": "2009.06332", "submitter": "Jiacheng Ruan", "authors": "Jiacheng Ruan and Jiahao Li", "title": "Adaptive Generation Model: A New Ensemble Method", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a common method in Machine Learning, Ensemble Method is used to train\nmultiple models from a data set and obtain better results through certain\ncombination strategies. Stacking method, as representatives of Ensemble\nLearning methods, is often used in Machine Learning Competitions such as\nKaggle. This paper proposes a variant of Stacking Model based on the idea of\ngcForest, namely Adaptive Generation Model (AGM). It means that the adaptive\ngeneration is performed not only in the horizontal direction to expand the\nwidth of each layer model, but also in the vertical direction to expand the\ndepth of the model. For base models of AGM, they all come from preset basic\nMachine Learning Models. In addition, a feature augmentation method is added\nbetween layers to further improve the overall accuracy of the model. Finally,\nthrough comparative experiments on 7 data sets, the results show that the\naccuracy of AGM are better than its previous models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 11:34:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ruan", "Jiacheng", ""], ["Li", "Jiahao", ""]]}, {"id": "2009.06342", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Alexander Schulz and Terrence C. Stewart and\n  Barbara Hammer", "title": "Reservoir Memory Machines as Neural Computers", "comments": "In print at the special issue 'New Frontiers in Extremely Efficient\n  Reservoir Computing' of IEEE TNNLS", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3094139", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable neural computers extend artificial neural networks with an\nexplicit memory without interference, thus enabling the model to perform\nclassic computation tasks such as graph traversal. However, such models are\ndifficult to train, requiring long training times and large datasets. In this\nwork, we achieve some of the computational capabilities of differentiable\nneural computers with a model that can be trained very efficiently, namely an\necho state network with an explicit memory without interference. This extension\nenables echo state networks to recognize all regular languages, including those\nthat contractive echo state networks provably can not recognize. Further, we\ndemonstrate experimentally that our model performs comparably to its\nfully-trained deep version on several typical benchmark tasks for\ndifferentiable neural computers.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:01:30 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 08:57:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["Schulz", "Alexander", ""], ["Stewart", "Terrence C.", ""], ["Hammer", "Barbara", ""]]}, {"id": "2009.06343", "submitter": "Selahattin Serdar Helli", "authors": "Selahattin Serdar Helli, \\c{C}a\\u{g}kan Dem\\.irc\\.i, Onur \\c{C}oban\n  and Anda\\c{c} Hamamci", "title": "Short-Term Forecasting COVID-19 Cases In Turkey Using Long Short-Term\n  Memory Network", "comments": "4 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has been one of the most severe diseases, causing a harsh pandemic\nall over the world, since December 2019. The aim of this study is to evaluate\nthe value of Long Short-Term Memory (LSTM) Networks in forecasting the total\nnumber of COVID-19 cases in Turkey. The COVID-19 data for 30 days, between\nMarch 24 and April 23, 2020, are used to estimate the next fifteen days. The\nmean absolute error of the LSTM Network for 15 days estimation is\n1,69$\\pm$1.35%. Whereas, for the same data, the error of the Box-Jenkins method\nis 3.24$\\pm$1.56%, Prophet method is 6.88$\\pm$4.96% and Holt-Winters Additive\nmethod with Damped Trend is 0.47$\\pm$0.28%. Additionally, when the number of\ndeaths data is also provided with the number of total cases to the input of\nLSTM Network, the mean error reduces to 0.99$\\pm$0.51%. Consequently, addition\nof the number of deaths data to the input, results a lower error in\nforecasting, compared to using only the number of total cases as the input.\nHowever, Holt-Winters Additive method with Damped Trend gives superior results\nto LSTM Networks in forecasting the total number of COVID-19 cases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:01:40 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 12:10:32 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Helli", "Selahattin Serdar", ""], ["Demirci", "\u00c7a\u011fkan", ""], ["\u00c7oban", "Onur", ""], ["Hamamci", "Anda\u00e7", ""]]}, {"id": "2009.06349", "submitter": "Mark Keane", "authors": "Courtney Ford and Eoin M. Kenny and Mark T. Keane", "title": "Play MNIST For Me! User Studies on the Effects of Post-Hoc,\n  Example-Based Explanations & Error Rates on Debugging a Deep Learning,\n  Black-Box Classifier", "comments": "2 Figures, 1 Table, 8 pages", "journal-ref": "IJCAI-20 Workshop on Explainable AI (XAI), September 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports two experiments (N=349) on the impact of post hoc\nexplanations by example and error rates on peoples perceptions of a black box\nclassifier. Both experiments show that when people are given case based\nexplanations, from an implemented ANN CBR twin system, they perceive miss\nclassifications to be more correct. They also show that as error rates increase\nabove 4%, people trust the classifier less and view it as being less correct,\nless reasonable and less trustworthy. The implications of these results for XAI\nare discussed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:55:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ford", "Courtney", ""], ["Kenny", "Eoin M.", ""], ["Keane", "Mark T.", ""]]}, {"id": "2009.06355", "submitter": "Jamie Carr", "authors": "Jamie Carr", "title": "Using Graph Convolutional Networks and TD($\\lambda$) to play the game of\n  Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk is 6 player game with significant randomness and a large game-tree\ncomplexity which poses a challenge to creating an agent to play the game\neffectively. Previous AIs focus on creating high-level handcrafted features\ndetermine agent decision making. In this project, I create D.A.D, A Risk agent\nusing temporal difference reinforcement learning to train a Deep Neural Network\nincluding a Graph Convolutional Network to evaluate player positions. This is\nused in a game-tree to select optimal moves. This allows minimal handcrafting\nof knowledge into the AI, assuring input features are as low-level as possible\nto allow the network to extract useful and sophisticated features itself, even\nwith the network starting from a random initialisation. I also tackle the issue\nof non-determinism in Risk by introducing a new method of interpreting attack\nmoves necessary for the search. The result is an AI which wins 35% of the time\nversus 5 of best inbuilt AIs in Lux Delux, a Risk variant.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:47:08 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Carr", "Jamie", ""]]}, {"id": "2009.06356", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Adam Summerville, Sam Snodgrass, Gerard Bentley, Joseph\n  Osborn", "title": "Exploring Level Blending across Platformers via Paths and Affordances", "comments": "6 pages, 5 figures, 16th AAAI Conference on Artificial Intelligence\n  and Interactive Digital Entertainment (AIIDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for procedural content generation via machine learning (PCGML)\nhave been shown to be useful for generating novel game content. While used\nprimarily for producing new content in the style of the game domain used for\ntraining, recent works have increasingly started to explore methods for\ndiscovering and generating content in novel domains via techniques such as\nlevel blending and domain transfer. In this paper, we build on these works and\nintroduce a new PCGML approach for producing novel game content spanning\nmultiple domains. We use a new affordance and path vocabulary to encode data\nfrom six different platformer games and train variational autoencoders on this\ndata, enabling us to capture the latent level space spanning all the domains\nand generate new content with varying proportions of the different domains.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:43:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sarkar", "Anurag", ""], ["Summerville", "Adam", ""], ["Snodgrass", "Sam", ""], ["Bentley", "Gerard", ""], ["Osborn", "Joseph", ""]]}, {"id": "2009.06358", "submitter": "Mehrdad Yousefzadeh", "authors": "Ruixiao Sun, Jie Yang, Mehrdad Yousefzadeh", "title": "Improving Language Generation with Sentence Coherence Objective", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional story generation and contextual text continuation have become\nincreasingly popular topics in NLP community. Existing models are often prone\nto output paragraphs of texts that gradually diverge from the given prompt.\nAlthough the generated text may have a reasonable perplexity and diversity, it\ncould easily be identified by human as gibberish. The goal of our project is to\nimprove the coherence and consistency across sentences in a language-generation\nmodel. We aim to solve this issue by first training a sentence pair coherence\nclassifier with GPT-2 pretrained model, and then co-train the GPT-2 language\nmodel with this new coherence objective using a method analogous to the\nREINFORCE algorithm. This fine-tuned language model is able to generate lengthy\nparagraph conditioned on a given topic without diverging too much. The\nsimplicity of this model allows it to be applicable to a variety of underlying\nlanguage model architecture since it only modifies the final layer of the\npre-trained model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:10:03 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sun", "Ruixiao", ""], ["Yang", "Jie", ""], ["Yousefzadeh", "Mehrdad", ""]]}, {"id": "2009.06365", "submitter": "Krenare Pireva Nuci", "authors": "Arianit Mehana and Krenare Pireva Nuci", "title": "Fraud Detection using Data-Driven approach", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extensive use of the internet is continuously drifting businesses to\nincorporate their services in the online environment. One of the first\nspectrums to embrace this evolution was the banking sector. In fact, the first\nknown online banking service came in 1980. It was deployed from a community\nbank located in Knoxville, called the United American Bank. Since then,\ninternet banking has been offering ease and efficiency to costumers in\ncompleting their daily banking tasks.\n  The ever increasing use of internet banking and a large number of online\ntransactions increased fraudulent behavior also. As if fraud increase was not\nenough, the massive number of online transactions further increased the data\ncomplexity. Modern data sources are not only complex but generated at high\nspeed and in real-time as well. This presents a serious problem and a definite\nreason why more advanced solutions are desired to protect financial service\ncompanies and credit cardholders.\n  Therefore, this research paper aims to construct an efficient fraud detection\nmodel which is adaptive to customer behavior changes and tends to decrease\nfraud manipulation, by detecting and filtering fraud in real-time. In order to\nachieve this aim, a review of various methods is conducted, adding above a\npersonal experience working in the Banking sector, specifically in the Fraud\nDetection office. Unlike the majority of reviewed methods, the proposed model\nin this research paper is able to detect fraud in the moment of occurrence\nusing an incremental classifier. The evaluation of synthetic data, based on\nfraud scenarios selected in collaboration with domain experts that replicate\ntypical, real-world attacks, shows that this approach correctly ranks complex\nfrauds. In particular, our proposal detects fraudulent behavior and anomalies\nwith up to 97\\% detection rate while maintaining a satisfyingly low cost.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 20:58:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mehana", "Arianit", ""], ["Nuci", "Krenare Pireva", ""]]}, {"id": "2009.06367", "submitter": "Benjamin Krause", "authors": "Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, Nitish Shirish\n  Keskar, Shafiq Joty, Richard Socher, Nazneen Fatema Rajani", "title": "GeDi: Generative Discriminator Guided Sequence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While large-scale language models (LMs) are able to imitate the distribution\nof natural language well enough to generate realistic text, it is difficult to\ncontrol which regions of the distribution they generate. This is especially\nproblematic because datasets used for training large LMs usually contain\nsignificant toxicity, hate, bias, and negativity. We propose GeDi as an\nefficient method for using smaller LMs as generative discriminators to guide\ngeneration from large LMs to make them safer and more controllable. GeDi guides\ngeneration at each step by computing classification probabilities for all\npossible next tokens via Bayes rule by normalizing over two class-conditional\ndistributions; one conditioned on the desired attribute, or control code, and\nanother conditioned on the undesired attribute, or anti control code. We find\nthat GeDi gives stronger controllability than the state of the art method while\nalso achieving generation speeds more than 30 times faster. Additionally,\ntraining GeDi on only four topics allows us to controllably generate new topics\nzero-shot from just a keyword, unlocking a new capability that previous\ncontrollable generation methods do not have. Lastly, we show that GeDi can make\nGPT-2 (1.5B parameters) significantly less toxic without sacrificing linguistic\nquality, making it by far the most practical existing method for detoxifying\nlarge language models while maintaining a fast generation speed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:45:36 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:14:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Krause", "Ben", ""], ["Gotmare", "Akhilesh Deepak", ""], ["McCann", "Bryan", ""], ["Keskar", "Nitish Shirish", ""], ["Joty", "Shafiq", ""], ["Socher", "Richard", ""], ["Rajani", "Nazneen Fatema", ""]]}, {"id": "2009.06368", "submitter": "Yanjun  Qi Dr.", "authors": "Jin Yong Yoo, John X. Morris, Eli Lifland, Yanjun Qi", "title": "Searching for a Search Method: Benchmarking Search Algorithms for\n  Generating NLP Adversarial Examples", "comments": "14 pages, 5 figures, 4 tables; Accepted by EMNLP BlackBox NLP\n  Workshop 2020 @ https://blackboxnlp.github.io/cfp.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of several black-box search algorithms used for\ngenerating adversarial examples for natural language processing (NLP) tasks. We\nperform a fine-grained analysis of three elements relevant to search: search\nalgorithm, search space, and search budget. When new search algorithms are\nproposed in past work, the attack search space is often modified alongside the\nsearch algorithm. Without ablation studies benchmarking the search algorithm\nchange with the search space held constant, one cannot tell if an increase in\nattack success rate is a result of an improved search algorithm or a less\nrestrictive search space. Additionally, many previous studies fail to properly\nconsider the search algorithms' run-time cost, which is essential for\ndownstream tasks like adversarial training. Our experiments provide a\nreproducible benchmark of search algorithms across a variety of search spaces\nand query budgets to guide future research in adversarial NLP. Based on our\nexperiments, we recommend greedy attacks with word importance ranking when\nunder a time constraint or attacking long inputs, and either beam search or\nparticle swarm optimization otherwise. Code implementation shared via\nhttps://github.com/QData/TextAttack-Search-Benchmark\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:04:42 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:46:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yoo", "Jin Yong", ""], ["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Qi", "Yanjun", ""]]}, {"id": "2009.06372", "submitter": "Thai Hoang", "authors": "Thai Quoc Hoang and Phuong Thu Vu", "title": "Not-NUTs at W-NUT 2020 Task 2: A BERT-based System in Identifying\n  Informative COVID-19 English Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of 2020 when the COVID-19 pandemic is full-blown on a global scale,\npeople's need to have access to legitimate information regarding COVID-19 is\nmore urgent than ever, especially via online media where the abundance of\nirrelevant information overshadows the more informative ones. In response to\nsuch, we proposed a model that, given an English tweet, automatically\nidentifies whether that tweet bears informative content regarding COVID-19 or\nnot. By ensembling different BERTweet model configurations, we have achieved\ncompetitive results that are only shy of those by top performing teams by\nroughly 1% in terms of F1 score on the informative class. In the\npost-competition period, we have also experimented with various other\napproaches that potentially boost generalization to a new dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:49:16 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hoang", "Thai Quoc", ""], ["Vu", "Phuong Thu", ""]]}, {"id": "2009.06373", "submitter": "Huale Li", "authors": "Huale Li, Xuan Wang, Fengwei Jia, Yifan Li, Yulin Wu, Jiajia Zhang,\n  Shuhan Qi", "title": "RLCFR: Minimize Counterfactual Regret by Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual regret minimization (CFR) is a popular method to deal with\ndecision-making problems of two-player zero-sum games with imperfect\ninformation. Unlike existing studies that mostly explore for solving larger\nscale problems or accelerating solution efficiency, we propose a framework,\nRLCFR, which aims at improving the generalization ability of the CFR method. In\nthe RLCFR, the game strategy is solved by the CFR in a reinforcement learning\nframework. And the dynamic procedure of iterative interactive strategy updating\nis modeled as a Markov decision process (MDP). Our method, RLCFR, then learns a\npolicy to select the appropriate way of regret updating in the process of\niteration. In addition, a stepwise reward function is formulated to learn the\naction policy, which is proportional to how well the iteration strategy is at\neach step. Extensive experimental results on various games have shown that the\ngeneralization ability of our method is significantly improved compared with\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:20:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Huale", ""], ["Wang", "Xuan", ""], ["Jia", "Fengwei", ""], ["Li", "Yifan", ""], ["Wu", "Yulin", ""], ["Zhang", "Jiajia", ""], ["Qi", "Shuhan", ""]]}, {"id": "2009.06375", "submitter": "Nickil Maveli", "authors": "Nickil Maveli", "title": "EdinburghNLP at WNUT-2020 Task 2: Leveraging Transformers with\n  Generalized Augmentation for Identifying Informativeness in COVID-19 Tweets", "comments": "Accepted at W-NUT workshop of EMNLP 2020 (7 pages, 6 figures, 3\n  tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter and, in general, social media has become an indispensable\ncommunication channel in times of emergency. The ubiquitousness of smartphone\ngadgets enables people to declare an emergency observed in real-time. As a\nresult, more agencies are interested in programmatically monitoring Twitter\n(disaster relief organizations and news agencies). Therefore, recognizing the\ninformativeness of a Tweet can help filter noise from the large volumes of\nTweets. In this paper, we present our submission for WNUT-2020 Task 2:\nIdentification of informative COVID-19 English Tweets. Our most successful\nmodel is an ensemble of transformers, including RoBERTa, XLNet, and BERTweet\ntrained in a Semi-Supervised Learning (SSL) setting. The proposed system\nachieves an F1 score of 0.9011 on the test set (ranking 7th on the leaderboard)\nand shows significant gains in performance compared to a baseline system using\nFastText embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:57:28 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:47:10 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2021 12:28:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Maveli", "Nickil", ""]]}, {"id": "2009.06389", "submitter": "Sahib Singh", "authors": "Tom Farrand, Fatemehsadat Mireshghallah, Sahib Singh, Andrew Trask", "title": "Neither Private Nor Fair: Impact of Data Imbalance on Utility and\n  Fairness in Differential Privacy", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep learning in different fields and industries is growing day\nby day due to its performance, which relies on the availability of data and\ncompute. Data is often crowd-sourced and contains sensitive information about\nits contributors, which leaks into models that are trained on it. To achieve\nrigorous privacy guarantees, differentially private training mechanisms are\nused. However, it has recently been shown that differential privacy can\nexacerbate existing biases in the data and have disparate impacts on the\naccuracy of different subgroups of data. In this paper, we aim to study these\neffects within differentially private deep learning. Specifically, we aim to\nstudy how different levels of imbalance in the data affect the accuracy and the\nfairness of the decisions made by the model, given different levels of privacy.\nWe demonstrate that even small imbalances and loose privacy guarantees can\ncause disparate impacts.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:35:49 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 16:00:29 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 11:55:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Farrand", "Tom", ""], ["Mireshghallah", "Fatemehsadat", ""], ["Singh", "Sahib", ""], ["Trask", "Andrew", ""]]}, {"id": "2009.06390", "submitter": "Yuxi Huan", "authors": "Yuxi Huan, Fan Wu, Michail Basios, Leslie Kanthan, Lingbo Li, Baowen\n  Xu", "title": "IEO: Intelligent Evolutionary Optimisation for Hyperparameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimisation is a crucial process in searching the optimal\nmachine learning model. The efficiency of finding the optimal hyperparameter\nsettings has been a big concern in recent researches since the optimisation\nprocess could be time-consuming, especially when the objective functions are\nhighly expensive to evaluate. In this paper, we introduce an intelligent\nevolutionary optimisation algorithm which applies machine learning technique to\nthe traditional evolutionary algorithm to accelerate the overall optimisation\nprocess of tuning machine learning models in classification problems. We\ndemonstrate our Intelligent Evolutionary Optimisation (IEO)in a series of\ncontrolled experiments, comparing with traditional evolutionary optimisation in\nhyperparameter tuning. The empirical study shows that our approach accelerates\nthe optimisation speed by 30.40% on average and up to 77.06% in the best\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:47:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Huan", "Yuxi", ""], ["Wu", "Fan", ""], ["Basios", "Michail", ""], ["Kanthan", "Leslie", ""], ["Li", "Lingbo", ""], ["Xu", "Baowen", ""]]}, {"id": "2009.06398", "submitter": "Reda Marzouk", "authors": "Reda Marzouk", "title": "On Computability, Learnability and Extractability of Finite State\n  Machines from Recurrent Neural Networks", "comments": "Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at shedding some light on connections between finite state\nmachines (FSMs), and recurrent neural networks (RNNs). Examined connections in\nthis master's thesis is threefold: the extractability of finite state machines\nfrom recurrent neural networks, learnability aspects and computationnal links.\nWith respect to the former, the long-standing clustering hypothesis of RNN\nhidden state space when trained to recognize regular languages was explored,\nand new insights into this hypothesis through the lens of recent advances of\nthe generalization theory of Deep Learning are provided. As for learnability,\nan extension of the active learning framework better suited to the problem of\napproximating RNNs with FSMs is proposed, with the aim of better formalizing\nthe problem of RNN approximation by FSMs. Theoretical analysis of two possible\nscenarions in this framework were performed. With regard to computability, new\ncomputational results on the distance and the equivalence problem between RNNs\ntrained as language models and different types of weighted finite state\nmachines were given.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:55:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Marzouk", "Reda", ""]]}, {"id": "2009.06399", "submitter": "Mark Keane", "authors": "Eoin M. Kenny and Mark T. Keane", "title": "On Generating Plausible Counterfactual and Semi-Factual Explanations for\n  Deep Learning", "comments": "4 figures, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing concern that the recent progress made in AI, especially\nregarding the predictive competence of deep learning models, will be undermined\nby a failure to properly explain their operation and outputs. In response to\nthis disquiet counterfactual explanations have become massively popular in\neXplainable AI (XAI) due to their proposed computational psychological, and\nlegal benefits. In contrast however, semifactuals, which are a similar way\nhumans commonly explain their reasoning, have surprisingly received no\nattention. Most counterfactual methods address tabular rather than image data,\npartly due to the nondiscrete nature of the latter making good counterfactuals\ndifficult to define. Additionally generating plausible looking explanations\nwhich lie on the data manifold is another issue which hampers progress. This\npaper advances a novel method for generating plausible counterfactuals (and\nsemifactuals) for black box CNN classifiers doing computer vision. The present\nmethod, called PlausIble Exceptionality-based Contrastive Explanations (PIECE),\nmodifies all exceptional features in a test image to be normal from the\nperspective of the counterfactual class (hence concretely defining a\ncounterfactual). Two controlled experiments compare this method to others in\nthe literature, showing that PIECE not only generates the most plausible\ncounterfactuals on several measures, but also the best semifactuals.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:48:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kenny", "Eoin M.", ""], ["Keane", "Mark T.", ""]]}, {"id": "2009.06401", "submitter": "Pepa Atanasova", "authors": "Wojciech Ostrowski, Arnav Arora, Pepa Atanasova, Isabelle Augenstein", "title": "Multi-Hop Fact Checking of Political Claims", "comments": "10 pages, to be published at Proceedings of IJCAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed multi-hop models and datasets for studying complex\nnatural language reasoning. One notable task requiring multi-hop reasoning is\nfact checking, where a set of connected evidence pieces leads to the final\nverdict of a claim. However, existing datasets either do not provide\nannotations for gold evidence pages, or the only dataset which does (FEVER)\nmostly consists of claims which can be fact-checked with simple reasoning and\nis constructed artificially. Here, we study more complex claim verification of\nnaturally occurring claims with multiple hops over interconnected evidence\nchunks. We: 1) construct a small annotated dataset, PolitiHop, of evidence\nsentences for claim verification; 2) compare it to existing multi-hop datasets;\nand 3) study how to transfer knowledge from more extensive in- and\nout-of-domain resources to PolitiHop. We find that the task is complex and\nachieve the best performance with an architecture that specifically models\nreasoning over evidence pieces in combination with in-domain transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:54:15 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 17:00:26 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 14:06:14 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ostrowski", "Wojciech", ""], ["Arora", "Arnav", ""], ["Atanasova", "Pepa", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.06402", "submitter": "Liesbeth Allein", "authors": "Liesbeth Allein, Isabelle Augenstein and Marie-Francine Moens", "title": "Time-Aware Evidence Ranking for Fact-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truth can vary over time. Fact-checking decisions on claim veracity should\ntherefore take into account temporal information of both the claim and\nsupporting or refuting evidence. In this work, we investigate the hypothesis\nthat the timestamp of a Web page is crucial to how it should be ranked for a\ngiven claim. We delineate four temporal ranking methods that constrain evidence\nranking differently and simulate hypothesis-specific evidence rankings given\nthe evidence timestamps as gold standard. Evidence ranking in three\nfact-checking models is ultimately optimized using a learning-to-rank loss\nfunction. Our study reveals that time-aware evidence ranking not only surpasses\nrelevance assumptions based purely on semantic similarity or position in a\nsearch results list, but also improves veracity predictions of time-sensitive\nclaims in particular.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:39:49 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 09:15:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Allein", "Liesbeth", ""], ["Augenstein", "Isabelle", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2009.06403", "submitter": "Annika Pick", "authors": "Annika Pick, Sebastian Ginzel, Stefan R\\\"uping, Jil Sander, Ann\n  Christina Foldenauer, Michaela K\\\"ohm", "title": "Aligning Subjective Ratings in Clinical Decision Making", "comments": "Accepted at the ECML 2020 workshop on Machine Learning for Pharma and\n  Healthcare Applications (PharML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to objective indicators (e.g. laboratory values), clinical data\noften contain subjective evaluations by experts (e.g. disease severity\nassessments). While objective indicators are more transparent and robust, the\nsubjective evaluation contains a wealth of expert knowledge and intuition. In\nthis work, we demonstrate the potential of pairwise ranking methods to align\nthe subjective evaluation with objective indicators, creating a new score that\ncombines their advantages and facilitates diagnosis. In a case study on\npatients at risk for developing Psoriatic Arthritis, we illustrate that the\nresulting score (1) increases classification accuracy when detecting disease\npresence/absence, (2) is sparse and (3) provides a nuanced assessment of\nseverity for subsequent analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:32:35 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Pick", "Annika", ""], ["Ginzel", "Sebastian", ""], ["R\u00fcping", "Stefan", ""], ["Sander", "Jil", ""], ["Foldenauer", "Ann Christina", ""], ["K\u00f6hm", "Michaela", ""]]}, {"id": "2009.06410", "submitter": "Celine Hocquette", "authors": "Lun Ai and Stephen H. Muggleton and C\\'eline Hocquette and Mark\n  Gromowski and Ute Schmid", "title": "Beneficial and Harmful Explanatory Machine Learning", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent successes of Deep Learning in AI there has been increased\ninterest in the role and need for explanations in machine learned theories. A\ndistinct notion in this context is that of Michie's definition of Ultra-Strong\nMachine Learning (USML). USML is demonstrated by a measurable increase in human\nperformance of a task following provision to the human of a symbolic machine\nlearned theory for task performance. A recent paper demonstrates the beneficial\neffect of a machine learned logic theory for a classification task, yet no\nexisting work to our knowledge has examined the potential harmfulness of\nmachine's involvement for human comprehension during learning. This paper\ninvestigates the explanatory effects of a machine learned theory in the context\nof simple two person games and proposes a framework for identifying the\nharmfulness of machine explanations based on the Cognitive Science literature.\nThe approach involves a cognitive window consisting of two quantifiable bounds\nand it is supported by empirical evidence collected from human trials. Our\nquantitative and qualitative results indicate that human learning aided by a\nsymbolic machine learned theory which satisfies a cognitive window has achieved\nsignificantly higher performance than human self learning. Results also\ndemonstrate that human learning aided by a symbolic machine learned theory that\nfails to satisfy this window leads to significantly worse performance than\nunaided human learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:14:38 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:19:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ai", "Lun", ""], ["Muggleton", "Stephen H.", ""], ["Hocquette", "C\u00e9line", ""], ["Gromowski", "Mark", ""], ["Schmid", "Ute", ""]]}, {"id": "2009.06412", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos, Nicholas Vretos and Petros Daras", "title": "Comprehensive Comparison of Deep Learning Models for Lung and COVID-19\n  Lesion Segmentation in CT scans", "comments": "10 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an explosion in the use of Deep Learning (DL) methods\nfor medical image segmentation. However the field's reliability is hindered by\nthe lack of a common base of reference for accuracy/performance evaluation and\nthe fact that previous research uses different datasets for evaluation. In this\npaper, an extensive comparison of DL models for lung and COVID-19 lesion\nsegmentation in Computerized Tomography (CT) scans is presented, which can also\nbe used as a benchmark for testing medical image segmentation models. Four DL\narchitectures (Unet, Linknet, FPN, PSPNet) are combined with 25 randomly\ninitialized and pretrained encoders (variations of VGG, DenseNet, ResNet,\nResNext, DPN, MobileNet, Xception, Inception-v4, EfficientNet), to construct\n200 tested models. Three experimental setups are conducted for lung\nsegmentation, lesion segmentation and lesion segmentation using the original\nlung masks. A public COVID-19 dataset with 100 CT scan images (80 for train, 20\nfor validation) is used for training/validation and a different public dataset\nconsisting of 829 images from 9 CT scan volumes for testing. Multiple findings\nare provided including the best architecture-encoder models for each experiment\nas well as mean Dice results for each experiment, architecture and encoder\nindependently. Finally, the upper bounds improvements when using lung masks as\na preprocessing step or when using pretrained models are quantified. The source\ncode and 600 pretrained models for the three experiments are provided, suitable\nfor fine-tuning in experimental setups without GPU capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:05:06 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 16:54:03 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""], ["Vretos", "Nicholas", ""], ["Daras", "Petros", ""]]}, {"id": "2009.06413", "submitter": "Falco J. Bargagli Stoffi", "authors": "Falco J. Bargagli-Stoffi, Jan Niederreiter, Massimo Riccaboni", "title": "Supervised learning for the prediction of firm dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the increasing availability of granular, yet high-dimensional, firm\nlevel data, machine learning (ML) algorithms have been successfully applied to\naddress multiple research questions related to firm dynamics. Especially\nsupervised learning (SL), the branch of ML dealing with the prediction of\nlabelled outcomes, has been used to better predict firms' performance. In this\ncontribution, we will illustrate a series of SL approaches to be used for\nprediction tasks, relevant at different stages of the company life cycle. The\nstages we will focus on are (i) startup and innovation, (ii) growth and\nperformance of companies, and (iii) firms exit from the market. First, we\nreview SL implementations to predict successful startups and R&D projects.\nNext, we describe how SL tools can be used to analyze company growth and\nperformance. Finally, we review SL applications to better forecast financial\ndistress and company failure. In the concluding Section, we extend the\ndiscussion of SL methods in the light of targeted policies, result\ninterpretability, and causality.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:31:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bargagli-Stoffi", "Falco J.", ""], ["Niederreiter", "Jan", ""], ["Riccaboni", "Massimo", ""]]}, {"id": "2009.06419", "submitter": "Rahif Kassab", "authors": "Rahif Kassab and Osvaldo Simeone", "title": "Federated Generalized Bayesian Learning via Distributed Stein\n  Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Distributed Stein Variational Gradient Descent (DSVGD),\na non-parametric generalized Bayesian inference framework for federated\nlearning. DSVGD maintains a number of non-random and interacting particles at a\ncentral server to represent the current iterate of the model global posterior.\nThe particles are iteratively downloaded and updated by one of the agents with\nthe end goal of minimizing the global free energy. By varying the number of\nparticles, DSVGD enables a flexible trade-off between per-iteration\ncommunication load and number of communication rounds. DSVGD is shown to\ncompare favorably to benchmark frequentist and Bayesian federated learning\nstrategies, also scheduling a single device per iteration, in terms of accuracy\nand scalability with respect to the number of agents, while also providing\nwell-calibrated, and hence trustworthy, predictions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:33:22 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 17:31:29 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 17:35:45 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 09:34:17 GMT"}, {"version": "v5", "created": "Fri, 20 Nov 2020 08:22:57 GMT"}, {"version": "v6", "created": "Tue, 30 Mar 2021 13:14:24 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kassab", "Rahif", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2009.06421", "submitter": "Aydin Shishehgaran", "authors": "Aydin Shishegaran, Hessam Varaee, Timon Rabczuk, Gholamreza\n  Shishegaran", "title": "High correlated variables creator machine: Prediction of the compressive\n  strength of concrete", "comments": "27 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel hybrid model for predicting the\ncompressive strength of concrete using ultrasonic pulse velocity (UPV) and\nrebound number (RN). First, 516 data from 8 studies of UPV and rebound hammer\n(RH) tests was collected. Then, high correlated variables creator machine\n(HVCM) is used to create the new variables that have a better correlation with\nthe output and improve the prediction models. Three single models, including a\nstep-by-step regression (SBSR), gene expression programming (GEP) and an\nadaptive neuro-fuzzy inference system (ANFIS) as well as three hybrid models,\ni.e. HCVCM-SBSR, HCVCM-GEP and HCVCM-ANFIS, were employed to predict the\ncompressive strength of concrete. The statistical parameters and error terms\nsuch as coefficient of determination, root mean square error (RMSE), normalized\nmean square error (NMSE), fractional bias, the maximum positive and negative\nerrors, and mean absolute percentage error (MAPE), were computed to evaluate\nand compare the models. The results show that HCVCM-ANFIS can predict the\ncompressive strength of concrete better than all other models. HCVCM improves\nthe accuracy of ANFIS by 5% in the coefficient of determination, 10% in RMSE,\n3% in NMSE, 20% in MAPE, and 7% in the maximum negative error.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:06:05 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shishegaran", "Aydin", ""], ["Varaee", "Hessam", ""], ["Rabczuk", "Timon", ""], ["Shishegaran", "Gholamreza", ""]]}, {"id": "2009.06429", "submitter": "Anna Lukina", "authors": "Anna Lukina, Christian Schilling, Thomas A. Henzinger", "title": "Into the Unknown: Active Monitoring of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-network classifiers achieve high accuracy when predicting the class of\nan input that they were trained to identify. Maintaining this accuracy in\ndynamic environments, where inputs frequently fall outside the fixed set of\ninitially known classes, remains a challenge. The typical approach is to detect\ninputs from novel classes and retrain the classifier on an augmented dataset.\nHowever, not only the classifier but also the detection mechanism needs to\nadapt in order to distinguish between newly learned and yet unknown input\nclasses. To address this challenge, we introduce an algorithmic framework for\nactive monitoring of a neural network. A monitor wrapped in our framework\noperates in parallel with the neural network and interacts with a human user\nvia a series of interpretable labeling queries for incremental adaptation. In\naddition, we propose an adaptive quantitative monitor to improve precision. An\nexperimental evaluation on a diverse set of benchmarks with varying numbers of\nclasses confirms the benefits of our active monitoring framework in dynamic\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:29:47 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 13:00:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lukina", "Anna", ""], ["Schilling", "Christian", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "2009.06456", "submitter": "Qingsong Yao", "authors": "Qingsong Yao, Li Xiao, Peihang Liu and S. Kevin Zhou", "title": "Label-Free Segmentation of COVID-19 Lesions in Lung CT", "comments": "Accepted by Transaction on Medical Imaging 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scarcity of annotated images hampers the building of automated solution for\nreliable COVID-19 diagnosis and evaluation from CT. To alleviate the burden of\ndata annotation, we herein present a label-free approach for segmenting\nCOVID-19 lesions in CT via pixel-level anomaly modeling that mines out the\nrelevant knowledge from normal CT lung scans. Our modeling is inspired by the\nobservation that the parts of tracheae and vessels, which lay in the\nhigh-intensity range where lesions belong to, exhibit strong patterns. To\nfacilitate the learning of such patterns at a pixel level, we synthesize\n`lesions' using a set of surprisingly simple operations and insert the\nsynthesized `lesions' into normal CT lung scans to form training pairs, from\nwhich we learn a normalcy-converting network (NormNet) that turns an 'abnormal'\nimage back to normal. Our experiments on three different datasets validate the\neffectiveness of NormNet, which conspicuously outperforms a variety of\nunsupervised anomaly detection (UAD) methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:38:34 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 13:33:32 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 03:01:58 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Yao", "Qingsong", ""], ["Xiao", "Li", ""], ["Liu", "Peihang", ""], ["Zhou", "S. Kevin", ""]]}, {"id": "2009.06459", "submitter": "Jihong Park", "authors": "Chaouki Ben Issaid, Anis Elgabli, Jihong Park, Mehdi Bennis,\n  M\\'erouane Debbah", "title": "Communication Efficient Distributed Learning with Censored, Quantized,\n  and Generalized Group ADMM", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a communication-efficiently decentralized machine\nlearning framework that solves a consensus optimization problem defined over a\nnetwork of inter-connected workers. The proposed algorithm, Censored and\nQuantized Generalized GADMM (CQ-GGADMM), leverages the worker grouping and\ndecentralized learning ideas of Group Alternating Direction Method of\nMultipliers (GADMM), and pushes the frontier in communication efficiency by\nextending its applicability to generalized network topologies, while\nincorporating link censoring for negligible updates after quantization. We\ntheoretically prove that CQ-GGADMM achieves the linear convergence rate when\nthe local objective functions are strongly convex under some mild assumptions.\nNumerical simulations corroborate that CQ-GGADMM exhibits higher communication\nefficiency in terms of the number of communication rounds and transmit energy\nconsumption without compromising the accuracy and convergence speed, compared\nto the censored decentralized ADMM, and the worker grouping method of GADMM.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:18:19 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 05:37:15 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Issaid", "Chaouki Ben", ""], ["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "2009.06472", "submitter": "Alberto Caron", "authors": "Alberto Caron, Gianluca Baio and Ioanna Manolopoulou", "title": "Estimating Individual Treatment Effects using Non-Parametric Regression\n  Models: a Review", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large observational data are increasingly available in disciplines such as\nhealth, economic and social sciences, where researchers are interested in\ncausal questions rather than prediction. In this paper, we investigate the\nproblem of estimating heterogeneous treatment effects using non-parametric\nregression-based methods. Firstly, we introduce the setup and the issues\nrelated to conducting causal inference with observational or non-fully\nrandomized data, and how these issues can be tackled with the help of\nstatistical learning tools. Then, we provide a review of state-of-the-art\nmethods, with a particular focus on non-parametric modeling, and we cast them\nunder a unifying taxonomy. After presenting a brief overview on the problem of\nmodel selection, we illustrate the performance of some of the methods on three\ndifferent simulated studies and on a real world example to investigate the\neffect of participation in school meal programs on health indicators.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:26:55 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 10:14:48 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 20:50:50 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 23:29:04 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Caron", "Alberto", ""], ["Baio", "Gianluca", ""], ["Manolopoulou", "Ioanna", ""]]}, {"id": "2009.06487", "submitter": "Chengyu Wang", "authors": "Chengyu Wang, Mengli Cheng, Xu Hu, Jun Huang", "title": "EasyASR: A Distributed Machine Learning Platform for End-to-end\n  Automatic Speech Recognition", "comments": "aaai 2021 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EasyASR, a distributed machine learning platform for training and\nserving large-scale Automatic Speech Recognition (ASR) models, as well as\ncollecting and processing audio data at scale. Our platform is built upon the\nMachine Learning Platform for AI of Alibaba Cloud. Its main functionality is to\nsupport efficient learning and inference for end-to-end ASR models on\ndistributed GPU clusters. It allows users to learn ASR models with either\npre-defined or user-customized network architectures via simple user interface.\nOn EasyASR, we have produced state-of-the-art results over several public\ndatasets for Mandarin speech recognition.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:47:02 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 09:44:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Chengyu", ""], ["Cheng", "Mengli", ""], ["Hu", "Xu", ""], ["Huang", "Jun", ""]]}, {"id": "2009.06489", "submitter": "Sara Hooker", "authors": "Sara Hooker", "title": "The Hardware Lottery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware, systems and algorithms research communities have historically had\ndifferent incentive structures and fluctuating motivation to engage with each\nother explicitly. This historical treatment is odd given that hardware and\nsoftware have frequently determined which research ideas succeed (and fail).\nThis essay introduces the term hardware lottery to describe when a research\nidea wins because it is suited to the available software and hardware and not\nbecause the idea is superior to alternative research directions. Examples from\nearly computer science history illustrate how hardware lotteries can delay\nresearch progress by casting successful ideas as failures. These lessons are\nparticularly salient given the advent of domain specialized hardware which make\nit increasingly costly to stray off of the beaten path of research ideas. This\nessay posits that the gains from progress in computing are likely to become\neven more uneven, with certain research directions moving into the fast-lane\nwhile progress on others is further obstructed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:49:10 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 22:58:12 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hooker", "Sara", ""]]}, {"id": "2009.06492", "submitter": "Gouri Ginde Deshpande", "authors": "Gouri Deshpande and Guenther Ruhe", "title": "Beyond Accuracy: ROI-driven Data Analytics of Empirical Data", "comments": "6 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This vision paper demonstrates that it is crucial to consider\nReturn-on-Investment (ROI) when performing Data Analytics. Decisions on \"How\nmuch analytics is needed\"? are hard to answer. ROI could guide for decision\nsupport on the What?, How?, and How Much? analytics for a given problem.\nMethod: The proposed conceptual framework is validated through two empirical\nstudies that focus on requirements dependencies extraction in the Mozilla\nFirefox project. The two case studies are (i) Evaluation of fine-tuned BERT\nagainst Naive Bayes and Random Forest machine learners for binary dependency\nclassification and (ii) Active Learning against passive Learning (random\nsampling) for REQUIRES dependency extraction. For both the cases, their\nanalysis investment (cost) is estimated, and the achievable benefit from DA is\npredicted, to determine a break-even point of the investigation. Results: For\nthe first study, fine-tuned BERT performed superior to the Random Forest,\nprovided that more than 40% of training data is available. For the second,\nActive Learning achieved higher F1 accuracy within fewer iterations and higher\nROI compared to Baseline (Random sampling based RF classifier). In both the\nstudies, estimate on, How much analysis likely would pay off for the invested\nefforts?, was indicated by the break-even point. Conclusions: Decisions for the\ndepth and breadth of DA of empirical data should not be made solely based on\nthe accuracy measures. Since ROI-driven Data Analytics provides a simple yet\neffective direction to discover when to stop further investigation while\nconsidering the cost and value of the various types of analysis, it helps to\navoid over-analyzing empirical data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:49:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Deshpande", "Gouri", ""], ["Ruhe", "Guenther", ""]]}, {"id": "2009.06496", "submitter": "Fauzi Adi Rafrastara", "authors": "Etika Kartikadarma, Sari Wijayanti, Sari Ayu Wulandari, Fauzi Adi\n  Rafrastara", "title": "Principle Component Analysis for Classification of the Quality of\n  Aromatic Rice", "comments": "5 pages, 11 figures, International Journal of Computer Science and\n  Information Security (IJCSIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research introduces an instrument for performing quality control on\naromatic rice by utilizing feature extraction of Principle Component Analysis\n(PCA) method. Our proposed system (DNose v0.2) uses the principle of electronic\nnose or enose. Enose is a detector instrument that work based on classification\nof the smell, like function of human nose. It has to be trained first for\nrecognizing the smell before work in classification process. The aim of this\nresearch is to build an enose system for quality control instrument, especially\non aromatic rice. The advantage of this system is easy to operate and not\ndamaging the object of research. In this experiment, ATMega 328 and 6 gas\nsensors are involved in the electronic module and PCA method is used for\nclassification process.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:58:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kartikadarma", "Etika", ""], ["Wijayanti", "Sari", ""], ["Wulandari", "Sari Ayu", ""], ["Rafrastara", "Fauzi Adi", ""]]}, {"id": "2009.06497", "submitter": "Fauzi Adi Rafrastara", "authors": "Cinantya Paramita, Fauzi Adi Rafrastara, Usman Sudibyo, R.I.W. Agung\n  Wibowo", "title": "Performance Evaluation of Linear Regression Algorithm in Cluster\n  Environment", "comments": "4 pages, 2 figures, International Journal of Computer Science and\n  Information Security (IJCSIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster computing was introduced to replace the superiority of super\ncomputers. Cluster computing is able to overcome the problems that cannot be\neffectively dealt with supercomputers. In this paper, we are going to evaluate\nthe performance of cluster computing by executing one of data mining techniques\nin the cluster environment. The experiment will attempt to predict the flight\ndelay by using linear regression algorithm with apache spark as a framework for\ncluster computing. The result shows that, by involving 5 PCs in cluster\nenvironment with equal specifications can increase the performance of\ncomputation up to 39.76% compared to the standalone one. Attaching more nodes\nto the cluster can make the process become faster significantly.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:58:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Paramita", "Cinantya", ""], ["Rafrastara", "Fauzi Adi", ""], ["Sudibyo", "Usman", ""], ["Wibowo", "R. I. W. Agung", ""]]}, {"id": "2009.06504", "submitter": "Longxiang Liu", "authors": "Longxiang Liu, Zhuosheng Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Filling the Gap of Utterance-aware and Speaker-aware Representation for\n  Multi-turn Dialogue", "comments": "accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-turn dialogue is composed of multiple utterances from two or more\ndifferent speaker roles. Thus utterance- and speaker-aware clues are supposed\nto be well captured in models. However, in the existing retrieval-based\nmulti-turn dialogue modeling, the pre-trained language models (PrLMs) as\nencoder represent the dialogues coarsely by taking the pairwise dialogue\nhistory and candidate response as a whole, the hierarchical information on\neither utterance interrelation or speaker roles coupled in such representations\nis not well addressed. In this work, we propose a novel model to fill such a\ngap by modeling the effective utterance-aware and speaker-aware representations\nentailed in a dialogue history. In detail, we decouple the contextualized word\nrepresentations by masking mechanisms in Transformer-based PrLM, making each\nword only focus on the words in current utterance, other utterances, two\nspeaker roles (i.e., utterances of sender and utterances of receiver),\nrespectively. Experimental results show that our method boosts the strong\nELECTRA baseline substantially in four public benchmark datasets, and achieves\nvarious new state-of-the-art performance over previous methods. A series of\nablation studies are conducted to demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:07:19 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 19:01:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Longxiang", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.06505", "submitter": "M. Emre Gursoy", "authors": "Mehmet Emre Gursoy, Vivekanand Rajasekar, Ling Liu", "title": "Utility-Optimized Synthesis of Differentially Private Location Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private location trace synthesis (DPLTS) has recently emerged\nas a solution to protect mobile users' privacy while enabling the analysis and\nsharing of their location traces. A key challenge in DPLTS is to best preserve\nthe utility in location trace datasets, which is non-trivial considering the\nhigh dimensionality, complexity and heterogeneity of datasets, as well as the\ndiverse types and notions of utility. In this paper, we present OptaTrace: a\nutility-optimized and targeted approach to DPLTS. Given a real trace dataset D,\nthe differential privacy parameter epsilon controlling the strength of privacy\nprotection, and the utility/error metric Err of interest; OptaTrace uses\nBayesian optimization to optimize DPLTS such that the output error (measured in\nterms of given metric Err) is minimized while epsilon-differential privacy is\nsatisfied. In addition, OptaTrace introduces a utility module that contains\nseveral built-in error metrics for utility benchmarking and for choosing Err,\nas well as a front-end web interface for accessible and interactive DPLTS\nservice. Experiments show that OptaTrace's optimized output can yield\nsubstantial utility improvement and error reduction compared to previous work.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:07:45 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Gursoy", "Mehmet Emre", ""], ["Rajasekar", "Vivekanand", ""], ["Liu", "Ling", ""]]}, {"id": "2009.06516", "submitter": "Debabrota Basu", "authors": "Bishwamittra Ghosh, Debabrota Basu, Kuldeep S. Meel", "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness", "comments": "24 pages, 7 figures, 5 theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a technology ML is oblivious to societal good or bad, and thus, the field\nof fair machine learning has stepped up to propose multiple mathematical\ndefinitions, algorithms, and systems to ensure different notions of fairness in\nML applications. Given the multitude of propositions, it has become imperative\nto formally verify the fairness metrics satisfied by different algorithms on\ndifferent datasets. In this paper, we propose a \\textit{stochastic\nsatisfiability} (SSAT) framework, Justicia, that formally verifies different\nfairness measures of supervised learning algorithms with respect to the\nunderlying data distribution. We instantiate Justicia on multiple\nclassification and bias mitigation algorithms, and datasets to verify different\nfairness metrics, such as disparate impact, statistical parity, and equalized\nodds. Justicia is scalable, accurate, and operates on non-Boolean and compound\nsensitive attributes unlike existing distribution-based verifiers, such as\nFairSquare and VeriFair. Being distribution-based by design, Justicia is more\nrobust than the verifiers, such as AIF360, that operate on specific test\nsamples. We also theoretically bound the finite-sample error of the verified\nfairness measure.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:23:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Basu", "Debabrota", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2009.06520", "submitter": "Kevin Moran P", "authors": "Cody Watson, Nathan Cooper, David Nader Palacio, Kevin Moran and Denys\n  Poshyvanyk", "title": "A Systematic Literature Review on the Use of Deep Learning in Software\n  Engineering Research", "comments": "48 pages, Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly popular set of techniques adopted by software engineering\n(SE) researchers to automate development tasks are those rooted in the concept\nof Deep Learning (DL). The popularity of such techniques largely stems from\ntheir automated feature engineering capabilities, which aid in modeling\nsoftware artifacts. However, due to the rapid pace at which DL techniques have\nbeen adopted, it is difficult to distill the current successes, failures, and\nopportunities of the current research landscape. In an effort to bring clarity\nto this cross-cutting area of work, from its modern inception to the present,\nthis paper presents a systematic literature review of research at the\nintersection of SE & DL. The review canvases work appearing in the most\nprominent SE and DL conferences and journals and spans 84 papers across 22\nunique SE tasks. We center our analysis around the components of learning, a\nset of principles that govern the application of machine learning techniques\n(ML) to a given problem domain, discussing several aspects of the surveyed work\nat a granular level. The end result of our analysis is a research roadmap that\nboth delineates the foundations of DL techniques applied to SE research, and\nlikely areas of fertile exploration for the future.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:28:28 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Watson", "Cody", ""], ["Cooper", "Nathan", ""], ["Palacio", "David Nader", ""], ["Moran", "Kevin", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "2009.06527", "submitter": "Joseph De Vilmarest", "authors": "David Obst, Joseph de Vilmarest, Yannig Goude", "title": "Adaptive Methods for Short-Term Electricity Load Forecasting During\n  COVID-19 Lockdown in France", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease 2019 (COVID-19) pandemic has urged many governments\nin the world to enforce a strict lockdown where all nonessential businesses are\nclosed and citizens are ordered to stay at home. One of the consequences of\nthis policy is a significant change in electricity consumption patterns. Since\nload forecasting models rely on calendar or meteorological information and are\ntrained on historical data, they fail to capture the significant break caused\nby the lockdown and have exhibited poor performances since the beginning of the\npandemic. This makes the scheduling of the electricity production challenging,\nand has a high cost for both electricity producers and grid operators. In this\npaper we introduce adaptive generalized additive models using Kalman filters\nand fine-tuning to adjust to new electricity consumption patterns.\nAdditionally, knowledge from the lockdown in Italy is transferred to anticipate\nthe change of behavior in France. The proposed methods are applied to forecast\nthe electricity demand during the French lockdown period, where they\ndemonstrate their ability to significantly reduce prediction errors compared to\ntraditional models. Finally expert aggregation is used to leverage the\nspecificities of each predictions and enhance results even further.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:41:36 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Obst", "David", ""], ["de Vilmarest", "Joseph", ""], ["Goude", "Yannig", ""]]}, {"id": "2009.06530", "submitter": "Ambar Pal", "authors": "Ambar Pal, Ren\\'e Vidal", "title": "A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses", "comments": "Accepted at Neural Information Processing Systems (NeurIPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in adversarial learning follows a cat and mouse game between\nattackers and defenders where attacks are proposed, they are mitigated by new\ndefenses, and subsequently new attacks are proposed that break earlier\ndefenses, and so on. However, it has remained unclear as to whether there are\nconditions under which no better attacks or defenses can be proposed. In this\npaper, we propose a game-theoretic framework for studying attacks and defenses\nwhich exist in equilibrium. Under a locally linear decision boundary model for\nthe underlying binary classifier, we prove that the Fast Gradient Method attack\nand the Randomized Smoothing defense form a Nash Equilibrium. We then show how\nthis equilibrium defense can be approximated given finitely many samples from a\ndata-generating distribution, and derive a generalization bound for the\nperformance of our approximation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:51:15 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 20:19:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Pal", "Ambar", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "2009.06540", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Daniel M. Kane and John\n  Peebles and Eric Price", "title": "Optimal Testing of Discrete Distributions with High Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing discrete distributions with a focus on the\nhigh probability regime. Specifically, given samples from one or more discrete\ndistributions, a property $\\mathcal{P}$, and parameters $0< \\epsilon, \\delta\n<1$, we want to distinguish {\\em with probability at least $1-\\delta$} whether\nthese distributions satisfy $\\mathcal{P}$ or are $\\epsilon$-far from\n$\\mathcal{P}$ in total variation distance. Most prior work in distribution\ntesting studied the constant confidence case (corresponding to $\\delta =\n\\Omega(1)$), and provided sample-optimal testers for a range of properties.\nWhile one can always boost the confidence probability of any such tester by\nblack-box amplification, this generic boosting method typically leads to\nsub-optimal sample bounds.\n  Here we study the following broad question: For a given property\n$\\mathcal{P}$, can we {\\em characterize} the sample complexity of testing\n$\\mathcal{P}$ as a function of all relevant problem parameters, including the\nerror probability $\\delta$? Prior to this work, uniformity testing was the only\nstatistical task whose sample complexity had been characterized in this\nsetting. As our main results, we provide the first algorithms for closeness and\nindependence testing that are sample-optimal, within constant factors, as a\nfunction of all relevant parameters. We also show matching\ninformation-theoretic lower bounds on the sample complexity of these problems.\nOur techniques naturally extend to give optimal testers for related problems.\nTo illustrate the generality of our methods, we give optimal algorithms for\ntesting collections of distributions and testing closeness with unequal sized\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:09:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Kane", "Daniel M.", ""], ["Peebles", "John", ""], ["Price", "Eric", ""]]}, {"id": "2009.06546", "submitter": "Guillaume Salha", "authors": "Walid Bendada and Guillaume Salha and Th\\'eo Bontempelli", "title": "Carousel Personalization in Music Streaming Apps with Contextual Bandits", "comments": "14th ACM Conference on Recommender Systems (RecSys 2020, Best Short\n  Paper Candidate)", "journal-ref": null, "doi": "10.1145/3383313.3412217", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media services providers, such as music streaming platforms, frequently\nleverage swipeable carousels to recommend personalized content to their users.\nHowever, selecting the most relevant items (albums, artists, playlists...) to\ndisplay in these carousels is a challenging task, as items are numerous and as\nusers have different preferences. In this paper, we model carousel\npersonalization as a contextual multi-armed bandit problem with multiple plays,\ncascade-based updates and delayed batch feedback. We empirically show the\neffectiveness of our framework at capturing characteristics of real-world\ncarousels by addressing a large-scale playlist recommendation task on a global\nmusic streaming mobile app. Along with this paper, we publicly release\nindustrial data from our experiments, as well as an open-source environment to\nsimulate comparable carousel personalization learning problems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:20:34 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:35:12 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bendada", "Walid", ""], ["Salha", "Guillaume", ""], ["Bontempelli", "Th\u00e9o", ""]]}, {"id": "2009.06548", "submitter": "Daoming Lyu", "authors": "Daoming Lyu, Qi Qi, Mohammad Ghavamzadeh, Hengshuai Yao, Tianbao Yang,\n  Bo Liu", "title": "Variance-Reduced Off-Policy Memory-Efficient Policy Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy policy optimization is a challenging problem in reinforcement\nlearning (RL). The algorithms designed for this problem often suffer from high\nvariance in their estimators, which results in poor sample efficiency, and have\nissues with convergence. A few variance-reduced on-policy policy gradient\nalgorithms have been recently proposed that use methods from stochastic\noptimization to reduce the variance of the gradient estimate in the REINFORCE\nalgorithm. However, these algorithms are not designed for the off-policy\nsetting and are memory-inefficient, since they need to collect and store a\nlarge ``reference'' batch of samples from time to time. To achieve\nvariance-reduced off-policy-stable policy optimization, we propose an algorithm\nfamily that is memory-efficient, stochastically variance-reduced, and capable\nof learning from off-policy samples. Empirical studies validate the\neffectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:22:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lyu", "Daoming", ""], ["Qi", "Qi", ""], ["Ghavamzadeh", "Mohammad", ""], ["Yao", "Hengshuai", ""], ["Yang", "Tianbao", ""], ["Liu", "Bo", ""]]}, {"id": "2009.06557", "submitter": "Guannan Liang", "authors": "Qianqian Tong, Guannan Liang and Jinbo Bi", "title": "Effective Federated Adaptive Gradient Methods with Non-IID Decentralized\n  Data", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows loads of edge computing devices to collaboratively\nlearn a global model without data sharing. The analysis with partial device\nparticipation under non-IID and unbalanced data reflects more reality. In this\nwork, we propose federated learning versions of adaptive gradient methods -\nFederated AGMs - which employ both the first-order and second-order momenta, to\nalleviate generalization performance deterioration caused by dissimilarity of\ndata population among devices. To further improve the test performance, we\ncompare several schemes of calibration for the adaptive learning rate,\nincluding the standard Adam calibrated by $\\epsilon$, $p$-Adam, and one\ncalibrated by an activation function. Our analysis provides the first set of\ntheoretical results that the proposed (calibrated) Federated AGMs converge to a\nfirst-order stationary point under non-IID and unbalanced data settings for\nnonconvex optimization. We perform extensive experiments to compare these\nfederated learning methods with the state-of-the-art FedAvg, FedMomentum and\nSCAFFOLD and to assess the different calibration schemes and the advantages of\nAGMs over the current federated learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:37:44 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 01:29:59 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Tong", "Qianqian", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""]]}, {"id": "2009.06560", "submitter": "Lily Xu", "authors": "Lily Xu, Elizabeth Bondi, Fei Fang, Andrew Perrault, Kai Wang, Milind\n  Tambe", "title": "Dual-Mandate Patrols: Multi-Armed Bandits for Green Security", "comments": "Published at AAAI 2021. 9 pages (paper and references), 3 page\n  appendix. 6 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conservation efforts in green security domains to protect wildlife and\nforests are constrained by the limited availability of defenders (i.e.,\npatrollers), who must patrol vast areas to protect from attackers (e.g.,\npoachers or illegal loggers). Defenders must choose how much time to spend in\neach region of the protected area, balancing exploration of infrequently\nvisited regions and exploitation of known hotspots. We formulate the problem as\na stochastic multi-armed bandit, where each action represents a patrol\nstrategy, enabling us to guarantee the rate of convergence of the patrolling\npolicy. However, a naive bandit approach would compromise short-term\nperformance for long-term optimality, resulting in animals poached and forests\ndestroyed. To speed up performance, we leverage smoothness in the reward\nfunction and decomposability of actions. We show a synergy between\nLipschitz-continuity and decomposition as each aids the convergence of the\nother. In doing so, we bridge the gap between combinatorial and Lipschitz\nbandits, presenting a no-regret approach that tightens existing guarantees\nwhile optimizing for short-term performance. We demonstrate that our algorithm,\nLIZARD, improves performance on real-world poaching data from Cambodia.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:40:44 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 05:35:48 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Xu", "Lily", ""], ["Bondi", "Elizabeth", ""], ["Fang", "Fei", ""], ["Perrault", "Andrew", ""], ["Wang", "Kai", ""], ["Tambe", "Milind", ""]]}, {"id": "2009.06562", "submitter": "Guannan Liang", "authors": "Guannan Liang, Qianqian Tong, Jiahao Ding, Miao Pan and Jinbo Bi", "title": "Effective Proximal Methods for Non-convex Non-smooth Regularized\n  Learning", "comments": "Accepted by ICDM 2020, 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse learning is a very important tool for mining useful information and\npatterns from high dimensional data. Non-convex non-smooth regularized learning\nproblems play essential roles in sparse learning, and have drawn extensive\nattentions recently. We design a family of stochastic proximal gradient methods\nby applying arbitrary sampling to solve the empirical risk minimization problem\nwith a non-convex and non-smooth regularizer. These methods draw mini-batches\nof training examples according to an arbitrary probability distribution when\ncomputing stochastic gradients. A unified analytic approach is developed to\nexamine the convergence and computational complexity of these methods, allowing\nus to compare the different sampling schemes. We show that the independent\nsampling scheme tends to improve performance over the commonly-used uniform\nsampling scheme. Our new analysis also derives a tighter bound on convergence\nspeed for the uniform sampling than the best one available so far. Empirical\nevaluations demonstrate that the proposed algorithms converge faster than the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:41:32 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 22:42:26 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 14:43:05 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Liang", "Guannan", ""], ["Tong", "Qianqian", ""], ["Ding", "Jiahao", ""], ["Pan", "Miao", ""], ["Bi", "Jinbo", ""]]}, {"id": "2009.06571", "submitter": "Waleed Mustafa", "authors": "Waleed Mustafa, Robert A. Vandermeulen, Marius Kloft", "title": "Input Hessian Regularization of Neural Networks", "comments": "Workshop on \"Beyond first-order methods in ML systems\" at the 37th\n  International Conference on Machine Learning, Vienna, Austria, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularizing the input gradient has shown to be effective in promoting the\nrobustness of neural networks. The regularization of the input's Hessian is\ntherefore a natural next step. A key challenge here is the computational\ncomplexity. Computing the Hessian of inputs is computationally infeasible. In\nthis paper we propose an efficient algorithm to train deep neural networks with\nHessian operator-norm regularization. We analyze the approach theoretically and\nprove that the Hessian operator norm relates to the ability of a neural network\nto withstand an adversarial attack. We give a preliminary experimental\nevaluation on the MNIST and FMNIST datasets, which demonstrates that the new\nregularizer can, indeed, be feasible and, furthermore, that it increases the\nrobustness of neural networks over input gradient regularization.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:58:16 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mustafa", "Waleed", ""], ["Vandermeulen", "Robert A.", ""], ["Kloft", "Marius", ""]]}, {"id": "2009.06576", "submitter": "Miguel Navascues", "authors": "Miguel Navascues, Costantino Budroni and Yelena Guryanova", "title": "Disease control as an optimization problem", "comments": "23 pages. Missing references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, expert epidemiologists devise policies for disease control\nthrough a mixture of intuition and brute force. Namely, they use their know-how\nto narrow down the set of logically conceivable policies to a small family\ndescribed by a few parameters, following which they conduct a grid search to\nidentify the optimal policy within the set. This scheme is not scalable, in the\nsense that, when used to optimize over policies which depend on many\nparameters, it will likely fail to output an optimal disease policy in time for\nits implementation. In this article, we use techniques from convex optimization\ntheory and machine learning to conduct optimizations over disease policies\ndescribed by hundreds of parameters. In contrast to past approaches for policy\noptimization based on control theory, our framework can deal with arbitrary\nuncertainties on the initial conditions and model parameters controlling the\nspread of the disease. In addition, our methods allow for optimization over\nweekly-constant policies, specified by either continuous or discrete government\nmeasures (e.g.: lockdown on/off). We illustrate our approach by minimizing the\ntotal time required to eradicate COVID-19 within the\nSusceptible-Exposed-Infected-Recovered (SEIR) model proposed by Kissler\n\\emph{et al.} (March, 2020).\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:07:41 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 14:58:42 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 11:21:40 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Navascues", "Miguel", ""], ["Budroni", "Costantino", ""], ["Guryanova", "Yelena", ""]]}, {"id": "2009.06579", "submitter": "Tugba Erpek", "authors": "Yi Shi, Yalin E. Sagduyu, Tugba Erpek", "title": "Reinforcement Learning for Dynamic Resource Optimization in 5G Radio\n  Access Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a reinforcement learning solution to dynamic resource\nallocation for 5G radio access network slicing. Available communication\nresources (frequency-time blocks and transmit powers) and computational\nresources (processor usage) are allocated to stochastic arrivals of network\nslice requests. Each request arrives with priority (weight), throughput,\ncomputational resource, and latency (deadline) requirements, and if feasible,\nit is served with available communication and computational resources allocated\nover its requested duration. As each decision of resource allocation makes some\nof the resources temporarily unavailable for future, the myopic solution that\ncan optimize only the current resource allocation becomes ineffective for\nnetwork slicing. Therefore, a Q-learning solution is presented to maximize the\nnetwork utility in terms of the total weight of granted network slicing\nrequests over a time horizon subject to communication and computational\nconstraints. Results show that reinforcement learning provides major\nimprovements in the 5G network utility relative to myopic, random, and first\ncome first served solutions. While reinforcement learning sustains scalable\nperformance as the number of served users increases, it can also be effectively\nused to assign resources to network slices when 5G needs to share the spectrum\nwith incumbent users that may dynamically occupy some of the frequency-time\nblocks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:10:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""], ["Erpek", "Tugba", ""]]}, {"id": "2009.06586", "submitter": "Yunhao Ge", "authors": "Yunhao Ge, Sami Abu-El-Haija, Gan Xin and Laurent Itti", "title": "Zero-shot Synthesis with Group-Supervised Learning", "comments": "Published at ICLR 2021 (16 pages including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual cognition of primates is superior to that of artificial neural\nnetworks in its ability to 'envision' a visual object, even a newly-introduced\none, in different attributes including pose, position, color, texture, etc. To\naid neural networks to envision objects with different attributes, we propose a\nfamily of objective functions, expressed on groups of examples, as a novel\nlearning framework that we term Group-Supervised Learning (GSL). GSL allows us\nto decompose inputs into a disentangled representation with swappable\ncomponents, that can be recombined to synthesize new samples. For instance,\nimages of red boats & blue cars can be decomposed and recombined to synthesize\nnovel images of red cars. We propose an implementation based on auto-encoder,\ntermed group-supervised zero-shot synthesis network (GZS-Net) trained with our\nlearning framework, that can produce a high-quality red car even if no such\nexample is witnessed during training. We test our model and learning framework\non existing benchmarks, in addition to anew dataset that we open-source. We\nqualitatively and quantitatively demonstrate that GZS-Net trained with GSL\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:17:49 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 19:43:03 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 21:19:12 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ge", "Yunhao", ""], ["Abu-El-Haija", "Sami", ""], ["Xin", "Gan", ""], ["Itti", "Laurent", ""]]}, {"id": "2009.06589", "submitter": "Wenqi Wei", "authors": "Wenqi Wei and Ling Liu", "title": "Robust Deep Learning Ensemble against Deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) models are known to be vulnerable to maliciously\ncrafted adversarial examples and to out-of-distribution inputs drawn\nsufficiently far away from the training data. How to protect a machine learning\nmodel against deception of both types of destructive inputs remains an open\nchallenge. This paper presents XEnsemble, a diversity ensemble verification\nmethodology for enhancing the adversarial robustness of DNN models against\ndeception caused by either adversarial examples or out-of-distribution inputs.\nXEnsemble by design has three unique capabilities. First, XEnsemble builds\ndiverse input denoising verifiers by leveraging different data cleaning\ntechniques. Second, XEnsemble develops a disagreement-diversity ensemble\nlearning methodology for guarding the output of the prediction model against\ndeception. Third, XEnsemble provides a suite of algorithms to combine input\nverification and output verification to protect the DNN prediction models from\nboth adversarial examples and out of distribution inputs. Evaluated using\neleven popular adversarial attacks and two representative out-of-distribution\ndatasets, we show that XEnsemble achieves a high defense success rate against\nadversarial examples and a high detection success rate against\nout-of-distribution data inputs, and outperforms existing representative\ndefense methods with respect to robustness and defensibility.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:20:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""]]}, {"id": "2009.06602", "submitter": "Tavpritesh Sethi", "authors": "Raghav Awasthi, Keerat Kaur Guliani, Saif Ahmad Khan, Aniket\n  Vashishtha, Mehrab Singh Gill, Arshita Bhatt, Aditya Nagori, Aniket Gupta,\n  Ponnurangam Kumaraguru, Tavpritesh Sethi", "title": "VacSIM: Learning Effective Strategies for COVID-19 Vaccine Distribution\n  using Reinforcement Learning", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A COVID-19 vaccine is our best bet for mitigating the ongoing onslaught of\nthe pandemic. However, vaccine is also expected to be a limited resource. An\noptimal allocation strategy, especially in countries with access inequities and\ntemporal separation of hot-spots, might be an effective way of halting the\ndisease spread. We approach this problem by proposing a novel pipeline VacSIM\nthat dovetails Sequential Decision based RL models into a Contextual Bandits\napproach for optimizing the distribution of COVID-19 vaccine. Whereas the\nReinforcement Learning models suggest better actions and rewards, Contextual\nBandits allow online modifications that may need to be implemented on a\nday-to-day basis in the real world scenario. We evaluate this framework against\na naive allocation approach of distributing vaccine proportional to the\nincidence of COVID-19 cases in five different States across India and\ndemonstrate up to 9039 additional lives potentially saved and a significant\nincrease in the efficacy of limiting the spread over a period of 45 days\nthrough the VacSIM approach. We also propose novel evaluation strategies\nincluding standard compartmental model-based projections and a causality\npreserving evaluation of our model. Finally, we contribute a new Open-AI\nenvironment meant for the vaccine distribution scenario and open-source VacSIM\nfor wide testing and applications across the\nglobe(http://vacsim.tavlab.iiitd.edu.in:8000/).\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:37:13 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:21:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Awasthi", "Raghav", ""], ["Guliani", "Keerat Kaur", ""], ["Khan", "Saif Ahmad", ""], ["Vashishtha", "Aniket", ""], ["Gill", "Mehrab Singh", ""], ["Bhatt", "Arshita", ""], ["Nagori", "Aditya", ""], ["Gupta", "Aniket", ""], ["Kumaraguru", "Ponnurangam", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2009.06606", "submitter": "Arghyadip Roy", "authors": "Arghyadip Roy, Sanjay Shakkottai, R. Srikant", "title": "Hellinger KL-UCB based Bandit Algorithms for Markovian and i.i.d.\n  Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the regret-based formulation of multi-armed bandit (MAB) problems, except\nin rare instances, much of the literature focuses on arms with i.i.d. rewards.\nIn this paper, we consider the problem of obtaining regret guarantees for MAB\nproblems in which the rewards of each arm form a Markov chain which may not\nbelong to a single parameter exponential family. To achieve logarithmic regret\nin such problems is not difficult: a variation of standard KL-UCB does the job.\nHowever, the constants obtained from such an analysis are poor for the\nfollowing reason: i.i.d. rewards are a special case of Markov rewards and it is\ndifficult to design an algorithm that works well independent of whether the\nunderlying model is truly Markovian or i.i.d. To overcome this issue, we\nintroduce a novel algorithm that identifies whether the rewards from each arm\nare truly Markovian or i.i.d. using a Hellinger distance-based test. Our\nalgorithm then switches from using a standard KL-UCB to a specialized version\nof KL-UCB when it determines that the arm reward is Markovian, thus resulting\nin low regret for both i.i.d. and Markovian settings.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:44:23 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Roy", "Arghyadip", ""], ["Shakkottai", "Sanjay", ""], ["Srikant", "R.", ""]]}, {"id": "2009.06615", "submitter": "Ales Zahorski", "authors": "Ales Zahorski", "title": "Multilevel regression with poststratification for the national level\n  Viber/Street poll on the 2020 presidential election in Belarus", "comments": "45 pages, 23 figures, 18 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent sociological polls are forbidden in Belarus. Online polls\nperformed without sound scientific rigour do not yield representative results.\nYet, both inside and outside Belarus it is of great importance to obtain\nprecise estimates of the ratings of all candidates. These ratings could\nfunction as reliable proxies for the election's outcomes. We conduct an\nindependent poll based on the combination of the data collected via Viber and\non the streets of Belarus. The Viber and the street data samples consist of\nalmost 45000 and 1150 unique observations respectively. Bayesian regressions\nwith poststratification were build to estimate ratings of the candidates and\nrates of early voting turnout for the population as a whole and within various\nfocus subgroups. We show that both the officially announced results of the\nelection and early voting rates are highly improbable. With a probability of at\nleast 95%, Sviatlana Tikhanouskaya's rating lies between 75% and 80%, whereas\nAliaksandr Lukashenka's rating lies between 13% and 18% and early voting rate\npredicted by the method ranges from 9% to 13% of those who took part in the\nelection. These results contradict the officially announced outcomes, which are\n10.12%, 80.11%, and 49.54% respectively and lie far outside even the 99.9%\ncredible intervals predicted by our model. The only marginal groups of people\nwhere the upper bounds of the 99.9% credible intervals of the rating of\nLukashenka are above 50% are people older than 60 and uneducated people. For\nall other marginal subgroups, including rural residents, even the upper bounds\nof 99.9% credible intervals for Lukashenka are far below 50%. The same is true\nfor the population as a whole. Thus, with a probability of at least 99.9%\nLukashenka could not have had enough electoral support to win the 2020\npresidential election in Belarus.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:55:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zahorski", "Ales", ""]]}, {"id": "2009.06629", "submitter": "Maria Athanasiou", "authors": "Maria Athanasiou, Konstantina Sfrintzeri, Konstantia Zarkogianni,\n  Anastasia C. Thanopoulou, and Konstantina S. Nikita", "title": "An explainable XGBoost-based approach towards assessing the risk of\n  cardiovascular disease in patients with Type 2 Diabetes Mellitus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular Disease (CVD) is an important cause of disability and death\namong individuals with Diabetes Mellitus (DM). International clinical\nguidelines for the management of Type 2 DM (T2DM) are founded on primary and\nsecondary prevention and favor the evaluation of CVD related risk factors\ntowards appropriate treatment initiation. CVD risk prediction models can\nprovide valuable tools for optimizing the frequency of medical visits and\nperforming timely preventive and therapeutic interventions against CVD events.\nThe integration of explainability modalities in these models can enhance human\nunderstanding on the reasoning process, maximize transparency and embellish\ntrust towards the models' adoption in clinical practice. The aim of the present\nstudy is to develop and evaluate an explainable personalized risk prediction\nmodel for the fatal or non-fatal CVD incidence in T2DM individuals. An\nexplainable approach based on the eXtreme Gradient Boosting (XGBoost) and the\nTree SHAP (SHapley Additive exPlanations) method is deployed for the\ncalculation of the 5-year CVD risk and the generation of individual\nexplanations on the model's decisions. Data from the 5-year follow up of 560\npatients with T2DM are used for development and evaluation purposes. The\nobtained results (AUC = 71.13%) indicate the potential of the proposed approach\nto handle the unbalanced nature of the used dataset, while providing clinically\nmeaningful insights about the ensemble model's decision process.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:19:10 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 18:03:07 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Athanasiou", "Maria", ""], ["Sfrintzeri", "Konstantina", ""], ["Zarkogianni", "Konstantia", ""], ["Thanopoulou", "Anastasia C.", ""], ["Nikita", "Konstantina S.", ""]]}, {"id": "2009.06635", "submitter": "Stefano Carrazza", "authors": "Stefano Carrazza, Juan M. Cruz-Martinez, Marco Rossi", "title": "PDFFlow: parton distribution functions on GPU", "comments": "8 pages, 7 figures, 2 tables. Code available at\n  https://github.com/N3PDF/pdfflow", "journal-ref": null, "doi": "10.1016/j.cpc.2021.107995", "report-no": null, "categories": "hep-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PDFFlow, a new software for fast evaluation of parton distribution\nfunctions (PDFs) designed for platforms with hardware accelerators. PDFs are\nessential for the calculation of particle physics observables through Monte\nCarlo simulation techniques. The evaluation of a generic set of PDFs for quarks\nand gluon at a given momentum fraction and energy scale requires the\nimplementation of interpolation algorithms as introduced for the first time by\nthe LHAPDF project. PDFFlow extends and implements these interpolation\nalgorithms using Google's TensorFlow library providing the capabilities to\nperform PDF evaluations taking fully advantage of multi-threading CPU and GPU\nsetups. We benchmark the performance of this library on multiple scenarios\nrelevant for the particle physics community.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:00:00 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Carrazza", "Stefano", ""], ["Cruz-Martinez", "Juan M.", ""], ["Rossi", "Marco", ""]]}, {"id": "2009.06672", "submitter": "Allen ONeill", "authors": "Allen ONeill", "title": "Data Quality Evaluation using Probability Models", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an approach with machine-learning probability models to\nevaluate the difference between good and bad data quality in a dataset. A\ndecision tree algorithm is used to predict data quality based on no domain\nknowledge of the datasets under examination. It is shown that for the data\nexamined, the ability to predict the quality of data based on simple good/bad\npre-labelled learning examples is accurate, however in general it may not be\nsufficient for useful production data quality assessment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:12:19 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["ONeill", "Allen", ""]]}, {"id": "2009.06675", "submitter": "David Broniatowski", "authors": "Lydia P. Gleaves, Reva Schwartz, David A. Broniatowski", "title": "The Role of Individual User Differences in Interpretable and Explainable\n  Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increased interest in assisting non-expert audiences to effectively\ninteract with machine learning (ML) tools and understand the complex output\nsuch systems produce. Here, we describe user experiments designed to study how\nindividual skills and personality traits predict interpretability,\nexplainability, and knowledge discovery from ML generated model output. Our\nwork relies on Fuzzy Trace Theory, a leading theory of how humans process\nnumerical stimuli, to examine how different end users will interpret the output\nthey receive while interacting with the ML system. While our sample was small,\nwe found that interpretability -- being able to make sense of system output --\nand explainability -- understanding how that output was generated -- were\ndistinct aspects of user experience. Additionally, subjects were more able to\ninterpret model output if they possessed individual traits that promote\nmetacognitive monitoring and editing, associated with more detailed, verbatim,\nprocessing of ML output. Finally, subjects who are more familiar with ML\nsystems felt better supported by them and more able to discover new patterns in\ndata; however, this did not necessarily translate to meaningful insights. Our\nwork motivates the design of systems that explicitly take users' mental\nrepresentations into account during the design process to more effectively\nsupport end user requirements.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:15:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gleaves", "Lydia P.", ""], ["Schwartz", "Reva", ""], ["Broniatowski", "David A.", ""]]}, {"id": "2009.06689", "submitter": "Thomas Beckers", "authors": "Thomas Beckers and Leonardo Colombo and Sandra Hirche", "title": "Safe learning-based trajectory tracking for underactuated vehicles with\n  partially unknown dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underactuated vehicles have gained much attention in the recent years due to\nthe increasing amount of aerial and underwater vehicles as well as\nnanosatellites. The safe tracking control of these vehicles is a substantial\naspect for an increasing range of application domains. However, external\ndisturbances and parts of the internal dynamics are often unknown or very\ntime-consuming to model. To overcome this issue, we present a safe tracking\ncontrol law for underactuated vehicles using a learning-based oracle for the\nprediction of the unknown dynamics. The presented approach guarantees the\nboundedness of the tracking error with high probability where the bound is\nexplicitly given. With additional assumptions, asymptotic stability is\nachieved. A simulation with a quadrocopter visualizes the effectiveness of the\nproposed control law.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:52:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Beckers", "Thomas", ""], ["Colombo", "Leonardo", ""], ["Hirche", "Sandra", ""]]}, {"id": "2009.06693", "submitter": "Abhinav Jangda", "authors": "Abhinav Jangda, Sandeep Polisetty, Arjun Guha, Marco Serafini", "title": "Accelerating Graph Sampling for Graph Machine Learning using GPUs", "comments": "Published in EuroSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning algorithms automatically learn the features of data.\nSeveral representation learning algorithms for graph data, such as DeepWalk,\nnode2vec, and GraphSAGE, sample the graph to produce mini-batches that are\nsuitable for training a DNN. However, sampling time can be a significant\nfraction of training time, and existing systems do not efficiently parallelize\nsampling.\n  Sampling is an embarrassingly parallel problem and may appear to lend itself\nto GPU acceleration, but the irregularity of graphs makes it hard to use GPU\nresources effectively. This paper presents NextDoor, a system designed to\neffectively perform graph sampling on GPUs. NextDoor employs a new approach to\ngraph sampling that we call transit-parallelism, which allows load balancing\nand caching of edges. NextDoor provides end-users with a high-level abstraction\nfor writing a variety of graph sampling algorithms. We implement several graph\nsampling applications, and show that NextDoor runs them orders of magnitude\nfaster than existing systems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:03:33 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 18:28:53 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 18:16:56 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 00:57:02 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Jangda", "Abhinav", ""], ["Polisetty", "Sandeep", ""], ["Guha", "Arjun", ""], ["Serafini", "Marco", ""]]}, {"id": "2009.06697", "submitter": "Boram Yoon", "authors": "Boram Yoon", "title": "A machine learning approach for efficient multi-dimensional integration", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-27161", "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel multi-dimensional integration algorithm using a machine\nlearning (ML) technique. After training a ML regression model to mimic a target\nintegrand, the regression model is used to evaluate an approximation of the\nintegral. Then, the difference between the approximation and the true answer is\ncalculated to correct the bias in the approximation of the integral induced by\na ML prediction error. Because of the bias correction, the final estimate of\nthe integral is unbiased and has a statistically correct error estimation. The\nperformance of the proposed algorithm is demonstrated on six different types of\nintegrands at various dimensions and integrand difficulties. The results show\nthat, for the same total number of integrand evaluations, the new algorithm\nprovides integral estimates with more than an order of magnitude smaller\nuncertainties than those of the VEGAS algorithm in most of the test cases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:11:14 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Yoon", "Boram", ""]]}, {"id": "2009.06701", "submitter": "Takami Sato", "authors": "Takami Sato, Junjie Shen, Ningfei Wang, Yunhan Jack Jia, Xue Lin, Qi\n  Alfred Chen", "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane\n  Centering under Physical-World Attack", "comments": "Accepted to Usenix Security '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Lane Centering (ALC) systems are convenient and widely deployed\ntoday, but also highly security and safety critical. In this work, we are the\nfirst to systematically study the security of state-of-the-art deep learning\nbased ALC systems in their designed operational domains under physical-world\nadversarial attacks. We formulate the problem with a safety-critical attack\ngoal, and a novel and domain-specific attack vector: dirty road patches. To\nsystematically generate the attack, we adopt an optimization-based approach and\novercome domain-specific design challenges such as camera frame\ninter-dependencies due to attack-influenced vehicle control, and the lack of\nobjective function design for lane detection models.\n  We evaluate our attack on a production ALC using 80 scenarios from real-world\ndriving traces. The results show that our attack is highly effective with over\n97.5% success rates and less than 0.903 sec average success time, which is\nsubstantially lower than the average driver reaction time. This attack is also\nfound (1) robust to various real-world factors such as lighting conditions and\nview angles, (2) general to different model designs, and (3) stealthy from the\ndriver's view. To understand the safety impacts, we conduct experiments using\nsoftware-in-the-loop simulation and attack trace injection in a real vehicle.\nThe results show that our attack can cause a 100% collision rate in different\nscenarios, including when tested with common safety features such as automatic\nemergency braking. We also evaluate and discuss defenses.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:22:39 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 22:38:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sato", "Takami", ""], ["Shen", "Junjie", ""], ["Wang", "Ningfei", ""], ["Jia", "Yunhan Jack", ""], ["Lin", "Xue", ""], ["Chen", "Qi Alfred", ""]]}, {"id": "2009.06704", "submitter": "Alberto Nogales", "authors": "Alberto Nogales, Rodrigo D\\'iaz Mor\\'on, \\'Alvaro J. Garc\\'ia-Tejedor", "title": "Food safety risk prediction with Deep Learning models using categorical\n  embeddings on European Union data", "comments": "20 pages,8 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is becoming more globalized every day and people can buy products\nfrom almost every country in the world in their local stores. Given the\ndifferent food and feed safety laws from country to country, the European Union\nbegan to register in 1977 all irregularities related to traded products to\nensure cross-border monitoring of information and a quick reaction when risks\nto public health are detected in the food chain. This information has also an\nenormous potential as a preventive tool, in order to warn actors involved in\nfood safety and optimize their resources. In this paper, a set of data related\nto food issues was scraped and analysed with Machine Learning techniques to\npredict some features of future notifications, so that pre-emptive measures can\nbe taken. The novelty of the work relies on two points: the use of categorical\nembeddings with Deep Learning models (Multilayer Perceptron and 1-Dimension\nConvolutional Neural Networks) and its application to solve the problem of\npredicting food issues in the European Union. The models allow several features\nto be predicted: product category, hazard category and finally the proper\naction to be taken. Results show that the system can predict these features\nwith an accuracy ranging from 74.08% to 93.06%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:36:58 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nogales", "Alberto", ""], ["Mor\u00f3n", "Rodrigo D\u00edaz", ""], ["Garc\u00eda-Tejedor", "\u00c1lvaro J.", ""]]}, {"id": "2009.06719", "submitter": "Ming Min", "authors": "Ming Min, Tomoyuki Ichiba", "title": "Convolutional Signature for Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signature is an infinite graded sequence of statistics known to characterize\ngeometric rough paths, which includes the paths with bounded variation. This\nobject has been studied successfully for machine learning with mostly\napplications in low dimensional cases. In the high dimensional case, it suffers\nfrom exponential growth in the number of features in truncated signature\ntransform. We propose a novel neural network based model which borrows the idea\nfrom Convolutional Neural Network to address this problem. Our model reduces\nthe number of features efficiently in a data dependent way. Some empirical\nexperiments are provided to support our model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:01:56 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Min", "Ming", ""], ["Ichiba", "Tomoyuki", ""]]}, {"id": "2009.06732", "submitter": "Yi Tay", "authors": "Yi Tay, Mostafa Dehghani, Dara Bahri, Donald Metzler", "title": "Efficient Transformers: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer model architectures have garnered immense interest lately due to\ntheir effectiveness across a range of domains like language, vision and\nreinforcement learning. In the field of natural language processing for\nexample, Transformers have become an indispensable staple in the modern deep\nlearning stack. Recently, a dizzying number of \"X-former\" models have been\nproposed - Reformer, Linformer, Performer, Longformer, to name a few - which\nimprove upon the original Transformer architecture, many of which make\nimprovements around computational and memory efficiency. With the aim of\nhelping the avid researcher navigate this flurry, this paper characterizes a\nlarge and thoughtful selection of recent efficiency-flavored \"X-former\" models,\nproviding an organized and comprehensive overview of existing work and models\nacross multiple domains.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:38:14 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:23:37 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Tay", "Yi", ""], ["Dehghani", "Mostafa", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""]]}, {"id": "2009.06734", "submitter": "Edward Frady", "authors": "E. Paxon Frady, Denis Kleyko, Friedrich T. Sommer", "title": "Variable Binding for Sparse Distributed Representations: Theory and\n  Applications", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic reasoning and neural networks are often considered incompatible\napproaches. Connectionist models known as Vector Symbolic Architectures (VSAs)\ncan potentially bridge this gap. However, classical VSAs and neural networks\nare still considered incompatible. VSAs encode symbols by dense pseudo-random\nvectors, where information is distributed throughout the entire neuron\npopulation. Neural networks encode features locally, often forming sparse\nvectors of neural activation. Following Rachkovskij (2001); Laiho et al.\n(2015), we explore symbolic reasoning with sparse distributed representations.\nThe core operations in VSAs are dyadic operations between vectors to express\nvariable binding and the representation of sets. Thus, algebraic manipulations\nenable VSAs to represent and process data structures in a vector space of fixed\ndimensionality. Using techniques from compressed sensing, we first show that\nvariable binding between dense vectors in VSAs is mathematically equivalent to\ntensor product binding between sparse vectors, an operation which increases\ndimensionality. This result implies that dimensionality-preserving binding for\ngeneral sparse vectors must include a reduction of the tensor matrix into a\nsingle sparse vector. Two options for sparsity-preserving variable binding are\ninvestigated. One binding method for general sparse vectors extends earlier\nproposals to reduce the tensor product into a vector, such as circular\nconvolution. The other method is only defined for sparse block-codes,\nblock-wise circular convolution. Our experiments reveal that variable binding\nfor block-codes has ideal properties, whereas binding for general sparse\nvectors also works, but is lossy, similar to previous proposals. We demonstrate\na VSA with sparse block-codes in example applications, cognitive reasoning and\nclassification, and discuss its relevance for neuroscience and neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:40:09 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Frady", "E. Paxon", ""], ["Kleyko", "Denis", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2009.06739", "submitter": "Aravind Krishnamoorthy", "authors": "Pankaj Rajak, Aravind Krishnamoorthy, Ankit Mishra, Rajiv K. Kalia,\n  Aiichiro Nakano and Priya Vashishta", "title": "Predictive Synthesis of Quantum Materials by Probabilistic Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive materials synthesis is the primary bottleneck in realizing new\nfunctional and quantum materials. Strategies for synthesis of promising\nmaterials are currently identified by time-consuming trial and error approaches\nand there are no known predictive schemes to design synthesis parameters for\nnew materials. We use reinforcement learning to predict optimal synthesis\nschedules, i.e. a time-sequence of reaction conditions like temperatures and\nreactant concentrations, for the synthesis of a prototypical quantum material,\nsemiconducting monolayer MoS$_{2}$, using chemical vapor deposition. The\npredictive reinforcement leaning agent is coupled to a deep generative model to\ncapture the crystallinity and phase-composition of synthesized MoS$_{2}$ during\nCVD synthesis as a function of time-dependent synthesis conditions. This model,\ntrained on 10000 computational synthesis simulations, successfully learned\nthreshold temperatures and chemical potentials for the onset of chemical\nreactions and predicted new synthesis schedules for producing well-sulfidized\ncrystalline and phase-pure MoS$_{2}$, which were validated by computational\nsynthesis simulations. The model can be extended to predict profiles for\nsynthesis of complex structures including multi-phase heterostructures and can\nalso predict long-time behavior of reacting systems, far beyond the domain of\nthe MD simulations used to train the model, making these predictions directly\nrelevant to experimental synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:50:45 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Rajak", "Pankaj", ""], ["Krishnamoorthy", "Aravind", ""], ["Mishra", "Ankit", ""], ["Kalia", "Rajiv K.", ""], ["Nakano", "Aiichiro", ""], ["Vashishta", "Priya", ""]]}, {"id": "2009.06747", "submitter": "Youbang Sun", "authors": "Youbang Sun, Shahin Shahrampour", "title": "Distributed Mirror Descent with Integral Feedback: Asymptotic\n  Convergence Analysis of Continuous-time Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses distributed optimization, where a network of agents wants\nto minimize a global strongly convex objective function. The global function\ncan be written as a sum of local convex functions, each of which is associated\nwith an agent. We propose a continuous-time distributed mirror descent\nalgorithm that uses purely local information to converge to the global optimum.\nUnlike previous work on distributed mirror descent, we incorporate an integral\nfeedback in the update, allowing the algorithm to converge with a constant\nstep-size when discretized. We establish the asymptotic convergence of the\nalgorithm using Lyapunov stability analysis. We further illustrate numerical\nexperiments that verify the advantage of adopting integral feedback for\nimproving the convergence rate of distributed mirror descent.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:11:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Sun", "Youbang", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2009.06750", "submitter": "Niander Assis", "authors": "Niander Assis, Renato Assun\\c{c}\\~ao and Pedro O. S. Vaz-De-Melo", "title": "Stop the Clock: Are Timeout Effects Real?", "comments": "Accepted at ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timeout is a short interruption during games used to communicate a change in\nstrategy, to give the players a rest or to stop a negative flow in the game.\nWhatever the reason, coaches expect an improvement in their team's performance\nafter a timeout. But how effective are these timeouts in doing so? The simple\naverage of the differences between the scores before and after the timeouts has\nbeen used as evidence that there is an effect and that it is substantial. We\nclaim that these statistical averages are not proper evidence and a more sound\napproach is needed. We applied a formal causal framework using a large dataset\nof official NBA play-by-play tables and drew our assumptions about the data\ngeneration process in a causal graph. Using different matching techniques to\nestimate the causal effect of timeouts, we concluded that timeouts have no\neffect on teams' performances. Actually, since most timeouts are called when\nthe opposing team is scoring more frequently, the moments that follow resemble\nan improvement in the team's performance but are just the natural game tendency\nto return to its average state. This is another example of what statisticians\ncall the regression to the mean phenomenon.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:21:41 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Assis", "Niander", ""], ["Assun\u00e7\u00e3o", "Renato", ""], ["Vaz-De-Melo", "Pedro O. S.", ""]]}, {"id": "2009.06762", "submitter": "Esteban Vilca", "authors": "Esteban Wilfredo Vilca Zu\\~niga", "title": "New complex network building methodology for High Level Classification\n  based on attribute-attribute interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-level classification algorithms focus on the interactions between\ninstances. These produce a new form to evaluate and classify data. In this\nprocess, the core is the complex network building methodology because it\ndetermines the metrics to be used for classification. The current methodologies\nuse variations of kNN to produce these graphs. However, this technique ignores\nsome hidden pattern between attributes and require normalization to be\naccurate. In this paper, we propose a new methodology for network building\nbased on attribute-attribute interactions that do not require normalization and\ncapture the hidden patterns of the attributes. The current results show us that\ncould be used to improve some current high-level techniques.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:58:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zu\u00f1iga", "Esteban Wilfredo Vilca", ""]]}, {"id": "2009.06764", "submitter": "Jean-Francois Rajotte", "authors": "Jean-Francois Rajotte, Raymond T Ng", "title": "Private data sharing between decentralized users through the privGAN\n  architecture", "comments": "6 pages, 9 figures, to be in the proceedings of International\n  Workshop on Privacy and Security in Enterprise Modeling (PriSEM'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More data is almost always beneficial for analysis and machine learning\ntasks. In many realistic situations however, an enterprise cannot share its\ndata, either to keep a competitive advantage or to protect the privacy of the\ndata sources, the enterprise's clients for example. We propose a method for\ndata owners to share synthetic or fake versions of their data without sharing\nthe actual data, nor the parameters of models that have direct access to the\ndata. The method proposed is based on the privGAN architecture where local GANs\nare trained on their respective data subsets with an extra penalty from a\ncentral discriminator aiming to discriminate the origin of a given fake sample.\nWe demonstrate that this approach, when applied to subsets of various sizes,\nleads to better utility for the owners than the utility from their real small\ndatasets. The only shared pieces of information are the parameter updates of\nthe central discriminator. The privacy is demonstrated with white-box attacks\non the most vulnerable elments of the architecture and the results are close to\nrandom guessing. This method would apply naturally in a federated learning\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 22:06:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Rajotte", "Jean-Francois", ""], ["Ng", "Raymond T", ""]]}, {"id": "2009.06775", "submitter": "Tuomo Raitio", "authors": "Tuomo Raitio, Ramya Rasipuram, Dan Castellani", "title": "Controllable neural text-to-speech synthesis using intuitive prosodic\n  features", "comments": "Accepted for publication in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural text-to-speech (TTS) synthesis can generate speech that is\nindistinguishable from natural speech. However, the prosody of generated\nutterances often represents the average prosodic style of the database instead\nof having wide prosodic variation. Moreover, the generated prosody is solely\ndefined by the input text, which does not allow for different styles for the\nsame sentence. In this work, we train a sequence-to-sequence neural network\nconditioned on acoustic speech features to learn a latent prosody space with\nintuitive and meaningful dimensions. Experiments show that a model conditioned\non sentence-wise pitch, pitch range, phone duration, energy, and spectral tilt\ncan effectively control each prosodic dimension and generate a wide variety of\nspeaking styles, while maintaining similar mean opinion score (4.23) to our\nTacotron baseline (4.26).\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 22:37:44 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Raitio", "Tuomo", ""], ["Rasipuram", "Ramya", ""], ["Castellani", "Dan", ""]]}, {"id": "2009.06780", "submitter": "Mohammad Morid", "authors": "Mohammad Amin Morid, Olivia R. Liu Sheng, Kensaku Kawamoto, Travis\n  Ault, Josette Dorius, Samir Abdelrahman", "title": "Healthcare Cost Prediction: Leveraging Fine-grain Temporal Patterns", "comments": null, "journal-ref": "Journal of biomedical informatics, 91 (2019)", "doi": "10.1016/j.jbi.2019.103113", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To design and assess a method to leverage individuals' temporal\ndata for predicting their healthcare cost. To achieve this goal, we first used\npatients' temporal data in their fine-grain form as opposed to coarse-grain\nform. Second, we devised novel spike detection features to extract temporal\npatterns that improve the performance of cost prediction. Third, we evaluated\nthe effectiveness of different types of temporal features based on cost\ninformation, visit information and medical information for the prediction task.\n  Materials and methods: We used three years of medical and pharmacy claims\ndata from 2013 to 2016 from a healthcare insurer, where the first two years\nwere used to build the model to predict the costs in the third year. To prepare\nthe data for modeling and prediction, the time series data of cost, visit and\nmedical information were extracted in the form of fine-grain features (i.e.,\nsegmenting each time series into a sequence of consecutive windows and\nrepresenting each window by various statistics such as sum). Then, temporal\npatterns of the time series were extracted and added to fine-grain features\nusing a novel set of spike detection features (i.e., the fluctuation of data\npoints). Gradient Boosting was applied on the final set of extracted features.\nMoreover, the contribution of each type of data (i.e., cost, visit and medical)\nwas assessed.\n  Conclusions: Leveraging fine-grain temporal patterns for healthcare cost\nprediction significantly improves prediction performance. Enhancing fine-grain\nfeatures with extraction of temporal cost and visit patterns significantly\nimproved the performance. However, medical features did not have a significant\neffect on prediction performance. Gradient Boosting outperformed all other\nprediction models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 22:49:50 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Morid", "Mohammad Amin", ""], ["Sheng", "Olivia R. Liu", ""], ["Kawamoto", "Kensaku", ""], ["Ault", "Travis", ""], ["Dorius", "Josette", ""], ["Abdelrahman", "Samir", ""]]}, {"id": "2009.06783", "submitter": "Mohammad Morid", "authors": "Mohammad Amin Morid, Olivia R. Liu Sheng, Kensaku Kawamoto, Samir\n  Abdelrahman", "title": "Learning Hidden Patterns from Patient Multivariate Time Series Data\n  Using Convolutional Neural Networks: A Case Study of Healthcare Cost\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To develop an effective and scalable individual-level patient cost\nprediction method by automatically learning hidden temporal patterns from\nmultivariate time series data in patient insurance claims using a convolutional\nneural network (CNN) architecture.\n  Methods: We used three years of medical and pharmacy claims data from 2013 to\n2016 from a healthcare insurer, where data from the first two years were used\nto build the model to predict costs in the third year. The data consisted of\nthe multivariate time series of cost, visit and medical features that were\nshaped as images of patients' health status (i.e., matrices with time windows\non one dimension and the medical, visit and cost features on the other\ndimension). Patients' multivariate time series images were given to a CNN\nmethod with a proposed architecture. After hyper-parameter tuning, the proposed\narchitecture consisted of three building blocks of convolution and pooling\nlayers with an LReLU activation function and a customized kernel size at each\nlayer for healthcare data. The proposed CNN learned temporal patterns became\ninputs to a fully connected layer.\n  Conclusions: Feature learning through the proposed CNN configuration\nsignificantly improved individual-level healthcare cost prediction. The\nproposed CNN was able to outperform temporal pattern detection methods that\nlook for a pre-defined set of pattern shapes, since it is capable of extracting\na variable number of patterns with various shapes. Temporal patterns learned\nfrom medical, visit and cost data made significant contributions to the\nprediction performance. Hyper-parameter tuning showed that considering\nthree-month data patterns has the highest prediction accuracy. Our results\nshowed that patients' images extracted from multivariate time series data are\ndifferent from regular images, and hence require unique designs of CNN\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 23:11:19 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Morid", "Mohammad Amin", ""], ["Sheng", "Olivia R. Liu", ""], ["Kawamoto", "Kensaku", ""], ["Abdelrahman", "Samir", ""]]}, {"id": "2009.06784", "submitter": "Cheng Mao", "authors": "Cheng Mao and Yihong Wu", "title": "Learning Mixtures of Permutations: Groups of Pairwise Comparisons and\n  Combinatorial Method of Moments", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications such as rank aggregation, mixture models for permutations are\nfrequently used when the population exhibits heterogeneity. In this work, we\nstudy the widely used Mallows mixture model. In the high-dimensional setting,\nwe propose a polynomial-time algorithm that learns a Mallows mixture of\npermutations on $n$ elements with the optimal sample complexity that is\nproportional to $\\log n$, improving upon previous results that scale\npolynomially with $n$. In the high-noise regime, we characterize the optimal\ndependency of the sample complexity on the noise parameter. Both objectives are\naccomplished by first studying demixing permutations under a noiseless query\nmodel using groups of pairwise comparisons, which can be viewed as moments of\nthe mixing distribution, and then extending these results to the noisy Mallows\nmodel by simulating the noiseless oracle.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 23:11:46 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mao", "Cheng", ""], ["Wu", "Yihong", ""]]}, {"id": "2009.06795", "submitter": "Huajie Shao", "authors": "Huajie Shao, Haohong Lin, Qinmin Yang, Shuochao Yao, Han Zhao, Tarek\n  Abdelzaher", "title": "DynamicVAE: Decoupling Reconstruction Error and Disentangled\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper challenges the common assumption that the weight $\\beta$, in\n$\\beta$-VAE, should be larger than $1$ in order to effectively disentangle\nlatent factors. We demonstrate that $\\beta$-VAE, with $\\beta < 1$, can not only\nattain good disentanglement but also significantly improve reconstruction\naccuracy via dynamic control. The paper removes the inherent trade-off between\nreconstruction accuracy and disentanglement for $\\beta$-VAE. Existing methods,\nsuch as $\\beta$-VAE and FactorVAE, assign a large weight to the KL-divergence\nterm in the objective function, leading to high reconstruction errors for the\nsake of better disentanglement. To mitigate this problem, a ControlVAE has\nrecently been developed that dynamically tunes the KL-divergence weight in an\nattempt to control the trade-off to more a favorable point. However, ControlVAE\nfails to eliminate the conflict between the need for a large $\\beta$ (for\ndisentanglement) and the need for a small $\\beta$. Instead, we propose\nDynamicVAE that maintains a different $\\beta$ at different stages of training,\nthereby decoupling disentanglement and reconstruction accuracy. In order to\nevolve the weight, $\\beta$, along a trajectory that enables such decoupling,\nDynamicVAE leverages a modified incremental PI (proportional-integral)\ncontroller, and employs a moving average as well as a hybrid annealing method\nto evolve the value of KL-divergence smoothly in a tightly controlled fashion.\nWe theoretically prove the stability of the proposed approach. Evaluation\nresults on three benchmark datasets demonstrate that DynamicVAE significantly\nimproves the reconstruction accuracy while achieving disentanglement comparable\nto the best of existing methods. The results verify that our method can\nseparate disentangled representation learning and reconstruction, removing the\ninherent tension between the two.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:01:11 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:11:07 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Shao", "Huajie", ""], ["Lin", "Haohong", ""], ["Yang", "Qinmin", ""], ["Yao", "Shuochao", ""], ["Zhao", "Han", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2009.06796", "submitter": "Nghia Doan Mr.", "authors": "Nghia Doan, Seyyed Ali Hashemi and Warren Gross", "title": "Decoding Polar Codes with Reinforcement Learning", "comments": "Accepted for presentation at IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of selecting factor-graph permutations\nof polar codes under belief propagation (BP) decoding to significantly improve\nthe error-correction performance of the code. In particular, we formalize the\nfactor-graph permutation selection as the multi-armed bandit problem in\nreinforcement learning and propose a decoder that acts like an online-learning\nagent that learns to select the good factor-graph permutations during the\ncourse of decoding. We use state-of-the-art algorithms for the multi-armed\nbandit problem and show that for a 5G polar codes of length 128 with 64\ninformation bits, the proposed decoder has an error-correction performance gain\nof around 0.125 dB at the target frame error rate of 10^{-4}, when compared to\nthe approach that randomly selects the factor-graph permutations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:05:38 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Doan", "Nghia", ""], ["Hashemi", "Seyyed Ali", ""], ["Gross", "Warren", ""]]}, {"id": "2009.06797", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Eva Zhang, Yongchan Kwon, James Zou", "title": "Competing AI: How does competition feedback affect machine learning?", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This papers studies how competition affects machine learning (ML) predictors.\nAs ML becomes more ubiquitous, it is often deployed by companies to compete\nover customers. For example, digital platforms like Yelp use ML to predict user\npreference and make recommendations. A service that is more often queried by\nusers, perhaps because it more accurately anticipates user preferences, is also\nmore likely to obtain additional user data (e.g. in the form of a Yelp review).\nThus, competing predictors cause feedback loops whereby a predictor's\nperformance impacts what training data it receives and biases its predictions\nover time. We introduce a flexible model of competing ML predictors that\nenables both rapid experimentation and theoretical tractability. We show with\nempirical and mathematical analysis that competition causes predictors to\nspecialize for specific sub-populations at the cost of worse performance over\nthe general population. We further analyze the impact of predictor\nspecialization on the overall prediction quality experienced by users. We show\nthat having too few or too many competing predictors in a market can hurt the\noverall prediction quality. Our theory is complemented by experiments on\nseveral real datasets using popular learning algorithms, such as neural\nnetworks and nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:13:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:12:49 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:01:12 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 04:04:22 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Ginart", "Antonio", ""], ["Zhang", "Eva", ""], ["Kwon", "Yongchan", ""], ["Zou", "James", ""]]}, {"id": "2009.06798", "submitter": "Julio Omar Palacio Ni\\~no", "authors": "Julio-Omar Palacio-Ni\\~no and Fernando Berzal", "title": "On the use of local structural properties for improving the efficiency\n  of hierarchical community detection methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Community detection is a fundamental problem in the analysis of complex\nnetworks. It is the analogue of clustering in network data mining. Within\ncommunity detection methods, hierarchical algorithms are popular. However,\ntheir iterative nature and the need to recompute the structural properties used\nto split the network (i.e. edge betweenness in Girvan and Newman's algorithm),\nmake them unsuitable for large network data sets. In this paper, we study how\nlocal structural network properties can be used as proxies to improve the\nefficiency of hierarchical community detection while, at the same time,\nachieving competitive results in terms of modularity. In particular, we study\nthe potential use of the structural properties commonly used to perform local\nlink prediction, a supervised learning problem where community structure is\nrelevant, as nodes are prone to establish new links with other nodes within\ntheir communities. In addition, we check the performance impact of network\npruning heuristics as an ancillary tactic to make hierarchical community\ndetection more efficient\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:16:12 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Palacio-Ni\u00f1o", "Julio-Omar", ""], ["Berzal", "Fernando", ""]]}, {"id": "2009.06799", "submitter": "Jacob Buckman", "authors": "Jacob Buckman, Carles Gelada, Marc G. Bellemare", "title": "The Importance of Pessimism in Fixed-Dataset Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study worst-case guarantees on the expected return of fixed-dataset policy\noptimization algorithms. Our core contribution is a unified conceptual and\nmathematical framework for the study of algorithms in this regime. This\nanalysis reveals that for naive approaches, the possibility of erroneous value\noverestimation leads to a difficult-to-satisfy requirement: in order to\nguarantee that we select a policy which is near-optimal, we may need the\ndataset to be informative of the value of every policy. To avoid this,\nalgorithms can follow the pessimism principle, which states that we should\nchoose the policy which acts optimally in the worst possible world. We show why\npessimistic algorithms can achieve good performance even when the dataset is\nnot informative of every policy, and derive families of algorithms which follow\nthis principle. These theoretical findings are validated by experiments on a\ntabular gridworld, and deep learning experiments on four MinAtar environments.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:18:34 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 23:51:31 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 05:58:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Buckman", "Jacob", ""], ["Gelada", "Carles", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2009.06808", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Abu Sebastian, Evangelos Eleftheriou (IBM Research\n  - Zurich)", "title": "Optimality of short-term synaptic plasticity in modelling certain\n  dynamic environments", "comments": "Main paper: 12 pages, 4 figures. Supplementary Information: 13 pages,\n  4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological neurons and their in-silico emulations for neuromorphic artificial\nintelligence (AI) use extraordinarily energy-efficient mechanisms, such as\nspike-based communication and local synaptic plasticity. It remains unclear\nwhether these neuronal mechanisms only offer efficiency or also underlie the\nsuperiority of biological intelligence. Here, we prove rigorously that, indeed,\nthe Bayes-optimal prediction and inference of randomly but continuously\ntransforming environments, a common natural setting, relies on short-term\nspike-timing-dependent plasticity, a hallmark of biological synapses. Further,\nthis dynamic Bayesian inference through plasticity enables circuits of the\ncerebral cortex in simulations to recognize previously unseen, highly distorted\ndynamic stimuli. Strikingly, this also introduces a biologically-modelled AI,\nthe first to overcome multiple limitations of deep learning and outperform\nartificial neural networks in a visual task. The cortical-like network is\nspiking and event-based, trained only with unsupervised and local plasticity,\non a small, narrow, and static training dataset, but achieves recognition of\nunseen, transformed, and dynamic data better than deep neural networks with\ncontinuous activations, trained with supervised backpropagation on the\ntransforming data. These results link short-term plasticity to high-level\ncortical function, suggest optimality of natural intelligence for natural\nenvironments, and repurpose neuromorphic AI from mere efficiency to\ncomputational supremacy altogether.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 01:04:28 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 22:14:34 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Moraitis", "Timoleon", "", "IBM Research\n  - Zurich"], ["Sebastian", "Abu", "", "IBM Research\n  - Zurich"], ["Eleftheriou", "Evangelos", "", "IBM Research\n  - Zurich"]]}, {"id": "2009.06823", "submitter": "Zhenglun Kong", "authors": "Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen\n  Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang", "title": "Real-Time Execution of Large-scale Language Models on Mobile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained large-scale language models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. However, the limited\nweight storage and computational speed on hardware platforms have impeded the\npopularity of pre-trained models, especially in the era of edge computing. In\nthis paper, we seek to find the best model structure of BERT for a given\ncomputation size to match specific devices. We propose the first compiler-aware\nneural architecture optimization framework. Our framework can guarantee the\nidentified model to meet both resource and real-time specifications of mobile\ndevices, thus achieving real-time execution of large transformer-based models\nlike BERT variants. We evaluate our model on several NLP tasks, achieving\ncompetitive results on well-known benchmarks with lower latency on mobile\ndevices. Specifically, our model is 5.2x faster on CPU and 4.1x faster on GPU\nwith 0.5-2% accuracy loss compared with BERT-base. Our overall framework\nachieves up to 7.8x speedup compared with TensorFlow-Lite with only minor\naccuracy loss.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 01:59:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 17:53:07 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Niu", "Wei", ""], ["Kong", "Zhenglun", ""], ["Yuan", "Geng", ""], ["Jiang", "Weiwen", ""], ["Guan", "Jiexiong", ""], ["Ding", "Caiwen", ""], ["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2009.06825", "submitter": "Peyman Tehrani", "authors": "Peyman Tehrani, Marco Levorato", "title": "Frequency-based Multi Task learning With Attention Mechanism for Fault\n  Detection In Power Systems", "comments": "This article has been accepted for publication in the IEEE\n  International Conference on Communications, Control, and Computing\n  Technologies for Smart Grids, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prompt and accurate detection of faults and abnormalities in electric\ntransmission lines is a critical challenge in smart grid systems. Existing\nmethods mostly rely on model-based approaches, which may not capture all the\naspects of these complex temporal series. Recently, the availability of data\nsets collected using advanced metering devices, such as Micro-Phasor\nMeasurement units ($\\mu$ PMU), which provide measurements at microsecond\ntimescale, boosted the development of data-driven methodologies. In this paper,\nwe introduce a novel deep learning-based approach for fault detection and test\nit on a real data set, namely, the Kaggle platform for a partial discharge\ndetection task. Our solution adopts a Long-Short Term Memory architecture with\nattention mechanism to extract time series features, and uses a\n1D-Convolutional Neural Network structure to exploit frequency information of\nthe signal for prediction. Additionally, we propose an unsupervised method to\ncluster signals based on their frequency components, and apply multi task\nlearning on different clusters. The method we propose outperforms the winner\nsolutions in the Kaggle competition and other state of the art methods in many\nperformance metrics, and improves the interpretability of analysis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:01:47 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Tehrani", "Peyman", ""], ["Levorato", "Marco", ""]]}, {"id": "2009.06828", "submitter": "Zhixuan Chu", "authors": "Zhixuan Chu, Stephen L. Rathbun, and Sheng Li", "title": "Matching in Selective and Balanced Representation Space for Treatment\n  Effects Estimation", "comments": "Proceedings of the 29th ACM International Conference on Information\n  and Knowledge Management (CIKM '20)", "journal-ref": null, "doi": "10.1145/3340531.3412037", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dramatically growing availability of observational data is being\nwitnessed in various domains of science and technology, which facilitates the\nstudy of causal inference. However, estimating treatment effects from\nobservational data is faced with two major challenges, missing counterfactual\noutcomes and treatment selection bias. Matching methods are among the most\nwidely used and fundamental approaches to estimating treatment effects, but\nexisting matching methods have poor performance when facing data with high\ndimensional and complicated variables. We propose a feature selection\nrepresentation matching (FSRM) method based on deep representation learning and\nmatching, which maps the original covariate space into a selective, nonlinear,\nand balanced representation space, and then conducts matching in the learned\nrepresentation space. FSRM adopts deep feature selection to minimize the\ninfluence of irrelevant variables for estimating treatment effects and\nincorporates a regularizer based on the Wasserstein distance to learn balanced\nrepresentations. We evaluate the performance of our FSRM method on three\ndatasets, and the results demonstrate superiority over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:07:34 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 09:12:23 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chu", "Zhixuan", ""], ["Rathbun", "Stephen L.", ""], ["Li", "Sheng", ""]]}, {"id": "2009.06837", "submitter": "EPTCS", "authors": "Bruno Gavranovi\\'c", "title": "Learning Functors using Gradient Descent", "comments": "In Proceedings ACT 2019, arXiv:2009.06334. This paper is a condensed\n  version of the master thesis of the author (arXiv:1907.08292)", "journal-ref": "EPTCS 323, 2020, pp. 230-245", "doi": "10.4204/EPTCS.323.15", "report-no": null, "categories": "cs.LG cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are a general framework for differentiable optimization which\nincludes many other machine learning approaches as special cases. In this paper\nwe build a category-theoretic formalism around a neural network system called\nCycleGAN. CycleGAN is a general approach to unpaired image-to-image translation\nthat has been getting attention in the recent years. Inspired by categorical\ndatabase systems, we show that CycleGAN is a \"schema\", i.e. a specific category\npresented by generators and relations, whose specific parameter instantiations\nare just set-valued functors on this schema. We show that enforcing\ncycle-consistencies amounts to enforcing composition invariants in this\ncategory. We generalize the learning procedure to arbitrary such categories and\nshow a special class of functors, rather than functions, can be learned using\ngradient descent. Using this framework we design a novel neural network system\ncapable of learning to insert and delete objects from images without paired\ndata. We qualitatively evaluate the system on the CelebA dataset and obtain\npromising results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:17:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gavranovi\u0107", "Bruno", ""]]}, {"id": "2009.06847", "submitter": "Guansong Pang", "authors": "Guansong Pang, Anton van den Hengel, Chunhua Shen, Longbing Cao", "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from\n  Partially Labeled Anomaly Data", "comments": "Accepted to KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467417", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:05:39 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:40:11 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Pang", "Guansong", ""], ["Hengel", "Anton van den", ""], ["Shen", "Chunhua", ""], ["Cao", "Longbing", ""]]}, {"id": "2009.06851", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Ruiyi Zhang, Manzil Zaheer, Amr Ahmed", "title": "Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality dialogue-summary paired data is expensive to produce and\ndomain-sensitive, making abstractive dialogue summarization a challenging task.\nIn this work, we propose the first unsupervised abstractive dialogue\nsummarization model for tete-a-tetes (SuTaT). Unlike standard text\nsummarization, a dialogue summarization method should consider the\nmulti-speaker scenario where the speakers have different roles, goals, and\nlanguage styles. In a tete-a-tete, such as a customer-agent conversation, SuTaT\naims to summarize for each speaker by modeling the customer utterances and the\nagent utterances separately while retaining their correlations. SuTaT consists\nof a conditional generative module and two unsupervised summarization modules.\nThe conditional generative module contains two encoders and two decoders in a\nvariational autoencoder framework where the dependencies between two latent\nspaces are captured. With the same encoders and decoders, two unsupervised\nsummarization modules equipped with sentence-level self-attention mechanisms\ngenerate summaries without using any annotations. Experimental results show\nthat SuTaT is superior on unsupervised dialogue summarization for both\nautomatic and human evaluations, and is capable of dialogue classification and\nsingle-turn conversation generation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:27:52 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Zhang", "Ruiyi", ""], ["Zaheer", "Manzil", ""], ["Ahmed", "Amr", ""]]}, {"id": "2009.06857", "submitter": "Aran Komatsuzaki", "authors": "Aran Komatsuzaki", "title": "Current Limitations of Language Models: What You Need is Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We classify and re-examine some of the current approaches to improve the\nperformance-computes trade-off of language models, including (1) non-causal\nmodels (such as masked language models), (2) extension of batch length with\nefficient attention, (3) recurrence, (4) conditional computation and (5)\nretrieval. We identify some limitations (1) - (4) suffer from. For example, (1)\ncurrently struggles with open-ended text generation with the output loosely\nconstrained by the input as well as performing general textual tasks like\nGPT-2/3 due to its need for a specific fine-tuning dataset. (2) and (3) do not\nimprove the prediction of the first $\\sim 10^3$ tokens. Scaling up a model size\n(e.g. efficiently with (4)) still results in poor performance scaling for some\ntasks. We argue (5) would resolve many of these limitations, and it can (a)\nreduce the amount of supervision and (b) efficiently extend the context over\nthe entire training dataset and the entire past of the current sample. We\nspeculate how to modify MARGE to perform unsupervised causal modeling that\nachieves (b) with the retriever jointly trained.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 04:04:20 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Komatsuzaki", "Aran", ""]]}, {"id": "2009.06858", "submitter": "Yubo Huang", "authors": "Yubo Huang, Xuechun Wang, Luobao Zou, Zhiwei Zhuang, Weidong Zhang", "title": "Soft policy optimization using dual-track advantage estimator", "comments": "This is the accepted version of my manuscript (ICDM2020). Due to I\n  should curtail my paper within 6 pages in this conference, now, I want to\n  upload the complete version of my draft to readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), we always expect the agent to explore as many\nstates as possible in the initial stage of training and exploit the explored\ninformation in the subsequent stage to discover the most returnable trajectory.\nBased on this principle, in this paper, we soften the proximal policy\noptimization by introducing the entropy and dynamically setting the temperature\ncoefficient to balance the opportunity of exploration and exploitation. While\nmaximizing the expected reward, the agent will also seek other trajectories to\navoid the local optimal policy. Nevertheless, the increase of randomness\ninduced by entropy will reduce the train speed in the early stage. Integrating\nthe temporal-difference (TD) method and the general advantage estimator (GAE),\nwe propose the dual-track advantage estimator (DTAE) to accelerate the\nconvergence of value functions and further enhance the performance of the\nalgorithm. Compared with other on-policy RL algorithms on the Mujoco\nenvironment, the proposed method not only significantly speeds up the training\nbut also achieves the most advanced results in cumulative return.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 04:09:29 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Huang", "Yubo", ""], ["Wang", "Xuechun", ""], ["Zou", "Luobao", ""], ["Zhuang", "Zhiwei", ""], ["Zhang", "Weidong", ""]]}, {"id": "2009.06869", "submitter": "Aydogan Ozcan", "authors": "Md Sadman Sakib Rahman, Jingxi Li, Deniz Mengu, Yair Rivenson and\n  Aydogan Ozcan", "title": "Ensemble learning of diffractive optical networks", "comments": "22 Pages, 4 Figures, 1 Table", "journal-ref": "Light: Science & Applications (2021)", "doi": "10.1038/s41377-020-00446-w", "report-no": null, "categories": "cs.NE cs.CV cs.LG eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of research advances have emerged in the fields of optics and\nphotonics that benefit from harnessing the power of machine learning.\nSpecifically, there has been a revival of interest in optical computing\nhardware, due to its potential advantages for machine learning tasks in terms\nof parallelization, power efficiency and computation speed. Diffractive Deep\nNeural Networks (D2NNs) form such an optical computing framework, which\nbenefits from deep learning-based design of successive diffractive layers to\nall-optically process information as the input light diffracts through these\npassive layers. D2NNs have demonstrated success in various tasks, including\ne.g., object classification, spectral-encoding of information, optical pulse\nshaping and imaging, among others. Here, we significantly improve the inference\nperformance of diffractive optical networks using feature engineering and\nensemble learning. After independently training a total of 1252 D2NNs that were\ndiversely engineered with a variety of passive input filters, we applied a\npruning algorithm to select an optimized ensemble of D2NNs that collectively\nimprove their image classification accuracy. Through this pruning, we\nnumerically demonstrated that ensembles of N=14 and N=30 D2NNs achieve blind\ntesting accuracies of 61.14% and 62.13%, respectively, on the classification of\nCIFAR-10 test images, providing an inference improvement of >16% compared to\nthe average performance of the individual D2NNs within each ensemble. These\nresults constitute the highest inference accuracies achieved to date by any\ndiffractive optical neural network design on the same dataset and might provide\na significant leapfrog to extend the application space of diffractive optical\nimage classification and machine vision systems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 05:02:50 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Rahman", "Md Sadman Sakib", ""], ["Li", "Jingxi", ""], ["Mengu", "Deniz", ""], ["Rivenson", "Yair", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2009.06876", "submitter": "Ross Maciejewski", "authors": "Yuxin Ma, Arlen Fan, Jingrui He, Arun Reddy Nelakurthi, Ross\n  Maciejewski", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer\n  Learning Processes", "comments": "Accepted to IEEE Transactions on Visualization and Computer Graphics\n  (Proc. IEEE VAST 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical learning models hold an assumption that the training data\nand the future unlabeled data are drawn from the same distribution. However,\nthis assumption is difficult to fulfill in real-world scenarios and creates\nbarriers in reusing existing labels from similar application domains. Transfer\nLearning is intended to relax this assumption by modeling relationships between\ndomains, and is often applied in deep learning applications to reduce the\ndemand for labeled data and training time. Despite recent advances in exploring\ndeep learning models with visual analytics tools, little work has explored the\nissue of explaining and diagnosing the knowledge transfer process between deep\nlearning models. In this paper, we present a visual analytics framework for the\nmulti-level exploration of the transfer learning processes when training deep\nneural networks. Our framework establishes a multi-aspect design to explain how\nthe learned knowledge from the existing model is transferred into the new\nlearning task when training deep neural networks. Based on a comprehensive\nrequirement and task analysis, we employ descriptive visualization with\nperformance measures and detailed inspections of model behaviors from the\nstatistical, instance, feature, and model structure levels. We demonstrate our\nframework through two case studies on image classification by fine-tuning\nAlexNets to illustrate how analysts can utilize our framework.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 05:59:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ma", "Yuxin", ""], ["Fan", "Arlen", ""], ["He", "Jingrui", ""], ["Nelakurthi", "Arun Reddy", ""], ["Maciejewski", "Ross", ""]]}, {"id": "2009.06888", "submitter": "Guoqiang Liang", "authors": "Guoqiang Liang, Yi Jiang, Haiyan Hou", "title": "Same data may bring conflict results: a caution to use the disruptive\n  index", "comments": "Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, scholars have designed various types of\nbibliographic related indicators to identify breakthrough-class academic\nachievements. In this study, we take a further step to look at properties of\nthe promising disruptive index, thus deepening our understanding of this index\nand further facilitating its wise use in bibliometrics. Using publication\nrecords for Nobel laureates between 1900 and 2016, we calculate the DI of Nobel\nPrize-winning articles and its benchmark articles in each year and use the\nmedian DI to denote the central tendency in each year, and compare results\nbetween Medicine, Chemistry, and Physics. We find that conclusions based on DI\ndepend on the length of their citation time window, and different citation time\nwindows may cause different, even controversial, results. Also, discipline and\ntime play a role on the length of citation window when using DI to measure the\ninnovativeness of a scientific work. Finally, not all articles with DI equals\nto 1 were the breakthrough-class achievements. In other words, the DI stands up\ntheoretically, but we should not neglect that the DI was only shaped by the\nnumber of citing articles and times the references have been cited, these data\nmay vary from database to database.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 07:00:04 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Liang", "Guoqiang", ""], ["Jiang", "Yi", ""], ["Hou", "Haiyan", ""]]}, {"id": "2009.06899", "submitter": "Xuyun Wen", "authors": "Xuyun Wen, Liming Hsu, Weili Lin, Han Zhang, Dinggang Shen", "title": "Co-evolution of Functional Brain Network at Multiple Scales during Early\n  Infancy", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brains are organized into hierarchically modular networks\nfacilitating efficient and stable information processing and supporting diverse\ncognitive processes during the course of development. While the remarkable\nreconfiguration of functional brain network has been firmly established in\nearly life, all these studies investigated the network development from a\n\"single-scale\" perspective, which ignore the richness engendered by its\nhierarchical nature. To fill this gap, this paper leveraged a longitudinal\ninfant resting-state functional magnetic resonance imaging dataset from birth\nto 2 years of age, and proposed an advanced methodological framework to\ndelineate the multi-scale reconfiguration of functional brain network during\nearly development. Our proposed framework is consist of two parts. The first\npart developed a novel two-step multi-scale module detection method that could\nuncover efficient and consistent modular structure for longitudinal dataset\nfrom multiple scales in a completely data-driven manner. The second part\ndesigned a systematic approach that employed the linear mixed-effect model to\nfour global and nodal module-related metrics to delineate scale-specific\nage-related changes of network organization. By applying our proposed\nmethodological framework on the collected longitudinal infant dataset, we\nprovided the first evidence that, in the first 2 years of life, the brain\nfunctional network is co-evolved at different scales, where each scale displays\nthe unique reconfiguration pattern in terms of modular organization.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 07:21:04 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Wen", "Xuyun", ""], ["Hsu", "Liming", ""], ["Lin", "Weili", ""], ["Zhang", "Han", ""], ["Shen", "Dinggang", ""]]}, {"id": "2009.06911", "submitter": "Soham Chattopadhyay", "authors": "Soham Chattopadhyay, Hritam Basak", "title": "Multi-scale Attention U-Net (MsAUNet): A Modified U-Net Architecture for\n  Scene Segmentation", "comments": "12 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing success of Convolution neural networks (CNN) in the\nrecent past in the task of scene segmentation, the standard models lack some of\nthe important features that might result in sub-optimal segmentation outputs.\nThe widely used encoder-decoder architecture extracts and uses several\nredundant and low-level features at different steps and different scales. Also,\nthese networks fail to map the long-range dependencies of local features, which\nresults in discriminative feature maps corresponding to each semantic class in\nthe resulting segmented image. In this paper, we propose a novel multi-scale\nattention network for scene segmentation purposes by using the rich contextual\ninformation from an image. Different from the original UNet architecture we\nhave used attention gates which take the features from the encoder and the\noutput of the pyramid pool as input and produced out-put is further\nconcatenated with the up-sampled output of the previous pyramid-pool layer and\nmapped to the next subsequent layer. This network can map local features with\ntheir global counterparts with improved accuracy and emphasize on\ndiscriminative image regions by focusing on relevant local features only. We\nalso propose a compound loss function by optimizing the IoU loss and fusing\nDice Loss and Weighted Cross-entropy loss with it to achieve an optimal\nsolution at a faster convergence rate. We have evaluated our model on two\nstandard datasets named PascalVOC2012 and ADE20k and was able to achieve mean\nIoU of 79.88% and 44.88% on the two datasets respectively, and compared our\nresult with the widely known models to prove the superiority of our model over\nthem.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:03:41 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Chattopadhyay", "Soham", ""], ["Basak", "Hritam", ""]]}, {"id": "2009.06921", "submitter": "Emir Demirovi\\'c", "authors": "Emir Demirovi\\'c, Peter J. Stuckey", "title": "Optimal Decision Trees for Nonlinear Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear metrics, such as the F1-score, Matthews correlation coefficient,\nand Fowlkes-Mallows index, are often used to evaluate the performance of\nmachine learning models, in particular, when facing imbalanced datasets that\ncontain more samples of one class than the other. Recent optimal decision tree\nalgorithms have shown remarkable progress in producing trees that are optimal\nwith respect to linear criteria, such as accuracy, but unfortunately nonlinear\nmetrics remain a challenge. To address this gap, we propose a novel algorithm\nbased on bi-objective optimisation, which treats misclassifications of each\nbinary class as a separate objective. We show that, for a large class of\nmetrics, the optimal tree lies on the Pareto frontier. Consequently, we obtain\nthe optimal tree by using our method to generate the set of all nondominated\ntrees. To the best of our knowledge, this is the first method to compute\nprovably optimal decision trees for nonlinear metrics. Our approach leads to a\ntrade-off when compared to optimising linear metrics: the resulting trees may\nbe more desirable according to the given nonlinear metric at the expense of\nhigher runtimes. Nevertheless, the experiments illustrate that runtimes are\nreasonable for majority of the tested datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:30:56 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Demirovi\u0107", "Emir", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2009.06946", "submitter": "Konstantinos Mavromatis", "authors": "Costas Mavromatis, George Karypis", "title": "Graph InfoClust: Leveraging cluster-level node information for\n  unsupervised graph representation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised (or self-supervised) graph representation learning is essential\nto facilitate various graph data mining tasks when external supervision is\nunavailable. The challenge is to encode the information about the graph\nstructure and the attributes associated with the nodes and edges into a low\ndimensional space. Most existing unsupervised methods promote similar\nrepresentations across nodes that are topologically close. Recently, it was\nshown that leveraging additional graph-level information, e.g., information\nthat is shared among all nodes, encourages the representations to be mindful of\nthe global properties of the graph, which greatly improves their quality.\nHowever, in most graphs, there is significantly more structure that can be\ncaptured, e.g., nodes tend to belong to (multiple) clusters that represent\nstructurally similar nodes. Motivated by this observation, we propose a graph\nrepresentation learning method called Graph InfoClust (GIC), that seeks to\nadditionally capture cluster-level information content. These clusters are\ncomputed by a differentiable K-means method and are jointly optimized by\nmaximizing the mutual information between nodes of the same clusters. This\noptimization leads the node representations to capture richer information and\nnodal interactions, which improves their quality. Experiments show that GIC\noutperforms state-of-art methods in various downstream tasks (node\nclassification, link prediction, and node clustering) with a 0.9% to 6.1% gain\nover the best competing approach, on average.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 09:33:20 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mavromatis", "Costas", ""], ["Karypis", "George", ""]]}, {"id": "2009.06962", "submitter": "Jang-Hyun Kim", "authors": "Jang-Hyun Kim, Wonho Choo, Hyun Oh Song", "title": "Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks achieve great performance on fitting the training\ndistribution, the learned networks are prone to overfitting and are susceptible\nto adversarial attacks. In this regard, a number of mixup based augmentation\nmethods have been recently proposed. However, these approaches mainly focus on\ncreating previously unseen virtual examples and can sometimes provide\nmisleading supervisory signal to the network. To this end, we propose Puzzle\nMix, a mixup method for explicitly utilizing the saliency information and the\nunderlying statistics of the natural examples. This leads to an interesting\noptimization problem alternating between the multi-label objective for optimal\nmixing mask and saliency discounted optimal transport objective. Our\nexperiments show Puzzle Mix achieves the state of the art generalization and\nthe adversarial robustness results compared to other mixup methods on\nCIFAR-100, Tiny-ImageNet, and ImageNet datasets. The source code is available\nat https://github.com/snu-mllab/PuzzleMix.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:10:23 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 10:45:39 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kim", "Jang-Hyun", ""], ["Choo", "Wonho", ""], ["Song", "Hyun Oh", ""]]}, {"id": "2009.06963", "submitter": "Dario Zanca", "authors": "Dario Zanca, Marco Gori, Stefano Melacci, Alessandra Rufa", "title": "Gravitational Models Explain Shifts on Human Visual Attention", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-020-73494-2", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attention refers to the human brain's ability to select relevant\nsensory information for preferential processing, improving performance in\nvisual and cognitive tasks. It proceeds in two phases. One in which visual\nfeature maps are acquired and processed in parallel. Another where the\ninformation from these maps is merged in order to select a single location to\nbe attended for further and more complex computations and reasoning. Its\ncomputational description is challenging, especially if the temporal dynamics\nof the process are taken into account. Numerous methods to estimate saliency\nhave been proposed in the last three decades. They achieve almost perfect\nperformance in estimating saliency at the pixel level, but the way they\ngenerate shifts in visual attention fully depends on winner-take-all (WTA)\ncircuitry. WTA is implemented} by the biological hardware in order to select a\nlocation with maximum saliency, towards which to direct overt attention. In\nthis paper we propose a gravitational model (GRAV) to describe the attentional\nshifts. Every single feature acts as an attractor and {the shifts are the\nresult of the joint effects of the attractors. In the current framework, the\nassumption of a single, centralized saliency map is no longer necessary, though\nstill plausible. Quantitative results on two large image datasets show that\nthis model predicts shifts more accurately than winner-take-all.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:12:41 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zanca", "Dario", ""], ["Gori", "Marco", ""], ["Melacci", "Stefano", ""], ["Rufa", "Alessandra", ""]]}, {"id": "2009.06966", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Kia Khezeli, Victor Picheny", "title": "On Information Gain and Regret Bounds in Gaussian Process Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider the sequential optimization of an expensive to evaluate and possibly\nnon-convex objective function $f$ from noisy feedback, that can be considered\nas a continuum-armed bandit problem. Upper bounds on the regret performance of\nseveral learning algorithms (GP-UCB, GP-TS, and their variants) are known under\nboth a Bayesian (when $f$ is a sample from a Gaussian process (GP)) and a\nfrequentist (when $f$ lives in a reproducing kernel Hilbert space) setting. The\nregret bounds often rely on the maximal information gain $\\gamma_T$ between $T$\nobservations and the underlying GP (surrogate) model. We provide general bounds\non $\\gamma_T$ based on the decay rate of the eigenvalues of the GP kernel,\nwhose specialisation for commonly used kernels, improves the existing bounds on\n$\\gamma_T$, and subsequently the regret bounds relying on $\\gamma_T$ under\nnumerous settings. For the Mat\\'ern family of kernels, where the lower bounds\non $\\gamma_T$, and regret under the frequentist setting, are known, our results\nclose a huge polynomial in $T$ gap between the upper and lower bounds (up to\nlogarithmic in $T$ factors).\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:15:29 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 14:28:46 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 22:46:52 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Vakili", "Sattar", ""], ["Khezeli", "Kia", ""], ["Picheny", "Victor", ""]]}, {"id": "2009.07000", "submitter": "Natalia Efremova", "authors": "Sagar Vaze, James Foley, Mohamed Seddiq, Alexey Unagaev, Natalia\n  Efremova", "title": "Optimal Use of Multi-spectral Satellite Data with Convolutional Neural\n  Networks", "comments": "AI for Social Good workshop - Harvard CRCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of satellite imagery will prove a crucial tool in the pursuit of\nsustainable development. While Convolutional Neural Networks (CNNs) have made\nlarge gains in natural image analysis, their application to multi-spectral\nsatellite images (wherein input images have a large number of channels) remains\nrelatively unexplored. In this paper, we compare different methods of\nleveraging multi-band information with CNNs, demonstrating the performance of\nall compared methods on the task of semantic segmentation of agricultural\nvegetation (vineyards). We show that standard industry practice of using bands\nselected by a domain expert leads to a significantly worse test accuracy than\nthe other methods compared. Specifically, we compare: using bands specified by\nan expert; using all available bands; learning attention maps over the input\nbands; and leveraging Bayesian optimisation to dictate band choice. We show\nthat simply using all available band information already increases test time\nperformance, and show that the Bayesian optimisation, first applied to band\nselection in this work, can be used to further boost accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 11:55:45 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Vaze", "Sagar", ""], ["Foley", "James", ""], ["Seddiq", "Mohamed", ""], ["Unagaev", "Alexey", ""], ["Efremova", "Natalia", ""]]}, {"id": "2009.07008", "submitter": "Nicolas Michael M\\\"uller", "authors": "Nicolas Michael M\\\"uller, Daniel Kowatsch, Konstantin B\\\"ottinger", "title": "Data Poisoning Attacks on Regression Learning and Corresponding Defenses", "comments": "Accepted for Publication at PRDC2020, Copyright by IEEE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial data poisoning is an effective attack against machine learning\nand threatens model integrity by introducing poisoned data into the training\ndataset. So far, it has been studied mostly for classification, even though\nregression learning is used in many mission critical systems (such as dosage of\nmedication, control of cyber-physical systems and managing power supply).\nTherefore, in the present research, we aim to evaluate all aspects of data\npoisoning attacks on regression learning, exceeding previous work both in terms\nof breadth and depth. We present realistic scenarios in which data poisoning\nattacks threaten production systems and introduce a novel black-box attack,\nwhich is then applied to a real-word medical use-case. As a result, we observe\nthat the mean squared error (MSE) of the regressor increases to 150 percent due\nto inserting only two percent of poison samples. Finally, we present a new\ndefense strategy against the novel and previous attacks and evaluate it\nthoroughly on 26 datasets. As a result of the conducted experiments, we\nconclude that the proposed defence strategy effectively mitigates the\nconsidered attacks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:14:54 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["M\u00fcller", "Nicolas Michael", ""], ["Kowatsch", "Daniel", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2009.07022", "submitter": "Ningyu Zhang", "authors": "Haiyang Yu, Ningyu Zhang, Shumin Deng, Zonggang Yuan, Yantao Jia,\n  Huajun Chen", "title": "The Devil is the Classifier: Investigating Long Tail Relation\n  Classification with Decoupling Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-tailed relation classification is a challenging problem as the head\nclasses may dominate the training phase, thereby leading to the deterioration\nof the tail performance. Existing solutions usually address this issue via\nclass-balancing strategies, e.g., data re-sampling and loss re-weighting, but\nall these methods adhere to the schema of entangling learning of the\nrepresentation and classifier. In this study, we conduct an in-depth empirical\ninvestigation into the long-tailed problem and found that pre-trained models\nwith instance-balanced sampling already capture the well-learned\nrepresentations for all classes; moreover, it is possible to achieve better\nlong-tailed classification ability at low cost by only adjusting the\nclassifier. Inspired by this observation, we propose a robust classifier with\nattentive relation routing, which assigns soft weights by automatically\naggregating the relations. Extensive experiments on two datasets demonstrate\nthe effectiveness of our proposed approach. Code and datasets are available in\nhttps://github.com/zjunlp/deepke.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:47:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Yu", "Haiyang", ""], ["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Yuan", "Zonggang", ""], ["Jia", "Yantao", ""], ["Chen", "Huajun", ""]]}, {"id": "2009.07044", "submitter": "Ilianna Kollia", "authors": "D. Kollias, N. Bouas, Y. Vlaxos, V. Brillakis, M. Seferis, I. Kollia,\n  L. Sukissian, J. Wingate, and S. Kollias", "title": "Deep Transparent Prediction through Latent Representation Analysis", "comments": "16 pages, 8 figures, to be published at Foundations of Trustworthy AI\n  integrating Learning, Optimisation and Reasoning (TAILOR) Workshop of\n  European Conference on Artificial Intelligence (ECAI) 2020. arXiv admin note:\n  substantial text overlap with arXiv:1911.10653", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a novel deep learning approach, which extracts latent\ninformation from trained Deep Neural Networks (DNNs) and derives concise\nrepresentations that are analyzed in an effective, unified way for prediction\npurposes. It is well known that DNNs are capable of analyzing complex data;\nhowever, they lack transparency in their decision making, in the sense that it\nis not straightforward to justify their prediction, or to visualize the\nfeatures on which the decision was based. Moreover, they generally require\nlarge amounts of data in order to learn and become able to adapt to different\nenvironments. This makes their use difficult in healthcare, where trust and\npersonalization are key issues. Transparency combined with high prediction\naccuracy are the targeted goals of the proposed approach. It includes both\nsupervised DNN training and unsupervised learning of latent variables extracted\nfrom the trained DNNs. Domain Adaptation from multiple sources is also\npresented as an extension, where the extracted latent variable representations\nare used to generate predictions in other, non-annotated, environments.\nSuccessful application is illustrated through a large experimental study in\nvarious fields: prediction of Parkinson's disease from MRI and DaTScans;\nprediction of COVID-19 and pneumonia from CT scans and X-rays; optical\ncharacter verification in retail food packaging.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 19:21:40 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 22:06:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kollias", "D.", ""], ["Bouas", "N.", ""], ["Vlaxos", "Y.", ""], ["Brillakis", "V.", ""], ["Seferis", "M.", ""], ["Kollia", "I.", ""], ["Sukissian", "L.", ""], ["Wingate", "J.", ""], ["Kollias", "S.", ""]]}, {"id": "2009.07052", "submitter": "Felix Wick", "authors": "F. Wick and U. Kerzel and M. Hahn and M. Wolf and T. Singhal and D.\n  Stemmer and J. Ernst and M. Feindt", "title": "Demand Forecasting of Individual Probability Density Functions with\n  Machine Learning", "comments": "final version published in Springer Nature Operations Research Forum", "journal-ref": "SN Oper. Res. Forum 2, 37 (2021)", "doi": "10.1007/s43069-021-00079-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand forecasting is a central component of the replenishment process for\nretailers, as it provides crucial input for subsequent decision making like\nordering processes. In contrast to point estimates, such as the conditional\nmean of the underlying probability distribution, or confidence intervals,\nforecasting complete probability density functions allows to investigate the\nimpact on operational metrics, which are important to define the business\nstrategy, over the full range of the expected demand. Whereas metrics\nevaluating point estimates are widely used, methods for assessing the accuracy\nof predicted distributions are rare, and this work proposes new techniques for\nboth qualitative and quantitative evaluation methods. Using the supervised\nmachine learning method \"Cyclic Boosting\", complete individual probability\ndensity functions can be predicted such that each prediction is fully\nexplainable. This is of particular importance for practitioners, as it allows\nto avoid \"black-box\" models and understand the contributing factors for each\nindividual prediction. Another crucial aspect in terms of both explainability\nand generalizability of demand forecasting methods is the limitation of the\ninfluence of temporal confounding, which is prevalent in most state of the art\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:05:05 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 09:12:38 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 07:12:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wick", "F.", ""], ["Kerzel", "U.", ""], ["Hahn", "M.", ""], ["Wolf", "M.", ""], ["Singhal", "T.", ""], ["Stemmer", "D.", ""], ["Ernst", "J.", ""], ["Feindt", "M.", ""]]}, {"id": "2009.07057", "submitter": "Parthasarathy Suryanarayanan", "authors": "Parthasarathy Suryanarayanan, Ching-Huei Tsou, Ananya Poddar, Diwakar\n  Mahajan, Bharath Dandala, Piyush Madan, Anshul Agrawal, Charles Wachira,\n  Osebe Mogaka Samuel, Osnat Bar-Shira, Clifton Kipchirchir, Sharon Okwako,\n  William Ogallo, Fred Otieno, Timothy Nyota, Fiona Matu, Vesna Resende Barros,\n  Daniel Shats, Oren Kagan, Sekou Remy, Oliver Bent, Pooja Guhan, Shilpa\n  Mahatma, Aisha Walcott-Bryant, Divya Pathak, Michal Rosen-Zvi", "title": "WNTRAC: AI Assisted Tracking of Non-pharmaceutical Interventions\n  Implemented Worldwide for COVID-19", "comments": "Updated title (Artificial Intelligence => AI). Updated figures.\n  Referenced the open-sourced code repository in Code Availability section.\n  Updated figures in the Usage Notes section", "journal-ref": null, "doi": "10.1038/s41597-021-00878-y", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Coronavirus disease 2019 (COVID-19) global pandemic has transformed\nalmost every facet of human society throughout the world. Against an emerging,\nhighly transmissible disease with no definitive treatment or vaccine,\ngovernments worldwide have implemented non-pharmaceutical intervention (NPI) to\nslow the spread of the virus. Examples of such interventions include community\nactions (e.g. school closures, restrictions on mass gatherings), individual\nactions (e.g. mask wearing, self-quarantine), and environmental actions (e.g.\npublic facility cleaning). We present the Worldwide Non-pharmaceutical\nInterventions Tracker for COVID-19 (WNTRAC), a comprehensive dataset consisting\nof over 6,000 NPIs implemented worldwide since the start of the pandemic.\nWNTRAC covers NPIs implemented across 261 countries and territories, and\nclassifies NPI measures into a taxonomy of sixteen NPI types. NPI measures are\nautomatically extracted daily from Wikipedia articles using natural language\nprocessing techniques and manually validated to ensure accuracy and veracity.\nWe hope that the dataset is valuable for policymakers, public health leaders,\nand researchers in modeling and analysis efforts for controlling the spread of\nCOVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:06:20 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 14:07:07 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 17:39:22 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 19:12:48 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Suryanarayanan", "Parthasarathy", ""], ["Tsou", "Ching-Huei", ""], ["Poddar", "Ananya", ""], ["Mahajan", "Diwakar", ""], ["Dandala", "Bharath", ""], ["Madan", "Piyush", ""], ["Agrawal", "Anshul", ""], ["Wachira", "Charles", ""], ["Samuel", "Osebe Mogaka", ""], ["Bar-Shira", "Osnat", ""], ["Kipchirchir", "Clifton", ""], ["Okwako", "Sharon", ""], ["Ogallo", "William", ""], ["Otieno", "Fred", ""], ["Nyota", "Timothy", ""], ["Matu", "Fiona", ""], ["Barros", "Vesna Resende", ""], ["Shats", "Daniel", ""], ["Kagan", "Oren", ""], ["Remy", "Sekou", ""], ["Bent", "Oliver", ""], ["Guhan", "Pooja", ""], ["Mahatma", "Shilpa", ""], ["Walcott-Bryant", "Aisha", ""], ["Pathak", "Divya", ""], ["Rosen-Zvi", "Michal", ""]]}, {"id": "2009.07098", "submitter": "Siyuan Shen", "authors": "Siyuan Shen, Tianjia Shao, Kun Zhou, Chenfanfu Jiang, Feng Luo, Yin\n  Yang", "title": "Second-order Neural Network Training Using Complex-step Directional\n  Derivative", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the superior performance of second-order optimization methods such as\nNewton's method is well known, they are hardly used in practice for deep\nlearning because neither assembling the Hessian matrix nor calculating its\ninverse is feasible for large-scale problems. Existing second-order methods\nresort to various diagonal or low-rank approximations of the Hessian, which\noften fail to capture necessary curvature information to generate a substantial\nimprovement. On the other hand, when training becomes batch-based (i.e.,\nstochastic), noisy second-order information easily contaminates the training\nprocedure unless expensive safeguard is employed. In this paper, we adopt a\nnumerical algorithm for second-order neural network training. We tackle the\npractical obstacle of Hessian calculation by using the complex-step finite\ndifference (CSFD) -- a numerical procedure adding an imaginary perturbation to\nthe function for derivative computation. CSFD is highly robust, efficient, and\naccurate (as accurate as the analytic result). This method allows us to\nliterally apply any known second-order optimization methods for deep learning\ntraining. Based on it, we design an effective Newton Krylov procedure. The key\nmechanism is to terminate the stochastic Krylov iteration as soon as a\ndisturbing direction is found so that unnecessary computation can be avoided.\nDuring the optimization, we monitor the approximation error in the Taylor\nexpansion to adjust the step size. This strategy combines advantages of line\nsearch and trust region methods making our method preserves good local and\nglobal convergency at the same time. We have tested our methods in various deep\nlearning tasks. The experiments show that our method outperforms exiting\nmethods, and it often converges one-order faster. We believe our method will\ninspire a wide-range of new algorithms for deep learning and numerical\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:46:57 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Shen", "Siyuan", ""], ["Shao", "Tianjia", ""], ["Zhou", "Kun", ""], ["Jiang", "Chenfanfu", ""], ["Luo", "Feng", ""], ["Yang", "Yin", ""]]}, {"id": "2009.07101", "submitter": "Kazuhisa Fujita Dr.", "authors": "Kazuhisa Fujita", "title": "Approximate spectral clustering using both reference vectors and\n  topology of the network generated by growing neural gas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering (SC) is one of the most popular clustering methods and\noften outperforms traditional clustering methods. SC uses the eigenvectors of a\nLaplacian matrix calculated from a similarity matrix of a dataset. SC has\nserious drawbacks: the significant increases in the time complexity derived\nfrom the computation of eigenvectors and the memory space complexity to store\nthe similarity matrix. To address the issues, I develop a new approximate\nspectral clustering using the network generated by growing neural gas (GNG),\ncalled ASC with GNG in this study. ASC with GNG uses not only reference vectors\nfor vector quantization but also the topology of the network for extraction of\nthe topological relationship between data points in a dataset. ASC with GNG\ncalculates the similarity matrix from both the reference vectors and the\ntopology of the network generated by GNG. Using the network generated from a\ndataset by GNG, ASC with GNG achieves to reduce the computational and space\ncomplexities and improve clustering quality. In this study, I demonstrate that\nASC with GNG effectively reduces the computational time. Moreover, this study\nshows that ASC with GNG provides equal to or better clustering performance than\nSC.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:49:24 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 13:55:19 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 02:23:16 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fujita", "Kazuhisa", ""]]}, {"id": "2009.07103", "submitter": "Aditya Singh", "authors": "Aditya Singh, Akram Mohammed, Lokesh Chinthala, Rishikesan\n  Kamaleswaran", "title": "Machine learning predicts early onset of fever from continuous\n  physiological data of critically ill patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fever can provide valuable information for diagnosis and prognosis of various\ndiseases such as pneumonia, dengue, sepsis, etc., therefore, predicting fever\nearly can help in the effectiveness of treatment options and expediting the\ntreatment process. This study aims to develop novel algorithms that can\naccurately predict fever onset in critically ill patients by applying machine\nlearning technique on continuous physiological data. We analyzed continuous\nphysiological data collected every 5-minute from a cohort of over 200,000\ncritically ill patients admitted to an Intensive Care Unit (ICU) over a 2-year\nperiod. Each episode of fever from the same patient were considered as an\nindependent event, with separations of at least 24 hours. We extracted\ndescriptive statistical features from six physiological data streams, including\nheart rate, respiration, systolic and diastolic blood pressure, mean arterial\npressure, and oxygen saturation, and use these features to independently\npredict the onset of fever. Using a bootstrap aggregation method, we created a\nbalanced dataset of 7,801 afebrile and febrile patients and analyzed features\nup to 4 hours before the fever onset. We found that supervised machine learning\nmethods can predict fever up to 4 hours before onset in critically ill patients\nwith high recall, precision, and F1-score. This study demonstrates the\nviability of using machine learning to predict fever among hospitalized adults.\nThe discovery of salient physiomarkers through machine learning and deep\nlearning techniques has the potential to further accelerate the development and\nimplementation of innovative care delivery protocols and strategies for\nmedically vulnerable patients.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 09:16:09 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Singh", "Aditya", ""], ["Mohammed", "Akram", ""], ["Chinthala", "Lokesh", ""], ["Kamaleswaran", "Rishikesan", ""]]}, {"id": "2009.07109", "submitter": "Roger David Soberanis-Mukul", "authors": "Roger D. Soberanis-Mukul, Shadi Albarqouni, Nassir Navab", "title": "Polyp-artifact relationship analysis using graph inductive learned\n  representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis process of colorectal cancer mainly focuses on the localization\nand characterization of abnormal growths in the colon tissue known as polyps.\nDespite recent advances in deep object localization, the localization of polyps\nremains challenging due to the similarities between tissues, and the high level\nof artifacts. Recent studies have shown the negative impact of the presence of\nartifacts in the polyp detection task, and have started to take them into\naccount within the training process. However, the use of prior knowledge\nrelated to the spatial interaction of polyps and artifacts has not yet been\nconsidered. In this work, we incorporate artifact knowledge in a\npost-processing step. Our method models this task as an inductive graph\nrepresentation learning problem, and is composed of training and inference\nsteps. Detected bounding boxes around polyps and artifacts are considered as\nnodes connected by a defined criterion. The training step generates a node\nclassifier with ground truth bounding boxes. In inference, we use this\nclassifier to analyze a second graph, generated from artifact and polyp\npredictions given by region proposal networks. We evaluate how the choices in\nthe connectivity and artifacts affect the performance of our method and show\nthat it has the potential to reduce the false positives in the results of a\nregion proposal network.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:56:39 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Soberanis-Mukul", "Roger D.", ""], ["Albarqouni", "Shadi", ""], ["Navab", "Nassir", ""]]}, {"id": "2009.07110", "submitter": "Wei Chen", "authors": "Wei Chen and Faez Ahmed", "title": "MO-PaDGAN: Reparameterizing Engineering Designs for Augmented\n  Multi-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimization is key to solving many Engineering Design\nproblems, where design parameters are optimized for several performance\nindicators. However, optimization results are highly dependent on how the\ndesigns are parameterized. Researchers have shown that deep generative models\ncan learn compact design representations, providing a new way of parameterizing\ndesigns to achieve faster convergence and improved optimization performance.\nDespite their success in capturing complex distributions, existing generative\nmodels face three challenges when used for design problems: 1) generated\ndesigns have limited design space coverage, 2) the generator ignores design\nperformance, and 3) the new parameterization is unable to represent designs\nbeyond training data. To address these challenges, we propose MO-PaDGAN, which\nadds a Determinantal Point Processes based loss function to the generative\nadversarial network to simultaneously model diversity and (multi-variate)\nperformance. MO-PaDGAN can thus improve the performances and coverage of\ngenerated designs, and even generate designs with performances exceeding those\nfrom training data. When using MO-PaDGAN as a new parameterization in\nmulti-objective optimization, we can discover much better Pareto fronts even\nthough the training data do not cover those Pareto fronts. In a real-world\nmulti-objective airfoil design example, we demonstrate that MO-PaDGAN achieves,\non average, a 186% improvement in the hypervolume indicator when compared to\nthe vanilla GAN or other state-of-the-art parameterization methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:58:31 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Chen", "Wei", ""], ["Ahmed", "Faez", ""]]}, {"id": "2009.07111", "submitter": "Sheng Wan", "authors": "Sheng Wan and Shirui Pan and Jian Yang and Chen Gong", "title": "Contrastive and Generative Graph Convolutional Networks for Graph-based\n  Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a\nhandful of labeled data to the remaining massive unlabeled data via a graph. As\none of the most popular graph-based SSL approaches, the recently proposed Graph\nConvolutional Networks (GCNs) have gained remarkable progress by combining the\nsound expressiveness of neural networks with graph structure. Nevertheless, the\nexisting graph-based methods do not directly address the core problem of SSL,\ni.e., the shortage of supervision, and thus their performances are still very\nlimited. To accommodate this issue, a novel GCN-based SSL algorithm is\npresented in this paper to enrich the supervision signals by utilizing both\ndata similarities and graph structure. Firstly, by designing a semi-supervised\ncontrastive loss, improved node representations can be generated via maximizing\nthe agreement between different views of the same data or the data from the\nsame class. Therefore, the rich unlabeled data and the scarce yet valuable\nlabeled data can jointly provide abundant supervision information for learning\ndiscriminative node representations, which helps improve the subsequent\nclassification result. Secondly, the underlying determinative relationship\nbetween the data features and input graph topology is extracted as\nsupplementary supervision signals for SSL via using a graph generative loss\nrelated to the input features. Intensive experimental results on a variety of\nreal-world datasets firmly verify the effectiveness of our algorithm compared\nwith other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:59:28 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 02:06:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wan", "Sheng", ""], ["Pan", "Shirui", ""], ["Yang", "Jian", ""], ["Gong", "Chen", ""]]}, {"id": "2009.07118", "submitter": "Timo Schick", "authors": "Timo Schick, Hinrich Sch\\\"utze", "title": "It's Not Just Size That Matters: Small Language Models Are Also Few-Shot\n  Learners", "comments": "Accepted at NAACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When scaled to hundreds of billions of parameters, pretrained language models\nsuch as GPT-3 (Brown et al., 2020) achieve remarkable few-shot performance.\nHowever, enormous amounts of compute are required for training and applying\nsuch big models, resulting in a large carbon footprint and making it difficult\nfor researchers and practitioners to use them. We show that performance similar\nto GPT-3 can be obtained with language models that are much \"greener\" in that\ntheir parameter count is several orders of magnitude smaller. This is achieved\nby converting textual inputs into cloze questions that contain a task\ndescription, combined with gradient-based optimization; exploiting unlabeled\ndata gives further improvements. We identify key factors required for\nsuccessful natural language understanding with small language models.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:18:53 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 08:16:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2009.07132", "submitter": "Nicola Milano", "authors": "Nicola Milano, Stefano Nolfi", "title": "Autonomous Learning of Features for Control: Experiments with Embodied\n  and Situated Agents", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0250040", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As discussed in previous studies, the efficacy of evolutionary or\nreinforcement learning algorithms for continuous control optimization can be\nenhanced by including a neural module dedicated to feature extraction trained\nthrough self-supervised methods. In this paper we report additional experiments\nsupporting this hypothesis and we demonstrate how the advantage provided by\nfeature extraction is not limited to problems that benefit from dimensionality\nreduction or that involve agents operating on the basis of allocentric\nperception. We introduce a method that permits to continue the training of the\nfeature-extraction module during the training of the policy network and that\nincreases the efficacy of feature extraction. Finally, we compare alternative\nfeature-extracting methods and we show that sequence-to-sequence learning\nyields better results than the methods considered in previous studies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:34:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Milano", "Nicola", ""], ["Nolfi", "Stefano", ""]]}, {"id": "2009.07139", "submitter": "Vikram Venkatraghavan", "authors": "Vikram Venkatraghavan, Stefan Klein, Lana Fani, Leontine S. Ham, Henri\n  Vrooman, M. Kamran Ikram, Wiro J. Niessen, Esther E. Bron (for the\n  Alzheimer's Disease Neuroimaging Initiative)", "title": "Analyzing the effect of APOE on Alzheimer's disease progression using an\n  event-based model for stratified populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Alzheimer's disease (AD) is the most common form of dementia and is\nphenotypically heterogeneous. APOE is a triallelic gene which correlates with\nphenotypic heterogeneity in AD. In this work, we determined the effect of APOE\nalleles on the disease progression timeline of AD using a discriminative\nevent-based model (DEBM). Since DEBM is a data-driven model, stratification\ninto smaller disease subgroups would lead to more inaccurate models as compared\nto fitting the model on the entire dataset. Hence our secondary aim is to\npropose and evaluate novel approaches in which we split the different steps of\nDEBM into group-aspecific and group-specific parts, where the entire dataset is\nused to train the group-aspecific parts and only the data from a specific group\nis used to train the group-specific parts of the DEBM. We performed simulation\nexperiments to benchmark the accuracy of the proposed approaches and to select\nthe optimal approach. Subsequently, the chosen approach was applied to the\nbaseline data of 417 cognitively normal, 235 mild cognitively impaired who\nconvert to AD within 3 years, and 342 AD patients from the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) dataset to gain new insights into the effect of\nAPOE carriership on the disease progression timeline of AD. The presented\nmodels could aid understanding of the disease, and in selecting homogeneous\ngroup of presymptomatic subjects at-risk of developing symptoms for clinical\ntrials.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:46:10 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Venkatraghavan", "Vikram", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Klein", "Stefan", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Fani", "Lana", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Ham", "Leontine S.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Vrooman", "Henri", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Ikram", "M. Kamran", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Niessen", "Wiro J.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Bron", "Esther E.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "2009.07165", "submitter": "Kaivalya Rawal", "authors": "Kaivalya Rawal, Himabindu Lakkaraju", "title": "Beyond Individualized Recourse: Interpretable and Interactive Summaries\n  of Actionable Recourses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As predictive models are increasingly being deployed in high-stakes\ndecision-making, there has been a lot of interest in developing algorithms\nwhich can provide recourses to affected individuals. While developing such\ntools is important, it is even more critical to analyse and interpret a\npredictive model, and vet it thoroughly to ensure that the recourses it offers\nare meaningful and non-discriminatory before it is deployed in the real world.\nTo this end, we propose a novel model agnostic framework called Actionable\nRecourse Summaries (AReS) to construct global counterfactual explanations which\nprovide an interpretable and accurate summary of recourses for the entire\npopulation. We formulate a novel objective which simultaneously optimizes for\ncorrectness of the recourses and interpretability of the explanations, while\nminimizing overall recourse costs across the entire population. More\nspecifically, our objective enables us to learn, with optimality guarantees on\nrecourse correctness, a small number of compact rule sets each of which capture\nrecourses for well defined subpopulations within the data. We also demonstrate\ntheoretically that several of the prior approaches proposed to generate\nrecourses for individuals are special cases of our framework. Experimental\nevaluation with real world datasets and user studies demonstrate that our\nframework can provide decision makers with a comprehensive overview of\nrecourses corresponding to any black box model, and consequently help detect\nundesirable model biases and discrimination.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:14:08 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 01:51:06 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 19:22:25 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Rawal", "Kaivalya", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2009.07173", "submitter": "Thosini Bamunu Mudiyanselage", "authors": "Thosini Bamunu Mudiyanselage, Xiujuan Lei, Nipuna Senanayake, Yanqing\n  Zhang, Yi Pan", "title": "Graph Convolution Networks Using Message Passing and Multi-Source\n  Similarity Features for Predicting circRNA-Disease Association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs can be used to effectively represent complex data structures. Learning\nthese irregular data in graphs is challenging and still suffers from shallow\nlearning. Applying deep learning on graphs has recently showed good performance\nin many applications in social analysis, bioinformatics etc. A message passing\ngraph convolution network is such a powerful method which has expressive power\nto learn graph structures. Meanwhile, circRNA is a type of non-coding RNA which\nplays a critical role in human diseases. Identifying the associations between\ncircRNAs and diseases is important to diagnosis and treatment of complex\ndiseases. However, there are limited number of known associations between them\nand conducting biological experiments to identify new associations is time\nconsuming and expensive. As a result, there is a need of building efficient and\nfeasible computation methods to predict potential circRNA-disease associations.\nIn this paper, we propose a novel graph convolution network framework to learn\nfeatures from a graph built with multi-source similarity information to predict\ncircRNA-disease associations. First we use multi-source information of circRNA\nsimilarity, disease and circRNA Gaussian Interaction Profile (GIP) kernel\nsimilarity to extract the features using first graph convolution. Then we\npredict disease associations for each circRNA with second graph convolution.\nProposed framework with five-fold cross validation on various experiments shows\npromising results in predicting circRNA-disease association and outperforms\nother existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:22:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mudiyanselage", "Thosini Bamunu", ""], ["Lei", "Xiujuan", ""], ["Senanayake", "Nipuna", ""], ["Zhang", "Yanqing", ""], ["Pan", "Yi", ""]]}, {"id": "2009.07196", "submitter": "Leto Peel", "authors": "Michael T. Schaub and Leto Peel", "title": "Hierarchical community structure in networks", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modular and hierarchical structures are pervasive in real-world complex\nsystems. A great deal of effort has gone into trying to detect and study these\nstructures. Important theoretical advances in the detection of modular, or\n\"community\", structures have included identifying fundamental limits of\ndetectability by formally defining community structure using probabilistic\ngenerative models. Detecting hierarchical community structure introduces\nadditional challenges alongside those inherited from community detection. Here\nwe present a theoretical study on hierarchical community structure in networks,\nwhich has thus far not received the same rigorous attention. We address the\nfollowing questions: 1)~How should we define a valid hierarchy of communities?\n2)~How should we determine if a hierarchical structure exists in a network? and\n3)~how can we detect hierarchical structure efficiently? We approach these\nquestions by introducing a definition of hierarchy based on the concept of\nstochastic externally equitable partitions and their relation to probabilistic\nmodels, such as the popular stochastic block model. We enumerate the challenges\ninvolved in detecting hierarchies and, by studying the spectral properties of\nhierarchical structure, present an efficient and principled method for\ndetecting them.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 16:18:26 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Schaub", "Michael T.", ""], ["Peel", "Leto", ""]]}, {"id": "2009.07200", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Jean-Jacques Ohana, and Jamal Atif", "title": "Detecting and adapting to crisis pattern with context based Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has reached super human levels in complex\ntasks like game solving (Go and autonomous driving). However, it remains an\nopen question whether DRL can reach human level in applications to financial\nproblems and in particular in detecting pattern crisis and consequently\ndis-investing. In this paper, we present an innovative DRL framework consisting\nin two sub-networks fed respectively with portfolio strategies past\nperformances and standard deviations as well as additional contextual features.\nThe second sub network plays an important role as it captures dependencies with\ncommon financial indicators features like risk aversion, economic surprise\nindex and correlations between assets that allows taking into account context\nbased information. We compare different network architectures either using\nlayers of convolutions to reduce network's complexity or LSTM block to capture\ntime dependency and whether previous allocations is important in the modeling.\nWe also use adversarial training to make the final model more robust. Results\non test set show this approach substantially over-performs traditional\nportfolio optimization methods like Markowitz and is able to detect and\nanticipate crisis like the current Covid one.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 12:11:08 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:49:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ohana", "Jean-Jacques", ""], ["Atif", "Jamal", ""]]}, {"id": "2009.07203", "submitter": "Zhengyang Wang", "authors": "Zhengyang Wang, Bunyamin Sisman, Hao Wei, Xin Luna Dong, Shuiwang Ji", "title": "CorDEL: A Contrastive Deep Learning Approach for Entity Linkage", "comments": "Accepted by the 20th IEEE International Conference on Data Mining\n  (ICDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linkage (EL) is a critical problem in data cleaning and integration.\nIn the past several decades, EL has typically been done by rule-based systems\nor traditional machine learning models with hand-curated features, both of\nwhich heavily depend on manual human inputs. With the ever-increasing growth of\nnew data, deep learning (DL) based approaches have been proposed to alleviate\nthe high cost of EL associated with the traditional models. Existing\nexploration of DL models for EL strictly follows the well-known twin-network\narchitecture. However, we argue that the twin-network architecture is\nsub-optimal to EL, leading to inherent drawbacks of existing models. In order\nto address the drawbacks, we propose a novel and generic contrastive DL\nframework for EL. The proposed framework is able to capture both syntactic and\nsemantic matching signals and pays attention to subtle but critical\ndifferences. Based on the framework, we develop a contrastive DL approach for\nEL, called CorDEL, with three powerful variants. We evaluate CorDEL with\nextensive experiments conducted on both public benchmark datasets and a\nreal-world dataset. CorDEL outperforms previous state-of-the-art models by 5.2%\non public benchmark datasets. Moreover, CorDEL yields a 2.4% improvement over\nthe current best DL model on the real-world dataset, while reducing the number\nof training parameters by 97.6%.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 16:33:05 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 21:30:29 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 00:30:33 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wang", "Zhengyang", ""], ["Sisman", "Bunyamin", ""], ["Wei", "Hao", ""], ["Dong", "Xin Luna", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2009.07213", "submitter": "Sudhakaran Jain", "authors": "Sudhakaran Jain and Hamidreza Kasaei", "title": "3D_DEN: Open-ended 3D Object Recognition using Dynamically Expandable\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service robots, in general, have to work independently and adapt to the\ndynamic changes happening in the environment in real-time. One important aspect\nin such scenarios is to continually learn to recognize newer object categories\nwhen they become available. This combines two main research problems namely\ncontinual learning and 3D object recognition. Most of the existing research\napproaches include the use of deep Convolutional Neural Networks (CNNs)\nfocusing on image datasets. A modified approach might be needed for continually\nlearning 3D object categories. A major concern in using CNNs is the problem of\ncatastrophic forgetting when a model tries to learn a new task. Despite various\nproposed solutions to mitigate this problem, there still exist some downsides\nof such solutions, e.g., computational complexity, especially when learning\nsubstantial number of tasks. These downsides can pose major problems in robotic\nscenarios where real-time response plays an essential role. Towards addressing\nthis challenge, we propose a new deep transfer learning approach based on a\ndynamic architectural method to make robots capable of open-ended learning\nabout new 3D object categories. Furthermore, we make sure that the mentioned\ndownsides are minimized to a great extent. Experimental results showed that the\nproposed model outperformed state-of-the-art approaches with regards to\naccuracy and also substantially minimizes computational overhead.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 16:44:18 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 19:41:06 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Jain", "Sudhakaran", ""], ["Kasaei", "Hamidreza", ""]]}, {"id": "2009.07238", "submitter": "Victor Makarenkov", "authors": "Victor Makarenkov and Lior Rokach", "title": "Lessons Learned from Applying off-the-shelf BERT: There is no Silver\n  Bullet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in the NLP field is training large classification\nmodels, a task that is both difficult and tedious. It is even harder when GPU\nhardware is unavailable. The increased availability of pre-trained and\noff-the-shelf word embeddings, models, and modules aim at easing the process of\ntraining large models and achieving a competitive performance. We explore the\nuse of off-the-shelf BERT models and share the results of our experiments and\ncompare their results to those of LSTM networks and more simple baselines. We\nshow that the complexity and computational cost of BERT is not a guarantee for\nenhanced predictive performance in the classification tasks at hand.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:24:52 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 12:58:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Makarenkov", "Victor", ""], ["Rokach", "Lior", ""]]}, {"id": "2009.07241", "submitter": "Laurent Callot", "authors": "Luyang Kong, Lifan Chen, Ming Chen, Parminder Bhatia, Laurent Callot", "title": "Improve black-box sequential anomaly detector relevancy with limited\n  user feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detectors are often designed to catch statistical anomalies.\nEnd-users typically do not have interest in all of the detected outliers, but\nonly those relevant to their application. Given an existing black-box\nsequential anomaly detector, this paper proposes a method to improve its user\nrelevancy using a small number of human feedback. As our first contribution,\nthe method is agnostic to the detector: it only assumes access to its anomaly\nscores, without requirement on any additional information inside it. Inspired\nby a fact that anomalies are of different types, our approach identifies these\ntypes and utilizes user feedback to assign relevancy to types. This relevancy\nscore, as our second contribution, is used to adjust the subsequent anomaly\nselection process. Empirical results on synthetic and real-world datasets show\nthat our approach yields significant improvements on precision and recall over\na range of anomaly detectors.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:26:38 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Kong", "Luyang", ""], ["Chen", "Lifan", ""], ["Chen", "Ming", ""], ["Bhatia", "Parminder", ""], ["Callot", "Laurent", ""]]}, {"id": "2009.07243", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Tianxing He, Kyunghyun Cho, James Glass", "title": "A Systematic Characterization of Sampling Algorithms for Open-ended\n  Language Generation", "comments": "To appear at AACL 2020; 9 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the widely adopted ancestral sampling algorithms for\nauto-regressive language models, which is not widely studied in the literature.\nWe use the quality-diversity (Q-D) trade-off to investigate three popular\nsampling algorithms (top-k, nucleus and tempered sampling). We focus on the\ntask of open-ended language generation. We first show that the existing\nsampling algorithms have similar performance. After carefully inspecting the\ntransformations defined by different sampling algorithms, we identify three key\nproperties that are shared among them: entropy reduction, order preservation,\nand slope preservation. To validate the importance of the identified\nproperties, we design two sets of new sampling algorithms: one set in which\neach algorithm satisfies all three properties, and one set in which each\nalgorithm violates at least one of the properties. We compare their performance\nwith existing sampling algorithms, and find that violating the identified\nproperties could lead to drastic performance degradation, as measured by the\nQ-D trade-off. On the other hand, we find that the set of sampling algorithms\nthat satisfies these properties performs on par with the existing sampling\nalgorithms. Our data and code are available at\nhttps://github.com/moinnadeem/characterizing-sampling-algorithms\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:28:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nadeem", "Moin", ""], ["He", "Tianxing", ""], ["Cho", "Kyunghyun", ""], ["Glass", "James", ""]]}, {"id": "2009.07250", "submitter": "Fatema Zohora", "authors": "Fatema Tuz Zohora, M Ziaur Rahman, Ngoc Hieu Tran, Lei Xin, Baozhen\n  Shan, Ming Li", "title": "PointIso: Point Cloud Based Deep Learning Model for Detecting\n  Arbitrary-Precision Peptide Features in LC-MS Map through Attention Based\n  Segmentation", "comments": "16 pages (main text) with 10 figures, then supplementary material of\n  about 5 pages. preprint of journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising technique of discovering disease biomarkers is to measure the\nrelative protein abundance in multiple biofluid samples through liquid\nchromatography with tandem mass spectrometry (LC-MS/MS) based quantitative\nproteomics. The key step involves peptide feature detection in LC-MS map, along\nwith its charge and intensity. Existing heuristic algorithms suffer from\ninaccurate parameters since different settings of the parameters result in\nsignificantly different outcomes. Therefore, we propose PointIso, to serve the\nnecessity of an automated system for peptide feature detection that is able to\nfind out the proper parameters itself, and is easily adaptable to different\ntypes of datasets. It consists of an attention based scanning step for\nsegmenting the multi-isotopic pattern of peptide features along with charge and\na sequence classification step for grouping those isotopes into potential\npeptide features. PointIso is the first point cloud based, arbitrary-precision\ndeep learning network to address the problem and achieves 98% detection of high\nquality MS/MS identifications in a benchmark dataset, which is higher than\nseveral other widely used algorithms. Besides contributing to the proteomics\nstudy, we believe our novel segmentation technique should serve the general\nimage processing domain as well.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:34:14 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zohora", "Fatema Tuz", ""], ["Rahman", "M Ziaur", ""], ["Tran", "Ngoc Hieu", ""], ["Xin", "Lei", ""], ["Shan", "Baozhen", ""], ["Li", "Ming", ""]]}, {"id": "2009.07253", "submitter": "Alexander Lin", "authors": "Alexander Lin, Jeremy Wohlwend, Howard Chen, and Tao Lei", "title": "Autoregressive Knowledge Distillation through Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of autoregressive models on natural language generation tasks\nhas dramatically improved due to the adoption of deep, self-attentive\narchitectures. However, these gains have come at the cost of hindering\ninference speed, making state-of-the-art models cumbersome to deploy in\nreal-world, time-sensitive settings. We develop a compression technique for\nautoregressive models that is driven by an imitation learning perspective on\nknowledge distillation. The algorithm is designed to address the exposure bias\nproblem. On prototypical language generation tasks such as translation and\nsummarization, our method consistently outperforms other distillation\nalgorithms, such as sequence-level knowledge distillation. Student models\ntrained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those\ntrained from scratch, while increasing inference speed by up to 14 times in\ncomparison to the teacher model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:43:02 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 00:40:45 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Lin", "Alexander", ""], ["Wohlwend", "Jeremy", ""], ["Chen", "Howard", ""], ["Lei", "Tao", ""]]}, {"id": "2009.07327", "submitter": "Przemys{\\l}aw Spurek", "authors": "Szymon Knop, Marcin Mazur, Przemys{\\l}aw Spurek, Jacek Tabor, Igor\n  Podolak", "title": "Generative models with kernel distance in data space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models dealing with modeling a~joint data distribution are\ngenerally either autoencoder or GAN based. Both have their pros and cons,\ngenerating blurry images or being unstable in training or prone to mode\ncollapse phenomenon, respectively. The objective of this paper is to construct\na~model situated between above architectures, one that does not inherit their\nmain weaknesses. The proposed LCW generator (Latent Cramer-Wold generator)\nresembles a classical GAN in transforming Gaussian noise into data space. What\nis of utmost importance, instead of a~discriminator, LCW generator uses kernel\ndistance. No adversarial training is utilized, hence the name generator. It is\ntrained in two phases. First, an autoencoder based architecture, using kernel\nmeasures, is built to model a manifold of data. We propose a Latent Trick\nmapping a Gaussian to latent in order to get the final model. This results in\nvery competitive FID values.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:11:47 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Knop", "Szymon", ""], ["Mazur", "Marcin", ""], ["Spurek", "Przemys\u0142aw", ""], ["Tabor", "Jacek", ""], ["Podolak", "Igor", ""]]}, {"id": "2009.07330", "submitter": "Alp Dener", "authors": "Alp Dener, Marco Andres Miller, Randy Michael Churchill, Todd Munson,\n  Choong-Seock Chang", "title": "Training neural networks under physical constraints using a stochastic\n  augmented Lagrangian approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG math.OC physics.plasm-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the physics-constrained training of an encoder-decoder neural\nnetwork for approximating the Fokker-Planck-Landau collision operator in the\n5-dimensional kinetic fusion simulation in XGC. To train this network, we\npropose a stochastic augmented Lagrangian approach that utilizes pyTorch's\nnative stochastic gradient descent method to solve the inner unconstrained\nminimization subproblem, paired with a heuristic update for the penalty factor\nand Lagrange multipliers in the outer augmented Lagrangian loop. Our training\nresults for a single ion species case, with self-collisions and collision\nagainst electrons, show that the proposed stochastic augmented Lagrangian\napproach can achieve higher model prediction accuracy than training with a\nfixed penalty method for our application problem, with the accuracy high enough\nfor practical applications in kinetic simulations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:20:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Dener", "Alp", ""], ["Miller", "Marco Andres", ""], ["Churchill", "Randy Michael", ""], ["Munson", "Todd", ""], ["Chang", "Choong-Seock", ""]]}, {"id": "2009.07346", "submitter": "Georgios Theocharous", "authors": "Georgios Theocharous, Yash Chandak, Philip S. Thomas, Frits de Nijs", "title": "Reinforcement Learning for Strategic Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic recommendations (SR) refer to the problem where an intelligent\nagent observes the sequential behaviors and activities of users and decides\nwhen and how to interact with them to optimize some long-term objectives, both\nfor the user and the business. These systems are in their infancy in the\nindustry and in need of practical solutions to some fundamental research\nchallenges. At Adobe research, we have been implementing such systems for\nvarious use-cases, including points of interest recommendations, tutorial\nrecommendations, next step guidance in multi-media editing software, and ad\nrecommendation for optimizing lifetime value. There are many research\nchallenges when building these systems, such as modeling the sequential\nbehavior of users, deciding when to intervene and offer recommendations without\nannoying the user, evaluating policies offline with high confidence, safe\ndeployment, non-stationarity, building systems from passive data that do not\ncontain past recommendations, resource constraint optimization in multi-user\nsystems, scaling to large and dynamic actions spaces, and handling and\nincorporating human cognitive biases. In this paper we cover various use-cases\nand research challenges we solved to make these systems practical.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 20:45:48 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Theocharous", "Georgios", ""], ["Chandak", "Yash", ""], ["Thomas", "Philip S.", ""], ["de Nijs", "Frits", ""]]}, {"id": "2009.07349", "submitter": "Robert Susik", "authors": "Robert Susik", "title": "Recurrent autoencoder with sequence-aware encoding", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-77964-1_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) received a vast amount of attention last\ndecade. Recently, the architectures of Recurrent AutoEncoders (RAE) found many\napplications in practice. RAE can extract the semantically valuable\ninformation, called context that represents a latent space useful for further\nprocessing. Nevertheless, recurrent autoencoders are hard to train, and the\ntraining process takes much time. In this paper, we propose an autoencoder\narchitecture with sequence-aware encoding, which employs 1D convolutional layer\nto improve its performance in terms of model training time. We prove that the\nrecurrent autoencoder with sequence-aware encoding outperforms a standard RAE\nin terms of training speed in most cases. The preliminary results show that the\nproposed solution dominates over the standard RAE, and the training process is\norder of magnitude faster.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 20:51:20 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 09:56:25 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 14:22:43 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Susik", "Robert", ""]]}, {"id": "2009.07351", "submitter": "Meng Jiang", "authors": "Meng Jiang and Taeho Jung and Ryan Karl and Tong Zhao", "title": "Federated Dynamic GNN with Secure Aggregation", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given video data from multiple personal devices or street cameras, can we\nexploit the structural and dynamic information to learn dynamic representation\nof objects for applications such as distributed surveillance, without storing\ndata at a central server that leads to a violation of user privacy? In this\nwork, we introduce Federated Dynamic Graph Neural Network (Feddy), a\ndistributed and secured framework to learn the object representations from\nmulti-user graph sequences: i) It aggregates structural information from nearby\nobjects in the current graph as well as dynamic information from those in the\nprevious graph. It uses a self-supervised loss of predicting the trajectories\nof objects. ii) It is trained in a federated learning manner. The centrally\nlocated server sends the model to user devices. Local models on the respective\nuser devices learn and periodically send their learning to the central server\nwithout ever exposing the user's data to server. iii) Studies showed that the\naggregated parameters could be inspected though decrypted when broadcast to\nclients for model synchronizing, after the server performed a weighted average.\nWe design an appropriate aggregation mechanism of secure aggregation primitives\nthat can protect the security and privacy in federated learning with\nscalability. Experiments on four video camera datasets (in four different\nscenes) as well as simulation demonstrate that Feddy achieves great\neffectiveness and security.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:04:45 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Jiang", "Meng", ""], ["Jung", "Taeho", ""], ["Karl", "Ryan", ""], ["Zhao", "Tong", ""]]}, {"id": "2009.07360", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie, Bert Huang", "title": "Constrained Labeling for Weakly Supervised Learning", "comments": "Accepted at UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Curation of large fully supervised datasets has become one of the major\nroadblocks for machine learning. Weak supervision provides an alternative to\nsupervised learning by training with cheap, noisy, and possibly correlated\nlabeling functions from varying sources. The key challenge in weakly supervised\nlearning is combining the different weak supervision signals while navigating\nmisleading correlations in their errors. In this paper, we propose a simple\ndata-free approach for combining weak supervision signals by defining a\nconstrained space for the possible labels of the weak signals and training with\na random labeling within this constrained space. Our method is efficient and\nstable, converging after a few iterations of gradient descent. We prove\ntheoretical conditions under which the worst-case error of the randomized label\ndecreases with the rank of the linear constraints. We show experimentally that\nour method outperforms other weak supervision methods on various text- and\nimage-classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:30:53 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 02:32:49 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 02:48:45 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 17:35:46 GMT"}, {"version": "v5", "created": "Sat, 29 May 2021 19:51:20 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Arachie", "Chidubem", ""], ["Huang", "Bert", ""]]}, {"id": "2009.07368", "submitter": "William Whitney", "authors": "William F. Whitney, Min Jae Song, David Brandfonbrener, Jaan Altosaar,\n  Kyunghyun Cho", "title": "Evaluating representations by the complexity of learning low-loss\n  predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of evaluating representations of data for use in\nsolving a downstream task. We propose to measure the quality of a\nrepresentation by the complexity of learning a predictor on top of the\nrepresentation that achieves low loss on a task of interest, and introduce two\nmethods, surplus description length (SDL) and $\\varepsilon$ sample complexity\n($\\varepsilon$SC). In contrast to prior methods, which measure the amount of\ninformation about the optimal predictor that is present in a specific amount of\ndata, our methods measure the amount of information needed from the data to\nrecover an approximation of the optimal predictor up to a specified tolerance.\nWe present a framework to compare these methods based on plotting the\nvalidation loss versus evaluation dataset size (the \"loss-data\" curve).\nExisting measures, such as mutual information and minimum description length\nprobes, correspond to slices and integrals along the data axis of the loss-data\ncurve, while ours correspond to slices and integrals along the loss axis. We\nprovide experiments on real data to compare the behavior of each of these\nmethods over datasets of varying size along with a high performance open source\nlibrary for representation evaluation at\nhttps://github.com/willwhitney/reprieve.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:06:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:50:13 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Whitney", "William F.", ""], ["Song", "Min Jae", ""], ["Brandfonbrener", "David", ""], ["Altosaar", "Jaan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2009.07378", "submitter": "Tomas Hodan", "authors": "Tomas Hodan, Martin Sundermeyer, Bertram Drost, Yann Labbe, Eric\n  Brachmann, Frank Michel, Carsten Rother, Jiri Matas", "title": "BOP Challenge 2020 on 6D Object Localization", "comments": "In ECCV 2020 Workshops Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the evaluation methodology, datasets, and results of the\nBOP Challenge 2020, the third in a series of public competitions organized with\nthe goal to capture the status quo in the field of 6D object pose estimation\nfrom an RGB-D image. In 2020, to reduce the domain gap between synthetic\ntraining and real test RGB images, the participants were provided 350K\nphotorealistic training images generated by BlenderProc4BOP, a new open-source\nand light-weight physically-based renderer (PBR) and procedural data generator.\nMethods based on deep neural networks have finally caught up with methods based\non point pair features, which were dominating previous editions of the\nchallenge. Although the top-performing methods rely on RGB-D image channels,\nstrong results were achieved when only RGB channels were used at both training\nand test time - out of the 26 evaluated methods, the third method was trained\non RGB channels of PBR and real images, while the fifth on RGB channels of PBR\nimages only. Strong data augmentation was identified as a key component of the\ntop-performing CosyPose method, and the photorealism of PBR images was\ndemonstrated effective despite the augmentation. The online evaluation system\nstays open and is available on the project website: bop.felk.cvut.cz.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:35:14 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 12:09:44 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Hodan", "Tomas", ""], ["Sundermeyer", "Martin", ""], ["Drost", "Bertram", ""], ["Labbe", "Yann", ""], ["Brachmann", "Eric", ""], ["Michel", "Frank", ""], ["Rother", "Carsten", ""], ["Matas", "Jiri", ""]]}, {"id": "2009.07392", "submitter": "Seyedehzahra Khoshmanesh", "authors": "Seyedehzahra Khoshmanesh and Robyn Lutz", "title": "Does Link Prediction Help Detect Feature Interactions in Software\n  Product Lines (SPLs)?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ongoing challenge for the requirements engineering of software product\nlines is to predict whether a new combination of features (units of\nfunctionality) will create an unwanted or even hazardous feature interaction.\nWe thus seek to improve and automate the prediction of unwanted feature\ninteractions early in development. In this paper, we show how the detection of\nunwanted feature interactions in a software product line can be effectively\nrepresented as a link prediction problem. Link prediction uses machine learning\nalgorithms and similarity scores among a graph's nodes to identify likely new\nedges. We here model the software product line features as nodes and the\nunwanted interactions among the features as edges. We investigate six\nlink-based similarity metrics, some using local and some using global knowledge\nof the graph, for use in this context. We evaluate our approach on a software\nproduct line benchmark in the literature, building six machine-learning models\nfrom the graph-based similarity data. Results show that the best ML algorithms\nachieved an accuracy of 0.75 to 1 for classifying feature interactions as\nunwanted or wanted in this small study and that global similarity metrics\nperformed better than local similarity metrics. The work shows how\nlink-prediction models can help find missing edges, which represent unwanted\nfeature interactions that are undocumented or unrecognized, earlier in\ndevelopment.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 23:39:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Khoshmanesh", "Seyedehzahra", ""], ["Lutz", "Robyn", ""]]}, {"id": "2009.07396", "submitter": "Victor Zhong", "authors": "Victor Zhong, Mike Lewis, Sida I. Wang, Luke Zettlemoyer", "title": "Grounded Adaptation for Zero-shot Executable Semantic Parsing", "comments": "EMNLP 2020 long paper. 14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing\n(GAZP) to adapt an existing semantic parser to new environments (e.g. new\ndatabase schemas). GAZP combines a forward semantic parser with a backward\nutterance generator to synthesize data (e.g. utterances and SQL queries) in the\nnew environment, then selects cycle-consistent examples to adapt the parser.\nUnlike data-augmentation, which typically synthesizes unverified examples in\nthe training environment, GAZP synthesizes examples in the new environment\nwhose input-output consistency are verified. On the Spider, Sparc, and CoSQL\nzero-shot semantic parsing tasks, GAZP improves logical form and execution\naccuracy of the baseline parser. Our analyses show that GAZP outperforms\ndata-augmentation in the training environment, performance increases with the\namount of GAZP-synthesized data, and cycle-consistency is central to successful\nadaptation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:16:59 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 00:37:15 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 20:44:05 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhong", "Victor", ""], ["Lewis", "Mike", ""], ["Wang", "Sida I.", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2009.07402", "submitter": "Xiyao Ma", "authors": "Xiyao Ma, Qile Zhu, Yanlin Zhou, Xiaolin Li, Dapeng Wu", "title": "Asking Complex Questions with Multi-hop Answer-focused Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions from natural language text has attracted increasing\nattention recently, and several schemes have been proposed with promising\nresults by asking the right question words and copy relevant words from the\ninput to the question. However, most state-of-the-art methods focus on asking\nsimple questions involving single-hop relations. In this paper, we propose a\nnew task called multihop question generation that asks complex and semantically\nrelevant questions by additionally discovering and modeling the multiple\nentities and their semantic relations given a collection of documents and the\ncorresponding answer 1. To solve the problem, we propose multi-hop\nanswer-focused reasoning on the grounded answer-centric entity graph to include\ndifferent granularity levels of semantic information including the word-level\nand document-level semantics of the entities and their semantic relations.\nThrough extensive experiments on the HOTPOTQA dataset, we demonstrate the\nsuperiority and effectiveness of our proposed model that serves as a baseline\nto motivate future work.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:30:49 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ma", "Xiyao", ""], ["Zhu", "Qile", ""], ["Zhou", "Yanlin", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2009.07415", "submitter": "Daochen Zha", "authors": "Daochen Zha, Kwei-Herng Lai, Mingyang Wan, Xia Hu", "title": "Meta-AAD: Active Anomaly Detection with Deep Reinforcement Learning", "comments": "Accepted by ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High false-positive rate is a long-standing challenge for anomaly detection\nalgorithms, especially in high-stake applications. To identify the true\nanomalies, in practice, analysts or domain experts will be employed to\ninvestigate the top instances one by one in a ranked list of anomalies\nidentified by an anomaly detection system. This verification procedure\ngenerates informative labels that can be leveraged to re-rank the anomalies so\nas to help the analyst to discover more true anomalies given a time budget.\nSome re-ranking strategies have been proposed to approximate the above\nsequential decision process. Specifically, existing strategies have been\nfocused on making the top instances more likely to be anomalous based on the\nfeedback. Then they greedily select the top-1 instance for query. However,\nthese greedy strategies could be sub-optimal since some low-ranked instances\ncould be more helpful in the long-term. In this work, we propose Active Anomaly\nDetection with Meta-Policy (Meta-AAD), a novel framework that learns a\nmeta-policy for query selection. Specifically, Meta-AAD leverages deep\nreinforcement learning to train the meta-policy to select the most proper\ninstance to explicitly optimize the number of discovered anomalies throughout\nthe querying process. Meta-AAD is easy to deploy since a trained meta-policy\ncan be directly applied to any new datasets without further tuning. Extensive\nexperiments on 24 benchmark datasets demonstrate that Meta-AAD significantly\noutperforms the state-of-the-art re-ranking strategies and the unsupervised\nbaseline. The empirical analysis shows that the trained meta-policy is\ntransferable and inherently achieves a balance between long-term and short-term\nrewards.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:47:42 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zha", "Daochen", ""], ["Lai", "Kwei-Herng", ""], ["Wan", "Mingyang", ""], ["Hu", "Xia", ""]]}, {"id": "2009.07417", "submitter": "Yicheng Xu", "authors": "Yicheng Xu, Vincent Chau, Chenchen Wu, Yong Zhang, Vassilis\n  Zissimopoulos, Yifei Zou", "title": "Too Much Information Kills Information: A Clustering Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most fundamental tools in the artificial\nintelligence area, particularly in the pattern recognition and learning theory.\nIn this paper, we propose a simple, but novel approach for variance-based\nk-clustering tasks, included in which is the widely known k-means clustering.\nThe proposed approach picks a sampling subset from the given dataset and makes\ndecisions based on the data information in the subset only. With certain\nassumptions, the resulting clustering is provably good to estimate the optimum\nof the variance-based objective with high probability. Extensive experiments on\nsynthetic datasets and real-world datasets show that to obtain competitive\nresults compared with k-means method (Llyod 1982) and k-means++ method (Arthur\nand Vassilvitskii 2007), we only need 7% information of the dataset. If we have\nup to 15% information of the dataset, then our algorithm outperforms both the\nk-means method and k-means++ method in at least 80% of the clustering tasks, in\nterms of the quality of clustering. Also, an extended algorithm based on the\nsame idea guarantees a balanced k-clustering result.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:54:26 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Xu", "Yicheng", ""], ["Chau", "Vincent", ""], ["Wu", "Chenchen", ""], ["Zhang", "Yong", ""], ["Zissimopoulos", "Vassilis", ""], ["Zou", "Yifei", ""]]}, {"id": "2009.07419", "submitter": "Achintya Gopal", "authors": "Achintya Gopal", "title": "Quasi-Autoregressive Residual (QuAR) Flows", "comments": "Appeared in ICML Workshop on Invertible Neural Networks, Normalizing\n  Flows, and Explicit Likelihood Models 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows are a powerful technique for learning and modeling\nprobability distributions given samples from those distributions. The current\nstate of the art results are built upon residual flows as these can model a\nlarger hypothesis space than coupling layers. However, residual flows are\nextremely computationally expensive both to train and to use, which limits\ntheir applicability in practice. In this paper, we introduce a simplification\nto residual flows using a Quasi-Autoregressive (QuAR) approach. Compared to the\nstandard residual flow approach, this simplification retains many of the\nbenefits of residual flows while dramatically reducing the compute time and\nmemory requirements, thus making flow-based modeling approaches far more\ntractable and broadening their potential applicability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:56:24 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Gopal", "Achintya", ""]]}, {"id": "2009.07430", "submitter": "Alex G. C.  de S\\'a", "authors": "M\\'arcio P. Basgalupp, Rodrigo C. Barros, Alex G. C. de S\\'a, Gisele\n  L. Pappa, Rafael G. Mantovani, Andr\\'e C. P. L. F. de Carvalho, Alex A.\n  Freitas", "title": "An Extensive Experimental Evaluation of Automated Machine Learning\n  Methods for Recommending Classification Algorithms (Extended Version)", "comments": "Accepted at Evolutionary Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an experimental comparison among four Automated Machine\nLearning (AutoML) methods for recommending the best classification algorithm\nfor a given input dataset. Three of these methods are based on Evolutionary\nAlgorithms (EAs), and the other is Auto-WEKA, a well-known AutoML method based\non the Combined Algorithm Selection and Hyper-parameter optimisation (CASH)\napproach. The EA-based methods build classification algorithms from a single\nmachine learning paradigm: either decision-tree induction, rule induction, or\nBayesian network classification. Auto-WEKA combines algorithm selection and\nhyper-parameter optimisation to recommend classification algorithms from\nmultiple paradigms. We performed controlled experiments where these four AutoML\nmethods were given the same runtime limit for different values of this limit.\nIn general, the difference in predictive accuracy of the three best AutoML\nmethods was not statistically significant. However, the EA evolving\ndecision-tree induction algorithms has the advantage of producing algorithms\nthat generate interpretable classification models and that are more scalable to\nlarge datasets, by comparison with many algorithms from other learning\nparadigms that can be recommended by Auto-WEKA. We also observed that Auto-WEKA\nhas shown meta-overfitting, a form of overfitting at the meta-learning level,\nrather than at the base-learning level.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 02:36:43 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Basgalupp", "M\u00e1rcio P.", ""], ["Barros", "Rodrigo C.", ""], ["de S\u00e1", "Alex G. C.", ""], ["Pappa", "Gisele L.", ""], ["Mantovani", "Rafael G.", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "2009.07433", "submitter": "Pawan Kumar Singh Dr.", "authors": "Pawan Kumar Singh, Iman Chatterjee, Ram Sarkar, Mita Nasipuri", "title": "Handwritten Script Identification from Text Lines", "comments": "12 pages, 4 figures, conference", "journal-ref": "Proc. of 7th International Conference on Advances in\n  Communication, Network and Computing (CNC), 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a multilingual country like India where 12 different official scripts are\nin use, automatic identification of handwritten script facilitates many\nimportant applications such as automatic transcription of multilingual\ndocuments, searching for documents on the web/digital archives containing a\nparticular script and for the selection of script specific Optical Character\nRecognition (OCR) system in a multilingual environment. In this paper, we\npropose a robust method towards identifying scripts from the handwritten\ndocuments at text line-level. The recognition is based upon features extracted\nusing Chain Code Histogram (CCH) and Discrete Fourier Transform (DFT). The\nproposed method is experimented on 800 handwritten text lines written in seven\nIndic scripts namely, Gujarati, Kannada, Malayalam, Oriya, Tamil, Telugu, Urdu\nalong with Roman script and yielded an average identification rate of 95.14%\nusing Support Vector Machine (SVM) classifier.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 02:43:24 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Singh", "Pawan Kumar", ""], ["Chatterjee", "Iman", ""], ["Sarkar", "Ram", ""], ["Nasipuri", "Mita", ""]]}, {"id": "2009.07435", "submitter": "Pawan Kumar Singh Dr.", "authors": "Pawan Kumar Singh, Supratim Das, Ram Sarkar, Mita Nasipuri", "title": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition", "comments": "13 pages, 5 figures, conference", "journal-ref": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC), pp. 247-259, 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 02:50:03 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Singh", "Pawan Kumar", ""], ["Das", "Supratim", ""], ["Sarkar", "Ram", ""], ["Nasipuri", "Mita", ""]]}, {"id": "2009.07439", "submitter": "Dachao Lin", "authors": "Dachao Lin, Ruoyu Sun, Zhihua Zhang", "title": "On the Landscape of One-hidden-layer Sparse Networks and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse neural networks have received increasing interests due to their small\nsize compared to dense networks. Nevertheless, most existing works on neural\nnetwork theory have focused on dense neural networks, and our understanding of\nsparse networks is very limited. In this paper, we study the loss landscape of\none-hidden-layer sparse networks. We first consider sparse networks with linear\nactivations. We show that sparse linear networks can have spurious strict\nminima, which is in sharp contrast to dense linear networks which do not even\nhave spurious minima. Second, we show that spurious valleys can exist for wide\nsparse non-linear networks. This is different from wide dense networks which do\nnot have spurious valleys under mild assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:02:13 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 12:29:35 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 03:49:33 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lin", "Dachao", ""], ["Sun", "Ruoyu", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2009.07451", "submitter": "Lei Zhou", "authors": "Yang Liu, Lei Zhou, Xiao Bai, Lin Gu, Tatsuya Harada, Jun Zhou", "title": "Information Bottleneck Constrained Latent Bidirectional Embedding for\n  Zero-Shot Learning", "comments": "The new version is not complete", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) aims to recognize novel classes by transferring\nsemantic knowledge from seen classes to unseen classes. Though many ZSL methods\nrely on a direct mapping between the visual and the semantic space, the\ncalibration deviation and hubness problem limit the generalization capability\nto unseen classes. Recently emerged generative ZSL methods generate unseen\nimage features to transform ZSL into a supervised classification problem.\nHowever, most generative models still suffer from the seen-unseen bias problem\nas only seen data is used for training. To address these issues, we propose a\nnovel bidirectional embedding based generative model with a tight\nvisual-semantic coupling constraint. We learn a unified latent space that\ncalibrates the embedded parametric distributions of both visual and semantic\nspaces. Since the embedding from high-dimensional visual features comprise much\nnon-semantic information, the alignment of visual and semantic in latent space\nwould inevitably been deviated. Therefore, we introduce information bottleneck\n(IB) constraint to ZSL for the first time to preserve essential attribute\ninformation during the mapping. Specifically, we utilize the uncertainty\nestimation and the wake-sleep procedure to alleviate the feature noises and\nimprove model abstraction capability. In addition, our method can be easily\nextended to transductive ZSL setting by generating labels for unseen images. We\nthen introduce a robust loss to solve this label noise problem. Extensive\nexperimental results show that our method outperforms the state-of-the-art\nmethods in different ZSL settings on most benchmark datasets. The code will be\navailable at https://github.com/osierboy/IBZSL.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:54:12 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 07:24:44 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 07:50:10 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Liu", "Yang", ""], ["Zhou", "Lei", ""], ["Bai", "Xiao", ""], ["Gu", "Lin", ""], ["Harada", "Tatsuya", ""], ["Zhou", "Jun", ""]]}, {"id": "2009.07453", "submitter": "Se Jung Kwon", "authors": "Insoo Chung, Byeongwook Kim, Yoonjung Choi, Se Jung Kwon, Yongkweon\n  Jeon, Baeseong Park, Sangha Kim and Dongsoo Lee", "title": "Extremely Low Bit Transformer Quantization for On-Device Neural Machine\n  Translation", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of widely used Transformer architecture is challenging because\nof heavy computation load and memory overhead during inference, especially when\nthe target device is limited in computational resources such as mobile or edge\ndevices. Quantization is an effective technique to address such challenges. Our\nanalysis shows that for a given number of quantization bits, each block of\nTransformer contributes to translation quality and inference computations in\ndifferent manners. Moreover, even inside an embedding block, each word presents\nvastly different contributions. Correspondingly, we propose a mixed precision\nquantization strategy to represent Transformer weights by an extremely low\nnumber of bits (e.g., under 3 bits). For example, for each word in an embedding\nblock, we assign different quantization bits based on statistical property. Our\nquantized Transformer model achieves 11.8$\\times$ smaller model size than the\nbaseline model, with less than -0.5 BLEU. We achieve 8.3$\\times$ reduction in\nrun-time memory footprints and 3.5$\\times$ speed up (Galaxy N10+) such that our\nproposed compression strategy enables efficient implementation for on-device\nNMT.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:58:01 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 05:23:31 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Chung", "Insoo", ""], ["Kim", "Byeongwook", ""], ["Choi", "Yoonjung", ""], ["Kwon", "Se Jung", ""], ["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Kim", "Sangha", ""], ["Lee", "Dongsoo", ""]]}, {"id": "2009.07455", "submitter": "Jianzong Wang", "authors": "Anxun He, Jianzong Wang, Zhangcheng Huang and Jing Xiao", "title": "FedSmart: An Auto Updating Federated Learning Optimization Mechanism", "comments": "has been presented in APWeb-WAIM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has made an important contribution to data\nprivacy-preserving. Many previous works are based on the assumption that the\ndata are independently identically distributed (IID). As a result, the model\nperformance on non-identically independently distributed (non-IID) data is\nbeyond expectation, which is the concrete situation. Some existing methods of\nensuring the model robustness on non-IID data, like the data-sharing strategy\nor pretraining, may lead to privacy leaking. In addition, there exist some\nparticipants who try to poison the model with low-quality data. In this paper,\na performance-based parameter return method for optimization is introduced, we\nterm it FederatedSmart (FedSmart). It optimizes different model for each client\nthrough sharing global gradients, and it extracts the data from each client as\na local validation set, and the accuracy that model achieves in round t\ndetermines the weights of the next round. The experiment results show that\nFedSmart enables the participants to allocate a greater weight to the ones with\nsimilar data distribution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:59:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["He", "Anxun", ""], ["Wang", "Jianzong", ""], ["Huang", "Zhangcheng", ""], ["Xiao", "Jing", ""]]}, {"id": "2009.07460", "submitter": "Sung-En Chang", "authors": "Sung-En Chang, Yanyu Li, Mengshu Sun, Weiwen Jiang, Runbin Shi, Xue\n  Lin, Yanzhi Wang", "title": "MSP: An FPGA-Specific Mixed-Scheme, Multi-Precision Deep Neural Network\n  Quantization Framework", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the tremendous success of deep learning, there exists imminent need to\ndeploy deep learning models onto edge devices. To tackle the limited computing\nand storage resources in edge devices, model compression techniques have been\nwidely used to trim deep neural network (DNN) models for on-device inference\nexecution. This paper targets the commonly used FPGA (field programmable gate\narray) devices as the hardware platforms for DNN edge computing. We focus on\nthe DNN quantization as the main model compression technique, since DNN\nquantization has been of great importance for the implementations of DNN models\non the hardware platforms. The novelty of this work comes in twofold: (i) We\npropose a mixed-scheme DNN quantization method that incorporates both the\nlinear and non-linear number systems for quantization, with the aim to boost\nthe utilization of the heterogeneous computing resources, i.e., LUTs (look up\ntables) and DSPs (digital signal processors) on an FPGA. Note that all the\nexisting (single-scheme) quantization methods can only utilize one type of\nresources (either LUTs or DSPs for the MAC (multiply-accumulate) operations in\ndeep learning computations. (ii) We use a quantization method that supports\nmultiple precisions along the intra-layer dimension, while the existing\nquantization methods apply multi-precision quantization along the inter-layer\ndimension. The intra-layer multi-precision method can uniform the hardware\nconfigurations for different layers to reduce computation overhead and at the\nsame time preserve the model accuracy as the inter-layer approach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 04:24:18 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 01:58:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chang", "Sung-En", ""], ["Li", "Yanyu", ""], ["Sun", "Mengshu", ""], ["Jiang", "Weiwen", ""], ["Shi", "Runbin", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2009.07476", "submitter": "Ryo Yonetani", "authors": "Ryo Yonetani and Tatsunori Taniai and Mohammadamin Barekatain and Mai\n  Nishimura and Asako Kanezaki", "title": "Path Planning using Neural A* Search", "comments": "To appear in the International Conference on Machine Learning (ICML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural A*, a novel data-driven search method for path planning\nproblems. Despite the recent increasing attention to data-driven path planning,\nmachine learning approaches to search-based planning are still challenging due\nto the discrete nature of search algorithms. In this work, we reformulate a\ncanonical A* search algorithm to be differentiable and couple it with a\nconvolutional encoder to form an end-to-end trainable neural network planner.\nNeural A* solves a path planning problem by encoding a problem instance to a\nguidance map and then performing the differentiable A* search with the guidance\nmap. By learning to match the search results with ground-truth paths provided\nby experts, Neural A* can produce a path consistent with the ground truth\naccurately and efficiently. Our extensive experiments confirmed that Neural A*\noutperformed state-of-the-art data-driven planners in terms of the search\noptimality and efficiency trade-off. Furthermore, Neural A* successfully\npredicted realistic human trajectories by directly performing search-based\nplanning on natural image inputs. Project page:\nhttps://omron-sinicx.github.io/neural-astar/\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:22:44 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 03:38:06 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 13:27:47 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yonetani", "Ryo", ""], ["Taniai", "Tatsunori", ""], ["Barekatain", "Mohammadamin", ""], ["Nishimura", "Mai", ""], ["Kanezaki", "Asako", ""]]}, {"id": "2009.07485", "submitter": "Hossein Khosravi", "authors": "Hossein Gholamalinezhad and Hossein Khosravi", "title": "Pooling Methods in Deep Neural Networks, a Review", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Deep Neural Networks are among the main tools used in various\nsciences. Convolutional Neural Network is a special type of DNN consisting of\nseveral convolution layers, each followed by an activation function and a\npooling layer. The pooling layer is an important layer that executes the\ndown-sampling on the feature maps coming from the previous layer and produces\nnew feature maps with a condensed resolution. This layer drastically reduces\nthe spatial dimension of input. It serves two main purposes. The first is to\nreduce the number of parameters or weights, thus lessening the computational\ncost. The second is to control the overfitting of the network. An ideal pooling\nmethod is expected to extract only useful information and discard irrelevant\ndetails. There are a lot of methods for the implementation of pooling operation\nin Deep Neural Networks. In this paper, we reviewed some of the famous and\nuseful pooling methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:11:40 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Gholamalinezhad", "Hossein", ""], ["Khosravi", "Hossein", ""]]}, {"id": "2009.07494", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Yunsong Meng, Xia Hu, Tie Wang, Bo Long", "title": "Are Interpretations Fairly Evaluated? A Definition Driven Pipeline for\n  Post-Hoc Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an increasing number of interpretation methods\nbeing developed for improving transparency of NLP models. Meanwhile,\nresearchers also try to answer the question that whether the obtained\ninterpretation is faithful in explaining mechanisms behind model prediction?\nSpecifically, (Jain and Wallace, 2019) proposes that \"attention is not\nexplanation\" by comparing attention interpretation with gradient alternatives.\nHowever, it raises a new question that can we safely pick one interpretation\nmethod as the ground-truth? If not, on what basis can we compare different\ninterpretation methods? In this work, we propose that it is crucial to have a\nconcrete definition of interpretation before we could evaluate faithfulness of\nan interpretation. The definition will affect both the algorithm to obtain\ninterpretation and, more importantly, the metric used in evaluation. Through\nboth theoretical and experimental analysis, we find that although\ninterpretation methods perform differently under a certain evaluation metric,\nsuch a difference may not result from interpretation quality or faithfulness,\nbut rather the inherent bias of the evaluation metric.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:38:03 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Liu", "Ninghao", ""], ["Meng", "Yunsong", ""], ["Hu", "Xia", ""], ["Wang", "Tie", ""], ["Long", "Bo", ""]]}, {"id": "2009.07503", "submitter": "Ranran Haoran Zhang", "authors": "Ranran Haoran Zhang, Qianying Liu, Aysa Xuemo Fan, Heng Ji, Daojian\n  Zeng, Fei Cheng, Daisuke Kawahara and Sadao Kurohashi", "title": "Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation\n  Extraction", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint entity and relation extraction aims to extract relation triplets from\nplain text directly. Prior work leverages Sequence-to-Sequence (Seq2Seq) models\nfor triplet sequence generation. However, Seq2Seq enforces an unnecessary order\non the unordered triplets and involves a large decoding length associated with\nerror accumulation. These introduce exposure bias, which may cause the models\noverfit to the frequent label combination, thus deteriorating the\ngeneralization. We propose a novel Sequence-to-Unordered-Multi-Tree\n(Seq2UMTree) model to minimize the effects of exposure bias by limiting the\ndecoding length to three within a triplet and removing the order among\ntriplets. We evaluate our model on two datasets, DuIE and NYT, and\nsystematically study how exposure bias alters the performance of Seq2Seq\nmodels. Experiments show that the state-of-the-art Seq2Seq model overfits to\nboth datasets while Seq2UMTree shows significantly better generalization. Our\ncode is available at https://github.com/WindChimeRan/OpenJERE .\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:53:34 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 08:56:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhang", "Ranran Haoran", ""], ["Liu", "Qianying", ""], ["Fan", "Aysa Xuemo", ""], ["Ji", "Heng", ""], ["Zeng", "Daojian", ""], ["Cheng", "Fei", ""], ["Kawahara", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "2009.07509", "submitter": "Anushree Rankawat", "authors": "Anushree Rankawat, Mansi Rankawat, Harshal B. Oza", "title": "A priori guarantees of finite-time convergence for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we perform Lyapunov based analysis of the loss function to\nderive an a priori upper bound on the settling time of deep neural networks.\nWhile previous studies have attempted to understand deep learning using control\ntheory framework, there is limited work on a priori finite time convergence\nanalysis. Drawing from the advances in analysis of finite-time control of\nnon-linear systems, we provide a priori guarantees of finite-time convergence\nin a deterministic control theoretic setting. We formulate the supervised\nlearning framework as a control problem where weights of the network are\ncontrol inputs and learning translates into a tracking problem. An analytical\nformula for finite-time upper bound on settling time is computed a priori under\nthe assumptions of boundedness of input. Finally, we prove the robustness and\nsensitivity of the loss function against input perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:13:16 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Rankawat", "Anushree", ""], ["Rankawat", "Mansi", ""], ["Oza", "Harshal B.", ""]]}, {"id": "2009.07514", "submitter": "Man-Chung Yue", "authors": "Huikang Liu, Man-Chung Yue, Anthony Man-Cho So", "title": "A Unified Approach to Synchronization Problems over Subgroups of the\n  Orthogonal Group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a group $\\mathcal{G}$, the problem of synchronization over the group\n$\\mathcal{G}$ is a constrained estimation problem where a collection of group\nelements $G^*_1, \\dots, G^*_n \\in \\mathcal{G}$ are estimated based on noisy\nobservations of pairwise ratios $G^*_i {G^*_j}^{-1}$ for an incomplete set of\nindex pairs $(i,j)$. This problem has gained much attention recently and finds\nlots of applications due to its appearance in a wide range of scientific and\nengineering areas. In this paper, we consider the class of synchronization\nproblems over a closed subgroup of the orthogonal group, which covers many\ninstances of group synchronization problems that arise in practice. Our\ncontributions are threefold. First, we propose a unified approach to solve this\nclass of group synchronization problems, which consists of a suitable\ninitialization and an iterative refinement procedure via the generalized power\nmethod. Second, we derive a master theorem on the performance guarantee of the\nproposed approach. Under certain conditions on the subgroup, the measurement\nmodel, the noise model and the initialization, the estimation error of the\niterates of our approach decreases geometrically. As our third contribution, we\nstudy concrete examples of the subgroup (including the orthogonal group, the\nspecial orthogonal group, the permutation group and the cyclic group), the\nmeasurement model, the noise model and the initialization. The validity of the\nrelated conditions in the master theorem are proved for these specific\nexamples. Numerical experiments are also presented. Experiment results show\nthat our approach outperforms existing approaches in terms of computational\nspeed, scalability and estimation error.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:25:50 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Liu", "Huikang", ""], ["Yue", "Man-Chung", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "2009.07517", "submitter": "Boris Ivanovic", "authors": "Boris Ivanovic, Amine Elhafsi, Guy Rosman, Adrien Gaidon, Marco Pavone", "title": "MATS: An Interpretable Trajectory Forecasting Representation for\n  Planning and Control", "comments": "14 pages, 6 figures, 1 table. All code, models, and data can be found\n  at https://github.com/StanfordASL/MATS . Conference on Robot Learning (CoRL)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about human motion is a core component of modern human-robot\ninteractive systems. In particular, one of the main uses of behavior prediction\nin autonomous systems is to inform robot motion planning and control. However,\na majority of planning and control algorithms reason about system dynamics\nrather than the predicted agent tracklets (i.e., ordered sets of waypoints)\nthat are commonly output by trajectory forecasting methods, which can hinder\ntheir integration. Towards this end, we propose Mixtures of Affine Time-varying\nSystems (MATS) as an output representation for trajectory forecasting that is\nmore amenable to downstream planning and control use. Our approach leverages\nsuccessful ideas from probabilistic trajectory forecasting works to learn\ndynamical system representations that are well-studied in the planning and\ncontrol literature. We integrate our predictions with a proposed multimodal\nplanning methodology and demonstrate significant computational efficiency\nimprovements on a large-scale autonomous driving dataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:32:37 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 09:46:46 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Ivanovic", "Boris", ""], ["Elhafsi", "Amine", ""], ["Rosman", "Guy", ""], ["Gaidon", "Adrien", ""], ["Pavone", "Marco", ""]]}, {"id": "2009.07518", "submitter": "Alexandre Letard", "authors": "Alexandre Letard, Tassadit Amghar, Olivier Camp, Nicolas Gutowski", "title": "Partial Bandit and Semi-Bandit: Making the Most Out of Scarce Users'\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on Multi-Armed Bandits (MAB) and Combinatorial Multi-Armed\nBandits (COM-MAB) show good results on a global accuracy metric. This can be\nachieved, in the case of recommender systems, with personalization. However,\nwith a combinatorial online learning approach, personalization implies a large\namount of user feedbacks. Such feedbacks can be hard to acquire when users need\nto be directly and frequently solicited. For a number of fields of activities\nundergoing the digitization of their business, online learning is unavoidable.\nThus, a number of approaches allowing implicit user feedback retrieval have\nbeen implemented. Nevertheless, this implicit feedback can be misleading or\ninefficient for the agent's learning. Herein, we propose a novel approach\nreducing the number of explicit feedbacks required by Combinatorial Multi Armed\nbandit (COM-MAB) algorithms while providing similar levels of global accuracy\nand learning efficiency to classical competitive methods. In this paper we\npresent a novel approach for considering user feedback and evaluate it using\nthree distinct strategies. Despite a limited number of feedbacks returned by\nusers (as low as 20% of the total), our approach obtains similar results to\nthose of state of the art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:32:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Letard", "Alexandre", ""], ["Amghar", "Tassadit", ""], ["Camp", "Olivier", ""], ["Gutowski", "Nicolas", ""]]}, {"id": "2009.07520", "submitter": "Johannes Hertrich", "authors": "Johannes Hertrich, Dang Phoung Lan Nguyen, Jean-Fancois Aujol,\n  Dominique Bernard, Yannick Berthoumieu, Abdellatif Saadaldin, Gabriele Steidl", "title": "PCA Reduced Gaussian Mixture Models with Applications in Superresolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid development of computational hardware, the treatment of\nlarge and high dimensional data sets is still a challenging problem. This paper\nprovides a twofold contribution to the topic. First, we propose a Gaussian\nMixture Model in conjunction with a reduction of the dimensionality of the data\nin each component of the model by principal component analysis, called PCA-GMM.\nTo learn the (low dimensional) parameters of the mixture model we propose an EM\nalgorithm whose M-step requires the solution of constrained optimization\nproblems. Fortunately, these constrained problems do not depend on the usually\nlarge number of samples and can be solved efficiently by an (inertial) proximal\nalternating linearized minimization algorithm. Second, we apply our PCA-GMM for\nthe superresolution of 2D and 3D material images based on the approach of\nSandeep and Jacob. Numerical results confirm the moderate influence of the\ndimensionality reduction on the overall superresolution result.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:33:56 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:33:52 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 11:40:57 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hertrich", "Johannes", ""], ["Nguyen", "Dang Phoung Lan", ""], ["Aujol", "Jean-Fancois", ""], ["Bernard", "Dominique", ""], ["Berthoumieu", "Yannick", ""], ["Saadaldin", "Abdellatif", ""], ["Steidl", "Gabriele", ""]]}, {"id": "2009.07525", "submitter": "Michael Schaub", "authors": "Leto Peel and Michael T. Schaub", "title": "Detectability of hierarchical communities in networks", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering a planted hierarchy of partitions in a\nnetwork. The detectability of a single planted partition has previously been\nanalysed in detail and a phase transition has been identified below which the\npartition cannot be detected. Here we show that, in the hierarchical setting,\nthere exist additional phases in which the presence of multiple consistent\npartitions can either help or hinder detection. Accordingly, the detectability\nlimit for non-hierarchical partitions typically provides insufficient\ninformation about the detectability of the complete hierarchical structure, as\nwe highlight with several constructive examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:44:27 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Peel", "Leto", ""], ["Schaub", "Michael T.", ""]]}, {"id": "2009.07530", "submitter": "Luca Parisi", "authors": "Luca Parisi", "title": "m-arcsinh: An Efficient and Reliable Function for SVM and MLP in\n  scikit-learn", "comments": "20 pages, 4 listings/Python code snippets, 2 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the 'm-arcsinh', a modified ('m-') version of the\ninverse hyperbolic sine function ('arcsinh'). Kernel and activation functions\nenable Machine Learning (ML)-based algorithms, such as Support Vector Machine\n(SVM) and Multi-Layer Perceptron (MLP), to learn from data in a supervised\nmanner. m-arcsinh, implemented in the open source Python library\n'scikit-learn', is hereby presented as an efficient and reliable kernel and\nactivation function for SVM and MLP respectively. Improvements in reliability\nand speed to convergence in classification tasks on fifteen (N = 15) datasets\navailable from scikit-learn and the University California Irvine (UCI) Machine\nLearning repository are discussed. Experimental results demonstrate the overall\ncompetitive classification performance of both SVM and MLP, achieved via the\nproposed function. This function is compared to gold standard kernel and\nactivation functions, demonstrating its overall competitive reliability\nregardless of the complexity of the classification tasks involved.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:59:15 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Parisi", "Luca", ""]]}, {"id": "2009.07532", "submitter": "Anupiya Nugaliyadde Dr", "authors": "A Nugaliyadde, Kok Wai Wong, Jeremy Parry, Ferdous Sohel, Hamid Laga,\n  Upeka V. Somaratne, Chris Yeomans, Orchid Foster", "title": "RCNN for Region of Interest Detection in Whole Slide Images", "comments": "This paper was accepted to the 27th International Conference on\n  Neural Information Processing (ICONIP 2020) and will be published in the\n  Springer CCIS Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital pathology has attracted significant attention in recent years.\nAnalysis of Whole Slide Images (WSIs) is challenging because they are very\nlarge, i.e., of Giga-pixel resolution. Identifying Regions of Interest (ROIs)\nis the first step for pathologists to analyse further the regions of diagnostic\ninterest for cancer detection and other anomalies. In this paper, we\ninvestigate the use of RCNN, which is a deep machine learning technique, for\ndetecting such ROIs only using a small number of labelled WSIs for training.\nFor experimentation, we used real WSIs from a public hospital pathology service\nin Western Australia. We used 60 WSIs for training the RCNN model and another\n12 WSIs for testing. The model was further tested on a new set of unseen WSIs.\nThe results show that RCNN can be effectively used for ROI detection from WSIs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:00:17 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 01:14:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Nugaliyadde", "A", ""], ["Wong", "Kok Wai", ""], ["Parry", "Jeremy", ""], ["Sohel", "Ferdous", ""], ["Laga", "Hamid", ""], ["Somaratne", "Upeka V.", ""], ["Yeomans", "Chris", ""], ["Foster", "Orchid", ""]]}, {"id": "2009.07547", "submitter": "Ketson Roberto Maximiano dos Santos", "authors": "K. R. M. dos Santos, D. G. Giovanis, M. D. Shields", "title": "Grassmannian diffusion maps based dimension reduction and classification\n  for high-dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces the Grassmannian Diffusion Maps, a novel nonlinear\ndimensionality reduction technique that defines the affinity between points\nthrough their representation as low-dimensional subspaces corresponding to\npoints on the Grassmann manifold. The method is designed for applications, such\nas image recognition and data-based classification of high-dimensional data\nthat can be compactly represented in a lower dimensional subspace. The GDMaps\nis composed of two stages. The first is a pointwise linear dimensionality\nreduction wherein each high-dimensional object is mapped onto the Grassmann.\nThe second stage is a multi-point nonlinear kernel-based dimension reduction\nusing Diffusion maps to identify the subspace structure of the points on the\nGrassmann manifold. To this aim, an appropriate Grassmannian kernel is used to\nconstruct the transition matrix of a random walk on a graph connecting points\non the Grassmann manifold. Spectral analysis of the transition matrix yields\nlow-dimensional Grassmannian diffusion coordinates embedding the data into a\nlow-dimensional reproducing kernel Hilbert space. Further, a novel data\nclassification/recognition technique is developed based on the construction of\nan overcomplete dictionary of reduced dimension whose atoms are given by the\nGrassmannian diffusion coordinates. Three examples are considered. First, a\n\"toy\" example shows that the GDMaps can identify an appropriate parametrization\nof structured points on the unit sphere. The second example demonstrates the\nability of the GDMaps to reveal the intrinsic subspace structure of\nhigh-dimensional random field data. In the last example, a face recognition\nproblem is solved considering face images subject to varying illumination\nconditions, changes in face expressions, and occurrence of occlusions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:32:02 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:55:56 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 19:51:41 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Santos", "K. R. M. dos", ""], ["Giovanis", "D. G.", ""], ["Shields", "M. D.", ""]]}, {"id": "2009.07554", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, Nandyala Hemachandra", "title": "Thompson Sampling for Unsupervised Sequential Selection", "comments": "Accepted to ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thompson Sampling has generated significant interest due to its better\nempirical performance than upper confidence bound based algorithms. In this\npaper, we study Thompson Sampling based algorithm for Unsupervised Sequential\nSelection (USS) problem. The USS problem is a variant of the stochastic\nmulti-armed bandits problem, where the loss of an arm can not be inferred from\nthe observed feedback. In the USS setup, arms are associated with fixed costs\nand are ordered, forming a cascade. In each round, the learner selects an arm\nand observes the feedback from arms up to the selected arm. The learner's goal\nis to find the arm that minimizes the expected total loss. The total loss is\nthe sum of the cost incurred for selecting the arm and the stochastic loss\nassociated with the selected arm. The problem is challenging because, without\nknowing the mean loss, one cannot compute the total loss for the selected arm.\nClearly, learning is feasible only if the optimal arm can be inferred from the\nproblem structure. As shown in the prior work, learning is possible when the\nproblem instance satisfies the so-called `Weak Dominance' (WD) property. Under\nWD, we show that our Thompson Sampling based algorithm for the USS problem\nachieves near optimal regret and has better numerical performance than existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:48:17 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "2009.07558", "submitter": "Shao-Bo Lin", "authors": "Yao Wang, Xin Guo, Shao-Bo Lin", "title": "Kernel-based L_2-Boosting with Structure Constraints", "comments": "33pages, 8figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient kernel methods for regression is very popular in the\npast decade. In this paper, utilizing boosting on kernel-based weaker learners,\nwe propose a novel kernel-based learning algorithm called kernel-based\nre-scaled boosting with truncation, dubbed as KReBooT. The proposed KReBooT\nbenefits in controlling the structure of estimators and producing sparse\nestimate, and is near overfitting resistant. We conduct both theoretical\nanalysis and numerical simulations to illustrate the power of KReBooT.\nTheoretically, we prove that KReBooT can achieve the almost optimal numerical\nconvergence rate for nonlinear approximation. Furthermore, using the recently\ndeveloped integral operator approach and a variant of Talagrand's concentration\ninequality, we provide fast learning rates for KReBooT, which is a new record\nof boosting-type algorithms. Numerically, we carry out a series of simulations\nto show the promising performance of KReBooT in terms of its good\ngeneralization, near over-fitting resistance and structure constraints.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:55:30 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Yao", ""], ["Guo", "Xin", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "2009.07560", "submitter": "Marija Jegorova", "authors": "Jean de Bodinat, Thomas Guerneve, Jose Vazquez, Marija Jegorova", "title": "Similarity-based data mining for online domain adaptation of a sonar ATR\n  system", "comments": "Accepted for publication in IEEE OCEANS2020", "journal-ref": "IEEE OCEANS2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the expensive nature of field data gathering, the lack of training\ndata often limits the performance of Automatic Target Recognition (ATR)\nsystems. This problem is often addressed with domain adaptation techniques,\nhowever the currently existing methods fail to satisfy the constraints of\nresource and time-limited underwater systems. We propose to address this issue\nvia an online fine-tuning of the ATR algorithm using a novel data-selection\nmethod. Our proposed data-mining approach relies on visual similarity and\noutperforms the traditionally employed hard-mining methods. We present a\ncomparative performance analysis in a wide range of simulated environments and\nhighlight the benefits of using our method for the rapid adaptation to\npreviously unseen environments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 09:07:54 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["de Bodinat", "Jean", ""], ["Guerneve", "Thomas", ""], ["Vazquez", "Jose", ""], ["Jegorova", "Marija", ""]]}, {"id": "2009.07563", "submitter": "Mina Ghaffari", "authors": "Mina Ghaffari, Arcot Sowmya, and Ruth Oliver", "title": "Brain tumour segmentation using cascaded 3D densely-connected U-net", "comments": "10 pages paper submitted to BraTS20 workshop (MICCAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate brain tumour segmentation is a crucial step towards improving\ndisease diagnosis and proper treatment planning. In this paper, we propose a\ndeep-learning based method to segment a brain tumour into its subregions: whole\ntumour, tumour core and enhancing tumour. The proposed architecture is a 3D\nconvolutional neural network based on a variant of the U-Net architecture of\nRonneberger et al. [17] with three main modifications: (i) a heavy encoder,\nlight decoder structure using residual blocks (ii) employment of dense blocks\ninstead of skip connections, and (iii) utilization of self-ensembling in the\ndecoder part of the network. The network was trained and tested using two\ndifferent approaches: a multitask framework to segment all tumour subregions at\nthe same time and a three-stage cascaded framework to segment one sub-region at\na time. An ensemble of the results from both frameworks was also computed. To\naddress the class imbalance issue, appropriate patch extraction was employed in\na pre-processing step. The connected component analysis was utilized in the\npost-processing step to reduce false positive predictions. Experimental results\non the BraTS20 validation dataset demonstrates that the proposed model achieved\naverage Dice Scores of 0.90, 0.82, and 0.78 for whole tumour, tumour core and\nenhancing tumour respectively.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 09:14:59 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ghaffari", "Mina", ""], ["Sowmya", "Arcot", ""], ["Oliver", "Ruth", ""]]}, {"id": "2009.07567", "submitter": "Lukman Hakim", "authors": "Lukman Hakim, Novanto Yudistira, Muthusubash Kavitha, and Takio Kurita", "title": "U-Net with Graph Based Smoothing Regularizer for Small Vessel\n  Segmentation on Fundus Image", "comments": null, "journal-ref": "ICONIP2019", "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of retinal blood vessels, especially the changes of small\nvessel condition is the most important indicator to identify the vascular\nnetwork of the human body. Existing techniques focused mainly on shape of the\nlarge vessels, which is not appropriate for the disconnected small and isolated\nvessels. Paying attention to the low contrast small blood vessel in fundus\nregion, first time we proposed to combine graph based smoothing regularizer\nwith the loss function in the U-net framework. The proposed regularizer treated\nthe image as two graphs by calculating the graph laplacians on vessel regions\nand the background regions on the image. The potential of the proposed graph\nbased smoothing regularizer in reconstructing small vessel is compared over the\nclassical U-net with or without regularizer. Numerical and visual results shows\nthat our developed regularizer proved its effectiveness in segmenting the small\nvessels and reconnecting the fragmented retinal blood vessels.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 09:21:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Hakim", "Lukman", ""], ["Yudistira", "Novanto", ""], ["Kavitha", "Muthusubash", ""], ["Kurita", "Takio", ""]]}, {"id": "2009.07578", "submitter": "Stephan Robert-Nicoud", "authors": "Giulia Moschini, R\\'egis Houssou, J\\'er\\^ome Bovay, Stephan\n  Robert-Nicoud", "title": "Anomaly and Fraud Detection in Credit Card Transactions Using the ARIMA\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unsupervised approach of credit card\nfraud detection in unbalanced dataset using the ARIMA model. The ARIMA model is\nfitted on the regular spending behaviour of the customer and is used to detect\nfraud if some deviations or discrepancies appear. Our model is applied to\ncredit card datasets and is compared to 4 anomaly detection approaches such as\nK-Means, Box-Plot, Local Outlier Factor and Isolation Forest. The results show\nthat the ARIMA model presents a better detecting power than the benchmark\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 09:48:26 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Moschini", "Giulia", ""], ["Houssou", "R\u00e9gis", ""], ["Bovay", "J\u00e9r\u00f4me", ""], ["Robert-Nicoud", "Stephan", ""]]}, {"id": "2009.07601", "submitter": "Alistair Smith", "authors": "Alistair W. R. Smith, Johnnie Gray, M. S. Kim", "title": "Efficient Quantum State Sample Tomography with Basis-dependent\n  Neural-networks", "comments": null, "journal-ref": "PRX Quantum 2, 020348 (2021)", "doi": "10.1103/PRXQuantum.2.020348", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a meta-learning neural-network approach to analyse data from a\nmeasured quantum state. Once our neural network has been trained it can be used\nto efficiently sample measurements of the state in measurement bases not\ncontained in the training data. These samples can be used calculate expectation\nvalues and other useful quantities. We refer to this process as \"state sample\ntomography\". We encode the state's measurement outcome distributions using an\nefficiently parameterized generative neural network. This allows each stage in\nthe tomography process to be performed efficiently even for large systems. Our\nscheme is demonstrated on recent IBM Quantum devices, producing a model for a\n6-qubit state's measurement outcomes with a predictive accuracy (classical\nfidelity) > 95% for all test cases using only 100 random measurement settings\nas opposed to the 729 settings required for standard full tomography using\nlocal measurements. This reduction in the required number of measurements\nscales favourably, with training data in 200 measurement settings yielding a\npredictive accuracy > 92% for a 10 qubit state where 59,049 settings are\ntypically required for full local measurement-based quantum state tomography. A\nreduction in number of measurements by a factor, in this case, of almost 600\ncould allow for estimations of expectation values and state fidelities in\npracticable times on current quantum devices.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:01:00 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 10:27:13 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 14:58:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Smith", "Alistair W. R.", ""], ["Gray", "Johnnie", ""], ["Kim", "M. S.", ""]]}, {"id": "2009.07608", "submitter": "Andreas Selmar Hauptmann", "authors": "Andreas Hauptmann and Ben Cox", "title": "Deep Learning in Photoacoustic Tomography: Current approaches and future\n  directions", "comments": null, "journal-ref": "J. of Biomedical Optics, 25(11), 112903 (2020)", "doi": "10.1117/1.JBO.25.11.112903", "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical photoacoustic tomography, which can provide high resolution 3D\nsoft tissue images based on the optical absorption, has advanced to the stage\nat which translation from the laboratory to clinical settings is becoming\npossible. The need for rapid image formation and the practical restrictions on\ndata acquisition that arise from the constraints of a clinical workflow are\npresenting new image reconstruction challenges. There are many classical\napproaches to image reconstruction, but ameliorating the effects of incomplete\nor imperfect data through the incorporation of accurate priors is challenging\nand leads to slow algorithms. Recently, the application of Deep Learning, or\ndeep neural networks, to this problem has received a great deal of attention.\nThis paper reviews the literature on learned image reconstruction, summarising\nthe current trends, and explains how these new approaches fit within, and to\nsome extent have arisen from, a framework that encompasses classical\nreconstruction methods. In particular, it shows how these new techniques can be\nunderstood from a Bayesian perspective, providing useful insights. The paper\nalso provides a concise tutorial demonstration of three prototypical approaches\nto learned image reconstruction. The code and data sets for these\ndemonstrations are available to researchers. It is anticipated that it is in in\nvivo applications - where data may be sparse, fast imaging critical and priors\ndifficult to construct by hand - that Deep Learning will have the most impact.\nWith this in mind, the paper concludes with some indications of possible future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:33:29 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Hauptmann", "Andreas", ""], ["Cox", "Ben", ""]]}, {"id": "2009.07612", "submitter": "Hanbaek Lyu", "authors": "Christopher Strohmeier and Hanbaek Lyu and Deanna Needell", "title": "Online tensor factorization and CP-dictionary learning for Markovian\n  data", "comments": "31 pages, 5 figures. Major revision in the convergence analysis.\n  Preliminary version appeared in NeurIPS 2020 Workshop on Optimization for\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online Tensor Factorization (OTF) is a fundamental tool in learning\nlow-dimensional interpretable features from streaming multi-modal data. While\nvarious algorithmic and theoretical aspects of OTF have been investigated\nrecently, general convergence guarantee to stationary points of the objective\nfunction without any incoherence or sparsity assumptions is still lacking even\nfor the i.i.d. case. In this work, we introduce a novel OTF algorithm that\nlearns a CANDECOMP/PARAFAC (CP) basis from a given stream of tensor-valued data\nunder general constraints, including nonnegativity constraints that induce\ninterpretability of learned CP basis. We prove that our algorithm converges\nalmost surely to the set of stationary points of the objective function under\nthe hypothesis that the sequence of data tensors is generated by some\nunderlying Markov chain. Our setting covers the classical i.i.d. case as well\nas a wide range of application contexts including data streams generated by\nindependent or MCMC sampling. Our result closes a gap between OTF and Online\nMatrix Factorization in global convergence analysis. Experimentally, we show\nthat our OTF algorithm converges much faster than standard algorithms for\nnonnegative tensor factorization tasks on both synthetic and real-world data.\nAlso, we demonstrate the utility of our algorithm on a diverse set of examples\nfrom image, video, and time-series data, illustrating how one may learn\nqualitatively different CP-dictionaries from the same tensor data by exploiting\nthe tensor structure in multiple ways.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:41:01 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 13:07:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Strohmeier", "Christopher", ""], ["Lyu", "Hanbaek", ""], ["Needell", "Deanna", ""]]}, {"id": "2009.07624", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Xingjian Li, Dejing Dou, Ji Wu", "title": "Measuring Information Transfer in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the information content in a neural network model is essentially\nestimating the model's Kolmogorov complexity. Recent success of prequential\ncoding on neural networks points to a promising path of deriving an efficient\ndescription length of a model. We propose a practical measure of the\ngeneralizable information in a neural network model based on prequential\ncoding, which we term Information Transfer ($L_{IT}$). Theoretically, $L_{IT}$\nis an estimation of the generalizable part of a model's information content. In\nexperiments, we show that $L_{IT}$ is consistently correlated with\ngeneralizable information and can be used as a measure of patterns or\n\"knowledge\" in a model or a dataset. Consequently, $L_{IT}$ can serve as a\nuseful analysis tool in deep learning. In this paper, we apply $L_{IT}$ to\ncompare and dissect information in datasets, evaluate representation models in\ntransfer learning, and analyze catastrophic forgetting and continual learning\nalgorithms. $L_{IT}$ provides an information perspective which helps us\ndiscover new insights into neural network learning.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:06:42 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 07:16:10 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zhang", "Xiao", ""], ["Li", "Xingjian", ""], ["Dou", "Dejing", ""], ["Wu", "Ji", ""]]}, {"id": "2009.07635", "submitter": "Nikhil Churamani", "authors": "Pablo Barros, Nikhil Churamani and Alessandra Sciutti", "title": "The FaceChannel: A Fast & Furious Deep Neural Network for Facial\n  Expression Recognition", "comments": "Accepted for publication at SN Computer Science. arXiv admin note:\n  substantial text overlap with arXiv:2004.08195", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art models for automatic Facial Expression Recognition\n(FER) are based on very deep neural networks that are effective but rather\nexpensive to train. Given the dynamic conditions of FER, this characteristic\nhinders such models of been used as a general affect recognition. In this\npaper, we address this problem by formalizing the FaceChannel, a light-weight\nneural network that has much fewer parameters than common deep neural networks.\nWe introduce an inhibitory layer that helps to shape the learning of facial\nfeatures in the last layer of the network and thus improving performance while\nreducing the number of trainable parameters. To evaluate our model, we perform\na series of experiments on different benchmark datasets and demonstrate how the\nFaceChannel achieves a comparable, if not better, performance to the current\nstate-of-the-art in FER. Our experiments include cross-dataset analysis, to\nestimate how our model behaves on different affective recognition conditions.\nWe conclude our paper with an analysis of how FaceChannel learns and adapt the\nlearned facial features towards the different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 09:25:37 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Barros", "Pablo", ""], ["Churamani", "Nikhil", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2009.07652", "submitter": "Zhao Wang", "authors": "Zhao Wang, Quande Liu, and Qi Dou", "title": "Contrastive Cross-site Learning with Redesigned Net for COVID-19 CT\n  Classification", "comments": "Published as a journal paper at IEEE J-BHI; code and dataset are\n  available at https://github.com/med-air/Contrastive-COVIDNet", "journal-ref": null, "doi": "10.1109/JBHI.2020.3023246", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pandemic of coronavirus disease 2019 (COVID-19) has lead to a global\npublic health crisis spreading hundreds of countries. With the continuous\ngrowth of new infections, developing automated tools for COVID-19\nidentification with CT image is highly desired to assist the clinical diagnosis\nand reduce the tedious workload of image interpretation. To enlarge the\ndatasets for developing machine learning methods, it is essentially helpful to\naggregate the cases from different medical systems for learning robust and\ngeneralizable models. This paper proposes a novel joint learning framework to\nperform accurate COVID-19 identification by effectively learning with\nheterogeneous datasets with distribution discrepancy. We build a powerful\nbackbone by redesigning the recently proposed COVID-Net in aspects of network\narchitecture and learning strategy to improve the prediction accuracy and\nlearning efficiency. On top of our improved backbone, we further explicitly\ntackle the cross-site domain shift by conducting separate feature normalization\nin latent space. Moreover, we propose to use a contrastive training objective\nto enhance the domain invariance of semantic embeddings for boosting the\nclassification performance on each dataset. We develop and evaluate our method\nwith two public large-scale COVID-19 diagnosis datasets made up of CT images.\nExtensive experiments show that our approach consistently improves the\nperformances on both datasets, outperforming the original COVID-Net trained on\neach dataset by 12.16% and 14.23% in AUC respectively, also exceeding existing\nstate-of-the-art multi-site learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 11:09:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Zhao", ""], ["Liu", "Quande", ""], ["Dou", "Qi", ""]]}, {"id": "2009.07664", "submitter": "Abdelhak Lemkhenter", "authors": "Abdelhak Lemkhenter and Paolo Favaro", "title": "Boosting Generalization in Bio-Signal Classification by Learning the\n  Phase-Amplitude Coupling", "comments": "Accepted at GCPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various hand-crafted features representations of bio-signals rely primarily\non the amplitude or power of the signal in specific frequency bands. The phase\ncomponent is often discarded as it is more sample specific, and thus more\nsensitive to noise, than the amplitude. However, in general, the phase\ncomponent also carries information relevant to the underlying biological\nprocesses. In fact, in this paper we show the benefits of learning the coupling\nof both phase and amplitude components of a bio-signal. We do so by introducing\na novel self-supervised learning task, which we call Phase-Swap, that detects\nif bio-signals have been obtained by merging the amplitude and phase from\ndifferent sources. We show in our evaluation that neural networks trained on\nthis task generalize better across subjects and recording sessions than their\nfully supervised counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:07:00 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:07:05 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lemkhenter", "Abdelhak", ""], ["Favaro", "Paolo", ""]]}, {"id": "2009.07672", "submitter": "Ahmed Mohamed Hussain", "authors": "Ahmed Mohamed Hussain, Gabriele Oligeri, and Thiemo Voigt", "title": "The Dark (and Bright) Side of IoT: Attacks and Countermeasures for\n  Identifying Smart Home Devices and Services", "comments": "15 pages, 7 figures. Accepted for the 9th International Symposium On\n  Security And Privacy On Internet of Things (SPIoT), 2020", "journal-ref": null, "doi": "10.1007/978-3-030-68884-4_10", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning-based attack that exploits network patterns\nto detect the presence of smart IoT devices and running services in the WiFi\nradio spectrum. We perform an extensive measurement campaign of data\ncollection, and we build up a model describing the traffic patterns\ncharacterizing three popular IoT smart home devices, i.e., Google Nest Mini,\nAmazon Echo, and Amazon Echo Dot. We prove that it is possible to detect and\nidentify with overwhelming probability their presence and the services running\nby the aforementioned devices in a crowded WiFi scenario. This work proves that\nstandard encryption techniques alone are not sufficient to protect the privacy\nof the end-user, since the network traffic itself exposes the presence of both\nthe device and the associated service. While more work is required to prevent\nnon-trusted third parties to detect and identify the user's devices, we\nintroduce Eclipse, a technique to mitigate these types of attacks, which\nreshapes the traffic making the identification of the devices and the\nassociated services similar to the random classification baseline.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:28:59 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 19:53:37 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 15:06:06 GMT"}, {"version": "v4", "created": "Sun, 25 Jul 2021 08:26:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hussain", "Ahmed Mohamed", ""], ["Oligeri", "Gabriele", ""], ["Voigt", "Thiemo", ""]]}, {"id": "2009.07701", "submitter": "Casper Solheim Bojer", "authors": "Casper Solheim Bojer and Jens Peder Meldgaard", "title": "Kaggle forecasting competitions: An overlooked learning opportunity", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijforecast.2020.07.007", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competitions play an invaluable role in the field of forecasting, as\nexemplified through the recent M4 competition. The competition received\nattention from both academics and practitioners and sparked discussions around\nthe representativeness of the data for business forecasting. Several\ncompetitions featuring real-life business forecasting tasks on the Kaggle\nplatform has, however, been largely ignored by the academic community. We\nbelieve the learnings from these competitions have much to offer to the\nforecasting community and provide a review of the results from six Kaggle\ncompetitions. We find that most of the Kaggle datasets are characterized by\nhigher intermittence and entropy than the M-competitions and that global\nensemble models tend to outperform local single models. Furthermore, we find\nthe strong performance of gradient boosted decision trees, increasing success\nof neural networks for forecasting, and a variety of techniques for adapting\nmachine learning models to the forecasting task.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:14:41 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Bojer", "Casper Solheim", ""], ["Meldgaard", "Jens Peder", ""]]}, {"id": "2009.07703", "submitter": "Hang Yu", "authors": "Hang Yu, Songwei Wu, and Justin Dauwels", "title": "Efficient Variational Bayesian Structure Learning of Dynamic Graphical\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating time-varying graphical models are of paramount importance in\nvarious social, financial, biological, and engineering systems, since the\nevolution of such networks can be utilized for example to spot trends, detect\nanomalies, predict vulnerability, and evaluate the impact of interventions.\nExisting methods require extensive tuning of parameters that control the graph\nsparsity and temporal smoothness. Furthermore, these methods are\ncomputationally burdensome with time complexity O(NP^3) for P variables and N\ntime points. As a remedy, we propose a low-complexity tuning-free Bayesian\napproach, named BADGE. Specifically, we impose temporally-dependent\nspike-and-slab priors on the graphs such that they are sparse and varying\nsmoothly across time. A variational inference algorithm is then derived to\nlearn the graph structures from the data automatically. Owning to the\npseudo-likelihood and the mean-field approximation, the time complexity of\nBADGE is only O(NP^2). Additionally, by identifying the frequency-domain\nresemblance to the time-varying graphical models, we show that BADGE can be\nextended to learning frequency-varying inverse spectral density matrices, and\nyields graphical models for multivariate stationary time series. Numerical\nresults on both synthetic and real data show that that BADGE can better recover\nthe underlying true graphs, while being more efficient than the existing\nmethods, especially for high-dimensional cases.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:19:23 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 15:59:08 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Yu", "Hang", ""], ["Wu", "Songwei", ""], ["Dauwels", "Justin", ""]]}, {"id": "2009.07708", "submitter": "Fan Fang", "authors": "Fan Fang, Carmine Ventre, Lingbo Li, Leslie Kanthan, Fan Wu, Michail\n  Basios", "title": "Better Model Selection with a new Definition of Feature Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance aims at measuring how crucial each input feature is for\nmodel prediction. It is widely used in feature engineering, model selection and\nexplainable artificial intelligence (XAI). In this paper, we propose a new\ntree-model explanation approach for model selection. Our novel concept\nleverages the Coefficient of Variation of a feature weight (measured in terms\nof the contribution of the feature to the prediction) to capture the dispersion\nof importance over samples. Extensive experimental results show that our novel\nfeature explanation performs better than general cross validation method in\nmodel selection both in terms of time efficiency and accuracy performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:32:22 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fang", "Fan", ""], ["Ventre", "Carmine", ""], ["Li", "Lingbo", ""], ["Kanthan", "Leslie", ""], ["Wu", "Fan", ""], ["Basios", "Michail", ""]]}, {"id": "2009.07712", "submitter": "Shaoxiong Feng", "authors": "Shaoxiong Feng, Hongshen Chen, Xuancheng Ren, Zhuoye Ding, Kan Li, Xu\n  Sun", "title": "Collaborative Group Learning", "comments": "Accepted by AAAI 2021; Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning has successfully applied knowledge transfer to guide a\npool of small student networks towards robust local minima. However, previous\napproaches typically struggle with drastically aggravated student\nhomogenization when the number of students rises. In this paper, we propose\nCollaborative Group Learning, an efficient framework that aims to diversify the\nfeature representation and conduct an effective regularization. Intuitively,\nsimilar to the human group study mechanism, we induce students to learn and\nexchange different parts of course knowledge as collaborative groups. First,\neach student is established by randomly routing on a modular neural network,\nwhich facilitates flexible knowledge communication between students due to\nrandom levels of representation sharing and branching. Second, to resist the\nstudent homogenization, students first compose diverse feature sets by\nexploiting the inductive bias from sub-sets of training data, and then\naggregate and distill different complementary knowledge by imitating a random\nsub-group of students at each time step. Overall, the above mechanisms are\nbeneficial for maximizing the student population to further improve the model\ngeneralization without sacrificing computational efficiency. Empirical\nevaluations on both image and text tasks indicate that our method significantly\noutperforms various state-of-the-art collaborative approaches whilst enhancing\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:34:39 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 11:48:43 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 10:46:46 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 04:57:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Feng", "Shaoxiong", ""], ["Chen", "Hongshen", ""], ["Ren", "Xuancheng", ""], ["Ding", "Zhuoye", ""], ["Li", "Kan", ""], ["Sun", "Xu", ""]]}, {"id": "2009.07717", "submitter": "Sara Ahmed", "authors": "Sara Atito Ali Ahmed, Berrin Yanikoglu", "title": "Relative Attribute Classification with Deep Rank SVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative attributes indicate the strength of a particular attribute between\nimage pairs. We introduce a deep Siamese network with rank SVM loss function,\ncalled Deep Rank SVM (DRSVM), in order to decide which one of a pair of images\nhas a stronger presence of a specific attribute. The network is trained in an\nend-to-end fashion to jointly learn the visual features and the ranking\nfunction. We demonstrate the effectiveness of our approach against the\nstate-of-the-art methods on four image benchmark datasets: LFW-10, PubFig,\nUTZap50K-lexi and UTZap50K-2 datasets. DRSVM surpasses state-of-art in terms of\nthe average accuracy across attributes, on three of the four image benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 09:21:39 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ahmed", "Sara Atito Ali", ""], ["Yanikoglu", "Berrin", ""]]}, {"id": "2009.07724", "submitter": "Colorado J Reed", "authors": "Colorado J Reed, Sean Metzger, Aravind Srinivas, Trevor Darrell, Kurt\n  Keutzer", "title": "SelfAugment: Automatic Augmentation Policies for Self-Supervised\n  Learning", "comments": "Computer Vision and Pattern Recognition (CVPR), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A common practice in unsupervised representation learning is to use labeled\ndata to evaluate the quality of the learned representations. This supervised\nevaluation is then used to guide critical aspects of the training process such\nas selecting the data augmentation policy. However, guiding an unsupervised\ntraining process through supervised evaluations is not possible for real-world\ndata that does not actually contain labels (which may be the case, for example,\nin privacy sensitive fields such as medical imaging). Therefore, in this work\nwe show that evaluating the learned representations with a self-supervised\nimage rotation task is highly correlated with a standard set of supervised\nevaluations (rank correlation $> 0.94$). We establish this correlation across\nhundreds of augmentation policies, training settings, and network architectures\nand provide an algorithm (SelfAugment) to automatically and efficiently select\naugmentation policies without using supervised evaluations. Despite not using\nany labeled data, the learned augmentation policies perform comparably with\naugmentation policies that were determined using exhaustive supervised\nevaluations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:49:03 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:53:51 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 15:11:06 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Reed", "Colorado J", ""], ["Metzger", "Sean", ""], ["Srinivas", "Aravind", ""], ["Darrell", "Trevor", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2009.07738", "submitter": "Alexander Lavin", "authors": "Alexander Lavin", "title": "Neuro-symbolic Neurodegenerative Disease Modeling as Probabilistic\n  Programmed Deep Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic programmed deep kernel learning approach to\npersonalized, predictive modeling of neurodegenerative diseases. Our analysis\nconsiders a spectrum of neural and symbolic machine learning approaches, which\nwe assess for predictive performance and important medical AI properties such\nas interpretability, uncertainty reasoning, data-efficiency, and leveraging\ndomain knowledge. Our Bayesian approach combines the flexibility of Gaussian\nprocesses with the structural power of neural networks to model biomarker\nprogressions, without needing clinical labels for training. We run evaluations\non the problem of Alzheimer's disease prediction, yielding results that surpass\ndeep learning in both accuracy and timeliness of predicting neurodegeneration,\nand with the practical advantages of Bayesian nonparametrics and probabilistic\nprogramming.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:16:03 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 13:20:28 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 15:54:14 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Lavin", "Alexander", ""]]}, {"id": "2009.07740", "submitter": "Juan Cruz-Benito", "authors": "Juan Cruz-Benito, Sanjay Vishwakarma, Francisco Martin-Fernandez,\n  Ismael Faro", "title": "Automated Source Code Generation and Auto-completion Using Deep\n  Learning: Comparing and Discussing Current Language-Model-Related Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use of deep learning in language models gained much\nattention. Some research projects claim that they can generate text that can be\ninterpreted as human-writing, enabling new possibilities in many application\nareas. Among the different areas related to language processing, one of the\nmost notable in applying this type of modeling is programming languages. For\nyears, the Machine Learning community has been researching this software\nengineering area, pursuing goals like applying different approaches to\nauto-complete, generate, fix, or evaluate code programmed by humans.\nConsidering the increasing popularity of the Deep-Learning-enabled language\nmodels approach, we detected a lack of empirical papers that compare different\ndeep learning architectures to create and use language models based on\nprogramming code. This paper compares different neural network architectures\nlike AWD-LSTMs, AWD-QRNNs, and Transformer while using transfer learning and\ndifferent tokenizations to see how they behave in building language models\nusing a Python dataset for code generation and filling mask tasks. Considering\nthe results, we discuss each approach's different strengths and weaknesses and\nwhat gaps we find to evaluate the language models or apply them in a real\nprogramming context.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:17:04 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 15:37:47 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 10:52:51 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 10:54:20 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Cruz-Benito", "Juan", ""], ["Vishwakarma", "Sanjay", ""], ["Martin-Fernandez", "Francisco", ""], ["Faro", "Ismael", ""]]}, {"id": "2009.07753", "submitter": "Erick Galinkin", "authors": "Erick Galinkin", "title": "Malicious Network Traffic Detection via Deep Learning: An Information\n  Theoretic View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention that deep learning has garnered from the academic community and\nindustry continues to grow year over year, and it has been said that we are in\na new golden age of artificial intelligence research. However, neural networks\nare still often seen as a \"black box\" where learning occurs but cannot be\nunderstood in a human-interpretable way. Since these machine learning systems\nare increasingly being adopted in security contexts, it is important to explore\nthese interpretations. We consider an Android malware traffic dataset for\napproaching this problem. Then, using the information plane, we explore how\nhomeomorphism affects learned representation of the data and the invariance of\nthe mutual information captured by the parameters on that data. We empirically\nvalidate these results, using accuracy as a second measure of similarity of\nlearned representations.\n  Our results suggest that although the details of learned representations and\nthe specific coordinate system defined over the manifold of all parameters\ndiffer slightly, the functional approximations are the same. Furthermore, our\nresults show that since mutual information remains invariant under\nhomeomorphism, only feature engineering methods that alter the entropy of the\ndataset will change the outcome of the neural network. This means that for some\ndatasets and tasks, neural networks require meaningful, human-driven feature\nengineering or changes in architecture to provide enough information for the\nneural network to generate a sufficient statistic. Applying our results can\nserve to guide analysis methods for machine learning engineers and suggests\nthat neural networks that can exploit the convolution theorem are equally\naccurate as standard convolutional neural networks, and can be more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:37:44 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Galinkin", "Erick", ""]]}, {"id": "2009.07755", "submitter": "Guillaume Salha", "authors": "Elena V. Epure and Guillaume Salha and Romain Hennequin", "title": "Multilingual Music Genre Embeddings for Effective Cross-Lingual Music\n  Item Annotation", "comments": "21st International Society for Music Information Retrieval Conference\n  (ISMIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating music items with music genres is crucial for music recommendation\nand information retrieval, yet challenging given that music genres are\nsubjective concepts. Recently, in order to explicitly consider this\nsubjectivity, the annotation of music items was modeled as a translation task:\npredict for a music item its music genres within a target vocabulary or\ntaxonomy (tag system) from a set of music genre tags originating from other tag\nsystems. However, without a parallel corpus, previous solutions could not\nhandle tag systems in other languages, being limited to the English-language\nonly. Here, by learning multilingual music genre embeddings, we enable\ncross-lingual music genre translation without relying on a parallel corpus.\nFirst, we apply compositionality functions on pre-trained word embeddings to\nrepresent multi-word tags.Second, we adapt the tag representations to the music\ndomain by leveraging multilingual music genres graphs with a modified\nretrofitting algorithm. Experiments show that our method: 1) is effective in\ntranslating music genres across tag systems in multiple languages (English,\nFrench and Spanish); 2) outperforms the previous baseline in an\nEnglish-language multi-source translation task. We publicly release the new\nmultilingual data and code.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:39:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Epure", "Elena V.", ""], ["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""]]}, {"id": "2009.07769", "submitter": "Sarah Alnegheimish", "authors": "Alexander Geiger, Dongyu Liu, Sarah Alnegheimish, Alfredo\n  Cuesta-Infante, Kalyan Veeramachaneni", "title": "TadGAN: Time Series Anomaly Detection Using Generative Adversarial\n  Networks", "comments": "Alexander Geiger and Dongyu Liu contributed equally. To appear in the\n  proceedings of IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomalies can offer information relevant to critical situations\nfacing various fields, from finance and aerospace to the IT, security, and\nmedical domains. However, detecting anomalies in time series data is\nparticularly challenging due to the vague definition of anomalies and said\ndata's frequent lack of labels and highly complex temporal correlations.\nCurrent state-of-the-art unsupervised machine learning methods for anomaly\ndetection suffer from scalability and portability issues, and may have high\nfalse positive rates. In this paper, we propose TadGAN, an unsupervised anomaly\ndetection approach built on Generative Adversarial Networks (GANs). To capture\nthe temporal correlations of time series distributions, we use LSTM Recurrent\nNeural Networks as base models for Generators and Critics. TadGAN is trained\nwith cycle consistency loss to allow for effective time-series data\nreconstruction. We further propose several novel methods to compute\nreconstruction errors, as well as different approaches to combine\nreconstruction errors and Critic outputs to compute anomaly scores. To\ndemonstrate the performance and generalizability of our approach, we test\nseveral anomaly scoring techniques and report the best-suited one. We compare\nour approach to 8 baseline anomaly detection methods on 11 datasets from\nmultiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter.\nThe results show that our approach can effectively detect anomalies and\noutperform baseline methods in most cases (6 out of 11). Notably, our method\nhas the highest averaged F1 score across all the datasets. Our code is open\nsource and is available as a benchmarking tool.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:52:04 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 23:25:06 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 23:05:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Geiger", "Alexander", ""], ["Liu", "Dongyu", ""], ["Alnegheimish", "Sarah", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "2009.07774", "submitter": "Matin Hashemi", "authors": "Sepehr Dehdashtian, Matin Hashemi, Saber Salehkaleybar", "title": "Deep-Learning Based Blind Recognition of Channel Code Parameters over\n  Candidate Sets under AWGN and Multi-Path Fading Conditions", "comments": "accepted for publication in IEEE Wireless Communications Letters", "journal-ref": null, "doi": "10.1109/LWC.2021.3056631", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering channel code parameters over a\ncandidate set by merely analyzing the received encoded signals. We propose a\ndeep learning-based solution that I) is capable of identifying the channel code\nparameters for any coding scheme (such as LDPC, Convolutional, Turbo, and Polar\ncodes), II) is robust against channel impairments like multi-path fading, III)\ndoes not require any previous knowledge or estimation of channel state or\nsignal-to-noise ratio (SNR), and IV) outperforms related works in terms of\nprobability of detecting the correct code parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:10:39 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 17:15:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Dehdashtian", "Sepehr", ""], ["Hashemi", "Matin", ""], ["Salehkaleybar", "Saber", ""]]}, {"id": "2009.07793", "submitter": "Himanshu Pradeep Aswani", "authors": "Himanshu Pradeep Aswani, Amit Sethi", "title": "Activation Functions: Do They Represent A Trade-Off Between Modular\n  Nature of Neural Networks And Task Performance", "comments": "5 pages, 1 figure, 2 tables, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research suggests that the key factors in designing neural network\narchitectures involve choosing number of filters for every convolution layer,\nnumber of hidden neurons for every fully connected layer, dropout and pruning.\nThe default activation function in most cases is the ReLU, as it has\nempirically shown faster training convergence. We explore whether ReLU is the\nbest choice if one is aiming to desire better modularity structure within a\nneural network.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:38:16 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Aswani", "Himanshu Pradeep", ""], ["Sethi", "Amit", ""]]}, {"id": "2009.07799", "submitter": "Qianxiao Li", "authors": "Zhong Li, Jiequn Han, Weinan E, Qianxiao Li", "title": "On the Curse of Memory in Recurrent Neural Networks: Approximation and\n  Optimization Analysis", "comments": "Published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation properties and optimization dynamics of recurrent\nneural networks (RNNs) when applied to learn input-output relationships in\ntemporal data. We consider the simple but representative setting of using\ncontinuous-time linear RNNs to learn from data generated by linear\nrelationships. Mathematically, the latter can be understood as a sequence of\nlinear functionals. We prove a universal approximation theorem of such linear\nfunctionals, and characterize the approximation rate and its relation with\nmemory. Moreover, we perform a fine-grained dynamical analysis of training\nlinear RNNs, which further reveal the intricate interactions between memory and\nlearning. A unifying theme uncovered is the non-trivial effect of memory, a\nnotion that can be made precise in our framework, on approximation and\noptimization: when there is long term memory in the target, it takes a large\nnumber of neurons to approximate it. Moreover, the training process will suffer\nfrom slow downs. In particular, both of these effects become exponentially more\npronounced with memory - a phenomenon we call the \"curse of memory\". These\nanalyses represent a basic step towards a concrete mathematical understanding\nof new phenomenon that may arise in learning temporal relationships using\nrecurrent architectures.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:48:28 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 03:36:21 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Zhong", ""], ["Han", "Jiequn", ""], ["E", "Weinan", ""], ["Li", "Qianxiao", ""]]}, {"id": "2009.07801", "submitter": "Mingyuan Zhang", "authors": "Mingyuan Zhang, Harish G. Ramaswamy, Shivani Agarwal", "title": "Convex Calibrated Surrogates for the Multi-Label F-Measure", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-measure is a widely used performance measure for multi-label\nclassification, where multiple labels can be active in an instance\nsimultaneously (e.g. in image tagging, multiple tags can be active in any\nimage). In particular, the F-measure explicitly balances recall (fraction of\nactive labels predicted to be active) and precision (fraction of labels\npredicted to be active that are actually so), both of which are important in\nevaluating the overall performance of a multi-label classifier. As with most\ndiscrete prediction problems, however, directly optimizing the F-measure is\ncomputationally hard. In this paper, we explore the question of designing\nconvex surrogate losses that are calibrated for the F-measure -- specifically,\nthat have the property that minimizing the surrogate loss yields (in the limit\nof sufficient data) a Bayes optimal multi-label classifier for the F-measure.\nWe show that the F-measure for an $s$-label problem, when viewed as a $2^s\n\\times 2^s$ loss matrix, has rank at most $s^2+1$, and apply a result of\nRamaswamy et al. (2014) to design a family of convex calibrated surrogates for\nthe F-measure. The resulting surrogate risk minimization algorithms can be\nviewed as decomposing the multi-label F-measure learning problem into $s^2+1$\nbinary class probability estimation problems. We also provide a quantitative\nregret transfer bound for our surrogates, which allows any regret guarantees\nfor the binary problems to be transferred to regret guarantees for the overall\nF-measure problem, and discuss a connection with the algorithm of Dembczynski\net al. (2013). Our experiments confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:50:55 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Mingyuan", ""], ["Ramaswamy", "Harish G.", ""], ["Agarwal", "Shivani", ""]]}, {"id": "2009.07806", "submitter": "Dustin Wright", "authors": "Dustin Wright and Isabelle Augenstein", "title": "Transformer Based Multi-Source Domain Adaptation", "comments": "12 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical machine learning settings, the data on which a model must make\npredictions often come from a different distribution than the data it was\ntrained on. Here, we investigate the problem of unsupervised multi-source\ndomain adaptation, where a model is trained on labelled data from multiple\nsource domains and must make predictions on a domain for which no labelled data\nhas been seen. Prior work with CNNs and RNNs has demonstrated the benefit of\nmixture of experts, where the predictions of multiple domain expert classifiers\nare combined; as well as domain adversarial training, to induce a domain\nagnostic representation space. Inspired by this, we investigate how such\nmethods can be effectively applied to large pretrained transformer models. We\nfind that domain adversarial training has an effect on the learned\nrepresentations of these models while having little effect on their\nperformance, suggesting that large transformer-based models are already\nrelatively robust across domains. Additionally, we show that mixture of experts\nleads to significant performance improvements by comparing several variants of\nmixing functions, including one novel mixture based on attention. Finally, we\ndemonstrate that the predictions of large pretrained transformer based domain\nexperts are highly homogenous, making it challenging to learn effective\nfunctions for mixing their predictions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:56:23 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.07810", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra", "title": "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CoDEx, a set of knowledge graph completion datasets extracted from\nWikidata and Wikipedia that improve upon existing knowledge graph completion\nbenchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises\nthree knowledge graphs varying in size and structure, multilingual descriptions\nof entities and relations, and tens of thousands of hard negative triples that\nare plausible but verified to be false. To characterize CoDEx, we contribute\nthorough empirical analyses and benchmarking experiments. First, we analyze\neach CoDEx dataset in terms of logical relation patterns. Next, we report\nbaseline link prediction and triple classification results on CoDEx for five\nextensively tuned embedding models. Finally, we differentiate CoDEx from the\npopular FB15K-237 knowledge graph completion dataset by showing that CoDEx\ncovers more diverse and interpretable content, and is a more difficult link\nprediction benchmark. Data, code, and pretrained models are available at\nhttps://bit.ly/2EPbrJs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:08:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:10:10 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.07839", "submitter": "Richard Yuanzhe Pang", "authors": "Richard Yuanzhe Pang, He He", "title": "Text Generation by Learning from Demonstrations", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to text generation largely rely on autoregressive models\nand maximum likelihood estimation. This paradigm leads to (i) diverse but\nlow-quality samples due to mismatched learning objective and evaluation metric\n(likelihood vs. quality) and (ii) exposure bias due to mismatched history\ndistributions (gold vs. model-generated). To alleviate these problems, we frame\ntext generation as an offline reinforcement learning (RL) problem with expert\ndemonstrations (i.e., the reference), where the goal is to maximize quality\ngiven model-generated histories. We propose GOLD (generation by off-policy\nlearning from demonstrations): an easy-to-optimize algorithm that learns from\nthe demonstrations by importance weighting. Intuitively, GOLD upweights\nconfident tokens and downweights unconfident ones in the reference during\ntraining, avoiding optimization issues faced by prior RL approaches that rely\non online data collection. According to both automatic and human evaluation,\nmodels trained by GOLD outperform those trained by MLE and policy gradient on\nsummarization, question generation, and machine translation. Further, our\nmodels are less sensitive to decoding algorithms and alleviate exposure bias.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:58:37 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:43:28 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Pang", "Richard Yuanzhe", ""], ["He", "He", ""]]}, {"id": "2009.07842", "submitter": "Sarthak Consul", "authors": "Kumar Ashutosh, Sarthak Consul, Bhishma Dedhia, Parthasarathi\n  Khirwadkar, Sahil Shah, Shivaram Kalyanakrishnan", "title": "Lower Bounds for Policy Iteration on Multi-action MDPs", "comments": "8 pages, 3 diagrams, 2 tables. Paper in IEEE CDC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy Iteration (PI) is a classical family of algorithms to compute an\noptimal policy for any given Markov Decision Problem (MDP). The basic idea in\nPI is to begin with some initial policy and to repeatedly update the policy to\none from an improving set, until an optimal policy is reached. Different\nvariants of PI result from the (switching) rule used for improvement. An\nimportant theoretical question is how many iterations a specified PI variant\nwill take to terminate as a function of the number of states $n$ and the number\nof actions $k$ in the input MDP. While there has been considerable progress\ntowards upper-bounding this number, there are fewer results on lower bounds. In\nparticular, existing lower bounds primarily focus on the special case of $k =\n2$ actions. We devise lower bounds for $k \\geq 3$. Our main result is that a\nparticular variant of PI can take $\\Omega(k^{n/2})$ iterations to terminate. We\nalso generalise existing constructions on $2$-action MDPs to scale lower bounds\nby a factor of $k$ for some common deterministic variants of PI, and by\n$\\log(k)$ for corresponding randomised variants.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:59:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Ashutosh", "Kumar", ""], ["Consul", "Sarthak", ""], ["Dedhia", "Bhishma", ""], ["Khirwadkar", "Parthasarathi", ""], ["Shah", "Sahil", ""], ["Kalyanakrishnan", "Shivaram", ""]]}, {"id": "2009.07879", "submitter": "Qiong Liu", "authors": "Qiong Liu, Yanxia Zhang", "title": "Using Sensory Time-cue to enable Unsupervised Multimodal Meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data from IoT (Internet of Things) sensors become ubiquitous,\nstate-of-the-art machine learning algorithms face many challenges on directly\nusing sensor data. To overcome these challenges, methods must be designed to\nlearn directly from sensors without manual annotations. This paper introduces\nSensory Time-cue for Unsupervised Meta-learning (STUM). Different from\ntraditional learning approaches that either heavily depend on labels or on\ntime-independent feature extraction assumptions, such as Gaussian distribution\nfeatures, the STUM system uses time relation of inputs to guide the feature\nspace formation within and across modalities. The fact that STUM learns from a\nvariety of small tasks may put this method in the camp of Meta-Learning.\nDifferent from existing Meta-Learning approaches, STUM learning tasks are\ncomposed within and across multiple modalities based on time-cue co-exist with\nthe IoT streaming data. In an audiovisual learning example, because consecutive\nvisual frames usually comprise the same object, this approach provides a unique\nway to organize features from the same object together. The same method can\nalso organize visual object features with the object's spoken-name features\ntogether if the spoken name is presented with the object at about the same\ntime. This cross-modality feature organization may further help the\norganization of visual features that belong to similar objects but acquired at\ndifferent location and time. Promising results are achieved through\nevaluations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:18:49 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Liu", "Qiong", ""], ["Zhang", "Yanxia", ""]]}, {"id": "2009.07888", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, and Jiayu Zhou", "title": "Transfer Learning in Deep Reinforcement Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is a key technique to address sequential\ndecision-making problems and is crucial to realize advanced artificial\nintelligence. Recent years have witnessed remarkable progress in RL by virtue\nof the fast development of deep neural networks. Along with the promising\nprospects of RL in numerous domains, such as robotics and game-playing,\ntransfer learning has arisen as an important technique to tackle various\nchallenges faced by RL, by transferring knowledge from external expertise to\naccelerate the learning process. In this survey, we systematically investigate\nthe recent progress of transfer learning approaches in the context of deep\nreinforcement learning. Specifically, we provide a framework for categorizing\nthe state-of-the-art transfer learning approaches, under which we analyze their\ngoals, methodologies, compatible RL backbones, and practical applications. We\nalso draw connections between transfer learning and other relevant topics from\nthe RL perspective and explore their potential challenges as well as open\nquestions that await future research progress.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:38:54 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 02:22:54 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 23:28:31 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 16:46:02 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2009.07896", "submitter": "Narine Kokhlikyan", "authors": "Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal\n  Alsallakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos\n  Araya, Siqi Yan, Orion Reblitz-Richardson", "title": "Captum: A unified and generic model interpretability library for PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel, unified, open-source model\ninterpretability library for PyTorch [12]. The library contains generic\nimplementations of a number of gradient and perturbation-based attribution\nalgorithms, also known as feature, neuron and layer importance algorithms, as\nwell as a set of evaluation metrics for these algorithms. It can be used for\nboth classification and non-classification models including graph-structured\nmodels built on Neural Networks (NN). In this paper we give a high-level\noverview of supported attribution algorithms and show how to perform\nmemory-efficient and scalable computations. We emphasize that the three main\ncharacteristics of the library are multimodality, extensibility and ease of\nuse. Multimodality supports different modality of inputs such as image, text,\naudio or video. Extensibility allows adding new algorithms and features. The\nlibrary is also designed for easy understanding and use. Besides, we also\nintroduce an interactive visualization tool called Captum Insights that is\nbuilt on top of Captum library and allows sample-based model debugging and\nvisualization using feature importance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:57:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Kokhlikyan", "Narine", ""], ["Miglani", "Vivek", ""], ["Martin", "Miguel", ""], ["Wang", "Edward", ""], ["Alsallakh", "Bilal", ""], ["Reynolds", "Jonathan", ""], ["Melnikov", "Alexander", ""], ["Kliushkina", "Natalia", ""], ["Araya", "Carlos", ""], ["Yan", "Siqi", ""], ["Reblitz-Richardson", "Orion", ""]]}, {"id": "2009.07899", "submitter": "Harikesh Nair", "authors": "Tong Geng, Xiliang Lin, Harikesh S. Nair, Jun Hao, Bin Xiang, Shurui\n  Fan", "title": "Comparison Lift: Bandit-based Experimentation System for Online\n  Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison Lift is an experimentation-as-a-service (EaaS) application for\ntesting online advertising audiences and creatives at JD.com. Unlike many other\nEaaS tools that focus primarily on fixed sample A/B testing, Comparison Lift\ndeploys a custom bandit-based experimentation algorithm. The advantages of the\nbandit-based approach are two-fold. First, it aligns the randomization induced\nin the test with the advertiser's goals from testing. Second, by adapting\nexperimental design to information acquired during the test, it reduces\nsubstantially the cost of experimentation to the advertiser. Since launch in\nMay 2019, Comparison Lift has been utilized in over 1,500 experiments. We\nestimate that utilization of the product has helped increase click-through\nrates of participating advertising campaigns by 46% on average. We estimate\nthat the adaptive design in the product has generated 27% more clicks on\naverage during testing compared to a fixed sample A/B design. Both suggest\nsignificant value generation and cost savings to advertisers from the product.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:08:44 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Geng", "Tong", ""], ["Lin", "Xiliang", ""], ["Nair", "Harikesh S.", ""], ["Hao", "Jun", ""], ["Xiang", "Bin", ""], ["Fan", "Shurui", ""]]}, {"id": "2009.07907", "submitter": "Sara Alaee", "authors": "Sara Alaee, Kaveh Kamgar, Eamonn Keogh", "title": "Matrix Profile XXII: Exact Discovery of Time Series Motifs under DTW", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, time series motif discovery has emerged as a useful\nprimitive for many downstream analytical tasks, including clustering,\nclassification, rule discovery, segmentation, and summarization. In parallel,\nthere has been an increased understanding that Dynamic Time Warping (DTW) is\nthe best time series similarity measure in a host of settings. Surprisingly\nhowever, there has been virtually no work on using DTW to discover motifs. The\nmost obvious explanation of this is the fact that both motif discovery and the\nuse of DTW can be computationally challenging, and the current best mechanisms\nto address their lethargy are mutually incompatible. In this work, we present\nthe first scalable exact method to discover time series motifs under DTW. Our\nmethod automatically performs the best trade-off between time-to-compute and\ntightness-of-lower-bounds for a novel hierarchy of lower bounds representation\nwe introduce. We show that under realistic settings, our algorithm can\nadmissibly prune up to 99.99% of the DTW computations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:35:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Alaee", "Sara", ""], ["Kamgar", "Kaveh", ""], ["Keogh", "Eamonn", ""]]}, {"id": "2009.07928", "submitter": "Felix K\\\"oster", "authors": "Felix K\\\"oster, Serhiy Yanchuk, Kathy L\\\"udge", "title": "Insight into Delay Based Reservoir Computing via Eigenvalue Analysis", "comments": "New Journal Submission", "journal-ref": null, "doi": "10.1088/2515-7647/abf237", "report-no": null, "categories": "cs.LG math.DS nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a profound insight into the computation capability of\ndelay-based reservoir computing via an eigenvalue analysis. We concentrate on\nthe task-independent memory capacity to quantify the reservoir performance and\ncompare these with the eigenvalue spectrum of the dynamical system. We show\nthat these two quantities are deeply connected, and thus the reservoir\ncomputing performance is predictable by analyzing the small signal response of\nthe reservoir. Our results suggest that any dynamical system used as a\nreservoir can be analyzed in this way. We apply our method exemplarily to a\nphotonic laser system with feedback and compare the numerically computed recall\ncapabilities with the eigenvalue spectrum. Optimal performance is found for a\nsystem with the eigenvalues having real parts close to zero and off-resonant\nimaginary parts.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 20:41:47 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:46:14 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:25:02 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["K\u00f6ster", "Felix", ""], ["Yanchuk", "Serhiy", ""], ["L\u00fcdge", "Kathy", ""]]}, {"id": "2009.07938", "submitter": "Zijun Cui", "authors": "Zijun Cui, Pavan Kapanipathi, Kartik Talamadupula, Tian Gao, Qiang Ji", "title": "Type-augmented Relation Prediction in Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) are of great importance to many real world\napplications, but they generally suffer from incomplete information in the form\nof missing relations between entities. Knowledge graph completion (also known\nas relation prediction) is the task of inferring missing facts given existing\nones. Most of the existing work is proposed by maximizing the likelihood of\nobserved instance-level triples. Not much attention, however, is paid to the\nontological information, such as type information of entities and relations. In\nthis work, we propose a type-augmented relation prediction (TaRP) method, where\nwe apply both the type information and instance-level information for relation\nprediction. In particular, type information and instance-level information are\nencoded as prior probabilities and likelihoods of relations respectively, and\nare combined by following Bayes' rule. Our proposed TaRP method achieves\nsignificantly better performance than state-of-the-art methods on four\nbenchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,\nwe show that TaRP achieves significantly improved data efficiency. More\nimportantly, the type information extracted from a specific dataset can\ngeneralize well to other datasets through the proposed TaRP model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:14:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 01:59:56 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 22:57:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Cui", "Zijun", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""], ["Gao", "Tian", ""], ["Ji", "Qiang", ""]]}, {"id": "2009.07943", "submitter": "Kouame Kouassi", "authors": "Kouame Hermann Kouassi and Deshendran Moodley", "title": "An analysis of deep neural networks for predicting trends in time series\n  data", "comments": null, "journal-ref": "SACAIR CCIS Springer proceedings, 2021 Feb", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a hybrid Deep Neural Network (DNN) algorithm, TreNet was proposed\nfor predicting trends in time series data. While TreNet was shown to have\nsuperior performance for trend prediction to other DNN and traditional ML\napproaches, the validation method used did not take into account the sequential\nnature of time series data sets and did not deal with model update. In this\nresearch we replicated the TreNet experiments on the same data sets using a\nwalk-forward validation method and tested our optimal model over multiple\nindependent runs to evaluate model stability. We compared the performance of\nthe hybrid TreNet algorithm, on four data sets to vanilla DNN algorithms that\ntake in point data, and also to traditional ML algorithms. We found that in\ngeneral TreNet still performs better than the vanilla DNN models, but not on\nall data sets as reported in the original TreNet study. This study highlights\nthe importance of using an appropriate validation method and evaluating model\nstability for evaluating and developing machine learning models for trend\nprediction in time series data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:24:20 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 20:44:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kouassi", "Kouame Hermann", ""], ["Moodley", "Deshendran", ""]]}, {"id": "2009.07961", "submitter": "Qi Zhang", "authors": "Rishabh Gupta, Qi Zhang", "title": "Decomposition and Adaptive Sampling for Data-Driven Inverse Linear\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses inverse linear optimization where the goal is to infer\nthe unknown cost vector of a linear program. Specifically, we consider the\ndata-driven setting in which the available data are noisy observations of\noptimal solutions that correspond to different instances of the linear program.\nWe introduce a new formulation of the problem that, compared to other existing\nmethods, allows the recovery of a less restrictive and generally more\nappropriate admissible set of cost estimates. It can be shown that this inverse\noptimization problem yields a finite number of solutions, and we develop an\nexact two-phase algorithm to determine all such solutions. Moreover, we propose\nan efficient decomposition algorithm to solve large instances of the problem.\nThe algorithm extends naturally to an online learning environment where it can\nbe used to provide quick updates of the cost estimate as new data becomes\navailable over time. For the online setting, we further develop an effective\nadaptive sampling strategy that guides the selection of the next samples. The\nefficacy of the proposed methods is demonstrated in computational experiments\ninvolving two applications, customer preference learning and cost estimation\nfor production planning. The results show significant reductions in computation\nand sampling efforts.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 22:25:31 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Gupta", "Rishabh", ""], ["Zhang", "Qi", ""]]}, {"id": "2009.07964", "submitter": "Zhijing Jin", "authors": "Xiaoyu Xing, Zhijing Jin, Di Jin, Bingning Wang, Qi Zhang, and\n  Xuanjing Huang", "title": "Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based\n  Sentiment Analysis", "comments": "EMNLP 2020, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards\na specific aspect in the text. However, existing ABSA test sets cannot be used\nto probe whether a model can distinguish the sentiment of the target aspect\nfrom the non-target aspects. To solve this problem, we develop a simple but\neffective approach to enrich ABSA test sets. Specifically, we generate new\nexamples to disentangle the confounding sentiments of the non-target aspects\nfrom the target aspect's sentiment. Based on the SemEval 2014 dataset, we\nconstruct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the\naspect robustness of ABSA models. Over 92% data of ARTS show high fluency and\ndesired sentiment on all aspects by human evaluation. Using ARTS, we analyze\nthe robustness of nine ABSA models, and observe, surprisingly, that their\naccuracy drops by up to 69.73%. We explore several ways to improve aspect\nrobustness, and find that adversarial training can improve models' performance\non ARTS by up to 32.85%. Our code and new test set are available at\nhttps://github.com/zhijing-jin/ARTS_TestSet\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 22:38:18 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 05:36:10 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 15:35:36 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 08:19:36 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Xing", "Xiaoyu", ""], ["Jin", "Zhijing", ""], ["Jin", "Di", ""], ["Wang", "Bingning", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2009.07971", "submitter": "Esteban Vilca", "authors": "Esteban Vilca, Liang Zhao", "title": "A Network-Based High-Level Data Classification Algorithm Using\n  Betweenness Centrality", "comments": null, "journal-ref": null, "doi": "10.5753/eniac.2020.12128", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data classification is a major machine learning paradigm, which has been\nwidely applied to solve a large number of real-world problems. Traditional data\nclassification techniques consider only physical features (e.g., distance,\nsimilarity, or distribution) of the input data. For this reason, those are\ncalled \\textit{low-level} classification. On the other hand, the human (animal)\nbrain performs both low and high orders of learning and it has a facility in\nidentifying patterns according to the semantic meaning of the input data. Data\nclassification that considers not only physical attributes but also the pattern\nformation is referred to as \\textit{high-level} classification. Several\nhigh-level classification techniques have been developed, which make use of\ncomplex networks to characterize data patterns and have obtained promising\nresults. In this paper, we propose a pure network-based high-level\nclassification technique that uses the betweenness centrality measure. We test\nthis model in nine different real datasets and compare it with other nine\ntraditional and well-known classification models. The results show us a\ncompetent classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 23:14:13 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Vilca", "Esteban", ""], ["Zhao", "Liang", ""]]}, {"id": "2009.07974", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "Analysis of Generalizability of Deep Neural Networks Based on the\n  Complexity of Decision Boundary", "comments": "7 pages, 11 figures. Accepted by ICMLA 2020", "journal-ref": "19th IEEE International Conference on Machine Learning and\n  Applications (ICMLA), 2020, pp. 101-106", "doi": "10.1109/ICMLA51294.2020.00025", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For supervised learning models, the analysis of generalization ability\n(generalizability) is vital because the generalizability expresses how well a\nmodel will perform on unseen data. Traditional generalization methods, such as\nthe VC dimension, do not apply to deep neural network (DNN) models. Thus, new\ntheories to explain the generalizability of DNNs are required. In this study,\nwe hypothesize that the DNN with a simpler decision boundary has better\ngeneralizability by the law of parsimony (Occam's Razor). We create the\ndecision boundary complexity (DBC) score to define and measure the complexity\nof decision boundary of DNNs. The idea of the DBC score is to generate data\npoints (called adversarial examples) on or near the decision boundary. Our new\napproach then measures the complexity of the boundary using the entropy of\neigenvalues of these data. The method works equally well for high-dimensional\ndata. We use training data and the trained model to compute the DBC score. And,\nthe ground truth for model's generalizability is its test accuracy. Experiments\nbased on the DBC score have verified our hypothesis. The DBC is shown to\nprovide an effective method to measure the complexity of a decision boundary\nand gives a quantitative measure of the generalizability of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 23:25:52 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2009.07988", "submitter": "Xiang Deng", "authors": "Xiang Deng and Zhongfei (Mark) Zhang", "title": "Deep Collective Learning: Learning Optimal Inputs and Weights Jointly in\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well observed that in deep learning and computer vision literature,\nvisual data are always represented in a manually designed coding scheme (eg.,\nRGB images are represented as integers ranging from 0 to 255 for each channel)\nwhen they are input to an end-to-end deep neural network (DNN) for any learning\ntask. We boldly question whether the manually designed inputs are good for DNN\ntraining for different tasks and study whether the input to a DNN can be\noptimally learned end-to-end together with learning the weights of the DNN. In\nthis paper, we propose the paradigm of {\\em deep collective learning} which\naims to learn the weights of DNNs and the inputs to DNNs simultaneously for\ngiven tasks. We note that collective learning has been implicitly but widely\nused in natural language processing while it has almost never been studied in\ncomputer vision. Consequently, we propose the lookup vision networks\n(Lookup-VNets) as a solution to deep collective learning in computer vision.\nThis is achieved by associating each color in each channel with a vector in\nlookup tables. As learning inputs in computer vision has almost never been\nstudied in the existing literature, we explore several aspects of this question\nthrough varieties of experiments on image classification tasks. Experimental\nresults on four benchmark datasets, i.e., CIFAR-10, CIFAR-100, Tiny ImageNet,\nand ImageNet (ILSVRC2012) have shown several surprising characteristics of\nLookup-VNets and have demonstrated the advantages and promise of Lookup-VNets\nand deep collective learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:33:04 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Deng", "Xiang", "", "Mark"], ["Zhongfei", "", "", "Mark"], ["Zhang", "", ""]]}, {"id": "2009.07994", "submitter": "Yanlun Tu", "authors": "Yanlun Tu, Jianxing Feng, Yang Yang", "title": "AAG: Self-Supervised Representation Learning by Auxiliary Augmentation\n  with GNT-Xent Loss", "comments": "8 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning is an emerging research topic for its\npowerful capacity in learning with unlabeled data. As a mainstream\nself-supervised learning method, augmentation-based contrastive learning has\nachieved great success in various computer vision tasks that lack manual\nannotations. Despite current progress, the existing methods are often limited\nby extra cost on memory or storage, and their performance still has large room\nfor improvement. Here we present a self-supervised representation learning\nmethod, namely AAG, which is featured by an auxiliary augmentation strategy and\nGNT-Xent loss. The auxiliary augmentation is able to promote the performance of\ncontrastive learning by increasing the diversity of images. The proposed\nGNT-Xent loss enables a steady and fast training process and yields competitive\naccuracy. Experiment results demonstrate the superiority of AAG to previous\nstate-of-the-art methods on CIFAR10, CIFAR100, and SVHN. Especially, AAG\nachieves 94.5% top-1 accuracy on CIFAR10 with batch size 64, which is 0.5%\nhigher than the best result of SimCLR with batch size 1024.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:54:35 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:15:20 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Tu", "Yanlun", ""], ["Feng", "Jianxing", ""], ["Yang", "Yang", ""]]}, {"id": "2009.07999", "submitter": "George Pu", "authors": "Yanlin Zhou, George Pu, Xiyao Ma, Xiaolin Li, Dapeng Wu", "title": "Distilled One-Shot Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current federated learning algorithms take tens of communication rounds\ntransmitting unwieldy model weights under ideal circumstances and hundreds when\ndata is poorly distributed. Inspired by recent work on dataset distillation and\ndistributed one-shot learning, we propose Distilled One-Shot Federated Learning\n(DOSFL) to significantly reduce the communication cost while achieving\ncomparable performance. In just one round, each client distills their private\ndataset, sends the synthetic data (e.g. images or sentences) to the server, and\ncollectively trains a global model. The distilled data look like noise and are\nonly useful to the specific model weights, i.e., become useless after the model\nupdates. With this weight-less and gradient-less design, the total\ncommunication cost of DOSFL is up to three orders of magnitude less than FedAvg\nwhile preserving between 93% to 99% performance of a centralized counterpart.\nAfterwards, clients could switch to traditional methods such as FedAvg to\nfinetune the last few percent to fit personalized local models with local\ndatasets. Through comprehensive experiments, we show the accuracy and\ncommunication performance of DOSFL on both vision and language tasks with\ndifferent models including CNN, LSTM, Transformer, etc. We demonstrate that an\neavesdropping attacker cannot properly train a good model using the leaked\ndistilled data, without knowing the initial model weights. DOSFL serves as an\ninexpensive method to quickly converge on a performant pre-trained model with\nless than 0.1% communication cost of traditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:14:47 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 21:10:36 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 06:55:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhou", "Yanlin", ""], ["Pu", "George", ""], ["Ma", "Xiyao", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2009.08000", "submitter": "Albert Cheu", "authors": "Albert Cheu and Jonathan Ullman", "title": "The Limits of Pan Privacy and Shuffle Privacy for Learning and\n  Estimation", "comments": "Corrected a proof in the Appendix. Added a reference to parallel and\n  concurrent work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent wave of interest in intermediate trust models for\ndifferential privacy that eliminate the need for a fully trusted central data\ncollector, but overcome the limitations of local differential privacy. This\ninterest has led to the introduction of the shuffle model (Cheu et al.,\nEUROCRYPT 2019; Erlingsson et al., SODA 2019) and revisiting the pan-private\nmodel (Dwork et al., ITCS 2010). The message of this line of work is that, for\na variety of low-dimensional problems -- such as counts, means, and histograms\n-- these intermediate models offer nearly as much power as central differential\nprivacy. However, there has been considerably less success using these models\nfor high-dimensional learning and estimation problems. In this work, we show\nthat, for a variety of high-dimensional learning and estimation problems, both\nthe shuffle model and the pan-private model inherently incur an exponential\nprice in sample complexity relative to the central model. For example, we show\nthat, private agnostic learning of parity functions over $d$ bits requires\n$\\Omega(2^{d/2})$ samples in these models, and privately selecting the most\ncommon attribute from a set of $d$ choices requires $\\Omega(d^{1/2})$ samples,\nboth of which are exponential separations from the central model. Our work\ngives the first non-trivial lower bounds for these problems for both the\npan-private model and the general multi-message shuffle model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:15:55 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 17:22:28 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 19:05:20 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Cheu", "Albert", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2009.08016", "submitter": "Linhai Ma", "authors": "Liang Liang, Linhai Ma, Linchen Qian, Jiasong Chen", "title": "An Algorithm for Out-Of-Distribution Attack to Neural Network Encoder", "comments": "26 pages, 25 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs), especially convolutional neural networks, have\nachieved superior performance on image classification tasks. However, such\nperformance is only guaranteed if the input to a trained model is similar to\nthe training samples, i.e., the input follows the probability distribution of\nthe training set. Out-Of-Distribution (OOD) samples do not follow the\ndistribution of training set, and therefore the predicted class labels on OOD\nsamples become meaningless. Classification-based methods have been proposed for\nOOD detection; however, in this study we show that this type of method has no\ntheoretical guarantee and is practically breakable by our OOD Attack algorithm\nbecause of dimensionality reduction in the DNN models. We also show that Glow\nlikelihood-based OOD detection is breakable as well.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:10:36 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 20:47:08 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 22:31:12 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 17:58:34 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Liang", "Liang", ""], ["Ma", "Linhai", ""], ["Qian", "Linchen", ""], ["Chen", "Jiasong", ""]]}, {"id": "2009.08026", "submitter": "R. Kenny Jones", "authors": "R. Kenny Jones, Theresa Barton, Xianghao Xu, Kai Wang, Ellen Jiang,\n  Paul Guerrero, Niloy J. Mitra, and Daniel Ritchie", "title": "ShapeAssembly: Learning to Generate Programs for 3D Shape Structure\n  Synthesis", "comments": "Accepted to Siggraph Asia 2020; project page:\n  https://rkjones4.github.io/shapeAssembly.html", "journal-ref": null, "doi": "10.1145/3414685.3417812", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually authoring 3D shapes is difficult and time consuming; generative\nmodels of 3D shapes offer compelling alternatives. Procedural representations\nare one such possibility: they offer high-quality and editable results but are\ndifficult to author and often produce outputs with limited diversity. On the\nother extreme are deep generative models: given enough data, they can learn to\ngenerate any class of shape but their outputs have artifacts and the\nrepresentation is not editable. In this paper, we take a step towards achieving\nthe best of both worlds for novel 3D shape synthesis. We propose ShapeAssembly,\na domain-specific \"assembly-language\" for 3D shape structures. ShapeAssembly\nprograms construct shapes by declaring cuboid part proxies and attaching them\nto one another, in a hierarchical and symmetrical fashion. Its functions are\nparameterized with free variables, so that one program structure is able to\ncapture a family of related shapes. We show how to extract ShapeAssembly\nprograms from existing shape structures in the PartNet dataset. Then we train a\ndeep generative model, a hierarchical sequence VAE, that learns to write novel\nShapeAssembly programs. The program captures the subset of variability that is\ninterpretable and editable. The deep model captures correlations across shape\ncollections that are hard to express procedurally. We evaluate our approach by\ncomparing shapes output by our generated programs to those from other recent\nshape structure synthesis models. We find that our generated shapes are more\nplausible and physically-valid than those of other methods. Additionally, we\nassess the latent spaces of these models, and find that ours is better\nstructured and produces smoother interpolations. As an application, we use our\ngenerative model and differentiable program interpreter to infer and fit shape\nprograms to unstructured geometry, such as point clouds.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:26:45 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Jones", "R. Kenny", ""], ["Barton", "Theresa", ""], ["Xu", "Xianghao", ""], ["Wang", "Kai", ""], ["Jiang", "Ellen", ""], ["Guerrero", "Paul", ""], ["Mitra", "Niloy J.", ""], ["Ritchie", "Daniel", ""]]}, {"id": "2009.08039", "submitter": "Jaewoong Choi", "authors": "Jaewoong Choi, Geonho Hwang, Myungjoo Kang", "title": "Discond-VAE: Disentangling Continuous Factors from the Discrete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real-world data, there are common variations shared by all classes\n(e.g. category label) and exclusive variations of each class. We propose a\nvariant of VAE capable of disentangling both of these variations. To represent\nthese generative factors of data, we introduce two sets of continuous latent\nvariables, private variable and public variable. Our proposed framework models\nthe private variable as a Mixture of Gaussian and the public variable as a\nGaussian, respectively. Each mode of the private variable is responsible for a\nclass of the discrete variable.\n  Most of the previous attempts to integrate the discrete generative factors to\ndisentanglement assume statistical independence between the continuous and\ndiscrete variables. Our proposed model, which we call Discond-VAE, DISentangles\nthe class-dependent CONtinuous factors from the Discrete factors by introducing\nthe private variables. The experiments show that Discond-VAE can discover the\nprivate and public factors from data. Moreover, even under the dataset with\nonly public factors, Discond-VAE does not fail and adapts the private variables\nto represent the public factors.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:19:03 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 01:45:45 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Choi", "Jaewoong", ""], ["Hwang", "Geonho", ""], ["Kang", "Myungjoo", ""]]}, {"id": "2009.08044", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Nick Gonsalves, Christina Lee, Anand Raman, Brendan\n  Walsh, Siddhartha Prasad, Dalitso Banda, Lucy Zhang, Lei Zhang, William T.\n  Freeman", "title": "Large-Scale Intelligent Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deploying Machine Learning (ML) algorithms within databases is a challenge\ndue to the varied computational footprints of modern ML algorithms and the\nmyriad of database technologies each with its own restrictive syntax. We\nintroduce an Apache Spark-based micro-service orchestration framework that\nextends database operations to include web service primitives. Our system can\norchestrate web services across hundreds of machines and takes full advantage\nof cluster, thread, and asynchronous parallelism. Using this framework, we\nprovide large scale clients for intelligent services such as speech, vision,\nsearch, anomaly detection, and text analysis. This allows users to integrate\nready-to-use intelligence into any datastore with an Apache Spark connector. To\neliminate the majority of overhead from network communication, we also\nintroduce a low-latency containerized version of our architecture. Finally, we\ndemonstrate that the services we investigate are competitive on a variety of\nbenchmarks, and present two applications of this framework to create\nintelligent search engines, and real-time auto race analytics systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:38:28 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 20:51:47 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Hamilton", "Mark", ""], ["Gonsalves", "Nick", ""], ["Lee", "Christina", ""], ["Raman", "Anand", ""], ["Walsh", "Brendan", ""], ["Prasad", "Siddhartha", ""], ["Banda", "Dalitso", ""], ["Zhang", "Lucy", ""], ["Zhang", "Lei", ""], ["Freeman", "William T.", ""]]}, {"id": "2009.08052", "submitter": "Chang Liu", "authors": "Chang Liu, Huichu Zhang, Weinan Zhang, Guanjie Zheng, Yong Yu", "title": "GeneraLight: Improving Environment Generalization of Traffic Signal\n  Control via Meta Reinforcement Learning", "comments": "Proceedings of the 29th ACM International on Conference on\n  Information and Knowledge Management (CIKM). ACM, 2020", "journal-ref": null, "doi": "10.1145/3340531.3411859", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy traffic congestion problem has always been a concern for modern\ncities. To alleviate traffic congestion, researchers use reinforcement learning\n(RL) to develop better traffic signal control (TSC) algorithms in recent years.\nHowever, most RL models are trained and tested in the same traffic flow\nenvironment, which results in a serious overfitting problem. Since the traffic\nflow environment in the real world keeps varying, these models can hardly be\napplied due to the lack of generalization ability. Besides, the limited number\nof accessible traffic flow data brings extra difficulty in testing the\ngeneralization ability of the models. In this paper, we design a novel traffic\nflow generator based on Wasserstein generative adversarial network to generate\nsufficient diverse and quality traffic flows and use them to build proper\ntraining and testing environments. Then we propose a meta-RL TSC framework\nGeneraLight to improve the generalization ability of TSC models. GeneraLight\nboosts the generalization performance by combining the idea of flow clustering\nand model-agnostic meta-learning. We conduct extensive experiments on multiple\nreal-world datasets to show the superior performance of GeneraLight on\ngeneralizing to different traffic flows.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:14:28 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Liu", "Chang", ""], ["Zhang", "Huichu", ""], ["Zhang", "Weinan", ""], ["Zheng", "Guanjie", ""], ["Yu", "Yong", ""]]}, {"id": "2009.08058", "submitter": "Shao-Yuan Lo", "authors": "Shao-Yuan Lo, Vishal M. Patel", "title": "MultAV: Multiplicative Adversarial Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of adversarial machine learning research focuses on additive\nthreat models, which add adversarial perturbation to input data. On the other\nhand, unlike image recognition problems, only a handful of threat models have\nbeen explored in the video domain. In this paper, we propose a novel\nadversarial attack against video recognition models, Multiplicative Adversarial\nVideos (MultAV), which imposes perturbation on video data by multiplication.\nMultAV has different noise distributions to the additive counterparts and thus\nchallenges the defense methods tailored to resisting additive attacks.\nMoreover, it can be generalized to not only Lp-norm attacks with a new\nadversary constraint called ratio bound, but also different types of physically\nrealizable attacks. Experimental results show that the model adversarially\ntrained against additive attack is less robust to MultAV.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:34:39 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lo", "Shao-Yuan", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2009.08061", "submitter": "Aounon Kumar", "authors": "Aounon Kumar, Alexander Levine, Soheil Feizi, Tom Goldstein", "title": "Certifying Confidence via Randomized Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing has been shown to provide good certified-robustness\nguarantees for high-dimensional classification problems. It uses the\nprobabilities of predicting the top two most-likely classes around an input\npoint under a smoothing distribution to generate a certified radius for a\nclassifier's prediction. However, most smoothing methods do not give us any\ninformation about the confidence with which the underlying classifier (e.g.,\ndeep neural network) makes a prediction. In this work, we propose a method to\ngenerate certified radii for the prediction confidence of the smoothed\nclassifier. We consider two notions for quantifying confidence: average\nprediction score of a class and the margin by which the average prediction\nscore of one class exceeds that of another. We modify the Neyman-Pearson lemma\n(a key theorem in randomized smoothing) to design a procedure for computing the\ncertified radius where the confidence is guaranteed to stay above a certain\nthreshold. Our experimental results on CIFAR-10 and ImageNet datasets show that\nusing information about the distribution of the confidence scores allows us to\nachieve a significantly better certified radius than ignoring it. Thus, we\ndemonstrate that extra information about the base classifier at the input point\ncan help improve certified guarantees for the smoothed classifier. Code for the\nexperiments is available at https://github.com/aounon/cdf-smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:37:26 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 21:15:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kumar", "Aounon", ""], ["Levine", "Alexander", ""], ["Feizi", "Soheil", ""], ["Goldstein", "Tom", ""]]}, {"id": "2009.08062", "submitter": "Ori Katz", "authors": "Ori Katz, Roy R. Lederman and Ronen Talmon", "title": "Spectral Flow on the Manifold of SPD Matrices for Multimodal Data\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider data acquired by multimodal sensors capturing\ncomplementary aspects and features of a measured phenomenon. We focus on a\nscenario in which the measurements share mutual sources of variability but\nmight also be contaminated by other measurement-specific sources such as\ninterferences or noise. Our approach combines manifold learning, which is a\nclass of nonlinear data-driven dimension reduction methods, with the well-known\nRiemannian geometry of symmetric and positive-definite (SPD) matrices. Manifold\nlearning typically includes the spectral analysis of a kernel built from the\nmeasurements. Here, we take a different approach, utilizing the Riemannian\ngeometry of the kernels. In particular, we study the way the spectrum of the\nkernels changes along geodesic paths on the manifold of SPD matrices. We show\nthat this change enables us, in a purely unsupervised manner, to derive a\ncompact, yet informative, description of the relations between the\nmeasurements, in terms of their underlying components. Based on this result, we\npresent new algorithms for extracting the common latent components and for\nidentifying common and measurement-specific components.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:38:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Katz", "Ori", ""], ["Lederman", "Roy R.", ""], ["Talmon", "Ronen", ""]]}, {"id": "2009.08063", "submitter": "Ruixuan Liu", "authors": "Ruixuan Liu, Yang Cao, Hong Chen, Ruoyang Guo, Masatoshi Yoshikawa", "title": "FLAME: Differentially Private Federated Learning in the Shuffle Model", "comments": "accepted by AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a promising machine learning paradigm that enables\nthe analyzer to train a model without collecting users' raw data. To ensure\nusers' privacy, differentially private federated learning has been intensively\nstudied. The existing works are mainly based on the \\textit{curator model} or\n\\textit{local model} of differential privacy. However, both of them have pros\nand cons. The curator model allows greater accuracy but requires a trusted\nanalyzer. In the local model where users randomize local data before sending\nthem to the analyzer, a trusted analyzer is not required but the accuracy is\nlimited. In this work, by leveraging the \\textit{privacy amplification} effect\nin the recently proposed shuffle model of differential privacy, we achieve the\nbest of two worlds, i.e., accuracy in the curator model and strong privacy\nwithout relying on any trusted party. We first propose an FL framework in the\nshuffle model and a simple protocol (SS-Simple) extended from existing work. We\nfind that SS-Simple only provides an insufficient privacy amplification effect\nin FL since the dimension of the model parameter is quite large. To solve this\nchallenge, we propose an enhanced protocol (SS-Double) to increase the privacy\namplification effect by subsampling. Furthermore, for boosting the utility when\nthe model size is greater than the user population, we propose an advanced\nprotocol (SS-Topk) with gradient sparsification techniques. We also provide\ntheoretical analysis and numerical evaluations of the privacy amplification of\nthe proposed protocols. Experiments on real-world dataset validate that SS-Topk\nimproves the testing accuracy by 60.7\\% than the local model based FL.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:44:27 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 02:40:56 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 05:55:16 GMT"}, {"version": "v4", "created": "Sat, 20 Mar 2021 09:05:39 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Liu", "Ruixuan", ""], ["Cao", "Yang", ""], ["Chen", "Hong", ""], ["Guo", "Ruoyang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2009.08065", "submitter": "Zhenglun Kong", "authors": "Bingbing Li, Zhenglun Kong, Tianyun Zhang, Ji Li, Zhengang Li, Hang\n  Liu, Caiwen Ding", "title": "Efficient Transformer-based Large Scale Language Representations using\n  Hardware-friendly Block Structured Pruning", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained large-scale language models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. However, the limited\nweight storage and computational speed on hardware platforms have impeded the\npopularity of pre-trained models, especially in the era of edge computing. In\nthis work, we propose an efficient transformer-based large-scale language\nrepresentation using hardware-friendly block structure pruning. We incorporate\nthe reweighted group Lasso into block-structured pruning for optimization.\nBesides the significantly reduced weight storage and computation, the proposed\napproach achieves high compression rates. Experimental results on different\nmodels (BERT, RoBERTa, and DistilBERT) on the General Language Understanding\nEvaluation (GLUE) benchmark tasks show that we achieve up to 5.0x with zero or\nminor accuracy degradation on certain task(s). Our proposed method is also\northogonal to existing compact pre-trained language models such as DistilBERT\nusing knowledge distillation, since a further 1.79x average compression rate\ncan be achieved on top of DistilBERT with zero or minor accuracy degradation.\nIt is suitable to deploy the final compressed model on resource-constrained\nedge devices.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:45:47 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 20:09:04 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 19:14:32 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2020 22:13:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Li", "Bingbing", ""], ["Kong", "Zhenglun", ""], ["Zhang", "Tianyun", ""], ["Li", "Ji", ""], ["Li", "Zhengang", ""], ["Liu", "Hang", ""], ["Ding", "Caiwen", ""]]}, {"id": "2009.08072", "submitter": "Nhat Tran", "authors": "Nhat Tran, Jean Gao", "title": "Layer-stacked Attention for Heterogeneous Network Embedding", "comments": "Technical appendix in last pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The heterogeneous network is a robust data abstraction that can model\nentities of different types interacting in various ways. Such heterogeneity\nbrings rich semantic information but presents nontrivial challenges in\naggregating the heterogeneous relationships between objects - especially those\nof higher-order indirect relations. Recent graph neural network approaches for\nrepresentation learning on heterogeneous networks typically employ the\nattention mechanism, which is often only optimized for predictions based on\ndirect links. Furthermore, even though most deep learning methods can aggregate\nhigher-order information by building deeper models, such a scheme can diminish\nthe degree of interpretability. To overcome these challenges, we explore an\narchitecture - Layer-stacked ATTention Embedding (LATTE) - that automatically\ndecomposes higher-order meta relations at each layer to extract the relevant\nheterogeneous neighborhood structures for each node. Additionally, by\nsuccessively stacking layer representations, the learned node embedding offers\na more interpretable aggregation scheme for nodes of different types at\ndifferent neighborhood ranges. We conducted experiments on several benchmark\nheterogeneous network datasets. In both transductive and inductive node\nclassification tasks, LATTE can achieve state-of-the-art performance compared\nto existing approaches, all while offering a lightweight model. With extensive\nexperimental analyses and visualizations, the framework can demonstrate the\nability to extract informative insights on heterogeneous networks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 05:13:41 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tran", "Nhat", ""], ["Gao", "Jean", ""]]}, {"id": "2009.08092", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Yamini Bansal", "title": "Distributional Generalization: A New Kind of Generalization", "comments": "Co-first authors. V2: Intro shortened; no new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of generalization -- Distributional Generalization\n-- which roughly states that outputs of a classifier at train and test time are\nclose *as distributions*, as opposed to close in just their average error. For\nexample, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then\na ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as\ncats on the *test set* as well, while leaving other classes unaffected. This\nbehavior is not captured by classical generalization, which would only consider\nthe average error and not the distribution of errors over the input domain. Our\nformal conjectures, which are much more general than this example, characterize\nthe form of distributional generalization that can be expected in terms of\nproblem parameters: model architecture, training procedure, number of samples,\nand data distribution. We give empirical evidence for these conjectures across\na variety of domains in machine learning, including neural networks, kernel\nmachines, and decision trees. Our results thus advance our empirical\nunderstanding of interpolating classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:26:17 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 02:41:52 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Bansal", "Yamini", ""]]}, {"id": "2009.08093", "submitter": "Zhixiang Li", "authors": "Yuqi Meng, Ying Zhao, Zhixiang Li", "title": "An early prediction of covid-19 associated hospitalization surge using\n  deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global pandemic caused by COVID-19 affects our lives in all aspects. As\nof September 11, more than 28 million people have tested positive for COVID-19\ninfection, and more than 911,000 people have lost their lives in this virus\nbattle. Some patients can not receive appropriate medical treatment due the\nlimits of hospitalization volume and shortage of ICU beds. An estimated future\nhospitalization is critical so that medical resources can be allocated as\nneeded. In this study, we propose to use 4 recurrent neural networks to infer\nhospitalization change for the following week compared with the current week.\nResults show that sequence to sequence model with attention achieves a high\naccuracy of 0.938 and AUC of 0.850 in the hospitalization prediction. Our work\nhas the potential to predict the hospitalization need and send a warning to\nmedical providers and other stakeholders when a re-surge initializes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:26:50 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Meng", "Yuqi", ""], ["Zhao", "Ying", ""], ["Li", "Zhixiang", ""]]}, {"id": "2009.08097", "submitter": "Sumit Kumar Jha", "authors": "Sumit Kumar Jha, Susmit Jha, Rickard Ewetz, Sunny Raj, Alvaro\n  Velasquez, Laura L. Pullum, Ananthram Swami", "title": "An Extension of Fano's Inequality for Characterizing Model\n  Susceptibility to Membership Inference Attacks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be vulnerable to membership inference\nattacks wherein the attacker aims to detect whether specific input data were\nused to train the model. These attacks can potentially leak private or\nproprietary data. We present a new extension of Fano's inequality and employ it\nto theoretically establish that the probability of success for a membership\ninference attack on a deep neural network can be bounded using the mutual\ninformation between its inputs and its activations. This enables the use of\nmutual information to measure the susceptibility of a DNN model to membership\ninference attacks. In our empirical evaluation, we show that the correlation\nbetween the mutual information and the susceptibility of the DNN model to\nmembership inference attacks is 0.966, 0.996, and 0.955 for CIFAR-10, SVHN and\nGTSRB models, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:37:15 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Jha", "Sumit Kumar", ""], ["Jha", "Susmit", ""], ["Ewetz", "Rickard", ""], ["Raj", "Sunny", ""], ["Velasquez", "Alvaro", ""], ["Pullum", "Laura L.", ""], ["Swami", "Ananthram", ""]]}, {"id": "2009.08102", "submitter": "Giorgio Corani", "authors": "Giorgio Corani, Alessio Benavoli, Marco Zaffalon", "title": "Time series forecasting with Gaussian Processes needs priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic forecasting is the task of receiving a time series and returning a\nforecast for the next time steps without any human intervention. Gaussian\nProcesses (GPs) are a powerful tool for modeling time series, but so far there\nare no competitive approaches for automatic forecasting based on GPs. We\npropose practical solutions to two problems: automatic selection of the optimal\nkernel and reliable estimation of the hyperparameters. We propose a fixed\ncomposition of kernels, which contains the components needed to model most time\nseries: linear trend, periodic patterns, and other flexible kernel for modeling\nthe non-linear trend. Not all components are necessary to model each time\nseries; during training the unnecessary components are automatically made\nirrelevant via automatic relevance determination (ARD). We moreover assign\npriors to the hyperparameters, in order to keep the inference within a\nplausible range; we design such priors through an empirical Bayes approach. We\npresent results on many time series of different types; our GP model is more\naccurate than state-of-the-art time series models. Thanks to the priors, a\nsingle restart is enough the estimate the hyperparameters; hence the model is\nalso fast to train.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:46:51 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 10:10:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Corani", "Giorgio", ""], ["Benavoli", "Alessio", ""], ["Zaffalon", "Marco", ""]]}, {"id": "2009.08107", "submitter": "Alessia Bertugli", "authors": "Alessia Bertugli, Stefano Vincenzi, Simone Calderara, Andrea Passerini", "title": "Few-Shot Unsupervised Continual Learning through Meta-Examples", "comments": "Accepted at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), 4th Workshop on Meta-Learning, 16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, data do not reflect the ones commonly used for\nneural networks training, since they are usually few, unlabeled and can be\navailable as a stream. Hence many existing deep learning solutions suffer from\na limited range of applications, in particular in the case of online streaming\ndata that evolve over time. To narrow this gap, in this work we introduce a\nnovel and complex setting involving unsupervised meta-continual learning with\nunbalanced tasks. These tasks are built through a clustering procedure applied\nto a fitted embedding space. We exploit a meta-learning scheme that\nsimultaneously alleviates catastrophic forgetting and favors the generalization\nto new tasks. Moreover, to encourage feature reuse during the\nmeta-optimization, we exploit a single inner loop taking advantage of an\naggregated representation achieved through the use of a self-attention\nmechanism. Experimental results on few-shot learning benchmarks show\ncompetitive performance even compared to the supervised case. Additionally, we\nempirically observe that in an unsupervised scenario, the small tasks and the\nvariability in the clusters pooling play a crucial role in the generalization\ncapability of the network. Further, on complex datasets, the exploitation of\nmore clusters than the true number of classes leads to higher results, even\ncompared to the ones obtained with full supervision, suggesting that a\npredefined partitioning into classes can miss relevant structural information.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:02:07 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 13:01:57 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 13:38:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bertugli", "Alessia", ""], ["Vincenzi", "Stefano", ""], ["Calderara", "Simone", ""], ["Passerini", "Andrea", ""]]}, {"id": "2009.08120", "submitter": "Kim Hammar", "authors": "Kim Hammar and Rolf Stadler", "title": "Finding Effective Security Strategies through Reinforcement Learning and\n  Self-Play", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14128.38405", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to automatically find security strategies for the use\ncase of intrusion prevention. Following this method, we model the interaction\nbetween an attacker and a defender as a Markov game and let attack and defense\nstrategies evolve through reinforcement learning and self-play without human\nintervention. Using a simple infrastructure configuration, we demonstrate that\neffective security strategies can emerge from self-play. This shows that\nself-play, which has been applied in other domains with great success, can be\neffective in the context of network security. Inspection of the converged\npolicies show that the emerged policies reflect common-sense knowledge and are\nsimilar to strategies of humans. Moreover, we address known challenges of\nreinforcement learning in this domain and present an approach that uses\nfunction approximation, an opponent pool, and an autoregressive policy\nrepresentation. Through evaluations we show that our method is superior to two\nbaseline methods but that policy convergence in self-play remains a challenge.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:41:27 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 16:22:54 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hammar", "Kim", ""], ["Stadler", "Rolf", ""]]}, {"id": "2009.08123", "submitter": "Akshay Smit", "authors": "Damir Vrabac, Akshay Smit, Rebecca Rojansky, Yasodha Natkunam, Ranjana\n  H. Advani, Andrew Y. Ng, Sebastian Fernandez-Pol, Pranav Rajpurkar", "title": "DLBCL-Morph: Morphological features computed using deep learning for an\n  annotated digital DLBCL image set", "comments": "Corrections to folder structure figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffuse Large B-Cell Lymphoma (DLBCL) is the most common non-Hodgkin\nlymphoma. Though histologically DLBCL shows varying morphologies, no\nmorphologic features have been consistently demonstrated to correlate with\nprognosis. We present a morphologic analysis of histology sections from 209\nDLBCL cases with associated clinical and cytogenetic data. Duplicate tissue\ncore sections were arranged in tissue microarrays (TMAs), and replicate\nsections were stained with H&E and immunohistochemical stains for CD10, BCL6,\nMUM1, BCL2, and MYC. The TMAs are accompanied by pathologist-annotated\nregions-of-interest (ROIs) that identify areas of tissue representative of\nDLBCL. We used a deep learning model to segment all tumor nuclei in the ROIs,\nand computed several geometric features for each segmented nucleus. We fit a\nCox proportional hazards model to demonstrate the utility of these geometric\nfeatures in predicting survival outcome, and found that it achieved a C-index\n(95% CI) of 0.635 (0.574,0.691). Our finding suggests that geometric features\ncomputed from tumor nuclei are of prognostic importance, and should be\nvalidated in prospective studies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:43:42 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 07:09:07 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 11:02:28 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Vrabac", "Damir", ""], ["Smit", "Akshay", ""], ["Rojansky", "Rebecca", ""], ["Natkunam", "Yasodha", ""], ["Advani", "Ranjana H.", ""], ["Ng", "Andrew Y.", ""], ["Fernandez-Pol", "Sebastian", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2009.08128", "submitter": "Youngbin Ro", "authors": "Youngbin Ro, Yukyung Lee, Pilsung Kang", "title": "Multi$^2$OIE: Multilingual Open Information Extraction Based on\n  Multi-Head Attention with BERT", "comments": "11 pages, Findings of EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.99", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Multi$^2$OIE, which performs open information\nextraction (open IE) by combining BERT with multi-head attention. Our model is\na sequence-labeling system with an efficient and effective argument extraction\nmethod. We use a query, key, and value setting inspired by the Multimodal\nTransformer to replace the previously used bidirectional long short-term memory\narchitecture with multi-head attention. Multi$^2$OIE outperforms existing\nsequence-labeling systems with high computational efficiency on two benchmark\nevaluation datasets, Re-OIE2016 and CaRB. Additionally, we apply the proposed\nmethod to multilingual open IE using multilingual BERT. Experimental results on\nnew benchmark datasets introduced for two languages (Spanish and Portuguese)\ndemonstrate that our model outperforms other multilingual systems without\ntraining data for the target languages.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:03:42 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 06:41:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ro", "Youngbin", ""], ["Lee", "Yukyung", ""], ["Kang", "Pilsung", ""]]}, {"id": "2009.08136", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Multidimensional Scaling, Sammon Mapping, and Isomap: Tutorial and\n  Survey", "comments": "To appear as a part of an upcoming academic book on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional Scaling (MDS) is one of the first fundamental manifold\nlearning methods. It can be categorized into several methods, i.e., classical\nMDS, kernel classical MDS, metric MDS, and non-metric MDS. Sammon mapping and\nIsomap can be considered as special cases of metric MDS and kernel classical\nMDS, respectively. In this tutorial and survey paper, we review the theory of\nMDS, Sammon mapping, and Isomap in detail. We explain all the mentioned\ncategories of MDS. Then, Sammon mapping, Isomap, and kernel Isomap are\nexplained. Out-of-sample embedding for MDS and Isomap using eigenfunctions and\nkernel mapping are introduced. Then, Nystrom approximation and its use in\nlandmark MDS and landmark Isomap are introduced for big data embedding. We also\nprovide some simulations for illustrating the embedding by these methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:12:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.08142", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov, Kishor Patil, Gugan Thoppe", "title": "Online Algorithms for Estimating Change Rates of Web Pages", "comments": "A significantly extended version of ValueTools 2020 conference paper\n  [arXiv:2004.02167]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For providing quick and accurate search results, a search engine maintains a\nlocal snapshot of the entire web. And, to keep this local cache fresh, it\nemploys a crawler for tracking changes across various web pages. It would have\nbeen ideal if the crawler managed to update the local snapshot as soon as a\npage changed on the web. However, finite bandwidth availability and server\nrestrictions mean that there is a bound on how frequently the different pages\ncan be crawled. This then brings forth the following optimisation problem:\nmaximise the freshness of the local cache subject to the crawling frequency\nbeing within the prescribed bounds. Recently, tractable algorithms have been\nproposed to solve this optimisation problem under different cost criteria.\nHowever, these assume the knowledge of exact page change rates, which is\nunrealistic in practice. We address this issue here. Specifically, we provide\nthree novel schemes for online estimation of page change rates. All these\nschemes only need partial information about the page change process, i.e., they\nonly need to know if the page has changed or not since the last crawl instance.\nOur first scheme is based on the law of large numbers, the second on the theory\nof stochastic approximation, while the third is an extension of the second and\ninvolves an additional momentum term. For all of these schemes, we prove\nconvergence and, also, provide their convergence rates. As far as we know, the\nresults concerning the third estimator is quite novel. Specifically, this is\nthe first convergence type result for a stochastic approximation algorithm with\nmomentum. Finally, we provide some numerical experiments (on real as well as\nsynthetic data) to compare the performance of our proposed estimators with the\nexisting ones (e.g., MLE).\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:25:02 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Patil", "Kishor", ""], ["Thoppe", "Gugan", ""]]}, {"id": "2009.08155", "submitter": "Antonio Liguori", "authors": "Antonio Liguori, Romana Markovic, Thi Thu Ha Dam, J\\'er\\^ome Frisch,\n  Christoph van Treeck, Francesco Causone", "title": "Indoor environment data time-series reconstruction using autoencoder\n  neural networks", "comments": "Accepted in Building and Environment", "journal-ref": "Building and Environment 191 (2021) 107623", "doi": "10.1016/j.buildenv.2021.107623", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of installed meters in buildings increases, there is a growing\nnumber of data time-series that could be used to develop data-driven models to\nsupport and optimize building operation. However, building data sets are often\ncharacterized by errors and missing values, which are considered, by the recent\nresearch, among the main limiting factors on the performance of the proposed\nmodels. Motivated by the need to address the problem of missing data in\nbuilding operation, this work presents a data-driven approach to fill these\ngaps. In this study, three different autoencoder neural networks are trained to\nreconstruct missing short-term indoor environment data time-series in a data\nset collected in an office building in Aachen, Germany. This consisted of a\nfour year-long monitoring campaign in and between the years 2014 and 2017, of\n84 different rooms. The models are applicable for different time-series\nobtained from room automation, such as indoor air temperature, relative\nhumidity and $CO_{2}$ data streams. The results prove that the proposed methods\noutperform classic numerical approaches and they result in reconstructing the\ncorresponding variables with average RMSEs of 0.42 {\\deg}C, 1.30 % and 78.41\nppm, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:05:40 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 09:36:37 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Liguori", "Antonio", ""], ["Markovic", "Romana", ""], ["Dam", "Thi Thu Ha", ""], ["Frisch", "J\u00e9r\u00f4me", ""], ["van Treeck", "Christoph", ""], ["Causone", "Francesco", ""]]}, {"id": "2009.08161", "submitter": "Jie Peng", "authors": "Jie Peng, Zhaoxian Wu, Qing Ling", "title": "Byzantine-Robust Variance-Reduced Federated Learning over Distributed\n  Non-i.i.d. Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Byzantine-robust variance-reduced stochastic gradient descent\n(SGD) method to solve the distributed finite-sum minimization problem when the\ndata on the workers are not independent and identically distributed (i.i.d.).\nDuring the learning process, an unknown number of Byzantine workers may send\nmalicious messages to the master node, leading to remarkable learning error.\nMost of the Byzantine-robust methods address this issue by using robust\naggregation rules to aggregate the received messages, but rely on the\nassumption that all the regular workers have i.i.d. data, which is not the case\nin many federated learning applications. In light of the significance of\nreducing stochastic gradient noise for mitigating the effect of Byzantine\nattacks, we use a resampling strategy to reduce the impact of both inner\nvariation (that describes the sample heterogeneity on every regular worker) and\nouter variation (that describes the sample heterogeneity among the regular\nworkers), along with a stochastic average gradient algorithm (SAGA) to fully\neliminate the inner variation. The variance-reduced messages are then\naggregated with a robust geometric median operator. Under certain conditions,\nwe prove that the proposed method reaches a neighborhood of the optimal\nsolution with linear convergence rate, and the learning error is much smaller\nthan those given by the state-of-the-art methods in the non-i.i.d. setting.\nNumerical experiments corroborate the theoretical results and show satisfactory\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:09:23 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Peng", "Jie", ""], ["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""]]}, {"id": "2009.08166", "submitter": "Shogo Iwazaki", "authors": "Shogo Iwazaki, Yu Inatsu, Ichiro Takeuchi", "title": "Mean-Variance Analysis in Bayesian Optimization under Uncertainty", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider active learning (AL) in an uncertain environment in which\ntrade-off between multiple risk measures need to be considered. As an AL\nproblem in such an uncertain environment, we study Mean-Variance Analysis in\nBayesian Optimization (MVA-BO) setting. Mean-variance analysis was developed in\nthe field of financial engineering and has been used to make decisions that\ntake into account the trade-off between the average and variance of investment\nuncertainty. In this paper, we specifically focus on BO setting with an\nuncertain component and consider multi-task, multi-objective, and constrained\noptimization scenarios for the mean-variance trade-off of the uncertain\ncomponent. When the target blackbox function is modeled by Gaussian Process\n(GP), we derive the bounds of the two risk measures and propose AL algorithm\nfor each of the above three problems based on the risk measure bounds. We show\nthe effectiveness of the proposed AL algorithms through theoretical analysis\nand numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:21:46 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Iwazaki", "Shogo", ""], ["Inatsu", "Yu", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2009.08169", "submitter": "Fabian Timm", "authors": "Lukas Enderich and Fabian Timm and Wolfram Burgard", "title": "Holistic Filter Pruning for Efficient Deep Neural Networks", "comments": "preprint, accepted at WACV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are usually over-parameterized to increase the\nlikelihood of getting adequate initial weights by random initialization.\nConsequently, trained DNNs have many redundancies which can be pruned from the\nmodel to reduce complexity and improve the ability to generalize. Structural\nsparsity, as achieved by filter pruning, directly reduces the tensor sizes of\nweights and activations and is thus particularly effective for reducing\ncomplexity. We propose \"Holistic Filter Pruning\" (HFP), a novel approach for\ncommon DNN training that is easy to implement and enables to specify accurate\npruning rates for the number of both parameters and multiplications. After each\nforward pass, the current model complexity is calculated and compared to the\ndesired target size. By gradient descent, a global solution can be found that\nallocates the pruning budget over the individual layers such that the desired\ntarget size is fulfilled. In various experiments, we give insights into the\ntraining and achieve state-of-the-art performance on CIFAR-10 and ImageNet (HFP\nprunes 60% of the multiplications of ResNet-50 on ImageNet with no significant\nloss in the accuracy). We believe our simple and powerful pruning approach to\nconstitute a valuable contribution for users of DNNs in low-cost applications.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:23:36 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Enderich", "Lukas", ""], ["Timm", "Fabian", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2009.08198", "submitter": "Lorenzo Mandow", "authors": "L. Mandow, J. L. P\\'erez de la Cruz, N. Pozas", "title": "Multi-objective dynamic programming with limited precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of approximating the set of all solutions\nfor Multi-objective Markov Decision Processes. We show that in the vast\nmajority of interesting cases, the number of solutions is exponential or even\ninfinite. In order to overcome this difficulty we propose to approximate the\nset of all solutions by means of a limited precision approach based on White's\nmulti-objective value-iteration dynamic programming algorithm. We prove that\nthe number of calculated solutions is tractable and show experimentally that\nthe solutions obtained are a good approximation of the true Pareto front.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 10:34:01 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mandow", "L.", ""], ["de la Cruz", "J. L. P\u00e9rez", ""], ["Pozas", "N.", ""]]}, {"id": "2009.08205", "submitter": "Dustin Wright", "authors": "Pepa Atanasova, Dustin Wright, and Isabelle Augenstein", "title": "Generating Label Cohesive and Well-Formed Adversarial Claims", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks reveal important vulnerabilities and flaws of trained\nmodels. One potent type of attack are universal adversarial triggers, which are\nindividual n-grams that, when appended to instances of a class under attack,\ncan trick a model into predicting a target class. However, for inference tasks\nsuch as fact checking, these triggers often inadvertently invert the meaning of\ninstances they are inserted in. In addition, such attacks produce semantically\nnonsensical inputs, as they simply concatenate triggers to existing samples.\nHere, we investigate how to generate adversarial attacks against fact checking\nsystems that preserve the ground truth meaning and are semantically valid. We\nextend the HotFlip attack algorithm used for universal trigger generation by\njointly minimising the target class loss of a fact checking model and the\nentailment class loss of an auxiliary natural language inference model. We then\ntrain a conditional language model to generate semantically valid statements,\nwhich include the found universal triggers. We find that the generated attacks\nmaintain the directionality and semantic validity of the claim better than\nprevious work.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 10:50:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Atanasova", "Pepa", ""], ["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.08219", "submitter": "Junaid Ahmed Ghauri", "authors": "Chanjong Im, Junaid Ghauri, John Rothman, Thomas Mandl", "title": "Deep Learning Approaches to Classification of Production Technology for\n  19th Century Books", "comments": "LWDA 2018: Mannheim, Germany", "journal-ref": "Proceedings of the Conference \"Lernen, Wissen, Daten, Analysen\",\n  {LWDA} 2018, Mannheim, Germany, August 22-24, 2018", "doi": null, "report-no": "ceur-ws.org/Vol-2191", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cultural research is dedicated to understanding the processes of knowledge\ndissemination and the social and technological practices in the book industry.\nResearch on children books in the 19th century can be supported by computer\nsystems. Specifically, the advances in digital image processing seem to offer\ngreat opportunities for analyzing and quantifying the visual components in the\nbooks. The production technology for illustrations in books in the 19th century\nwas characterized by a shift from wood or copper engraving to lithography. We\nreport classification experiments which intend to classify images based on the\nproduction technology. For a classification task that is also difficult for\nhumans, the classification quality reaches only around 70%. We analyze some\nfurther error sources and identify reasons for the low performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 11:39:35 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Im", "Chanjong", ""], ["Ghauri", "Junaid", ""], ["Rothman", "John", ""], ["Mandl", "Thomas", ""]]}, {"id": "2009.08228", "submitter": "Abhishek  Sinha", "authors": "Debjit Paria, Abhishek Sinha", "title": "LeadCache: Regret-Optimal Caching in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a set-valued online prediction problem in the context of network\ncaching. Assume that multiple users are connected to several caches via a\nbipartite network. At any time slot, each user requests an arbitrary file\nchosen from a large catalog. A user's request at a slot is met if the requested\nfile is cached in at least one of the caches connected to the user. Our\nobjective is to predict, prefetch, and optimally distribute the files on the\ncaches to maximize the total number of cache hits in an online setting. The\nproblem is non-trivial due to the non-convex and non-smooth nature of the\nobjective function. In this paper, we propose $\\texttt{LeadCache}$ - an online\ncaching policy based on the Follow-the-Perturbed-Leader paradigm. We show that\nthe policy is regret-optimal up to a factor of $\\tilde{O}(n^{3/8}),$ where $n$\nis the number of users. We design two efficient implementations of the\n$\\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based\non Madow's sampling, each of which makes precisely one call to an LP-solver per\niteration. With a Strong-Law-type assumption, we show that the total number of\nfile fetches under $\\texttt{LeadCache}$ remains almost surely finite over an\ninfinite horizon. Finally, we derive a tight regret lower bound using results\nfrom graph coloring. We conclude that the learning-based $\\texttt{LeadCache}$\npolicy decisively outperforms the known caching policies both theoretically and\nempirically.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:13:26 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 19:26:22 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 17:05:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Paria", "Debjit", ""], ["Sinha", "Abhishek", ""]]}, {"id": "2009.08246", "submitter": "Anyong Qin", "authors": "Anyong Qin and Zhaowei Shang and Zhuolin Tan and Taiping Zhang and\n  Yuan Yan Tang", "title": "Learning a Deep Part-based Representation by Preserving Data\n  Distribution", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised dimensionality reduction is one of the commonly used techniques\nin the field of high dimensional data recognition problems. The deep\nautoencoder network which constrains the weights to be non-negative, can learn\na low dimensional part-based representation of data. On the other hand, the\ninherent structure of the each data cluster can be described by the\ndistribution of the intraclass samples. Then one hopes to learn a new low\ndimensional representation which can preserve the intrinsic structure embedded\nin the original high dimensional data space perfectly. In this paper, by\npreserving the data distribution, a deep part-based representation can be\nlearned, and the novel algorithm is called Distribution Preserving Network\nEmbedding (DPNE). In DPNE, we first need to estimate the distribution of the\noriginal high dimensional data using the $k$-nearest neighbor kernel density\nestimation, and then we seek a part-based representation which respects the\nabove distribution. The experimental results on the real-world data sets show\nthat the proposed algorithm has good performance in terms of cluster accuracy\nand AMI. It turns out that the manifold structure in the raw data can be well\npreserved in the low dimensional feature space.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:49:36 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Qin", "Anyong", ""], ["Shang", "Zhaowei", ""], ["Tan", "Zhuolin", ""], ["Zhang", "Taiping", ""], ["Tang", "Yuan Yan", ""]]}, {"id": "2009.08253", "submitter": "Jiju Peethambaran Poovvancheri", "authors": "Sumesh Thakur and Jiju Peethambaran", "title": "Dynamic Edge Weights in Graph Neural Networks for 3D Object Detection", "comments": "11 pages; 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust and accurate 3D detection system is an integral part of autonomous\nvehicles. Traditionally, a majority of 3D object detection algorithms focus on\nprocessing 3D point clouds using voxel grids or bird's eye view (BEV). Recent\nworks, however, demonstrate the utilization of the graph neural network (GNN)\nas a promising approach to 3D object detection. In this work, we propose an\nattention based feature aggregation technique in GNN for detecting objects in\nLiDAR scan. We first employ a distance-aware down-sampling scheme that not only\nenhances the algorithmic performance but also retains maximum geometric\nfeatures of objects even if they lie far from the sensor. In each layer of the\nGNN, apart from the linear transformation which maps the per node input\nfeatures to the corresponding higher level features, a per node masked\nattention by specifying different weights to different nodes in its first ring\nneighborhood is also performed. The masked attention implicitly accounts for\nthe underlying neighborhood graph structure of every node and also eliminates\nthe need of costly matrix operations thereby improving the detection accuracy\nwithout compromising the performance. The experiments on KITTI dataset show\nthat our method yields comparable results for 3D object detection.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:56:17 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Thakur", "Sumesh", ""], ["Peethambaran", "Jiju", ""]]}, {"id": "2009.08257", "submitter": "Ignacio Iacobacci", "authors": "Ieva Stali\\=unait\\.e and Ignacio Iacobacci", "title": "Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A\n  Case Study on CoQA", "comments": "8 pages + 2 pages references, 3 tables, 1 figure. Accepted as long\n  paper in EMNLP2020 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP tasks have benefited from transferring knowledge from contextualized\nword embeddings, however the picture of what type of knowledge is transferred\nis incomplete. This paper studies the types of linguistic phenomena accounted\nfor by language models in the context of a Conversational Question Answering\n(CoQA) task. We identify the problematic areas for the finetuned RoBERTa, BERT\nand DistilBERT models through systematic error analysis - basic arithmetic\n(counting phrases), compositional semantics (negation and Semantic Role\nLabeling), and lexical semantics (surprisal and antonymy). When enhanced with\nthe relevant linguistic knowledge through multitask learning, the models\nimprove in performance. Ensembles of the enhanced models yield a boost between\n2.2 and 2.7 points in F1 score overall, and up to 42.1 points in F1 on the\nhardest question classes. The results show differences in ability to represent\ncompositional and lexical information between RoBERTa, BERT and DistilBERT.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:00:13 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Stali\u016bnait\u0117", "Ieva", ""], ["Iacobacci", "Ignacio", ""]]}, {"id": "2009.08265", "submitter": "Ningyuan Chen", "authors": "Wenhao Li, Ningyuan Chen, L. Jeff Hong", "title": "Dimension Reduction in Contextual Online Learning via Nonparametric\n  Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a contextual online learning (multi-armed bandit) problem with\nhigh-dimensional covariate $\\mathbf{x}$ and decision $\\mathbf{y}$. The reward\nfunction to learn, $f(\\mathbf{x},\\mathbf{y})$, does not have a particular\nparametric form. The literature has shown that the optimal regret is\n$\\tilde{O}(T^{(d_x+d_y+1)/(d_x+d_y+2)})$, where $d_x$ and $d_y$ are the\ndimensions of $\\mathbf x$ and $\\mathbf y$, and thus it suffers from the curse\nof dimensionality. In many applications, only a small subset of variables in\nthe covariate affect the value of $f$, which is referred to as\n\\textit{sparsity} in statistics. To take advantage of the sparsity structure of\nthe covariate, we propose a variable selection algorithm called\n\\textit{BV-LASSO}, which incorporates novel ideas such as binning and voting to\napply LASSO to nonparametric settings. Our algorithm achieves the regret\n$\\tilde{O}(T^{(d_x^*+d_y+1)/(d_x^*+d_y+2)})$, where $d_x^*$ is the effective\ncovariate dimension. The regret matches the optimal regret when the covariate\nis $d^*_x$-dimensional and thus cannot be improved. Our algorithm may serve as\na general recipe to achieve dimension reduction via variable selection in\nnonparametric settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:08:45 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Li", "Wenhao", ""], ["Chen", "Ningyuan", ""], ["Hong", "L. Jeff", ""]]}, {"id": "2009.08267", "submitter": "Viatcheslav Gurev", "authors": "Jaimit Parikh, James Kozloski, and Viatcheslav Gurev", "title": "Integration of AI and mechanistic modeling in generative adversarial\n  networks for stochastic inverse problems", "comments": "New appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic inverse problems (SIP) address the behavior of a set of objects of\nthe same kind but with variable properties, such as a population of cells.\nUsing a population of mechanistic models from a single parametric family, SIP\nexplains population variability by transferring real-world observations into\nthe latent space of model parameters. Previous research in SIP focused on\nsolving the parameter inference problem for a single population using Markov\nchain Monte Carlo methods. Here we extend SIP to address multiple related\npopulations simultaneously. Specifically, we simulate control and treatment\npopulations in experimental protocols by discovering two related latent spaces\nof model parameters. Instead of taking a Bayesian approach, our two-population\nSIP is reformulated as the constrained-optimization problem of finding\ndistributions of model parameters. To minimize the divergence between\ndistributions of experimental observations and model outputs, we developed\nnovel deep learning models based on generative adversarial networks (GANs)\nwhich have the structure of our underlying constrained-optimization problem.\nThe flexibility of GANs allowed us to build computationally scalable solutions\nand tackle complex model input parameter inference scenarios, which appear\nroutinely in physics, biophysics, economics and other areas, and which can not\nbe handled with existing methods. Specifically, we demonstrate two scenarios of\nparameter inference over a control population and a treatment population whose\ntreatment either selectively affects only a subset of model parameters with\nsome uncertainty or has a deterministic effect on all model parameters.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:13:21 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 23:16:26 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Parikh", "Jaimit", ""], ["Kozloski", "James", ""], ["Gurev", "Viatcheslav", ""]]}, {"id": "2009.08270", "submitter": "Saloni Dash", "authors": "Saloni Dash, Vineeth N Balasubramanian, Amit Sharma", "title": "Evaluating and Mitigating Bias in Image Classifiers: A Causal\n  Perspective Using Counterfactuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have reported biases in machine learning image classifiers,\nespecially against particular demographic groups. Counterfactual examples for\nan input -- perturbations that change specific features but not others -- have\nbeen shown to be useful for evaluating explainability and fairness of machine\nlearning models. However, generating counterfactual examples for images is\nnon-trivial due to the underlying causal structure governing the various\nfeatures of an image. To be meaningful, generated perturbations need to satisfy\nconstraints implied by the causal model. We present a method for generating\ncounterfactuals by incorporating a structural causal model (SCM) in a novel\nimproved variant of Adversarially Learned Inference (ALI), that generates\ncounterfactuals in accordance with the causal relationships between different\nattributes of an image. Based on the generated counterfactuals, we show how to\nevaluate bias and explain a pre-trained machine learning classifier. We also\npropose a counterfactual regularizer that can mitigate bias in the classifier.\nOn the Morpho-MNIST dataset, our method generates counterfactuals comparable in\nquality to prior work on SCM-based counterfactuals. Our method also works on\nthe more complex CelebA faces dataset; generated counterfactuals are\nindistinguishable from original images in a human evaluation experiment. As a\ndownstream task, we use counterfactuals to evaluate a standard classifier\ntrained on CelebA data and show that it is biased w.r.t. skin and hair color,\nand show how counterfactual regularization can be used to remove the identified\nbiases.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:19:31 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 07:52:28 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 09:12:31 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Dash", "Saloni", ""], ["Balasubramanian", "Vineeth N", ""], ["Sharma", "Amit", ""]]}, {"id": "2009.08273", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "When compressive learning fails: blame the decoder or the sketch?", "comments": "in Proceedings of iTWIST'20, Paper-ID: 22, Nantes, France, December,\n  2-4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressive learning, a mixture model (a set of centroids or a Gaussian\nmixture) is learned from a sketch vector, that serves as a highly compressed\nrepresentation of the dataset. This requires solving a non-convex optimization\nproblem, hence in practice approximate heuristics (such as CLOMPR) are used. In\nthis work we explore, by numerical simulations, properties of this non-convex\noptimization landscape and those heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:53:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "2009.08274", "submitter": "Liangming Chen", "authors": "Liangming Chen, Long Jin, Xiujuan Du, Shuai Li, Mei Liu", "title": "Deforming the Loss Surface to Affect the Behaviour of the Optimizer", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.12515", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning, it is usually assumed that the optimization process is\nconducted on a shape-fixed loss surface. Differently, we first propose a novel\nconcept of deformation mapping in this paper to affect the behaviour of the\noptimizer. Vertical deformation mapping (VDM), as a type of deformation\nmapping, can make the optimizer enter a flat region, which often implies better\ngeneralization performance. Moreover, we design various VDMs, and further\nprovide their contributions to the loss surface. After defining the local M\nregion, theoretical analyses show that deforming the loss surface can enhance\nthe gradient descent optimizer's ability to filter out sharp minima. With\nvisualizations of loss landscapes, we evaluate the flatnesses of minima\nobtained by both the original optimizer and optimizers enhanced by VDMs on\nCIFAR-100. The experimental results show that VDMs do find flatter regions.\nMoreover, we compare popular convolutional neural networks enhanced by VDMs\nwith the corresponding original ones on ImageNet, CIFAR-10, and CIFAR-100. The\nresults are surprising: there are significant improvements on all of the\ninvolved models equipped with VDMs. For example, the top-1 test accuracy of\nResNet-20 on CIFAR-100 increases by 1.46%, with insignificant additional\ncomputational overhead.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:43:16 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Chen", "Liangming", ""], ["Jin", "Long", ""], ["Du", "Xiujuan", ""], ["Li", "Shuai", ""], ["Liu", "Mei", ""]]}, {"id": "2009.08275", "submitter": "Amir Mosavi Prof", "authors": "Randall Claywell, Laszlo Nadai, Felde Imre, Amir Mosavi", "title": "Adaptive Neuro-Fuzzy Inference System and a Multilayer Perceptron Model\n  Trained with Grey Wolf Optimizer for Predicting Solar Diffuse Fraction", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": "10.3390/e22111192", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The accurate prediction of the solar Diffuse Fraction (DF), sometimes called\nthe Diffuse Ratio, is an important topic for solar energy research. In the\npresent study, the current state of Diffuse Irradiance research is discussed\nand then three robust, Machine Learning (ML) models, are examined using a large\ndataset (almost 8 years) of hourly readings from Almeria, Spain. The ML models\nused herein, are a hybrid Adaptive Network-based Fuzzy Inference System\n(ANFIS), a single Multi-Layer Perceptron (MLP) and a hybrid Multi-Layer\nPerceptron-Grey Wolf Optimizer (MLP-GWO). These models were evaluated for their\npredictive precision, using various Solar and Diffuse Fraction (DF) irradiance\ndata, from Spain. The results were then evaluated using two frequently used\nevaluation criteria, the Mean Absolute Error (MAE) and the Root Mean Square\nError (RMSE). The results showed that the MLP-GWO model, followed by the ANFIS\nmodel, provided a higher performance, in both the training and the testing\nprocedures.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 19:32:15 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Claywell", "Randall", ""], ["Nadai", "Laszlo", ""], ["Imre", "Felde", ""], ["Mosavi", "Amir", ""]]}, {"id": "2009.08278", "submitter": "Juliano Ferrari Gianlupi", "authors": "Camila Faccini de Lima, Juliano Ferrari Gianlupi, John Metzcar and\n  Juliette Zerick", "title": "Accelerated solving of coupled, non-linear ODEs through LSTM-AI", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present project aims to use machine learning, specifically neural\nnetworks (NN), to learn the trajectories of a set of coupled ordinary\ndifferential equations (ODEs) and decrease compute times for obtaining ODE\nsolutions by using this surragate model. As an example system of proven\nbiological significance, we use an ODE model of a gene regulatory circuit of\ncyanobacteria related to photosynthesis \\cite{original_biology_Kehoe,\nSundus_math_model}. Using data generated by a numeric solution to the exemplar\nsystem, we train several long-short-term memory neural networks. We stopping\ntraining when the networks achieve an accuracy of of 3\\% on testing data\nresulting in networks able to predict values in the ODE time series ranging\nfrom 0.25 minutes to 6.25 minutes beyond input values. We observed\ncomputational speed ups ranging from 9.75 to 197 times when comparing\nprediction compute time with compute time for obtaining the numeric solution.\nGiven the success of this proof of concept, we plan on continuing this project\nin the future and will attempt to realize the same computational speed-ups in\nthe context of an agent-based modeling platfom.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:31:53 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["de Lima", "Camila Faccini", ""], ["Gianlupi", "Juliano Ferrari", ""], ["Metzcar", "John", ""], ["Zerick", "Juliette", ""]]}, {"id": "2009.08292", "submitter": "Rama Krishna Kandukuri", "authors": "Rama Krishna Kandukuri, Jan Achterhold, Michael M\\\"oller, J\\\"org\n  St\\\"uckler", "title": "Learning to Identify Physical Parameters from Video Using Differentiable\n  Physics", "comments": "Accepted for 42nd German Conference on Pattern Recognition (DAGM-GCPR\n  2020), T\\\"ubingen, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video representation learning has recently attracted attention in computer\nvision due to its applications for activity and scene forecasting or\nvision-based planning and control. Video prediction models often learn a latent\nrepresentation of video which is encoded from input frames and decoded back\ninto images. Even when conditioned on actions, purely deep learning based\narchitectures typically lack a physically interpretable latent space. In this\nstudy, we use a differentiable physics engine within an action-conditional\nvideo representation network to learn a physical latent representation. We\npropose supervised and self-supervised learning methods to train our network\nand identify physical properties. The latter uses spatial transformers to\ndecode physical states back into images. The simulation scenarios in our\nexperiments comprise pushing, sliding and colliding objects, for which we also\nanalyze the observability of the physical properties. In experiments we\ndemonstrate that our network can learn to encode images and identify physical\nproperties like mass and friction from videos and action sequences in the\nsimulated scenarios. We evaluate the accuracy of our supervised and\nself-supervised methods and compare it with a system identification baseline\nwhich directly learns from state trajectories. We also demonstrate the ability\nof our method to predict future video frames from input images and actions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:36:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Kandukuri", "Rama Krishna", ""], ["Achterhold", "Jan", ""], ["M\u00f6ller", "Michael", ""], ["St\u00fcckler", "J\u00f6rg", ""]]}, {"id": "2009.08295", "submitter": "James Morrill Mr", "authors": "James Morrill and Cristopher Salvi and Patrick Kidger and James Foster\n  and Terry Lyons", "title": "Neural Rough Differential Equations for Long Time Series", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural controlled differential equations (CDEs) are the continuous-time\nanalogue of recurrent neural networks, as Neural ODEs are to residual networks,\nand offer a memory-efficient continuous-time way to model functions of\npotentially irregular time series. Existing methods for computing the forward\npass of a Neural CDE involve embedding the incoming time series into path\nspace, often via interpolation, and using evaluations of this path to drive the\nhidden state. Here, we use rough path theory to extend this formulation.\nInstead of directly embedding into path space, we instead represent the input\nsignal over small time intervals through its \\textit{log-signature}, which are\nstatistics describing how the signal drives a CDE. This is the approach for\nsolving \\textit{rough differential equations} (RDEs), and correspondingly we\ndescribe our main contribution as the introduction of Neural RDEs. This\nextension has a purpose: by generalising the Neural CDE approach to a broader\nclass of driving signals, we demonstrate particular advantages for tackling\nlong time series. In this regime, we demonstrate efficacy on problems of length\nup to 17k observations and observe significant training speed-ups, improvements\nin model performance, and reduced memory requirements compared to existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:43:47 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:08:20 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 11:28:41 GMT"}, {"version": "v4", "created": "Mon, 21 Jun 2021 12:04:06 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Morrill", "James", ""], ["Salvi", "Cristopher", ""], ["Kidger", "Patrick", ""], ["Foster", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2009.08296", "submitter": "Maryam Nazarieh", "authors": "Maryam Nazarieh, Volkhard Helms, Marc P. Hoeppner, Andre Franke", "title": "Identification of Biomarkers Controlling Cell Fate In Blood Cell\n  Development", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blood cell lineage consists of several consecutive developmental stages\nfrom the pluri- or multipotent stem cell to a state of terminal\ndifferentiation. Despite their importance for human biology, the regulatory\npathways and gene networks that govern these differentiation processes are not\nyet fully understood. This is in part due to challenges associated with\ndelineating the interactions between transcription factors (TFs) and their\ntarget genes. A possible path forward in this issue is provided by increasingly\navailable expression data as a basis for linking differentiation stages and\ngene activities. Here, we present a novel hierarchical approach to identify\ncharacteristic expression peak patterns that global regulators expose along the\ndifferentiation path of cell lineages. Based on such simple patterns, we\nidentify cell state-specific marker genes and extract TFs that likely drive\ntheir differentiation. Integration of the mean expression values of\nstage-specific key player genes yields a distinct peaking pattern for each\nlineage that is used to identify further genes in the dataset behaving\nsimilarly. Incorporating the set of TFs which regulate these genes incurred at\na set of stage-specific regulators controlling the biological process of cell\nfate. As proof of concept, we consider two expression datasets covering key\ndifferentiation events in blood cell formation of mice.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:43:53 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Nazarieh", "Maryam", ""], ["Helms", "Volkhard", ""], ["Hoeppner", "Marc P.", ""], ["Franke", "Andre", ""]]}, {"id": "2009.08299", "submitter": "Pietro Barbiero", "authors": "Pietro Barbiero, Ramon Vi\\~nas Torn\\'e, Pietro Li\\'o", "title": "Graph representation forecasting of patient's medical conditions:\n  towards a digital twin", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Modern medicine needs to shift from a wait and react, curative\ndiscipline to a preventative, interdisciplinary science aiming at providing\npersonalised, systemic and precise treatment plans to patients. The aim of this\nwork is to present how the integration of machine learning approaches with\nmechanistic computational modelling could yield a reliable infrastructure to\nrun probabilistic simulations where the entire organism is considered as a\nwhole. Methods: We propose a general framework that composes advanced AI\napproaches and integrates mathematical modelling in order to provide a\npanoramic view over current and future physiological conditions. The proposed\narchitecture is based on a graph neural network (GNNs) forecasting clinically\nrelevant endpoints (such as blood pressure) and a generative adversarial\nnetwork (GANs) providing a proof of concept of transcriptomic integrability.\nResults: We show the results of the investigation of pathological effects of\noverexpression of ACE2 across different signalling pathways in multiple tissues\non cardiovascular functions. We provide a proof of concept of integrating a\nlarge set of composable clinical models using molecular data to drive local and\nglobal clinical parameters and derive future trajectories representing the\nevolution of the physiological state of the patient. Significance: We argue\nthat the graph representation of a computational patient has potential to solve\nimportant technological challenges in integrating multiscale computational\nmodelling with AI. We believe that this work represents a step forward towards\na healthcare digital twin.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:49:48 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Barbiero", "Pietro", ""], ["Torn\u00e9", "Ramon Vi\u00f1as", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "2009.08311", "submitter": "Wenhao Ding", "authors": "Wenhao Ding, Baiming Chen, Bo Li, Kim Ji Eun, Ding Zhao", "title": "Multimodal Safety-Critical Scenarios Generation for Decision-Making\n  Algorithms Evaluation", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural network-based autonomous systems are shown to be vulnerable\nagainst adversarial attacks, therefore sophisticated evaluation on their\nrobustness is of great importance. However, evaluating the robustness only\nunder the worst-case scenarios based on known attacks is not comprehensive, not\nto mention that some of them even rarely occur in the real world. In addition,\nthe distribution of safety-critical data is usually multimodal, while most\ntraditional attacks and evaluation methods focus on a single modality. To solve\nthe above challenges, we propose a flow-based multimodal safety-critical\nscenario generator for evaluating decisionmaking algorithms. The proposed\ngenerative model is optimized with weighted likelihood maximization and a\ngradient-based sampling procedure is integrated to improve the sampling\nefficiency. The safety-critical scenarios are generated by querying the task\nalgorithms and the log-likelihood of the generated scenarios is in proportion\nto the risk level. Experiments on a self-driving task demonstrate our\nadvantages in terms of testing efficiency and multimodal modeling capability.\nWe evaluate six Reinforcement Learning algorithms with our generated traffic\nscenarios and provide empirical conclusions about their robustness.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:16:43 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:16:13 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 16:54:12 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ding", "Wenhao", ""], ["Chen", "Baiming", ""], ["Li", "Bo", ""], ["Eun", "Kim Ji", ""], ["Zhao", "Ding", ""]]}, {"id": "2009.08319", "submitter": "Michael Laskin", "authors": "Adam Stooke, Kimin Lee, Pieter Abbeel, and Michael Laskin", "title": "Decoupling Representation Learning from Reinforcement Learning", "comments": "Improved related works and fixed code hyperlink", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to overcome limitations of reward-driven feature learning in\ndeep reinforcement learning (RL) from images, we propose decoupling\nrepresentation learning from policy learning. To this end, we introduce a new\nunsupervised learning (UL) task, called Augmented Temporal Contrast (ATC),\nwhich trains a convolutional encoder to associate pairs of observations\nseparated by a short time difference, under image augmentations and using a\ncontrastive loss. In online RL experiments, we show that training the encoder\nexclusively using ATC matches or outperforms end-to-end RL in most\nenvironments. Additionally, we benchmark several leading UL algorithms by\npre-training encoders on expert demonstrations and using them, with weights\nfrozen, in RL agents; we find that agents using ATC-trained encoders outperform\nall others. We also train multi-task encoders on data from multiple\nenvironments and show generalization to different downstream RL tasks. Finally,\nwe ablate components of ATC, and introduce a new data augmentation to enable\nreplay of (compressed) latent images from pre-trained encoders when RL requires\naugmentation. Our experiments span visually diverse RL benchmarks in DeepMind\nControl, DeepMind Lab, and Atari, and our complete code is available at\nhttps://github.com/astooke/rlpyt/tree/master/rlpyt/ul.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:11:13 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 16:35:40 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 20:44:18 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Stooke", "Adam", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Laskin", "Michael", ""]]}, {"id": "2009.08325", "submitter": "Elahe Arani", "authors": "Fahad Sarfraz, Elahe Arani and Bahram Zonooz", "title": "Noisy Concurrent Training for Efficient Learning under Label Noise", "comments": "Accepted at IEEE Winter Conference on Applications of Computer Vision\n  (WACV, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) fail to learn effectively under label noise and\nhave been shown to memorize random labels which affect their generalization\nperformance. We consider learning in isolation, using one-hot encoded labels as\nthe sole source of supervision, and a lack of regularization to discourage\nmemorization as the major shortcomings of the standard training procedure.\nThus, we propose Noisy Concurrent Training (NCT) which leverages collaborative\nlearning to use the consensus between two models as an additional source of\nsupervision. Furthermore, inspired by trial-to-trial variability in the brain,\nwe propose a counter-intuitive regularization technique, target variability,\nwhich entails randomly changing the labels of a percentage of training samples\nin each batch as a deterrent to memorization and over-generalization in DNNs.\nTarget variability is applied independently to each model to keep them diverged\nand avoid the confirmation bias. As DNNs tend to prioritize learning simple\npatterns first before memorizing the noisy labels, we employ a dynamic learning\nscheme whereby as the training progresses, the two models increasingly rely\nmore on their consensus. NCT also progressively increases the target\nvariability to avoid memorization in later stages. We demonstrate the\neffectiveness of our approach on both synthetic and real-world noisy benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:22:17 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Sarfraz", "Fahad", ""], ["Arani", "Elahe", ""], ["Zonooz", "Bahram", ""]]}, {"id": "2009.08326", "submitter": "Abolfazl Taghribi", "authors": "Abolfazl Taghribi, Kerstin Bunte, Rory Smith, Jihye Shin, Michele\n  Mastropietro, Reynier F. Peletier and Peter Tino", "title": "LAAT: Locally Aligned Ant Technique for detecting manifolds of varying\n  density", "comments": "Submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction and clustering are often used as preliminary steps\nfor many complex machine learning tasks. The presence of noise and outliers can\ndeteriorate the performance of such preprocessing and therefore impair the\nsubsequent analysis tremendously. In manifold learning, several studies\nindicate solutions for removing background noise or noise close to the\nstructure when the density is substantially higher than that exhibited by the\nnoise. However, in many applications, including astronomical datasets, the\ndensity varies alongside manifolds that are buried in a noisy background. We\npropose a novel method to extract manifolds in the presence of noise based on\nthe idea of Ant colony optimization. In contrast to the existing random walk\nsolutions, our technique captures points which are locally aligned with major\ndirections of the manifold. Moreover, we empirically show that the biologically\ninspired formulation of ant pheromone reinforces this behavior enabling it to\nrecover multiple manifolds embedded in extremely noisy data clouds. The\nalgorithm's performance is demonstrated in comparison to the state-of-the-art\napproaches, such as Markov Chain, LLPD, and Disperse, on several synthetic and\nreal astronomical datasets stemming from an N-body simulation of a cosmological\nvolume.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:22:50 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Taghribi", "Abolfazl", ""], ["Bunte", "Kerstin", ""], ["Smith", "Rory", ""], ["Shin", "Jihye", ""], ["Mastropietro", "Michele", ""], ["Peletier", "Reynier F.", ""], ["Tino", "Peter", ""]]}, {"id": "2009.08327", "submitter": "Tayyebeh Jahani-Nezhad", "authors": "Tayyebeh Jahani-Nezhad, Mohammad Ali Maddah-Ali", "title": "Berrut Approximated Coded Computing: Straggler Resistance Beyond\n  Polynomial Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in using distributed learning to train\ncomplicated models with large data sets is to deal with stragglers effect. As a\nsolution, coded computation has been recently proposed to efficiently add\nredundancy to the computation tasks. In this technique, coding is used across\ndata sets, and computation is done over coded data, such that the results of an\narbitrary subset of worker nodes with a certain size are enough to recover the\nfinal results. The major challenges with those approaches are (1) they are\nlimited to polynomial function computations, (2) the size of the subset of\nservers that we need to wait for grows with the multiplication of the size of\nthe data set and the model complexity (the degree of the polynomial), which can\nbe prohibitively large, (3) they are not numerically stable for computation\nover real numbers. In this paper, we propose Berrut Approximated Coded\nComputing (BACC), as an alternative approach, which is not limited to\npolynomial function computation. In addition, the master node can approximately\ncalculate the final results, using the outcomes of any arbitrary subset of\navailable worker nodes. The approximation approach is proven to be numerically\nstable with low computational complexity. In addition, the accuracy of the\napproximation is established theoretically and verified by simulation results\nin different settings such as distributed learning problems. In particular,\nBACC is used to train a deep neural network on a cluster of servers, which\noutperforms repetitive computation (repetition coding) in terms of the rate of\nconvergence.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:23:38 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 16:11:42 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jahani-Nezhad", "Tayyebeh", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "2009.08328", "submitter": "Jeffrey Ede BSc MPhys", "authors": "Jeffrey M. Ede", "title": "Review: Deep Learning in Electron Microscopy", "comments": "33 pages, 16 figures + 2 tables + 65 pages of references", "journal-ref": null, "doi": "10.1088/2632-2153/abd614", "report-no": null, "categories": "eess.IV cond-mat.mtrl-sci cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is transforming most areas of science and technology, including\nelectron microscopy. This review paper offers a practical perspective aimed at\ndevelopers with limited familiarity. For context, we review popular\napplications of deep learning in electron microscopy. Afterwards, we discuss\nhardware and software needed to get started with deep learning and interface\nwith electron microscopes. We then review neural network components, popular\narchitectures, and their optimization. Finally, we discuss future directions of\ndeep learning in electron microscopy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:23:55 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 14:38:31 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 07:22:38 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 15:38:31 GMT"}, {"version": "v5", "created": "Sun, 27 Dec 2020 22:14:24 GMT"}, {"version": "v6", "created": "Thu, 31 Dec 2020 18:28:54 GMT"}, {"version": "v7", "created": "Mon, 8 Mar 2021 10:12:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ede", "Jeffrey M.", ""]]}, {"id": "2009.08330", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "More Embeddings, Better Sequence Labelers?", "comments": "Accepted to Findings of EMNLP 2020. Camera-ready, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent work proposes a family of contextual embeddings that significantly\nimproves the accuracy of sequence labelers over non-contextual embeddings.\nHowever, there is no definite conclusion on whether we can build better\nsequence labelers by combining different kinds of embeddings in various\nsettings. In this paper, we conduct extensive experiments on 3 tasks over 18\ndatasets and 8 languages to study the accuracy of sequence labeling with\nvarious embedding concatenations and make three observations: (1) concatenating\nmore embedding variants leads to better accuracy in rich-resource and\ncross-domain settings and some conditions of low-resource settings; (2)\nconcatenating additional contextual sub-word embeddings with contextual\ncharacter embeddings hurts the accuracy in extremely low-resource settings; (3)\nbased on the conclusion of (1), concatenating additional similar contextual\nembeddings cannot lead to further improvements. We hope these conclusions can\nhelp people build stronger sequence labelers in various settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:28:27 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 13:55:04 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 03:09:58 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2009.08340", "submitter": "Jean-Philippe Ovarlez", "authors": "Jose Agustin Barrachina and Chenfang Ren and Christele Morisseau and\n  Gilles Vieillard and Jean-Philippe Ovarlez", "title": "Complex-Valued vs. Real-Valued Neural Networks for Classification\n  Perspectives: An Example on Non-Circular Data", "comments": "6 pages, 5 figures, conference, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contributions of this paper are twofold. First, we show the potential\ninterest of Complex-Valued Neural Network (CVNN) on classification tasks for\ncomplex-valued datasets. To highlight this assertion, we investigate an example\nof complex-valued data in which the real and imaginary parts are statistically\ndependent through the property of non-circularity. In this context, the\nperformance of fully connected feed-forward CVNNs is compared against a\nreal-valued equivalent model. The results show that CVNN performs better for a\nwide variety of architectures and data structures. CVNN accuracy presents a\nstatistically higher mean and median and lower variance than Real-Valued Neural\nNetwork (RVNN). Furthermore, if no regularization technique is used, CVNN\nexhibits lower overfitting. The second contribution is the release of a Python\nlibrary (Barrachina 2019) using Tensorflow as back-end that enables the\nimplementation and training of CVNNs in the hopes of motivating further\nresearch on this area.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:39:35 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:20:21 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Barrachina", "Jose Agustin", ""], ["Ren", "Chenfang", ""], ["Morisseau", "Christele", ""], ["Vieillard", "Gilles", ""], ["Ovarlez", "Jean-Philippe", ""]]}, {"id": "2009.08346", "submitter": "Zhouyou Gu", "authors": "Zhouyou Gu and Changyang She and Wibowo Hardjawana and Simon Lumb and\n  David McKechnie and Todd Essery and Branka Vucetic", "title": "Knowledge-Assisted Deep Reinforcement Learning in 5G Scheduler Design:\n  From Theoretical Framework to Implementation", "comments": "This paper has been accepted in IEEE JSAC series on \"Machine Learning\n  in Communications and Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a knowledge-assisted deep reinforcement learning\n(DRL) algorithm to design wireless schedulers in the fifth-generation (5G)\ncellular networks with time-sensitive traffic. Since the scheduling policy is a\ndeterministic mapping from channel and queue states to scheduling actions, it\ncan be optimized by using deep deterministic policy gradient (DDPG). We show\nthat a straightforward implementation of DDPG converges slowly, has a poor\nquality-of-service (QoS) performance, and cannot be implemented in real-world\n5G systems, which are non-stationary in general. To address these issues, we\npropose a theoretical DRL framework, where theoretical models from wireless\ncommunications are used to formulate a Markov decision process in DRL. To\nreduce the convergence time and improve the QoS of each user, we design a\nknowledge-assisted DDPG (K-DDPG) that exploits expert knowledge of the\nscheduler design problem, such as the knowledge of the QoS, the target\nscheduling policy, and the importance of each training sample, determined by\nthe approximation error of the value function and the number of packet losses.\nFurthermore, we develop an architecture for online training and inference,\nwhere K-DDPG initializes the scheduler off-line and then fine-tunes the\nscheduler online to handle the mismatch between off-line simulations and\nnon-stationary real-world systems. Simulation results show that our approach\nreduces the convergence time of DDPG significantly and achieves better QoS than\nexisting schedulers (reducing 30% ~ 50% packet losses). Experimental results\nshow that with off-line initialization, our approach achieves better initial\nQoS than random initialization and the online fine-tuning converges in few\nminutes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:52:12 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 06:13:34 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Gu", "Zhouyou", ""], ["She", "Changyang", ""], ["Hardjawana", "Wibowo", ""], ["Lumb", "Simon", ""], ["McKechnie", "David", ""], ["Essery", "Todd", ""], ["Vucetic", "Branka", ""]]}, {"id": "2009.08354", "submitter": "Felix Rempe", "authors": "Felix Rempe, Klaus Bogenberger", "title": "Feature Engineering for Data-driven Traffic State Forecast in Urban Road\n  Networks", "comments": "Presented at Annual Meeting of the Transport Research Board (TRB),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most traffic state forecast algorithms when applied to urban road networks\nconsider only the links in close proximity to the target location. However, for\nlonger-term forecasts also the traffic state of more distant links or regions\nof the network are expected to provide valuable information for a data-driven\nalgorithm. This paper studies these expectations of using a network clustering\nalgorithm and one year of Floating Car (FCD) collected by a large fleet of\nvehicles. First, a clustering algorithm is applied to the data in order to\nextract congestion-prone regions in the Munich city network. The level of\ncongestion inside these clusters is analyzed with the help of statistical\ntools. Clear spatio-temporal congestion patterns and correlations between the\nclustered regions are identified. These correlations are integrated into a K-\nNearest Neighbors (KNN) travel time prediction algorithm. In a comparison with\nother approaches, this method achieves the best results. The statistical\nresults and the performance of the KNN predictor indicate that the\nconsideration of the network-wide traffic is a valuable feature for predictors\nand a promising way to develop more accurate algorithms in the future.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:03:33 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Rempe", "Felix", ""], ["Bogenberger", "Klaus", ""]]}, {"id": "2009.08360", "submitter": "Ronald de Wolf", "authors": "Adam Izdebski and Ronald de Wolf", "title": "Improved Quantum Boosting", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a general method to convert a weak learner (which generates\nhypotheses that are just slightly better than random) into a strong learner\n(which generates hypotheses that are much better than random). Recently,\nArunachalam and Maity gave the first quantum improvement for boosting, by\ncombining Freund and Schapire's AdaBoost algorithm with a quantum algorithm for\napproximate counting. Their booster is faster than classical boosting as a\nfunction of the VC-dimension of the weak learner's hypothesis class, but worse\nas a function of the quality of the weak learner. In this paper we give a\nsubstantially faster and simpler quantum boosting algorithm, based on\nServedio's SmoothBoost algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:16:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Izdebski", "Adam", ""], ["de Wolf", "Ronald", ""]]}, {"id": "2009.08371", "submitter": "Nils Eckstein", "authors": "Nils Eckstein and Julia Buhmann and Matthew Cook and Jan Funke", "title": "Microtubule Tracking in Electron Microscopy Volumes", "comments": "Accepted at MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for microtubule tracking in electron microscopy volumes.\nOur method first identifies a sparse set of voxels that likely belong to\nmicrotubules. Similar to prior work, we then enumerate potential edges between\nthese voxels, which we represent in a candidate graph. Tracks of microtubules\nare found by selecting nodes and edges in the candidate graph by solving a\nconstrained optimization problem incorporating biological priors on microtubule\nstructure. For this, we present a novel integer linear programming formulation,\nwhich results in speed-ups of three orders of magnitude and an increase of 53%\nin accuracy compared to prior art (evaluated on three 1.2 x 4 x 4$\\mu$m volumes\nof Drosophila neural tissue). We also propose a scheme to solve the\noptimization problem in a block-wise fashion, which allows distributed tracking\nand is necessary to process very large electron microscopy volumes. Finally, we\nrelease a benchmark dataset for microtubule tracking, here used for training,\ntesting and validation, consisting of eight 30 x 1000 x 1000 voxel blocks (1.2\nx 4 x 4$\\mu$m) of densely annotated microtubules in the CREMI data set\n(https://github.com/nilsec/micron).\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:37:30 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Eckstein", "Nils", ""], ["Buhmann", "Julia", ""], ["Cook", "Matthew", ""], ["Funke", "Jan", ""]]}, {"id": "2009.08372", "submitter": "Emmanuel de B\\'ezenac", "authors": "Skander Karkar, Ibrahim Ayed, Emmanuel de B\\'ezenac, Patrick Gallinari", "title": "A Principle of Least Action for the Training of Neural Networks", "comments": "ECML PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been achieving high generalization performance on many\ntasks despite being highly over-parameterized. Since classical statistical\nlearning theory struggles to explain this behavior, much effort has recently\nbeen focused on uncovering the mechanisms behind it, in the hope of developing\na more adequate theoretical framework and having a better control over the\ntrained models. In this work, we adopt an alternate perspective, viewing the\nneural network as a dynamical system displacing input particles over time. We\nconduct a series of experiments and, by analyzing the network's behavior\nthrough its displacements, we show the presence of a low kinetic energy\ndisplacement bias in the transport map of the network, and link this bias with\ngeneralization performance. From this observation, we reformulate the learning\nproblem as follows: finding neural networks which solve the task while\ntransporting the data as efficiently as possible. This offers a novel\nformulation of the learning problem which allows us to provide regularity\nresults for the solution network, based on Optimal Transport theory. From a\npractical viewpoint, this allows us to propose a new learning algorithm, which\nautomatically adapts to the complexity of the given task, and leads to networks\nwith a high generalization ability even in low data regimes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:37:34 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 13:37:31 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 05:28:48 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 09:42:46 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Karkar", "Skander", ""], ["Ayed", "Ibrahim", ""], ["de B\u00e9zenac", "Emmanuel", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2009.08387", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Towards Stable Imbalanced Data Classification via Virtual Big Data\n  Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Big Data (VBD) proved to be effective to alleviate mode collapse and\nvanishing generator gradient as two major problems of Generative Adversarial\nNeural Networks (GANs) very recently. In this paper, we investigate the\ncapability of VBD to address two other major challenges in Machine Learning\nincluding deep autoencoder training and imbalanced data classification. First,\nwe prove that, VBD can significantly decrease the validation loss of\nautoencoders via providing them a huge diversified training data which is the\nkey to reach better generalization to minimize the over-fitting problem.\nSecond, we use the VBD to propose the first projection-based method called\ncross-concatenation to balance the skewed class distributions without\nover-sampling. We prove that, cross-concatenation can solve uncertainty problem\nof data driven methods for imbalanced classification.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 04:01:51 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "2009.08388", "submitter": "George Panagopoulos", "authors": "George Panagopoulos and Giannis Nikolentzos and Michalis Vazirgiannis", "title": "Transfer Graph Neural Networks for Pandemic Forecasting", "comments": "9 pages, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent outbreak of COVID-19 has affected millions of individuals around\nthe world and has posed a significant challenge to global healthcare. From the\nearly days of the pandemic, it became clear that it is highly contagious and\nthat human mobility contributes significantly to its spread. In this paper, we\nstudy the impact of population movement on the spread of COVID-19, and we\ncapitalize on recent advances in the field of representation learning on graphs\nto capture the underlying dynamics. Specifically, we create a graph where nodes\ncorrespond to a country's regions and the edge weights denote human mobility\nfrom one region to another. Then, we employ graph neural networks to predict\nthe number of future cases, encoding the underlying diffusion patterns that\ngovern the spread into our learning model. Furthermore, to account for the\nlimited amount of training data, we capitalize on the pandemic's asynchronous\noutbreaks across countries and use a model-agnostic meta-learning based method\nto transfer knowledge from one country's model to another's. We compare the\nproposed approach against simple baselines and more traditional forecasting\ntechniques in 3 European countries. Experimental results demonstrate the\nsuperiority of our method, highlighting the usefulness of GNNs in\nepidemiological prediction. Transfer learning provides the best model,\nhighlighting its potential to improve the accuracy of the predictions in case\nof secondary waves, if data from past/parallel outbreaks is utilized.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:23:52 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 16:00:31 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 18:43:17 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 10:32:36 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 14:53:57 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Panagopoulos", "George", ""], ["Nikolentzos", "Giannis", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2009.08390", "submitter": "Julio Omar Palacio Ni\\~no", "authors": "Julio Omar Palacio Ni\\~no", "title": "Detecci\\'on de comunidades en redes: Algoritmos y aplicaciones", "comments": "Master's Thesis", "journal-ref": "University of Granada (2013)", "doi": "10.13140/RG.2.2.15213.82400", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This master's thesis work has the objective of performing an analysis of the\nmethods for detecting communities in networks. As an initial part, I study of\nthe main features of graph theory and communities, as well as common measures\nin this problem. Subsequently, I was performed a review of the main methods of\ndetecting communities, developing a classification, taking into account its\ncharacteristics and computational complexity for the detection of strengths and\nweaknesses in the methods, as well as later works. Then, study the problem of\nclassification of a clustering method, this in order to evaluate the quality of\nthe communities detected by analyzing different measures. Finally conclusions\nare elaborated and possible lines of work that can be derived.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:18:06 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Ni\u00f1o", "Julio Omar Palacio", ""]]}, {"id": "2009.08392", "submitter": "Joshua Garland", "authors": "Joshua Garland, Keyan Ghazi-Zahedi, Jean-Gabriel Young, Laurent\n  H\\'ebert-Dufresne, Mirta Galesic", "title": "Impact and dynamics of hate and counter speech online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen-generated counter speech is a promising way to fight hate speech and\npromote peaceful, non-polarized discourse. However, there is a lack of\nlarge-scale longitudinal studies of its effectiveness for reducing hate speech.\nWe investigate the effectiveness of counter speech using several different\nmacro- and micro-level measures of over 180,000 political conversations that\ntook place on German Twitter over four years. We report on the dynamic\ninteractions of hate and counter speech over time and provide insights into\nwhether, as in `classic' bullying situations, organized efforts are more\neffective than independent individuals in steering online discourse. Taken\ntogether, our results build a multifaceted picture of the dynamics of hate and\ncounter speech online. They suggest that organized hate speech produced changes\nin the public discourse. Counter speech, especially when organized, could help\nin curbing hate speech in online discussions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:43:28 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:46:04 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Garland", "Joshua", ""], ["Ghazi-Zahedi", "Keyan", ""], ["Young", "Jean-Gabriel", ""], ["H\u00e9bert-Dufresne", "Laurent", ""], ["Galesic", "Mirta", ""]]}, {"id": "2009.08395", "submitter": "Tariq Habib Afridi Mr.", "authors": "Tariq Habib Afridi, Aftab Alam, Muhammad Numan Khan, Jawad Khan,\n  Young-Koo Lee", "title": "A Multimodal Memes Classification: A Survey and Open Research Issues", "comments": "This is a survey paper on recent state of the art VL models that can\n  be used for memes classification. it has 15 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:13:21 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Afridi", "Tariq Habib", ""], ["Alam", "Aftab", ""], ["Khan", "Muhammad Numan", ""], ["Khan", "Jawad", ""], ["Lee", "Young-Koo", ""]]}, {"id": "2009.08410", "submitter": "Konstantin Klemmer", "authors": "Konstantin Klemmer, Godwin Yeboah, Jo\\~ao Porto de Albuquerque,\n  Stephen A Jarvis", "title": "Population Mapping in Informal Settlements with High-Resolution\n  Satellite Imagery and Equitable Ground-Truth", "comments": "ML-IRL workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generalizable framework for the population estimation of dense,\ninformal settlements in low-income urban areas--so called 'slums'--using\nhigh-resolution satellite imagery. Precise population estimates are a crucial\nfactor for efficient resource allocations by government authorities and NGO's,\nfor instance in medical emergencies. We utilize equitable ground-truth data,\nwhich is gathered in collaboration with local communities: Through training and\ncommunity mapping, the local population contributes their unique domain\nknowledge, while also maintaining agency over their data. This practice allows\nus to avoid carrying forward potential biases into the modeling pipeline, which\nmight arise from a less rigorous ground-truthing approach. We contextualize our\napproach in respect to the ongoing discussion within the machine learning\ncommunity, aiming to make real-world machine learning applications more\ninclusive, fair and accountable. Because of the resource intensive ground-truth\ngeneration process, our training data is limited. We propose a gridded\npopulation estimation model, enabling flexible and customizable spatial\nresolutions. We test our pipeline on three experimental site in Nigeria,\nutilizing pre-trained and fine-tune vision networks to overcome data sparsity.\nOur findings highlight the difficulties of transferring common benchmark models\nto real-world tasks. We discuss this and propose steps forward.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:37:32 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Klemmer", "Konstantin", ""], ["Yeboah", "Godwin", ""], ["de Albuquerque", "Jo\u00e3o Porto", ""], ["Jarvis", "Stephen A", ""]]}, {"id": "2009.08420", "submitter": "Jonne Pohjankukka Dr.", "authors": "Jonne Pohjankukka, Sakari Tuominen, Jukka Heikkonen", "title": "Utilizing remote sensing data in forest inventory sampling via Bayesian\n  optimization", "comments": "36 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-area forest inventories a trade-off between the amount of data to be\nsampled and the costs of collecting the data is necessary. It is not always\npossible to have a very large data sample when dealing with sampling-based\ninventories. It is therefore necessary to optimize the sampling design in order\nto achieve optimal population parameter estimation. On the contrary, the\navailability of remote sensing (RS) data correlated with the forest inventory\nvariables is usually much higher. The combination of RS and the sampled field\nmeasurement data is often used for improving the forest inventory parameter\nestimation. In addition, it is also reasonable to study the utilization of RS\ndata in inventory sampling, which can further improve the estimation of forest\nvariables. In this study, we propose a data sampling method based on Bayesian\noptimization which uses RS data in forest inventory sample selection. The\npresented method applies the learned functional relationship between the RS and\ninventory data in new sampling decisions. We evaluate our method by conducting\nsimulated sampling experiments with both synthetic data and measured data from\nthe Aland region in Finland. The proposed method is benchmarked against two\nbaseline methods: simple random sampling and the local pivotal method. The\nresults of the simulated experiments show the best results in terms of MSE\nvalues for the proposed method when the functional relationship between RS and\ninventory data is correctly learned from the available training data.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:05:16 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Pohjankukka", "Jonne", ""], ["Tuominen", "Sakari", ""], ["Heikkonen", "Jukka", ""]]}, {"id": "2009.08424", "submitter": "Mariya Toneva", "authors": "Mariya Toneva, Otilia Stretcu, Barnabas Poczos, Leila Wehbe, Tom M.\n  Mitchell", "title": "Modeling Task Effects on Meaning Representation in the Brain via\n  Zero-Shot MEG Prediction", "comments": "accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How meaning is represented in the brain is still one of the big open\nquestions in neuroscience. Does a word (e.g., bird) always have the same\nrepresentation, or does the task under which the word is processed alter its\nrepresentation (answering \"can you eat it?\" versus \"can it fly?\")? The brain\nactivity of subjects who read the same word while performing different semantic\ntasks has been shown to differ across tasks. However, it is still not\nunderstood how the task itself contributes to this difference. In the current\nwork, we study Magnetoencephalography (MEG) brain recordings of participants\ntasked with answering questions about concrete nouns. We investigate the effect\nof the task (i.e. the question being asked) on the processing of the concrete\nnoun by predicting the millisecond-resolution MEG recordings as a function of\nboth the semantics of the noun and the task. Using this approach, we test\nseveral hypotheses about the task-stimulus interactions by comparing the\nzero-shot predictions made by these hypotheses for novel tasks and nouns not\nseen during training. We find that incorporating the task semantics\nsignificantly improves the prediction of MEG recordings, across participants.\nThe improvement occurs 475-550ms after the participants first see the word,\nwhich corresponds to what is considered to be the ending time of semantic\nprocessing for a word. These results suggest that only the end of semantic\nprocessing of a word is task-dependent, and pose a challenge for future\nresearch to formulate new hypotheses for earlier task effects as a function of\nthe task and stimuli.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:20:18 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 22:31:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Toneva", "Mariya", ""], ["Stretcu", "Otilia", ""], ["Poczos", "Barnabas", ""], ["Wehbe", "Leila", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2009.08427", "submitter": "Andrei Nicolicioiu", "authors": "Iulia Duta and Andrei Nicolicioiu and Marius Leordeanu", "title": "Discovering Dynamic Salient Regions with Spatio-Temporal Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks are perfectly suited to capture latent interactions\nbetween various entities in the spatio-temporal domain (e.g. videos). However,\nwhen an explicit structure is not available, it is not obvious what atomic\nelements should be represented as nodes. Current works generally use\npre-trained object detectors or fixed, predefined regions to extract graph\nnodes. In turn, our proposed model learns nodes that dynamically attach to\nsalient space-time regions, which are relevant for a higher-level task, without\nusing any object-level supervision. Constructing these localised, adaptive\nnodes gives our model inductive bias towards object-centric representations and\nwe show that it discovers regions that are well correlated with objects in the\nvideo. The localised nodes are the key components of the method and visualising\ntheir regions leads to a more explainable model. In extensive ablation studies\nand experiments on two challenging datasets we show superior performance to\nprevious graph neural networks models for video classification.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:23:38 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 13:00:34 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Duta", "Iulia", ""], ["Nicolicioiu", "Andrei", ""], ["Leordeanu", "Marius", ""]]}, {"id": "2009.08435", "submitter": "Youwei Liang", "authors": "Youwei Liang, Dong Huang", "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness", "comments": "15 pages, 4 figures; v5: corrected typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the Lipschitz properties of CNN are widely considered to be related to\nadversarial robustness, we theoretically characterize the $\\ell_1$ norm and\n$\\ell_\\infty$ norm of 2D multi-channel convolutional layers and provide\nefficient methods to compute the exact $\\ell_1$ norm and $\\ell_\\infty$ norm.\nBased on our theorem, we propose a novel regularization method termed norm\ndecay, which can effectively reduce the norms of convolutional layers and\nfully-connected layers. Experiments show that norm-regularization methods,\nincluding norm decay, weight decay, and singular value clipping, can improve\ngeneralization of CNNs. However, they can slightly hurt adversarial robustness.\nObserving this unexpected phenomenon, we compute the norms of layers in the\nCNNs trained with three different adversarial training frameworks and\nsurprisingly find that adversarially robust CNNs have comparable or even larger\nlayer norms than their non-adversarially robust counterparts. Furthermore, we\nprove that under a mild assumption, adversarially robust classifiers can be\nachieved, and can have an arbitrarily large Lipschitz constant. For this\nreason, enforcing small norms on CNN layers may be neither necessary nor\neffective in achieving adversarial robustness. The code is available at\nhttps://github.com/youweiliang/norm_robustness.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:33:50 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 06:28:59 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 07:34:27 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 02:58:32 GMT"}, {"version": "v5", "created": "Thu, 10 Jun 2021 06:21:01 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liang", "Youwei", ""], ["Huang", "Dong", ""]]}, {"id": "2009.08443", "submitter": "Joscha Diehl", "authors": "Joscha Diehl, Kurusch Ebrahimi-Fard, Nikolas Tapia", "title": "Tropical time series, iterated-sums signatures and quasisymmetric\n  functions", "comments": "fix notational errors, clarify certain proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the need for principled extraction of features from time series, we\nintroduce the iterated-sums signature over any commutative semiring. The case\nof the tropical semiring is a central, and our motivating, example, as it leads\nto features of (real-valued) time series that are not easily available using\nexisting signature-type objects.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:51:43 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 21:36:52 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Diehl", "Joscha", ""], ["Ebrahimi-Fard", "Kurusch", ""], ["Tapia", "Nikolas", ""]]}, {"id": "2009.08445", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, Rishikesh Jha, Tsendsuren Munkhdalai, Andrew McCallum", "title": "Self-Supervised Meta-Learning for Few-Shot Natural Language\n  Classification Tasks", "comments": "To appear in EMNLP 2020, camera-ready, link to code added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised pre-training of transformer models has revolutionized NLP\napplications. Such pre-training with language modeling objectives provides a\nuseful initial point for parameters that generalize well to new tasks with\nfine-tuning. However, fine-tuning is still data inefficient -- when there are\nfew labeled examples, accuracy can be low. Data efficiency can be improved by\noptimizing pre-training directly for future fine-tuning with few examples; this\ncan be treated as a meta-learning problem. However, standard meta-learning\ntechniques require many training tasks in order to generalize; unfortunately,\nfinding a diverse set of such supervised tasks is usually difficult. This paper\nproposes a self-supervised approach to generate a large, rich, meta-learning\ntask distribution from unlabeled text. This is achieved using a cloze-style\nobjective, but creating separate multi-class classification tasks by gathering\ntokens-to-be blanked from among only a handful of vocabulary terms. This yields\nas many unique meta-training tasks as the number of subsets of vocabulary\nterms. We meta-train a transformer model on this distribution of tasks using a\nrecent meta-learning framework. On 17 NLP tasks, we show that this\nmeta-training leads to better few-shot generalization than language-model\npre-training followed by finetuning. Furthermore, we show how the\nself-supervised tasks can be combined with supervised tasks for meta-learning,\nproviding substantial accuracy gains over previous supervised meta-learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:53:59 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 20:31:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bansal", "Trapit", ""], ["Jha", "Rishikesh", ""], ["Munkhdalai", "Tsendsuren", ""], ["McCallum", "Andrew", ""]]}, {"id": "2009.08447", "submitter": "Yujia Jin", "authors": "Yair Carmon, Yujia Jin, Aaron Sidford, Kevin Tian", "title": "Coordinate Methods for Matrix Games", "comments": "Accepted at FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop primal-dual coordinate methods for solving bilinear saddle-point\nproblems of the form $\\min_{x \\in \\mathcal{X}} \\max_{y\\in\\mathcal{Y}} y^\\top A\nx$ which contain linear programming, classification, and regression as special\ncases. Our methods push existing fully stochastic sublinear methods and\nvariance-reduced methods towards their limits in terms of per-iteration\ncomplexity and sample complexity. We obtain nearly-constant per-iteration\ncomplexity by designing efficient data structures leveraging Taylor\napproximations to the exponential and a binomial heap. We improve sample\ncomplexity via low-variance gradient estimators using dynamic sampling\ndistributions that depend on both the iterates and the magnitude of the matrix\nentries.\n  Our runtime bounds improve upon those of existing primal-dual methods by a\nfactor depending on sparsity measures of the $m$ by $n$ matrix $A$. For\nexample, when rows and columns have constant $\\ell_1/\\ell_2$ norm ratios, we\noffer improvements by a factor of $m+n$ in the fully stochastic setting and\n$\\sqrt{m+n}$ in the variance-reduced setting. We apply our methods to\ncomputational geometry problems, i.e. minimum enclosing ball, maximum inscribed\nball, and linear regression, and obtain improved complexity bounds. For linear\nregression with an elementwise nonnegative matrix, our guarantees improve on\nexact gradient methods by a factor of $\\sqrt{\\mathrm{nnz}(A)/(m+n)}$.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:55:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Carmon", "Yair", ""], ["Jin", "Yujia", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "2009.08449", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "'Less Than One'-Shot Learning: Learning N Classes From M<N Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks require large training sets but suffer from high\ncomputational cost and long training times. Training on much smaller training\nsets while maintaining nearly the same accuracy would be very beneficial. In\nthe few-shot learning setting, a model must learn a new class given only a\nsmall number of samples from that class. One-shot learning is an extreme form\nof few-shot learning where the model must learn a new class from a single\nexample. We propose the `less than one'-shot learning task where models must\nlearn $N$ new classes given only $M<N$ examples and we show that this is\nachievable with the help of soft labels. We use a soft-label generalization of\nthe k-Nearest Neighbors classifier to explore the intricate decision landscapes\nthat can be created in the `less than one'-shot learning setting. We analyze\nthese decision landscapes to derive theoretical lower bounds for separating $N$\nclasses using $M<N$ soft-label samples and investigate the robustness of the\nresulting systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:55:29 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2009.08451", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Pan Li, Ritesh Kumar, Bryan Hooi", "title": "MSTREAM: Fast Anomaly Detection in Multi-Aspect Streams", "comments": "The Web Conference (WWW), 2021", "journal-ref": null, "doi": "10.1145/3442381.3450023", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of entries in a multi-aspect data setting i.e., entries having\nmultiple dimensions, how can we detect anomalous activities in an unsupervised\nmanner? For example, in the intrusion detection setting, existing work seeks to\ndetect anomalous events or edges in dynamic graph streams, but this does not\nallow us to take into account additional attributes of each entry. Our work\naims to define a streaming multi-aspect data anomaly detection framework,\ntermed MSTREAM which can detect unusual group anomalies as they occur, in a\ndynamic manner. MSTREAM has the following properties: (a) it detects anomalies\nin multi-aspect data including both categorical and numeric attributes; (b) it\nis online, thus processing each record in constant time and constant memory;\n(c) it can capture the correlation between multiple aspects of the data.\nMSTREAM is evaluated over the KDDCUP99, CICIDS-DoS, UNSW-NB 15 and CICIDS-DDoS\ndatasets, and outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:16 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 14:11:06 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 23:42:21 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 14:49:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Li", "Pan", ""], ["Kumar", "Ritesh", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.08452", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Rui Liu, Bryan Hooi, Minji Yoon, Kijung Shin and\n  Christos Faloutsos", "title": "Real-Time Anomaly Detection in Edge Streams", "comments": "Extended Journal Version of arXiv:1911.04464", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges in an online manner, for the purpose of detecting unusual\nbehavior, using constant time and memory? Existing approaches aim to detect\nindividually surprising edges. In this work, we propose MIDAS, which focuses on\ndetecting microcluster anomalies, or suddenly arriving groups of suspiciously\nsimilar edges, such as lockstep behavior, including denial of service attacks\nin network traffic data. We further propose MIDAS-F, to solve the problem by\nwhich anomalies are incorporated into the algorithm's internal states, creating\na `poisoning' effect that can allow future anomalies to slip through\nundetected. MIDAS-F introduces two modifications: 1) We modify the anomaly\nscoring function, aiming to reduce the `poisoning' effect of newly arriving\nedges; 2) We introduce a conditional merge step, which updates the algorithm's\ndata structures after each time tick, but only if the anomaly score is below a\nthreshold value, also to reduce the `poisoning' effect. Experiments show that\nMIDAS-F has significantly higher accuracy than MIDAS. MIDAS has the following\nproperties: (a) it detects microcluster anomalies while providing theoretical\nguarantees about its false positive probability; (b) it is online, thus\nprocessing each edge in constant time and constant memory, and also processes\nthe data orders-of-magnitude faster than state-of-the-art approaches; (c) it\nprovides up to 62% higher ROC-AUC than state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 11:38:44 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Liu", "Rui", ""], ["Hooi", "Bryan", ""], ["Yoon", "Minji", ""], ["Shin", "Kijung", ""], ["Faloutsos", "Christos", ""]]}, {"id": "2009.08453", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Marios Savvides", "title": "MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet\n  without Tricks", "comments": "12 pages. Code and trained models are available at:\n  https://github.com/szq0214/MEAL-V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple yet effective distillation framework that is able to\nboost the vanilla ResNet-50 to 80%+ Top-1 accuracy on ImageNet without tricks.\nWe construct such a framework through analyzing the problems in the existing\nclassification system and simplify the base method ensemble knowledge\ndistillation via discriminators by: (1) adopting the similarity loss and\ndiscriminator only on the final outputs and (2) using the average of softmax\nprobabilities from all teacher ensembles as the stronger supervision.\nIntriguingly, three novel perspectives are presented for distillation: (1)\nweight decay can be weakened or even completely removed since the soft label\nalso has a regularization effect; (2) using a good initialization for students\nis critical; and (3) one-hot/hard label is not necessary in the distillation\nprocess if the weights are well initialized. We show that such a\nstraight-forward framework can achieve state-of-the-art results without\ninvolving any commonly-used techniques, such as architecture modification;\noutside training data beyond ImageNet; autoaug/randaug; cosine learning rate;\nmixup/cutmix training; label smoothing; etc. Our method obtains 80.67% top-1\naccuracy on ImageNet using a single crop-size of 224x224 with vanilla\nResNet-50, outperforming the previous state-of-the-arts by a significant margin\nunder the same network structure. Our result can be regarded as a strong\nbaseline using knowledge distillation, and to our best knowledge, this is also\nthe first method that is able to boost vanilla ResNet-50 to surpass 80% on\nImageNet without architecture modification or additional training data. On\nsmaller ResNet-18, our distillation framework consistently improves from 69.76%\nto 73.19%, which shows tremendous practical values in real-world applications.\nOur code and models are available at: https://github.com/szq0214/MEAL-V2.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:33 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 17:40:19 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Savvides", "Marios", ""]]}, {"id": "2009.08454", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Bryan Hooi", "title": "ExGAN: Adversarial Generation of Extreme Samples", "comments": "AAAI Conference on Artificial Intelligence (AAAI), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating the risk arising from extreme events is a fundamental goal with\nmany applications, such as the modelling of natural disasters, financial\ncrashes, epidemics, and many others. To manage this risk, a vital step is to be\nable to understand or generate a wide range of extreme scenarios. Existing\napproaches based on Generative Adversarial Networks (GANs) excel at generating\nrealistic samples, but seek to generate typical samples, rather than extreme\nsamples. Hence, in this work, we propose ExGAN, a GAN-based approach to\ngenerate realistic and extreme samples. To model the extremes of the training\ndistribution in a principled way, our work draws from Extreme Value Theory\n(EVT), a probabilistic approach for modelling the extreme tails of\ndistributions. For practical utility, our framework allows the user to specify\nboth the desired extremeness measure, as well as the desired extremeness\nprobability they wish to sample at. Experiments on real US Precipitation data\nshow that our method generates realistic samples, based on visual inspection\nand quantitative measures, in an efficient manner. Moreover, generating\nincreasingly extreme examples using ExGAN can be done in constant time (with\nrespect to the extremeness probability $\\tau$), as opposed to the\n$\\mathcal{O}(\\frac{1}{\\tau})$ time required by the baseline approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:36 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:17:31 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 15:49:39 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.08457", "submitter": "Baihan Lin", "authors": "Baihan Lin", "title": "Online Semi-Supervised Learning in Contextual Bandits with Episodic\n  Reward", "comments": "Proceeding of AJCAI 2020. This article supersedes our work\n  arXiv:1802.00981 on contextual bandits in nonstationary setting, introduces a\n  new problem setting with episodically revealed reward, and provides a novel\n  solution by propagating pseudo-feedbacks to un-rewarded cases from\n  self-supervision. Also check out our speaker diarization application of this\n  algorithm at arXiv:2006.04376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We considered a novel practical problem of online learning with episodically\nrevealed rewards, motivated by several real-world applications, where the\ncontexts are nonstationary over different episodes and the reward feedbacks are\nnot always available to the decision making agents. For this online\nsemi-supervised learning setting, we introduced Background Episodic Reward\nLinUCB (BerlinUCB), a solution that easily incorporates clustering as a\nself-supervision module to provide useful side information when rewards are not\nobserved. Our experiments on a variety of datasets, both in stationary and\nnonstationary environments of six different scenarios, demonstrated clear\nadvantages of the proposed approach over the standard contextual bandit.\nLastly, we introduced a relevant real-life example where this problem setting\nis especially useful.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 20:41:02 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 03:29:56 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lin", "Baihan", ""]]}, {"id": "2009.08474", "submitter": "Yukiya Hono", "authors": "Yukiya Hono, Kazuna Tsuboi, Kei Sawada, Kei Hashimoto, Keiichiro Oura,\n  Yoshihiko Nankaku, Keiichi Tokuda", "title": "Hierarchical Multi-Grained Generative Model for Expressive Speech\n  Synthesis", "comments": "5 pages, accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hierarchical generative model with a multi-grained\nlatent variable to synthesize expressive speech. In recent years, fine-grained\nlatent variables are introduced into the text-to-speech synthesis that enable\nthe fine control of the prosody and speaking styles of synthesized speech.\nHowever, the naturalness of speech degrades when these latent variables are\nobtained by sampling from the standard Gaussian prior. To solve this problem,\nwe propose a novel framework for modeling the fine-grained latent variables,\nconsidering the dependence on an input text, a hierarchical linguistic\nstructure, and a temporal structure of latent variables. This framework\nconsists of a multi-grained variational autoencoder, a conditional prior, and a\nmulti-level auto-regressive latent converter to obtain the different\ntime-resolution latent variables and sample the finer-level latent variables\nfrom the coarser-level ones by taking into account the input text. Experimental\nresults indicate an appropriate method of sampling fine-grained latent\nvariables without the reference signal at the synthesis stage. Our proposed\nframework also provides the controllability of speaking style in an entire\nutterance.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:00:19 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Hono", "Yukiya", ""], ["Tsuboi", "Kazuna", ""], ["Sawada", "Kei", ""], ["Hashimoto", "Kei", ""], ["Oura", "Keiichiro", ""], ["Nankaku", "Yoshihiko", ""], ["Tokuda", "Keiichi", ""]]}, {"id": "2009.08496", "submitter": "Elchanan Solomon", "authors": "Elchanan Solomon, Alexander Wagner, Paul Bendich", "title": "A Fast and Robust Method for Global Topological Functional Optimization", "comments": "Added new experiments: one on robustness, the other a cell\n  segmentation task. Other parts of the paper were clarified by including more\n  background exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Topological statistics, in the form of persistence diagrams, are a class of\nshape descriptors that capture global structural information in data. The\nmapping from data structures to persistence diagrams is almost everywhere\ndifferentiable, allowing for topological gradients to be backpropagated to\nordinary gradients. However, as a method for optimizing a topological\nfunctional, this backpropagation method is expensive, unstable, and produces\nvery fragile optima. Our contribution is to introduce a novel backpropagation\nscheme that is significantly faster, more stable, and produces more robust\noptima. Moreover, this scheme can also be used to produce a stable\nvisualization of dots in a persistence diagram as a distribution over critical,\nand near-critical, simplices in the data structure.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:46:16 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:59:39 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 21:25:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Solomon", "Elchanan", ""], ["Wagner", "Alexander", ""], ["Bendich", "Paul", ""]]}, {"id": "2009.08497", "submitter": "Tarek Richard Besold", "authors": "Lorijn Zaadnoordijk, Tarek R. Besold, Rhodri Cusack", "title": "The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons\n  from Infant Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a surge in popularity of supervised Deep Learning, the desire to reduce\nthe dependence on curated, labelled data sets and to leverage the vast\nquantities of unlabelled data available recently triggered renewed interest in\nunsupervised learning algorithms. Despite a significantly improved performance\ndue to approaches such as the identification of disentangled latent\nrepresentations, contrastive learning, and clustering optimisations, the\nperformance of unsupervised machine learning still falls short of its\nhypothesised potential. Machine learning has previously taken inspiration from\nneuroscience and cognitive science with great success. However, this has mostly\nbeen based on adult learners with access to labels and a vast amount of prior\nknowledge. In order to push unsupervised machine learning forward, we argue\nthat developmental science of infant cognition might hold the key to unlocking\nthe next generation of unsupervised learning approaches. Conceptually, human\ninfant learning is the closest biological parallel to artificial unsupervised\nlearning, as infants too must learn useful representations from unlabelled\ndata. In contrast to machine learning, these new representations are learned\nrapidly and from relatively few examples. Moreover, infants learn robust\nrepresentations that can be used flexibly and efficiently in a number of\ndifferent tasks and contexts. We identify five crucial factors enabling\ninfants' quality and speed of learning, assess the extent to which these have\nalready been exploited in machine learning, and propose how further adoption of\nthese factors can give rise to previously unseen performance levels in\nunsupervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:47:06 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zaadnoordijk", "Lorijn", ""], ["Besold", "Tarek R.", ""], ["Cusack", "Rhodri", ""]]}, {"id": "2009.08507", "submitter": "Zifan Wang", "authors": "Xuan Chen, Zifan Wang, Yucai Fan, Bonan Jin, Piotr Mardziel, Carlee\n  Joe-Wong, Anupam Datta", "title": "Reconstructing Actions To Explain Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attribution has been a foundational building block for explaining the\ninput feature importance in supervised learning with Deep Neural Network\n(DNNs), but face new challenges when applied to deep Reinforcement Learning\n(RL).We propose a new approach to explaining deep RL actions by defining a\nclass of \\emph{action reconstruction} functions that mimic the behavior of a\nnetwork in deep RL. This approach allows us to answer more complex\nexplainability questions than direct application of DNN attribution methods,\nwhich we adapt to \\emph{behavior-level attributions} in building our action\nreconstructions. It also allows us to define \\emph{agreement}, a metric for\nquantitatively evaluating the explainability of our methods. Our experiments on\na variety of Atari games suggest that perturbation-based attribution methods\nare significantly more suitable in reconstructing actions to explain the deep\nRL agent than alternative attribution methods, and show greater\n\\emph{agreement} than existing explainability work utilizing attention. We\nfurther show that action reconstruction allows us to demonstrate how a deep\nagent learns to play Pac-Man game.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 19:25:56 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 06:09:26 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 01:42:38 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Chen", "Xuan", ""], ["Wang", "Zifan", ""], ["Fan", "Yucai", ""], ["Jin", "Bonan", ""], ["Mardziel", "Piotr", ""], ["Joe-Wong", "Carlee", ""], ["Datta", "Anupam", ""]]}, {"id": "2009.08510", "submitter": "Kouame Kouassi", "authors": "Kouame Hermann Kouassi and Deshendran Moodley", "title": "Automatic deep learning for trend prediction in time series data", "comments": "arXiv admin note: text overlap with arXiv:2009.07943", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Neural Network (DNN) algorithms have been explored for\npredicting trends in time series data. In many real world applications, time\nseries data are captured from dynamic systems. DNN models must provide stable\nperformance when they are updated and retrained as new observations becomes\navailable. In this work we explore the use of automatic machine learning\ntechniques to automate the algorithm selection and hyperparameter optimisation\nprocess for trend prediction. We demonstrate how a recent AutoML tool,\nspecifically the HpBandSter framework, can be effectively used to automate DNN\nmodel development. Our AutoML experiments found optimal configurations that\nproduced models that compared well against the average performance and\nstability levels of configurations found during the manual experiments across\nfour data sets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 19:47:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kouassi", "Kouame Hermann", ""], ["Moodley", "Deshendran", ""]]}, {"id": "2009.08525", "submitter": "Kevin Moran P", "authors": "Prem Devanbu, Matthew Dwyer, Sebastian Elbaum, Michael Lowry, Kevin\n  Moran, Denys Poshyvanyk, Baishakhi Ray, Rishabh Singh, and Xiangyu Zhang", "title": "Deep Learning & Software Engineering: State of Research and Future\n  Directions", "comments": "Community Report from the 2019 NSF Workshop on Deep Learning &\n  Software Engineering, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the current transformative potential of research that sits at the\nintersection of Deep Learning (DL) and Software Engineering (SE), an\nNSF-sponsored community workshop was conducted in co-location with the 34th\nIEEE/ACM International Conference on Automated Software Engineering (ASE'19) in\nSan Diego, California. The goal of this workshop was to outline high priority\nareas for cross-cutting research. While a multitude of exciting directions for\nfuture work were identified, this report provides a general summary of the\nresearch areas representing the areas of highest priority which were discussed\nat the workshop. The intent of this report is to serve as a potential roadmap\nto guide future work that sits at the intersection of SE & DL.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 20:46:08 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Devanbu", "Prem", ""], ["Dwyer", "Matthew", ""], ["Elbaum", "Sebastian", ""], ["Lowry", "Michael", ""], ["Moran", "Kevin", ""], ["Poshyvanyk", "Denys", ""], ["Ray", "Baishakhi", ""], ["Singh", "Rishabh", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2009.08528", "submitter": "Ran Zhang", "authors": "Ran Zhang, Miao Wang, and Lin X. Cai", "title": "SREC: Proactive Self-Remedy of Energy-Constrained UAV-Based Networks via\n  Deep Reinforcement Learning", "comments": "6 pages, IEEE Global Communications Conference, 7-11 December 2020,\n  Taipei, Taiwan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-aware control for multiple unmanned aerial vehicles (UAVs) is one of\nthe major research interests in UAV based networking. Yet few existing works\nhave focused on how the network should react around the timing when the UAV\nlineup is changed. In this work, we study proactive self-remedy of\nenergy-constrained UAV networks when one or more UAVs are short of energy and\nabout to quit for charging. We target at an energy-aware optimal UAV control\npolicy which proactively relocates the UAVs when any UAV is about to quit the\nnetwork, rather than passively dispatches the remaining UAVs after the quit.\nSpecifically, a deep reinforcement learning (DRL)-based self remedy approach,\nnamed SREC-DRL, is proposed to maximize the accumulated user satisfaction\nscores for a certain period within which at least one UAV will quit the\nnetwork. To handle the continuous state and action space in the problem, the\nstate-of-the-art algorithm of the actor-critic DRL, i.e., deep deterministic\npolicy gradient (DDPG), is applied with better convergence stability. Numerical\nresults demonstrate that compared with the passive reaction method, the\nproposed SREC-DRL approach shows a $12.12\\%$ gain in accumulative user\nsatisfaction score during the remedy period.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 20:51:17 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zhang", "Ran", ""], ["Wang", "Miao", ""], ["Cai", "Lin X.", ""]]}, {"id": "2009.08541", "submitter": "Zidi Xiu", "authors": "Zidi Xiu, Chenyang Tao, Michael Gao, Connor Davis, Benjamin A.\n  Goldstein, Ricardo Henao", "title": "Variational Disentanglement for Rare Event Modeling", "comments": "Accepted to AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining the increasing availability and abundance of healthcare data and\nthe current advances in machine learning methods have created renewed\nopportunities to improve clinical decision support systems. However, in\nhealthcare risk prediction applications, the proportion of cases with the\ncondition (label) of interest is often very low relative to the available\nsample size. Though very prevalent in healthcare, such imbalanced\nclassification settings are also common and challenging in many other\nscenarios. So motivated, we propose a variational disentanglement approach to\nsemi-parametrically learn from rare events in heavily imbalanced classification\nproblems. Specifically, we leverage the imposed extreme-distribution behavior\non a latent space to extract information from low-prevalence events, and\ndevelop a robust prediction arm that joins the merits of the generalized\nadditive model and isotonic neural nets. Results on synthetic studies and\ndiverse real-world datasets, including mortality prediction on a COVID-19\ncohort, demonstrate that the proposed approach outperforms existing\nalternatives.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 21:35:36 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 02:29:41 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 23:13:43 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 20:28:29 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 14:50:43 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Xiu", "Zidi", ""], ["Tao", "Chenyang", ""], ["Gao", "Michael", ""], ["Davis", "Connor", ""], ["Goldstein", "Benjamin A.", ""], ["Henao", "Ricardo", ""]]}, {"id": "2009.08551", "submitter": "Li Li", "authors": "Li Li, Stephan Hoyer, Ryan Pederson, Ruoxi Sun, Ekin D. Cubuk, Patrick\n  Riley, Kieron Burke", "title": "Kohn-Sham equations as regularizer: building prior knowledge into\n  machine-learned physics", "comments": null, "journal-ref": "Phys. Rev. Lett. 126, 036401 (2021)", "doi": "10.1103/PhysRevLett.126.036401", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Including prior knowledge is important for effective machine learning models\nin physics, and is usually achieved by explicitly adding loss terms or\nconstraints on model architectures. Prior knowledge embedded in the physics\ncomputation itself rarely draws attention. We show that solving the Kohn-Sham\nequations when training neural networks for the exchange-correlation functional\nprovides an implicit regularization that greatly improves generalization. Two\nseparations suffice for learning the entire one-dimensional H$_2$ dissociation\ncurve within chemical accuracy, including the strongly correlated region. Our\nmodels also generalize to unseen types of molecules and overcome\nself-interaction error.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:06:39 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 20:03:52 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Li", "Li", ""], ["Hoyer", "Stephan", ""], ["Pederson", "Ryan", ""], ["Sun", "Ruoxi", ""], ["Cubuk", "Ekin D.", ""], ["Riley", "Patrick", ""], ["Burke", "Kieron", ""]]}, {"id": "2009.08559", "submitter": "Abhinav Aggarwal", "authors": "Abhinav Aggarwal, Zekun Xu, Oluwaseyi Feyisetan, Nathanael Teissier", "title": "On Primes, Log-Loss Scores and (No) Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership Inference Attacks exploit the vulnerabilities of exposing models\ntrained on customer data to queries by an adversary. In a recently proposed\nimplementation of an auditing tool for measuring privacy leakage from sensitive\ndatasets, more refined aggregates like the Log-Loss scores are exposed for\nsimulating inference attacks as well as to assess the total privacy leakage\nbased on the adversary's predictions. In this paper, we prove that this\nadditional information enables the adversary to infer the membership of any\nnumber of datapoints with full accuracy in a single query, causing complete\nmembership privacy breach. Our approach obviates any attack model training or\naccess to side knowledge with the adversary. Moreover, our algorithms are\nagnostic to the model under attack and hence, enable perfect membership\ninference even for models that do not memorize or overfit. In particular, our\nobservations provide insight into the extent of information leakage from\nstatistical aggregates and how they can be exploited.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:35:12 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Aggarwal", "Abhinav", ""], ["Xu", "Zekun", ""], ["Feyisetan", "Oluwaseyi", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2009.08562", "submitter": "Anders Host-Madsen", "authors": "Anders Host-Madsen", "title": "Bounds for Learning Lossless Source Coding", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper asks a basic question: how much training is required to beat a\nuniversal source coder? Traditionally, there have been two types of source\ncoders: fixed, optimum coders such as Huffman coders; and universal source\ncoders, such as Lempel-Ziv The paper considers a third type of source coders:\nlearned coders. These are coders that are trained on data of a particular type,\nand then used to encode new data of that type. This is a type of coder that has\nrecently become very popular for (lossy) image and video coding.\n  The paper consider two criteria for performance of learned coders: the\naverage performance over training data, and a guaranteed performance over all\ntraining except for some error probability $P_e$. In both cases the coders are\nevaluated with respect to redundancy.\n  The paper considers the IID binary case and binary Markov chains. In both\ncases it is shown that the amount of training data required is very moderate:\nto code sequences of length $l$ the amount of training data required to beat a\nuniversal source coder is $m=K\\frac{l}{\\log l}$, where the constant in front\ndepends the case considered.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 00:07:02 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Host-Madsen", "Anders", ""]]}, {"id": "2009.08563", "submitter": "Saeed Seyyedi", "authors": "Saeed Seyyedi, Margaret J. Wong, Debra M. Ikeda, Curtis P. Langlotz", "title": "SCREENet: A Multi-view Deep Convolutional Neural Network for\n  Classification of High-resolution Synthetic Mammographic Screening Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To develop and evaluate the accuracy of a multi-view deep learning\napproach to the analysis of high-resolution synthetic mammograms from digital\nbreast tomosynthesis screening cases, and to assess the effect on accuracy of\nimage resolution and training set size. Materials and Methods: In a\nretrospective study, 21,264 screening digital breast tomosynthesis (DBT) exams\nobtained at our institution were collected along with associated radiology\nreports. The 2D synthetic mammographic images from these exams, with varying\nresolutions and data set sizes, were used to train a multi-view deep\nconvolutional neural network (MV-CNN) to classify screening images into BI-RADS\nclasses (BI-RADS 0, 1 and 2) before evaluation on a held-out set of exams.\n  Results: Area under the receiver operating characteristic curve (AUC) for\nBI-RADS 0 vs non-BI-RADS 0 class was 0.912 for the MV-CNN trained on the full\ndataset. The model obtained accuracy of 84.8%, recall of 95.9% and precision of\n95.0%. This AUC value decreased when the same model was trained with 50% and\n25% of images (AUC = 0.877, P=0.010 and 0.834, P=0.009 respectively). Also, the\nperformance dropped when the same model was trained using images that were\nunder-sampled by 1/2 and 1/4 (AUC = 0.870, P=0.011 and 0.813, P=0.009\nrespectively).\n  Conclusion: This deep learning model classified high-resolution synthetic\nmammography scans into normal vs needing further workup using tens of thousands\nof high-resolution images. Smaller training data sets and lower resolution\nimages both caused significant decrease in performance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 00:12:33 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 23:05:47 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 19:36:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Seyyedi", "Saeed", ""], ["Wong", "Margaret J.", ""], ["Ikeda", "Debra M.", ""], ["Langlotz", "Curtis P.", ""]]}, {"id": "2009.08574", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan and Mikhail Belkin and Caroline Uhler", "title": "Linear Convergence and Implicit Regularization of Generalized Mirror\n  Descent with Time-Dependent Mirrors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following questions are fundamental to understanding the properties of\nover-parameterization in modern machine learning: (1) Under what conditions and\nat what rate does training converge to a global minimum? (2) What form of\nimplicit regularization occurs through training? While significant progress has\nbeen made in answering both of these questions for gradient descent, they have\nyet to be answered more completely for general optimization methods. In this\nwork, we establish sufficient conditions for linear convergence and obtain\napproximate implicit regularization results for generalized mirror descent\n(GMD), a generalization of mirror descent with a possibly time-dependent\nmirror. GMD subsumes popular first order optimization methods including\ngradient descent, mirror descent, and preconditioned gradient descent methods\nsuch as Adagrad. By using the Polyak-Lojasiewicz inequality, we first present a\nsimple analysis under which non-stochastic GMD converges linearly to a global\nminimum. We then present a novel, Taylor-series based analysis to establish\nsufficient conditions for linear convergence of stochastic GMD. As a corollary,\nour result establishes sufficient conditions and provides learning rates for\nlinear convergence of stochastic mirror descent and Adagrad. Lastly, we obtain\napproximate implicit regularization results for GMD by proving that GMD\nconverges to an interpolating solution that is approximately the closest\ninterpolating solution to the initialization in l2-norm in the dual space,\nthereby generalizing the result of Azizan, Lale, and Hassibi (2019) in the full\nbatch setting.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:05:14 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Belkin", "Mikhail", ""], ["Uhler", "Caroline", ""]]}, {"id": "2009.08576", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, Michael\n  Carbin", "title": "Pruning Neural Networks at Initialization: Why are We Missing the Mark?", "comments": "Published in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored the possibility of pruning neural networks at\ninitialization. We assess proposals for doing so: SNIP (Lee et al., 2019),\nGraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude\npruning. Although these methods surpass the trivial baseline of random pruning,\nthey remain below the accuracy of magnitude pruning after training, and we\nendeavor to understand why. We show that, unlike pruning after training,\nrandomly shuffling the weights these methods prune within each layer or\nsampling new initial values preserves or improves accuracy. As such, the\nper-weight pruning decisions made by these methods can be replaced by a\nper-layer choice of the fraction of weights to prune. This property suggests\nbroader challenges with the underlying pruning heuristics, the desire to prune\nat initialization, or both.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:13:38 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 21:38:32 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Frankle", "Jonathan", ""], ["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""], ["Carbin", "Michael", ""]]}, {"id": "2009.08578", "submitter": "Rodolfo Lobo", "authors": "Rodolfo Anibal Lobo and Marcos Eduardo Valle", "title": "Ensemble of Binary Classifiers Combined Using Recurrent Correlation\n  Associative Memories", "comments": "14 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble method should cleverly combine a group of base classifiers to\nyield an improved classifier. The majority vote is an example of a methodology\nused to combine classifiers in an ensemble method. In this paper, we propose to\ncombine classifiers using an associative memory model. Precisely, we introduce\nensemble methods based on recurrent correlation associative memories (RCAMs)\nfor binary classification problems. We show that an RCAM-based ensemble\nclassifier can be viewed as a majority vote classifier whose weights depend on\nthe similarity between the base classifiers and the resulting ensemble method.\nMore precisely, the RCAM-based ensemble combines the classifiers using a\nrecurrent consult and vote scheme. Furthermore, computational experiments\nconfirm the potential application of the RCAM-based ensemble method for binary\nclassification problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 01:16:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lobo", "Rodolfo Anibal", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2009.08586", "submitter": "Ting-Han Fan", "authors": "Ting-Han Fan, Peter J. Ramadge", "title": "A Contraction Approach to Model-based Reinforcement Learning", "comments": "The 24th International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its experimental success, Model-based Reinforcement Learning still\nlacks a complete theoretical understanding. To this end, we analyze the error\nin the cumulative reward using a contraction approach. We consider both\nstochastic and deterministic state transitions for continuous (non-discrete)\nstate and action spaces. This approach doesn't require strong assumptions and\ncan recover the typical quadratic error to the horizon. We prove that branched\nrollouts can reduce this error and are essential for deterministic transitions\nto have a Bellman contraction. Our analysis of policy mismatch error also\napplies to Imitation Learning. In this case, we show that GAN-type learning has\nan advantage over Behavioral Cloning when its discriminator is well-trained.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:03:14 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 11:35:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fan", "Ting-Han", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2009.08593", "submitter": "Rodrigo de Lamare", "authors": "Yi Yu, Tao Yang, Hongyang Chen, Rodrigo C. de Lamare, Yingsong Li", "title": "Sparsity-Aware SSAF Algorithm with Individual Weighting Factors for\n  Acoustic Echo Cancellation", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and analyze the sparsity-aware sign subband\nadaptive filtering with individual weighting factors (S-IWF-SSAF) algorithm,\nand consider its application in acoustic echo cancellation (AEC). Furthermore,\nwe design a joint optimization scheme of the step-size and the sparsity penalty\nparameter to enhance the S-IWF-SSAF performance in terms of convergence rate\nand steady-state error. A theoretical analysis shows that the S-IWF-SSAF\nalgorithm outperforms the previous sign subband adaptive filtering with\nindividual weighting factors (IWF-SSAF) algorithm in sparse scenarios. In\nparticular, compared with the existing analysis on the IWF-SSAF algorithm, the\nproposed analysis does not require the assumptions of large number of subbands,\nlong adaptive filter, and paraunitary analysis filter bank, and matches well\nthe simulated results. Simulations in both system identification and AEC\nsituations have demonstrated our theoretical analysis and the effectiveness of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:27:44 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yu", "Yi", ""], ["Yang", "Tao", ""], ["Chen", "Hongyang", ""], ["de Lamare", "Rodrigo C.", ""], ["Li", "Yingsong", ""]]}, {"id": "2009.08606", "submitter": "Shuyan Wang", "authors": "Shuyan Wang", "title": "Causal Clustering for 1-Factor Measurement Models on Data with Various\n  Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tetrad constraint is a condition of which the satisfaction signals a rank\nreduction of a covariance submatrix and is used to design causal discovery\nalgorithms that detects the existence of latent (unmeasured) variables, such as\nFOFC. Initially such algorithms only work for cases where the measured and\nlatent variables are all Gaussian and have linear relations (Gaussian-Gaussian\nCase). It has been shown that a unidimentional latent variable model implies\ntetrad constraints when the measured and latent variables are all binary\n(Binary-Binary case). This paper proves that the tetrad constraint can also be\nentailed when the measured variables are of mixed data types and when the\nmeasured variables are discrete and the latent common causes are continuous,\nwhich implies that any clustering algorithm relying on this constraint can work\non those cases. Each case is shown with an example and a proof. The performance\nof FOFC on mixed data is shown by simulation studies and is compared with some\nalgorithms with similar functions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 03:15:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Shuyan", ""]]}, {"id": "2009.08607", "submitter": "Jiaqi Lv", "authors": "Jiaqi Lv, Tianran Wu, Chenglun Peng, Yunpeng Liu, Ning Xu, Xin Geng", "title": "Compact Learning for Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) studies the problem where each instance is\nassociated with multiple relevant labels, which leads to the exponential growth\nof output space. MLC encourages a popular framework named label compression\n(LC) for capturing label dependency with dimension reduction. Nevertheless,\nmost existing LC methods failed to consider the influence of the feature space\nor misguided by original problematic features, so that may result in\nperformance degeneration. In this paper, we present a compact learning (CL)\nframework to embed the features and labels simultaneously and with mutual\nguidance. The proposal is a versatile concept, hence the embedding way is\narbitrary and independent of the subsequent learning process. Following its\nspirit, a simple yet effective implementation called compact multi-label\nlearning (CMLL) is proposed to learn a compact low-dimensional representation\nfor both spaces. CMLL maximizes the dependence between the embedded spaces of\nthe labels and features, and minimizes the loss of label space recovery\nconcurrently. Theoretically, we provide a general analysis for different\nembedding methods. Practically, we conduct extensive experiments to validate\nthe effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 03:19:14 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lv", "Jiaqi", ""], ["Wu", "Tianran", ""], ["Peng", "Chenglun", ""], ["Liu", "Yunpeng", ""], ["Xu", "Ning", ""], ["Geng", "Xin", ""]]}, {"id": "2009.08621", "submitter": "Hai Dong", "authors": "Mingwei Zhang, Jiawei Zhao, Hai Dong, Ke Deng, and Ying Liu", "title": "A Knowledge Graph based Approach for Mobile Application Recommendation", "comments": "15 pages. The 18th International Conference on Service Oriented\n  Computing (ICSOC 2020) (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid prevalence of mobile devices and the dramatic proliferation of\nmobile applications (apps), app recommendation becomes an emergent task that\nwould benefit both app users and stockholders. How to effectively organize and\nmake full use of rich side information of users and apps is a key challenge to\naddress the sparsity issue for traditional approaches. To meet this challenge,\nwe proposed a novel end-to-end Knowledge Graph Convolutional Embedding\nPropagation Model (KGEP) for app recommendation. Specifically, we first\ndesigned a knowledge graph construction method to model the user and app side\ninformation, then adopted KG embedding techniques to capture the factual\ntriplet-focused semantics of the side information related to the first-order\nstructure of the KG, and finally proposed a relation-weighted convolutional\nembedding propagation model to capture the recommendation-focused semantics\nrelated to high-order structure of the KG. Extensive experiments conducted on a\nreal-world dataset validate the effectiveness of the proposed approach compared\nto the state-of-the-art recommendation approaches.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 04:17:23 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zhang", "Mingwei", ""], ["Zhao", "Jiawei", ""], ["Dong", "Hai", ""], ["Deng", "Ke", ""], ["Liu", "Ying", ""]]}, {"id": "2009.08626", "submitter": "Taeyeong Choi", "authors": "Taeyeong Choi, Benjamin Pyenson, Juergen Liebig, Theodore P. Pavlic", "title": "Identification of Abnormal States in Videos of Ants Undergoing Social\n  Phase Change", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biology is both an important application area and a source of motivation for\ndevelopment of advanced machine learning techniques. Although much attention\nhas been paid to large and complex data sets resulting from high-throughput\nsequencing, advances in high-quality video recording technology have begun to\ngenerate similarly rich data sets requiring sophisticated techniques from both\ncomputer vision and time-series analysis. Moreover, just as studying gene\nexpression patterns in one organism can reveal general principles that apply to\nother organisms, the study of complex social interactions in an experimentally\ntractable model system, such as a laboratory ant colony, can provide general\nprinciples about the dynamics many other social groups. Here, we focus on one\nsuch example from the study of reproductive regulation in small laboratory\ncolonies of $\\sim$50 Harpgenathos ants. These ants can be artificially induced\nto begin a $\\sim$20 day process of hierarchy reformation. Although the\nconclusion of this process is conspicuous to a human observer, it is still\nunclear which behaviors during the transients are contributing to the process.\nTo address this issue, we explore the potential application of One-class\nClassification (OC) to the detection of abnormal states in ant colonies for\nwhich behavioral data is only available for the normal societal conditions\nduring training. Specifically, we build upon the Deep Support Vector Data\nDescription (DSVDD) and introduce the Inner-Outlier Generator (IO-GEN) that\nsynthesizes fake \"inner outlier\" observations during training that are near the\ncenter of the DSVDD data description. We show that IO-GEN increases the\nreliability of the final OC classifier relative to other DSVDD baselines. This\nmethod can be used to screen video frames for which additional human\nobservation is needed.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 04:48:47 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Choi", "Taeyeong", ""], ["Pyenson", "Benjamin", ""], ["Liebig", "Juergen", ""], ["Pavlic", "Theodore P.", ""]]}, {"id": "2009.08634", "submitter": "Guy Van den Broeck", "authors": "Guy Van den Broeck, Anton Lykov, Maximilian Schleich, Dan Suciu", "title": "On the Tractability of SHAP Explanations", "comments": "Proceedings of the 35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SHAP explanations are a popular feature-attribution mechanism for explainable\nAI. They use game-theoretic notions to measure the influence of individual\nfeatures on the prediction of a machine learning model. Despite a lot of recent\ninterest from both academia and industry, it is not known whether SHAP\nexplanations of common machine learning models can be computed efficiently. In\nthis paper, we establish the complexity of computing the SHAP explanation in\nthree important settings. First, we consider fully-factorized data\ndistributions, and show that the complexity of computing the SHAP explanation\nis the same as the complexity of computing the expected value of the model.\nThis fully-factorized setting is often used to simplify the SHAP computation,\nyet our results show that the computation can be intractable for commonly used\nmodels such as logistic regression. Going beyond fully-factorized\ndistributions, we show that computing SHAP explanations is already intractable\nfor a very simple setting: computing SHAP explanations of trivial classifiers\nover naive Bayes distributions. Finally, we show that even computing SHAP over\nthe empirical distribution is #P-hard.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:48:15 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:41:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Broeck", "Guy Van den", ""], ["Lykov", "Anton", ""], ["Schleich", "Maximilian", ""], ["Suciu", "Dan", ""]]}, {"id": "2009.08646", "submitter": "Rahim Rahmani", "authors": "Rahim Rahmani and Ramin Firouzi", "title": "Gateway Controller with Deep Sensing: Learning to be Autonomic in\n  Intelligent Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Internet of Things(IoT) will revolutionize the Future Internet through\nubiquitous sensing. One of the challenges of having the hundreds of billions of\ndevices that are estimated to be deployed would be rise of an enormous amount\nof data, along with the devices ability to manage. This paper presents an\napproach as a controller solution and designed specifically for autonomous\nmanagement, connectivity and data interoperability in an IoT gateway. The\napproach supports distributed IoT nodes with both management and data\ninteroperability with other cloud-based solutions. The concept further allows\ngateways to easily collect and process interoperability of data from IoT\ndevices. We demonstrated the feasibility of the approach and evaluate its\nadvantages regarding deep sensing and autonomous enabled gateway as an edge\ncomputational intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 06:22:04 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Rahmani", "Rahim", ""], ["Firouzi", "Ramin", ""]]}, {"id": "2009.08666", "submitter": "Anirudh Joshi", "authors": "Anirudh Joshi, Namit Katariya, Xavier Amatriain, Anitha Kannan", "title": "Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting\n  Local Structures", "comments": "Accepted for publication in Findings of EMNLP at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a medical conversation between a patient and a physician poses\na unique natural language understanding challenge since it combines elements of\nstandard open ended conversation with very domain specific elements that\nrequire expertise and medical knowledge. Summarization of medical conversations\nis a particularly important aspect of medical conversation understanding since\nit addresses a very real need in medical practice: capturing the most important\naspects of a medical encounter so that they can be used for medical decision\nmaking and subsequent follow ups.\n  In this paper we present a novel approach to medical conversation\nsummarization that leverages the unique and independent local structures\ncreated when gathering a patient's medical history. Our approach is a variation\nof the pointer generator network where we introduce a penalty on the generator\ndistribution, and we explicitly model negations. The model also captures\nimportant properties of medical conversations such as medical knowledge coming\nfrom standardized medical ontologies better than when those concepts are\nintroduced explicitly. Through evaluation by doctors, we show that our approach\nis preferred on twice the number of summaries to the baseline pointer generator\nmodel and captures most or all of the information in 80% of the conversations\nmaking it a realistic alternative to costly manual summarization by medical\nexperts.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:35:44 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Joshi", "Anirudh", ""], ["Katariya", "Namit", ""], ["Amatriain", "Xavier", ""], ["Kannan", "Anitha", ""]]}, {"id": "2009.08685", "submitter": "Trista Chen", "authors": "Yu-Sheng Lin, Hung Chang Lu, Yang-Bin Tsao, Yi-Min Chih, Wei-Chao\n  Chen, Shao-Yi Chien", "title": "GrateTile: Efficient Sparse Tensor Tiling for CNN Processing", "comments": "To be published at IEEE Workshop on Signal Processing System (SiPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose GrateTile, an efficient, hardwarefriendly data storage scheme for\nsparse CNN feature maps (activations). It divides data into uneven-sized\nsubtensors and, with small indexing overhead, stores them in a compressed yet\nrandomly accessible format. This design enables modern CNN accelerators to\nfetch and decompressed sub-tensors on-the-fly in a tiled processing manner.\nGrateTile is suitable for architectures that favor aligned, coalesced data\naccess, and only requires minimal changes to the overall architectural design.\nWe simulate GrateTile with state-of-the-art CNNs and show an average of 55%\nDRAM bandwidth reduction while using only 0.6% of feature map size for indexing\nstorage.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 08:31:41 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Yu-Sheng", ""], ["Lu", "Hung Chang", ""], ["Tsao", "Yang-Bin", ""], ["Chih", "Yi-Min", ""], ["Chen", "Wei-Chao", ""], ["Chien", "Shao-Yi", ""]]}, {"id": "2009.08687", "submitter": "Yang Liu", "authors": "Yang Liu and Hisashi Kashima", "title": "Chemical Property Prediction Under Experimental Biases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict the chemical properties of compounds is crucial in\ndiscovering novel materials and drugs with specific desired characteristics.\nRecent significant advances in machine learning technologies have enabled\nautomatic predictive modeling from past experimental data reported in the\nliterature.However, these datasets are often biased due to various reasons,\nsuch as experimental plans and publication decisions, and the prediction models\ntrained using such biased datasets often suffer from over-fitting to the biased\ndistributions and perform poorly on subsequent uses.The present study focuses\non mitigating bias in the experimental datasets. To this purpose, we adopt two\ntechniques from causal inference and domain adaptation combined with graph\nneural networks capable of handling molecular structures.The experimental\nresults in four possible bias scenarios show that the inverse propensity\nscoring-based method makes solid improvements, while the domain-invariant\nrepresentation learning approach fails.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 08:40:57 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Liu", "Yang", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2009.08697", "submitter": "Shangwei Guo", "authors": "Shangwei Guo, Tianwei Zhang, Han Qiu, Yi Zeng, Tao Xiang, and Yang Liu", "title": "Fine-tuning Is Not Enough: A Simple yet Effective Watermark Removal\n  Attack for DNN Models", "comments": "7 pages, 4 figures, accpeted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking has become the tendency in protecting the intellectual property\nof DNN models. Recent works, from the adversary's perspective, attempted to\nsubvert watermarking mechanisms by designing watermark removal attacks.\nHowever, these attacks mainly adopted sophisticated fine-tuning techniques,\nwhich have certain fatal drawbacks or unrealistic assumptions. In this paper,\nwe propose a novel watermark removal attack from a different perspective.\nInstead of just fine-tuning the watermarked models, we design a simple yet\npowerful transformation algorithm by combining imperceptible pattern embedding\nand spatial-level transformations, which can effectively and blindly destroy\nthe memorization of watermarked models to the watermark samples. We also\nintroduce a lightweight fine-tuning strategy to preserve the model performance.\nOur solution requires much less resource or knowledge about the watermarking\nscheme than prior works. Extensive experimental results indicate that our\nattack can bypass state-of-the-art watermarking solutions with very high\nsuccess rates. Based on our attack, we propose watermark augmentation\ntechniques to enhance the robustness of existing watermarks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:14:54 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 06:23:29 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Qiu", "Han", ""], ["Zeng", "Yi", ""], ["Xiang", "Tao", ""], ["Liu", "Yang", ""]]}, {"id": "2009.08698", "submitter": "Marc Ortiz", "authors": "Marc Ortiz, Florian Scheidegger, Marc Casas, Cristiano Malossi, Eduard\n  Ayguad\\'e", "title": "Generating Efficient DNN-Ensembles with Evolutionary Computation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we leverage ensemble learning as a tool for the creation of\nfaster, smaller, and more accurate deep learning models. We demonstrate that we\ncan jointly optimize for accuracy, inference time, and the number of parameters\nby combining DNN classifiers. To achieve this, we combine multiple ensemble\nstrategies: bagging, boosting, and an ordered chain of classifiers. To reduce\nthe number of DNN ensemble evaluations during the search, we propose EARN, an\nevolutionary approach that optimizes the ensemble according to three objectives\nregarding the constraints specified by the user. We run EARN on 10 image\nclassification datasets with an initial pool of 32 state-of-the-art DCNN on\nboth CPU and GPU platforms, and we generate models with speedups up to\n$7.60\\times$, reductions of parameters by $10\\times$, or increases in accuracy\nup to $6.01\\%$ regarding the best DNN in the pool. In addition, our method\ngenerates models that are $5.6\\times$ faster than the state-of-the-art methods\nfor automatic model generation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:14:56 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 12:59:02 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ortiz", "Marc", ""], ["Scheidegger", "Florian", ""], ["Casas", "Marc", ""], ["Malossi", "Cristiano", ""], ["Ayguad\u00e9", "Eduard", ""]]}, {"id": "2009.08716", "submitter": "Zhengjie Yang", "authors": "Zhengjie Yang, Wei Bao, Dong Yuan, Nguyen H. Tran, and Albert Y.\n  Zomaya", "title": "Federated Learning with Nesterov Accelerated Gradient Momentum Method", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a fast-developing technique that allows multiple\nworkers to train a global model based on a distributed dataset. Conventional FL\nemploys gradient descent algorithm, which may not be efficient enough. It is\nwell known that Nesterov Accelerated Gradient (NAG) is more advantageous in\ncentralized training environment, but it is not clear how to quantify the\nbenefits of NAG in FL so far. In this work, we focus on a version of FL based\non NAG (FedNAG) and provide a detailed convergence analysis. The result is\ncompared with conventional FL based on gradient descent. One interesting\nconclusion is that as long as the learning step size is sufficiently small,\nFedNAG outperforms FedAvg. Extensive experiments based on real-world datasets\nare conducted, verifying our conclusions and confirming the better convergence\nperformance of FedNAG.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:38:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yang", "Zhengjie", ""], ["Bao", "Wei", ""], ["Yuan", "Dong", ""], ["Tran", "Nguyen H.", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2009.08720", "submitter": "Diego Marcos", "authors": "Diego Marcos, Ruth Fong, Sylvain Lobry, Remi Flamary, Nicolas Courty\n  and Devis Tuia", "title": "Contextual Semantic Interpretability", "comments": null, "journal-ref": "ACCV 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNN) are known to learn an image\nrepresentation that captures concepts relevant to the task, but do so in an\nimplicit way that hampers model interpretability. However, one could argue that\nsuch a representation is hidden in the neurons and can be made explicit by\nteaching the model to recognize semantically interpretable attributes that are\npresent in the scene. We call such an intermediate layer a \\emph{semantic\nbottleneck}. Once the attributes are learned, they can be re-combined to reach\nthe final decision and provide both an accurate prediction and an explicit\nreasoning behind the CNN decision. In this paper, we look into semantic\nbottlenecks that capture context: we want attributes to be in groups of a few\nmeaningful elements and participate jointly to the final decision. We use a\ntwo-layer semantic bottleneck that gathers attributes into interpretable,\nsparse groups, allowing them contribute differently to the final output\ndepending on the context. We test our contextual semantic interpretable\nbottleneck (CSIB) on the task of landscape scenicness estimation and train the\nsemantic interpretable bottleneck using an auxiliary database (SUN Attributes).\nOur model yields in predictions as accurate as a non-interpretable baseline\nwhen applied to a real-world test set of Flickr images, all while providing\nclear and interpretable explanations for each prediction.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:47:05 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Marcos", "Diego", ""], ["Fong", "Ruth", ""], ["Lobry", "Sylvain", ""], ["Flamary", "Remi", ""], ["Courty", "Nicolas", ""], ["Tuia", "Devis", ""]]}, {"id": "2009.08727", "submitter": "Yao Lei Xu", "authors": "Yao Lei Xu, Danilo P. Mandic", "title": "Recurrent Graph Tensor Networks: A Low-Complexity Framework for\n  Modelling High-Dimensional Multi-Way Sequence", "comments": "29th European Signal Processing Conference (EUSIPCO) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are among the most successful machine\nlearning models for sequence modelling, but tend to suffer from an exponential\nincrease in the number of parameters when dealing with large multidimensional\ndata. To this end, we develop a multi-linear graph filter framework for\napproximating the modelling of hidden states in RNNs, which is embedded in a\ntensor network architecture to improve modelling power and reduce parameter\ncomplexity, resulting in a novel Recurrent Graph Tensor Network (RGTN). The\nproposed framework is validated through several multi-way sequence modelling\ntasks and benchmarked against traditional RNNs. By virtue of the domain aware\ninformation processing of graph filters and the expressive power of tensor\nnetworks, we show that the proposed RGTN is capable of not only out-performing\nstandard RNNs, but also mitigating the Curse of Dimensionality associated with\ntraditional RNNs, demonstrating superior properties in terms of performance and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 10:13:36 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 14:00:01 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 14:18:30 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 12:35:31 GMT"}, {"version": "v5", "created": "Tue, 11 May 2021 12:40:23 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Xu", "Yao Lei", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2009.08739", "submitter": "Ruoxin Chen", "authors": "Ruoxin Chen, Jie Li, Chentao Wu, Bin Sheng, Ping Li", "title": "A Framework of Randomized Selection Based Certified Defenses Against\n  Data Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network classifiers are vulnerable to data poisoning attacks, as\nattackers can degrade or even manipulate their predictions thorough poisoning\nonly a few training samples. However, the robustness of heuristic defenses is\nhard to measure. Random selection based defenses can achieve certified\nrobustness by averaging the classifiers' predictions on the sub-datasets\nsampled from the training set. This paper proposes a framework of random\nselection based certified defenses against data poisoning attacks.\nSpecifically, we prove that the random selection schemes that satisfy certain\nconditions are robust against data poisoning attacks. We also derive the\nanalytical form of the certified radius for the qualified random selection\nschemes. The certified radius of bagging derived by our framework is tighter\nthan the previous work. Our framework allows users to improve robustness by\nleveraging prior knowledge about the training set and the poisoning model.\nGiven higher level of prior knowledge, we can achieve higher certified accuracy\nboth theoretically and practically. According to the experiments on three\nbenchmark datasets: MNIST 1/7, MNIST, and CIFAR-10, our method outperforms the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 10:38:12 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 09:33:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Chen", "Ruoxin", ""], ["Li", "Jie", ""], ["Wu", "Chentao", ""], ["Sheng", "Bin", ""], ["Li", "Ping", ""]]}, {"id": "2009.08790", "submitter": "Jigar Doshi", "authors": "Piyush Bagad, Aman Dalmia, Jigar Doshi, Arsha Nagrani, Parag Bhamare,\n  Amrita Mahale, Saurabh Rane, Neeraj Agarwal, Rahul Panicker", "title": "Cough Against COVID: Evidence of COVID-19 Signature in Cough Sounds", "comments": "Under submission to AAAI 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Testing capacity for COVID-19 remains a challenge globally due to the lack of\nadequate supplies, trained personnel, and sample-processing equipment. These\nproblems are even more acute in rural and underdeveloped regions. We\ndemonstrate that solicited-cough sounds collected over a phone, when analysed\nby our AI model, have statistically significant signal indicative of COVID-19\nstatus (AUC 0.72, t-test,p <0.01,95% CI 0.61-0.83). This holds true for\nasymptomatic patients as well. Towards this, we collect the largest known(to\ndate) dataset of microbiologically confirmed COVID-19 cough sounds from 3,621\nindividuals. When used in a triaging step within an overall testing protocol,\nby enabling risk-stratification of individuals before confirmatory tests, our\ntool can increase the testing capacity of a healthcare system by 43% at disease\nprevalence of 5%, without additional supplies, trained personnel, or physical\ninfrastructure\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:59:14 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:31:00 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bagad", "Piyush", ""], ["Dalmia", "Aman", ""], ["Doshi", "Jigar", ""], ["Nagrani", "Arsha", ""], ["Bhamare", "Parag", ""], ["Mahale", "Amrita", ""], ["Rane", "Saurabh", ""], ["Agarwal", "Neeraj", ""], ["Panicker", "Rahul", ""]]}, {"id": "2009.08796", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Nicola Landro", "title": "$\\sigma^2$R Loss: a Weighted Loss by Multiplicative Factors using\n  Sigmoidal Functions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In neural networks, the loss function represents the core of the learning\nprocess that leads the optimizer to an approximation of the optimal convergence\nerror. Convolutional neural networks (CNN) use the loss function as a\nsupervisory signal to train a deep model and contribute significantly to\nachieving the state of the art in some fields of artificial vision.\nCross-entropy and Center loss functions are commonly used to increase the\ndiscriminating power of learned functions and increase the generalization\nperformance of the model. Center loss minimizes the class intra-class variance\nand at the same time penalizes the long distance between the deep features\ninside each class. However, the total error of the center loss will be heavily\ninfluenced by the majority of the instances and can lead to a freezing state in\nterms of intra-class variance. To address this, we introduce a new loss\nfunction called sigma squared reduction loss ($\\sigma^2$R loss), which is\nregulated by a sigmoid function to inflate/deflate the error per instance and\nthen continue to reduce the intra-class variance. Our loss has clear intuition\nand geometric interpretation, furthermore, we demonstrate by experiments the\neffectiveness of our proposal on several benchmark datasets showing the\nintra-class variance reduction and overcoming the results obtained with center\nloss and soft nearest neighbour functions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 12:34:40 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Landro", "Nicola", ""]]}, {"id": "2009.08798", "submitter": "Yu Guan", "authors": "Xi Chen, Yu Guan, Jian-Qing Shi, Xiu-Li Du, Janet Eyre", "title": "Automated Stroke Rehabilitation Assessment using Wearable Accelerometers\n  in Free-Living Environments", "comments": "submitted to ACM IMWUT", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stroke is known as a major global health problem, and for stroke survivors it\nis key to monitor the recovery levels. However, traditional stroke\nrehabilitation assessment methods (such as the popular clinical assessment) can\nbe subjective and expensive, and it is also less convenient for patients to\nvisit clinics in a high frequency. To address this issue, in this work based on\nwearable sensing and machine learning techniques, we developed an automated\nsystem that can predict the assessment score in an objective manner. With\nwrist-worn sensors, accelerometer data was collected from 59 stroke survivors\nin free-living environments for a duration of 8 weeks, and we aim to map the\nweek-wise accelerometer data (3 days per week) to the assessment score by\ndeveloping signal processing and predictive model pipeline. To achieve this, we\nproposed two types of new features, which can encode the rehabilitation\ninformation from both paralysed/non-paralysed sides while suppressing the\nhigh-level noises such as irrelevant daily activities. Based on the proposed\nfeatures, we further developed the longitudinal mixed-effects model with\nGaussian process prior (LMGP), which can model the random effects caused by\ndifferent subjects and time slots (during the 8 weeks). Comprehensive\nexperiments were conducted to evaluate our system on both acute and chronic\npatients, and the results suggested its effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:10:48 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 22:47:23 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chen", "Xi", ""], ["Guan", "Yu", ""], ["Shi", "Jian-Qing", ""], ["Du", "Xiu-Li", ""], ["Eyre", "Janet", ""]]}, {"id": "2009.08801", "submitter": "Marco Anteghini", "authors": "Marco Anteghini, Jennifer D'Souza, Vitor A. P. Martins dos Santos,\n  S\\\"oren Auer", "title": "SciBERT-based Semantification of Bioassays in the Open Research\n  Knowledge Graph", "comments": "In proceedings of the '22nd International Conference on Knowledge\n  Engineering and Knowledge Management' 'Demo and Poster section'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a novel contribution to the problem of semantifying biological assays, in\nthis paper, we propose a neural-network-based approach to automatically\nsemantify, thereby structure, unstructured bioassay text descriptions.\nExperimental evaluations, to this end, show promise as the neural-based\nsemantification significantly outperforms a naive frequency-based baseline\napproach. Specifically, the neural method attains 72% F1 versus 47% F1 from the\nfrequency-based method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:36:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Anteghini", "Marco", ""], ["D'Souza", "Jennifer", ""], ["Santos", "Vitor A. P. Martins dos", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2009.08807", "submitter": "Amit Surana", "authors": "Kunal Srivastava, Amit Surana", "title": "Monte Carlo Tree Search Based Tactical Maneuvering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the application of simultaneous move Monte Carlo\nTree Search (MCTS) based online framework for tactical maneuvering between two\nunmanned aircrafts. Compared to other techniques, MCTS enables efficient search\nover long horizons and uses self-play to select best maneuver in the current\nstate while accounting for the opponent aircraft tactics. We explore different\nalgorithmic choices in MCTS and demonstrate the framework numerically in a\nsimulated 2D tactical maneuvering application.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:03:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Srivastava", "Kunal", ""], ["Surana", "Amit", ""]]}, {"id": "2009.08809", "submitter": "Abolfazl Zargari", "authors": "Najmeh Mashhadi, Abolfazl Zargari Khuzani, Morteza Heidari, Donya\n  Khaledyan", "title": "Deep learning denoising for EOG artifacts removal from EEG signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many sources of interference encountered in the\nelectroencephalogram (EEG) recordings, specifically ocular, muscular, and\ncardiac artifacts. Rejection of EEG artifacts is an essential process in EEG\nanalysis since such artifacts cause many problems in EEG signals analysis. One\nof the most challenging issues in EEG denoising processes is removing the\nocular artifacts where Electrooculographic (EOG), and EEG signals have an\noverlap in both frequency and time domains. In this paper, we build and train a\ndeep learning model to deal with this challenge and remove the ocular artifacts\neffectively. In the proposed scheme, we convert each EEG signal to an image to\nbe fed to a U-NET model, which is a deep learning model usually used in image\nsegmentation tasks. We proposed three different schemes and made our U-NET\nbased models learn to purify contaminated EEG signals similar to the process\nused in the image segmentation process. The results confirm that one of our\nschemes can achieve a reliable and promising accuracy to reduce the Mean square\nerror between the target signal (Pure EEGs) and the predicted signal (Purified\nEEGs).\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 23:28:12 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Mashhadi", "Najmeh", ""], ["Khuzani", "Abolfazl Zargari", ""], ["Heidari", "Morteza", ""], ["Khaledyan", "Donya", ""]]}, {"id": "2009.08810", "submitter": "Kadierdan Kaheman", "authors": "Kadierdan Kaheman, Steven L. Brunton, J. Nathan Kutz", "title": "Automatic Differentiation to Simultaneously Identify Nonlinear Dynamics\n  and Extract Noise Probability Distributions from Data", "comments": "30 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse identification of nonlinear dynamics (SINDy) is a regression\nframework for the discovery of parsimonious dynamic models and governing\nequations from time-series data. As with all system identification methods,\nnoisy measurements compromise the accuracy and robustness of the model\ndiscovery procedure. In this work, we develop a variant of the SINDy algorithm\nthat integrates automatic differentiation and recent time-stepping constrained\nmotivated by Rudy et al. for simultaneously (i) denoising the data, (ii)\nlearning and parametrizing the noise probability distribution, and (iii)\nidentifying the underlying parsimonious dynamical system responsible for\ngenerating the time-series data. Thus within an integrated optimization\nframework, noise can be separated from signal, resulting in an architecture\nthat is approximately twice as robust to noise as state-of-the-art methods,\nhandling as much as 40% noise on a given time-series signal and explicitly\nparametrizing the noise probability distribution. We demonstrate this approach\non several numerical examples, from Lotka-Volterra models to the\nspatio-temporal Lorenz 96 model. Further, we show the method can identify a\ndiversity of probability distributions including Gaussian, uniform, Gamma, and\nRayleigh.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 23:52:25 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 23:17:17 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kaheman", "Kadierdan", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2009.08811", "submitter": "Subhro Ghosh", "authors": "Subhro Ghosh, Naoto Miyoshi, Tomoyuki Shirai", "title": "Disordered complex networks: energy optimal lattices and persistent\n  homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cond-mat.dis-nn cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disordered complex networks are of fundamental interest as stochastic models\nfor information transmission over wireless networks. Well-known networks based\non the Poisson point process model have limitations vis-a-vis network\nefficiency, whereas strongly correlated alternatives, such as those based on\nrandom matrix spectra (RMT), have tractability and robustness issues. In this\nwork, we demonstrate that network models based on random perturbations of\nEuclidean lattices interpolate between Poisson and rigidly structured networks,\nand allow us to achieve the best of both worlds : significantly improve upon\nthe Poisson model in terms of network efficacy measured by the Signal to\nInterference plus Noise Ratio (abbrv. SINR) and the related concept of coverage\nprobabilities, at the same time retaining a considerable measure of\nmathematical and computational simplicity and robustness to erasure and noise.\n  We investigate the optimal choice of the base lattice in this model,\nconnecting it to the celebrated problem optimality of Euclidean lattices with\nrespect to the Epstein Zeta function, which is in turn related to notions of\nlattice energy. This leads us to the choice of the triangular lattice in 2D and\nface centered cubic lattice in 3D. We demonstrate that the coverage probability\ndecreases with increasing strength of perturbation, eventually converging to\nthat of the Poisson network. In the regime of low disorder, we approximately\ncharacterize the statistical law of the coverage function.\n  In 2D, we determine the disorder strength at which the PTL and the RMT\nnetworks are the closest measured by comparing their network topologies via a\ncomparison of their Persistence Diagrams . We demonstrate that the PTL network\nat this disorder strength can be taken to be an effective substitute for the\nRMT network model, while at the same time offering the advantages of greater\ntractability.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:37:18 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Ghosh", "Subhro", ""], ["Miyoshi", "Naoto", ""], ["Shirai", "Tomoyuki", ""]]}, {"id": "2009.08819", "submitter": "Panagiotis Petsagkourakis", "authors": "Ehecatl Antonio del Rio-Chanona and Panagiotis Petsagkourakis and Eric\n  Bradford and Jose Eduardo Alves Graciano and Benoit Chachuat", "title": "Real-Time Optimization Meets Bayesian Optimization and Derivative-Free\n  Optimization: A Tale of Modifier Adaptation", "comments": "The first two authors have an equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates a new class of modifier-adaptation schemes to\novercome plant-model mismatch in real-time optimization of uncertain processes.\nThe main contribution lies in the integration of concepts from the areas of\nBayesian optimization and derivative-free optimization. The proposed schemes\nembed a physical model and rely on trust-region ideas to minimize risk during\nthe exploration, while employing Gaussian process regression to capture the\nplant-model mismatch in a non-parametric way and drive the exploration by means\nof acquisition functions. The benefits of using an acquisition function,\nknowing the process noise level, or specifying a nominal process model are\nillustrated on numerical case studies, including a semi-batch photobioreactor\noptimization problem.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 12:57:17 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 16:51:56 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["del Rio-Chanona", "Ehecatl Antonio", ""], ["Petsagkourakis", "Panagiotis", ""], ["Bradford", "Eric", ""], ["Graciano", "Jose Eduardo Alves", ""], ["Chachuat", "Benoit", ""]]}, {"id": "2009.08831", "submitter": "Redha Ali", "authors": "Hussin K. Ragb, Ian T. Dover, Redha Ali", "title": "Fused Deep Convolutional Neural Network for Precision Diagnosis of\n  COVID-19 Using Chest X-Ray Images", "comments": "9 Pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With a Coronavirus disease (COVID-19) case count exceeding 10 million\nworldwide, there is an increased need for a diagnostic capability. The main\nvariables in increasing diagnostic capability are reduced cost, turnaround or\ndiagnosis time, and upfront equipment cost and accessibility. Two candidates\nfor machine learning COVID-19 diagnosis are Computed Tomography (CT) scans and\nplain chest X-rays. While CT scans score higher in sensitivity, they have a\nhigher cost, maintenance requirement, and turnaround time as compared to plain\nchest X-rays. The use of portable chest X-radiograph (CXR) is recommended by\nthe American College of Radiology (ACR) since using CT places a massive burden\non radiology services. Therefore, X-ray imagery paired with machine learning\ntechniques is proposed a first-line triage tool for COVID-19 diagnostics. In\nthis paper we propose a computer-aided diagnosis (CAD) to accurately classify\nchest X-ray scans of COVID-19 and normal subjects by fine-tuning several neural\nnetworks (ResNet18, ResNet50, DenseNet201) pre-trained on the ImageNet dataset.\nThese neural networks are fused in a parallel architecture and the voting\ncriteria are applied in the final classification decision between the candidate\nobject classes where the output of each neural network is representing a single\nvote. Several experiments are conducted on the weakly labeled COVID-19-CT-CXR\ndataset consisting of 263 COVID-19 CXR images extracted from PubMed Central\nOpen Access subsets combined with 25 normal classification CXR images. These\nexperiments show an optimistic result and a capability of the proposed model to\noutperforming many state-of-the-art algorithms on several measures. Using\nk-fold cross-validation and a bagging classifier ensemble, we achieve an\naccuracy of 99.7% and a sensitivity of 100%.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:27:20 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Ragb", "Hussin K.", ""], ["Dover", "Ian T.", ""], ["Ali", "Redha", ""]]}, {"id": "2009.08835", "submitter": "David Schedl", "authors": "David C. Schedl and Indrajit Kurmi and Oliver Bimber", "title": "Search and Rescue with Airborne Optical Sectioning", "comments": "11 pages, 5 figures, 3 tables, Nature Machine Intelligence (under\n  review)", "journal-ref": null, "doi": "10.1038/s42256-020-00261-3", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that automated person detection under occlusion conditions can be\nsignificantly improved by combining multi-perspective images before\nclassification. Here, we employed image integration by Airborne Optical\nSectioning (AOS)---a synthetic aperture imaging technique that uses camera\ndrones to capture unstructured thermal light fields---to achieve this with a\nprecision/recall of 96/93%. Finding lost or injured people in dense forests is\nnot generally feasible with thermal recordings, but becomes practical with use\nof AOS integral images. Our findings lay the foundation for effective future\nsearch and rescue technologies that can be applied in combination with\nautonomous or manned aircraft. They can also be beneficial for other fields\nthat currently suffer from inaccurate classification of partially occluded\npeople, animals, or objects.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 13:40:19 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Schedl", "David C.", ""], ["Kurmi", "Indrajit", ""], ["Bimber", "Oliver", ""]]}, {"id": "2009.08841", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh, \\'Ad\\'am J. Berki", "title": "On the spatiotemporal behavior in biology-mimicking computing systems", "comments": "33 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The payload performance of conventional computing systems, from single\nprocessors to supercomputers, reached its limits the nature enables. Both the\ngrowing demand to cope with \"big data\" (based on, or assisted by, artificial\nintelligence) and the interest in understanding the operation of our brain more\ncompletely, stimulated the efforts to build biology-mimicking computing systems\nfrom inexpensive conventional components and build different (\"neuromorphic\")\ncomputing systems. On one side, those systems require an unusually large number\nof processors, which introduces performance limitations and nonlinear scaling.\nOn the other side, the neuronal operation drastically differs from the\nconventional workloads. The conventional computing (including both its\nmathematical background and physical implementation) is based on assuming\ninstant interaction, while the biological neuronal systems have a\n\"spatiotemporal\" behavior. This difference alone makes imitating biological\nbehavior in technical implementation hard. Besides, the recent issues in\ncomputing called the attention to that the temporal behavior is a general\nfeature of computing systems, too. Some of their effects in both biological and\ntechnical systems were already noticed. Nevertheless, handling of those issues\nis incomplete/improper. Introducing temporal logic, based on the Minkowski\ntransform, gives quantitative insight into the operation of both kinds of\ncomputing systems, furthermore provides a natural explanation of decades-old\nempirical phenomena. Without considering their temporal behavior correctly,\nneither effective implementation nor a true imitation of biological neural\nsystems are possible.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 13:53:58 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 05:03:00 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 14:20:21 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""], ["Berki", "\u00c1d\u00e1m J.", ""]]}, {"id": "2009.08845", "submitter": "Daniel Ruiz", "authors": "Daniel V. Ruiz and Bruno A. Krinski and Eduardo Todt", "title": "IDA: Improved Data Augmentation Applied to Salient Object Detection", "comments": "Accepted for presentation at SIBGRAPI 2020 - 33rd Conference on\n  Graphics, Patterns and Images", "journal-ref": null, "doi": "10.1109/SIBGRAPI51738.2020.00036", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an Improved Data Augmentation (IDA) technique\nfocused on Salient Object Detection (SOD). Standard data augmentation\ntechniques proposed in the literature, such as image cropping, rotation,\nflipping, and resizing, only generate variations of the existing examples,\nproviding a limited generalization. Our method combines image inpainting,\naffine transformations, and the linear combination of different generated\nbackground images with salient objects extracted from labeled data. Our\nproposed technique enables more precise control of the object's position and\nsize while preserving background information. The background choice is based on\nan inter-image optimization, while object size follows a uniform random\ndistribution within a specified interval, and the object position is\nintra-image optimal. We show that our method improves the segmentation quality\nwhen used for training state-of-the-art neural networks on several famous\ndatasets of the SOD field. Combining our method with others surpasses\ntraditional techniques such as horizontal-flip in 0.52% for F-measure and 1.19%\nfor Precision. We also provide an evaluation in 7 different SOD datasets, with\n9 distinct evaluation metrics and an average ranking of the evaluated methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:03:27 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ruiz", "Daniel V.", ""], ["Krinski", "Bruno A.", ""], ["Todt", "Eduardo", ""]]}, {"id": "2009.08859", "submitter": "Neslihan Suzen", "authors": "Neslihan Suzen, Alexander Gorban, Jeremy Levesley, and Evgeny Mirkes", "title": "Principal Components of the Meaning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we argue that (lexical) meaning in science can be represented\nin a 13 dimension Meaning Space. This space is constructed using principal\ncomponent analysis (singular decomposition) on the matrix of word category\nrelative information gains, where the categories are those used by the Web of\nScience, and the words are taken from a reduced word set from texts in the Web\nof Science. We show that this reduced word set plausibly represents all texts\nin the corpus, so that the principal component analysis has some objective\nmeaning with respect to the corpus. We argue that 13 dimensions is adequate to\ndescribe the meaning of scientific texts, and hypothesise about the qualitative\nmeaning of the principal components.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:28:32 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Suzen", "Neslihan", ""], ["Gorban", "Alexander", ""], ["Levesley", "Jeremy", ""], ["Mirkes", "Evgeny", ""]]}, {"id": "2009.08868", "submitter": "Qi Zhao", "authors": "Qi Zhao, Zheng Zhao, Xiaoya Fan, Zhengwei Yuan, Qian Mao, Yudong Yao", "title": "Review of Machine-Learning Methods for RNA Secondary Structure\n  Prediction", "comments": "25 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Secondary structure plays an important role in determining the function of\nnon-coding RNAs. Hence, identifying RNA secondary structures is of great value\nto research. Computational prediction is a mainstream approach for predicting\nRNA secondary structure. Unfortunately, even though new methods have been\nproposed over the past 40 years, the performance of computational prediction\nmethods has stagnated in the last decade. Recently, with the increasing\navailability of RNA structure data, new methods based on machine-learning\ntechnologies, especially deep learning, have alleviated the issue. In this\nreview, we provide a comprehensive overview of RNA secondary structure\nprediction methods based on machine-learning technologies and a tabularized\nsummary of the most important methods in this field. The current pending issues\nin the field of RNA secondary structure prediction and future trends are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 03:17:15 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zhao", "Qi", ""], ["Zhao", "Zheng", ""], ["Fan", "Xiaoya", ""], ["Yuan", "Zhengwei", ""], ["Mao", "Qian", ""], ["Yao", "Yudong", ""]]}, {"id": "2009.08869", "submitter": "Wajid Arshad Abbasi", "authors": "Wajid Arshad Abbasi, Syed Ali Abbas, Saiqa Andleeb", "title": "PANDA: Predicting the change in proteins binding affinity upon mutations\n  using sequence information", "comments": null, "journal-ref": "Journal of Bioinformatics and Computational Biology, 2021", "doi": "10.1142/S0219720021500153", "report-no": null, "categories": "q-bio.BM cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately determining a change in protein binding affinity upon mutations is\nimportant for the discovery and design of novel therapeutics and to assist\nmutagenesis studies. Determination of change in binding affinity upon mutations\nrequires sophisticated, expensive, and time-consuming wet-lab experiments that\ncan be aided with computational methods. Most of the computational prediction\ntechniques require protein structures that limit their applicability to protein\ncomplexes with known structures. In this work, we explore the sequence-based\nprediction of change in protein binding affinity upon mutation. We have used\nprotein sequence information instead of protein structures along with machine\nlearning techniques to accurately predict the change in protein binding\naffinity upon mutation. Our proposed sequence-based novel change in protein\nbinding affinity predictor called PANDA gives better accuracy than existing\nmethods over the same validation set as well as on an external independent test\ndataset. On an external test dataset, our proposed method gives a maximum\nPearson correlation coefficient of 0.52 in comparison to the state-of-the-art\nexisting protein structure-based method called MutaBind which gives a maximum\nPearson correlation coefficient of 0.59. Our proposed protein sequence-based\nmethod, to predict a change in binding affinity upon mutations, has wide\napplicability and comparable performance in comparison to existing protein\nstructure-based methods. A cloud-based webserver implementation of PANDA and\nits python code is available at\nhttps://sites.google.com/view/wajidarshad/software and\nhttps://github.com/wajidarshad/panda.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:12:25 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Abbasi", "Wajid Arshad", ""], ["Abbas", "Syed Ali", ""], ["Andleeb", "Saiqa", ""]]}, {"id": "2009.08876", "submitter": "Shihong Fang", "authors": "Shihong Fang, Anna Choromanska", "title": "Multi-modal Experts Network for Autonomous Driving", "comments": "Published at the International Conference on Robotics and Automation\n  (ICRA), 2020", "journal-ref": "2020 IEEE International Conference on Robotics and Automation\n  (ICRA), Paris, France, 2020, pp. 6439-6445", "doi": "10.1109/ICRA40945.2020.9197459", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  End-to-end learning from sensory data has shown promising results in\nautonomous driving. While employing many sensors enhances world perception and\nshould lead to more robust and reliable behavior of autonomous vehicles, it is\nchallenging to train and deploy such network and at least two problems are\nencountered in the considered setting. The first one is the increase of\ncomputational complexity with the number of sensing devices. The other is the\nphenomena of network overfitting to the simplest and most informative input. We\naddress both challenges with a novel, carefully tailored multi-modal experts\nnetwork architecture and propose a multi-stage training procedure. The network\ncontains a gating mechanism, which selects the most relevant input at each\ninference time step using a mixed discrete-continuous policy. We demonstrate\nthe plausibility of the proposed approach on our 1/6 scale truck equipped with\nthree cameras and one LiDAR.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:54:54 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Fang", "Shihong", ""], ["Choromanska", "Anna", ""]]}, {"id": "2009.08880", "submitter": "Jakob Struye", "authors": "Jakob Struye, Kevin Mets, Steven Latr\\'e", "title": "HTMRL: Biologically Plausible Reinforcement Learning with Hierarchical\n  Temporal Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building Reinforcement Learning (RL) algorithms which are able to adapt to\ncontinuously evolving tasks is an open research challenge. One technology that\nis known to inherently handle such non-stationary input patterns well is\nHierarchical Temporal Memory (HTM), a general and biologically plausible\ncomputational model for the human neocortex. As the RL paradigm is inspired by\nhuman learning, HTM is a natural framework for an RL algorithm supporting\nnon-stationary environments. In this paper, we present HTMRL, the first\nstrictly HTM-based RL algorithm. We empirically and statistically show that\nHTMRL scales to many states and actions, and demonstrate that HTM's ability for\nadapting to changing patterns extends to RL. Specifically, HTMRL performs well\non a 10-armed bandit after 750 steps, but only needs a third of that to adapt\nto the bandit suddenly shuffling its arms. HTMRL is the first iteration of a\nnovel RL approach, with the potential of extending to a capable algorithm for\nMeta-RL.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:05:17 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Struye", "Jakob", ""], ["Mets", "Kevin", ""], ["Latr\u00e9", "Steven", ""]]}, {"id": "2009.08900", "submitter": "Mehak Gupta", "authors": "Mehak Gupta, Rahmatollah Beheshti", "title": "Time-series Imputation and Prediction with Bi-Directional Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time-series data are used in many classification and regression\npredictive tasks, and recurrent models have been widely used for such tasks.\nMost common recurrent models assume that time-series data elements are of equal\nlength and the ordered observations are recorded at regular intervals. However,\nreal-world time-series data have neither a similar length nor a same number of\nobservations. They also have missing entries, which hinders the performance of\npredictive tasks. In this paper, we approach these issues by presenting a model\nfor the combined task of imputing and predicting values for the irregularly\nobserved and varying length time-series data with missing entries. Our proposed\nmodel (Bi-GAN) uses a bidirectional recurrent network in a generative\nadversarial setting. The generator is a bidirectional recurrent network that\nreceives actual incomplete data and imputes the missing values. The\ndiscriminator attempts to discriminate between the actual and the imputed\nvalues in the output of the generator. Our model learns how to impute missing\nelements in-between (imputation) or outside of the input time steps\n(prediction), hence working as an effective any-time prediction tool for\ntime-series data. Our method has three advantages to the state-of-the-art\nmethods in the field: (a) single model can be used for both imputation and\nprediction tasks; (b) it can perform prediction task for time-series of varying\nlength with missing data; (c) it does not require to know the observation and\nprediction time window during training which provides a flexible length of\nprediction window for both long-term and short-term predictions. We evaluate\nour model on two public datasets and on another large real-world electronic\nhealth records dataset to impute and predict body mass index (BMI) values in\nchildren and show its superior performance in both settings.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:47:51 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Gupta", "Mehak", ""], ["Beheshti", "Rahmatollah", ""]]}, {"id": "2009.08905", "submitter": "R\\'emy Garnier", "authors": "R\\'emy Garnier and Rapha\\\"el Langhendries", "title": "Deviation bound for non-causal machine learning", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concentration inequalities are widely used for analyzing machine learning\nalgorithms. However, current concentration inequalities cannot be applied to\nsome of the most popular deep neural networks, notably in natural language\nprocessing. This is mostly due to the non-causal nature of such involved data,\nin the sense that each data point depends on other neighbor data points. In\nthis paper, a framework for modeling non-causal random fields is provided and a\nHoeffding-type concentration inequality is obtained for this framework. The\nproof of this result relies on a local approximation of the non-causal random\nfield by a function of a finite number of i.i.d. random variables.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:57:59 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 16:55:42 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Garnier", "R\u00e9my", ""], ["Langhendries", "Rapha\u00ebl", ""]]}, {"id": "2009.08909", "submitter": "Hritam Basak", "authors": "Soham Chattopadhyay, Arijit Dey, Hritam Basak", "title": "Optimizing Speech Emotion Recognition using Manta-Ray Based Feature\n  Selection", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition from audio signals has been regarded as a challenging\ntask in signal processing as it can be considered as a collection of static and\ndynamic classification tasks. Recognition of emotions from speech data has been\nheavily relied upon end-to-end feature extraction and classification using\nmachine learning models, though the absence of feature selection and\noptimization have restrained the performance of these methods. Recent studies\nhave shown that Mel Frequency Cepstral Coefficients (MFCC) have been emerged as\none of the most relied feature extraction methods, though it circumscribes the\naccuracy of classification with a very small feature dimension. In this paper,\nwe propose that the concatenation of features, extracted by using different\nexisting feature extraction methods can not only boost the classification\naccuracy but also expands the possibility of efficient feature selection. We\nhave used Linear Predictive Coding (LPC) apart from the MFCC feature extraction\nmethod, before feature merging. Besides, we have performed a novel application\nof Manta Ray optimization in speech emotion recognition tasks that resulted in\na state-of-the-art result in this field. We have evaluated the performance of\nour model using SAVEE and Emo-DB, two publicly available datasets. Our proposed\nmethod outperformed all the existing methods in speech emotion analysis and\nresulted in a decent result in these two datasets with a classification\naccuracy of 97.06% and 97.68% respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 16:09:34 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Chattopadhyay", "Soham", ""], ["Dey", "Arijit", ""], ["Basak", "Hritam", ""]]}, {"id": "2009.08920", "submitter": "Haoming Lu", "authors": "Haoming Lu, Humphrey Shi", "title": "Deep Learning for 3D Point Cloud Understanding: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of practical applications, such as autonomous driving and\nrobotics, has brought increasing attention to 3D point cloud understanding.\nWhile deep learning has achieved remarkable success on image-based tasks, there\nare many unique challenges faced by deep neural networks in processing massive,\nunstructured and noisy 3D points. To demonstrate the latest progress of deep\nlearning for 3D point cloud understanding, this paper summarizes recent\nremarkable research contributions in this area from several different\ndirections (classification, segmentation, detection, tracking, flow estimation,\nregistration, augmentation and completion), together with commonly used\ndatasets, metrics and state-of-the-art performances. More information regarding\nthis survey can be found at:\nhttps://github.com/SHI-Labs/3D-Point-Cloud-Learning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 16:34:12 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 15:04:30 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Lu", "Haoming", ""], ["Shi", "Humphrey", ""]]}, {"id": "2009.08932", "submitter": "Ajay Patrikar", "authors": "Ajay M. Patrikar", "title": "Multi-Activation Hidden Units for Neural Networks with Random Weights", "comments": "4 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2008.10425", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single layer feedforward networks with random weights are successful in a\nvariety of classification and regression problems. These networks are known for\ntheir non-iterative and fast training algorithms. A major drawback of these\nnetworks is that they require a large number of hidden units. In this paper, we\npropose the use of multi-activation hidden units. Such units increase the\nnumber of tunable parameters and enable formation of complex decision surfaces,\nwithout increasing the number of hidden units. We experimentally show that\nmulti-activation hidden units can be used either to improve the classification\naccuracy, or to reduce computations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:17:33 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 20:54:20 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Patrikar", "Ajay M.", ""]]}, {"id": "2009.08934", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Junaid Malik, Habib Ben Abdallah, Turker Ince,\n  Alexandros Iosifidis, Moncef Gabbouj", "title": "Exploiting Heterogeneity in Operational Neural Networks by Synaptic\n  Plasticity", "comments": "15 pages, 19 figures, journal manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed network model, Operational Neural Networks (ONNs), can\ngeneralize the conventional Convolutional Neural Networks (CNNs) that are\nhomogenous only with a linear neuron model. As a heterogenous network model,\nONNs are based on a generalized neuron model that can encapsulate any set of\nnon-linear operators to boost diversity and to learn highly complex and\nmulti-modal functions or spaces with minimal network complexity and training\ndata. However, the default search method to find optimal operators in ONNs, the\nso-called Greedy Iterative Search (GIS) method, usually takes several training\nsessions to find a single operator set per layer. This is not only\ncomputationally demanding, also the network heterogeneity is limited since the\nsame set of operators will then be used for all neurons in each layer. To\naddress this deficiency and exploit a superior level of heterogeneity, in this\nstudy the focus is drawn on searching the best-possible operator set(s) for the\nhidden neurons of the network based on the Synaptic Plasticity paradigm that\nposes the essential learning theory in biological neurons. During training,\neach operator set in the library can be evaluated by their synaptic plasticity\nlevel, ranked from the worst to the best, and an elite ONN can then be\nconfigured using the top ranked operator sets found at each hidden layer.\nExperimental results over highly challenging problems demonstrate that the\nelite ONNs even with few neurons and layers can achieve a superior learning\nperformance than GIS-based ONNs and as a result the performance gap over the\nCNNs further widens.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:03:23 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Malik", "Junaid", ""], ["Abdallah", "Habib Ben", ""], ["Ince", "Turker", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.08936", "submitter": "Majdi Radaideh", "authors": "Majdi I. Radaideh, Koroush Shirvan", "title": "Improving Intelligence of Evolutionary Algorithms Using Experience Share\n  and Replay", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PESA, a novel approach combining Particle Swarm Optimisation\n(PSO), Evolution Strategy (ES), and Simulated Annealing (SA) in a hybrid\nAlgorithm, inspired from reinforcement learning. PESA hybridizes the three\nalgorithms by storing their solutions in a shared replay memory. Next, PESA\napplies prioritized replay to redistribute data between the three algorithms in\nfrequent form based on their fitness and priority values, which significantly\nenhances sample diversity and algorithm exploration. Additionally, greedy\nreplay is used implicitly within SA to improve PESA exploitation close to the\nend of evolution. The validation against 12 high-dimensional continuous\nbenchmark functions shows superior performance by PESA against standalone ES,\nPSO, and SA, under similar initial starting points, hyperparameters, and number\nof generations. PESA shows much better exploration behaviour, faster\nconvergence, and ability to find the global optima compared to its standalone\ncounterparts. Given the promising performance, PESA can offer an efficient\noptimisation option, especially after it goes through additional\nmultiprocessing improvements to handle complex and expensive fitness functions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:27:30 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Radaideh", "Majdi I.", ""], ["Shirvan", "Koroush", ""]]}, {"id": "2009.08942", "submitter": "Tuhin Chakrabarty Mr", "authors": "Tuhin Chakrabarty, Smaranda Muresan, Nanyun Peng", "title": "Generating similes effortlessly like a Pro: A Style Transfer Approach\n  for Simile Generation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Literary tropes, from poetry to stories, are at the crux of human imagination\nand communication. Figurative language such as a simile go beyond plain\nexpressions to give readers new insights and inspirations. In this paper, we\ntackle the problem of simile generation. Generating a simile requires proper\nunderstanding for effective mapping of properties between two concepts. To this\nend, we first propose a method to automatically construct a parallel corpus by\ntransforming a large number of similes collected from Reddit to their literal\ncounterpart using structured common sense knowledge. We then propose to\nfine-tune a pretrained sequence to sequence model, BART~\\cite{lewis2019bart},\non the literal-simile pairs to gain generalizability, so that we can generate\nnovel similes given a literal sentence. Experiments show that our approach\ngenerates $88\\%$ novel similes that do not share properties with the training\ndata. Human evaluation on an independent set of literal statements shows that\nour model generates similes better than two literary experts\n\\textit{37\\%}\\footnote{We average 32.6\\% and 41.3\\% for 2 humans.} of the\ntimes, and three baseline systems including a recent metaphor generation model\n\\textit{71\\%}\\footnote{We average 82\\% ,63\\% and 68\\% for three baselines.} of\nthe times when compared pairwise.\\footnote{The simile in the title is generated\nby our best model. Input: Generating similes effortlessly, output: Generating\nsimiles \\textit{like a Pro}.} We also show how replacing literal sentences with\nsimiles from our best model in machine generated stories improves evocativeness\nand leads to better acceptance by human judges.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 17:37:13 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 05:47:43 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Muresan", "Smaranda", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.08947", "submitter": "Markus Viljanen", "authors": "Markus Viljanen, Jukka Vahlo, Aki Koponen, Tapio Pahikkala", "title": "Content Based Player and Game Interaction Model for Game Recommendation\n  in the Cold Start setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game recommendation is an important application of recommender systems.\nRecommendations are made possible by data sets of historical player and game\ninteractions, and sometimes the data sets include features that describe games\nor players. Collaborative filtering has been found to be the most accurate\npredictor of past interactions. However, it can only be applied to predict new\ninteractions for those games and players where a significant number of past\ninteractions are present. In other words, predictions for completely new games\nand players is not possible. In this paper, we use a survey data set of game\nlikes to present content based interaction models that generalize into new\ngames, new players, and both new games and players simultaneously. We find that\nthe models outperform collaborative filtering in these tasks, which makes them\nuseful for real world game recommendation. The content models also provide\ninterpretations of why certain games are liked by certain players for game\nanalytics purposes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:10:49 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Viljanen", "Markus", ""], ["Vahlo", "Jukka", ""], ["Koponen", "Aki", ""], ["Pahikkala", "Tapio", ""]]}, {"id": "2009.08950", "submitter": "Karthik Raja Kalaiselvi Bhaskar", "authors": "Karthik Raja Kalaiselvi Bhaskar, Deepa Kundur, Yuri Lawryshyn", "title": "Implicit Feedback Deep Collaborative Filtering Product Recommendation\n  System", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, several Collaborative Filtering (CF) approaches with latent\nvariable methods were studied using user-item interactions to capture important\nhidden variations of the sparse customer purchasing behaviours. The latent\nfactors are used to generalize the purchasing pattern of the customers and to\nprovide product recommendations. CF with Neural Collaborative Filtering(NCF)\nwas shown to produce the highest Normalized Discounted Cumulative Gain (NDCG)\nperformance on the real-world proprietary dataset provided by a large parts\nsupply company. Different hyperparameters were tested using Bayesian\nOptimization (BO) for applicability in the CF framework. External data sources\nlike click-data and metrics like Clickthrough Rate (CTR) were reviewed for\npotential extensions to the work presented. The work shown in this paper\nprovides techniques the Company can use to provide product recommendations to\nenhance revenues, attract new customers, and gain advantages over competitors.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:30:14 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 15:08:40 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bhaskar", "Karthik Raja Kalaiselvi", ""], ["Kundur", "Deepa", ""], ["Lawryshyn", "Yuri", ""]]}, {"id": "2009.08952", "submitter": "Charles Dickens", "authors": "Charles Dickens, Rishika Singh, Lise Getoor", "title": "HyperFair: A Soft Approach to Integrating Fairness Criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are being employed across an increasingly diverse set of\ndomains that can potentially make a significant social and individual impact.\nFor this reason, considering fairness is a critical step in the design and\nevaluation of such systems. In this paper, we introduce HyperFair, a general\nframework for enforcing soft fairness constraints in a hybrid recommender\nsystem. HyperFair models integrate variations of fairness metrics as a\nregularization of a joint inference objective function. We implement our\napproach using probabilistic soft logic and show that it is particularly\nwell-suited for this task as it is expressive and structural constraints can be\nadded to the system in a concise and interpretable manner. We propose two ways\nto employ the methods we introduce: first as an extension of a probabilistic\nsoft logic recommender system template; second as a fair retrofitting technique\nthat can be used to improve the fairness of predictions from a black-box model.\nWe empirically validate our approach by implementing multiple HyperFair hybrid\nrecommenders and compare them to a state-of-the-art fair recommender. We also\nrun experiments showing the effectiveness of our methods for the task of\nretrofitting a black-box model and the trade-off between the amount of fairness\nenforced and the prediction performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 05:00:06 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Dickens", "Charles", ""], ["Singh", "Rishika", ""], ["Getoor", "Lise", ""]]}, {"id": "2009.08955", "submitter": "Rashidul Islam", "authors": "Rashidul Islam, Kamrun Naher Keya, Ziqian Zeng, Shimei Pan, James\n  Foulds", "title": "Neural Fair Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing proportion of human interactions are digitized on social media\nplatforms and subjected to algorithmic decision-making, and it has become\nincreasingly important to ensure fair treatment from these algorithms. In this\nwork, we investigate gender bias in collaborative-filtering recommender systems\ntrained on social media data. We develop neural fair collaborative filtering\n(NFCF), a practical framework for mitigating gender bias in recommending\nsensitive items (e.g. jobs, academic concentrations, or courses of study) using\na pre-training and fine-tuning approach to neural collaborative filtering,\naugmented with bias correction techniques. We show the utility of our methods\nfor gender de-biased career and college major recommendations on the MovieLens\ndataset and a Facebook dataset, respectively, and achieve better performance\nand fairer behavior than several state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:11:11 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Islam", "Rashidul", ""], ["Keya", "Kamrun Naher", ""], ["Zeng", "Ziqian", ""], ["Pan", "Shimei", ""], ["Foulds", "James", ""]]}, {"id": "2009.08956", "submitter": "Jiri Hron", "authors": "Jiri Hron and Karl Krauth and Michael I. Jordan and Niki Kilbertus", "title": "Exploration in two-stage recommender systems", "comments": "Published at the REVEAL 2020 workshop (RecSys 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-stage recommender systems are widely adopted in industry due to their\nscalability and maintainability. These systems produce recommendations in two\nsteps: (i) multiple nominators preselect a small number of items from a large\npool using cheap-to-compute item embeddings; (ii) with a richer set of\nfeatures, a ranker rearranges the nominated items and serves them to the user.\nA key challenge of this setup is that optimal performance of each stage in\nisolation does not imply optimal global performance. In response to this issue,\nMa et al. (2020) proposed a nominator training objective importance weighted by\nthe ranker's probability of recommending each item. In this work, we focus on\nthe complementary issue of exploration. Modeled as a contextual bandit problem,\nwe find LinUCB (a near optimal exploration strategy for single-stage systems)\nmay lead to linear regret when deployed in two-stage recommenders. We therefore\npropose a method of synchronising the exploration strategies between the ranker\nand the nominators. Our algorithm only relies on quantities already computed by\nstandard LinUCB at each stage and can be implemented in three lines of\nadditional code. We end by demonstrating the effectiveness of our algorithm\nexperimentally.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:52:51 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Hron", "Jiri", ""], ["Krauth", "Karl", ""], ["Jordan", "Michael I.", ""], ["Kilbertus", "Niki", ""]]}, {"id": "2009.08957", "submitter": "Sheng-Chieh Lin", "authors": "Sheng-Chieh Lin, Ting-Wei Lin, Jing-Kai Lou, Ming-Feng Tsai, Chuan-Ju\n  Wang", "title": "Personalized TV Recommendation: Fusing User Behavior and Preferences", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a two-stage ranking approach for recommending\nlinear TV programs. The proposed approach first leverages user viewing patterns\nregarding time and TV channels to identify potential candidates for\nrecommendation and then further leverages user preferences to rank these\ncandidates given textual information about programs. To evaluate the method, we\nconduct empirical studies on a real-world TV dataset, the results of which\ndemonstrate the superior performance of our model in terms of both\nrecommendation accuracy and time efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 16:05:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Sheng-Chieh", ""], ["Lin", "Ting-Wei", ""], ["Lou", "Jing-Kai", ""], ["Tsai", "Ming-Feng", ""], ["Wang", "Chuan-Ju", ""]]}, {"id": "2009.08962", "submitter": "Meimei Liu", "authors": "Meimei Liu, Hongxia Yang", "title": "DVE: Dynamic Variational Embeddings with Applications in Recommender\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding is a useful technique to project a high-dimensional feature into a\nlow-dimensional space, and it has many successful applications including link\nprediction, node classification and natural language processing. Current\napproaches mainly focus on static data, which usually lead to unsatisfactory\nperformance in applications involving large changes over time. How to\ndynamically characterize the variation of the embedded features is still\nlargely unexplored. In this paper, we introduce a dynamic variational embedding\n(DVE) approach for sequence-aware data based on recent advances in recurrent\nneural networks. DVE can model the node's intrinsic nature and temporal\nvariation explicitly and simultaneously, which are crucial for exploration. We\nfurther apply DVE to sequence-aware recommender systems, and develop an\nend-to-end neural architecture for link prediction.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 20:05:56 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Liu", "Meimei", ""], ["Yang", "Hongxia", ""]]}, {"id": "2009.08965", "submitter": "Micah Goldblum", "authors": "Manli Shu, Zuxuan Wu, Micah Goldblum, Tom Goldstein", "title": "Prepare for the Worst: Generalizing across Domain Shifts with\n  Adversarial Batch Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is the industry standard for producing models that are\nrobust to small adversarial perturbations. However, machine learning\npractitioners need models that are robust to domain shifts that occur\nnaturally, such as changes in the style or illumination of input images. Such\nchanges in input distribution have been effectively modeled as shifts in the\nmean and variance of deep image features. We adapt adversarial training by\nadversarially perturbing these feature statistics, rather than image pixels, to\nproduce models that are robust to domain shift. We also visualize images from\nadversarially crafted distributions. Our method, Adversarial Batch\nNormalization (AdvBN), significantly improves the performance of ResNet-50 on\nImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%)\nover standard training practices. In addition, we demonstrate that AdvBN can\nalso improve generalization on semantic segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 17:52:34 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 19:41:32 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Shu", "Manli", ""], ["Wu", "Zuxuan", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2009.08973", "submitter": "Lin Shao", "authors": "Lin Shao, Yifan You, Mengyuan Yan, Qingyun Sun, Jeannette Bohg", "title": "GRAC: Self-Guided and Self-Regularized Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) algorithms have successfully been\ndemonstrated on a range of challenging decision making and control tasks. One\ndominant component of recent deep reinforcement learning algorithms is the\ntarget network which mitigates the divergence when learning the Q function.\nHowever, target networks can slow down the learning process due to delayed\nfunction updates. Our main contribution in this work is a self-regularized\nTD-learning method to address divergence without requiring a target network.\nAdditionally, we propose a self-guided policy improvement method by combining\npolicy-gradient with zero-order optimization to search for actions associated\nwith higher Q-values in a broad neighborhood. This makes learning more robust\nto local noise in the Q function approximation and guides the updates of our\nactor network. Taken together, these components define GRAC, a novel\nself-guided and self-regularized actor critic algorithm. We evaluate GRAC on\nthe suite of OpenAI gym tasks, achieving or outperforming state of the art in\nevery environment tested.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 17:58:29 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:26:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shao", "Lin", ""], ["You", "Yifan", ""], ["Yan", "Mengyuan", ""], ["Sun", "Qingyun", ""], ["Bohg", "Jeannette", ""]]}, {"id": "2009.08978", "submitter": "Diego Antognini", "authors": "Milena Filipovic, Blagoj Mitrevski, Diego Antognini, Emma Lejal\n  Glaude, Boi Faltings, Claudiu Musat", "title": "Modeling Online Behavior in Recommender Systems: The Importance of\n  Temporal Context", "comments": "Under review. 8 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating online recommender system performance is notoriously difficult and\nthe discrepancy between the online and offline behaviors is typically not\naccounted for in offline evaluations. Recommender systems research tends to\nevaluate model performance on randomly sampled targets, yet the same systems\nare later used to predict user behavior sequentially from a fixed point in\ntime. This disparity permits weaknesses to go unnoticed until the model is\ndeployed in a production setting. We first demonstrate how omitting temporal\ncontext when evaluating recommender system performance leads to false\nconfidence. To overcome this, we propose an offline evaluation protocol\nmodeling the real-life use-case that simultaneously accounts for temporal\ncontext.\n  Next, we propose a training procedure to further embed the temporal context\nin existing models: we introduce it in a multi-objective approach to\ntraditionally time-unaware recommender systems. We confirm the advantage of\nadding a temporal objective via the proposed evaluation protocol. Finally, we\nvalidate that the Pareto Fronts obtained with the added objective dominate\nthose produced by state-of-the-art models that are only optimized for accuracy\non three real-world publicly available datasets. The results show that\nincluding our temporal objective can improve recall@20 by up to 20%.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:36:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Filipovic", "Milena", ""], ["Mitrevski", "Blagoj", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.08997", "submitter": "Arman Garakani", "authors": "Arman Garakani, Martin Malmstedt-Miller, Ionela Manole, Adrian Y.\n  Rossler and John R. Zibert", "title": "Psoriasis Severity Assessment with a Similarity-Clustering Machine\n  Learning Approach Reduces Intra- and Inter-observation variation", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psoriasis is a complex disease with many variations in genotype and\nphenotype. General advancements in medicine has further complicated both\nassessments and treatment for both physicians and dermatologist alike. Even\nwith all of our technological progress we still primarily use the assessment\ntool Psoriasis Area and Severity Index (PASI) for severity assessments which\nwas developed in the 1970s. In this study we evaluate a method involving\ndigital images, a comparison web application and similarity clustering,\ndeveloped to improve the assessment tool in terms of intra- and inter-observer\nvariation. Images of patients was collected from a mobile device. Images were\ncaptured of the same lesion area taken approximately 1 week apart. Five\ndermatologists evaluated the severity of psoriasis by modified-PASI, absolute\nscoring and a relative pairwise PASI scoring using similarity-clustering and\nconducted using a web-program displaying two images at a time. mPASI scoring of\nsingle photos by the same or different dermatologist showed mPASI ratings of\n50% to 80%, respectively. Repeated mPASI comparison using similarity clustering\nshowed consistent mPASI ratings > 95%. Pearson correlation between absolute\nscoring and pairwise scoring progression was 0.72.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:04:32 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:21:31 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Garakani", "Arman", ""], ["Malmstedt-Miller", "Martin", ""], ["Manole", "Ionela", ""], ["Rossler", "Adrian Y.", ""], ["Zibert", "John R.", ""]]}, {"id": "2009.09009", "submitter": "Vidya A. Chhabria", "authors": "Vidya A. Chhabria, Vipul Ahuja, Ashwath Prabhu, Nikhil Patil, Palkesh\n  Jain, and Sachin S. Sapatnekar", "title": "Thermal and IR Drop Analysis Using Convolutional Encoder-Decoder\n  Networks", "comments": "Accepted in ASP-DAC 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computationally expensive temperature and power grid analyses are required\nduring the design cycle to guide IC design. This paper employs encoder-decoder\nbased generative (EDGe) networks to map these analyses to fast and accurate\nimage-to-image and sequence-to-sequence translation tasks. The network takes a\npower map as input and outputs the corresponding temperature or IR drop map. We\npropose two networks: (i) ThermEDGe: a static and dynamic full-chip temperature\nestimator and (ii) IREDGe: a full-chip static IR drop predictor based on input\npower, power grid distribution, and power pad distribution patterns. The models\nare design-independent and must be trained just once for a particular\ntechnology and packaging solution. ThermEDGe and IREDGe are demonstrated to\nrapidly predict the on-chip temperature and IR drop contours in milliseconds\n(in contrast with commercial tools that require several hours or more) and\nprovide an average error of 0.6% and 0.008% respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:29:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chhabria", "Vidya A.", ""], ["Ahuja", "Vipul", ""], ["Prabhu", "Ashwath", ""], ["Patil", "Nikhil", ""], ["Jain", "Palkesh", ""], ["Sapatnekar", "Sachin S.", ""]]}, {"id": "2009.09011", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Giovanni Galatro, Antonio Liotta", "title": "Experimental Review of Neural-based approaches for Network Intrusion\n  Management", "comments": "Early Access on IEEE Transactions on Network and Service Management", "journal-ref": null, "doi": "10.1109/TNSM.2020.3024225", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Machine Learning (ML) techniques in Intrusion Detection Systems\n(IDS) has taken a prominent role in the network security management field, due\nto the substantial number of sophisticated attacks that often pass undetected\nthrough classic IDSs. These are typically aimed at recognising attacks based on\na specific signature, or at detecting anomalous events. However, deterministic,\nrule-based methods often fail to differentiate particular (rarer) network\nconditions (as in peak traffic during specific network situations) from actual\ncyber attacks. In this paper we provide an experimental-based review of\nneural-based methods applied to intrusion detection issues. Specifically, we i)\noffer a complete view of the most prominent neural-based techniques relevant to\nintrusion detection, including deep-based approaches or weightless neural\nnetworks, which feature surprising outcomes; ii) evaluate novel datasets\n(updated w.r.t. the obsolete KDD99 set) through a designed-from-scratch\nPython-based routine; iii) perform experimental analyses including time\ncomplexity and performance (accuracy and F-measure), considering both\nsingle-class and multi-class problems, and identifying trade-offs between\nresource consumption and performance. Our evaluation quantifies the value of\nneural networks, particularly when state-of-the-art datasets are used to train\nthe models. This leads to interesting guidelines for security managers and\ncomputer network practitioners who are looking at the incorporation of\nneural-based ML into IDS.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:32:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Di Mauro", "Mario", ""], ["Galatro", "Giovanni", ""], ["Liotta", "Antonio", ""]]}, {"id": "2009.09026", "submitter": "Jun Wu", "authors": "Yao Zhou and Jun Wu and Jingrui He", "title": "Robust Decentralized Learning for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized learning, data is distributed among local clients which\ncollaboratively train a shared prediction model using secure aggregation. To\npreserve the privacy of the clients, modern decentralized learning paradigms\nrequire each client to maintain a private local training data set and only\nupload their summarized model updates to the server. However, this can quickly\nlead to a degenerate model and collapse in performance when corrupted updates\n(e.g., adversarial manipulations) are aggregated at the server. In this work,\nwe present a robust decentralized learning framework, Decent_BVA, using\nbias-variance based adversarial training via asymmetrical communications\nbetween each client and the server. The experiments are conducted on neural\nnetworks with cross-entropy loss. Nevertheless, the proposed framework allows\nthe use of various classification loss functions (e.g., cross-entropy loss,\nmean squared error loss) where the gradients of the bias and variance are\ntractable to be estimated from local clients' models. In this case, any\ngradient-based adversarial training strategies could be used by taking the\nbias-variance oriented adversarial examples into consideration, e.g.,\nbias-variance based FGSM and PGD proposed in this paper. Experiments show that\nDecent_BVA is robust to the classical adversarial attacks when the level of\ncorruption is high while being competitive compared with conventional\ndecentralized learning in terms of the model's accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:58:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhou", "Yao", ""], ["Wu", "Jun", ""], ["He", "Jingrui", ""]]}, {"id": "2009.09028", "submitter": "Kapil Ahuja", "authors": "Aditya A. Shastri, Kapil Ahuja, Milind B. Ratnaparkhe, and Yann Busnel", "title": "Probabilistically Sampled and Spectrally Clustered Plant Genotypes using\n  Phenotypic Characteristics", "comments": "16 Pages, 3 Figures, and 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering genotypes based upon their phenotypic characteristics is used to\nobtain diverse sets of parents that are useful in their breeding programs. The\nHierarchical Clustering (HC) algorithm is the current standard in clustering of\nphenotypic data. This algorithm suffers from low accuracy and high\ncomputational complexity issues. To address the accuracy challenge, we propose\nthe use of Spectral Clustering (SC) algorithm. To make the algorithm\ncomputationally cheap, we propose using sampling, specifically, Pivotal\nSampling that is probability based. Since application of samplings to\nphenotypic data has not been explored much, for effective comparison, another\nsampling technique called Vector Quantization (VQ) is adapted for this data as\nwell. VQ has recently given promising results for genome data.\n  The novelty of our SC with Pivotal Sampling algorithm is in constructing the\ncrucial similarity matrix for the clustering algorithm and defining\nprobabilities for the sampling technique. Although our algorithm can be applied\nto any plant genotypes, we test it on the phenotypic data obtained from about\n2400 Soybean genotypes. SC with Pivotal Sampling achieves substantially more\naccuracy (in terms of Silhouette Values) than all the other proposed\ncompetitive clustering with sampling algorithms (i.e. SC with VQ, HC with\nPivotal Sampling, and HC with VQ). The complexities of our SC with Pivotal\nSampling algorithm and these three variants are almost same because of the\ninvolved sampling. In addition to this, SC with Pivotal Sampling outperforms\nthe standard HC algorithm in both accuracy and computational complexity. We\nexperimentally show that we are up to 45% more accurate than HC in terms of\nclustering accuracy. The computational complexity of our algorithm is more than\na magnitude lesser than HC.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:59:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Shastri", "Aditya A.", ""], ["Ahuja", "Kapil", ""], ["Ratnaparkhe", "Milind B.", ""], ["Busnel", "Yann", ""]]}, {"id": "2009.09031", "submitter": "YooJung Choi", "authors": "YooJung Choi, Meihua Dang, Guy Van den Broeck", "title": "Group Fairness by Probabilistic Modeling with Latent Fair Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are increasingly being used to make impactful\ndecisions such as loan applications and criminal justice risk assessments, and\nas such, ensuring fairness of these systems is critical. This is often\nchallenging as the labels in the data are biased. This paper studies learning\nfair probability distributions from biased data by explicitly modeling a latent\nvariable that represents a hidden, unbiased label. In particular, we aim to\nachieve demographic parity by enforcing certain independencies in the learned\nmodel. We also show that group fairness guarantees are meaningful only if the\ndistribution used to provide those guarantees indeed captures the real-world\ndata. In order to closely model the data distribution, we employ probabilistic\ncircuits, an expressive and tractable probabilistic model, and propose an\nalgorithm to learn them from incomplete data. We evaluate our approach on a\nsynthetic dataset in which observed labels indeed come from fair labels but\nwith added bias, and demonstrate that the fair labels are successfully\nretrieved. Moreover, we show on real-world datasets that our approach not only\nis a better model than existing methods of how the data was generated but also\nachieves competitive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:13:23 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 00:28:37 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Choi", "YooJung", ""], ["Dang", "Meihua", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2009.09043", "submitter": "Robert Moss", "authors": "Robert J. Moss", "title": "Cross-Entropy Method Variants for Optimization", "comments": "9 pages, 6 figures, code available at\n  https://github.com/mossr/CrossEntropyVariants.jl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cross-entropy (CE) method is a popular stochastic method for optimization\ndue to its simplicity and effectiveness. Designed for rare-event simulations\nwhere the probability of a target event occurring is relatively small, the\nCE-method relies on enough objective function calls to accurately estimate the\noptimal parameters of the underlying distribution. Certain objective functions\nmay be computationally expensive to evaluate, and the CE-method could\npotentially get stuck in local minima. This is compounded with the need to have\nan initial covariance wide enough to cover the design space of interest. We\nintroduce novel variants of the CE-method to address these concerns. To\nmitigate expensive function calls, during optimization we use every sample to\nbuild a surrogate model to approximate the objective function. The surrogate\nmodel augments the belief of the objective function with less expensive\nevaluations. We use a Gaussian process for our surrogate model to incorporate\nuncertainty in the predictions which is especially helpful when dealing with\nsparse data. To address local minima convergence, we use Gaussian mixture\nmodels to encourage exploration of the design space. We experiment with\nevaluation scheduling techniques to reallocate true objective function calls\nearlier in the optimization when the covariance is the largest. To test our\napproach, we created a parameterized test objective function with many local\nminima and a single global minimum. Our test function can be adjusted to\ncontrol the spread and distinction of the minima. Experiments were run to\nstress the cross-entropy method variants and results indicate that the\nsurrogate model-based approach reduces local minima convergence using the same\nnumber of function evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:51:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moss", "Robert J.", ""]]}, {"id": "2009.09051", "submitter": "Ian Fox", "authors": "Ian Fox, Joyce Lee, Rodica Pop-Busui, Jenna Wiens", "title": "Deep Reinforcement Learning for Closed-Loop Blood Glucose Control", "comments": "Accepted to MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People with type 1 diabetes (T1D) lack the ability to produce the insulin\ntheir bodies need. As a result, they must continually make decisions about how\nmuch insulin to self-administer to adequately control their blood glucose\nlevels. Longitudinal data streams captured from wearables, like continuous\nglucose monitors, can help these individuals manage their health, but currently\nthe majority of the decision burden remains on the user. To relieve this\nburden, researchers are working on closed-loop solutions that combine a\ncontinuous glucose monitor and an insulin pump with a control algorithm in an\n`artificial pancreas.' Such systems aim to estimate and deliver the appropriate\namount of insulin. Here, we develop reinforcement learning (RL) techniques for\nautomated blood glucose control. Through a series of experiments, we compare\nthe performance of different deep RL approaches to non-RL approaches. We\nhighlight the flexibility of RL approaches, demonstrating how they can adapt to\nnew individuals with little additional data. On over 2.1 million hours of data\nfrom 30 simulated patients, our RL approach outperforms baseline control\nalgorithms: leading to a decrease in median glycemic risk of nearly 50% from\n8.34 to 4.24 and a decrease in total time hypoglycemic of 99.8%, from 4,610\ndays to 6. Moreover, these approaches are able to adapt to predictable meal\ntimes (decreasing average risk by an additional 24% as meals increase in\npredictability). This work demonstrates the potential of deep RL to help people\nwith T1D manage their blood glucose levels without requiring expert knowledge.\nAll of our code is publicly available, allowing for replication and extension.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:15:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Fox", "Ian", ""], ["Lee", "Joyce", ""], ["Pop-Busui", "Rodica", ""], ["Wiens", "Jenna", ""]]}, {"id": "2009.09052", "submitter": "Giuseppe Vietri", "authors": "Giuseppe Vietri, Borja Balle, Akshay Krishnamurthy, Zhiwei Steven Wu", "title": "Private Reinforcement Learning with PAC and Regret Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by high-stakes decision-making domains like personalized medicine\nwhere user information is inherently sensitive, we design privacy preserving\nexploration policies for episodic reinforcement learning (RL). We first provide\na meaningful privacy formulation using the notion of joint differential privacy\n(JDP)--a strong variant of differential privacy for settings where each user\nreceives their own sets of output (e.g., policy recommendations). We then\ndevelop a private optimism-based learning algorithm that simultaneously\nachieves strong PAC and regret bounds, and enjoys a JDP guarantee. Our\nalgorithm only pays for a moderate privacy cost on exploration: in comparison\nto the non-private bounds, the privacy parameter only appears in lower-order\nterms. Finally, we present lower bounds on sample complexity and regret for\nreinforcement learning subject to JDP.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:18:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vietri", "Giuseppe", ""], ["Balle", "Borja", ""], ["Krishnamurthy", "Akshay", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2009.09069", "submitter": "Vaibhav Sourirajan", "authors": "Vaibhav Sourirajan, Anas Belouali, Mary Ann Dutton, Matthew Reinhard,\n  Jyotishman Pathak", "title": "A Machine Learning Approach to Detect Suicidal Ideation in US Veterans\n  Based on Acoustic and Linguistic Features of Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventing Veteran suicide is a national priority. The US Department of\nVeterans Affairs (VA) collects, analyzes, and publishes data to inform suicide\nprevention strategies. Current approaches for detecting suicidal ideation\nmostly rely on patient self report which are inadequate and time consuming. In\nthis research study, our goal was to automate suicidal ideation detection from\nacoustic and linguistic features of an individual's speech using machine\nlearning (ML) algorithms. Using voice data collected from Veterans enrolled in\na large interventional study on Gulf War Illness at the Washington DC VA\nMedical Center, we conducted an evaluation of the performance of different ML\napproaches in achieving our objective. By fitting both classical ML and deep\nlearning models to the dataset, we identified the algorithms that were most\neffective for each feature set. Among classical machine learning algorithms,\nthe Support Vector Machine (SVM) trained on acoustic features performed best in\nclassifying suicidal Veterans. Among deep learning methods, the Convolutional\nNeural Network (CNN) trained on the linguistic features performed best. Our\nstudy shows that speech analysis in a machine learning pipeline is a promising\napproach for detecting suicidality among Veterans.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 00:01:45 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 17:36:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sourirajan", "Vaibhav", ""], ["Belouali", "Anas", ""], ["Dutton", "Mary Ann", ""], ["Reinhard", "Matthew", ""], ["Pathak", "Jyotishman", ""]]}, {"id": "2009.09070", "submitter": "Tim Friede", "authors": "Sarah Friedrich, Gerd Antes, Sigrid Behr, Harald Binder, Werner\n  Brannath, Florian Dumpert, Katja Ickstadt, Hans Kestler, Johannes Lederer,\n  Heinz Leitg\\\"ob, Markus Pauly, Ansgar Steland, Adalbert Wilhelm, Tim Friede", "title": "Is there a role for statistics in artificial intelligence?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on and application of artificial intelligence (AI) has triggered\na comprehensive scientific, economic, social and political discussion. Here we\nargue that statistics, as an interdisciplinary scientific field, plays a\nsubstantial role both for the theoretical and practical understanding of AI and\nfor its future development. Statistics might even be considered a core element\nof AI. With its specialist knowledge of data evaluation, starting with the\nprecise formulation of the research question and passing through a study design\nstage on to analysis and interpretation of the results, statistics is a natural\npartner for other disciplines in teaching, research and practice. This paper\naims at contributing to the current discussion by highlighting the relevance of\nstatistical methodology in the context of AI development. In particular, we\ndiscuss contributions of statistics to the field of artificial intelligence\nconcerning methodological development, planning and design of studies,\nassessment of data quality and data collection, differentiation of causality\nand associations and assessment of uncertainty in results. Moreover, the paper\nalso deals with the equally necessary and meaningful extension of curricula in\nschools and universities.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:39:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Friedrich", "Sarah", ""], ["Antes", "Gerd", ""], ["Behr", "Sigrid", ""], ["Binder", "Harald", ""], ["Brannath", "Werner", ""], ["Dumpert", "Florian", ""], ["Ickstadt", "Katja", ""], ["Kestler", "Hans", ""], ["Lederer", "Johannes", ""], ["Leitg\u00f6b", "Heinz", ""], ["Pauly", "Markus", ""], ["Steland", "Ansgar", ""], ["Wilhelm", "Adalbert", ""], ["Friede", "Tim", ""]]}, {"id": "2009.09072", "submitter": "Matthew Ross", "authors": "Blake VanBerlo, Matthew A. S. Ross, Jonathan Rivard and Ryan Booker", "title": "Interpretable Machine Learning Approaches to Prediction of Chronic\n  Homelessness", "comments": "14 pages, 7 figures, submitted to Engineering Applications of\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a machine learning approach to predict chronic homelessness from\nde-identified client shelter records drawn from a commonly used Canadian\nhomelessness management information system. Using a 30-day time step, a dataset\nfor 6521 individuals was generated. Our model, HIFIS-RNN-MLP, incorporates both\nstatic and dynamic features of a client's history to forecast chronic\nhomelessness 6 months into the client's future. The training method was\nfine-tuned to achieve a high F1-score, giving a desired balance between high\nrecall and precision. Mean recall and precision across 10-fold cross validation\nwere 0.921 and 0.651 respectively. An interpretability method was applied to\nexplain individual predictions and gain insight into the overall factors\ncontributing to chronic homelessness among the population studied. The model\nachieves state-of-the-art performance and improved stakeholder trust of what is\nusually a \"black box\" neural network model through interpretable AI.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:02:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["VanBerlo", "Blake", ""], ["Ross", "Matthew A. S.", ""], ["Rivard", "Jonathan", ""], ["Booker", "Ryan", ""]]}, {"id": "2009.09074", "submitter": "Xia Li", "authors": "Rachel Grotheer, Yihuan Huang, Pengyu Li, Elizaveta Rebrova, Deanna\n  Needell, Longxiu Huang, Alona Kryshchenko, Xia Li, Kyung Ha, Oleksandr\n  Kryshchenko", "title": "COVID-19 Literature Topic-Based Search via Hierarchical NMF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dataset of COVID-19-related scientific literature is compiled, combining\nthe articles from several online libraries and selecting those with open access\nand full text available. Then, hierarchical nonnegative matrix factorization is\nused to organize literature related to the novel coronavirus into a tree\nstructure that allows researchers to search for relevant literature based on\ndetected topics. We discover eight major latent topics and 52 granular\nsubtopics in the body of literature, related to vaccines, genetic structure and\nmodeling of the disease and patient studies, as well as related diseases and\nvirology. In order that our tool may help current researchers, an interactive\nwebsite is created that organizes available literature using this hierarchical\nstructure.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 05:45:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Grotheer", "Rachel", ""], ["Huang", "Yihuan", ""], ["Li", "Pengyu", ""], ["Rebrova", "Elizaveta", ""], ["Needell", "Deanna", ""], ["Huang", "Longxiu", ""], ["Kryshchenko", "Alona", ""], ["Li", "Xia", ""], ["Ha", "Kyung", ""], ["Kryshchenko", "Oleksandr", ""]]}, {"id": "2009.09078", "submitter": "Tharindu Bandaragoda", "authors": "Tharindu Bandaragoda", "title": "Beyond Social Media Analytics: Understanding Human Behaviour and Deep\n  Emotion using Self Structuring Incremental Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis develops a conceptual framework considering social data as\nrepresenting the surface layer of a hierarchy of human social behaviours, needs\nand cognition which is employed to transform social data into representations\nthat preserve social behaviours and their causalities. Based on this framework\ntwo platforms were built to capture insights from fast-paced and slow-paced\nsocial data. For fast-paced, a self-structuring and incremental learning\ntechnique was developed to automatically capture salient topics and\ncorresponding dynamics over time. An event detection technique was developed to\nautomatically monitor those identified topic pathways for significant\nfluctuations in social behaviours using multiple indicators such as volume and\nsentiment. This platform is demonstrated using two large datasets with over 1\nmillion tweets. The separated topic pathways were representative of the key\ntopics of each entity and coherent against topic coherence measures. Identified\nevents were validated against contemporary events reported in news. Secondly\nfor the slow-paced social data, a suite of new machine learning and natural\nlanguage processing techniques were developed to automatically capture\nself-disclosed information of the individuals such as demographics, emotions\nand timeline of personal events. This platform was trialled on a large text\ncorpus of over 4 million posts collected from online support groups. This was\nfurther extended to transform prostate cancer related online support group\ndiscussions into a multidimensional representation and investigated the\nself-disclosed quality of life of patients (and partners) against time,\ndemographics and clinical factors. The capabilities of this extended platform\nhave been demonstrated using a text corpus collected from 10 prostate cancer\nonline support groups comprising of 609,960 prostate cancer discussions and\n22,233 patients.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:53:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bandaragoda", "Tharindu", ""]]}, {"id": "2009.09084", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Emily Alsentzer, Hyesun Park, Richard Thomas, Babina\n  Gosangi, Rahul Gujrathi, Bharti Khurana", "title": "Intimate Partner Violence and Injury Prediction From Radiology Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intimate partner violence (IPV) is an urgent, prevalent, and under-detected\npublic health issue. We present machine learning models to assess patients for\nIPV and injury. We train the predictive algorithms on radiology reports with 1)\nIPV labels based on entry to a violence prevention program and 2) injury labels\nprovided by emergency radiology fellowship-trained physicians. Our dataset\nincludes 34,642 radiology reports and 1479 patients of IPV victims and control\npatients. Our best model predicts IPV a median of 3.08 years before violence\nprevention program entry with a sensitivity of 64% and a specificity of 95%. We\nconduct error analysis to determine for which patients our model has especially\nhigh or low performance and discuss next steps for a deployed clinical risk\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:20:37 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:26:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Chen", "Irene Y.", ""], ["Alsentzer", "Emily", ""], ["Park", "Hyesun", ""], ["Thomas", "Richard", ""], ["Gosangi", "Babina", ""], ["Gujrathi", "Rahul", ""], ["Khurana", "Bharti", ""]]}, {"id": "2009.09087", "submitter": "Joshua Vendrow", "authors": "Joshua Vendrow, Jamie Haddock, Deanna Needell, and Lorraine Johnson", "title": "Feature Selection on Lyme Disease Patient Survey Data", "comments": "9 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyme disease is a rapidly growing illness that remains poorly understood\nwithin the medical community. Critical questions about when and why patients\nrespond to treatment or stay ill, what kinds of treatments are effective, and\neven how to properly diagnose the disease remain largely unanswered. We\ninvestigate these questions by applying machine learning techniques to a large\nscale Lyme disease patient registry, MyLymeData, developed by the nonprofit\nLymeDisease.org. We apply various machine learning methods in order to measure\nthe effect of individual features in predicting participants' answers to the\nGlobal Rating of Change (GROC) survey questions that assess the self-reported\ndegree to which their condition improved, worsened, or remained unchanged\nfollowing antibiotic treatment. We use basic linear regression, support vector\nmachines, neural networks, entropy-based decision tree models, and $k$-nearest\nneighbors approaches. We first analyze the general performance of the model and\nthen identify the most important features for predicting participant answers to\nGROC. After we identify the \"key\" features, we separate them from the dataset\nand demonstrate the effectiveness of these features at identifying GROC. In\ndoing so, we highlight possible directions for future study both mathematically\nand clinically.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:35:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vendrow", "Joshua", ""], ["Haddock", "Jamie", ""], ["Needell", "Deanna", ""], ["Johnson", "Lorraine", ""]]}, {"id": "2009.09092", "submitter": "Mucahit Cevik", "authors": "Ozan Ozyegen and Igor Ilic and Mucahit Cevik", "title": "Evaluation of Local Explanation Methods for Multivariate Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to interpret a machine learning model is a crucial task in many\napplications of machine learning. Specifically, local interpretability is\nimportant in determining why a model makes particular predictions. Despite the\nrecent focus on AI interpretability, there has been a lack of research in local\ninterpretability methods for time series forecasting while the few\ninterpretable methods that exist mainly focus on time series classification\ntasks. In this study, we propose two novel evaluation metrics for time series\nforecasting: Area Over the Perturbation Curve for Regression and Ablation\nPercentage Threshold. These two metrics can measure the local fidelity of local\nexplanation models. We extend the theoretical foundation to collect\nexperimental results on two popular datasets, \\textit{Rossmann sales} and\n\\textit{electricity}. Both metrics enable a comprehensive comparison of\nnumerous local explanation models and find which metrics are more sensitive.\nLastly, we provide heuristical reasoning for this analysis.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:15:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ozyegen", "Ozan", ""], ["Ilic", "Igor", ""], ["Cevik", "Mucahit", ""]]}, {"id": "2009.09093", "submitter": "Runsheng Xu", "authors": "Runsheng Xu, Faezeh Tafazzoli, Li Zhang, Timo Rehfeld, Gunther Krehl,\n  Arunava Seal", "title": "Holistic Grid Fusion Based Stop Line Estimation", "comments": "Submitted to ICPR2020", "journal-ref": "2020 25th International Conference on Pattern Recognition (ICPR),\n  Milan, Italy, 2021 pp. 8400-8407", "doi": "10.1109/ICPR48806.2021.9413070", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersection scenarios provide the most complex traffic situations in\nAutonomous Driving and Driving Assistance Systems. Knowing where to stop in\nadvance in an intersection is an essential parameter in controlling the\nlongitudinal velocity of the vehicle. Most of the existing methods in\nliterature solely use cameras to detect stop lines, which is typically not\nsufficient in terms of detection range. To address this issue, we propose a\nmethod that takes advantage of fused multi-sensory data including stereo camera\nand lidar as input and utilizes a carefully designed convolutional neural\nnetwork architecture to detect stop lines. Our experiments show that the\nproposed approach can improve detection range compared to camera data alone,\nworks under heavy occlusion without observing the ground markings explicitly,\nis able to predict stop lines for all lanes and allows detection at a distance\nup to 50 meters.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:29:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Xu", "Runsheng", ""], ["Tafazzoli", "Faezeh", ""], ["Zhang", "Li", ""], ["Rehfeld", "Timo", ""], ["Krehl", "Gunther", ""], ["Seal", "Arunava", ""]]}, {"id": "2009.09099", "submitter": "Anshuman Mishra", "authors": "Anshuman Mishra, Dhruvesh Patel, Aparna Vijayakumar, Xiang Li, Pavan\n  Kapanipathi, Kartik Talamadupula", "title": "Looking Beyond Sentence-Level Natural Language Inference for Downstream\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the Natural Language Inference (NLI) task has garnered\nsignificant attention, with new datasets and models achieving near human-level\nperformance on it. However, the full promise of NLI -- particularly that it\nlearns knowledge that should be generalizable to other downstream NLP tasks --\nhas not been realized. In this paper, we study this unfulfilled promise from\nthe lens of two downstream tasks: question answering (QA), and text\nsummarization. We conjecture that a key difference between the NLI datasets and\nthese downstream tasks concerns the length of the premise; and that creating\nnew long premise NLI datasets out of existing QA datasets is a promising avenue\nfor training a truly generalizable NLI model. We validate our conjecture by\nshowing competitive results on the task of QA and obtaining the best reported\nresults on the task of Checking Factual Correctness of Summaries.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:44:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Anshuman", ""], ["Patel", "Dhruvesh", ""], ["Vijayakumar", "Aparna", ""], ["Li", "Xiang", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2009.09110", "submitter": "Mucahit Cevik", "authors": "Igor Ilic and Berk Gorgulu and Mucahit Cevik and Mustafa Gokce\n  Baydogan", "title": "Explainable boosted linear regression for time series forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting involves collecting and analyzing past observations\nto develop a model to extrapolate such observations into the future.\nForecasting of future events is important in many fields to support decision\nmaking as it contributes to reducing the future uncertainty. We propose\nexplainable boosted linear regression (EBLR) algorithm for time series\nforecasting, which is an iterative method that starts with a base model, and\nexplains the model's errors through regression trees. At each iteration, the\npath leading to highest error is added as a new variable to the base model. In\nthis regard, our approach can be considered as an improvement over general time\nseries models since it enables incorporating nonlinear features by residuals\nexplanation. More importantly, use of the single rule that contributes to the\nerror most allows for interpretable results. The proposed approach extends to\nprobabilistic forecasting through generating prediction intervals based on the\nempirical error distribution. We conduct a detailed numerical study with EBLR\nand compare against various other approaches. We observe that EBLR\nsubstantially improves the base model performance through extracted features,\nand provide a comparable performance to other well established approaches. The\ninterpretability of the model predictions and high predictive accuracy of EBLR\nmakes it a promising method for time series forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:31:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ilic", "Igor", ""], ["Gorgulu", "Berk", ""], ["Cevik", "Mucahit", ""], ["Baydogan", "Mustafa Gokce", ""]]}, {"id": "2009.09111", "submitter": "Barinder Thind", "authors": "Barinder Thind, Sidi Wu, Richard Groenewald, Jiguo Cao", "title": "FuncNN: An R Package to Fit Deep Neural Networks Using Generalized Input\n  Spaces", "comments": "23 pages, 5 figures, submitted to JSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have excelled at regression and classification problems when\nthe input space consists of scalar variables. As a result of this proficiency,\nseveral popular packages have been developed that allow users to easily fit\nthese kinds of models. However, the methodology has excluded the use of\nfunctional covariates and to date, there exists no software that allows users\nto build deep learning models with this generalized input space. To the best of\nour knowledge, the functional neural network (FuncNN) library is the first such\npackage in any programming language; the library has been developed for R and\nis built on top of the keras architecture. Throughout this paper, several\nfunctions are introduced that provide users an avenue to easily build models,\ngenerate predictions, and run cross-validations. A summary of the underlying\nmethodology is also presented. The ultimate contribution is a package that\nprovides a set of general modelling and diagnostic tools for data problems in\nwhich there exist both functional and scalar covariates.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:32:29 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:41:36 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Thind", "Barinder", ""], ["Wu", "Sidi", ""], ["Groenewald", "Richard", ""], ["Cao", "Jiguo", ""]]}, {"id": "2009.09115", "submitter": "Hussein Osman", "authors": "Hussein Osman, Karim Zaghw, Mostafa Hazem, Seifeldin Elsehely", "title": "An Efficient Language-Independent Multi-Font OCR for Arabic Script", "comments": "9 pages, 4 figures, 4 tables, 2 algorithms, accepted in the\n  International Conference of Digital Image Processing and Pattern Recognition\n  (DPPR), London, UK, November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Character Recognition (OCR) is the process of extracting digitized\ntext from images of scanned documents. While OCR systems have already matured\nin many languages, they still have shortcomings in cursive languages with\noverlapping letters such as the Arabic language. This paper proposes a complete\nArabic OCR system that takes a scanned image of Arabic Naskh script as an input\nand generates a corresponding digital document. Our Arabic OCR system consists\nof the following modules: Pre-processing, Word-level Feature Extraction,\nCharacter Segmentation, Character Recognition, and Post-processing. This paper\nalso proposes an improved font-independent character segmentation algorithm\nthat outperforms the state-of-the-art segmentation algorithms. Lastly, the\npaper proposes a neural network model for the character recognition task. The\nsystem has experimented on several open Arabic corpora datasets with an average\ncharacter segmentation accuracy 98.06%, character recognition accuracy 99.89%,\nand overall system accuracy 97.94% achieving outstanding results compared to\nthe state-of-the-art Arabic OCR systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:57:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Osman", "Hussein", ""], ["Zaghw", "Karim", ""], ["Hazem", "Mostafa", ""], ["Elsehely", "Seifeldin", ""]]}, {"id": "2009.09116", "submitter": "Srihari Maruthachalam", "authors": "Srihari Maruthachalam", "title": "Analysis of artifacts in EEG signals for building BCIs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Computer Interface (BCI) is an essential mechanism that interprets the\nhuman brain signal. It provides an assistive technology that enables persons\nwith motor disabilities to communicate with the world and also empowers them to\nlead independent lives. The common BCI devices use Electroencephalography (EEG)\nelectrical activity recorded from the scalp. EEG signals are noisy owing to the\npresence of many artifacts, namely, eye blink, head movement, and jaw movement.\nSuch artifacts corrupt the EEG signal and make EEG analysis challenging. This\nissue is addressed by locating the artifacts and excluding the EEG segment from\nthe analysis, which could lead to a loss of useful information. However, we\npropose a practical BCI that uses the artifacts which has a low signal to noise\nratio.\n  The objective of our work is to classify different types of artifacts, namely\neye blink, head nod, head turn, and jaw movements in the EEG signal. The\noccurrence of the artifacts is first located in the EEG signal. The located\nartifacts are then classified using linear time and dynamic time warping\ntechniques. The located artifacts can be used by a person with a motor\ndisability to control a smartphone. A speech synthesis application that uses\neyeblinks in a single channel EEG system and jaw clinches in four channels EEG\nsystem are developed. Word prediction models are used for word completion, thus\nreducing the number of artifacts required.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 23:03:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Maruthachalam", "Srihari", ""]]}, {"id": "2009.09136", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki, Mohammad Amin Hariri-Ardebili, Lydia\n  Morawiec", "title": "Kernel Ridge Regression Using Importance Sampling with Application to\n  Seismic Response Prediction", "comments": "Accepted for publication in IEEE International Conference on Machine\n  Learning and Applications (ICMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable kernel methods, including kernel ridge regression, often rely on\nlow-rank matrix approximations using the Nystrom method, which involves\nselecting landmark points from large data sets. The existing approaches to\nselecting landmarks are typically computationally demanding as they require\nmanipulating and performing computations with large matrices in the input or\nfeature space. In this paper, our contribution is twofold. The first\ncontribution is to propose a novel landmark selection method that promotes\ndiversity using an efficient two-step approach. Our landmark selection\ntechnique follows a coarse to fine strategy, where the first step computes\nimportance scores with a single pass over the whole data. The second step\nperforms K-means clustering on the constructed coreset to use the obtained\ncentroids as landmarks. Hence, the introduced method provides tunable\ntrade-offs between accuracy and efficiency. Our second contribution is to\ninvestigate the performance of several landmark selection techniques using a\nnovel application of kernel methods for predicting structural responses due to\nearthquake load and material uncertainties. Our experiments exhibit the merits\nof our proposed landmark selection scheme against baselines.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 01:44:56 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""], ["Hariri-Ardebili", "Mohammad Amin", ""], ["Morawiec", "Lydia", ""]]}, {"id": "2009.09139", "submitter": "Jonathan Pilault", "authors": "Jonathan Pilault, Amine Elhattami, Christopher Pal", "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning\n  in NLP Using Fewer Parameters & Less Data", "comments": "ICLR 2021 (Reprint)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-Task Learning (MTL) networks have emerged as a promising method for\ntransferring learned knowledge across different tasks. However, MTL must deal\nwith challenges such as: overfitting to low resource tasks, catastrophic\nforgetting, and negative task transfer, or learning interference. Often, in\nNatural Language Processing (NLP), a separate model per task is needed to\nobtain the best performance. However, many fine-tuning approaches are both\nparameter inefficient, i.e., potentially involving one new model per task, and\nhighly susceptible to losing knowledge acquired during pretraining. We propose\na novel Transformer architecture consisting of a new conditional attention\nmechanism as well as a set of task-conditioned modules that facilitate weight\nsharing. Through this construction, we achieve more efficient parameter sharing\nand mitigate forgetting by keeping half of the weights of a pretrained model\nfixed. We also use a new multi-task data sampling strategy to mitigate the\nnegative effects of data imbalance across tasks. Using this approach, we are\nable to surpass single task fine-tuning methods while being parameter and data\nefficient (using around 66% of the data for weight updates). Compared to other\nBERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by\n2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and\nsingle task fine-tuning. We show that a larger variant of our single multi-task\nmodel approach performs competitively across 26 NLP tasks and yields\nstate-of-the-art results on a number of test and development sets. Our code is\npublicly available at https://github.com/CAMTL/CA-MTL.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:04:34 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 15:09:41 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Pilault", "Jonathan", ""], ["Elhattami", "Amine", ""], ["Pal", "Christopher", ""]]}, {"id": "2009.09140", "submitter": "Jindong Gu", "authors": "Jindong Gu and Zhiliang Wu and Volker Tresp", "title": "Introspective Learning by Distilling Knowledge from Online\n  Self-explanation", "comments": null, "journal-ref": "15th Asian Conference on Computer Vision (ACCV) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many explanation methods have been proposed to explain\nindividual classifications of deep neural networks. However, how to leverage\nthe created explanations to improve the learning process has been less\nexplored. As the privileged information, the explanations of a model can be\nused to guide the learning process of the model itself. In the community,\nanother intensively investigated privileged information used to guide the\ntraining of a model is the knowledge from a powerful teacher model. The goal of\nthis work is to leverage the self-explanation to improve the learning process\nby borrowing ideas from knowledge distillation. We start by investigating the\neffective components of the knowledge transferred from the teacher network to\nthe student network. Our investigation reveals that both the responses in\nnon-ground-truth classes and class-similarity information in teacher's outputs\ncontribute to the success of the knowledge distillation. Motivated by the\nconclusion, we propose an implementation of introspective learning by\ndistilling knowledge from online self-explanations. The models trained with the\nintrospective learning procedure outperform the ones trained with the standard\nlearning procedure, as well as the ones trained with different regularization\nmethods. When compared to the models learned from peer networks or teacher\nnetworks, our models also show competitive performance and requires neither\npeers nor teachers.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:05:32 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Gu", "Jindong", ""], ["Wu", "Zhiliang", ""], ["Tresp", "Volker", ""]]}, {"id": "2009.09143", "submitter": "Sayyed Zahiri", "authors": "Yun Zhu, Sayyed M. Zahiri, Jiaqi Wang, Han-Yu Chen, Faizan Javed", "title": "Active Learning for Product Type Ontology Enhancement in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity-based semantic search has been widely adopted in modern search engines\nto improve search accuracy by understanding users' intent. In e-commerce, an\naccurate and complete product type (PT) ontology is essential for recognizing\nproduct entities in queries and retrieving relevant products from catalog.\nHowever, finding product types (PTs) to construct such an ontology is usually\nexpensive due to the considerable amount of human efforts it may involve. In\nthis work, we propose an active learning framework that efficiently utilizes\ndomain experts' knowledge for PT discovery. We also show the quality and\ncoverage of the resulting PTs in the experiment results.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:21:12 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 22:41:09 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Zhu", "Yun", ""], ["Zahiri", "Sayyed M.", ""], ["Wang", "Jiaqi", ""], ["Chen", "Han-Yu", ""], ["Javed", "Faizan", ""]]}, {"id": "2009.09153", "submitter": "David Krueger", "authors": "David Krueger, Tegan Maharaj, Jan Leike", "title": "Hidden Incentives for Auto-Induced Distributional Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions made by machine learning systems have increasing influence on the\nworld, yet it is common for machine learning algorithms to assume that no such\ninfluence exists. An example is the use of the i.i.d. assumption in content\nrecommendation. In fact, the (choice of) content displayed can change users'\nperceptions and preferences, or even drive them away, causing a shift in the\ndistribution of users. We introduce the term auto-induced distributional shift\n(ADS) to describe the phenomenon of an algorithm causing a change in the\ndistribution of its own inputs. Our goal is to ensure that machine learning\nsystems do not leverage ADS to increase performance when doing so could be\nundesirable. We demonstrate that changes to the learning algorithm, such as the\nintroduction of meta-learning, can cause hidden incentives for auto-induced\ndistributional shift (HI-ADS) to be revealed. To address this issue, we\nintroduce `unit tests' and a mitigation strategy for HI-ADS, as well as a toy\nenvironment for modelling real-world issues with HI-ADS in content\nrecommendation, where we demonstrate that strong meta-learners achieve gains in\nperformance via ADS. We show meta-learning and Q-learning both sometimes fail\nunit tests, but pass when using our mitigation strategy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:31:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Krueger", "David", ""], ["Maharaj", "Tegan", ""], ["Leike", "Jan", ""]]}, {"id": "2009.09155", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "SecDD: Efficient and Secure Method for Remotely Training Neural Networks", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage what are typically considered the worst qualities of deep\nlearning algorithms - high computational cost, requirement for large data, no\nexplainability, high dependence on hyper-parameter choice, overfitting, and\nvulnerability to adversarial perturbations - in order to create a method for\nthe secure and efficient training of remotely deployed neural networks over\nunsecured channels.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:37:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2009.09161", "submitter": "Chenguang Zhang", "authors": "Chenguang Zhang and Yuexian Hou and Dawei Song and Liangzhu Ge and\n  Yaoshuai Yao", "title": "Label-Based Diversity Measure Among Hidden Units of Deep Neural\n  Networks: A Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the deep structure guarantees the powerful expressivity of deep\nnetworks (DNNs), it also triggers serious overfitting problem. To improve the\ngeneralization capacity of DNNs, many strategies were developed to improve the\ndiversity among hidden units. However, most of these strategies are empirical\nand heuristic in absence of either a theoretical derivation of the diversity\nmeasure or a clear connection from the diversity to the generalization\ncapacity. In this paper, from an information theoretic perspective, we\nintroduce a new definition of redundancy to describe the diversity of hidden\nunits under supervised learning settings by formalizing the effect of hidden\nlayers on the generalization capacity as the mutual information. We prove an\nopposite relationship existing between the defined redundancy and the\ngeneralization capacity, i.e., the decrease of redundancy generally improving\nthe generalization capacity. The experiments show that the DNNs using the\nredundancy as the regularizer can effectively reduce the overfitting and\ndecrease the generalization error, which well supports above points.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 04:27:44 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 12:32:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhang", "Chenguang", ""], ["Hou", "Yuexian", ""], ["Song", "Dawei", ""], ["Ge", "Liangzhu", ""], ["Yao", "Yaoshuai", ""]]}, {"id": "2009.09171", "submitter": "Kohei Numata", "authors": "Kohei Numata and Kenichi Tanaka", "title": "Stochastic Threshold Model Trees: A Tree-Based Ensemble Method for\n  Dealing with Extrapolation", "comments": "Code is available at\n  https://github.com/funatsu-lab/Stochastic-Threshold-Model-Trees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the field of chemistry, there have been many attempts to predict the\nproperties of unknown compounds from statistical models constructed using\nmachine learning. In an area where many known compounds are present (the\ninterpolation area), an accurate model can be constructed. In contrast, data in\nareas where there are no known compounds (the extrapolation area) are generally\ndifficult to predict. However, in the development of new materials, it is\ndesirable to search this extrapolation area and discover compounds with\nunprecedented physical properties. In this paper, we propose Stochastic\nThreshold Model Trees (STMT), an extrapolation method that reflects the trend\nof the data, while maintaining the accuracy of conventional interpolation\nmethods. The behavior of STMT is confirmed through experiments using both\nartificial and real data. In the case of the real data, although there is no\nsignificant overall improvement in accuracy, there is one compound for which\nthe prediction accuracy is notably improved, suggesting that STMT reflects the\ndata trends in the extrapolation area. We believe that the proposed method will\ncontribute to more efficient searches in situations such as new material\ndevelopment.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 05:48:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Numata", "Kohei", ""], ["Tanaka", "Kenichi", ""]]}, {"id": "2009.09172", "submitter": "Detlef Schmicker", "authors": "Detlef Schmicker", "title": "Few-shot learning using pre-training and shots, enriched by pre-trained\n  samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use the EMNIST dataset of handwritten digits to test a simple approach for\nfew-shot learning. A fully connected neural network is pre-trained with a\nsubset of the 10 digits and used for few-shot learning with untrained digits.\nTwo basic ideas are introduced: during few-shot learning the learning of the\nfirst layer is disabled, and for every shot a previously unknown digit is used\ntogether with four previously trained digits for the gradient descend, until a\npredefined threshold condition is fulfilled. This way we reach about 90%\naccuracy after 10 shots.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 06:08:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schmicker", "Detlef", ""]]}, {"id": "2009.09176", "submitter": "Yan Zeng", "authors": "Yan Zeng, Shohei Shimizu, Ruichu Cai, Feng Xie, Michio Yamamoto,\n  Zhifeng Hao", "title": "Causal Discovery with Multi-Domain LiNGAM for Latent Factors", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering causal structures among latent factors from observed data is a\nparticularly challenging problem. Despite some efforts for this problem,\nexisting methods focus on the single-domain data only. In this paper, we\npropose Multi-Domain Linear Non-Gaussian Acyclic Models for Latent Factors\n(MD-LiNA), where the causal structure among latent factors of interest is\nshared for all domains, and we provide its identification results. The model\nenriches the causal representation for multi-domain data. We propose an\nintegrated two-phase algorithm to estimate the model. In particular, we first\nlocate the latent factors and estimate the factor loading matrix. Then to\nuncover the causal structure among shared latent factors of interest, we derive\na score function based on the characterization of independence relations\nbetween external influences and the dependence relations between multi-domain\nlatent factors and latent factors of interest. We show that the proposed method\nprovides locally consistent estimators. Experimental results on both synthetic\nand real-world data demonstrate the efficacy and robustness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 06:44:03 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 13:36:41 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zeng", "Yan", ""], ["Shimizu", "Shohei", ""], ["Cai", "Ruichu", ""], ["Xie", "Feng", ""], ["Yamamoto", "Michio", ""], ["Hao", "Zhifeng", ""]]}, {"id": "2009.09187", "submitter": "Matthias Karlbauer", "authors": "Matthias Karlbauer, Sebastian Otte, Hendrik P.A. Lensch, Thomas\n  Scholten, Volker Wulfmeyer, and Martin V. Butz", "title": "Inferring, Predicting, and Denoising Causal Wave Dynamics", "comments": "As accepted by the 29th International Conference on Artificial Neural\n  Networks (ICANN20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel DISTributed Artificial neural Network Architecture (DISTANA) is a\ngenerative, recurrent graph convolution neural network. It implements a grid or\nmesh of locally parameterizable laterally connected network modules. DISTANA is\nspecifically designed to identify the causality behind spatially distributed,\nnon-linear dynamical processes. We show that DISTANA is very well-suited to\ndenoise data streams, given that re-occurring patterns are observed,\nsignificantly outperforming alternative approaches, such as temporal\nconvolution networks and ConvLSTMs, on a complex spatial wave propagation\nbenchmark. It produces stable and accurate closed-loop predictions even over\nhundreds of time steps. Moreover, it is able to effectively filter noise -- an\nability that can be improved further by applying denoising autoencoder\nprinciples or by actively tuning latent neural state activities\nretrospectively. Results confirm that DISTANA is ready to model real-world\nspatio-temporal dynamics such as brain imaging, supply networks, water flow, or\nsoil and weather data patterns.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 08:33:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Karlbauer", "Matthias", ""], ["Otte", "Sebastian", ""], ["Lensch", "Hendrik P. A.", ""], ["Scholten", "Thomas", ""], ["Wulfmeyer", "Volker", ""], ["Butz", "Martin V.", ""]]}, {"id": "2009.09196", "submitter": "Sheng Wan", "authors": "Sheng Wan and Chen Gong and Shirui Pan and Jie Yang and Jian Yang", "title": "Multi-Level Graph Convolutional Network with Automatic Graph Learning\n  for Hyperspectral Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, deep learning methods, especially the Graph Convolutional Network\n(GCN), have shown impressive performance in hyperspectral image (HSI)\nclassification. However, the current GCN-based methods treat graph construction\nand image classification as two separate tasks, which often results in\nsuboptimal performance. Another defect of these methods is that they mainly\nfocus on modeling the local pairwise importance between graph nodes while lack\nthe capability to capture the global contextual information of HSI. In this\npaper, we propose a Multi-level GCN with Automatic Graph Learning method\n(MGCN-AGL) for HSI classification, which can automatically learn the graph\ninformation at both local and global levels. By employing attention mechanism\nto characterize the importance among spatially neighboring regions, the most\nrelevant information can be adaptively incorporated to make decisions, which\nhelps encode the spatial context to form the graph information at local level.\nMoreover, we utilize multiple pathways for local-level graph convolution, in\norder to leverage the merits from the diverse spatial context of HSI and to\nenhance the expressive power of the generated representations. To reconstruct\nthe global contextual relations, our MGCN-AGL encodes the long range\ndependencies among image regions based on the expressive representations that\nhave been produced at local level. Then inference can be performed along the\nreconstructed graph edges connecting faraway regions. Finally, the multi-level\ninformation is adaptively fused to generate the network output. In this means,\nthe graph learning and image classification can be integrated into a unified\nframework and benefit each other. Extensive experiments have been conducted on\nthree real-world hyperspectral datasets, which are shown to outperform the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:26:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wan", "Sheng", ""], ["Gong", "Chen", ""], ["Pan", "Shirui", ""], ["Yang", "Jie", ""], ["Yang", "Jian", ""]]}, {"id": "2009.09206", "submitter": "Ayush Mangal", "authors": "Ayush Mangal, Jitesh Jain, Keerat Kaur Guliani, Omkar Bhalerao", "title": "DEAP Cache: Deep Eviction Admission and Prefetching for Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for learning policies to improve caching, target just one\nout of the prefetching, admission and eviction processes. In contrast, we\npropose an end to end pipeline to learn all three policies using machine\nlearning. We also take inspiration from the success of pretraining on large\ncorpora to learn specialized embeddings for the task. We model prefetching as a\nsequence prediction task based on past misses. Following previous works\nsuggesting that frequency and recency are the two orthogonal fundamental\nattributes for caching, we use an online reinforcement learning technique to\nlearn the optimal policy distribution between two orthogonal eviction\nstrategies based on them. While previous approaches used the past as an\nindicator of the future, we instead explicitly model the future frequency and\nrecency in a multi-task fashion with prefetching, leveraging the abilities of\ndeep networks to capture futuristic trends and use them for learning eviction\nand admission. We also model the distribution of the data in an online fashion\nusing Kernel Density Estimation in our approach, to deal with the problem of\ncaching non-stationary data. We present our approach as a \"proof of concept\" of\nlearning all three components of cache strategies using machine learning and\nleave improving practical deployment for future work.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 10:23:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mangal", "Ayush", ""], ["Jain", "Jitesh", ""], ["Guliani", "Keerat Kaur", ""], ["Bhalerao", "Omkar", ""]]}, {"id": "2009.09213", "submitter": "Yihao Huang", "authors": "Yihao Huang, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Lei Ma, Weikai\n  Miao, Yang Liu, Geguang Pu", "title": "FakeRetouch: Evading DeepFakes Detection via the Guidance of Deliberate\n  Noise", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novelty and creativity of DeepFake generation techniques have attracted\nworldwide media attention. Many researchers focus on detecting fake images\nproduced by these GAN-based image generation methods with fruitful results,\nindicating that the GAN-based image generation methods are not yet perfect.\nMany studies show that the upsampling procedure used in the decoder of\nGAN-based image generation methods inevitably introduce artifact patterns into\nfake images. In order to further improve the fidelity of DeepFake images, in\nthis work, we propose a simple yet powerful framework to reduce the artifact\npatterns of fake images without hurting image quality. The method is based on\nan important observation that adding noise to a fake image can successfully\nreduce the artifact patterns in both spatial and frequency domains. Thus we use\na combination of additive noise and deep image filtering to reconstruct the\nfake images, and we name our method FakeRetouch. The deep image filtering\nprovides a specialized filter for each pixel in the noisy image, taking full\nadvantages of deep learning. The deeply filtered images retain very high\nfidelity to their DeepFake counterparts. Moreover, we use the semantic\ninformation of the image to generate an adversarial guidance map to add noise\nintelligently. Our method aims at improving the fidelity of DeepFake images and\nexposing the problems of existing DeepFake detection methods, and we hope that\nthe found vulnerabilities can help improve the future generation DeepFake\ndetection methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 11:26:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Huang", "Yihao", ""], ["Juefei-Xu", "Felix", ""], ["Guo", "Qing", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Miao", "Weikai", ""], ["Liu", "Yang", ""], ["Pu", "Geguang", ""]]}, {"id": "2009.09217", "submitter": "Luca Martino", "authors": "Luca Martino, Jesse Read", "title": "A Joint introduction to Gaussian Processes and Relevance Vector Machines\n  with Connections to Kalman filtering and other Kernel Smoothers", "comments": null, "journal-ref": "Information Fusion, Volume 74, Pages 17-38, 2021", "doi": "10.1016/j.inffus.2021.03.002", "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of Bayesian kernel-based methods has led them to become\nan important tool across many different facets of artificial intelligence, and\nuseful to a plethora of modern application domains, providing both power and\ninterpretability via uncertainty analysis. This article introduces and\ndiscusses two methods which straddle the areas of probabilistic Bayesian\nschemes and kernel methods for regression: Gaussian Processes and Relevance\nVector Machines. Our focus is on developing a common framework with which to\nview these methods, via intermediate methods a probabilistic version of the\nwell-known kernel ridge regression, and drawing connections among them, via\ndual formulations, and discussion of their application in the context of major\ntasks: regression, smoothing, interpolation, and filtering. Overall, we provide\nunderstanding of the mathematical concepts behind these models, and we\nsummarize and discuss in depth different interpretations and highlight the\nrelationship to other methods, such as linear kernel smoothers, Kalman\nfiltering and Fourier approximations. Throughout, we provide numerous figures\nto promote understanding, and we make numerous recommendations to\npractitioners. Benefits and drawbacks of the different techniques are\nhighlighted. To our knowledge, this is the most in-depth study of its kind to\ndate focused on these two methods, and will be relevant to theoretical\nunderstanding and practitioners throughout the domains of data-science, signal\nprocessing, machine learning, and artificial intelligence in general.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:22:41 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 20:03:15 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 17:02:30 GMT"}, {"version": "v4", "created": "Sun, 11 Jul 2021 19:28:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Martino", "Luca", ""], ["Read", "Jesse", ""]]}, {"id": "2009.09224", "submitter": "Jamil Ispahany Mr", "authors": "Jamil Ispahany and Rafiqul Islam", "title": "Detecting Malicious URLs of COVID-19 Pandemic using ML technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the COVID-19 outbreak, malicious attacks have become more\npervasive and damaging than ever. Malicious intruders have been responsible for\nmost cybercrimes committed recently and are the cause for a growing number of\ncyber threats, including identity and IP thefts, financial crimes, and\ncyber-attacks to critical infrastructures. Machine learning (ML) has proven\nitself as a prominent field of study over the past decade by solving many\nhighly complex and sophisticated real-world problems. This paper proposes an\nML-based classification technique to detect the growing number of malicious\nURLs, due to the COVID-19 pandemic, which is currently considered a threat to\nIT users. We have used a large volume of Open Source data and preprocessed it\nusing our developed tool to generate feature vectors and we trained the ML\nmodel using the apprehensive malicious threat weight. Our ML model has been\ntested, with and without entropy to forecast the threatening factors of\nCOVID-19 URLs. The empirical evidence proves our methods to be a promising\nmechanism to mitigate COVID-19 related threats early in the attack lifecycle.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:59:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ispahany", "Jamil", ""], ["Islam", "Rafiqul", ""]]}, {"id": "2009.09230", "submitter": "Xiaosa Zhao", "authors": "Xiaosa Zhao, Kunpeng Liu, Wei Fan, Lu Jiang, Xiaowei Zhao, Minghao\n  Yin, and Yanjie Fu", "title": "Simplifying Reinforced Feature Selection via Restructured Choice\n  Strategy of Single Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection aims to select a subset of features to optimize the\nperformances of downstream predictive tasks. Recently, multi-agent reinforced\nfeature selection (MARFS) has been introduced to automate feature selection, by\ncreating agents for each feature to select or deselect corresponding features.\nAlthough MARFS enjoys the automation of the selection process, MARFS suffers\nfrom not just the data complexity in terms of contents and dimensionality, but\nalso the exponentially-increasing computational costs with regard to the number\nof agents. The raised concern leads to a new research question: Can we simplify\nthe selection process of agents under reinforcement learning context so as to\nimprove the efficiency and costs of feature selection? To address the question,\nwe develop a single-agent reinforced feature selection approach integrated with\nrestructured choice strategy. Specifically, the restructured choice strategy\nincludes: 1) we exploit only one single agent to handle the selection task of\nmultiple features, instead of using multiple agents. 2) we develop a scanning\nmethod to empower the single agent to make multiple selection/deselection\ndecisions in each round of scanning. 3) we exploit the relevance to predictive\nlabels of features to prioritize the scanning orders of the agent for multiple\nfeatures. 4) we propose a convolutional auto-encoder algorithm, integrated with\nthe encoded index information of features, to improve state representation. 5)\nwe design a reward scheme that take into account both prediction accuracy and\nfeature redundancy to facilitate the exploration process. Finally, we present\nextensive experimental results to demonstrate the efficiency and effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 13:41:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Xiaosa", ""], ["Liu", "Kunpeng", ""], ["Fan", "Wei", ""], ["Jiang", "Lu", ""], ["Zhao", "Xiaowei", ""], ["Yin", "Minghao", ""], ["Fu", "Yanjie", ""]]}, {"id": "2009.09232", "submitter": "Duo Wang", "authors": "Yiren Zhao, Duo Wang, Daniel Bates, Robert Mullins, Mateja Jamnik,\n  Pietro Lio", "title": "Learned Low Precision Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Graph Neural Networks (GNNs) show promising performance on a range of\ngraph tasks, yet at present are costly to run and lack many of the\noptimisations applied to DNNs. We show, for the first time, how to\nsystematically quantise GNNs with minimal or no loss in performance using\nNetwork Architecture Search (NAS). We define the possible quantisation search\nspace of GNNs. The proposed novel NAS mechanism, named Low Precision Graph NAS\n(LPGNAS), constrains both architecture and quantisation choices to be\ndifferentiable. LPGNAS learns the optimal architecture coupled with the best\nquantisation strategy for different components in the GNN automatically using\nback-propagation in a single search round. On eight different datasets, solving\nthe task of classifying unseen nodes in a graph, LPGNAS generates quantised\nmodels with significant reductions in both model and buffer sizes but with\nsimilar accuracy to manually designed networks and other NAS results. In\nparticular, on the Pubmed dataset, LPGNAS shows a better size-accuracy Pareto\nfrontier compared to seven other manual and searched baselines, offering a 2.3\ntimes reduction in model size but a 0.4% increase in accuracy when compared to\nthe best NAS competitor. Finally, from our collected quantisation statistics on\na wide range of datasets, we suggest a W4A8 (4-bit weights, 8-bit activations)\nquantisation strategy might be the bottleneck for naive GNN quantisations.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 13:51:09 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Yiren", ""], ["Wang", "Duo", ""], ["Bates", "Daniel", ""], ["Mullins", "Robert", ""], ["Jamnik", "Mateja", ""], ["Lio", "Pietro", ""]]}, {"id": "2009.09247", "submitter": "Qing Guo", "authors": "Binyu Tian, Qing Guo, Felix Juefei-Xu, Wen Le Chan, Yupeng Cheng,\n  Xiaohong Li, Xiaofei Xie, Shengchao Qin", "title": "Bias Field Poses a Threat to DNN-based X-Ray Recognition", "comments": "6 pages, 5 figures; This work has been accepted to ICME 2021 as the\n  oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The chest X-ray plays a key role in screening and diagnosis of many lung\ndiseases including the COVID-19. More recently, many works construct deep\nneural networks (DNNs) for chest X-ray images to realize automated and\nefficient diagnosis of lung diseases. However, bias field caused by the\nimproper medical image acquisition process widely exists in the chest X-ray\nimages while the robustness of DNNs to the bias field is rarely explored, which\ndefinitely poses a threat to the X-ray-based automated diagnosis system. In\nthis paper, we study this problem based on the recent adversarial attack and\npropose a brand new attack, i.e., the adversarial bias field attack where the\nbias field instead of the additive noise works as the adversarial perturbations\nfor fooling the DNNs. This novel attack posts a key problem: how to locally\ntune the bias field to realize high attack success rate while maintaining its\nspatial smoothness to guarantee high realisticity. These two goals contradict\neach other and thus has made the attack significantly challenging. To overcome\nthis challenge, we propose the adversarial-smooth bias field attack that can\nlocally tune the bias field with joint smooth & adversarial constraints. As a\nresult, the adversarial X-ray images can not only fool the DNNs effectively but\nalso retain very high level of realisticity. We validate our method on real\nchest X-ray datasets with powerful DNNs, e.g., ResNet50, DenseNet121, and\nMobileNet, and show different properties to the state-of-the-art attacks in\nboth image realisticity and attack transferability. Our method reveals the\npotential threat to the DNN-based X-ray automated diagnosis and can definitely\nbenefit the development of bias-field-robust automated diagnosis system.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 14:58:02 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 04:00:36 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Tian", "Binyu", ""], ["Guo", "Qing", ""], ["Juefei-Xu", "Felix", ""], ["Chan", "Wen Le", ""], ["Cheng", "Yupeng", ""], ["Li", "Xiaohong", ""], ["Xie", "Xiaofei", ""], ["Qin", "Shengchao", ""]]}, {"id": "2009.09249", "submitter": "Hakan G\\\"okcesu", "authors": "Kaan Gokcesu, Hakan Gokcesu", "title": "Recursive Experts: An Efficient Optimal Mixture of Learning Systems in\n  Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential learning systems are used in a wide variety of problems from\ndecision making to optimization, where they provide a 'belief' (opinion) to\nnature, and then update this belief based on the feedback (result) to minimize\n(or maximize) some cost or loss (conversely, utility or gain). The goal is to\nreach an objective by exploiting the temporal relation inherent to the nature's\nfeedback (state). By exploiting this relation, specific learning systems can be\ndesigned that perform asymptotically optimal for various applications. However,\nif the framework of the problem is not stationary, i.e., the nature's state\nsometimes changes arbitrarily, the past cumulative belief revision done by the\nsystem may become useless and the system may fail if it lacks adaptivity. While\nthis adaptivity can be directly implemented in specific cases (e.g., convex\noptimization), it is mostly not straightforward for general learning tasks. To\nthis end, we propose an efficient optimal mixture framework for general\nsequential learning systems, which we call the recursive experts for dynamic\nenvironments. For this purpose, we design hyper-experts that incorporate the\nlearning systems at our disposal and recursively merge in a specific way to\nachieve minimax optimal regret bounds up to constant factors. The\nmultiplicative increases in computational complexity from the initial system to\nour adaptive system are only logarithmic-in-time factors.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 15:02:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Gokcesu", "Kaan", ""], ["Gokcesu", "Hakan", ""]]}, {"id": "2009.09253", "submitter": "Thirunavukarasu Balasubramaniam", "authors": "Thirunavukarasu Balasubramaniam, Richi Nayak, Md Abul Bashar", "title": "Understanding the Spatio-temporal Topic Dynamics of Covid-19 using\n  Nonnegative Tensor Factorization: A Case Study", "comments": "Accepted in 18th Australasian Data Mining Conference (AusDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms facilitate mankind a data-driven world by enabling\nbillions of people to share their thoughts and activities ubiquitously. This\nhuge collection of data, if analysed properly, can provide useful insights into\npeople's behavior. More than ever, now is a crucial time under the Covid-19\npandemic to understand people's online behaviors detailing what topics are\nbeing discussed, and where (space) and when (time) they are discussed. Given\nthe high complexity and poor quality of the huge social media data, an\neffective spatio-temporal topic detection method is needed. This paper proposes\na tensor-based representation of social media data and Non-negative Tensor\nFactorization (NTF) to identify the topics discussed in social media data along\nwith the spatio-temporal topic dynamics. A case study on Covid-19 related\ntweets from the Australia Twittersphere is presented to identify and visualize\nspatio-temporal topic dynamics on Covid-19\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 15:16:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Balasubramaniam", "Thirunavukarasu", ""], ["Nayak", "Richi", ""], ["Bashar", "Md Abul", ""]]}, {"id": "2009.09259", "submitter": "Shengjun Pan", "authors": "Shengjun Pan, Brendan Kitts, Tian Zhou, Hao He, Bharatbhushan Shetty,\n  Aaron Flores, Djordje Gligorijevic, Junwei Pan, Tingyu Mao, San Gultekin and\n  Jianlong Zhang", "title": "Bid Shading by Win-Rate Estimation and Surplus Maximization", "comments": "AdKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new win-rate based bid shading algorithm (WR) that\ndoes not rely on the minimum-bid-to-win feedback from a Sell-Side Platform\n(SSP). The method uses a modified logistic regression to predict the profit\nfrom each possible shaded bid price. The function form allows fast maximization\nat run-time, a key requirement for Real-Time Bidding (RTB) systems. We report\nproduction results from this method along with several other algorithms. We\nfound that bid shading, in general, can deliver significant value to\nadvertisers, reducing price per impression to about 55% of the unshaded cost.\nFurther, the particular approach described in this paper captures 7% more\nprofit for advertisers, than do benchmark methods of just bidding the most\nprobable winning price. We also report 4.3% higher surplus than an industry\nSell-Side Platform shading service. Furthermore, we observed 3% - 7% lower\neCPM, eCPC and eCPA when the algorithm was integrated with budget controllers.\nWe attribute the gains above as being mainly due to the explicit maximization\nof the surplus function, and note that other algorithms can take advantage of\nthis same approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 15:46:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pan", "Shengjun", ""], ["Kitts", "Brendan", ""], ["Zhou", "Tian", ""], ["He", "Hao", ""], ["Shetty", "Bharatbhushan", ""], ["Flores", "Aaron", ""], ["Gligorijevic", "Djordje", ""], ["Pan", "Junwei", ""], ["Mao", "Tingyu", ""], ["Gultekin", "San", ""], ["Zhang", "Jianlong", ""]]}, {"id": "2009.09271", "submitter": "Negar Foroutan", "authors": "Negar Foroutan Eghlidi and Martin Jaggi", "title": "Sparse Communication for Training Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous stochastic gradient descent (SGD) is the most common method used\nfor distributed training of deep learning models. In this algorithm, each\nworker shares its local gradients with others and updates the parameters using\nthe average gradients of all workers. Although distributed training reduces the\ncomputation time, the communication overhead associated with the gradient\nexchange forms a scalability bottleneck for the algorithm. There are many\ncompression techniques proposed to reduce the number of gradients that needs to\nbe communicated. However, compressing the gradients introduces yet another\noverhead to the problem. In this work, we study several compression schemes and\nidentify how three key parameters affect the performance. We also provide a set\nof insights on how to increase performance and introduce a simple\nsparsification scheme, random-block sparsification, that reduces communication\nwhile keeping the performance close to standard SGD.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 17:28:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Eghlidi", "Negar Foroutan", ""], ["Jaggi", "Martin", ""]]}, {"id": "2009.09277", "submitter": "Yun Liao", "authors": "Yun Liao, Seyyed Ali Hashemi, John Cioffi, Andrea Goldsmith", "title": "Construction of Polar Codes with Reinforcement Learning", "comments": "To be published in Proceedings of IEEE Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates the polar-code construction problem for the\nsuccessive-cancellation list (SCL) decoder as a maze-traversing game, which can\nbe solved by reinforcement learning techniques. The proposed method provides a\nnovel technique for polar-code construction that no longer depends on sorting\nand selecting bit-channels by reliability. Instead, this technique decides\nwhether the input bits should be frozen in a purely sequential manner. The\nequivalence of optimizing the polar-code construction for the SCL decoder under\nthis technique and maximizing the expected reward of traversing a maze is\ndrawn. Simulation results show that the standard polar-code constructions that\nare designed for the successive-cancellation decoder are no longer optimal for\nthe SCL decoder with respect to the frame error rate. In contrast, the\nsimulations show that, with a reasonable amount of training, the game-based\nconstruction method finds code constructions that have lower frame-error rate\nfor various code lengths and decoders compared to standard constructions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 17:59:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liao", "Yun", ""], ["Hashemi", "Seyyed Ali", ""], ["Cioffi", "John", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "2009.09279", "submitter": "Mohamed Wiem Mkaouer", "authors": "Eman Abdullah AlOmar, Mohamed Wiem Mkaouer, Ali Ouni", "title": "Toward the Automatic Classification of Self-Affirmed Refactoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of Self-Affirmed Refactoring (SAR) was introduced to explore how\ndevelopers document their refactoring activities in commit messages, i.e.,\ndevelopers' explicit documentation of refactoring operations intentionally\nintroduced during a code change. In our previous study, we have manually\nidentified refactoring patterns and defined three main common quality\nimprovement categories, including internal quality attributes, external quality\nattributes, and code smells, by only considering refactoring-related commits.\nHowever, this approach heavily depends on the manual inspection of commit\nmessages. In this paper, we propose a two-step approach to first identify\nwhether a commit describes developer-related refactoring events, then to\nclassify it according to the refactoring common quality improvement categories.\nSpecifically, we combine the N-Gram TF-IDF feature selection with binary and\nmulticlass classifiers to build a new model to automate the classification of\nrefactorings based on their quality improvement categories. We challenge our\nmodel using a total of 2,867 commit messages extracted from well-engineered\nopen-source Java projects. Our findings show that (1) our model is able to\naccurately classify SAR commits, outperforming the pattern-based and random\nclassifier approaches, and allowing the discovery of 40 more relevant SAR\npatterns, and (2) our model reaches an F-measure of up to 90% even with a\nrelatively small training dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 18:35:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["AlOmar", "Eman Abdullah", ""], ["Mkaouer", "Mohamed Wiem", ""], ["Ouni", "Ali", ""]]}, {"id": "2009.09282", "submitter": "Nan Wu", "authors": "Nan Wu and Zhe Huang and Yiqiu Shen and Jungkyu Park and Jason Phang\n  and Taro Makino and S. Gene Kim and Kyunghyun Cho and Laura Heacock and Linda\n  Moy and Krzysztof J. Geras", "title": "Reducing false-positive biopsies with deep neural networks that utilize\n  local and global information in screening mammograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most common cancer in women, and hundreds of thousands\nof unnecessary biopsies are done around the world at a tremendous cost. It is\ncrucial to reduce the rate of biopsies that turn out to be benign tissue. In\nthis study, we build deep neural networks (DNNs) to classify biopsied lesions\nas being either malignant or benign, with the goal of using these networks as\nsecond readers serving radiologists to further reduce the number of false\npositive findings. We enhance the performance of DNNs that are trained to learn\nfrom small image patches by integrating global context provided in the form of\nsaliency maps learned from the entire image into their reasoning, similar to\nhow radiologists consider global context when evaluating areas of interest. Our\nexperiments are conducted on a dataset of 229,426 screening mammography exams\nfrom 141,473 patients. We achieve an AUC of 0.8 on a test set consisting of 464\nbenign and 136 malignant lesions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 18:54:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wu", "Nan", ""], ["Huang", "Zhe", ""], ["Shen", "Yiqiu", ""], ["Park", "Jungkyu", ""], ["Phang", "Jason", ""], ["Makino", "Taro", ""], ["Kim", "S. Gene", ""], ["Cho", "Kyunghyun", ""], ["Heacock", "Laura", ""], ["Moy", "Linda", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2009.09283", "submitter": "Kang Liu", "authors": "Kang Liu, Benjamin Tan, Siddharth Garg", "title": "Subverting Privacy-Preserving GANs: Hiding Secrets in Sanitized Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unprecedented data collection and sharing have exacerbated privacy concerns\nand led to increasing interest in privacy-preserving tools that remove\nsensitive attributes from images while maintaining useful information for other\ntasks. Currently, state-of-the-art approaches use privacy-preserving generative\nadversarial networks (PP-GANs) for this purpose, for instance, to enable\nreliable facial expression recognition without leaking users' identity.\nHowever, PP-GANs do not offer formal proofs of privacy and instead rely on\nexperimentally measuring information leakage using classification accuracy on\nthe sensitive attributes of deep learning (DL)-based discriminators. In this\nwork, we question the rigor of such checks by subverting existing\nprivacy-preserving GANs for facial expression recognition. We show that it is\npossible to hide the sensitive identification data in the sanitized output\nimages of such PP-GANs for later extraction, which can even allow for\nreconstruction of the entire input images, while satisfying privacy checks. We\ndemonstrate our approach via a PP-GAN-based architecture and provide\nqualitative and quantitative evaluations using two public datasets. Our\nexperimental results raise fundamental questions about the need for more\nrigorous privacy checks of PP-GANs, and we provide insights into the social\nimpact of these.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:02:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Garg", "Siddharth", ""]]}, {"id": "2009.09284", "submitter": "Mahdi Jafari Siavoshani", "authors": "Aida Ramezani, Amirhossein Khajehpour, Mahdi Jafari Siavoshani", "title": "On Multi-Session Website Fingerprinting over TLS Handshake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing users' Internet traffic data and activities has a certain impact on\nusers' experiences in different ways, from maintaining the quality of service\non the Internet and providing users with high-quality recommendation systems to\nanomaly detection and secure connection. Considering that the Internet is a\ncomplex network, we cannot disintegrate the packets for each activity.\nTherefore we have to have a model that can identify all the activities an\nInternet user does in a given period of time. In this paper, we propose a deep\nlearning approach to generate a multi-label classifier that can predict the\nwebsites visited by a user in a certain period. This model works by extracting\nthe server names appearing in chronological order in the TLSv1.2 and TLSv1.3\nClient Hello packets. We compare the results on the test data with a simple\nfully-connected neural network developed for the same purpose to prove that\nusing the time-sequential information improves the performance. For further\nevaluations, we test the model on a human-made dataset and a modified dataset\nto check the model's accuracy under different circumstances. Finally, our\nproposed model achieved an accuracy of 95% on the test dataset and above 90% on\nboth the modified dataset and the human-made dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:18:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramezani", "Aida", ""], ["Khajehpour", "Amirhossein", ""], ["Siavoshani", "Mahdi Jafari", ""]]}, {"id": "2009.09290", "submitter": "Gabriela Surita", "authors": "Gabriela Surita, Rodrigo Nogueira, Roberto Lotufo", "title": "Can questions summarize a corpus? Using question generation for\n  characterizing COVID-19 research", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the latent questions on some textual data? In this work, we\ninvestigate using question generation models for exploring a collection of\ndocuments. Our method, dubbed corpus2question, consists of applying a\npre-trained question generation model over a corpus and aggregating the\nresulting questions by frequency and time. This technique is an alternative to\nmethods such as topic modelling and word cloud for summarizing large amounts of\ntextual data. Results show that applying corpus2question on a corpus of\nscientific articles related to COVID-19 yields relevant questions about the\ntopic. The most frequent questions are \"what is covid 19\" and \"what is the\ntreatment for covid\". Among the 1000 most frequent questions are \"what is the\nthreshold for herd immunity\" and \"what is the role of ace2 in viral entry\". We\nshow that the proposed method generated similar questions for 13 of the 27\nexpert-made questions from the CovidQA question answering dataset.\n  The code to reproduce our experiments and the generated questions are\navailable at: https://github.com/unicamp-dl/corpus2question\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:57:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Surita", "Gabriela", ""], ["Nogueira", "Rodrigo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "2009.09300", "submitter": "Thyagharajan K K", "authors": "S. Kavitha, K.K. Thyagharajan", "title": "Features based Mammogram Image Classification using Weighted Feature\n  Support Vector Machine", "comments": "9 pages, 3 figures, \"submitted to International Conference on\n  Computing and Communication Systems\"", "journal-ref": "Vol. 270, 2012, 320-329", "doi": "10.1007/978-3-642-29216-3_35", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the existing research of mammogram image classification, either clinical\ndata or image features of a specific type is considered along with the\nsupervised classifiers such as Neural Network (NN) and Support Vector Machine\n(SVM). This paper considers automated classification of breast tissue type as\nbenign or malignant using Weighted Feature Support Vector Machine (WFSVM)\nthrough constructing the precomputed kernel function by assigning more weight\nto relevant features using the principle of maximizing deviations. Initially,\nMIAS dataset of mammogram images is divided into training and test set, then\nthe preprocessing techniques such as noise removal and background removal are\napplied to the input images and the Region of Interest (ROI) is identified. The\nstatistical features and texture features are extracted from the ROI and the\nclinical features are obtained directly from the dataset. The extracted\nfeatures of the training dataset are used to construct the weighted features\nand precomputed linear kernel for training the WFSVM, from which the training\nmodel file is created. Using this model file the kernel matrix of test samples\nis classified as benign or malignant. This analysis shows that the texture\nfeatures have resulted in better accuracy than the other features with WFSVM\nand SVM. However, the number of support vectors created in WFSVM is less than\nthe SVM classifier.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:28:31 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kavitha", "S.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.09304", "submitter": "Nikita Zhivotovskiy", "authors": "Tomas Va\\v{s}kevi\\v{c}ius and Nikita Zhivotovskiy", "title": "Suboptimality of Constrained Least Squares and Improvements via\n  Non-Linear Predictors", "comments": "37 pages, extended discussion, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of predicting as well as the best linear predictor in a\nbounded Euclidean ball with respect to the squared loss. When only boundedness\nof the data generating distribution is assumed, we establish that the least\nsquares estimator constrained to a bounded Euclidean ball does not attain the\nclassical $O(d/n)$ excess risk rate, where $d$ is the dimension of the\ncovariates and $n$ is the number of samples. In particular, we construct a\nbounded distribution such that the constrained least squares estimator incurs\nan excess risk of order $\\Omega(d^{3/2}/n)$ hence refuting a recent conjecture\nof Ohad Shamir [JMLR 2015]. In contrast, we observe that non-linear predictors\ncan achieve the optimal rate $O(d/n)$ with no assumptions on the distribution\nof the covariates. We discuss additional distributional assumptions sufficient\nto guarantee an $O(d/n)$ excess risk rate for the least squares estimator.\nAmong them are certain moment equivalence assumptions often used in the robust\nstatistics literature. While such assumptions are central in the analysis of\nunbounded and heavy-tailed settings, our work indicates that in some cases,\nthey also rule out unfavorable bounded distributions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:39:46 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:24:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2009.09318", "submitter": "Anian Ruoss", "authors": "Anian Ruoss, Maximilian Baader, Mislav Balunovi\\'c, Martin Vechev", "title": "Efficient Certification of Spatial Robustness", "comments": "Conference Paper at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has exposed the vulnerability of computer vision models to vector\nfield attacks. Due to the widespread usage of such models in safety-critical\napplications, it is crucial to quantify their robustness against such spatial\ntransformations. However, existing work only provides empirical robustness\nquantification against vector field deformations via adversarial attacks, which\nlack provable guarantees. In this work, we propose novel convex relaxations,\nenabling us, for the first time, to provide a certificate of robustness against\nvector field transformations. Our relaxations are model-agnostic and can be\nleveraged by a wide range of neural network verifiers. Experiments on various\nnetwork architectures and different datasets demonstrate the effectiveness and\nscalability of our method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 23:09:11 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:24:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ruoss", "Anian", ""], ["Baader", "Maximilian", ""], ["Balunovi\u0107", "Mislav", ""], ["Vechev", "Martin", ""]]}, {"id": "2009.09321", "submitter": "Vincent Lostanlen", "authors": "Christopher Ick and Vincent Lostanlen", "title": "Learning a Lie Algebra from Unlabeled Data Pairs", "comments": "2 pages, 1 figure. Presented at the first DeepMath conference, New\n  York City, NY, USA, November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional networks (convnets) show a remarkable ability to learn\ndisentangled representations. In recent years, the generalization of deep\nlearning to Lie groups beyond rigid motion in $\\mathbb{R}^n$ has allowed to\nbuild convnets over datasets with non-trivial symmetries, such as patterns over\nthe surface of a sphere. However, one limitation of this approach is the need\nto explicitly define the Lie group underlying the desired invariance property\nbefore training the convnet. Whereas rotations on the sphere have a well-known\nsymmetry group ($\\mathrm{SO}(3)$), the same cannot be said of many real-world\nfactors of variability. For example, the disentanglement of pitch, intensity\ndynamics, and playing technique remains a challenging task in music information\nretrieval.\n  This article proposes a machine learning method to discover a nonlinear\ntransformation of the space $\\mathbb{R}^n$ which maps a collection of\n$n$-dimensional vectors $(\\boldsymbol{x}_i)_i$ onto a collection of target\nvectors $(\\boldsymbol{y}_i)_i$. The key idea is to approximate every target\n$\\boldsymbol{y}_i$ by a matrix--vector product of the form\n$\\boldsymbol{\\widetilde{y}}_i = \\boldsymbol{\\phi}(t_i) \\boldsymbol{x}_i$, where\nthe matrix $\\boldsymbol{\\phi}(t_i)$ belongs to a one-parameter subgroup of\n$\\mathrm{GL}_n (\\mathbb{R})$. Crucially, the value of the parameter $t_i \\in\n\\mathbb{R}$ may change between data pairs $(\\boldsymbol{x}_i,\n\\boldsymbol{y}_i)$ and does not need to be known in advance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 23:23:52 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 02:08:00 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 09:29:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ick", "Christopher", ""], ["Lostanlen", "Vincent", ""]]}, {"id": "2009.09326", "submitter": "Nicolas Araque", "authors": "Nicolas Araque, Germano Rojas, Maria Vitali", "title": "UniNet: Next Term Course Recommendation using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICACSIS51025.2020.9263144", "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Course enrollment recommendation is a relevant task that helps university\nstudents decide what is the best combination of courses to enroll in the next\nterm. In particular, recommender system techniques like matrix factorization\nand collaborative filtering have been developed to try to solve this problem.\nAs these techniques fail to represent the time-dependent nature of academic\nperformance datasets we propose a deep learning approach using recurrent neural\nnetworks that aims to better represent how chronological order of course grades\naffects the probability of success. We have shown that it is possible to obtain\na performance of 81.10% on AUC metric using only grade information and that it\nis possible to develop a recommender system with academic student performance\nprediction. This is shown to be meaningful across different student GPA levels\nand course difficulties\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 00:07:45 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Araque", "Nicolas", ""], ["Rojas", "Germano", ""], ["Vitali", "Maria", ""]]}, {"id": "2009.09341", "submitter": "Justin Terry", "authors": "Justin K. Terry, Benjamin Black, Luis Santos", "title": "Multiplayer Support for the Arcade Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arcade Learning Environment (\"ALE\") is a widely used library in the\nreinforcement learning community that allows easy programmatic interfacing with\nAtari 2600 games, via the Stella emulator. We introduce a publicly available\nextension to the ALE that extends its support to multiplayer games and game\nmodes. This interface is additionally integrated with PettingZoo to allow for a\nsimple Gym-like interface in Python to interact with these games. We\nadditionally introduce experimental baselines for all environments included.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:19:12 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 22:21:57 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Terry", "Justin K.", ""], ["Black", "Benjamin", ""], ["Santos", "Luis", ""]]}, {"id": "2009.09346", "submitter": "Michael Poli", "authors": "Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama,\n  Jinkyoo Park", "title": "TorchDyn: A Neural Differential Equations Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-depth learning has recently emerged as a novel perspective on deep\nlearning, improving performance in tasks related to dynamical systems and\ndensity estimation. Core to these approaches is the neural differential\nequation, whose forward passes are the solutions of an initial value problem\nparametrized by a neural network. Unlocking the full potential of\ncontinuous-depth models requires a different set of software tools, due to\npeculiar differences compared to standard discrete neural networks, e.g\ninference must be carried out via numerical solvers. We introduce TorchDyn, a\nPyTorch library dedicated to continuous-depth learning, designed to elevate\nneural differential equations to be as accessible as regular plug-and-play deep\nlearning primitives. This objective is achieved by identifying and subdividing\ndifferent variants into common essential components, which can be combined and\nfreely repurposed to obtain complex compositional architectures. TorchDyn\nfurther offers step-by-step tutorials and benchmarks designed to guide\nresearchers and contributors.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:45:49 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2009.09347", "submitter": "Zhecheng Wang", "authors": "Mingxiang Chen, Qichang Chen, Lei Gao, Yilin Chen, Zhecheng Wang", "title": "Predicting Geographic Information with Neural Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework using neural cellular automata (NCA) to\nregenerate and predict geographic information. The model extends the idea of\nusing NCA to generate/regenerate a specific image by training the model with\nvarious geographic data, and thus, taking the traffic condition map as an\nexample, the model is able to predict traffic conditions by giving certain\ninduction information. Our research verified the analogy between NCA and gene\nin biology, while the innovation of the model significantly widens the boundary\nof possible applications based on NCAs. From our experimental results, the\nmodel shows great potentials in its usability and versatility which are not\navailable in previous studies. The code for model implementation is available\nat https://redacted.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:53:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Mingxiang", ""], ["Chen", "Qichang", ""], ["Gao", "Lei", ""], ["Chen", "Yilin", ""], ["Wang", "Zhecheng", ""]]}, {"id": "2009.09358", "submitter": "Egor Klevak", "authors": "Egor Klevak and Sangdi Lin and Andy Martin and Ondrej Linda and Eric\n  Ringger", "title": "Out-Of-Bag Anomaly Detection", "comments": "13 pages, 4 figures, KDD 2020 TrueFact Workshop: Making a Credible\n  Web for Tomorrow", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data anomalies are ubiquitous in real world datasets, and can have an adverse\nimpact on machine learning (ML) systems, such as automated home valuation.\nDetecting anomalies could make ML applications more responsible and\ntrustworthy. However, the lack of labels for anomalies and the complex nature\nof real-world datasets make anomaly detection a challenging unsupervised\nlearning problem. In this paper, we propose a novel model-based anomaly\ndetection method, that we call Out-of- Bag anomaly detection, which handles\nmulti-dimensional datasets consisting of numerical and categorical features.\nThe proposed method decomposes the unsupervised problem into the training of a\nset of ensemble models. Out-of-Bag estimates are leveraged to derive an\neffective measure for anomaly detection. We not only demonstrate the\nstate-of-the-art performance of our method through comprehensive experiments on\nbenchmark datasets, but also show our model can improve the accuracy and\nreliability of an ML system as data pre-processing step via a case study on\nhome valuation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:01:52 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Klevak", "Egor", ""], ["Lin", "Sangdi", ""], ["Martin", "Andy", ""], ["Linda", "Ondrej", ""], ["Ringger", "Eric", ""]]}, {"id": "2009.09361", "submitter": "Wei Pan", "authors": "Qingrui Zhang, Hao Dong, Wei Pan", "title": "Lyapunov-Based Reinforcement Learning for Decentralized Multi-Agent\n  Control", "comments": "Accepted to The 2nd International Conference on Distributed\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decentralized multi-agent control has broad applications, ranging from\nmulti-robot cooperation to distributed sensor networks. In decentralized\nmulti-agent control, systems are complex with unknown or highly uncertain\ndynamics, where traditional model-based control methods can hardly be applied.\nCompared with model-based control in control theory, deep reinforcement\nlearning (DRL) is promising to learn the controller/policy from data without\nthe knowing system dynamics. However, to directly apply DRL to decentralized\nmulti-agent control is challenging, as interactions among agents make the\nlearning environment non-stationary. More importantly, the existing multi-agent\nreinforcement learning (MARL) algorithms cannot ensure the closed-loop\nstability of a multi-agent system from a control-theoretic perspective, so the\nlearned control polices are highly possible to generate abnormal or dangerous\nbehaviors in real applications. Hence, without stability guarantee, the\napplication of the existing MARL algorithms to real multi-agent systems is of\ngreat concern, e.g., UAVs, robots, and power systems, etc. In this paper, we\naim to propose a new MARL algorithm for decentralized multi-agent control with\na stability guarantee. The new MARL algorithm, termed as a multi-agent\nsoft-actor critic (MASAC), is proposed under the well-known framework of\n\"centralized-training-with-decentralized-execution\". The closed-loop stability\nis guaranteed by the introduction of a stability constraint during the policy\nimprovement in our MASAC algorithm. The stability constraint is designed based\non Lyapunov's method in control theory. To demonstrate the effectiveness, we\npresent a multi-agent navigation example to show the efficiency of the proposed\nMASAC algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:11:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhang", "Qingrui", ""], ["Dong", "Hao", ""], ["Pan", "Wei", ""]]}, {"id": "2009.09364", "submitter": "Bang An", "authors": "Bang An, Jie Lyu, Zhenyi Wang, Chunyuan Li, Changwei Hu, Fei Tan,\n  Ruiyi Zhang, Yifan Hu, Changyou Chen", "title": "Repulsive Attention: Rethinking Multi-head Attention as Bayesian\n  Inference", "comments": "accepted by EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural attention mechanism plays an important role in many natural\nlanguage processing applications. In particular, the use of multi-head\nattention extends single-head attention by allowing a model to jointly attend\ninformation from different perspectives. Without explicit constraining,\nhowever, multi-head attention may suffer from attention collapse, an issue that\nmakes different heads extract similar attentive features, thus limiting the\nmodel's representation power. In this paper, for the first time, we provide a\nnovel understanding of multi-head attention from a Bayesian perspective. Based\non the recently developed particle-optimization sampling techniques, we propose\na non-parametric approach that explicitly improves the repulsiveness in\nmulti-head attention and consequently strengthens model's expressiveness.\nRemarkably, our Bayesian interpretation provides theoretical inspirations on\nthe not-well-understood questions: why and how one uses multi-head attention.\nExtensive experiments on various attention models and applications demonstrate\nthat the proposed repulsive attention can improve the learned feature\ndiversity, leading to more informative representations with consistent\nperformance improvement on various tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:32:23 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:22:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["An", "Bang", ""], ["Lyu", "Jie", ""], ["Wang", "Zhenyi", ""], ["Li", "Chunyuan", ""], ["Hu", "Changwei", ""], ["Tan", "Fei", ""], ["Zhang", "Ruiyi", ""], ["Hu", "Yifan", ""], ["Chen", "Changyou", ""]]}, {"id": "2009.09371", "submitter": "Takayuki Nishio", "authors": "Takayuki Nishio, Ryoichi Shinkuma, Narayan B. Mandayam", "title": "Estimation of Individual Device Contributions for Incentivizing\n  Federated Learning", "comments": "Submitted to IEEE Globecom Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging technique used to train a\nmachine-learning model collaboratively using the data and computation resource\nof the mobile devices without exposing privacy-sensitive user data.\n  Appropriate incentive mechanisms that motivate the data and mobile-device\nowner to participate in FL is key to building a sustainable platform for FL.\nHowever, it is difficult to evaluate the contribution level of the\ndevices/owners to determine appropriate rewards without large computation and\ncommunication overhead.\n  This paper proposes a computation-and communication-efficient method of\nestimating a participating device's contribution level. The proposed method\nenables such estimation during a single FL training process, there by reducing\nthe need for traffic and computation overhead. The performance evaluations\nusing the MNIST dataset show that the proposed method estimates individual\nparticipants' contributions accurately with 46-49% less computation overhead\nand no communication overhead than a naive estimation method.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:03:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nishio", "Takayuki", ""], ["Shinkuma", "Ryoichi", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "2009.09379", "submitter": "Leye Wang", "authors": "Leye Wang, Di Chai, Xuanzhe Liu, Liyue Chen, Kai Chen", "title": "Exploring the Generalizability of Spatio-Temporal Crowd Flow Prediction:\n  Meta-Modeling and an Analytic Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Spatio-Temporal Crowd Flow Prediction (STCFP) problem is a classical\nproblem with plenty of prior research efforts that benefit from traditional\nstatistical learning and recent deep learning approaches. While STCFP can refer\nto many real-world problems, most existing studies focus on quite specific\napplications, such as the prediction of taxi demand, ridesharing order, and so\non. This hinders the STCFP research as the approaches designed for different\napplications are hardly comparable, and thus how an applicationdriven approach\ncan be generalized to other scenarios is unclear. To fill in this gap, this\npaper makes two efforts: (i) we propose an analytic framework, called\nSTAnalytic, to qualitatively investigate STCFP approaches regarding their\ndesign considerations on various spatial and temporal factors, aiming to make\ndifferent application-driven approaches comparable; (ii) we construct an\nextensively large-scale STCFP benchmark datasets with four different scenarios\n(including ridesharing, bikesharing, metro, and electrical vehicle charging)\nwith up to hundreds of millions of flow records, to quantitatively measure the\ngeneralizability of STCFP approaches. Furthermore, to elaborate the\neffectiveness of STAnalytic in helping design generalizable STCFP approaches,\nwe propose a spatio-temporal meta-model, called STMeta, by integrating\ngeneralizable temporal and spatial knowledge identified by STAnalytic. We\nimplement three variants of STMeta with different deep learning techniques.\nWith the datasets, we demonstrate that STMeta variants can outperform\nstate-of-the-art STCFP approaches by 5%.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:50:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Leye", ""], ["Chai", "Di", ""], ["Liu", "Xuanzhe", ""], ["Chen", "Liyue", ""], ["Chen", "Kai", ""]]}, {"id": "2009.09380", "submitter": "Chongwen Huang", "authors": "Chongwen Huang, Zhaohui Yang, George C. Alexandropoulos, Kai Xiong, Li\n  Wei, Chau Yuen, and Zhaoyang Zhang", "title": "Hybrid Beamforming for RIS-Empowered Multi-hop Terahertz Communications:\n  A DRL-based Method", "comments": "Accepted by 2020 GLOBECOM Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless communication in the TeraHertz band (0.1--10 THz) is envisioned as\none of the key enabling technologies for the future six generation (6G)\nwireless communication systems. However, very high propagation attenuations and\nmolecular absorptions of THz frequencies often limit the signal transmission\ndistance and coverage range. Benefited from the recent breakthrough on the\nreconfigurable intelligent surfaces (RIS) for realizing smart radio propagation\nenvironment, we propose a novel hybrid beamforming scheme for the multi-hop\nRIS-assisted communication networks to improve the coverage range at THz-band\nfrequencies. We investigate the joint design of digital beamforming matrix at\nthe BS and analog beamforming matrices at the RISs, by leveraging the recent\nadvances in deep reinforcement learning (DRL) to combat the propagation loss.\nSimulation results show that our proposed scheme is able to improve 50\\% more\ncoverage range of THz communications compared with the benchmarks. Furthermore,\nit is also shown that our proposed DRL-based method is a state-of-the-art\nmethod to solve the NP-bard beamforming problem, especially when the signals at\nRIS-empowered THz communication networks experience multiple hops.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:51:49 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Huang", "Chongwen", ""], ["Yang", "Zhaohui", ""], ["Alexandropoulos", "George C.", ""], ["Xiong", "Kai", ""], ["Wei", "Li", ""], ["Yuen", "Chau", ""], ["Zhang", "Zhaoyang", ""]]}, {"id": "2009.09382", "submitter": "Lukasz Korycki", "authors": "{\\L}ukasz Korycki and Bartosz Krawczyk", "title": "Instance exploitation for learning temporary concepts from sparsely\n  labeled drifting data streams", "comments": "35 pages, 17 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning from streaming data sources becomes more and more popular\ndue to the increasing number of online tools and systems. Dealing with dynamic\nand everlasting problems poses new challenges for which traditional batch-based\noffline algorithms turn out to be insufficient in terms of computational time\nand predictive performance. One of the most crucial limitations is that we\ncannot assume having access to a finite and complete data set - we always have\nto be ready for new data that may complement our model. This poses a critical\nproblem of providing labels for potentially unbounded streams. In the real\nworld, we are forced to deal with very strict budget limitations, therefore, we\nwill most likely face the scarcity of annotated instances, which are essential\nin supervised learning. In our work, we emphasize this problem and propose a\nnovel instance exploitation technique. We show that when: (i) data is\ncharacterized by temporary non-stationary concepts, and (ii) there are very few\nlabels spanned across a long time horizon, it is actually better to risk\noverfitting and adapt models more aggressively by exploiting the only labeled\ninstances we have, instead of sticking to a standard learning mode and\nsuffering from severe underfitting. We present different strategies and\nconfigurations for our methods, as well as an ensemble algorithm that attempts\nto maintain a sweet spot between risky and normal adaptation. Finally, we\nconduct a complex in-depth comparative analysis of our methods, using\nstate-of-the-art streaming algorithms relevant to the given problem.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 08:11:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Korycki", "\u0141ukasz", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2009.09384", "submitter": "Matthias Treder", "authors": "Matthias S. Treder, Juan Mayor-Torres, Christoph Teufel", "title": "Deriving Visual Semantics from Spatial Context: An Adaptation of LSA and\n  Word2Vec to generate Object and Scene Embeddings from Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings are an important tool for the representation of word meaning.\nTheir effectiveness rests on the distributional hypothesis: words that occur in\nthe same context carry similar semantic information. Here, we adapt this\napproach to index visual semantics in images of scenes. To this end, we\nformulate a distributional hypothesis for objects and scenes: Scenes that\ncontain the same objects (object context) are semantically related. Similarly,\nobjects that appear in the same spatial context (within a scene or subregions\nof a scene) are semantically related. We develop two approaches for learning\nobject and scene embeddings from annotated images. In the first approach, we\nadapt LSA and Word2vec's Skipgram and CBOW models to generate two sets of\nembeddings from object co-occurrences in whole images, one for objects and one\nfor scenes. The representational space spanned by these embeddings suggests\nthat the distributional hypothesis holds for images. In an initial application\nof this approach, we show that our image-based embeddings improve scene\nclassification models such as ResNet18 and VGG-11 (3.72\\% improvement on Top5\naccuracy, 4.56\\% improvement on Top1 accuracy). In the second approach, rather\nthan analyzing whole images of scenes, we focus on co-occurrences of objects\nwithin subregions of an image. We illustrate that this method yields a sensible\nhierarchical decomposition of a scene into collections of semantically related\nobjects. Overall, these results suggest that object and scene embeddings from\nobject co-occurrences and spatial context yield semantically meaningful\nrepresentations as well as computational improvements for downstream\napplications such as scene classification.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 08:26:38 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Treder", "Matthias S.", ""], ["Mayor-Torres", "Juan", ""], ["Teufel", "Christoph", ""]]}, {"id": "2009.09386", "submitter": "Yunxia Lin", "authors": "Yunxia Lin, Songcan Chen", "title": "Convex Subspace Clustering by Adaptive Block Diagonal Representation", "comments": "13 pages, 11 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering is a class of extensively studied clustering methods and\nthe spectral-type approaches are its important subclass whose key first step is\nto learn a coefficient matrix with block diagonal structure. To realize this\nstep, sparse subspace clustering (SSC), low rank representation (LRR) and block\ndiagonal representation (BDR) were successively proposed and have become the\nstate-of-the-arts (SOTAs). Among them, the former two minimize their convex\nobjectives by imposing sparsity and low rankness on the coefficient matrix\nrespectively, but so-desired block diagonality cannot neccesarily be guaranteed\npractically while the latter designs a block diagonal matrix induced\nregularizer but sacrifices convexity. For solving this dilemma, inspired by\nConvex Biclustering, in this paper, we propose a simple yet efficient\nspectral-type subspace clustering method named Adaptive Block Diagonal\nRepresentation (ABDR) which strives to pursue so-desired block diagonality as\nBDR by coercively fusing the columns/rows of the coefficient matrix via a\nspecially designed convex regularizer, consequently, ABDR naturally enjoys\ntheir merits and can adaptively form more desired block diagonality than the\nSOTAs without needing to prefix the number of blocks as done in BDR. Finally,\nexperimental results on synthetic and real benchmarks demonstrate the\nsuperiority of ABDR.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 08:31:43 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 13:10:47 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lin", "Yunxia", ""], ["Chen", "Songcan", ""]]}, {"id": "2009.09417", "submitter": "Byung-Ju Choi", "authors": "Byung-Ju Choi, Jimin Hong, David Keetae Park, Sang Wan Lee", "title": "F^2-Softmax: Diversifying Neural Text Generation via Frequency\n  Factorized Softmax", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in neural text generation, encoding the rich\ndiversity in human language remains elusive. We argue that the sub-optimal text\ngeneration is mainly attributable to the imbalanced token distribution, which\nparticularly misdirects the learning model when trained with the\nmaximum-likelihood objective. As a simple yet effective remedy, we propose two\nnovel methods, F^2-Softmax and MefMax, for a balanced training even with the\nskewed frequency distribution. MefMax assigns tokens uniquely to frequency\nclasses, trying to group tokens with similar frequencies and equalize frequency\nmass between the classes. F^2-Softmax then decomposes a probability\ndistribution of the target token into a product of two conditional\nprobabilities of (i) frequency class, and (ii) token from the target frequency\nclass. Models learn more uniform probability distributions because they are\nconfined to subsets of vocabularies. Significant performance gains on seven\nrelevant metrics suggest the supremacy of our approach in improving not only\nthe diversity but also the quality of generated texts.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 12:03:58 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 08:46:58 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Choi", "Byung-Ju", ""], ["Hong", "Jimin", ""], ["Park", "David Keetae", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2009.09422", "submitter": "Alfredo Braunstein", "authors": "Antoine Baker, Indaco Biazzo, Alfredo Braunstein, Giovanni Catania,\n  Luca Dall'Asta, Alessandro Ingrosso, Florent Krzakala, Fabio Mazza, Marc\n  M\\'ezard, Anna Paola Muntoni, Maria Refinetti, Stefano Sarao Mannelli, Lenka\n  Zdeborov\\'a", "title": "Epidemic mitigation by statistical inference from contact tracing data", "comments": "21 pages, 7 figures", "journal-ref": "PNAS 2021 Vol. 118 No. 32 e2106548118", "doi": "10.1073/pnas.2106548118", "report-no": null, "categories": "q-bio.PE cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact-tracing is an essential tool in order to mitigate the impact of\npandemic such as the COVID-19. In order to achieve efficient and scalable\ncontact-tracing in real time, digital devices can play an important role. While\na lot of attention has been paid to analyzing the privacy and ethical risks of\nthe associated mobile applications, so far much less research has been devoted\nto optimizing their performance and assessing their impact on the mitigation of\nthe epidemic. We develop Bayesian inference methods to estimate the risk that\nan individual is infected. This inference is based on the list of his recent\ncontacts and their own risk levels, as well as personal information such as\nresults of tests or presence of syndromes. We propose to use probabilistic risk\nestimation in order to optimize testing and quarantining strategies for the\ncontrol of an epidemic. Our results show that in some range of epidemic\nspreading (typically when the manual tracing of all contacts of infected people\nbecomes practically impossible, but before the fraction of infected people\nreaches the scale where a lock-down becomes unavoidable), this inference of\nindividuals at risk could be an efficient way to mitigate the epidemic. Our\napproaches translate into fully distributed algorithms that only require\ncommunication between individuals who have recently been in contact. Such\ncommunication may be encrypted and anonymized and thus compatible with privacy\npreserving standards. We conclude that probabilistic risk estimation is capable\nto enhance performance of digital contact tracing and should be considered in\nthe currently developed mobile applications.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 12:24:45 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Baker", "Antoine", ""], ["Biazzo", "Indaco", ""], ["Braunstein", "Alfredo", ""], ["Catania", "Giovanni", ""], ["Dall'Asta", "Luca", ""], ["Ingrosso", "Alessandro", ""], ["Krzakala", "Florent", ""], ["Mazza", "Fabio", ""], ["M\u00e9zard", "Marc", ""], ["Muntoni", "Anna Paola", ""], ["Refinetti", "Maria", ""], ["Mannelli", "Stefano Sarao", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2009.09435", "submitter": "Francisco Vargas", "authors": "Francisco Vargas and Ryan Cotterell", "title": "Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation", "comments": null, "journal-ref": "Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bolukbasi et al. (2016) presents one of the first gender bias mitigation\ntechniques for word embeddings. Their method takes pre-trained word embeddings\nas input and attempts to isolate a linear subspace that captures most of the\ngender bias in the embeddings. As judged by an analogical evaluation task,\ntheir method virtually eliminates gender bias in the embeddings. However, an\nimplicit and untested assumption of their method is that the bias sub-space is\nactually linear. In this work, we generalize their method to a kernelized,\nnon-linear version. We take inspiration from kernel principal component\nanalysis and derive a non-linear bias isolation technique. We discuss and\novercome some of the practical drawbacks of our method for non-linear gender\nbias mitigation in word embeddings and analyze empirically whether the bias\nsubspace is actually linear. Our analysis shows that gender bias is in fact\nwell captured by a linear subspace, justifying the assumption of Bolukbasi et\nal. (2016).\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:13:45 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:11:40 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Vargas", "Francisco", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2009.09439", "submitter": "Hlynur Dav{\\i}{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Merlin Sch\\\"uler, Robin Schiewer, Tobias\n  Glasmachers, Laurenz Wiskott", "title": "Latent Representation Prediction Networks", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deeply-learned planning methods are often based on learning representations\nthat are optimized for unrelated tasks. For example, they might be trained on\nreconstructing the environment. These representations are then combined with\npredictor functions for simulating rollouts to navigate the environment. We\nfind this principle of learning representations unsatisfying and propose to\nlearn them such that they are directly optimized for the task at hand: to be\nmaximally predictable for the predictor function. This results in\nrepresentations that are by design optimal for the downstream task of planning,\nwhere the learned predictor function is used as a forward model.\n  To this end, we propose a new way of jointly learning this representation\nalong with the prediction function, a system we dub Latent Representation\nPrediction Network (LARP). The prediction function is used as a forward model\nfor search on a graph in a viewpoint-matching task and the representation\nlearned to maximize predictability is found to outperform a pre-trained\nrepresentation. Our approach is shown to be more sample-efficient than standard\nreinforcement learning methods and our learned representation transfers\nsuccessfully to dissimilar objects.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:26:03 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 13:42:06 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Sch\u00fcler", "Merlin", ""], ["Schiewer", "Robin", ""], ["Glasmachers", "Tobias", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "2009.09443", "submitter": "Duc Nguyen", "authors": "Duc Nguyen, Phuoc Nguyen, Kien Do, Santu Rana, Sunil Gupta, Truyen\n  Tran", "title": "Unsupervised Anomaly Detection on Temporal Multiway Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal anomaly detection looks for irregularities over space-time.\nUnsupervised temporal models employed thus far typically work on sequences of\nfeature vectors, and much less on temporal multiway data. We focus our\ninvestigation on two-way data, in which a data matrix is observed at each time\nstep. Leveraging recent advances in matrix-native recurrent neural networks, we\ninvestigated strategies for data arrangement and unsupervised training for\ntemporal multiway anomaly detection. These include compressing-decompressing,\nencoding-predicting, and temporal data differencing. We conducted a\ncomprehensive suite of experiments to evaluate model behaviors under various\nsettings on synthetic data, moving digits, and ECG recordings. We found\ninteresting phenomena not previously reported. These include the capacity of\nthe compact matrix LSTM to compress noisy data near perfectly, making the\nstrategy of compressing-decompressing data ill-suited for anomaly detection\nunder the noise. Also, long sequence of vectors can be addressed directly by\nmatrix models that allow very long context and multiple step prediction.\nOverall, the encoding-predicting strategy works very well for the matrix LSTMs\nin the conducted experiments, thanks to its compactness and better fit to the\ndata dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:49:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nguyen", "Duc", ""], ["Nguyen", "Phuoc", ""], ["Do", "Kien", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Tran", "Truyen", ""]]}, {"id": "2009.09457", "submitter": "Patrick Kidger", "authors": "Patrick Kidger and Ricky T. Q. Chen and Terry Lyons", "title": "\"Hey, that's not an ODE\": Faster ODE Adjoints via Seminorms", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural differential equations may be trained by backpropagating gradients via\nthe adjoint method, which is another differential equation typically solved\nusing an adaptive-step-size numerical differential equation solver. A proposed\nstep is accepted if its error, \\emph{relative to some norm}, is sufficiently\nsmall; else it is rejected, the step is shrunk, and the process is repeated.\nHere, we demonstrate that the particular structure of the adjoint equations\nmakes the usual choices of norm (such as $L^2$) unnecessarily stringent. By\nreplacing it with a more appropriate (semi)norm, fewer steps are unnecessarily\nrejected and the backpropagation is made faster. This requires only minor code\nmodifications. Experiments on a wide range of tasks -- including time series,\ngenerative modeling, and physical control -- demonstrate a median improvement\nof 40% fewer function evaluations. On some problems we see as much as 62% fewer\nfunction evaluations, so that the overall training time is roughly halved.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 15:42:32 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 12:37:42 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kidger", "Patrick", ""], ["Chen", "Ricky T. Q.", ""], ["Lyons", "Terry", ""]]}, {"id": "2009.09463", "submitter": "Yue Zhao", "authors": "Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, Xiyang Hu", "title": "COPOD: Copula-Based Outlier Detection", "comments": "Proceedings of the 2020 International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection refers to the identification of rare items that are deviant\nfrom the general data distribution. Existing approaches suffer from high\ncomputational complexity, low predictive capability, and limited\ninterpretability. As a remedy, we present a novel outlier detection algorithm\ncalled COPOD, which is inspired by copulas for modeling multivariate data\ndistribution. COPOD first constructs an empirical copula, and then uses it to\npredict tail probabilities of each given data point to determine its level of\n\"extremeness\". Intuitively, we think of this as calculating an anomalous\np-value. This makes COPOD both parameter-free, highly interpretable, and\ncomputationally efficient. In this work, we make three key contributions, 1)\npropose a novel, parameter-free outlier detection algorithm with both great\nperformance and interpretability, 2) perform extensive experiments on 30\nbenchmark datasets to show that COPOD outperforms in most cases and is also one\nof the fastest algorithms, and 3) release an easy-to-use Python implementation\nfor reproducibility.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:06:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Zheng", ""], ["Zhao", "Yue", ""], ["Botta", "Nicola", ""], ["Ionescu", "Cezar", ""], ["Hu", "Xiyang", ""]]}, {"id": "2009.09467", "submitter": "Rohit Jena", "authors": "Rohit Jena, Siddharth Agrawal, Katia Sycara", "title": "Addressing reward bias in Adversarial Imitation Learning with neutral\n  reward functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Imitation Learning suffers from the fundamental\nproblem of reward bias stemming from the choice of reward functions used in the\nalgorithm. Different types of biases also affect different types of\nenvironments - which are broadly divided into survival and task-based\nenvironments. We provide a theoretical sketch of why existing reward functions\nwould fail in imitation learning scenarios in task based environments with\nmultiple terminal states. We also propose a new reward function for GAIL which\noutperforms existing GAIL methods on task based environments with single and\nmultiple terminal states and effectively overcomes both survival and\ntermination bias.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:24:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jena", "Rohit", ""], ["Agrawal", "Siddharth", ""], ["Sycara", "Katia", ""]]}, {"id": "2009.09468", "submitter": "Mason Del Rosario", "authors": "Zhenyu Liu, Mason del Rosario, and Zhi Ding", "title": "A Markovian Model-Driven Deep Learning Framework for Massive MIMO CSI\n  Feedback", "comments": "14 pages, 14 figures, 4 tables. Submitted to IEEE Transactions on\n  Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forward channel state information (CSI) often plays a vital role in\nscheduling and capacity-approaching transmission optimization for massive\nmultiple-input multiple-output (MIMO) communication systems. In frequency\ndivision duplex (FDD) massive MIMO systems, forwardlink CSI reconstruction at\nthe transmitter relies critically on CSI feedback from receiving nodes and must\ncarefully weigh the tradeoff between reconstruction accuracy and feedback\nbandwidth. Recent studies on the use of recurrent neural networks (RNNs) have\ndemonstrated strong promises, though the cost of computation and memory remains\nhigh, for massive MIMO deployment. In this work, we exploit channel coherence\nin time to substantially improve the feedback efficiency. Using a Markovian\nmodel, we develop a deep convolutional neural network (CNN)-based framework\nMarkovNet to differentially encode forward CSI in time to effectively improve\nreconstruction accuracy. Furthermore, we explore important physical insights,\nincluding spherical normalization of input data and convolutional layers for\nfeedback compression. We demonstrate substantial performance improvement and\ncomplexity reduction over the RNN-based work by our proposed MarkovNet to\nrecover forward CSI estimates accurately. We explore additional practical\nconsideration in feedback quantization, and show that MarkovNet outperforms\nRNN-based CSI estimation networks at a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:26:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Zhenyu", ""], ["del Rosario", "Mason", ""], ["Ding", "Zhi", ""]]}, {"id": "2009.09471", "submitter": "Yue Zhao", "authors": "Zheng Li, Yue Zhao, Jialin Fu", "title": "SYNC: A Copula based Framework for Generating Synthetic Data from\n  Aggregated Sources", "comments": "Proceedings of the 2020 IEEE International Conference on Data Mining\n  Workshops (ICDMW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A synthetic dataset is a data object that is generated programmatically, and\nit may be valuable to creating a single dataset from multiple sources when\ndirect collection is difficult or costly. Although it is a fundamental step for\nmany data science tasks, an efficient and standard framework is absent. In this\npaper, we study a specific synthetic data generation task called downscaling, a\nprocedure to infer high-resolution, harder-to-collect information (e.g.,\nindividual level records) from many low-resolution, easy-to-collect sources,\nand propose a multi-stage framework called SYNC (Synthetic Data Generation via\nGaussian Copula). For given low-resolution datasets, the central idea of SYNC\nis to fit Gaussian copula models to each of the low-resolution datasets in\norder to correctly capture dependencies and marginal distributions, and then\nsample from the fitted models to obtain the desired high-resolution subsets.\nPredictive models are then used to merge sampled subsets into one, and finally,\nsampled datasets are scaled according to low-resolution marginal constraints.\nWe make four key contributions in this work: 1) propose a novel framework for\ngenerating individual level data from aggregated data sources by combining\nstate-of-the-art machine learning and statistical techniques, 2) perform\nsimulation studies to validate SYNC's performance as a synthetic data\ngeneration algorithm, 3) demonstrate its value as a feature engineering tool,\nas well as an alternative to data collection in situations where gathering is\ndifficult through two real-world datasets, 4) release an easy-to-use framework\nimplementation for reproducibility and scalability at the production level that\neasily incorporates new data.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:36:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Zheng", ""], ["Zhao", "Yue", ""], ["Fu", "Jialin", ""]]}, {"id": "2009.09474", "submitter": "Ehsan Doostmohammadi", "authors": "Ehsan Doostmohammadi, Minoo Nassajian, Adel Rahimi", "title": "Persian Ezafe Recognition Using Transformers and Its Role in\n  Part-Of-Speech Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ezafe is a grammatical particle in some Iranian languages that links two\nwords together. Regardless of the important information it conveys, it is\nalmost always not indicated in Persian script, resulting in mistakes in reading\ncomplex sentences and errors in natural language processing tasks. In this\npaper, we experiment with different machine learning methods to achieve\nstate-of-the-art results in the task of ezafe recognition. Transformer-based\nmethods, BERT and XLMRoBERTa, achieve the best results, the latter achieving\n2.68% F1-score more than the previous state-of-the-art. We, moreover, use ezafe\ninformation to improve Persian part-of-speech tagging results and show that\nsuch information will not be useful to transformer-based methods and explain\nwhy that might be the case.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 17:01:43 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 19:52:11 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Doostmohammadi", "Ehsan", ""], ["Nassajian", "Minoo", ""], ["Rahimi", "Adel", ""]]}, {"id": "2009.09496", "submitter": "Nidhi Kaushik Vyas", "authors": "Nidhi Vyas, Shreyas Saxena, Thomas Voice", "title": "Learning Soft Labels via Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-hot labels do not represent soft decision boundaries among concepts, and\nhence, models trained on them are prone to overfitting. Using soft labels as\ntargets provide regularization, but different soft labels might be optimal at\ndifferent stages of optimization. Also, training with fixed labels in the\npresence of noisy annotations leads to worse generalization. To address these\nlimitations, we propose a framework, where we treat the labels as learnable\nparameters, and optimize them along with model parameters. The learned labels\ncontinuously adapt themselves to the model's state, thereby providing dynamic\nregularization. When applied to the task of supervised image-classification,\nour method leads to consistent gains across different datasets and\narchitectures. For instance, dynamically learned labels improve ResNet18 by\n2.1% on CIFAR100. When applied to dataset containing noisy labels, the learned\nlabels correct the annotation mistakes, and improves over state-of-the-art by a\nsignificant margin. Finally, we show that learned labels capture semantic\nrelationship between classes, and thereby improve teacher models for the\ndownstream task of distillation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 18:42:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Vyas", "Nidhi", ""], ["Saxena", "Shreyas", ""], ["Voice", "Thomas", ""]]}, {"id": "2009.09497", "submitter": "Lukasz Korycki", "authors": "{\\L}ukasz Korycki and Bartosz Krawczyk", "title": "Adversarial Concept Drift Detection under Poisoning Attacks for Robust\n  Data Stream Mining", "comments": "42 pages, 13 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous learning from streaming data is among the most challenging topics\nin the contemporary machine learning. In this domain, learning algorithms must\nnot only be able to handle massive volumes of rapidly arriving data, but also\nadapt themselves to potential emerging changes. The phenomenon of the evolving\nnature of data streams is known as concept drift. While there is a plethora of\nmethods designed for detecting its occurrence, all of them assume that the\ndrift is connected with underlying changes in the source of data. However, one\nmust consider the possibility of a malicious injection of false data that\nsimulates a concept drift. This adversarial setting assumes a poisoning attack\nthat may be conducted in order to damage the underlying classification system\nby forcing adaptation to false data. Existing drift detectors are not capable\nof differentiating between real and adversarial concept drift. In this paper,\nwe propose a framework for robust concept drift detection in the presence of\nadversarial and poisoning attacks. We introduce the taxonomy for two types of\nadversarial concept drifts, as well as a robust trainable drift detector. It is\nbased on the augmented Restricted Boltzmann Machine with improved gradient\ncomputation and energy function. We also introduce Relative Loss of Robustness\n- a novel measure for evaluating the performance of concept drift detectors\nunder poisoning attacks. Extensive computational experiments, conducted on both\nfully and sparsely labeled data streams, prove the high robustness and efficacy\nof the proposed drift detection framework in adversarial scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 18:46:31 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Korycki", "\u0141ukasz", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2009.09511", "submitter": "Bhaskar Ramasubramanian", "authors": "Bhaskar Ramasubramanian, Baicen Xiao, Linda Bushnell, Radha Poovendran", "title": "Safety-Critical Online Control with Adversarial Disturbances", "comments": "Paper accepted to the Conference on Decision and Control (CDC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the control of safety-critical dynamical systems in the\npresence of adversarial disturbances. We seek to synthesize state-feedback\ncontrollers to minimize a cost incurred due to the disturbance, while\nrespecting a safety constraint. The safety constraint is given by a bound on an\nH-inf norm, while the cost is specified as an upper bound on the H-2 norm of\nthe system. We consider an online setting where costs at each time are revealed\nonly after the controller at that time is chosen. We propose an iterative\napproach to the synthesis of the controller by solving a modified discrete-time\nRiccati equation. Solutions of this equation enforce the safety constraint. We\ncompare the cost of this controller with that of the optimal controller when\none has complete knowledge of disturbances and costs in hindsight. We show that\nthe regret function, which is defined as the difference between these costs,\nvaries logarithmically with the time horizon. We validate our approach on a\nprocess control setup that is subject to two kinds of adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 19:59:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramasubramanian", "Bhaskar", ""], ["Xiao", "Baicen", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "2009.09521", "submitter": "Yashesh Dhebar", "authors": "Yashesh Dhebar, Kalyanmoy Deb, Subramanya Nageshrao, Ling Zhu and\n  Dimitar Filev", "title": "Towards Interpretable-AI Policies Induction using Evolutionary Nonlinear\n  Decision Trees for Discrete Action Systems", "comments": "main paper: 12 pages (pages 1-12), Supplementary Document: 5 pages\n  (from pages 13-17). Video link: https://youtu.be/DByYWTQ6X3E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box AI induction methods such as deep reinforcement learning (DRL) are\nincreasingly being used to find optimal policies for a given control task.\nAlthough policies represented using a black-box AI are capable of efficiently\nexecuting the underlying control task and achieving optimal closed-loop\nperformance, the developed control rules are often complex and neither\ninterpretable nor explainable. In this paper, we use a recently proposed\nnonlinear decision-tree (NLDT) approach to find a hierarchical set of control\nrules in an attempt to maximize the open-loop performance for approximating and\nexplaining the pre-trained black-box DRL (oracle) agent using the labelled\nstate-action dataset. Recent advances in nonlinear optimization approaches\nusing evolutionary computation facilitates finding a hierarchical set of\nnonlinear control rules as a function of state variables using a\ncomputationally fast bilevel optimization procedure at each node of the\nproposed NLDT. Additionally, we propose a re-optimization procedure for\nenhancing closed-loop performance of an already derived NLDT. We evaluate our\nproposed methodologies (open and closed-loop NLDTs) on different control\nproblems having multiple discrete actions. In all these problems our proposed\napproach is able to find relatively simple and interpretable rules involving\none to four non-linear terms per rule, while simultaneously achieving on par\nclosed-loop performance when compared to a trained black-box DRL agent. A\npost-processing approach for simplifying the NLDT is also suggested. The\nobtained results are inspiring as they suggest the replacement of complicated\nblack-box DRL policies involving thousands of parameters (making them\nnon-interpretable) with relatively simple interpretable policies. Results are\nencouraging and motivating to pursue further applications of proposed approach\nin solving more complex control tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 20:41:57 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 17:28:51 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Dhebar", "Yashesh", ""], ["Deb", "Kalyanmoy", ""], ["Nageshrao", "Subramanya", ""], ["Zhu", "Ling", ""], ["Filev", "Dimitar", ""]]}, {"id": "2009.09523", "submitter": "Andrew Or", "authors": "Andrew Or, Haoyu Zhang, Michael J. Freedman", "title": "VirtualFlow: Decoupling Deep Learning Models from the Underlying\n  Hardware", "comments": "12 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep learning systems such as TensorFlow and PyTorch tightly\ncouple the model with the underlying hardware. This coupling requires the user\nto modify application logic in order to run the same job across a different set\nof resources, thereby limiting the choice of hardware for a given workload and\npotentially forcing the user to forgo more efficient hardware configurations.\n  We propose VirtualFlow, a system leveraging a novel abstraction called\nvirtual node processing to decouple the model from the hardware. In each step\nof training or inference, the batch of input data is split across virtual nodes\ninstead of hardware accelerators (e.g. GPUs and TPUs). Mapping multiple virtual\nnodes to each accelerator and processing them sequentially effectively time\nslices the batch, thereby allowing users to reduce the memory requirement of\ntheir workloads and mimic large batch sizes on small clusters.\n  Using this technique, VirtualFlow enables many new use cases, such as\nreproducing training results across different hardware, resource elasticity,\nand heterogeneous training. In our evaluation, our implementation of\nVirtualFlow for TensorFlow achieved strong convergence guarantees across\ndifferent hardware with out-of-the-box hyperparameters, up to 48% lower job\ncompletion times with resource elasticity, and up to 42% higher throughput with\nheterogeneous training.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 20:49:48 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 20:35:46 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Or", "Andrew", ""], ["Zhang", "Haoyu", ""], ["Freedman", "Michael J.", ""]]}, {"id": "2009.09525", "submitter": "Romain Cosentino Mr", "authors": "Romain Cosentino, Randall Balestriero, Richard Baraniuk, Behnaam\n  Aazhang", "title": "Deep Autoencoders: From Understanding to Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A big mystery in deep learning continues to be the ability of methods to\ngeneralize when the number of model parameters is larger than the number of\ntraining examples. In this work, we take a step towards a better understanding\nof the underlying phenomena of Deep Autoencoders (AEs), a mainstream deep\nlearning solution for learning compressed, interpretable, and structured data\nrepresentations. In particular, we interpret how AEs approximate the data\nmanifold by exploiting their continuous piecewise affine structure. Our\nreformulation of AEs provides new insights into their mapping, reconstruction\nguarantees, as well as an interpretation of commonly used regularization\ntechniques. We leverage these findings to derive two new regularizations that\nenable AEs to capture the inherent symmetry in the data. Our regularizations\nleverage recent advances in the group of transformation learning to enable AEs\nto better approximate the data manifold without explicitly defining the group\nunderlying the manifold. Under the assumption that the symmetry of the data can\nbe explained by a Lie group, we prove that the regularizations ensure the\ngeneralization of the corresponding AEs. A range of experimental evaluations\ndemonstrate that our methods outperform other state-of-the-art regularization\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 21:01:18 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 02:15:43 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Cosentino", "Romain", ""], ["Balestriero", "Randall", ""], ["Baraniuk", "Richard", ""], ["Aazhang", "Behnaam", ""]]}, {"id": "2009.09535", "submitter": "Sehwan Kim", "authors": "Sehwan Kim, Qifan Song, and Faming Liang", "title": "Stochastic Gradient Langevin Dynamics Algorithms with Adaptive Drifts", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian deep learning offers a principled way to address many issues\nconcerning safety of artificial intelligence (AI), such as model\nuncertainty,model interpretability, and prediction bias. However, due to the\nlack of efficient Monte Carlo algorithms for sampling from the posterior of\ndeep neural networks (DNNs), Bayesian deep learning has not yet powered our AI\nsystem. We propose a class of adaptive stochastic gradient Markov chain Monte\nCarlo (SGMCMC) algorithms, where the drift function is biased to enhance escape\nfrom saddle points and the bias is adaptively adjusted according to the\ngradient of past samples. We establish the convergence of the proposed\nalgorithms under mild conditions, and demonstrate via numerical examples that\nthe proposed algorithms can significantly outperform the existing SGMCMC\nalgorithms, such as stochastic gradient Langevin dynamics (SGLD), stochastic\ngradient Hamiltonian Monte Carlo (SGHMC) and preconditioned SGLD, in both\nsimulation and optimization tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:03:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kim", "Sehwan", ""], ["Song", "Qifan", ""], ["Liang", "Faming", ""]]}, {"id": "2009.09538", "submitter": "Mengfan Xu", "authors": "Mengfan Xu and Diego Klabjan", "title": "Regret Bounds and Reinforcement Learning Exploration of EXP-based\n  Algorithms", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EXP-based algorithms are often used for exploration in multi-armed bandit. We\nrevisit the EXP3.P algorithm and establish both the lower and upper bounds of\nregret in the Gaussian multi-armed bandit setting, as well as a more general\ndistribution option. The analyses do not require bounded rewards compared to\nclassical regret assumptions. We also extend EXP4 from multi-armed bandit to\nreinforcement learning to incentivize exploration by multiple agents. The\nresulting algorithm has been tested on hard-to-explore games and it shows an\nimprovement on exploration compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:31:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xu", "Mengfan", ""], ["Klabjan", "Diego", ""]]}, {"id": "2009.09543", "submitter": "Alexandre Lima Ph.D.", "authors": "Alexandre Barbosa de Lima and Maur\\'icio B. C. Salles and Jos\\'e\n  Roberto Cardoso", "title": "State-of-Charge Estimation of a Li-Ion Battery using Deep Forward Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article presents two Deep Forward Networks with two and four hidden\nlayers, respectively, that model the drive cycle of a Panasonic 18650PF\nlithium-ion (Li-ion) battery at a given temperature using the K-fold\ncross-validation method, in order to estimate the State of Charge (SOC) of the\ncell. The drive cycle power profile is calculated for an electric truck with a\n35kWh battery pack scaled for a single 18650PF cell. We propose a machine\nlearning workflow which is able to fight overfitting when developing deep\nlearning models for SOC estimation. The contribution of this work is to present\na methodology of building a Deep Forward Network for a lithium-ion battery and\nits performance assessment, which follows the best practices in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 23:47:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["de Lima", "Alexandre Barbosa", ""], ["Salles", "Maur\u00edcio B. C.", ""], ["Cardoso", "Jos\u00e9 Roberto", ""]]}, {"id": "2009.09545", "submitter": "Mirko Pieropan", "authors": "Alfredo Braunstein, Thomas Gueudr\\'e, Andrea Pagnani and Mirko\n  Pieropan", "title": "Expectation propagation on the diluted Bayesian classifier", "comments": "24 pages, 6 figures", "journal-ref": "Phys. Rev. E 103, 043301 (2021)", "doi": "10.1103/PhysRevE.103.043301", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient feature selection from high-dimensional datasets is a very\nimportant challenge in many data-driven fields of science and engineering. We\nintroduce a statistical mechanics inspired strategy that addresses the problem\nof sparse feature selection in the context of binary classification by\nleveraging a computational scheme known as expectation propagation (EP). The\nalgorithm is used in order to train a continuous-weights perceptron learning a\nclassification rule from a set of (possibly partly mislabeled) examples\nprovided by a teacher perceptron with diluted continuous weights. We test the\nmethod in the Bayes optimal setting under a variety of conditions and compare\nit to other state-of-the-art algorithms based on message passing and on\nexpectation maximization approximate inference schemes. Overall, our\nsimulations show that EP is a robust and competitive algorithm in terms of\nvariable selection properties, estimation accuracy and computational\ncomplexity, especially when the student perceptron is trained from correlated\npatterns that prevent other iterative methods from converging. Furthermore, our\nnumerical tests demonstrate that the algorithm is capable of learning online\nthe unknown values of prior parameters, such as the dilution level of the\nweights of the teacher perceptron and the fraction of mislabeled examples,\nquite accurately. This is achieved by means of a simple maximum likelihood\nstrategy that consists in minimizing the free energy associated with the EP\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 23:59:44 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:46:21 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Braunstein", "Alfredo", ""], ["Gueudr\u00e9", "Thomas", ""], ["Pagnani", "Andrea", ""], ["Pieropan", "Mirko", ""]]}, {"id": "2009.09556", "submitter": "Mufan Sang", "authors": "Mufan Sang, Wei Xia, John H.L. Hansen", "title": "Open-set Short Utterance Forensic Speaker Verification using\n  Teacher-Student Network with Explicit Inductive Bias", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In forensic applications, it is very common that only small naturalistic\ndatasets consisting of short utterances in complex or unknown acoustic\nenvironments are available. In this study, we propose a pipeline solution to\nimprove speaker verification on a small actual forensic field dataset. By\nleveraging large-scale out-of-domain datasets, a knowledge distillation based\nobjective function is proposed for teacher-student learning, which is applied\nfor short utterance forensic speaker verification. The objective function\ncollectively considers speaker classification loss, Kullback-Leibler\ndivergence, and similarity of embeddings. In order to advance the trained deep\nspeaker embedding network to be robust for a small target dataset, we introduce\na novel strategy to fine-tune the pre-trained student model towards a forensic\ntarget domain by utilizing the model as a finetuning start point and a\nreference in regularization. The proposed approaches are evaluated on the\n1st48-UTD forensic corpus, a newly established naturalistic dataset of actual\nhomicide investigations consisting of short utterances recorded in uncontrolled\nconditions. We show that the proposed objective function can efficiently\nimprove the performance of teacher-student learning on short utterances and\nthat our fine-tuning strategy outperforms the commonly used weight decay method\nby providing an explicit inductive bias towards the pre-trained model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 00:58:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sang", "Mufan", ""], ["Xia", "Wei", ""], ["Hansen", "John H. L.", ""]]}, {"id": "2009.09561", "submitter": "Hang Chen", "authors": "Hang Chen, Jun Du, Yu Hu, Li-Rong Dai, Bao-Cai Yin, Chin-Hui Lee", "title": "Correlating Subword Articulation with Lip Shapes for Embedding Aware\n  Audio-Visual Speech Enhancement", "comments": "34 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a visual embedding approach to improving embedding\naware speech enhancement (EASE) by synchronizing visual lip frames at the phone\nand place of articulation levels. We first extract visual embedding from lip\nframes using a pre-trained phone or articulation place recognizer for\nvisual-only EASE (VEASE). Next, we extract audio-visual embedding from noisy\nspeech and lip videos in an information intersection manner, utilizing a\ncomplementarity of audio and visual features for multi-modal EASE (MEASE).\nExperiments on the TCD-TIMIT corpus corrupted by simulated additive noises show\nthat our proposed subword based VEASE approach is more effective than\nconventional embedding at the word level. Moreover, visual embedding at the\narticulation place level, leveraging upon a high correlation between place of\narticulation and lip shapes, shows an even better performance than that at the\nphone level. Finally the proposed MEASE framework, incorporating both audio and\nvisual embedding, yields significantly better speech quality and\nintelligibility than those obtained with the best visual-only and audio-only\nEASE systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 01:26:19 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Hang", ""], ["Du", "Jun", ""], ["Hu", "Yu", ""], ["Dai", "Li-Rong", ""], ["Yin", "Bao-Cai", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2009.09577", "submitter": "Yongcan Cao", "authors": "Feng Tao and Yongcan Cao", "title": "Learn to Exceed: Stereo Inverse Reinforcement Learning with Concurrent\n  Policy Optimization", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of obtaining a control policy that can\nmimic and then outperform expert demonstrations in Markov decision processes\nwhere the reward function is unknown to the learning agent. One main relevant\napproach is the inverse reinforcement learning (IRL), which mainly focuses on\ninferring a reward function from expert demonstrations. The obtained control\npolicy by IRL and the associated algorithms, however, can hardly outperform\nexpert demonstrations. To overcome this limitation, we propose a novel method\nthat enables the learning agent to outperform the demonstrator via a new\nconcurrent reward and action policy learning approach. In particular, we first\npropose a new stereo utility definition that aims to address the bias in the\ninterpretation of expert demonstrations. We then propose a loss function for\nthe learning agent to learn reward and action policies concurrently such that\nthe learning agent can outperform expert demonstrations. The performance of the\nproposed method is first demonstrated in OpenAI environments. Further efforts\nare conducted to experimentally validate the proposed method via an indoor\ndrone flight scenario.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:16:21 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 23:04:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Tao", "Feng", ""], ["Cao", "Yongcan", ""]]}, {"id": "2009.09579", "submitter": "JaeSung Yoo", "authors": "Jaesung Yoo, Jeman Park, An Wang, David Mohaisen, and Joongheon Kim", "title": "On the Performance of Generative Adversarial Network (GAN) Variants: A\n  Clinical Data Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) is a useful type of Neural Networks in\nvarious types of applications including generative models and feature\nextraction. Various types of GANs are being researched with different insights,\nresulting in a diverse family of GANs with a better performance in each\ngeneration. This review focuses on various GANs categorized by their common\ntraits.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:18:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yoo", "Jaesung", ""], ["Park", "Jeman", ""], ["Wang", "An", ""], ["Mohaisen", "David", ""], ["Kim", "Joongheon", ""]]}, {"id": "2009.09583", "submitter": "Mel McCurrie", "authors": "Mel McCurrie, Hamish Nicholson, Walter J. Scheirer, Samuel Anthony", "title": "Modeling Score Distributions and Continuous Covariates: A Bayesian\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer Vision practitioners must thoroughly understand their model's\nperformance, but conditional evaluation is complex and error-prone. In\nbiometric verification, model performance over continuous\ncovariates---real-number attributes of images that affect performance---is\nparticularly challenging to study. We develop a generative model of the match\nand non-match score distributions over continuous covariates and perform\ninference with modern Bayesian methods. We use mixture models to capture\narbitrary distributions and local basis functions to capture non-linear,\nmultivariate trends. Three experiments demonstrate the accuracy and\neffectiveness of our approach. First, we study the relationship between age and\nface verification performance and find previous methods may overstate\nperformance and confidence. Second, we study preprocessing for CNNs and find a\nhighly non-linear, multivariate surface of model performance. Our method is\naccurate and data efficient when evaluated against previous synthetic methods.\nThird, we demonstrate the novel application of our method to pedestrian\ntracking and calculate variable thresholds and expected performance while\ncontrolling for multiple covariates.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:41:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["McCurrie", "Mel", ""], ["Nicholson", "Hamish", ""], ["Scheirer", "Walter J.", ""], ["Anthony", "Samuel", ""]]}, {"id": "2009.09588", "submitter": "Jisu Jeong", "authors": "Jisu Jeong, Jeong-Min Yun, Hongi Keam, Young-Jin Park, Zimin Park,\n  Junki Cho", "title": "div2vec: Diversity-Emphasized Node Embedding", "comments": "To appear in the ImpactRS Workshop at ACM RecSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the interest of graph representation learning has been rapidly\nincreasing in recommender systems. However, most existing studies have focused\non improving accuracy, but in real-world systems, the recommendation diversity\nshould be considered as well to improve user experiences. In this paper, we\npropose the diversity-emphasized node embedding div2vec, which is a random\nwalk-based unsupervised learning method like DeepWalk and node2vec. When\ngenerating random walks, DeepWalk and node2vec sample nodes of higher degree\nmore and nodes of lower degree less. On the other hand, div2vec samples nodes\nwith the probability inversely proportional to its degree so that every node\ncan evenly belong to the collection of random walks. This strategy improves the\ndiversity of recommendation models. Offline experiments on the MovieLens\ndataset showed that our new method improves the recommendation performance in\nterms of both accuracy and diversity. Moreover, we evaluated the proposed model\non two real-world services, WATCHA and LINE Wallet Coupon, and observed the\ndiv2vec improves the recommendation quality by diversifying the system.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:50:50 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jeong", "Jisu", ""], ["Yun", "Jeong-Min", ""], ["Keam", "Hongi", ""], ["Park", "Young-Jin", ""], ["Park", "Zimin", ""], ["Cho", "Junki", ""]]}, {"id": "2009.09590", "submitter": "Lirong Wu", "authors": "Lirong Wu, Zicheng Liu, Zelin Zang, Jun Xia, Siyuan Li, Stan. Z Li", "title": "Deep Clustering and Representation Learning with Geometric Structure\n  Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework for Deep Clustering and\nmulti-manifold Representation Learning (DCRL) that preserves the geometric\nstructure of data. In the proposed framework, manifold clustering is done in\nthe latent space guided by a clustering loss. To overcome the problem that\nclustering-oriented losses may deteriorate the geometric structure of\nembeddings in the latent space, an isometric loss is proposed for preserving\nintra-manifold structure locally and a ranking loss for inter-manifold\nstructure globally. Experimental results on various datasets show that DCRL\nleads to performances comparable to current state-of-the-art deep clustering\nalgorithms, yet exhibits superior performance for manifold representation. Our\nresults also demonstrate the importance and effectiveness of the proposed\nlosses in preserving geometric structure in terms of visualization and\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:04:57 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 00:56:18 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 14:59:56 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Wu", "Lirong", ""], ["Liu", "Zicheng", ""], ["Zang", "Zelin", ""], ["Xia", "Jun", ""], ["Li", "Siyuan", ""], ["Li", "Stan. Z", ""]]}, {"id": "2009.09593", "submitter": "Junjie Wang", "authors": "Junjie Wang, Qichao Zhang, Dongbin Zhao, Mengchen Zhao, Jianye Hao", "title": "Dynamic Horizon Value Estimation for Model-based Reinforcement Learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing model-based value expansion methods typically leverage a world model\nfor value estimation with a fixed rollout horizon to assist policy learning.\nHowever, the fixed rollout with an inaccurate model has a potential to harm the\nlearning process. In this paper, we investigate the idea of using the model\nknowledge for value expansion adaptively. We propose a novel method called\nDynamic-horizon Model-based Value Expansion (DMVE) to adjust the world model\nusage with different rollout horizons. Inspired by reconstruction-based\ntechniques that can be applied for visual data novelty detection, we utilize a\nworld model with a reconstruction module for image feature extraction, in order\nto acquire more precise value estimation. The raw and the reconstructed images\nare both used to determine the appropriate horizon for adaptive value\nexpansion. On several benchmark visual control tasks, experimental results show\nthat DMVE outperforms all baselines in sample efficiency and final performance,\nindicating that DMVE can achieve more effective and accurate value estimation\nthan state-of-the-art model-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:09:33 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Junjie", ""], ["Zhang", "Qichao", ""], ["Zhao", "Dongbin", ""], ["Zhao", "Mengchen", ""], ["Hao", "Jianye", ""]]}, {"id": "2009.09595", "submitter": "Tamir Blum", "authors": "Tamir Blum, Gabin Paillet, Mickael Laine, Kazuya Yoshida", "title": "RL STaR Platform: Reinforcement Learning for Simulation based Training\n  of Robots", "comments": "3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising field to enhance robotic autonomy\nand decision making capabilities for space robotics, something which is\nchallenging with traditional techniques due to stochasticity and uncertainty\nwithin the environment. RL can be used to enable lunar cave exploration with\ninfrequent human feedback, faster and safer lunar surface locomotion or the\ncoordination and collaboration of multi-robot systems. However, there are many\nhurdles making research challenging for space robotic applications using RL and\nmachine learning, particularly due to insufficient resources for traditional\nrobotics simulators like CoppeliaSim. Our solution to this is an open source\nmodular platform called Reinforcement Learning for Simulation based Training of\nRobots, or RL STaR, that helps to simplify and accelerate the application of RL\nto the space robotics research field. This paper introduces the RL STaR\nplatform, and how researchers can use it through a demonstration.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:09:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Blum", "Tamir", ""], ["Paillet", "Gabin", ""], ["Laine", "Mickael", ""], ["Yoshida", "Kazuya", ""]]}, {"id": "2009.09604", "submitter": "Badih Ghazi", "authors": "Lijie Chen, Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "On Distributed Differential Privacy and Counting Distinct Elements", "comments": "68 pages, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the setup where each of $n$ users holds an element from a discrete\nset, and the goal is to count the number of distinct elements across all users,\nunder the constraint of $(\\epsilon, \\delta)$-differentially privacy:\n  - In the non-interactive local setting, we prove that the additive error of\nany protocol is $\\Omega(n)$ for any constant $\\epsilon$ and for any $\\delta$\ninverse polynomial in $n$.\n  - In the single-message shuffle setting, we prove a lower bound of\n$\\Omega(n)$ on the error for any constant $\\epsilon$ and for some $\\delta$\ninverse quasi-polynomial in $n$. We do so by building on the moment-matching\nmethod from the literature on distribution estimation.\n  - In the multi-message shuffle setting, we give a protocol with at most one\nmessage per user in expectation and with an error of $\\tilde{O}(\\sqrt(n))$ for\nany constant $\\epsilon$ and for any $\\delta$ inverse polynomial in $n$. Our\nprotocol is also robustly shuffle private, and our error of $\\sqrt(n)$ matches\na known lower bound for such protocols.\n  Our proof technique relies on a new notion, that we call dominated protocols,\nand which can also be used to obtain the first non-trivial lower bounds against\nmulti-message shuffle protocols for the well-studied problems of selection and\nlearning parity.\n  Our first lower bound for estimating the number of distinct elements provides\nthe first $\\omega(\\sqrt(n))$ separation between global sensitivity and error in\nlocal differential privacy, thus answering an open question of Vadhan (2017).\nWe also provide a simple construction that gives $\\tilde{\\Omega}(n)$ separation\nbetween global sensitivity and error in two-party differential privacy, thereby\nanswering an open question of McGregor et al. (2011).\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:13:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Lijie", ""], ["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2009.09609", "submitter": "Shamik Roy", "authors": "Shamik Roy, Dan Goldwasser", "title": "Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization\n  in News Media", "comments": "19 pages, 6 figures, Will appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest a minimally-supervised approach for identifying\nnuanced frames in news article coverage of politically divisive topics. We\nsuggest to break the broad policy frames suggested by Boydstun et al., 2014\ninto fine-grained subframes which can capture differences in political ideology\nin a better way. We evaluate the suggested subframes and their embedding,\nlearned using minimal supervision, over three topics, namely, immigration,\ngun-control and abortion. We demonstrate the ability of the subframes to\ncapture ideological differences and analyze political discourse in news media.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:29:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Roy", "Shamik", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2009.09612", "submitter": "Tuan Anh Bui", "authors": "Anh Bui, Trung Le, He Zhao, Paul Montague, Olivier deVel, Tamas\n  Abraham, Dinh Phung", "title": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting\n  Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble-based adversarial training is a principled approach to achieve\nrobustness against adversarial attacks. An important technique of this approach\nis to control the transferability of adversarial examples among ensemble\nmembers. We propose in this work a simple yet effective strategy to collaborate\namong committee models of an ensemble model. This is achieved via the secure\nand insecure sets defined for each model member on a given sample, hence help\nus to quantify and regularize the transferability. Consequently, our proposed\nframework provides the flexibility to reduce the adversarial transferability as\nwell as to promote the diversity of ensemble members, which are two crucial\nfactors for better robustness in our ensemble approach. We conduct extensive\nand comprehensive experiments to demonstrate that our proposed method\noutperforms the state-of-the-art ensemble baselines, at the same time can\ndetect a wide range of adversarial examples with a nearly perfect accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:54:38 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bui", "Anh", ""], ["Le", "Trung", ""], ["Zhao", "He", ""], ["Montague", "Paul", ""], ["deVel", "Olivier", ""], ["Abraham", "Tamas", ""], ["Phung", "Dinh", ""]]}, {"id": "2009.09618", "submitter": "Weikai Yang", "authors": "Weikai Yang, Xiting Wang, Jie Lu, Wenwen Dou, Shixia Liu", "title": "Interactive Steering of Hierarchical Clustering", "comments": "Accepted for IEEE Transactions on Visualization and Computer Graphics\n  (TVCG)", "journal-ref": null, "doi": "10.1109/TVCG.2020.2995100", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is an important technique to organize big data for\nexploratory data analysis. However, existing one-size-fits-all hierarchical\nclustering methods often fail to meet the diverse needs of different users. To\naddress this challenge, we present an interactive steering method to visually\nsupervise constrained hierarchical clustering by utilizing both public\nknowledge (e.g., Wikipedia) and private knowledge from users. The novelty of\nour approach includes 1) automatically constructing constraints for\nhierarchical clustering using knowledge (knowledge-driven) and intrinsic data\ndistribution (data-driven), and 2) enabling the interactive steering of\nclustering through a visual interface (user-driven). Our method first maps each\ndata item to the most relevant items in a knowledge base. An initial constraint\ntree is then extracted using the ant colony optimization algorithm. The\nalgorithm balances the tree width and depth and covers the data items with high\nconfidence. Given the constraint tree, the data items are hierarchically\nclustered using evolutionary Bayesian rose tree. To clearly convey the\nhierarchical clustering results, an uncertainty-aware tree visualization has\nbeen developed to enable users to quickly locate the most uncertain\nsub-hierarchies and interactively improve them. The quantitative evaluation and\ncase study demonstrate that the proposed approach facilitates the building of\ncustomized clustering trees in an efficient and effective manner.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 05:26:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yang", "Weikai", ""], ["Wang", "Xiting", ""], ["Lu", "Jie", ""], ["Dou", "Wenwen", ""], ["Liu", "Shixia", ""]]}, {"id": "2009.09623", "submitter": "Emmanouil Zampetakis", "authors": "Constantinos Daskalakis and Stratis Skoulakis and Manolis Zampetakis", "title": "The Complexity of Constrained Min-Max Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its important applications in Machine Learning, min-max optimization\nof nonconvex-nonconcave objectives remains elusive. Not only are there no known\nfirst-order methods converging even to approximate local min-max points, but\nthe computational complexity of identifying them is also poorly understood. In\nthis paper, we provide a characterization of the computational complexity of\nthe problem, as well as of the limitations of first-order methods in\nconstrained min-max optimization problems with nonconvex-nonconcave objectives\nand linear constraints.\n  As a warm-up, we show that, even when the objective is a Lipschitz and smooth\ndifferentiable function, deciding whether a min-max point exists, in fact even\ndeciding whether an approximate min-max point exists, is NP-hard. More\nimportantly, we show that an approximate local min-max point of large enough\napproximation is guaranteed to exist, but finding one such point is\nPPAD-complete. The same is true of computing an approximate fixed point of\nGradient Descent/Ascent.\n  An important byproduct of our proof is to establish an unconditional hardness\nresult in the Nemirovsky-Yudin model. We show that, given oracle access to some\nfunction $f : P \\to [-1, 1]$ and its gradient $\\nabla f$, where $P \\subseteq\n[0, 1]^d$ is a known convex polytope, every algorithm that finds a\n$\\varepsilon$-approximate local min-max point needs to make a number of queries\nthat is exponential in at least one of $1/\\varepsilon$, $L$, $G$, or $d$, where\n$L$ and $G$ are respectively the smoothness and Lipschitzness of $f$ and $d$ is\nthe dimension. This comes in sharp contrast to minimization problems, where\nfinding approximate local minima in the same setting can be done with Projected\nGradient Descent using $O(L/\\varepsilon)$ many queries. Our result is the first\nto show an exponential separation between these two fundamental optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 05:54:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Skoulakis", "Stratis", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "2009.09634", "submitter": "Saswata Sahoo Dr", "authors": "Saswata Sahoo and Souradip Chakraborty", "title": "Learning Representation for Mixed Data Types with a Nonlinear Deep\n  Encoder-Decoder Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation of data on mixed variables, numerical and categorical types to\nget suitable feature map is a challenging task as important information lies in\na complex non-linear manifold. The feature transformation should be able to\nincorporate marginal information of the individual variables and complex\ncross-dependence structure among the mixed type of variables simultaneously. In\nthis work, we propose a novel nonlinear Deep Encoder-Decoder framework to\ncapture the cross-domain information for mixed data types. The hidden layers of\nthe network connect the two types of variables through various non-linear\ntransformations to give latent feature maps. We encode the information on the\nnumerical variables in a number of hidden nonlinear units. We use these units\nto recreate categorical variables through further nonlinear transformations. A\nseparate and similar network is developed switching the roles of the numerical\nand categorical variables. The hidden representational units are stacked one\nnext to the others and transformed into a common space using a locality\npreserving projection. The derived feature maps are used to explore the\nclusters in the data. Various standard datasets are investigated to show nearly\nthe state of the art performance in clustering using the feature maps with\nsimple K-means clustering.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 06:29:49 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sahoo", "Saswata", ""], ["Chakraborty", "Souradip", ""]]}, {"id": "2009.09663", "submitter": "Yu Li", "authors": "Yu Li, Min Li, Bo Luo, Ye Tian, and Qiang Xu", "title": "DeepDyve: Dynamic Verification for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3372297.3423338", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become one of the enabling technologies in\nmany safety-critical applications, e.g., autonomous driving and medical image\nanalysis. DNN systems, however, suffer from various kinds of threats, such as\nadversarial example attacks and fault injection attacks. While there are many\ndefense methods proposed against maliciously crafted inputs, solutions against\nfaults presented in the DNN system itself (e.g., parameters and calculations)\nare far less explored. In this paper, we develop a novel lightweight\nfault-tolerant solution for DNN-based systems, namely DeepDyve, which employs\npre-trained neural networks that are far simpler and smaller than the original\nDNN for dynamic verification. The key to enabling such lightweight checking is\nthat the smaller neural network only needs to produce approximate results for\nthe initial task without sacrificing fault coverage much. We develop efficient\nand effective architecture and task exploration techniques to achieve optimized\nrisk/overhead trade-off in DeepDyve. Experimental results show that DeepDyve\ncan reduce 90% of the risks at around 10% overhead.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 07:58:18 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:00:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Yu", ""], ["Li", "Min", ""], ["Luo", "Bo", ""], ["Tian", "Ye", ""], ["Xu", "Qiang", ""]]}, {"id": "2009.09677", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Eneko Osaba, Albert Bifet, Francisco\n  Herrera", "title": "CURIE: A Cellular Automaton for Concept Drift Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data stream mining extracts information from large quantities of data flowing\nfast and continuously (data streams). They are usually affected by changes in\nthe data distribution, giving rise to a phenomenon referred to as concept\ndrift. Thus, learning models must detect and adapt to such changes, so as to\nexhibit a good predictive performance after a drift has occurred. In this\nregard, the development of effective drift detection algorithms becomes a key\nfactor in data stream mining. In this work we propose CU RIE, a drift detector\nrelying on cellular automata. Specifically, in CU RIE the distribution of the\ndata stream is represented in the grid of a cellular automata, whose\nneighborhood rule can then be utilized to detect possible distribution changes\nover the stream. Computer simulations are presented and discussed to show that\nCU RIE, when hybridized with other base learners, renders a competitive\nbehavior in terms of detection metrics and classification accuracy. CU RIE is\ncompared with well-established drift detectors over synthetic datasets with\nvarying drift characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:28:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Osaba", "Eneko", ""], ["Bifet", "Albert", ""], ["Herrera", "Francisco", ""]]}, {"id": "2009.09687", "submitter": "Xi Peng", "authors": "Yunfan Li, Peng Hu, Zitao Liu, Dezhong Peng, Joey Tianyi Zhou, Xi Peng", "title": "Contrastive Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a one-stage online clustering method called\nContrastive Clustering (CC) which explicitly performs the instance- and\ncluster-level contrastive learning. To be specific, for a given dataset, the\npositive and negative instance pairs are constructed through data augmentations\nand then projected into a feature space. Therein, the instance- and\ncluster-level contrastive learning are respectively conducted in the row and\ncolumn space by maximizing the similarities of positive pairs while minimizing\nthose of negative ones. Our key observation is that the rows of the feature\nmatrix could be regarded as soft labels of instances, and accordingly the\ncolumns could be further regarded as cluster representations. By simultaneously\noptimizing the instance- and cluster-level contrastive loss, the model jointly\nlearns representations and cluster assignments in an end-to-end manner.\nExtensive experimental results show that CC remarkably outperforms 17\ncompetitive clustering methods on six challenging image benchmarks. In\nparticular, CC achieves an NMI of 0.705 (0.431) on the CIFAR-10 (CIFAR-100)\ndataset, which is an up to 19\\% (39\\%) performance improvement compared with\nthe best baseline.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:54:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Yunfan", ""], ["Hu", "Peng", ""], ["Liu", "Zitao", ""], ["Peng", "Dezhong", ""], ["Zhou", "Joey Tianyi", ""], ["Peng", "Xi", ""]]}, {"id": "2009.09696", "submitter": "Yash Satsangi", "authors": "Yash Satsangi, Shimon Whiteson, Frans A. Oliehoek, Matthijs T. J.\n  Spaan", "title": "Exploiting Submodular Value Functions For Scaling Up Active Perception", "comments": null, "journal-ref": "Autonomous Robot 42 2018. Original article available via Springer\n  journal open access:\n  https://link.springer.com/article/10.1007/s10514-017-9666-5", "doi": "10.1007/s10514-017-9666-5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In active perception tasks, an agent aims to select sensory actions that\nreduce its uncertainty about one or more hidden variables. While partially\nobservable Markov decision processes (POMDPs) provide a natural model for such\nproblems, reward functions that directly penalize uncertainty in the agent's\nbelief can remove the piecewise-linear and convex property of the value\nfunction required by most POMDP planners. Furthermore, as the number of sensors\navailable to the agent grows, the computational cost of POMDP planning grows\nexponentially with it, making POMDP planning infeasible with traditional\nmethods. In this article, we address a twofold challenge of modeling and\nplanning for active perception tasks. We show the mathematical equivalence of\n$\\rho$POMDP and POMDP-IR, two frameworks for modeling active perception tasks,\nthat restore the PWLC property of the value function. To efficiently plan for\nactive perception tasks, we identify and exploit the independence properties of\nPOMDP-IR to reduce the computational cost of solving POMDP-IR (and\n$\\rho$POMDP). We propose greedy point-based value iteration (PBVI), a new POMDP\nplanning method that uses greedy maximization to greatly improve scalability in\nthe action space of an active perception POMDP. Furthermore, we show that,\nunder certain conditions, including submodularity, the value function computed\nusing greedy PBVI is guaranteed to have bounded error with respect to the\noptimal value function. We establish the conditions under which the value\nfunction of an active perception POMDP is guaranteed to be submodular. Finally,\nwe present a detailed empirical analysis on a dataset collected from a\nmulti-camera tracking system employed in a shopping mall. Our method achieves\nsimilar performance to existing methods but at a fraction of the computational\ncost leading to better scalability for solving active perception tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:11:36 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Satsangi", "Yash", ""], ["Whiteson", "Shimon", ""], ["Oliehoek", "Frans A.", ""], ["Spaan", "Matthijs T. J.", ""]]}, {"id": "2009.09706", "submitter": "Johannes Dornheim", "authors": "Johannes Dornheim, Lukas Morand, Samuel Zeitvogel, Tarek Iraki,\n  Norbert Link, Dirk Helm", "title": "Deep Reinforcement Learning Methods for Structure-Guided Processing Path\n  Optimization", "comments": null, "journal-ref": "Journal of Intelligent Manufacturing (2021)", "doi": "10.1007/s10845-021-01805-z", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major goal of materials design is to find material structures with desired\nproperties and in a second step to find a processing path to reach one of these\nstructures. In this paper, we propose and investigate a deep reinforcement\nlearning approach for the optimization of processing paths. The goal is to find\noptimal processing paths in the material structure space that lead to\ntarget-structures, which have been identified beforehand to result in desired\nmaterial properties. There exists a target set containing one or multiple\ndifferent structures. Our proposed methods can find an optimal path from a\nstart structure to a single target structure, or optimize the processing paths\nto one of the equivalent target-structures in the set. In the latter case, the\nalgorithm learns during processing to simultaneously identify the best\nreachable target structure and the optimal path to it. The proposed methods\nbelong to the family of model-free deep reinforcement learning algorithms. They\nare guided by structure representations as features of the process state and by\na reward signal, which is formulated based on a distance function in the\nstructure space. Model-free reinforcement learning algorithms learn through\ntrial and error while interacting with the process. Thereby, they are not\nrestricted to information from a priori sampled processing data and are able to\nadapt to the specific process. The optimization itself is model-free and does\nnot require any prior knowledge about the process itself. We instantiate and\nevaluate the proposed methods by optimizing paths of a generic metal forming\nprocess. We show the ability of both methods to find processing paths leading\nclose to target structures and the ability of the extended method to identify\ntarget-structures that can be reached effectively and efficiently and to focus\non these targets for sample efficient processing path optimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:20:24 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 10:47:15 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 12:55:49 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 23:00:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Dornheim", "Johannes", ""], ["Morand", "Lukas", ""], ["Zeitvogel", "Samuel", ""], ["Iraki", "Tarek", ""], ["Link", "Norbert", ""], ["Helm", "Dirk", ""]]}, {"id": "2009.09715", "submitter": "Lingchao Guo", "authors": "Lingchao Guo, Zhaoming Lu, Shuang Zhou, Xiangming Wen, Zhihong He", "title": "When Healthcare Meets Off-the-Shelf WiFi: A Non-Wearable and Low-Costs\n  Approach for In-Home Monitoring", "comments": "41 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As elderly population grows, social and health care begin to face validation\nchallenges, in-home monitoring is becoming a focus for professionals in the\nfield. Governments urgently need to improve the quality of healthcare services\nat lower costs while ensuring the comfort and independence of the elderly. This\nwork presents an in-home monitoring approach based on off-the-shelf WiFi, which\nis low-costs, non-wearable and makes all-round daily healthcare information\navailable to caregivers. The proposed approach can capture fine-grained human\npose figures even through a wall and track detailed respiration status\nsimultaneously by off-the-shelf WiFi devices. Based on them, behavioral data,\nphysiological data and the derived information (e.g., abnormal events and\nunderlying diseases), of the elderly could be seen by caregivers directly. We\ndesign a series of signal processing methods and a neural network to capture\nhuman pose figures and extract respiration status curves from WiFi Channel\nState Information (CSI). Extensive experiments are conducted and according to\nthe results, off-the-shelf WiFi devices are capable of capturing fine-grained\nhuman pose figures, similar to cameras, even through a wall and track accurate\nrespiration status, thus demonstrating the effectiveness and feasibility of our\napproach for in-home monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:35:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Guo", "Lingchao", ""], ["Lu", "Zhaoming", ""], ["Zhou", "Shuang", ""], ["Wen", "Xiangming", ""], ["He", "Zhihong", ""]]}, {"id": "2009.09719", "submitter": "arXiv Admin", "authors": "Sagar Verma", "title": "A Survey on Machine Learning Applied to Dynamic Physical Systems", "comments": "arXiv admin note: submission has been withdrawn by arXiv\n  administrators due to inappropriate text overlap with external source", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This survey is on recent advancements in the intersection of physical\nmodeling and machine learning. We focus on the modeling of nonlinear systems\nwhich are closer to electric motors. Survey on motor control and fault\ndetection in operation of electric motors has been done.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:41:54 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 13:27:14 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Verma", "Sagar", ""]]}, {"id": "2009.09723", "submitter": "Stefano Teso", "authors": "Teodora Popordanoska, Mohit Kumar, Stefano Teso", "title": "Machine Guides, Human Supervises: Interactive Learning with Global\n  Explanations", "comments": "Preliminary version. Submitted to AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce explanatory guided learning (XGL), a novel interactive learning\nstrategy in which a machine guides a human supervisor toward selecting\ninformative examples for a classifier. The guidance is provided by means of\nglobal explanations, which summarize the classifier's behavior on different\nregions of the instance space and expose its flaws. Compared to other\nexplanatory interactive learning strategies, which are machine-initiated and\nrely on local explanations, XGL is designed to be robust against cases in which\nthe explanations supplied by the machine oversell the classifier's quality.\nMoreover, XGL leverages global explanations to open up the black-box of\nhuman-initiated interaction, enabling supervisors to select informative\nexamples that challenge the learned model. By drawing a link to interactive\nmachine teaching, we show theoretically that global explanations are a viable\napproach for guiding supervisors. Our simulations show that explanatory guided\nlearning avoids overselling the model's quality and performs comparably or\nbetter than machine- and human-initiated interactive learning strategies in\nterms of model quality.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:55:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Popordanoska", "Teodora", ""], ["Kumar", "Mohit", ""], ["Teso", "Stefano", ""]]}, {"id": "2009.09748", "submitter": "Resul Tugay", "authors": "Muhammet cakir, sule gunduz oguducu, resul tugay", "title": "A Deep Hybrid Model for Recommendation Systems", "comments": "International Conference of the Italian Association for Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation has been a long-standing problem in many areas ranging from\ne-commerce to social websites. Most current studies focus only on traditional\napproaches such as content-based or collaborative filtering while there are\nrelatively fewer studies in hybrid recommender systems. Due to the latest\nadvances of deep learning achieved in different fields including computer\nvision and natural language processing, deep learning has also gained much\nattention in Recommendation Systems. There are several studies that utilize ID\nembeddings of users and items to implement collaborative filtering with deep\nneural networks. However, such studies do not take advantage of other\ncategorical or continuous features of inputs. In this paper, we propose a new\ndeep neural network architecture which consists of not only ID embeddings but\nalso auxiliary information such as features of job postings and candidates for\njob recommendation system which is a reciprocal recommendation system.\nExperimental results on the dataset from a job-site show that the proposed\nmethod improves recommendation results over deep learning models utilizing ID\nembeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:41:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["cakir", "Muhammet", ""], ["oguducu", "sule gunduz", ""], ["tugay", "resul", ""]]}, {"id": "2009.09756", "submitter": "Resul Tugay", "authors": "Resul Tugay, Sule Gunduz Oguducu", "title": "Demand Prediction Using Machine Learning Methods and Stacked\n  Generalization", "comments": "Proceedings of the 6th International Conference on Data Science,\n  Technology and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply and demand are two fundamental concepts of sellers and customers.\nPredicting demand accurately is critical for organizations in order to be able\nto make plans. In this paper, we propose a new approach for demand prediction\non an e-commerce web site. The proposed model differs from earlier models in\nseveral ways. The business model used in the e-commerce web site, for which the\nmodel is implemented, includes many sellers that sell the same product at the\nsame time at different prices where the company operates a market place model.\nThe demand prediction for such a model should consider the price of the same\nproduct sold by competing sellers along the features of these sellers. In this\nstudy we first applied different regression algorithms for specific set of\nproducts of one department of a company that is one of the most popular online\ne-commerce companies in Turkey. Then we used stacked generalization or also\nknown as stacking ensemble learning to predict demand. Finally, all the\napproaches are evaluated on a real world data set obtained from the e-commerce\ncompany. The experimental results show that some of the machine learning\nmethods do produce almost as good results as the stacked generalization method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:58:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tugay", "Resul", ""], ["Oguducu", "Sule Gunduz", ""]]}, {"id": "2009.09758", "submitter": "Marie-Anne Lachaux", "authors": "Marie-Anne Lachaux, Armand Joulin, Guillaume Lample", "title": "Target Conditioning for One-to-Many Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models often lack diversity in their\ngenerated translations, even when paired with search algorithm, like beam\nsearch. A challenge is that the diversity in translations are caused by the\nvariability in the target language, and cannot be inferred from the source\nsentence alone. In this paper, we propose to explicitly model this one-to-many\nmapping by conditioning the decoder of a NMT model on a latent variable that\nrepresents the domain of target sentences. The domain is a discrete variable\ngenerated by a target encoder that is jointly trained with the NMT model. The\npredicted domain of target sentences are given as input to the decoder during\ntraining. At inference, we can generate diverse translations by decoding with\ndifferent domains. Unlike our strongest baseline (Shen et al., 2019), our\nmethod can scale to any number of domains without affecting the performance or\nthe training time. We assess the quality and diversity of translations\ngenerated by our model with several metrics, on three different datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:01:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lachaux", "Marie-Anne", ""], ["Joulin", "Armand", ""], ["Lample", "Guillaume", ""]]}, {"id": "2009.09761", "submitter": "Wei Ping", "authors": "Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, Bryan Catanzaro", "title": "DiffWave: A Versatile Diffusion Model for Audio Synthesis", "comments": "ICLR 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose DiffWave, a versatile diffusion probabilistic model\nfor conditional and unconditional waveform generation. The model is\nnon-autoregressive, and converts the white noise signal into structured\nwaveform through a Markov chain with a constant number of steps at synthesis.\nIt is efficiently trained by optimizing a variant of variational bound on the\ndata likelihood. DiffWave produces high-fidelity audios in different waveform\ngeneration tasks, including neural vocoding conditioned on mel spectrogram,\nclass-conditional generation, and unconditional generation. We demonstrate that\nDiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44\nversus 4.43), while synthesizing orders of magnitude faster. In particular, it\nsignificantly outperforms autoregressive and GAN-based waveform models in the\nchallenging unconditional generation task in terms of audio quality and sample\ndiversity from various automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:20:38 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 09:47:28 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 19:48:38 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Kong", "Zhifeng", ""], ["Ping", "Wei", ""], ["Huang", "Jiaji", ""], ["Zhao", "Kexin", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2009.09764", "submitter": "J\\'er\\^ome Kunegis", "authors": "J\\'er\\^ome Kunegis", "title": "Modeling the Evolution of Networks as Shrinking Structural Diversity", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews and evaluates models of network evolution based on the\nnotion of structural diversity. We show that diversity is an underlying theme\nof three principles of network evolution: the preferential attachment model,\nconnectivity and link prediction. We show that in all three cases, a dominant\ntrend towards shrinking diversity is apparent, both theoretically and\nempirically. In previous work, many kinds of different data have been modeled\nas networks: social structure, navigational structure, transport\ninfrastructure, communication, etc. Almost all these types of networks are not\nstatic structures, but instead dynamic systems that change continuously. Thus,\nan important question concerns the trends observable in these networks and\ntheir interpretation in terms of existing network models. We show in this\narticle that most numerical network characteristics follow statistically\nsignificant trends going either up or down, and that these trends can be\npredicted by considering the notion of diversity. Our work extends previous\nwork observing a shrinking network diameter to measures such as the clustering\ncoefficient, power-law exponent and random walk return probability, and\njustifies preferential attachment models and link prediction algorithms. We\nevaluate our hypothesis experimentally using a diverse collection of\ntwenty-seven temporally evolving real-world network datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:30:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kunegis", "J\u00e9r\u00f4me", ""]]}, {"id": "2009.09767", "submitter": "Resul Tugay", "authors": "Resul Tugay, Sule Gunduz Oguducu", "title": "Ranky : An Approach to Solve Distributed SVD on Large Sparse Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Value Decomposition (SVD) is a well studied research topic in many\nfields and applications from data mining to image processing. Data arising from\nthese applications can be represented as a matrix where it is large and sparse.\nMost existing algorithms are used to calculate singular values, left and right\nsingular vectors of a large-dense matrix but not large and sparse matrix. Even\nif they can find SVD of a large matrix, calculation of large-dense matrix has\nhigh time complexity due to sequential algorithms. Distributed approaches are\nproposed for computing SVD of large matrices. However, rank of the matrix is\nstill being a problem when solving SVD with these distributed algorithms. In\nthis paper we propose Ranky, set of methods to solve rank problem on large and\nsparse matrices in a distributed manner. Experimental results show that the\nRanky approach recovers singular values, singular left and right vectors of a\ngiven large and sparse matrix with negligible error.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:36:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tugay", "Resul", ""], ["Oguducu", "Sule Gunduz", ""]]}, {"id": "2009.09768", "submitter": "Santtu Tikka", "authors": "Santtu Tikka, Antti Hyttinen, Juha Karvanen", "title": "Identifying Causal Effects via Context-specific Independence Relations", "comments": "Appeared at 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal effect identification considers whether an interventional probability\ndistribution can be uniquely determined from a passively observed distribution\nin a given causal structure. If the generating system induces context-specific\nindependence (CSI) relations, the existing identification procedures and\ncriteria based on do-calculus are inherently incomplete. We show that deciding\ncausal effect non-identifiability is NP-hard in the presence of CSIs. Motivated\nby this, we design a calculus and an automated search procedure for identifying\ncausal effects in the presence of CSIs. The approach is provably sound and it\nincludes standard do-calculus as a special case. With the approach we can\nobtain identifying formulas that were unobtainable previously, and demonstrate\nthat a small number of CSI-relations may be sufficient to turn a previously\nnon-identifiable instance to identifiable.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:38:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tikka", "Santtu", ""], ["Hyttinen", "Antti", ""], ["Karvanen", "Juha", ""]]}, {"id": "2009.09780", "submitter": "Lucas Teixeira", "authors": "Lucas O. Teixeira, Rodolfo M. Pereira, Diego Bertolini, Luiz S.\n  Oliveira, Loris Nanni, George D. C. Cavalcanti, Yandre M. G. Costa", "title": "Impact of lung segmentation on the diagnosis and explanation of COVID-19\n  in chest X-ray images", "comments": "Submitted to International Journal of Universal Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic is undoubtedly one of the biggest public health crises\nour society has ever faced in recent history. One of the main complications\ncaused by COVID-19 is pneumonia, which is diagnosed using imaging exams, such\nas chest X-ray (CXR) and computed tomography (CT) scan. The CT scan is more\nprecise than the CXR. However, CXR is suitable in particular situations because\nit is cheaper, faster, more widespread, and exposes the patient to less\nradiation. This study aims to demonstrate the impact of lung segmentation in\nCOVID-19 identification using CXR images and evaluate which contents of the\nimage decisively contribute to its identification. We performed the lung\nsegmentation using a U-Net CNN architecture, and the classification using three\nwell-known CNN architectures: VGG, ResNet, and Inception. To estimate the\nimpact of lung segmentation, we applied some Explainable Artificial\nIntelligence (XAI) techniques, specifically LIME and Grad-CAM. To empirically\nevaluate our approach, we composed a database with three classes: lung opacity\n(pneumonia), COVID-19, and normal. The segmentation achieved a Jaccard distance\nof 0.034 and a Dice coefficient of 0.982. The classification using segmented\nlung achieved an F1-Score of 0.88 for the multi-class setup and 0.83 for\nCOVID-19 identification. Further testing and XAI techniques suggest that\nsegmented CXR images represent a much more realistic and less biased\nperformance. To the best of our knowledge, no other work tried to estimate the\nimpact of lung segmentation in COVID-19 identification using comprehensive XAI\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:03:54 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 11:08:55 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 10:09:45 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Teixeira", "Lucas O.", ""], ["Pereira", "Rodolfo M.", ""], ["Bertolini", "Diego", ""], ["Oliveira", "Luiz S.", ""], ["Nanni", "Loris", ""], ["Cavalcanti", "George D. C.", ""], ["Costa", "Yandre M. G.", ""]]}, {"id": "2009.09781", "submitter": "Ziming Li", "authors": "Ziming Li and Julia Kiseleva and Maarten de Rijke", "title": "Rethinking Supervised Learning and Reinforcement Learning in\n  Task-Oriented Dialogue Systems", "comments": "10 pages", "journal-ref": "Findings of EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy learning for task-oriented dialogue systems has enjoyed great\nprogress recently mostly through employing reinforcement learning methods.\nHowever, these approaches have become very sophisticated. It is time to\nre-evaluate it. Are we really making progress developing dialogue agents only\nbased on reinforcement learning? We demonstrate how (1)~traditional supervised\nlearning together with (2)~a simulator-free adversarial learning method can be\nused to achieve performance comparable to state-of-the-art RL-based methods.\nFirst, we introduce a simple dialogue action decoder to predict the appropriate\nactions. Then, the traditional multi-label classification solution for dialogue\npolicy learning is extended by adding dense layers to improve the dialogue\nagent performance. Finally, we employ the Gumbel-Softmax estimator to\nalternatively train the dialogue agent and the dialogue reward model without\nusing reinforcement learning. Based on our extensive experimentation, we can\nconclude the proposed methods can achieve more stable and higher performance\nwith fewer efforts, such as the domain knowledge required to design a user\nsimulator and the intractable parameter tuning in reinforcement learning. Our\nmain goal is not to beat reinforcement learning with supervised learning, but\nto demonstrate the value of rethinking the role of reinforcement learning and\nsupervised learning in optimizing task-oriented dialogue systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:04:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2009.09794", "submitter": "Ahmed Alharbi", "authors": "Ahmed Alharbi and Hai Dong", "title": "Subjective Metrics-based Cloud Market Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores an effective machine learning approach to predict cloud\nmarket performance for cloud consumers, providers and investors based on social\nmedia. We identified a set of comprehensive subjective metrics that may affect\ncloud market performance via literature survey. We used a popular sentiment\nanalysis technique to process customer reviews collected from social media.\nCloud market revenue growth was selected as an indicator of cloud market\nperformance. We considered the revenue growth of Amazon Web Services as the\nstakeholder of our experiments. Three machine learning models were selected:\nlinear regression, artificial neural network, and support vector machine. These\nmodels were compared with a time series prediction model. We found that the set\nof subjective metrics is able to improve the prediction performance for all the\nmodels. The support vector machine showed the best prediction results compared\nto the other models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:18:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Alharbi", "Ahmed", ""], ["Dong", "Hai", ""]]}, {"id": "2009.09796", "submitter": "Michael Crawshaw", "authors": "Michael Crawshaw", "title": "Multi-Task Learning with Deep Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) is a subfield of machine learning in which multiple\ntasks are simultaneously learned by a shared model. Such approaches offer\nadvantages like improved data efficiency, reduced overfitting through shared\nrepresentations, and fast learning by leveraging auxiliary information.\nHowever, the simultaneous learning of multiple tasks presents new design and\noptimization challenges, and choosing which tasks should be learned jointly is\nin itself a non-trivial problem. In this survey, we give an overview of\nmulti-task learning methods for deep neural networks, with the aim of\nsummarizing both the well-established and most recent directions within the\nfield. Our discussion is structured according to a partition of the existing\ndeep MTL techniques into three groups: architectures, optimization methods, and\ntask relationship learning. We also provide a summary of common multi-task\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:31:04 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Crawshaw", "Michael", ""]]}, {"id": "2009.09799", "submitter": "Jaehyuk Park", "authors": "Jaehyuk Park, Morgan R. Frank, Lijun Sun, Hyejin Youn", "title": "Industrial Topics in Urban Labor System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorization is an essential component for us to understand the world for\nourselves and to communicate it collectively. It is therefore important to\nrecognize that classification system are not necessarily static, especially for\neconomic systems, and even more so in urban areas where most innovation takes\nplace and is implemented. Out-of-date classification systems would potentially\nlimit further understanding of the current economy because things constantly\nchange. Here, we develop an occupation-based classification system for the US\nlabor economy, called industrial topics, that satisfy adaptability and\nrepresentability. By leveraging the distributions of occupations across the US\nurban areas, we identify industrial topics - clusters of occupations based on\ntheir co-existence pattern. Industrial topics indicate the mechanisms under the\nsystematic allocation of different occupations. Considering the densely\nconnected occupations as an industrial topic, our approach characterizes\nregional economies by their topical composition. Unlike the existing\nsurvey-based top-down approach, our method provides timely information about\nthe underlying structure of the regional economy, which is critical for\npolicymakers and business leaders, especially in our fast-changing economy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:07:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Park", "Jaehyuk", ""], ["Frank", "Morgan R.", ""], ["Sun", "Lijun", ""], ["Youn", "Hyejin", ""]]}, {"id": "2009.09803", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Usman Roshan", "title": "Defending against substitute model black box adversarial attacks with\n  the 01 loss", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.07800;\n  text overlap with arXiv:2008.09148", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Substitute model black box attacks can create adversarial examples for a\ntarget model just by accessing its output labels. This poses a major challenge\nto machine learning models in practice, particularly in security sensitive\napplications. The 01 loss model is known to be more robust to outliers and\nnoise than convex models that are typically used in practice. Motivated by\nthese properties we present 01 loss linear and 01 loss dual layer neural\nnetwork models as a defense against transfer based substitute model black box\nattacks. We compare the accuracy of adversarial examples from substitute model\nblack box attacks targeting our 01 loss models and their convex counterparts\nfor binary classification on popular image benchmarks. Our 01 loss dual layer\nneural network has an adversarial accuracy of 66.2%, 58%, 60.5%, and 57% on\nMNIST, CIFAR10, STL10, and ImageNet respectively whereas the sigmoid activated\nlogistic loss counterpart has accuracies of 63.5%, 19.3%, 14.9%, and 27.6%.\nExcept for MNIST the convex counterparts have substantially lower adversarial\naccuracies. We show practical applications of our models to deter traffic sign\nand facial recognition adversarial attacks. On GTSRB street sign and CelebA\nfacial detection our 01 loss network has 34.6% and 37.1% adversarial accuracy\nrespectively whereas the convex logistic counterpart has accuracy 24% and 1.9%.\nFinally we show that our 01 loss network can attain robustness on par with\nsimple convolutional neural networks and much higher than its convex\ncounterpart even when attacked with a convolutional network substitute model.\nOur work shows that 01 loss models offer a powerful defense against substitute\nmodel black box attacks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 22:32:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Roshan", "Usman", ""]]}, {"id": "2009.09805", "submitter": "Shuang Ma", "authors": "Shuang Ma, Zhaoyang Zeng, Daniel McDuff, Yale Song", "title": "Active Contrastive Learning of Audio-Visual Video Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning has been shown to produce generalizable representations\nof audio and visual data by maximizing the lower bound on the mutual\ninformation (MI) between different views of an instance. However, obtaining a\ntight lower bound requires a sample size exponential in MI and thus a large set\nof negative samples. We can incorporate more samples by building a large\nqueue-based dictionary, but there are theoretical limits to performance\nimprovements even with a large number of negative samples. We hypothesize that\n\\textit{random negative sampling} leads to a highly redundant dictionary that\nresults in suboptimal representations for downstream tasks. In this paper, we\npropose an active contrastive learning approach that builds an \\textit{actively\nsampled} dictionary with diverse and informative items, which improves the\nquality of negative samples and improves performances on tasks where there is\nhigh mutual information in the data, e.g., video classification. Our model\nachieves state-of-the-art performance on challenging audio and visual\ndownstream benchmarks including UCF101, HMDB51 and ESC50.\\footnote{Code is\navailable at: \\url{https://github.com/yunyikristy/CM-ACC}}\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:18:30 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 22:16:18 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ma", "Shuang", ""], ["Zeng", "Zhaoyang", ""], ["McDuff", "Daniel", ""], ["Song", "Yale", ""]]}, {"id": "2009.09811", "submitter": "Anurag Sarkar", "authors": "Zhihan Yang, Anurag Sarkar, Seth Cooper", "title": "Game Level Clustering and Generation using Gaussian Mixture VAEs", "comments": "6 pages, 5 figures, 16th AAAI Conference on Artificial Intelligence\n  and Interactive Digital Entertainment (AIIDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have been shown to be able to generate game\nlevels but require manual exploration of the learned latent space to generate\noutputs with desired attributes. While conditional VAEs address this by\nallowing generation to be conditioned on labels, such labels have to be\nprovided during training and thus require prior knowledge which may not always\nbe available. In this paper, we apply Gaussian Mixture VAEs (GMVAEs), a variant\nof the VAE which imposes a mixture of Gaussians (GM) on the latent space,\nunlike regular VAEs which impose a unimodal Gaussian. This allows GMVAEs to\ncluster levels in an unsupervised manner using the components of the GM and\nthen generate new levels using the learned components. We demonstrate our\napproach with levels from Super Mario Bros., Kid Icarus and Mega Man. Our\nresults show that the learned components discover and cluster level structures\nand patterns and can be used to generate levels with desired characteristics.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 15:07:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yang", "Zhihan", ""], ["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2009.09822", "submitter": "Kwei-Herng Lai", "authors": "Kwei-Herng Lai, Daochen Zha, Guanchu Wang, Junjie Xu, Yue Zhao, Devesh\n  Kumar, Yile Chen, Purav Zumkhawaka, Minyang Wan, Diego Martinez, Xia Hu", "title": "TODS: An Automated Time Series Outlier Detection System", "comments": "Accepted by AAAI'21 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TODS, an automated Time Series Outlier Detection System for\nresearch and industrial applications. TODS is a highly modular system that\nsupports easy pipeline construction. The basic building block of TODS is\nprimitive, which is an implementation of a function with hyperparameters. TODS\ncurrently supports 70 primitives, including data processing, time series\nprocessing, feature analysis, detection algorithms, and a reinforcement module.\nUsers can freely construct a pipeline using these primitives and perform end-\nto-end outlier detection with the constructed pipeline. TODS provides a\nGraphical User Interface (GUI), where users can flexibly design a pipeline with\ndrag-and-drop. Moreover, a data-driven searcher is provided to automatically\ndiscover the most suitable pipelines given a dataset. TODS is released under\nApache 2.0 license at https://github.com/datamllab/tods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:36:43 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:21:31 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 00:00:47 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lai", "Kwei-Herng", ""], ["Zha", "Daochen", ""], ["Wang", "Guanchu", ""], ["Xu", "Junjie", ""], ["Zhao", "Yue", ""], ["Kumar", "Devesh", ""], ["Chen", "Yile", ""], ["Zumkhawaka", "Purav", ""], ["Wan", "Minyang", ""], ["Martinez", "Diego", ""], ["Hu", "Xia", ""]]}, {"id": "2009.09823", "submitter": "Matthias Karlbauer", "authors": "Matthias Karlbauer, Tobias Menge, Sebastian Otte, Hendrik P.A. Lensch,\n  Thomas Scholten, Volker Wulfmeyer, and Martin V. Butz", "title": "Hidden Latent State Inference in a Spatio-Temporal Generative Model", "comments": "As submitted to the 35th conference of the Association for the\n  Advancement of Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of the hidden factors that determine particular system dynamics is\ncrucial for both explaining them and pursuing goal-directed, interventional\nactions. The inference of these factors without supervision given time series\ndata remains an open challenge. Here, we focus on spatio-temporal processes,\nincluding wave propagations and weather dynamics, and assume that universal\ncauses (e.g. physics) apply throughout space and time. We apply a novel\nDIstributed, Spatio-Temporal graph Artificial Neural network Architecture,\nDISTANA, which learns a generative model in such domains. DISTANA requires\nfewer parameters, and yields more accurate predictions than temporal\nconvolutional neural networks and other related approaches on a 2D circular\nwave prediction task. We show that DISTANA, when combined with a retrospective\nlatent state inference principle called active tuning, can reliably derive\nhidden local causal factors. In a current weather prediction benchmark, DISTANA\ninfers our planet's land-sea mask solely by observing temperature dynamics and\nuses the self inferred information to improve its own prediction of\ntemperature. We are convinced that the retrospective inference of latent states\nin generative RNN architectures will play an essential role in future research\non causal inference and explainable systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:59:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Karlbauer", "Matthias", ""], ["Menge", "Tobias", ""], ["Otte", "Sebastian", ""], ["Lensch", "Hendrik P. A.", ""], ["Scholten", "Thomas", ""], ["Wulfmeyer", "Volker", ""], ["Butz", "Martin V.", ""]]}, {"id": "2009.09826", "submitter": "Hengjun Zhao", "authors": "Hengjun Zhao, Xia Zeng, Taolue Chen, Zhiming Liu and Jim Woodcock", "title": "Learning Safe Neural Network Controllers with Barrier Certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel approach to synthesize controllers for nonlinear\ncontinuous dynamical systems with control against safety properties. The\ncontrollers are based on neural networks (NNs). To certify the safety property\nwe utilize barrier functions, which are represented by NNs as well. We train\nthe controller-NN and barrier-NN simultaneously, achieving a\nverification-in-the-loop synthesis. We provide a prototype tool nncontroller\nwith a number of case studies. The experiment results confirm the feasibility\nand efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:55:55 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Hengjun", ""], ["Zeng", "Xia", ""], ["Chen", "Taolue", ""], ["Liu", "Zhiming", ""], ["Woodcock", "Jim", ""]]}, {"id": "2009.09827", "submitter": "Lukas Hirsch", "authors": "Lukas Hirsch, MS, Yu Huang, PhD, Shaojun Luo, PhD, Carolina Rossi\n  Saccarelli, MD, Roberto Lo Gullo, MD, Isaac Daimiel Naranjo, MD, Almir G.V.\n  Bitencourt, PhD, Natsuko Onishi, MD, PhD, Eun Sook Ko, PhD, Dortis Leithner,\n  MD, Daly Avendano, MD, Sarah Eskreis-Winkler, MD, PhD, Mary Hughes, MD, Danny\n  F. Martinez, MS, Katja Pinker, MD, PhD, Krishna Juluru, MD, Amin E.\n  El-Rowmeim, MS, MA, Pierre Elnajjar, MS, Hedvig Hricak, MD, Elizabeth A.\n  Morris, MD, Hernan A. Makse, PhD, Lucas C Parra, PhD, Elizabeth J. Sutton, MD", "title": "Deep learning achieves radiologist-level performance of tumor\n  segmentation in breast MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.med-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Purpose: The goal of this research was to develop a deep network architecture\nthat achieves fully-automated radiologist-level segmentation of breast tumors\nin MRI.\n  Materials and Methods: We leveraged 38,229 clinical MRI breast exams\ncollected retrospectively from women aged 12-94 (mean age 54) who presented\nbetween 2002 and 2014 at a single clinical site. The training set for the\nnetwork consisted of 2,555 malignant breasts that were segmented in 2D by\nexperienced radiologists, as well as 60,108 benign breasts that served as\nnegative controls. The test set consisted of 250 exams with tumors segmented\nindependently by four radiologists. We selected among several 3D deep\nconvolutional neural network architectures, input modalities and harmonization\nmethods. The outcome measure was the Dice score for 2D segmentation, and was\ncompared between the network and radiologists using the Wilcoxon signed-rank\ntest and the TOST procedure.\n  Results: The best-performing network on the training set was a volumetric\nU-Net with contrast enhancement dynamic as input and with intensity normalized\nfor each exam. In the test set the median Dice score of this network was 0.77.\nThe performance of the network was equivalent to that of the radiologists (TOST\nprocedure with radiologist performance of 0.69-0.84 as equivalence bounds: p =\n5e-10 and p = 2e-5, respectively; N = 250) and compares favorably with\npublished state of the art (0.6-0.77).\n  Conclusion: When trained on a dataset of over 60 thousand breasts, a\nvolumetric U-Net performs as well as expert radiologists at segmenting\nmalignant breast lesions in MRI.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:07:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hirsch", "Lukas", ""], ["MS", "", ""], ["Huang", "Yu", ""], ["PhD", "", ""], ["Luo", "Shaojun", ""], ["PhD", "", ""], ["Saccarelli", "Carolina Rossi", ""], ["MD", "", ""], ["Gullo", "Roberto Lo", ""], ["MD", "", ""], ["Naranjo", "Isaac Daimiel", ""], ["MD", "", ""], ["Bitencourt", "Almir G. V.", ""], ["PhD", "", ""], ["Onishi", "Natsuko", ""], ["MD", "", ""], ["PhD", "", ""], ["Ko", "Eun Sook", ""], ["PhD", "", ""], ["Leithner", "Dortis", ""], ["MD", "", ""], ["Avendano", "Daly", ""], ["MD", "", ""], ["Eskreis-Winkler", "Sarah", ""], ["MD", "", ""], ["PhD", "", ""], ["Hughes", "Mary", ""], ["MD", "", ""], ["Martinez", "Danny F.", ""], ["MS", "", ""], ["Pinker", "Katja", ""], ["MD", "", ""], ["PhD", "", ""], ["Juluru", "Krishna", ""], ["MD", "", ""], ["El-Rowmeim", "Amin E.", ""], ["MS", "", ""], ["MA", "", ""], ["Elnajjar", "Pierre", ""], ["MS", "", ""], ["Hricak", "Hedvig", ""], ["MD", "", ""], ["Morris", "Elizabeth A.", ""], ["MD", "", ""], ["Makse", "Hernan A.", ""], ["PhD", "", ""], ["Parra", "Lucas C", ""], ["PhD", "", ""], ["Sutton", "Elizabeth J.", ""], ["MD", "", ""]]}, {"id": "2009.09829", "submitter": "Zhao Song", "authors": "Jason D. Lee, Ruoqi Shen, Zhao Song, Mengdi Wang, Zheng Yu", "title": "Generalized Leverage Score Sampling for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Leverage score sampling is a powerful technique that originates from\ntheoretical computer science, which can be used to speed up a large number of\nfundamental questions, e.g. linear regression, linear programming,\nsemi-definite programming, cutting plane method, graph sparsification, maximum\nmatching and max-flow. Recently, it has been shown that leverage score sampling\nhelps to accelerate kernel methods [Avron, Kapralov, Musco, Musco, Velingker\nand Zandieh 17].\n  In this work, we generalize the results in [Avron, Kapralov, Musco, Musco,\nVelingker and Zandieh 17] to a broader class of kernels. We further bring the\nleverage score sampling into the field of deep learning theory.\n  $\\bullet$ We show the connection between the initialization for neural\nnetwork training and approximating the neural tangent kernel with random\nfeatures.\n  $\\bullet$ We prove the equivalence between regularized neural network and\nneural tangent kernel ridge regression under the initialization of both\nclassical random Gaussian and leverage score sampling.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:46:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lee", "Jason D.", ""], ["Shen", "Ruoqi", ""], ["Song", "Zhao", ""], ["Wang", "Mengdi", ""], ["Yu", "Zheng", ""]]}, {"id": "2009.09835", "submitter": "Pan Zhou", "authors": "Pan Zhou, Xiaotong Yuan", "title": "Hybrid Stochastic-Deterministic Minibatch Proximal Gradient:\n  Less-Than-Single-Pass Optimization with Nearly Optimal Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance-reduced gradient (SVRG) algorithms have been shown to\nwork favorably in solving large-scale learning problems. Despite the remarkable\nsuccess, the stochastic gradient complexity of SVRG-type algorithms usually\nscales linearly with data size and thus could still be expensive for huge data.\nTo address this deficiency, we propose a hybrid stochastic-deterministic\nminibatch proximal gradient (HSDMPG) algorithm for strongly-convex problems\nthat enjoys provably improved data-size-independent complexity guarantees. More\nprecisely, for quadratic loss $F(\\theta)$ of $n$ components, we prove that\nHSDMPG can attain an $\\epsilon$-optimization-error\n$\\mathbb{E}[F(\\theta)-F(\\theta^*)]\\leq\\epsilon$ within\n$\\mathcal{O}\\Big(\\frac{\\kappa^{1.5}\\epsilon^{0.75}\\log^{1.5}(\\frac{1}{\\epsilon})+1}{\\epsilon}\\wedge\\Big(\\kappa\n\\sqrt{n}\\log^{1.5}\\big(\\frac{1}{\\epsilon}\\big)+n\\log\\big(\\frac{1}{\\epsilon}\\big)\\Big)\\Big)$\nstochastic gradient evaluations, where $\\kappa$ is condition number. For\ngeneric strongly convex loss functions, we prove a nearly identical complexity\nbound though at the cost of slightly increased logarithmic factors. For\nlarge-scale learning problems, our complexity bounds are superior to those of\nthe prior state-of-the-art SVRG algorithms with or without dependence on data\nsize. Particularly, in the case of $\\epsilon=\\mathcal{O}\\big(1/\\sqrt{n}\\big)$\nwhich is at the order of intrinsic excess error bound of a learning model and\nthus sufficient for generalization, the stochastic gradient complexity bounds\nof HSDMPG for quadratic and generic loss functions are respectively\n$\\mathcal{O} (n^{0.875}\\log^{1.5}(n))$ and $\\mathcal{O}\n(n^{0.875}\\log^{2.25}(n))$, which to our best knowledge, for the first time\nachieve optimal generalization in less than a single pass over data. Extensive\nnumerical results demonstrate the computational advantages of our algorithm\nover the prior ones.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:18:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhou", "Pan", ""], ["Yuan", "Xiaotong", ""]]}, {"id": "2009.09841", "submitter": "Zifeng Wang", "authors": "Zifeng Wang, Rui Wen, Xi Chen, Shao-Lun Huang, Ningyu Zhang, Yefeng\n  Zheng", "title": "Finding Influential Instances for Distantly Supervised Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision has been demonstrated to be highly beneficial to enhance\nrelation extraction models, but it often suffers from high label noise. In this\nwork, we propose a novel model-agnostic instance subsampling method for\ndistantly supervised relation extraction, namely REIF, which bridges the gap of\nrealizing influence subsampling in deep learning. It encompasses two key steps:\nfirst calculating instance-level influences that measure how much each training\ninstance contributes to the validation loss change of our model, then deriving\nsampling probabilities via the proposed sigmoid sampling function to perform\nbatch-in-bag sampling. We design a fast influence subsampling scheme that\nreduces the computational complexity from O(mn) to O(1), and analyze its\nrobustness when the sigmoid sampling function is employed. Empirical\nexperiments demonstrate our method's superiority over the baselines, and its\nability to support interpretable instance selection.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:02:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Zifeng", ""], ["Wen", "Rui", ""], ["Chen", "Xi", ""], ["Huang", "Shao-Lun", ""], ["Zhang", "Ningyu", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.09842", "submitter": "Karush Suri", "authors": "Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn", "title": "Energy-based Surprise Minimization for Multi-Agent Value Factorization", "comments": "Preprint, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) has demonstrated significant\nsuccess in training decentralised policies in a centralised manner by making\nuse of value factorization methods. However, addressing surprise across\nspurious states and approximation bias remain open problems for multi-agent\nsettings. Towards this goal, we introduce the Energy-based MIXer (EMIX), an\nalgorithm which minimizes surprise utilizing the energy across agents. Our\ncontributions are threefold; (1) EMIX introduces a novel surprise minimization\ntechnique across multiple agents in the case of multi-agent\npartially-observable settings. (2) EMIX highlights a practical use of energy\nfunctions in MARL with theoretical guarantees and experiment validations of the\nenergy operator. Lastly, (3) EMIX extends Maxmin Q-learning for addressing\noverestimation bias across agents in MARL. In a study of challenging StarCraft\nII micromanagement scenarios, EMIX demonstrates consistent stable performance\nfor multiagent surprise minimization. Moreover, our ablation study highlights\nthe necessity of the energy-based scheme and the need for elimination of\noverestimation bias in MARL. Our implementation of EMIX can be found at\nkarush17.github.io/emix-web/.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:42:42 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:26:43 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 16:10:26 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 03:06:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suri", "Karush", ""], ["Shi", "Xiao Qi", ""], ["Plataniotis", "Konstantinos", ""], ["Lawryshyn", "Yuri", ""]]}, {"id": "2009.09849", "submitter": "Marcus Kalander", "authors": "Marcus Kalander, Min Zhou, Chengzhi Zhang, Hanling Yi, Lujia Pan", "title": "Spatio-Temporal Hybrid Graph Convolutional Network for Traffic\n  Forecasting in Telecommunication Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telecommunication networks play a critical role in modern society. With the\narrival of 5G networks, these systems are becoming even more diversified,\nintegrated, and intelligent. Traffic forecasting is one of the key components\nin such a system, however, it is particularly challenging due to the complex\nspatial-temporal dependency. In this work, we consider this problem from the\naspect of a cellular network and the interactions among its base stations. We\nthoroughly investigate the characteristics of cellular network traffic and shed\nlight on the dependency complexities based on data collected from a densely\npopulated metropolis area. Specifically, we observe that the traffic shows both\ndynamic and static spatial dependencies as well as diverse cyclic temporal\npatterns. To address these complexities, we propose an effective\ndeep-learning-based approach, namely, Spatio-Temporal Hybrid Graph\nConvolutional Network (STHGCN). It employs GRUs to model the temporal\ndependency, while capturing the complex spatial dependency through a hybrid-GCN\nfrom three perspectives: spatial proximity, functional similarity, and recent\ntrend similarity. We conduct extensive experiments on real-world traffic\ndatasets collected from telecommunication networks. Our experimental results\ndemonstrate the superiority of the proposed model in that it consistently\noutperforms both classical methods and state-of-the-art deep learning models,\nwhile being more robust and stable.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:54:16 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kalander", "Marcus", ""], ["Zhou", "Min", ""], ["Zhang", "Chengzhi", ""], ["Yi", "Hanling", ""], ["Pan", "Lujia", ""]]}, {"id": "2009.09875", "submitter": "Pritish Chandna", "authors": "Pritish Chandna, Helena Cuesta and Emilia G\\'omez", "title": "A Deep Learning Based Analysis-Synthesis Framework For Unison Singing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unison singing is the name given to an ensemble of singers simultaneously\nsinging the same melody and lyrics. While each individual singer in a unison\nsings the same principle melody, there are slight timing and pitch deviations\nbetween the singers, which, along with the ensemble of timbres, give the\nlistener a perceived sense of \"unison\". In this paper, we present a study of\nunison singing in the context of choirs; utilising some recently proposed\ndeep-learning based methodologies, we analyse the fundamental frequency (F0)\ndistribution of the individual singers in recordings of unison mixtures. Based\non the analysis, we propose a system for synthesising a unison signal from an a\ncappella input and a single voice prototype representative of a unison mixture.\nWe use subjective listening tests to evaluate perceptual factors of our\nproposed system for synthesis, including quality, adherence to the melody as\nwell the degree of perceived unison.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:48:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chandna", "Pritish", ""], ["Cuesta", "Helena", ""], ["G\u00f3mez", "Emilia", ""]]}, {"id": "2009.09878", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Christoph-Nikolas Straehle, Mario Fritz, Bernt\n  Schiele", "title": "Haar Wavelet based Block Autoregressive Flows for Trajectories", "comments": "German Conference on Pattern Recognition, 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of trajectories such as that of pedestrians is crucial to the\nperformance of autonomous agents. While previous works have leveraged\nconditional generative models like GANs and VAEs for learning the likely future\ntrajectories, accurately modeling the dependency structure of these multimodal\ndistributions, particularly over long time horizons remains challenging.\nNormalizing flow based generative models can model complex distributions\nadmitting exact inference. These include variants with split coupling\ninvertible transformations that are easier to parallelize compared to their\nautoregressive counterparts. To this end, we introduce a novel Haar wavelet\nbased block autoregressive model leveraging split couplings, conditioned on\ncoarse trajectories obtained from Haar wavelet based transformations at\ndifferent levels of granularity. This yields an exact inference method that\nmodels trajectories at different spatio-temporal resolutions in a hierarchical\nmanner. We illustrate the advantages of our approach for generating diverse and\naccurate trajectories on two real-world datasets - Stanford Drone and\nIntersection Drone.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:57:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Straehle", "Christoph-Nikolas", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "2009.09893", "submitter": "R. Ian Etheredge", "authors": "R. Ian Etheredge, Manfred Schartl, Alex Jordan", "title": "Decontextualized learning for interpretable hierarchical representations\n  of visual patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apart from discriminative models for classification and object detection\ntasks, the application of deep convolutional neural networks to basic research\nutilizing natural imaging data has been somewhat limited; particularly in cases\nwhere a set of interpretable features for downstream analysis is needed, a key\nrequirement for many scientific investigations. We present an algorithm and\ntraining paradigm designed specifically to address this: decontextualized\nhierarchical representation learning (DHRL). By combining a generative model\nchaining procedure with a ladder network architecture and latent space\nregularization for inference, DHRL address the limitations of small datasets\nand encourages a disentangled set of hierarchically organized features. In\naddition to providing a tractable path for analyzing complex hierarchal\npatterns using variation inference, this approach is generative and can be\ndirectly combined with empirical and theoretical approaches. To highlight the\nextensibility and usefulness of DHRL, we demonstrate this method in application\nto a question from evolutionary biology.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:47:55 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Etheredge", "R. Ian", ""], ["Schartl", "Manfred", ""], ["Jordan", "Alex", ""]]}, {"id": "2009.09899", "submitter": "Jacob Householder", "authors": "Jacob Householder, Andrew Householder, John Paul Gomez-Reed, Fredrick\n  Park, Shuai Zhang", "title": "Clustering COVID-19 Lung Scans", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent outbreak of COVID-19, creating a means to stop it's spread\nand eventually develop a vaccine are the most important and challenging tasks\nthat the scientific community is facing right now. The first step towards these\ngoals is to correctly identify a patient that is infected with the virus. Our\ngroup applied an unsupervised machine learning technique to identify COVID-19\ncases. This is an important topic as COVID-19 is a novel disease currently\nbeing studied in detail and our methodology has the potential to reveal\nimportant differences between it and other viral pneumonia. This could then, in\nturn, enable doctors to more confidently help each patient. Our experiments\nutilize Principal Component Analysis (PCA), t-distributed Stochastic Neighbor\nEmbedding (t-SNE), and the recently developed Robust Continuous Clustering\nalgorithm (RCC). We display the performance of RCC in identifying COVID-19\npatients and its ability to compete with other unsupervised algorithms, namely\nK-Means++ (KM++). Using a COVID-19 Radiography dataset, we found that RCC\noutperformed KM++; we used the Adjusted Mutual Information Score (AMI) in order\nto measure the effectiveness of both algorithms. The AMI for the two and three\nclass cases of KM++ were 0.0250 and 0.054, respectively. In comparison, RCC\nscored 0.5044 in the two class case and 0.267 in the three class case, clearly\nshowing RCC as the superior algorithm. This not only opens new possible\napplications of RCC, but it could potentially aid in the creation of a new tool\nfor COVID-19 identification.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 00:21:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Householder", "Jacob", ""], ["Householder", "Andrew", ""], ["Gomez-Reed", "John Paul", ""], ["Park", "Fredrick", ""], ["Zhang", "Shuai", ""]]}, {"id": "2009.09908", "submitter": "Aleksandr Beznosikov", "authors": "Abdurakhmon Sadiev, Aleksandr Beznosikov, Pavel Dvurechensky,\n  Alexander Gasnikov", "title": "Zeroth-Order Algorithms for Smooth Saddle-Point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saddle-point problems have recently gained increased attention from the\nmachine learning community, mainly due to applications in training Generative\nAdversarial Networks using stochastic gradients. At the same time, in some\napplications only a zeroth-order oracle is available. In this paper, we propose\nseveral algorithms to solve stochastic smooth (strongly) convex-concave\nsaddle-point problems using zeroth-order oracles and estimate their convergence\nrate and its dependence on the dimension $n$ of the variable. In particular,\nour analysis shows that in the case when the feasible set is a direct product\nof two simplices, our convergence rate for the stochastic term is only by a\n$\\log n$ factor worse than for the first-order methods. We also consider a\nmixed setup and develop 1/2th-order methods that use zeroth-order oracle for\nthe minimization part and first-order oracle for the maximization part.\nFinally, we demonstrate the practical performance of our zeroth-order and\n1/2th-order methods on practical problems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:26:48 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 19:13:00 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sadiev", "Abdurakhmon", ""], ["Beznosikov", "Aleksandr", ""], ["Dvurechensky", "Pavel", ""], ["Gasnikov", "Alexander", ""]]}, {"id": "2009.09914", "submitter": "Talayeh Aledavood", "authors": "Talayeh Aledavood, Ilkka Kivim\\\"aki, Sune Lehmann, and Jari Saram\\\"aki", "title": "A Non-negative Matrix Factorization Based Method for Quantifying Rhythms\n  of Activity and Sleep and Chronotypes Using Mobile Phone Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activities follow daily, weekly, and seasonal rhythms. The emergence of\nthese rhythms is related to physiology and natural cycles as well as social\nconstructs. The human body and biological functions undergo near 24-hour\nrhythms (circadian rhythms). The frequency of these rhythms is more or less\nsimilar across people, but its phase is different. In the chronobiology\nliterature, based on the propensity to sleep at different hours of the day,\npeople are categorized into morning-type, evening-type, and intermediate-type\ngroups called \\textit{chronotypes}. This typology is typically based on\ncarefully designed questionnaires or manually crafted features drawing on data\non timings of people's activity. Here we develop a fully data-driven\n(unsupervised) method to decompose individual temporal activity patterns into\ncomponents. This has the advantage of not including any predetermined\nassumptions about sleep and activity hours, but the results are fully\ncontext-dependent and determined by the most prominent features of the activity\ndata. Using a year-long dataset from mobile phone screen usage logs of 400\npeople, we find four emergent temporal components: morning activity, night\nactivity, evening activity and activity at noon. Individual behavior can be\nreduced to weights on these four components. We do not observe any clear\nemergent categories of people based on the weights, but individuals are rather\nplaced on a continuous spectrum according to the timings of their activities.\nHigh loads on morning and night components highly correlate with going to bed\nand waking up times. Our work points towards a data-driven way of categorizing\npeople based on their full daily and weekly rhythms of activity and behavior,\nrather than focusing mainly on the timing of their sleeping periods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:33:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Aledavood", "Talayeh", ""], ["Kivim\u00e4ki", "Ilkka", ""], ["Lehmann", "Sune", ""], ["Saram\u00e4ki", "Jari", ""]]}, {"id": "2009.09919", "submitter": "Eric Alcaide", "authors": "Eric Alcaide", "title": "Improving Graph Property Prediction with Generalized Readout Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph property prediction is drawing increasing attention in the recent years\ndue to the fact that graphs are one of the most general data structures since\nthey can contain an arbitrary number of nodes and connections between them, and\nit is the backbone for many different tasks like classification and regression\non such kind of data (networks, molecules, knowledge bases, ...). We introduce\na novel generalized global pooling layer to mitigate the information loss that\ntypically occurs at the Readout phase in Message-Passing Neural Networks. This\nnovel layer is parametrized by two values ($\\beta$ and $p$) which can\noptionally be learned, and the transformation it performs can revert to several\nalready popular readout functions (mean, max and sum) under certain settings,\nwhich can be specified. To showcase the superior expressiveness and performance\nof this novel technique, we test it in a popular graph property prediction task\nby taking the current best-performing architecture and using our readout layer\nas a drop-in replacement and we report new state of the art results. The code\nto reproduce the experiments can be accessed here:\nhttps://github.com/EricAlcaide/generalized-readout-phase\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:41:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Alcaide", "Eric", ""]]}, {"id": "2009.09922", "submitter": "Tao Bai", "authors": "Tao Bai, Jinnan Chen, Jun Zhao, Bihan Wen, Xudong Jiang, Alex Kot", "title": "Feature Distillation With Guided Adversarial Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are shown to be vulnerable to adversarial examples.\nThough adversarial training can enhance model robustness, typical approaches\nare computationally expensive. Recent works proposed to transfer the robustness\nto adversarial attacks across different tasks or models with soft\nlabels.Compared to soft labels, feature contains rich semantic information and\nholds the potential to be applied to different downstream tasks. In this paper,\nwe propose a novel approach called Guided Adversarial Contrastive Distillation\n(GACD), to effectively transfer adversarial robustness from teacher to student\nwith features. We first formulate this objective as contrastive learning and\nconnect it with mutual information. With a well-trained teacher model as an\nanchor, students are expected to extract features similar to the teacher. Then\nconsidering the potential errors made by teachers, we propose sample reweighted\nestimation to eliminate the negative effects from teachers. With GACD, the\nstudent not only learns to extract robust features, but also captures\nstructural knowledge from the teacher. By extensive experiments evaluating over\npopular datasets such as CIFAR-10, CIFAR-100 and STL-10, we demonstrate that\nour approach can effectively transfer robustness across different models and\neven different tasks, and achieve comparable or better results than existing\nmethods. Besides, we provide a detailed analysis of various methods, showing\nthat students produced by our approach capture more structural knowledge from\nteachers and learn more robust features under adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:46:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bai", "Tao", ""], ["Chen", "Jinnan", ""], ["Zhao", "Jun", ""], ["Wen", "Bihan", ""], ["Jiang", "Xudong", ""], ["Kot", "Alex", ""]]}, {"id": "2009.09924", "submitter": "Peyman Moghadam", "authors": "Scarlett Raine, Ross Marchant, Peyman Moghadam, Frederic Maire, Brett\n  Kettle, Brano Kusy", "title": "Multi-species Seagrass Detection and Classification from Underwater\n  Images", "comments": "Accepted to DICTA 2020. project page is at:\n  https://github.com/csiro-robotics/deepseagrass", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underwater surveys conducted using divers or robots equipped with customized\ncamera payloads can generate a large number of images. Manual review of these\nimages to extract ecological data is prohibitive in terms of time and cost,\nthus providing strong incentive to automate this process using machine learning\nsolutions. In this paper, we introduce a multi-species detector and classifier\nfor seagrasses based on a deep convolutional neural network (achieved an\noverall accuracy of 92.4%). We also introduce a simple method to\nsemi-automatically label image patches and therefore minimize manual labelling\nrequirement. We describe and release publicly the dataset collected in this\nstudy as well as the code and pre-trained models to replicate our experiments\nat: https://github.com/csiro-robotics/deepseagrass\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:20:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Raine", "Scarlett", ""], ["Marchant", "Ross", ""], ["Moghadam", "Peyman", ""], ["Maire", "Frederic", ""], ["Kettle", "Brett", ""], ["Kusy", "Brano", ""]]}, {"id": "2009.09925", "submitter": "Yongcan Cao", "authors": "Feng Tao, Rengan Suresh, Johnathan Votion, and Yongcan Cao", "title": "Graph Based Multi-layer K-means++ (G-MLKM) for Sensory Pattern Analysis\n  in Constrained Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on developing a novel unsupervised machine learning\nalgorithm, named graph based multi-layer k-means++ (G-MLKM), to solve\ndata-target association problem when targets move on a constrained space and\nminimal information of the targets can be obtained by sensors. Instead of\nemploying the traditional data-target association methods that are based on\nstatistical probabilities, the G-MLKM solves the problem via data clustering.\nWe first will develop the Multi-layer K-means++ (MLKM) method for data-target\nassociation at local space given a simplified constrained space situation. Then\na p-dual graph is proposed to represent the general constrained space when\nlocal spaces are interconnected. Based on the dual graph and graph theory, we\nthen generalize MLKM to G-MLKM by first understanding local data-target\nassociation and then extracting cross-local data-target association\nmathematically analyze the data association at intersections of that space. To\nexclude potential data-target association errors that disobey physical rules,\nwe also develop error correction mechanisms to further improve the accuracy.\nNumerous simulation examples are conducted to demonstrate the performance of\nG-MLKM.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:52:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tao", "Feng", ""], ["Suresh", "Rengan", ""], ["Votion", "Johnathan", ""], ["Cao", "Yongcan", ""]]}, {"id": "2009.09926", "submitter": "Po Li", "authors": "Po Li, Lei Li, Yan Fu, Jun Rong, Yu Zhang", "title": "Cross-Modal Alignment with Mixture Experts Neural Network for\n  Intral-City Retail Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Cross-modal Alignment with mixture experts Neural\nNetwork (CameNN) recommendation model for intral-city retail industry, which\naims to provide fresh foods and groceries retailing within 5 hours delivery\nservice arising for the outbreak of Coronavirus disease (COVID-19) pandemic\naround the world. We propose CameNN, which is a multi-task model with three\ntasks including Image to Text Alignment (ITA) task, Text to Image Alignment\n(TIA) task and CVR prediction task. We use pre-trained BERT to generate the\ntext embedding and pre-trained InceptionV4 to generate image patch embedding\n(each image is split into small patches with the same pixels and treat each\npatch as an image token). Softmax gating networks follow to learn the weight of\neach transformer expert output and choose only a subset of experts conditioned\non the input. Then transformer encoder is applied as the share-bottom layer to\nlearn all input features' shared interaction. Next, mixture of transformer\nexperts (MoE) layer is implemented to model different aspects of tasks. At top\nof the MoE layer, we deploy a transformer layer for each task as task tower to\nlearn task-specific information. On the real word intra-city dataset,\nexperiments demonstrate CameNN outperform baselines and achieve significant\nimprovements on the image and text representation. In practice, we applied\nCameNN on CVR prediction in our intra-city recommender system which is one of\nthe leading intra-city platforms operated in China.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:36:52 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Li", "Po", ""], ["Li", "Lei", ""], ["Fu", "Yan", ""], ["Rong", "Jun", ""], ["Zhang", "Yu", ""]]}, {"id": "2009.09928", "submitter": "Yue Liu", "authors": "Yue Liu, Alex Colburn, Mehlika Inanici", "title": "Deep Neural Network Approach for Annual Luminance Simulations", "comments": null, "journal-ref": null, "doi": "10.1080/19401493.2020.1803404", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Annual luminance maps provide meaningful evaluations for occupants' visual\ncomfort, preferences, and perception. However, acquiring long-term luminance\nmaps require labor-intensive and time-consuming simulations or impracticable\nlong-term field measurements. This paper presents a novel data-driven machine\nlearning approach that makes annual luminance-based evaluations more efficient\nand accessible. The methodology is based on predicting the annual luminance\nmaps from a limited number of point-in-time high dynamic range imagery by\nutilizing a deep neural network (DNN). Panoramic views are utilized, as they\ncan be post-processed to study multiple view directions. The proposed DNN model\ncan faithfully predict high-quality annual panoramic luminance maps from one of\nthe three options within 30 minutes training time: a) point-in-time luminance\nimagery spanning 5% of the year, when evenly distributed during daylight hours,\nb) one-month hourly imagery generated or collected continuously during daylight\nhours around the equinoxes (8% of the year); or c) 9 days of hourly data\ncollected around the spring equinox, summer and winter solstices (2.5% of the\nyear) all suffice to predict the luminance maps for the rest of the year. The\nDNN predicted high-quality panoramas are validated against Radiance (RPICT)\nrenderings using a series of quantitative and qualitative metrics. The most\nefficient predictions are achieved with 9 days of hourly data collected around\nthe spring equinox, summer and winter solstices. The results clearly show that\npractitioners and researchers can efficiently incorporate long-term\nluminance-based metrics over multiple view directions into the design and\nresearch processes using the proposed DNN workflow.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:19:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Yue", ""], ["Colburn", "Alex", ""], ["Inanici", "Mehlika", ""]]}, {"id": "2009.09929", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Lorenzo Pellegrini, Pau Rodriguez, Massimo Caccia,\n  Qi She, Yu Chen, Quentin Jodelet, Ruiping Wang, Zheda Mai, David Vazquez,\n  German I. Parisi, Nikhil Churamani, Marc Pickett, Issam Laradji, Davide\n  Maltoni", "title": "CVPR 2020 Continual Learning in Computer Vision Competition: Approaches,\n  Results, Current Challenges and Future Directions", "comments": "Pre-print v1: 12 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, we have witnessed a renewed and fast-growing interest\nin continual learning with deep neural networks with the shared objective of\nmaking current AI systems more adaptive, efficient and autonomous. However,\ndespite the significant and undoubted progress of the field in addressing the\nissue of catastrophic forgetting, benchmarking different continual learning\napproaches is a difficult task by itself. In fact, given the proliferation of\ndifferent settings, training and evaluation protocols, metrics and\nnomenclature, it is often tricky to properly characterize a continual learning\nalgorithm, relate it to other solutions and gauge its real-world applicability.\nThe first Continual Learning in Computer Vision challenge held at CVPR in 2020\nhas been one of the first opportunities to evaluate different continual\nlearning algorithms on a common hardware with a large set of shared evaluation\nmetrics and 3 different settings based on the realistic CORe50 video benchmark.\nIn this paper, we report the main results of the competition, which counted\nmore than 79 teams registered, 11 finalists and 2300$ in prizes. We also\nsummarize the winning approaches, current challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 08:53:05 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Pellegrini", "Lorenzo", ""], ["Rodriguez", "Pau", ""], ["Caccia", "Massimo", ""], ["She", "Qi", ""], ["Chen", "Yu", ""], ["Jodelet", "Quentin", ""], ["Wang", "Ruiping", ""], ["Mai", "Zheda", ""], ["Vazquez", "David", ""], ["Parisi", "German I.", ""], ["Churamani", "Nikhil", ""], ["Pickett", "Marc", ""], ["Laradji", "Issam", ""], ["Maltoni", "Davide", ""]]}, {"id": "2009.09930", "submitter": "Mohammad Hadi", "authors": "Mohammad Abdul Hadi and Fatemeh H Fard", "title": "AOBTM: Adaptive Online Biterm Topic Modeling for Version Sensitive\n  Short-texts Analysis", "comments": "13 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of mobile app reviews has shown its important role in requirement\nengineering, software maintenance and evolution of mobile apps. Mobile app\ndevelopers check their users' reviews frequently to clarify the issues\nexperienced by users or capture the new issues that are introduced due to a\nrecent app update. App reviews have a dynamic nature and their discussed topics\nchange over time. The changes in the topics among collected reviews for\ndifferent versions of an app can reveal important issues about the app update.\nA main technique in this analysis is using topic modeling algorithms. However,\napp reviews are short texts and it is challenging to unveil their latent topics\nover time. Conventional topic models suffer from the sparsity of word\nco-occurrence patterns while inferring topics for short texts. Furthermore,\nthese algorithms cannot capture topics over numerous consecutive time-slices.\nOnline topic modeling algorithms speed up the inference of topic models for the\ntexts collected in the latest time-slice by saving a fraction of data from the\nprevious time-slice. But these algorithms do not analyze the statistical-data\nof all the previous time-slices, which can confer contributions to the topic\ndistribution of the current time-slice.\n  We propose Adaptive Online Biterm Topic Model (AOBTM) to model topics in\nshort texts adaptively. AOBTM alleviates the sparsity problem in short-texts\nand considers the statistical-data for an optimal number of previous\ntime-slices. We also propose parallel algorithms to automatically determine the\noptimal number of topics and the best number of previous versions that should\nbe considered in topic inference phase. Automatic evaluation on collections of\napp reviews and real-world short text datasets confirm that AOBTM can find more\ncoherent topics and outperforms the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:50:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hadi", "Mohammad Abdul", ""], ["Fard", "Fatemeh H", ""]]}, {"id": "2009.09931", "submitter": "Harshit Pande", "authors": "Harshit Pande", "title": "Field-Embedded Factorization Machines for Click-through rate prediction", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction models are common in many online\napplications such as digital advertising and recommender systems. Field-Aware\nFactorization Machine (FFM) and Field-weighted Factorization Machine (FwFM) are\nstate-of-the-art among the shallow models for CTR prediction. Recently, many\ndeep learning-based models have also been proposed. Among deeper models,\nDeepFM, xDeepFM, AutoInt+, and FiBiNet are state-of-the-art models. The deeper\nmodels combine a core architectural component, which learns explicit feature\ninteractions, with a deep neural network (DNN) component. We propose a novel\nshallow Field-Embedded Factorization Machine (FEFM) and its deep counterpart\nDeep Field-Embedded Factorization Machine (DeepFEFM). FEFM learns symmetric\nmatrix embeddings for each field pair along with the usual single vector\nembeddings for each feature. FEFM has significantly lower model complexity than\nFFM and roughly the same complexity as FwFM. FEFM also has insightful\nmathematical properties about important fields and field interactions. DeepFEFM\ncombines the FEFM interaction vectors learned by the FEFM component with a DNN\nand is thus able to learn higher order interactions. We conducted comprehensive\nexperiments over a wide range of hyperparameters on two large publicly\navailable real-world datasets. When comparing test AUC and log loss, the\nresults show that FEFM and DeepFEFM outperform the existing state-of-the-art\nshallow and deep models for CTR prediction tasks. We have made the code of FEFM\nand DeepFEFM available in the DeepCTR library\n(https://github.com/shenweichen/DeepCTR).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:32:42 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:45:02 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Pande", "Harshit", ""]]}, {"id": "2009.09932", "submitter": "Song Cheng", "authors": "Song Cheng, Lei Wang, Pan Zhang", "title": "Supervised Learning with Projected Entangled Pair States", "comments": "7 pages, 4 figures, 1 table", "journal-ref": "Phys. Rev. B 103, 125117 (2021)", "doi": "10.1103/PhysRevB.103.125117", "report-no": null, "categories": "cs.CV cond-mat.str-el cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor networks, a model that originated from quantum physics, has been\ngradually generalized as efficient models in machine learning in recent years.\nHowever, in order to achieve exact contraction, only tree-like tensor networks\nsuch as the matrix product states and tree tensor networks have been\nconsidered, even for modeling two-dimensional data such as images. In this\nwork, we construct supervised learning models for images using the projected\nentangled pair states (PEPS), a two-dimensional tensor network having a similar\nstructure prior to natural images. Our approach first performs a feature map,\nwhich transforms the image data to a product state on a grid, then contracts\nthe product state to a PEPS with trainable parameters to predict image labels.\nThe tensor elements of PEPS are trained by minimizing differences between\ntraining labels and predicted labels. The proposed model is evaluated on image\nclassifications using the MNIST and the Fashion-MNIST datasets. We show that\nour model is significantly superior to existing models using tree-like tensor\nnetworks. Moreover, using the same input features, our method performs as well\nas the multilayer perceptron classifier, but with much fewer parameters and is\nmore stable. Our results shed light on potential applications of\ntwo-dimensional tensor network models in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 09:15:00 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Cheng", "Song", ""], ["Wang", "Lei", ""], ["Zhang", "Pan", ""]]}, {"id": "2009.09934", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Monocular Depth Estimation Using Multi Scale Neural Network And Feature\n  Fusion", "comments": "11 pages, 4 figures, Submitted to Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth estimation from monocular images is a challenging problem in computer\nvision. In this paper, we tackle this problem using a novel network\narchitecture using multi scale feature fusion. Our network uses two different\nblocks, first which uses different filter sizes for convolution and merges all\nthe individual feature maps. The second block uses dilated convolutions in\nplace of fully connected layers thus reducing computations and increasing the\nreceptive field. We present a new loss function for training the network which\nuses a depth regression term, SSIM loss term and a multinomial logistic loss\nterm combined. We train and test our network on Make 3D dataset, NYU Depth V2\ndataset and Kitti dataset using standard evaluation metrics for depth\nestimation comprised of RMSE loss and SILog loss. Our network outperforms\nprevious state of the art methods with lesser parameters.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:08:52 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2009.09936", "submitter": "Michela Paganini", "authors": "Michela Paganini", "title": "Prune Responsibly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irrespective of the specific definition of fairness in a machine learning\napplication, pruning the underlying model affects it. We investigate and\ndocument the emergence and exacerbation of undesirable per-class performance\nimbalances, across tasks and architectures, for almost one million categories\nconsidered across over 100K image classification models that undergo a pruning\nprocess.We demonstrate the need for transparent reporting, inclusive of bias,\nfairness, and inclusion metrics, in real-life engineering decision-making\naround neural network pruning. In response to the calls for quantitative\nevaluation of AI models to be population-aware, we present neural network\npruning as a tangible application domain where the ways in which\naccuracy-efficiency trade-offs disproportionately affect underrepresented or\noutlier groups have historically been overlooked. We provide a simple,\nPareto-based framework to insert fairness considerations into value-based\noperating point selection processes, and to re-evaluate pruning technique\nchoices.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 04:43:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Paganini", "Michela", ""]]}, {"id": "2009.09937", "submitter": "Morteza Heidari", "authors": "Morteza Heidari (1), Sivaramakrishnan Lakshmivarahan (2),\n  Seyedehnafiseh Mirniaharikandehei (1), Gopichandh Danala (1), Sai Kiran R.\n  Maryada (2), Hong Liu (1), Bin Zheng (1), ((1) School of Electrical and\n  Computer Engineering, University of Oklahoma, Norman, OK, USA, (2) School of\n  Computer Sciences, University of Oklahoma, Norman, OK, USA)", "title": "Applying a random projection algorithm to optimize machine learning\n  model for breast lesion classification", "comments": "11 pages, 6 figures", "journal-ref": "IEEE Transactions on Biomedical Engineering, 2021", "doi": "10.1109/TBME.2021.3054248", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is widely used in developing computer-aided diagnosis (CAD)\nschemes of medical images. However, CAD usually computes large number of image\nfeatures from the targeted regions, which creates a challenge of how to\nidentify a small and optimal feature vector to build robust machine learning\nmodels. In this study, we investigate feasibility of applying a random\nprojection algorithm to build an optimal feature vector from the initially\nCAD-generated large feature pool and improve performance of machine learning\nmodel. We assemble a retrospective dataset involving 1,487 cases of mammograms\nin which 644 cases have confirmed malignant mass lesions and 843 have benign\nlesions. A CAD scheme is first applied to segment mass regions and initially\ncompute 181 features. Then, support vector machine (SVM) models embedded with\nseveral feature dimensionality reduction methods are built to predict\nlikelihood of lesions being malignant. All SVM models are trained and tested\nusing a leave-one-case-out cross-validation method. SVM generates a likelihood\nscore of each segmented mass region depicting on one-view mammogram. By fusion\nof two scores of the same mass depicting on two-view mammograms, a case-based\nlikelihood score is also evaluated. Comparing with the principle component\nanalyses, nonnegative matrix factorization, and Chi-squared methods, SVM\nembedded with the random projection algorithm yielded a significantly higher\ncase-based lesion classification performance with the area under ROC curve of\n0.84+0.01 (p<0.02). The study demonstrates that the random project algorithm is\na promising method to generate optimal feature vectors to help improve\nperformance of machine learning models of medical images.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 21:27:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Heidari", "Morteza", ""], ["Lakshmivarahan", "Sivaramakrishnan", ""], ["Mirniaharikandehei", "Seyedehnafiseh", ""], ["Danala", "Gopichandh", ""], ["Maryada", "Sai Kiran R.", ""], ["Liu", "Hong", ""], ["Zheng", "Bin", ""]]}, {"id": "2009.09942", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, J. Andrew Bagnell, Maxim Likhachev", "title": "CMAX++ : Leveraging Experience in Planning and Execution using\n  Inaccurate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given access to accurate dynamical models, modern planning approaches are\neffective in computing feasible and optimal plans for repetitive robotic tasks.\nHowever, it is difficult to model the true dynamics of the real world before\nexecution, especially for tasks requiring interactions with objects whose\nparameters are unknown. A recent planning approach, CMAX, tackles this problem\nby adapting the planner online during execution to bias the resulting plans\naway from inaccurately modeled regions. CMAX, while being provably guaranteed\nto reach the goal, requires strong assumptions on the accuracy of the model\nused for planning and fails to improve the quality of the solution over\nrepetitions of the same task. In this paper we propose CMAX++, an approach that\nleverages real-world experience to improve the quality of resulting plans over\nsuccessive repetitions of a robotic task. CMAX++ achieves this by integrating\nmodel-free learning using acquired experience with model-based planning using\nthe potentially inaccurate model. We provide provable guarantees on the\ncompleteness and asymptotic convergence of CMAX++ to the optimal path cost as\nthe number of repetitions increases. CMAX++ is also shown to outperform\nbaselines in simulated robotic tasks including 3D mobile robot navigation where\nthe track friction is incorrectly modeled, and a 7D pick-and-place task where\nthe mass of the object is unknown leading to discrepancy between true and\nmodeled dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:59:31 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 01:23:29 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 18:44:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Vemula", "Anirudh", ""], ["Bagnell", "J. Andrew", ""], ["Likhachev", "Maxim", ""]]}, {"id": "2009.09943", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Jingbo Wang, Jiawei Wang, Chao Wang", "title": "NeuroDiff: Scalable Differential Verification of Neural Networks using\n  Fine-Grained Approximation", "comments": "Published as a conference paper at ASE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks make their way into safety-critical systems, where\nmisbehavior can lead to catastrophes, there is a growing interest in certifying\nthe equivalence of two structurally similar neural networks. For example,\ncompression techniques are often used in practice for deploying trained neural\nnetworks on computationally- and energy-constrained devices, which raises the\nquestion of how faithfully the compressed network mimics the original network.\nUnfortunately, existing methods either focus on verifying a single network or\nrely on loose approximations to prove the equivalence of two networks. Due to\noverly conservative approximation, differential verification lacks scalability\nin terms of both accuracy and computational cost. To overcome these problems,\nwe propose NeuroDiff, a symbolic and fine-grained approximation technique that\ndrastically increases the accuracy of differential verification while achieving\nmany orders-of-magnitude speedup. NeuroDiff has two key contributions. The\nfirst one is new convex approximations that more accurately bound the\ndifference neurons of two networks under all possible inputs. The second one is\njudicious use of symbolic variables to represent neurons whose difference\nbounds have accumulated significant error. We also find that these two\ntechniques are complementary, i.e., when combined, the benefit is greater than\nthe sum of their individual benefits. We have evaluated NeuroDiff on a variety\nof differential verification tasks. Our results show that NeuroDiff is up to\n1000X faster and 5X more accurate than the state-of-the-art tool.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:00:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Paulsen", "Brandon", ""], ["Wang", "Jingbo", ""], ["Wang", "Jiawei", ""], ["Wang", "Chao", ""]]}, {"id": "2009.09967", "submitter": "Hwanjin Kim", "authors": "Hwanjin Kim, Sucheol Kim, Hyeongtaek Lee, Chulhee Jang, Yongyun Choi,\n  and Junil Choi", "title": "Massive MIMO Channel Prediction: Kalman Filtering vs. Machine Learning", "comments": "Accepted to IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on channel prediction techniques for massive\nmultiple-input multiple-output (MIMO) systems. Previous channel predictors are\nbased on theoretical channel models, which would be deviated from realistic\nchannels. In this paper, we develop and compare a vector Kalman filter\n(VKF)-based channel predictor and a machine learning (ML)-based channel\npredictor using the realistic channels from the spatial channel model (SCM),\nwhich has been adopted in the 3GPP standard for years. First, we propose a\nlow-complexity mobility estimator based on the spatial average using a large\nnumber of antennas in massive MIMO. The mobility estimate can be used to\ndetermine the complexity order of developed predictors. The VKF-based channel\npredictor developed in this paper exploits the autoregressive (AR) parameters\nestimated from the SCM channels based on the Yule-Walker equations. Then, the\nML-based channel predictor using the linear minimum mean square error\n(LMMSE)-based noise pre-processed data is developed. Numerical results reveal\nthat both channel predictors have substantial gain over the outdated channel in\nterms of the channel prediction accuracy and data rate. The ML-based predictor\nhas larger overall computational complexity than the VKF-based predictor, but\nonce trained, the operational complexity of ML-based predictor becomes smaller\nthan that of VKF-based predictor.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:47:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kim", "Hwanjin", ""], ["Kim", "Sucheol", ""], ["Lee", "Hyeongtaek", ""], ["Jang", "Chulhee", ""], ["Choi", "Yongyun", ""], ["Choi", "Junil", ""]]}, {"id": "2009.09988", "submitter": "Yinglun Zhu", "authors": "Yinglun Zhu, Sumeet Katariya and Robert Nowak", "title": "Robust Outlier Arm Identification", "comments": "Full version of our ICML 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of Robust Outlier Arm Identification (ROAI), where the\ngoal is to identify arms whose expected rewards deviate substantially from the\nmajority, by adaptively sampling from their reward distributions. We compute\nthe outlier threshold using the median and median absolute deviation of the\nexpected rewards. This is a robust choice for the threshold compared to using\nthe mean and standard deviation, since it can identify outlier arms even in the\npresence of extreme outlier values. Our setting is different from existing pure\nexploration problems where the threshold is pre-specified as a given value or\nrank. This is useful in applications where the goal is to identify the set of\npromising items but the cardinality of this set is unknown, such as finding\npromising drugs for a new disease or identifying items favored by a population.\nWe propose two $\\delta$-PAC algorithms for ROAI, which includes the first\nUCB-style algorithm for outlier detection, and derive upper bounds on their\nsample complexity. We also prove a matching, up to logarithmic factors, worst\ncase lower bound for the problem, indicating that our upper bounds are\ngenerally unimprovable. Experimental results show that our algorithms are both\nrobust and about $5$x sample efficient compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:13:01 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhu", "Yinglun", ""], ["Katariya", "Sumeet", ""], ["Nowak", "Robert", ""]]}, {"id": "2009.09991", "submitter": "Sebastian Bruch", "authors": "Mathieu Guillame-Bert, Sebastian Bruch, Petr Mitrichev, Petr Mikheev,\n  Jan Pfeifer", "title": "Modeling Text with Decision Forests using Categorical-Set Splits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision forest algorithms typically model data by learning a binary tree\nstructure recursively where every node splits the feature space into two\nsub-regions, sending examples into the left or right branch as a result. In\naxis-aligned decision forests, the \"decision\" to route an input example is the\nresult of the evaluation of a condition on a single dimension in the feature\nspace. Such conditions are learned using efficient, often greedy algorithms\nthat optimize a local loss function. For example, a node's condition may be a\nthreshold function applied to a numerical feature, and its parameter may be\nlearned by sweeping over the set of values available at that node and choosing\na threshold that maximizes some measure of purity. Crucially, whether an\nalgorithm exists to learn and evaluate conditions for a feature type determines\nwhether a decision forest algorithm can model that feature type at all. For\nexample, decision forests today cannot consume textual features directly --\nsuch features must be transformed to summary statistics instead. In this work,\nwe set out to bridge that gap. We define a condition that is specific to\ncategorical-set features -- defined as an unordered set of categorical\nvariables -- and present an algorithm to learn it, thereby equipping decision\nforests with the ability to directly model text, albeit without preserving\nsequential order. Our algorithm is efficient during training and the resulting\nconditions are fast to evaluate with our extension of the QuickScorer inference\nalgorithm. Experiments on benchmark text classification datasets demonstrate\nthe utility and effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:16:35 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:29:59 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 11:44:02 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Guillame-Bert", "Mathieu", ""], ["Bruch", "Sebastian", ""], ["Mitrichev", "Petr", ""], ["Mikheev", "Petr", ""], ["Pfeifer", "Jan", ""]]}, {"id": "2009.09993", "submitter": "Artur Sokolovsky", "authors": "Artur Sokolovsky and Luca Arnaboldi", "title": "Machine Learning Classification of Price Extrema Based on Market\n  Microstructure and Price Action Features. A Case Study of S&P500 E-mini\n  Futures", "comments": "Associated processing files are available at:\n  https://doi.org/10.5281/zenodo.4036850", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study introduces an automated trading system for S\\&P500 E-mini futures\n(ES) based on state-of-the-art machine learning. Concretely: we extract a set\nof scenarios from the tick market data to train the models and further use the\npredictions to statistically assess the soundness of the approach. We define\nthe scenarios from the local extrema of the price action. Price extrema is a\ncommonly traded pattern, however, to the best of our knowledge, there is no\nstudy presenting a pipeline for automated classification and profitability\nevaluation. Additionally, we evaluate the approach in the simulated trading\nenvironment on the historical data. Our study is filling this gap by presenting\na broad evaluation of the approach supported by statistical tools which make it\ngeneralisable to unseen data and comparable to other approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:17:42 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 14:28:54 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 12:58:49 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Sokolovsky", "Artur", ""], ["Arnaboldi", "Luca", ""]]}, {"id": "2009.10007", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Stein Kristiansen, Thomas Plagemann, Vera\n  Goebel, Knut Liest{\\o}l, Mohan Kankanhalli, Gunn Marit Traaen, Britt\n  {\\O}verland, Harriet Akre, Lars Aaker{\\o}y, Sigurd Steinshamn", "title": "Learning Realistic Patterns from Unrealistic Stimuli: Generalization and\n  Data Anonymization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Good training data is a prerequisite to develop useful ML applications.\nHowever, in many domains existing data sets cannot be shared due to privacy\nregulations (e.g., from medical studies). This work investigates a simple yet\nunconventional approach for anonymized data synthesis to enable third parties\nto benefit from such private data. We explore the feasibility of learning\nimplicitly from unrealistic, task-relevant stimuli, which are synthesized by\nexciting the neurons of a trained deep neural network (DNN). As such, neuronal\nexcitation serves as a pseudo-generative model. The stimuli data is used to\ntrain new classification models. Furthermore, we extend this framework to\ninhibit representations that are associated with specific individuals. We use\nsleep monitoring data from both an open and a large closed clinical study and\nevaluate whether (1) end-users can create and successfully use customized\nclassification models for sleep apnea detection, and (2) the identity of\nparticipants in the study is protected. Extensive comparative empirical\ninvestigation shows that different algorithms trained on the stimuli are able\ngeneralize successfully on the same task as the original model. However,\narchitectural and algorithmic similarity between new and original models play\nan important role in performance. For similar architectures, the performance is\nclose to that of using the true data (e.g., Accuracy difference of 0.56\\%,\nKappa coefficient difference of 0.03-0.04). Further experiments show that the\nstimuli can to a large extent successfully anonymize participants of the\nclinical studies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:31:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Kristiansen", "Stein", ""], ["Plagemann", "Thomas", ""], ["Goebel", "Vera", ""], ["Liest\u00f8l", "Knut", ""], ["Kankanhalli", "Mohan", ""], ["Traaen", "Gunn Marit", ""], ["\u00d8verland", "Britt", ""], ["Akre", "Harriet", ""], ["Aaker\u00f8y", "Lars", ""], ["Steinshamn", "Sigurd", ""]]}, {"id": "2009.10008", "submitter": "Tom Tirer", "authors": "Tom Tirer, Joan Bruna, Raja Giryes", "title": "Kernel-Based Smoothness Analysis of Residual Networks", "comments": "Accepted to MSML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major factor in the success of deep neural networks is the use of\nsophisticated architectures rather than the classical multilayer perceptron\n(MLP). Residual networks (ResNets) stand out among these powerful modern\narchitectures. Previous works focused on the optimization advantages of deep\nResNets over deep MLPs. In this paper, we show another distinction between the\ntwo models, namely, a tendency of ResNets to promote smoother interpolations\nthan MLPs. We analyze this phenomenon via the neural tangent kernel (NTK)\napproach. First, we compute the NTK for a considered ResNet model and prove its\nstability during gradient descent training. Then, we show by various evaluation\nmethodologies that for ReLU activations the NTK of ResNet, and its kernel\nregression results, are smoother than the ones of MLP. The better smoothness\nobserved in our analysis may explain the better generalization ability of\nResNets and the practice of moderately attenuating the residual blocks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:32:04 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 18:44:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tirer", "Tom", ""], ["Bruna", "Joan", ""], ["Giryes", "Raja", ""]]}, {"id": "2009.10017", "submitter": "Ryan Rossi", "authors": "Di Jin, Sungchul Kim, Ryan A. Rossi, Danai Koutra", "title": "From Static to Dynamic Node Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for leveraging graph stream data for\ntemporal prediction-based applications. Our proposed framework includes novel\nmethods for learning an appropriate graph time-series representation, modeling\nand weighting the temporal dependencies, and generalizing existing embedding\nmethods for such data. While previous work on dynamic modeling and embedding\nhas focused on representing a stream of timestamped edges using a time-series\nof graphs based on a specific time-scale (e.g., 1 month), we propose the notion\nof an $\\epsilon$-graph time-series that uses a fixed number of edges for each\ngraph, and show its superiority over the time-scale representation used in\nprevious work. In addition, we propose a number of new temporal models based on\nthe notion of temporal reachability graphs and weighted temporal summary\ngraphs. These temporal models are then used to generalize existing base\n(static) embedding methods by enabling them to incorporate and appropriately\nmodel temporal dependencies in the data. From the 6 temporal network models\ninvestigated (for each of the 7 base embedding methods), we find that the top-3\ntemporal models are always those that leverage the new $\\epsilon$-graph\ntime-series representation. Furthermore, the dynamic embedding methods from the\nframework almost always achieve better predictive performance than existing\nstate-of-the-art dynamic node embedding methods that are developed specifically\nfor such temporal prediction tasks. Finally, the findings of this work are\nuseful for designing better dynamic embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:48:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jin", "Di", ""], ["Kim", "Sungchul", ""], ["Rossi", "Ryan A.", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.10019", "submitter": "Zhaoming Xie", "authors": "Xingye Da, Zhaoming Xie, David Hoeller, Byron Boots, Animashree\n  Anandkumar, Yuke Zhu, Buck Babich, Animesh Garg", "title": "Learning a Contact-Adaptive Controller for Robust, Efficient Legged\n  Locomotion", "comments": "supplementary video: https://youtu.be/JJOmFZKpYTo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a hierarchical framework that combines model-based control and\nreinforcement learning (RL) to synthesize robust controllers for a quadruped\n(the Unitree Laikago). The system consists of a high-level controller that\nlearns to choose from a set of primitives in response to changes in the\nenvironment and a low-level controller that utilizes an established control\nmethod to robustly execute the primitives. Our framework learns a controller\nthat can adapt to challenging environmental changes on the fly, including novel\nscenarios not seen during training. The learned controller is up to 85~percent\nmore energy efficient and is more robust compared to baseline methods. We also\ndeploy the controller on a physical robot without any randomization or\nadaptation scheme.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:49:26 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 20:52:41 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 17:30:18 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 19:03:06 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Da", "Xingye", ""], ["Xie", "Zhaoming", ""], ["Hoeller", "David", ""], ["Boots", "Byron", ""], ["Anandkumar", "Animashree", ""], ["Zhu", "Yuke", ""], ["Babich", "Buck", ""], ["Garg", "Animesh", ""]]}, {"id": "2009.10026", "submitter": "Mirantha Jayathilaka", "authors": "Mirantha Jayathilaka, Tingting Mu, Uli Sattler", "title": "Visual-Semantic Embedding Model Informed by Structured Knowledge", "comments": "European Starting AI Researchers' Symposium 2020 (STAIRS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to improve a visual-semantic embedding model by\nincorporating concept representations captured from an external structured\nknowledge base. We investigate its performance on image classification under\nboth standard and zero-shot settings. We propose two novel evaluation\nframeworks to analyse classification errors with respect to the class hierarchy\nindicated by the knowledge base. The approach is tested using the ILSVRC 2012\nimage dataset and a WordNet knowledge base. With respect to both standard and\nzero-shot image classification, our approach shows superior performance\ncompared with the original approach, which uses word embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:04:32 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jayathilaka", "Mirantha", ""], ["Mu", "Tingting", ""], ["Sattler", "Uli", ""]]}, {"id": "2009.10031", "submitter": "Om Thakkar", "authors": "Swaroop Ramaswamy, Om Thakkar, Rajiv Mathews, Galen Andrew, H. Brendan\n  McMahan, Fran\\c{c}oise Beaufays", "title": "Training Production Language Models without Memorizing User Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents the first consumer-scale next-word prediction (NWP) model\ntrained with Federated Learning (FL) while leveraging the Differentially\nPrivate Federated Averaging (DP-FedAvg) technique. There has been prior work on\nbuilding practical FL infrastructure, including work demonstrating the\nfeasibility of training language models on mobile devices using such\ninfrastructure. It has also been shown (in simulations on a public corpus) that\nit is possible to train NWP models with user-level differential privacy using\nthe DP-FedAvg algorithm. Nevertheless, training production-quality NWP models\nwith DP-FedAvg in a real-world production environment on a heterogeneous fleet\nof mobile phones requires addressing numerous challenges. For instance, the\ncoordinating central server has to keep track of the devices available at the\nstart of each round and sample devices uniformly at random from them, while\nensuring \\emph{secrecy of the sample}, etc. Unlike all prior privacy-focused FL\nwork of which we are aware, for the first time we demonstrate the deployment of\na differentially private mechanism for the training of a production neural\nnetwork in FL, as well as the instrumentation of the production training\ninfrastructure to perform an end-to-end empirical measurement of unintended\nmemorization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:12:33 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ramaswamy", "Swaroop", ""], ["Thakkar", "Om", ""], ["Mathews", "Rajiv", ""], ["Andrew", "Galen", ""], ["McMahan", "H. Brendan", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "2009.10035", "submitter": "Md. Khaledur Rahman", "authors": "Md. Khaledur Rahman, Majedul Haque Sujon, Ariful Azad", "title": "Force2Vec: Parallel force-directed graph embedding", "comments": "Accepted for publication in ICDM 2020 as a regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A graph embedding algorithm embeds a graph into a low-dimensional space such\nthat the embedding preserves the inherent properties of the graph. While graph\nembedding is fundamentally related to graph visualization, prior work did not\nexploit this connection explicitly. We develop Force2Vec that uses\nforce-directed graph layout models in a graph embedding setting with an aim to\nexcel in both machine learning (ML) and visualization tasks. We make Force2Vec\nhighly parallel by mapping its core computations to linear algebra and\nutilizing multiple levels of parallelism available in modern processors. The\nresultant algorithm is an order of magnitude faster than existing methods (43x\nfaster than DeepWalk, on average) and can generate embeddings from graphs with\nbillions of edges in a few hours. In comparison to existing methods, Force2Vec\nis better in graph visualization and performs comparably or better in ML tasks\nsuch as link prediction, node classification, and clustering. Source code is\navailable at https://github.com/HipGraph/Force2Vec.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:53:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Rahman", "Md. Khaledur", ""], ["Sujon", "Majedul Haque", ""], ["Azad", "Ariful", ""]]}, {"id": "2009.10054", "submitter": "Doyup Lee", "authors": "Doyup Lee, Yeongjae Cheon, Wook-Shin Han", "title": "Regularizing Attention Networks for Anomaly Detection in Visual Question\n  Answering", "comments": "16 pages, 7 figures, Accepted to AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For stability and reliability of real-world applications, the robustness of\nDNNs in unimodal tasks has been evaluated. However, few studies consider\nabnormal situations that a visual question answering (VQA) model might\nencounter at test time after deployment in the real-world. In this study, we\nevaluate the robustness of state-of-the-art VQA models to five different\nanomalies, including worst-case scenarios, the most frequent scenarios, and the\ncurrent limitation of VQA models. Different from the results in unimodal tasks,\nthe maximum confidence of answers in VQA models cannot detect anomalous inputs,\nand post-training of the outputs, such as outlier exposure, is ineffective for\nVQA models. Thus, we propose an attention-based method, which uses confidence\nof reasoning between input images and questions and shows much more promising\nresults than the previous methods in unimodal tasks. In addition, we show that\na maximum entropy regularization of attention networks can significantly\nimprove the attention-based anomaly detection of the VQA models. Thanks to the\nsimplicity, attention-based anomaly detection and the regularization are\nmodel-agnostic methods, which can be used for various cross-modal attentions in\nthe state-of-the-art VQA models. The results imply that cross-modal attention\nin VQA is important to improve not only VQA accuracy, but also the robustness\nto various anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:47:49 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 12:46:47 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Lee", "Doyup", ""], ["Cheon", "Yeongjae", ""], ["Han", "Wook-Shin", ""]]}, {"id": "2009.10058", "submitter": "Asim Iqbal", "authors": "Hassan Mahmood, Asim Iqbal, Syed Mohammed Shamsul Islam", "title": "Exploring Intensity Invariance in Deep Neural Networks for Brain Image\n  Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is a widely-used technique in analysing large scale\ndatasets that are captured through various imaging modalities and techniques in\nbiomedical imaging such as MRI, X-Rays, etc. These datasets are typically\ncollected from various sites and under different imaging protocols using a\nvariety of scanners. Such heterogeneity in the data collection process causes\ninhomogeneity or variation in intensity (brightness) and noise distribution.\nThese variations play a detrimental role in the performance of image\nregistration, segmentation and detection algorithms. Classical image\nregistration methods are computationally expensive but are able to handle these\nartifacts relatively better. However, deep learning-based techniques are shown\nto be computationally efficient for automated brain registration but are\nsensitive to the intensity variations. In this study, we investigate the effect\nof variation in intensity distribution among input image pairs for deep\nlearning-based image registration methods. We find a performance degradation of\nthese models when brain image pairs with different intensity distribution are\npresented even with similar structures. To overcome this limitation, we\nincorporate a structural similarity-based loss function in a deep neural\nnetwork and test its performance on the validation split separated before\ntraining as well as on a completely unseen new dataset. We report that the deep\nlearning models trained with structure similarity-based loss seems to perform\nbetter for both datasets. This investigation highlights a possible performance\nlimiting factor in deep learning-based registration models and suggests a\npotential solution to incorporate the intensity distribution variation in the\ninput image pairs. Our code and models are available at\nhttps://github.com/hassaanmahmood/DeepIntense.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:49:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mahmood", "Hassan", ""], ["Iqbal", "Asim", ""], ["Islam", "Syed Mohammed Shamsul", ""]]}, {"id": "2009.10061", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Andrea Celli and Nicola Gatti and Tuomas Sandholm", "title": "Faster Algorithms for Optimal Ex-Ante Coordinated Collusive Strategies\n  in Extensive-Form Zero-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of finding an optimal strategy for a team of two\nplayers that faces an opponent in an imperfect-information zero-sum\nextensive-form game. Team members are not allowed to communicate during play\nbut can coordinate before the game. In that setting, it is known that the best\nthe team can do is sample a profile of potentially randomized strategies (one\nper player) from a joint (a.k.a. correlated) probability distribution at the\nbeginning of the game. In this paper, we first provide new modeling results\nabout computing such an optimal distribution by drawing a connection to a\ndifferent literature on extensive-form correlation. Second, we provide an\nalgorithm that computes such an optimal distribution by only using profiles\nwhere only one of the team members gets to randomize in each profile. We can\nalso cap the number of such profiles we allow in the solution. This begets an\nanytime algorithm by increasing the cap. We find that often a handful of\nwell-chosen such profiles suffices to reach optimal utility for the team. This\nenables team members to reach coordination through a relatively simple and\nunderstandable plan. Finally, inspired by this observation and leveraging\ntheoretical concepts that we introduce, we develop an efficient\ncolumn-generation algorithm for finding an optimal distribution for the team.\nWe evaluate it on a suite of common benchmark games. It is three orders of\nmagnitude faster than the prior state of the art on games that the latter can\nsolve and it can also solve several games that were previously unsolvable.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:51:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Farina", "Gabriele", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2009.10064", "submitter": "Maurice Weber", "authors": "Maurice Weber, Nana Liu, Bo Li, Ce Zhang, Zhikuan Zhao", "title": "Optimal Provable Robustness of Quantum Classification via Quantum\n  Hypothesis Testing", "comments": "28 pages, 5 figures", "journal-ref": "npj Quantum Information 7, 76 (2021)", "doi": "10.1038/s41534-021-00410-5", "report-no": null, "categories": "quant-ph cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning models have the potential to offer speedups and\nbetter predictive accuracy compared to their classical counterparts. However,\nthese quantum algorithms, like their classical counterparts, have been shown to\nalso be vulnerable to input perturbations, in particular for classification\nproblems. These can arise either from noisy implementations or, as a worst-case\ntype of noise, adversarial attacks. In order to develop defence mechanisms and\nto better understand the reliability of these algorithms, it is crucial to\nunderstand their robustness properties in presence of natural noise sources or\nadversarial manipulation. From the observation that measurements involved in\nquantum classification algorithms are naturally probabilistic, we uncover and\nformalize a fundamental link between binary quantum hypothesis testing and\nprovably robust quantum classification. This link leads to a tight robustness\ncondition which puts constraints on the amount of noise a classifier can\ntolerate, independent of whether the noise source is natural or adversarial.\nBased on this result, we develop practical protocols to optimally certify\nrobustness. Finally, since this is a robustness condition against worst-case\ntypes of noise, our result naturally extends to scenarios where the noise\nsource is known. Thus, we also provide a framework to study the reliability of\nquantum classification protocols beyond the adversarial, worst-case noise\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:55:28 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 09:07:35 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Weber", "Maurice", ""], ["Liu", "Nana", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""], ["Zhao", "Zhikuan", ""]]}, {"id": "2009.10065", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov and Ikhlaas Gurrib", "title": "Machine learning based forecasting of significant daily returns in\n  foreign exchange markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asset value forecasting has always attracted an enormous amount of interest\namong researchers in quantitative analysis. The advent of modern machine\nlearning models has introduced new tools to tackle this classical problem. In\nthis paper, we apply machine learning algorithms to hitherto unexplored\nquestion of forecasting instances of significant fluctuations in currency\nexchange rates. We perform analysis of nine modern machine learning algorithms\nusing data on four major currency pairs over a 10 year period. A key\ncontribution is the novel use of outlier detection methods for this purpose.\nNumerical experiments show that outlier detection methods substantially\noutperform traditional machine learning and finance techniques. In addition, we\nshow that a recently proposed new outlier detection method PKDE produces best\noverall results. Our findings hold across different currency pairs,\nsignificance levels, and time horizons indicating the robustness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:56:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamalov", "Firuz", ""], ["Gurrib", "Ikhlaas", ""]]}, {"id": "2009.10069", "submitter": "Sheng-Dong Zhang", "authors": "Shengdong Zhang, Shihui You, Longfei Chen, Xiaofei Liu", "title": "Analysis of tunnel failure characteristics under multiple explosion\n  loads based on persistent homology-based machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of tunnel failure characteristics under the load of external\nexplosion source is an important problem in tunnel design and protection, in\nparticular, it is of great significance to construct an intelligent topological\nfeature description of the tunnel failure process. The failure characteristics\nof tunnels under explosive loading are described by using discrete element\nmethod and persistent homology-based machine learning. Firstly, the discrete\nelement model of shallow buried tunnel was established in the discrete element\nsoftware, and the explosive load was equivalent to a series of uniformly\ndistributed loads acting on the surface by Saint-Venant principle, and the\ndynamic response of the tunnel under multiple explosive loads was obtained\nthrough iterative calculation. The topological characteristics of surrounding\nrock is studied by persistent homology-based machine learning. The geometric,\nphysical and interunit characteristics of the tunnel subjected to explosive\nloading are extracted, and the nonlinear mapping relationship between the\ntopological quantity of persistent homology, and the failure characteristics of\nthe surrounding rock is established, and the results of the intelligent\ndescription of the failure characteristics of the tunnel are obtained. The\nresearch shows that the length of the longest Betty 1 bar code is closely\nrelated to the stability of the tunnel, which can be used for effective early\nwarning of the tunnel failure, and an intelligent description of the tunnel\nfailure process can be established to provide a new idea for tunnel engineering\nprotection.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 07:38:28 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zhang", "Shengdong", ""], ["You", "Shihui", ""], ["Chen", "Longfei", ""], ["Liu", "Xiaofei", ""]]}, {"id": "2009.10071", "submitter": "Denisa Roberts", "authors": "Denisa A.O. Roberts and Lucas R. Roberts", "title": "QR and LQ Decomposition Matrix Backpropagation Algorithms for Square,\n  Wide, and Deep -- Real or Complex -- Matrices and Their Software\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.MS cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents matrix backpropagation algorithms for the QR\ndecomposition of matrices $A_{m, n}$, that are either square (m = n), wide (m <\nn), or deep (m > n), with rank $k = min(m, n)$. Furthermore, we derive novel\nmatrix backpropagation results for the pivoted (full-rank) QR decomposition and\nfor the LQ decomposition of deep input matrices. Differentiable QR\ndecomposition offers a numerically stable, computationally efficient method to\nsolve least squares problems frequently encountered in machine learning and\ncomputer vision. Other use cases such as graph learning and network compression\nare listed in the article. Software implementation across popular deep learning\nframeworks (PyTorch, TensorFlow, MXNet) incorporate the methods for general use\nwithin the deep learning community. Furthermore, this article aids the\npractitioner in understanding the matrix backpropagation methodology as part of\nlarger computational graphs.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:03:37 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 13:43:04 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 21:18:53 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 12:54:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Roberts", "Denisa A. O.", ""], ["Roberts", "Lucas R.", ""]]}, {"id": "2009.10073", "submitter": "Dattaraj Rao", "authors": "Dattaraj Rao", "title": "Contextual Bandits for adapting to changing User preferences over time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits provide an effective way to model the dynamic data problem\nin ML by leveraging online (incremental) learning to continuously adjust the\npredictions based on changing environment. We explore details on contextual\nbandits, an extension to the traditional reinforcement learning (RL) problem\nand build a novel algorithm to solve this problem using an array of\naction-based learners. We apply this approach to model an article\nrecommendation system using an array of stochastic gradient descent (SGD)\nlearners to make predictions on rewards based on actions taken. We then extend\nthe approach to a publicly available MovieLens dataset and explore the\nfindings. First, we make available a simplified simulated dataset showing\nvarying user preferences over time and how this can be evaluated with static\nand dynamic learning algorithms. This dataset made available as part of this\nresearch is intentionally simulated with limited number of features and can be\nused to evaluate different problem-solving strategies. We will build a\nclassifier using static dataset and evaluate its performance on this dataset.\nWe show limitations of static learner due to fixed context at a point of time\nand how changing that context brings down the accuracy. Next we develop a novel\nalgorithm for solving the contextual bandit problem. Similar to the linear\nbandits, this algorithm maps the reward as a function of context vector but\nuses an array of learners to capture variation between actions/arms. We develop\na bandit algorithm using an array of stochastic gradient descent (SGD)\nlearners, with separate learner per arm. Finally, we will apply this contextual\nbandit algorithm to predicting movie ratings over time by different users from\nthe standard Movie Lens dataset and demonstrate the results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:17:42 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:01:59 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Rao", "Dattaraj", ""]]}, {"id": "2009.10126", "submitter": "Hamed Honari", "authors": "Hamed Honari (1), Ann S. Choe (2 and 3 and 4), Martin A. Lindquist (5)\n  ((1) Department of Electrical and Computer Engineering, Johns Hopkins\n  University, USA (2) F. M. Kirby Research Center for Functional Brain Imaging,\n  Kennedy Krieger Institute, USA (3) International Center for Spinal Cord\n  Injury, Kennedy Krieger Institute, USA (4) Russell H. Morgan Department of\n  Radiology and Radiological Science, Johns Hopkins School of Medicine, USA (5)\n  Department of Biostatistics, Johns Hopkins University, USA)", "title": "Evaluating phase synchronization methods in fMRI: a comparison study and\n  new approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been growing interest in measuring time-varying\nfunctional connectivity between different brain regions using resting-state\nfunctional magnetic resonance imaging (rs-fMRI) data. One way to assess the\nrelationship between signals from different brain regions is to measure their\nphase synchronization (PS) across time. There are several ways to perform such\nanalyses, and here we compare methods that utilize a PS metric together with a\nsliding window, referred to here as windowed phase synchronization (WPS), with\nthose that directly measure the instantaneous phase synchronization (IPS). In\nparticular, IPS has recently gained popularity as it offers single time-point\nresolution of time-resolved fMRI connectivity. In this paper, we discuss the\nunderlying assumptions required for performing PS analyses and emphasize the\nnecessity of band-pass filtering the data to obtain valid results. We review\nvarious methods for evaluating PS and introduce a new approach within the IPS\nframework denoted the cosine of the relative phase (CRP). We contrast methods\nthrough a series of simulations and application to rs-fMRI data. Our results\nindicate that CRP outperforms other tested methods and overcomes issues related\nto undetected temporal transitions from positive to negative associations\ncommon in IPS analysis. Further, in contrast to phase coherence, CRP unfolds\nthe distribution of PS measures, which benefits subsequent clustering of PS\nmatrices into recurring brain states.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:38:27 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Honari", "Hamed", "", "2 and 3 and 4"], ["Choe", "Ann S.", "", "2 and 3 and 4"], ["Lindquist", "Martin A.", ""]]}, {"id": "2009.10132", "submitter": "Sarah Jabbour", "authors": "Sarah Jabbour, David Fouhey, Ella Kazerooni, Michael W. Sjoding, Jenna\n  Wiens", "title": "Deep Learning Applied to Chest X-Rays: Exploiting and Preventing\n  Shortcuts", "comments": "32 pages, 9 figures, 12 tables, MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has shown promise in improving the automated diagnosis of\ndisease based on chest X-rays, deep networks may exhibit undesirable behavior\nrelated to shortcuts. This paper studies the case of spurious class skew in\nwhich patients with a particular attribute are spuriously more likely to have\nthe outcome of interest. For instance, clinical protocols might lead to a\ndataset in which patients with pacemakers are disproportionately likely to have\ncongestive heart failure. This skew can lead to models that take shortcuts by\nheavily relying on the biased attribute. We explore this problem across a\nnumber of attributes in the context of diagnosing the cause of acute hypoxemic\nrespiratory failure. Applied to chest X-rays, we show that i) deep nets can\naccurately identify many patient attributes including sex (AUROC = 0.96) and\nage (AUROC >= 0.90), ii) they tend to exploit correlations between such\nattributes and the outcome label when learning to predict a diagnosis, leading\nto poor performance when such correlations do not hold in the test population\n(e.g., everyone in the test set is male), and iii) a simple transfer learning\napproach is surprisingly effective at preventing the shortcut and promoting\ngood generalization performance. On the task of diagnosing congestive heart\nfailure based on a set of chest X-rays skewed towards older patients (age >=\n63), the proposed approach improves generalization over standard training from\n0.66 (95% CI: 0.54-0.77) to 0.84 (95% CI: 0.73-0.92) AUROC. While simple, the\nproposed approach has the potential to improve the performance of models across\npopulations by encouraging reliance on clinically relevant manifestations of\ndisease, i.e., those that a clinician would use to make a diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:52:43 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Jabbour", "Sarah", ""], ["Fouhey", "David", ""], ["Kazerooni", "Ella", ""], ["Sjoding", "Michael W.", ""], ["Wiens", "Jenna", ""]]}, {"id": "2009.10135", "submitter": "Silviu Maniu", "authors": "Silviu Maniu, Stratis Ioannidis, Bogdan Cautis", "title": "Bandits Under The Influence (Extended Version)", "comments": "27 pages, 4 figures, 6 tables. Extended version of accepted ICDM 2020\n  conference article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems should adapt to user interests as the latter evolve. A\nprevalent cause for the evolution of user interests is the influence of their\nsocial circle. In general, when the interests are not known, online algorithms\nthat explore the recommendation space while also exploiting observed\npreferences are preferable. We present online recommendation algorithms rooted\nin the linear multi-armed bandit literature. Our bandit algorithms are tailored\nprecisely to recommendation scenarios where user interests evolve under social\ninfluence. In particular, we show that our adaptations of the classic LinREL\nand Thompson Sampling algorithms maintain the same asymptotic regret bounds as\nin the non-social case. We validate our approach experimentally using both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:02:00 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Maniu", "Silviu", ""], ["Ioannidis", "Stratis", ""], ["Cautis", "Bogdan", ""]]}, {"id": "2009.10142", "submitter": "Alex Wong", "authors": "Alex Wong, Mukund Mundhra, Stefano Soatto", "title": "Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of adversarial perturbations of images on the estimates\nof disparity by deep learning models trained for stereo. We show that\nimperceptible additive perturbations can significantly alter the disparity map,\nand correspondingly the perceived geometry of the scene. These perturbations\nnot only affect the specific model they are crafted for, but transfer to models\nwith different architecture, trained with different loss functions. We show\nthat, when used for adversarial data augmentation, our perturbations result in\ntrained models that are more robust, without sacrificing overall accuracy of\nthe model. This is unlike what has been observed in image classification, where\nadding the perturbed images to the training set makes the model less vulnerable\nto adversarial perturbations, but to the detriment of overall accuracy. We test\nour method using the most recent stereo networks and evaluate their performance\non public benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:20:09 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 02:56:33 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 10:53:55 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wong", "Alex", ""], ["Mundhra", "Mukund", ""], ["Soatto", "Stefano", ""]]}, {"id": "2009.10149", "submitter": "Khaza Anuarul Hoque", "authors": "Gautam Raj Mode, Khaza Anuarul Hoque", "title": "Crafting Adversarial Examples for Deep Learning Based Prognostics\n  (Extended Version)", "comments": "This is the extended version of the paper \"Crafting Adversarial\n  Examples for Deep Learning Based Prognostics\" accepted for publication in the\n  IEEE International Conference on Machine Learning and Applications (ICMLA\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In manufacturing, unexpected failures are considered a primary operational\nrisk, as they can hinder productivity and can incur huge losses.\nState-of-the-art Prognostics and Health Management (PHM) systems incorporate\nDeep Learning (DL) algorithms and Internet of Things (IoT) devices to ascertain\nthe health status of equipment, and thus reduce the downtime, maintenance cost\nand increase the productivity. Unfortunately, IoT sensors and DL algorithms,\nboth are vulnerable to cyber attacks, and hence pose a significant threat to\nPHM systems. In this paper, we adopt the adversarial example crafting\ntechniques from the computer vision domain and apply them to the PHM domain.\nSpecifically, we craft adversarial examples using the Fast Gradient Sign Method\n(FGSM) and Basic Iterative Method (BIM) and apply them on the Long Short-Term\nMemory (LSTM), Gated Recurrent Unit (GRU), and Convolutional Neural Network\n(CNN) based PHM models. We evaluate the impact of adversarial attacks using\nNASA's turbofan engine dataset. The obtained results show that all the\nevaluated PHM models are vulnerable to adversarial attacks and can cause a\nserious defect in the remaining useful life estimation. The obtained results\nalso show that the crafted adversarial examples are highly transferable and may\ncause significant damages to PHM systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:43:38 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 15:26:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mode", "Gautam Raj", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "2009.10159", "submitter": "Du Nguyen", "authors": "Du Nguyen", "title": "Operator-valued formulas for Riemannian Gradient and Hessian and\n  families of tractable metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an explicit formula for the Levi-Civita connection and Riemannian\nHessian for a Riemannian manifold that is a quotient of a manifold embedded in\nan inner product space with a non-constant metric function. Together with a\nclassical formula for projection, this allows us to evaluate Riemannian\ngradient and Hessian for several families of metrics on classical manifolds,\nincluding a family of metrics on Stiefel manifolds connecting both the constant\nand canonical ambient metrics with closed-form geodesics. Using these formulas,\nwe derive Riemannian optimization frameworks on quotients of Stiefel manifolds,\nincluding flag manifolds, and a new family of complete quotient metrics on the\nmanifold of positive-semidefinite matrices of fixed rank, considered as a\nquotient of a product of Stiefel and positive-definite matrix manifold with\naffine-invariant metrics. The method is procedural, and in many instances, the\nRiemannian gradient and Hessian formulas could be derived by symbolic calculus.\nThe method extends the list of potential metrics that could be used in manifold\noptimization and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 20:15:57 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 22:06:30 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Nguyen", "Du", ""]]}, {"id": "2009.10189", "submitter": "Hannah Kerner", "authors": "Hannah Kerner, Ritvik Sahajpal, Sergii Skakun, Inbal Becker-Reshef,\n  Brian Barker, Mehdi Hosseini, Estefania Puricelli, Patrick Gray", "title": "Resilient In-Season Crop Type Classification in Multispectral Satellite\n  Observations using Growth Stage Normalization", "comments": "Presented at KDD 2020 Fragile Earth: Data Science for a Sustainable\n  Planet Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crop type classification using satellite observations is an important tool\nfor providing insights about planted area and enabling estimates of crop\ncondition and yield, especially within the growing season when uncertainties\naround these quantities are highest. As the climate changes and extreme weather\nevents become more frequent, these methods must be resilient to changes in\ndomain shifts that may occur, for example, due to shifts in planting timelines.\nIn this work, we present an approach for within-season crop type classification\nusing moderate spatial resolution (30 m) satellite data that addresses domain\nshift related to planting timelines by normalizing inputs by crop growth stage.\nWe use a neural network leveraging both convolutional and recurrent layers to\npredict if a pixel contains corn, soybeans, or another crop or land cover type.\nWe evaluated this method for the 2019 growing season in the midwestern US,\nduring which planting was delayed by as much as 1-2 months due to extreme\nweather that caused record flooding. We show that our approach using growth\nstage-normalized time series outperforms fixed-date time series, and achieves\noverall classification accuracy of 85.4% prior to harvest (September-November)\nand 82.8% by mid-season (July-September).\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 21:55:32 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Kerner", "Hannah", ""], ["Sahajpal", "Ritvik", ""], ["Skakun", "Sergii", ""], ["Becker-Reshef", "Inbal", ""], ["Barker", "Brian", ""], ["Hosseini", "Mehdi", ""], ["Puricelli", "Estefania", ""], ["Gray", "Patrick", ""]]}, {"id": "2009.10190", "submitter": "Faisal Mahmood", "authors": "Ming Y. Lu, Dehan Kong, Jana Lipkova, Richard J. Chen, Rajendra Singh,\n  Drew F. K. Williamson, Tiffany Y. Chen, Faisal Mahmood", "title": "Federated Learning for Computational Pathology on Gigapixel Whole Slide\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning-based computational pathology algorithms have demonstrated\nprofound ability to excel in a wide array of tasks that range from\ncharacterization of well known morphological phenotypes to predicting\nnon-human-identifiable features from histology such as molecular alterations.\nHowever, the development of robust, adaptable, and accurate deep learning-based\nmodels often rely on the collection and time-costly curation large high-quality\nannotated training data that should ideally come from diverse sources and\npatient populations to cater for the heterogeneity that exists in such\ndatasets. Multi-centric and collaborative integration of medical data across\nmultiple institutions can naturally help overcome this challenge and boost the\nmodel performance but is limited by privacy concerns amongst other difficulties\nthat may arise in the complex data sharing process as models scale towards\nusing hundreds of thousands of gigapixel whole slide images. In this paper, we\nintroduce privacy-preserving federated learning for gigapixel whole slide\nimages in computational pathology using weakly-supervised attention multiple\ninstance learning and differential privacy. We evaluated our approach on two\ndifferent diagnostic problems using thousands of histology whole slide images\nwith only slide-level labels. Additionally, we present a weakly-supervised\nlearning framework for survival prediction and patient stratification from\nwhole slide images and demonstrate its effectiveness in a federated setting.\nOur results show that using federated learning, we can effectively develop\naccurate weakly supervised deep learning models from distributed data silos\nwithout direct data sharing and its associated complexities, while also\npreserving differential privacy using randomized noise generation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 21:56:08 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 00:11:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lu", "Ming Y.", ""], ["Kong", "Dehan", ""], ["Lipkova", "Jana", ""], ["Chen", "Richard J.", ""], ["Singh", "Rajendra", ""], ["Williamson", "Drew F. K.", ""], ["Chen", "Tiffany Y.", ""], ["Mahmood", "Faisal", ""]]}, {"id": "2009.10191", "submitter": "Somrita Banerjee", "authors": "S. Banerjee, J. Harrison, P. M. Furlong, M. Pavone", "title": "Adaptive Meta-Learning for Identification of Rover-Terrain Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rovers require knowledge of terrain to plan trajectories that maximize safety\nand efficiency. Terrain type classification relies on input from human\noperators or machine learning-based image classification algorithms. However,\nhigh level terrain classification is typically not sufficient to prevent\nincidents such as rovers becoming unexpectedly stuck in a sand trap; in these\nsituations, online rover-terrain interaction data can be leveraged to\naccurately predict future dynamics and prevent further damage to the rover.\nThis paper presents a meta-learning-based approach to adapt probabilistic\npredictions of rover dynamics by augmenting a nominal model affine in\nparameters with a Bayesian regression algorithm (P-ALPaCA). A regularization\nscheme is introduced to encourage orthogonality of nominal and learned\nfeatures, leading to interpretable probabilistic estimates of terrain\nparameters in varying terrain conditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 21:56:44 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Banerjee", "S.", ""], ["Harrison", "J.", ""], ["Furlong", "P. M.", ""], ["Pavone", "M.", ""]]}, {"id": "2009.10195", "submitter": "Nathan Ng", "authors": "Nathan Ng, Kyunghyun Cho, Marzyeh Ghassemi", "title": "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving\n  Out-of-Domain Robustness", "comments": "16 pages, 8 figures, to be published in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that perform well on a training domain often fail to generalize to\nout-of-domain (OOD) examples. Data augmentation is a common method used to\nprevent overfitting and improve OOD generalization. However, in natural\nlanguage, it is difficult to generate new examples that stay on the underlying\ndata manifold. We introduce SSMBA, a data augmentation method for generating\nsynthetic training examples by using a pair of corruption and reconstruction\nfunctions to move randomly on a data manifold. We investigate the use of SSMBA\nin the natural language domain, leveraging the manifold assumption to\nreconstruct corrupted text with masked language models. In experiments on\nrobustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently\noutperforms existing data augmentation methods and baseline models on both\nin-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews,\n1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 22:02:33 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 22:47:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ng", "Nathan", ""], ["Cho", "Kyunghyun", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2009.10214", "submitter": "Prerit Terway", "authors": "Prerit Terway, Kenza Hamidouche, and Niraj K. Jha", "title": "DISPATCH: Design Space Exploration of Cyber-Physical Systems", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of cyber-physical systems (CPSs) is a challenging task that involves\nsearching over a large search space of various CPS configurations and possible\nvalues of components composing the system. Hence, there is a need for\nsample-efficient CPS design space exploration to select the system architecture\nand component values that meet the target system requirements. We address this\nchallenge by formulating CPS design as a multi-objective optimization problem\nand propose DISPATCH, a two-step methodology for sample-efficient search over\nthe design space. First, we use a genetic algorithm to search over discrete\nchoices of system component values for architecture search and component\nselection or only component selection and terminate the algorithm even before\nmeeting the system requirements, thus yielding a coarse design. In the second\nstep, we use an inverse design to search over a continuous space to fine-tune\nthe component values and meet the diverse set of system requirements. We use a\nneural network as a surrogate function for the inverse design of the system.\nThe neural network, converted into a mixed-integer linear program, is used for\nactive learning to sample component values efficiently in a continuous search\nspace. We illustrate the efficacy of DISPATCH on electrical circuit benchmarks:\ntwo-stage and three-stage transimpedence amplifiers. Simulation results show\nthat the proposed methodology improves sample efficiency by 5-14x compared to a\nprior synthesis method that relies on reinforcement learning. It also\nsynthesizes circuits with the best performance (highest bandwidth/lowest area)\ncompared to designs synthesized using reinforcement learning, Bayesian\noptimization, or humans.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 23:14:51 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:06:05 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Terway", "Prerit", ""], ["Hamidouche", "Kenza", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2009.10221", "submitter": "Boris Kovalerchuk", "authors": "Boris Kovalerchuk (1), Muhammad Aurangzeb Ahmad (2 and 3), Ankur\n  Teredesai (2 and 3) ((1) Department of Computer Science, Central Washington\n  University, USA (2) Department of Computer Science and Systems, University of\n  Washington Tacoma, USA (3) Kensci Inc., USA)", "title": "Survey of explainable machine learning with visual and granular methods\n  beyond quasi-explanations", "comments": "45 pages, 34 figures", "journal-ref": "In: Interpretable Artificial Intelligence: A Perspective of\n  Granular Computing (Eds. W. Pedrycz, S.M.Chen), Springer, 2021, pp. 217-267", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys visual methods of explainability of Machine Learning (ML)\nwith focus on moving from quasi-explanations that dominate in ML to\ndomain-specific explanation supported by granular visuals. ML interpretation is\nfundamentally a human activity and visual methods are more readily\ninterpretable. While efficient visual representations of high-dimensional data\nexist, the loss of interpretable information, occlusion, and clutter continue\nto be a challenge, which lead to quasi-explanations. We start with the\nmotivation and the different definitions of explainability. The paper focuses\non a clear distinction between quasi-explanations and domain specific\nexplanations, and between explainable and an actually explained ML model that\nare critically important for the explainability domain. We discuss foundations\nof interpretability, overview visual interpretability and present several types\nof methods to visualize the ML models. Next, we present methods of visual\ndiscovery of ML models, with the focus on interpretable models, based on the\nrecently introduced concept of General Line Coordinates (GLC). These methods\ntake the critical step of creating visual explanations that are not merely\nquasi-explanations but are also domain specific visual explanations while these\nmethods themselves are domain-agnostic. The paper includes results on\ntheoretical limits to preserve n-D distances in lower dimensions, based on the\nJohnson-Lindenstrauss lemma, point-to-point and point-to-graph GLC approaches,\nand real-world case studies. The paper also covers traditional visual methods\nfor understanding ML models, which include deep learning and time series\nmodels. We show that many of these methods are quasi-explanations and need\nfurther enhancement to become domain specific explanations. We conclude with\noutlining open problems and current research frontiers.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 23:39:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kovalerchuk", "Boris", "", "2 and 3"], ["Ahmad", "Muhammad Aurangzeb", "", "2 and 3"], ["Teredesai", "Ankur", "", "2 and 3"]]}, {"id": "2009.10233", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Xu Li, and Yufei Ding", "title": "Scalable Adversarial Attack on Graph Neural Networks with Alternating\n  Direction Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved high performance in analyzing\ngraph-structured data and have been widely deployed in safety-critical areas,\nsuch as finance and autonomous driving. However, only a few works have explored\nGNNs' robustness to adversarial attacks, and their designs are usually limited\nby the scale of input datasets (i.e., focusing on small graphs with only\nthousands of nodes). In this work, we propose, SAG, the first scalable\nadversarial attack method with Alternating Direction Method of Multipliers\n(ADMM). We first decouple the large-scale graph into several smaller graph\npartitions and cast the original problem into several subproblems. Then, we\npropose to solve these subproblems using projected gradient descent on both the\ngraph topology and the node features that lead to considerably lower memory\nconsumption compared to the conventional attack methods. Rigorous experiments\nfurther demonstrate that SAG can significantly reduce the computation and\nmemory overhead compared with the state-of-the-art approach, making SAG\napplicable towards graphs with large size of nodes and edges.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:33:36 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Li", "Xu", ""], ["Ding", "Yufei", ""]]}, {"id": "2009.10235", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Zheng Wang, and Yufei Ding", "title": "Uncertainty-aware Attention Graph Neural Network for Defending\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of graph-based learning, graph neural networks\n(GNNs) emerge as the essential tool for gaining insights from graphs. However,\nunlike the conventional CNNs that have been extensively explored and\nexhaustively tested, people are still worrying about the GNNs' robustness under\nthe critical settings, such as financial services. The main reason is that\nexisting GNNs usually serve as a black-box in predicting and do not provide the\nuncertainty on the predictions. On the other side, the recent advancement of\nBayesian deep learning on CNNs has demonstrated its success of quantifying and\nexplaining such uncertainties to fortify CNN models. Motivated by these\nobservations, we propose UAG, the first systematic solution to defend\nadversarial attacks on GNNs through identifying and exploiting hierarchical\nuncertainties in GNNs. UAG develops a Bayesian Uncertainty Technique (BUT) to\nexplicitly capture uncertainties in GNNs and further employs an\nUncertainty-aware Attention Technique (UAT) to defend adversarial attacks on\nGNNs. Intensive experiments show that our proposed defense approach outperforms\nthe state-of-the-art solutions by a significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:46:40 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Wang", "Zheng", ""], ["Ding", "Yufei", ""]]}, {"id": "2009.10252", "submitter": "EPTCS", "authors": "Elena Mastria (Department of Mathematics and Computer Science,\n  University of Calabria, Italy), Jessica Zangari (Department of Mathematics\n  and Computer Science, University of Calabria, Italy), Simona Perri\n  (Department of Mathematics and Computer Science, University of Calabria,\n  Italy), Francesco Calimeri (Department of Mathematics and Computer Science,\n  University of Calabria, Italy)", "title": "A Machine Learning guided Rewriting Approach for ASP Logic Programs", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 261-267", "doi": "10.4204/EPTCS.325.31", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a declarative logic formalism that allows to\nencode computational problems via logic programs. Despite the declarative\nnature of the formalism, some advanced expertise is required, in general, for\ndesigning an ASP encoding that can be efficiently evaluated by an actual ASP\nsystem. A common way for trying to reduce the burden of manually tweaking an\nASP program consists in automatically rewriting the input encoding according to\nsuitable techniques, for producing alternative, yet semantically equivalent,\nASP programs. However, rewriting does not always grant benefits in terms of\nperformance; hence, proper means are needed for predicting their effects with\nthis respect. In this paper we describe an approach based on Machine Learning\n(ML) to automatically decide whether to rewrite. In particular, given an ASP\nprogram and a set of input facts, our approach chooses whether and how to\nrewrite input rules based on a set of features measuring their structural\nproperties and domain information. To this end, a Multilayer Perceptrons model\nhas then been trained to guide the ASP grounder I-DLV on rewriting input rules.\nWe report and discuss the results of an experimental evaluation over a\nprototypical implementation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:51:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mastria", "Elena", "", "Department of Mathematics and Computer Science,\n  University of Calabria, Italy"], ["Zangari", "Jessica", "", "Department of Mathematics\n  and Computer Science, University of Calabria, Italy"], ["Perri", "Simona", "", "Department of Mathematics and Computer Science, University of Calabria,\n  Italy"], ["Calimeri", "Francesco", "", "Department of Mathematics and Computer Science,\n  University of Calabria, Italy"]]}, {"id": "2009.10259", "submitter": "Weixin Liang", "authors": "Weixin Liang, James Zou, Zhou Yu", "title": "ALICE: Active Learning with Contrastive Natural Language Explanations", "comments": null, "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a supervised neural network classifier typically requires many\nannotated training samples. Collecting and annotating a large number of data\npoints are costly and sometimes even infeasible. Traditional annotation process\nuses a low-bandwidth human-machine communication interface: classification\nlabels, each of which only provides several bits of information. We propose\nActive Learning with Contrastive Explanations (ALICE), an expert-in-the-loop\ntraining framework that utilizes contrastive natural language explanations to\nimprove data efficiency in learning. ALICE learns to first use active learning\nto select the most informative pairs of label classes to elicit contrastive\nnatural language explanations from experts. Then it extracts knowledge from\nthese explanations using a semantic parser. Finally, it incorporates the\nextracted knowledge through dynamically changing the learning model's\nstructure. We applied ALICE in two visual recognition tasks, bird species\nclassification and social relationship classification. We found by\nincorporating contrastive explanations, our models outperform baseline models\nthat are trained with 40-100% more training data. We found that adding 1\nexplanation leads to similar performance gain as adding 13-30 labeled training\ndata points.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:02:07 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Liang", "Weixin", ""], ["Zou", "James", ""], ["Yu", "Zhou", ""]]}, {"id": "2009.10263", "submitter": "Juan Manuel Carrillo Garcia", "authors": "Juan Carrillo, Daniel Garijo, Mark Crowley, Rober Carrillo, Yolanda\n  Gil, Katherine Borda", "title": "Semantic Workflows and Machine Learning for the Assessment of Carbon\n  Storage by Urban Trees", "comments": "Previously published as part of the SciKnow 2019 Workshop, November\n  19th, 2019. Los Angeles, California, USA. Collocated with the tenth\n  International Conference on Knowledge Capture (K-CAP)", "journal-ref": "Proceedings of the Third International Workshop on Capturing\n  Scientific Knowledge co-located with the 10th International Conference on\n  Knowledge Capture (K-CAP 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.CY eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate science is critical for understanding both the causes and\nconsequences of changes in global temperatures and has become imperative for\ndecisive policy-making. However, climate science studies commonly require\naddressing complex interoperability issues between data, software, and\nexperimental approaches from multiple fields. Scientific workflow systems\nprovide unparalleled advantages to address these issues, including\nreproducibility of experiments, provenance capture, software reusability and\nknowledge sharing. In this paper, we introduce a novel workflow with a series\nof connected components to perform spatial data preparation, classification of\nsatellite imagery with machine learning algorithms, and assessment of carbon\nstored by urban trees. To the best of our knowledge, this is the first study\nthat estimates carbon storage for a region in Africa following the guidelines\nfrom the Intergovernmental Panel on Climate Change (IPCC).\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:30:29 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Carrillo", "Juan", ""], ["Garijo", "Daniel", ""], ["Crowley", "Mark", ""], ["Carrillo", "Rober", ""], ["Gil", "Yolanda", ""], ["Borda", "Katherine", ""]]}, {"id": "2009.10269", "submitter": "Tra Le Ms", "authors": "Tra Huong Thi Le, Nguyen H. Tran, Yan Kyaw Tun, Minh N. H. Nguyen,\n  Shashi Raj Pandey, Zhu Han, and Choong Seon Hong", "title": "An Incentive Mechanism for Federated Learning in Wireless Cellular\n  network: An Auction Approach", "comments": null, "journal-ref": "Paper-TW-Apr-20-0557(2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed learning framework that can deal\nwith the distributed issue in machine learning and still guarantee high\nlearning performance. However, it is impractical that all users will sacrifice\ntheir resources to join the FL algorithm. This motivates us to study the\nincentive mechanism design for FL. In this paper, we consider a FL system that\ninvolves one base station (BS) and multiple mobile users. The mobile users use\ntheir own data to train the local machine learning model, and then send the\ntrained models to the BS, which generates the initial model, collects local\nmodels and constructs the global model. Then, we formulate the incentive\nmechanism between the BS and mobile users as an auction game where the BS is an\nauctioneer and the mobile users are the sellers. In the proposed game, each\nmobile user submits its bids according to the minimal energy cost that the\nmobile users experiences in participating in FL. To decide winners in the\nauction and maximize social welfare, we propose the primal-dual greedy auction\nmechanism. The proposed mechanism can guarantee three economic properties,\nnamely, truthfulness, individual rationality and efficiency. Finally, numerical\nresults are shown to demonstrate the performance effectiveness of our proposed\nmechanism.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:50:39 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Le", "Tra Huong Thi", ""], ["Tran", "Nguyen H.", ""], ["Tun", "Yan Kyaw", ""], ["Nguyen", "Minh N. H.", ""], ["Pandey", "Shashi Raj", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2009.10273", "submitter": "Yizhu Jiao", "authors": "Yizhu Jiao, Yun Xiong, Jiawei Zhang, Yao Zhang, Tianqi Zhang, Yangyong\n  Zhu", "title": "Sub-graph Contrast for Scalable Self-Supervised Graph Representation\n  Learning", "comments": "Best Student Paper Runner-up Award at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has attracted lots of attention recently.\nExisting graph neural networks fed with the complete graph data are not\nscalable due to limited computation and memory costs. Thus, it remains a great\nchallenge to capture rich information in large-scale graph data. Besides, these\nmethods mainly focus on supervised learning and highly depend on node label\ninformation, which is expensive to obtain in the real world. As to unsupervised\nnetwork embedding approaches, they overemphasize node proximity instead, whose\nlearned representations can hardly be used in downstream application tasks\ndirectly. In recent years, emerging self-supervised learning provides a\npotential solution to address the aforementioned problems. However, existing\nself-supervised works also operate on the complete graph data and are biased to\nfit either global or very local (1-hop neighborhood) graph structures in\ndefining the mutual information based loss terms.\n  In this paper, a novel self-supervised representation learning method via\nSubgraph Contrast, namely \\textsc{Subg-Con}, is proposed by utilizing the\nstrong correlation between central nodes and their sampled subgraphs to capture\nregional structure information. Instead of learning on the complete input graph\ndata, with a novel data augmentation strategy, \\textsc{Subg-Con} learns node\nrepresentations through a contrastive loss defined based on subgraphs sampled\nfrom the original graph instead. Compared with existing graph representation\nlearning approaches, \\textsc{Subg-Con} has prominent performance advantages in\nweaker supervision requirements, model learning scalability, and\nparallelization. Extensive experiments verify both the effectiveness and the\nefficiency of our work compared with both classic and state-of-the-art graph\nrepresentation learning approaches on multiple real-world large-scale benchmark\ndatasets from different domains.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:58:19 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 06:45:16 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 06:32:34 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jiao", "Yizhu", ""], ["Xiong", "Yun", ""], ["Zhang", "Jiawei", ""], ["Zhang", "Yao", ""], ["Zhang", "Tianqi", ""], ["Zhu", "Yangyong", ""]]}, {"id": "2009.10277", "submitter": "Chris Kennedy", "authors": "Chris J. Kennedy, Geoff Bacon, Alexander Sahn, Claudia von Vacano", "title": "Constructing interval variables via faceted Rasch measurement and\n  multitask deep learning: a hate speech application", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general method for measuring complex variables on a continuous,\ninterval spectrum by combining supervised deep learning with the Constructing\nMeasures approach to faceted Rasch item response theory (IRT). We decompose the\ntarget construct, hate speech in our case, into multiple constituent components\nthat are labeled as ordinal survey items. Those survey responses are\ntransformed via IRT into a debiased, continuous outcome measure. Our method\nestimates the survey interpretation bias of the human labelers and eliminates\nthat influence on the generated continuous measure. We further estimate the\nresponse quality of each labeler using faceted IRT, allowing responses from\nlow-quality labelers to be removed.\n  Our faceted Rasch scaling procedure integrates naturally with a multitask\ndeep learning architecture for automated prediction on new data. The ratings on\nthe theorized components of the target outcome are used as supervised, ordinal\nvariables for the neural networks' internal concept learning. We test the use\nof an activation function (ordinal softmax) and loss function (ordinal\ncross-entropy) designed to exploit the structure of ordinal outcome variables.\nOur multitask architecture leads to a new form of model interpretation because\neach continuous prediction can be directly explained by the constituent\ncomponents in the penultimate layer.\n  We demonstrate this new method on a dataset of 50,000 social media comments\nsourced from YouTube, Twitter, and Reddit and labeled by 11,000 U.S.-based\nAmazon Mechanical Turk workers to measure a continuous spectrum from hate\nspeech to counterspeech. We evaluate Universal Sentence Encoders, BERT, and\nRoBERTa as language representation models for the comment text, and compare our\npredictive accuracy to Google Jigsaw's Perspective API models, showing\nsignificant improvement over this standard benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:15:05 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Kennedy", "Chris J.", ""], ["Bacon", "Geoff", ""], ["Sahn", "Alexander", ""], ["von Vacano", "Claudia", ""]]}, {"id": "2009.10283", "submitter": "Mohsen Jafarzadeh", "authors": "Mohsen Jafarzadeh, Yonas Tadesse", "title": "End-to-End Learning of Speech 2D Feature-Trajectory for Prosthetic Hands", "comments": null, "journal-ref": "2020 Second International Conference on Transdisciplinary AI\n  (TransAI), pages 25-33", "doi": "10.1109/TransAI49837.2020.00010", "report-no": null, "categories": "eess.AS cs.LG cs.RO cs.SD cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech is one of the most common forms of communication in humans. Speech\ncommands are essential parts of multimodal controlling of prosthetic hands. In\nthe past decades, researchers used automatic speech recognition systems for\ncontrolling prosthetic hands by using speech commands. Automatic speech\nrecognition systems learn how to map human speech to text. Then, they used\nnatural language processing or a look-up table to map the estimated text to a\ntrajectory. However, the performance of conventional speech-controlled\nprosthetic hands is still unsatisfactory. Recent advancements in\ngeneral-purpose graphics processing units (GPGPUs) enable intelligent devices\nto run deep neural networks in real-time. Thus, architectures of intelligent\nsystems have rapidly transformed from the paradigm of composite subsystems\noptimization to the paradigm of end-to-end optimization. In this paper, we\npropose an end-to-end convolutional neural network (CNN) that maps speech 2D\nfeatures directly to trajectories for prosthetic hands. The proposed\nconvolutional neural network is lightweight, and thus it runs in real-time in\nan embedded GPGPU. The proposed method can use any type of speech 2D feature\nthat has local correlations in each dimension such as spectrogram, MFCC, or\nPNCC. We omit the speech to text step in controlling the prosthetic hand in\nthis paper. The network is written in Python with Keras library that has a\nTensorFlow backend. We optimized the CNN for NVIDIA Jetson TX2 developer kit.\nOur experiment on this CNN demonstrates a root-mean-square error of 0.119 and\n20ms running time to produce trajectory outputs corresponding to the voice\ninput data. To achieve a lower error in real-time, we can optimize a similar\nCNN for a more powerful embedded GPGPU such as NVIDIA AGX Xavier.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:31:00 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Jafarzadeh", "Mohsen", ""], ["Tadesse", "Yonas", ""]]}, {"id": "2009.10298", "submitter": "Paria Jamshid Lou", "authors": "Paria Jamshid Lou and Mark Johnson", "title": "End-to-End Speech Recognition and Disfluency Removal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disfluency detection is usually an intermediate step between an automatic\nspeech recognition (ASR) system and a downstream task. By contrast, this paper\naims to investigate the task of end-to-end speech recognition and disfluency\nremoval. We specifically explore whether it is possible to train an ASR model\nto directly map disfluent speech into fluent transcripts, without relying on a\nseparate disfluency detection model. We show that end-to-end models do learn to\ndirectly generate fluent transcripts; however, their performance is slightly\nworse than a baseline pipeline approach consisting of an ASR system and a\ndisfluency detection model. We also propose two new metrics that can be used\nfor evaluating integrated ASR and disfluency models. The findings of this paper\ncan serve as a benchmark for further research on the task of end-to-end speech\nrecognition and disfluency removal in the future.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:11:37 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 08:13:32 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 23:07:21 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lou", "Paria Jamshid", ""], ["Johnson", "Mark", ""]]}, {"id": "2009.10301", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Stochastic Neighbor Embedding with Gaussian and Student-t Distributions:\n  Tutorial and Survey", "comments": "To appear as a part of an upcoming academic book on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Neighbor Embedding (SNE) is a manifold learning and dimensionality\nreduction method with a probabilistic approach. In SNE, every point is consider\nto be the neighbor of all other points with some probability and this\nprobability is tried to be preserved in the embedding space. SNE considers\nGaussian distribution for the probability in both the input and embedding\nspaces. However, t-SNE uses the Student-t and Gaussian distributions in these\nspaces, respectively. In this tutorial and survey paper, we explain SNE,\nsymmetric SNE, t-SNE (or Cauchy-SNE), and t-SNE with general degrees of\nfreedom. We also cover the out-of-sample extension and acceleration for these\nmethods. Some simulations to visualize the embeddings are also provided.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:32:05 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.10303", "submitter": "Ricardo Baptista", "authors": "Ricardo Baptista, Olivier Zahm, Youssef Marzouk", "title": "An adaptive transport framework for joint and conditional density\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework to robustly characterize joint and conditional\nprobability distributions via transport maps. Transport maps or \"flows\"\ndeterministically couple two distributions via an expressive monotone\ntransformation. Yet, learning the parameters of such transformations in high\ndimensions is challenging given few samples from the unknown target\ndistribution, and structural choices for these transformations can have a\nsignificant impact on performance. Here we formulate a systematic framework for\nrepresenting and learning monotone maps, via invertible transformations of\nsmooth functions, and demonstrate that the associated minimization problem has\na unique global optimum. Given a hierarchical basis for the appropriate\nfunction space, we propose a sample-efficient adaptive algorithm that estimates\na sparse approximation for the map. We demonstrate how this framework can learn\ndensities with stable generalization performance across a wide range of sample\nsizes on real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:41:45 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Baptista", "Ricardo", ""], ["Zahm", "Olivier", ""], ["Marzouk", "Youssef", ""]]}, {"id": "2009.10312", "submitter": "Ambareesh Ravi", "authors": "Ambareesh Ravi", "title": "Stacked Generalization for Human Activity Recognition", "comments": "A short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper aims to discuss the effectiveness and performance of\nclassical machine learning approaches for Human Activity Recognition (HAR). It\nproposes two important models - Extra Trees and Stacked Classifier with the\nemphasize on the best practices, heuristics and measures that are required to\nmaximize the performance of those models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:38:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ravi", "Ambareesh", ""]]}, {"id": "2009.10315", "submitter": "Aneesh Vartakavi", "authors": "Aneesh Vartakavi and Amanmeet Garg", "title": "PodSumm -- Podcast Audio Summarization", "comments": "For PodRecs: Workshop on Podcast Recommendations at RecSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The diverse nature, scale, and specificity of podcasts present a unique\nchallenge to content discovery systems. Listeners often rely on text\ndescriptions of episodes provided by the podcast creators to discover new\ncontent. Some factors like the presentation style of the narrator and\nproduction quality are significant indicators of subjective user preference but\nare difficult to quantify and not reflected in the text descriptions provided\nby the podcast creators. We propose the automated creation of podcast audio\nsummaries to aid in content discovery and help listeners to quickly preview\npodcast content before investing time in listening to an entire episode. In\nthis paper, we present a method to automatically construct a podcast summary\nvia guidance from the text-domain. Our method performs two key steps, namely,\naudio to text transcription and text summary generation. Motivated by a lack of\ndatasets for this task, we curate an internal dataset, find an effective scheme\nfor data augmentation, and design a protocol to gather summaries from\nannotators. We fine-tune a PreSumm[10] model with our augmented dataset and\nperform an ablation study. Our method achieves ROUGE-F(1/2/L) scores of\n0.63/0.53/0.63 on our dataset. We hope these results may inspire future\nresearch in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:49:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Vartakavi", "Aneesh", ""], ["Garg", "Amanmeet", ""]]}, {"id": "2009.10318", "submitter": "Yuanda Zhu", "authors": "Yuanda Zhu, Ying Sha, Hang Wu, Mai Li, Ryan A. Hoffman and May D. Wang", "title": "Public Health Informatics: Proposing Causal Sequence of Death Using\n  Neural Machine Translation", "comments": "11 pages, 8 figures, 8 tables. Updates: (1) Added Section II: Recent\n  Work (2) Added three accuracy evaluation criteria (3) Re-run experiments of\n  OpenNMT and updated the results and discussion in Section VI: Results and\n  Discussion (4) Finished FHIR mobile app and updated Section VII: FHIR\n  Interface (5) Revised Section VIII: Conclusion accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year there are nearly 57 million deaths around the world, with over 2.7\nmillion in the United States. Timely, accurate and complete death reporting is\ncritical in public health, as institutions and government agencies rely on\ndeath reports to analyze vital statistics and to formulate responses to\ncommunicable diseases. Inaccurate death reporting may result in potential\nmisdirection of public health policies. Determining the causes of death is,\nnevertheless, challenging even for experienced physicians. To facilitate\nphysicians in accurately reporting causes of death, we present an advanced AI\napproach to determine a chronically ordered sequence of clinical conditions\nthat lead to death, based on decedent's last hospital discharge record. The\nsequence of clinical codes on the death report is named as causal chain of\ndeath, coded in the tenth revision of International Statistical Classification\nof Diseases (ICD-10); in line with the ICD-9-CM Official Guidelines for Coding\nand Reporting, the priority-ordered clinical conditions on the discharge record\nare coded in ICD-9. We identify three challenges in proposing the causal chain\nof death: two versions of coding system in clinical codes, medical domain\nknowledge conflict, and data interoperability. To overcome the first challenge\nin this sequence-to-sequence problem, we apply neural machine translation\nmodels to generate target sequence. Along with three accuracy metrics, we\nevaluate the quality of generated sequences with the BLEU (BiLingual Evaluation\nUnderstudy) score and achieve 16.04 out of 100. To address the second\nchallenge, we incorporate expert-verified medical domain knowledge as\nconstraint in generating output sequence to exclude infeasible causal chains.\nLastly, we demonstrate the usability of our work in a Fast Healthcare\nInteroperability Resources (FHIR) interface to address the third challenge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:56:23 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 19:43:37 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Zhu", "Yuanda", ""], ["Sha", "Ying", ""], ["Wu", "Hang", ""], ["Li", "Mai", ""], ["Hoffman", "Ryan A.", ""], ["Wang", "May D.", ""]]}, {"id": "2009.10333", "submitter": "Aanchal Mongia", "authors": "Aanchal Mongia, Stuti Jain, Emilie Chouzenoux and Angshul Majumda", "title": "DeepVir -- Graphical Deep Matrix Factorization for \"In Silico\" Antiviral\n  Repositioning: Application to COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work formulates antiviral repositioning as a matrix completion problem\nwhere the antiviral drugs are along the rows and the viruses along the columns.\nThe input matrix is partially filled, with ones in positions where the\nantiviral has been known to be effective against a virus. The curated metadata\nfor antivirals (chemical structure and pathways) and viruses (genomic structure\nand symptoms) is encoded into our matrix completion framework as graph\nLaplacian regularization. We then frame the resulting multiple graph\nregularized matrix completion problem as deep matrix factorization. This is\nsolved by using a novel optimization method called HyPALM (Hybrid Proximal\nAlternating Linearized Minimization). Results on our curated RNA drug virus\nassociation (DVA) dataset shows that the proposed approach excels over\nstate-of-the-art graph regularized matrix completion techniques. When applied\nto \"in silico\" prediction of antivirals for COVID-19, our approach returns\nantivirals that are either used for treating patients or are under for trials\nfor the same.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:57:03 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mongia", "Aanchal", ""], ["Jain", "Stuti", ""], ["Chouzenoux", "Emilie", ""], ["Majumda", "Angshul", ""]]}, {"id": "2009.10337", "submitter": "Amin Babadi", "authors": "Amin Babadi, Michiel van de Panne, C. Karen Liu, Perttu\n  H\\\"am\\\"al\\\"ainen", "title": "Learning Task-Agnostic Action Spaces for Movement Optimization", "comments": "Accepted as a regular paper by IEEE Transactions on Visualization and\n  Computer Graphics (TVCG) in July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for exploring the dynamics of physically based\nanimated characters, and learning a task-agnostic action space that makes\nmovement optimization easier. Like several previous papers, we parameterize\nactions as target states, and learn a short-horizon goal-conditioned low-level\ncontrol policy that drives the agent's state towards the targets. Our novel\ncontribution is that with our exploration data, we are able to learn the\nlow-level policy in a generic manner and without any reference movement data.\nTrained once for each agent or simulation environment, the policy improves the\nefficiency of optimizing both trajectories and high-level policies across\nmultiple tasks and optimization algorithms. We also contribute novel\nvisualizations that show how using target states as actions makes optimized\ntrajectories more robust to disturbances; this manifests as wider optima that\nare easy to find. Due to its simplicity and generality, our proposed approach\nshould provide a building block that can improve a large variety of movement\noptimization methods and applications.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 06:18:56 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 13:48:13 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Babadi", "Amin", ""], ["van de Panne", "Michiel", ""], ["Liu", "C. Karen", ""], ["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""]]}, {"id": "2009.10343", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov and Dmitry Denisov", "title": "Gamma distribution-based sampling for imbalanced data", "comments": "Preprint of the paper that was published in Knowledge-Based Systems", "journal-ref": "Knowledge-Based Systems (2020)", "doi": "10.1016/j.knosys.2020.106368", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced class distribution is a common problem in a number of fields\nincluding medical diagnostics, fraud detection, and others. It causes bias in\nclassification algorithms leading to poor performance on the minority class\ndata. In this paper, we propose a novel method for balancing the class\ndistribution in data through intelligent resampling of the minority class\ninstances. The proposed method is based on generating new minority instances in\nthe neighborhood of the existing minority points via a gamma distribution. Our\nmethod offers a natural and coherent approach to balancing the data. We conduct\na comprehensive numerical analysis of the new sampling technique. The\nexperimental results show that the proposed method outperforms the existing\nstate-of-the-art methods for imbalanced data. Concretely, the new sampling\ntechnique produces the best results on 12 out of 24 real life as well as\nsynthetic datasets. For comparison, the SMOTE method achieves the top score on\nonly 1 dataset. We conclude that the new technique offers a simple yet\neffective sampling approach to balance data.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 06:39:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Kamalov", "Firuz", ""], ["Denisov", "Dmitry", ""]]}, {"id": "2009.10365", "submitter": "Diego Alvarez-Estevez", "authors": "Diego Alvarez-Estevez and Roselyne M. Rijsman", "title": "Inter-database validation of a deep learning approach for automatic\n  sleep scoring", "comments": "Original submission manuscript, 19 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a new deep learning approach for automatic sleep\nstaging, and carry out its validation by addressing its generalization\ncapabilities on a wide range of sleep staging databases. Prediction\ncapabilities are evaluated in the context of independent local and external\ngeneralization scenarios. Effectively, by comparing both procedures it is\npossible to better extrapolate the expected performance of the method on the\ngeneral reference task of sleep staging, regardless of data from a specific\ndatabase. In addition, we examine the suitability of a novel approach based on\nthe use of an ensemble of individual local models and evaluate its impact on\nthe resulting inter-database generalization performance. Validation results\nshow good general performance, as compared to the expected levels of human\nexpert agreement, as well as state-of-the-art automatic sleep staging\napproaches\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:46:43 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Alvarez-Estevez", "Diego", ""], ["Rijsman", "Roselyne M.", ""]]}, {"id": "2009.10367", "submitter": "Ping-En Lu", "authors": "Ping-En Lu and Cheng-Shang Chang", "title": "Explainable, Stable, and Scalable Graph Convolutional Networks for\n  Learning Graph Representation", "comments": "This manuscript was submitted to IEEE Transactions on Neural Networks\n  and Learning Systems (IEEE TNNLS) on September 22, 2020, and is being under\n  reviewed. This work was supported by the Ministry of Science and Technology\n  (MOST) of Taiwan (R.O.C.) under Project MOST108-2221-E007-016-MY3.\n  (Corresponding author: Ping-En Lu.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network embedding problem that maps nodes in a graph to vectors in\nEuclidean space can be very useful for addressing several important tasks on a\ngraph. Recently, graph neural networks (GNNs) have been proposed for solving\nsuch a problem. However, most embedding algorithms and GNNs are difficult to\ninterpret and do not scale well to handle millions of nodes. In this paper, we\ntackle the problem from a new perspective based on the equivalence of three\nconstrained optimization problems: the network embedding problem, the trace\nmaximization problem of the modularity matrix in a sampled graph, and the\nmatrix factorization problem of the modularity matrix in a sampled graph. The\noptimal solutions to these three problems are the dominant eigenvectors of the\nmodularity matrix. We proposed two algorithms that belong to a special class of\ngraph convolutional networks (GCNs) for solving these problems: (i) Clustering\nAs Feature Embedding GCN (CAFE-GCN) and (ii) sphere-GCN. Both algorithms are\nstable trace maximization algorithms, and they yield good approximations of\ndominant eigenvectors. Moreover, there are linear-time implementations for\nsparse graphs. In addition to solving the network embedding problem, both\nproposed GCNs are capable of performing dimensionality reduction. Various\nexperiments are conducted to evaluate our proposed GCNs and show that our\nproposed GCNs outperform almost all the baseline methods. Moreover, CAFE-GCN\ncould be benefited from the labeled data and have tremendous improvements in\nvarious performance metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:49:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lu", "Ping-En", ""], ["Chang", "Cheng-Shang", ""]]}, {"id": "2009.10380", "submitter": "Md. Aminur Rab Ratul", "authors": "Md Aminur Rab Ratul, Maryam Tavakol Elahi, M. Hamed Mozaffari and\n  WonSook Lee", "title": "PS8-Net: A Deep Convolutional Neural Network to Predict the Eight-State\n  Protein Secondary Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Protein secondary structure is crucial to creating an information bridge\nbetween the primary and tertiary (3D) structures. Precise prediction of\neight-state protein secondary structure (PSS) has significantly utilized in the\nstructural and functional analysis of proteins in bioinformatics. Deep learning\ntechniques have been recently applied in this research area and raised the\neight-state (Q8) protein secondary structure prediction accuracy remarkably.\nNevertheless, from a theoretical standpoint, there are still lots of rooms for\nimprovement, specifically in the eight-state PSS prediction. In this study, we\nhave presented a new deep convolutional neural network (DCNN), namely PS8-Net,\nto enhance the accuracy of eight-class PSS prediction. The input of this\narchitecture is a carefully constructed feature matrix from the proteins\nsequence features and profile features. We introduce a new PS8 module in the\nnetwork, which is applied with skip connection to extracting the long-term\ninter-dependencies from higher layers, obtaining local contexts in earlier\nlayers, and achieving global information during secondary structure prediction.\nOur proposed PS8-Net achieves 76.89%, 71.94%, 76.86%, and 75.26% Q8 accuracy\nrespectively on benchmark CullPdb6133, CB513, CASP10, and CASP11 datasets. This\narchitecture enables the efficient processing of local and global\ninterdependencies between amino acids to make an accurate prediction of each\nclass. To the best of our knowledge, PS8-Net experiment results demonstrate\nthat it outperforms all the state-of-the-art methods on the aforementioned\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:19:10 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ratul", "Md Aminur Rab", ""], ["Elahi", "Maryam Tavakol", ""], ["Mozaffari", "M. Hamed", ""], ["Lee", "WonSook", ""]]}, {"id": "2009.10395", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright, Jean Pauphilet", "title": "Mixed-Projection Conic Optimization: A New Paradigm for Modeling Rank\n  Constraints", "comments": "major revision submitted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for modeling and solving low-rank optimization\nproblems to certifiable optimality. We introduce symmetric projection matrices\nthat satisfy $Y^2=Y$, the matrix analog of binary variables that satisfy\n$z^2=z$, to model rank constraints. By leveraging regularization and strong\nduality, we prove that this modeling paradigm yields tractable convex\noptimization problems over the non-convex set of orthogonal projection\nmatrices. Furthermore, we design outer-approximation algorithms to solve\nlow-rank problems to certifiable optimality, compute lower bounds via their\nsemidefinite relaxations, and provide near-optimal solutions through rounding\nand local search techniques. We implement these numerical ingredients and, for\nthe first time, solve low-rank optimization problems to certifiable optimality.\nUsing currently available spatial branch-and-bound codes, not tailored to\nprojection matrices, we can scale our exact (resp. near-exact) algorithms to\nmatrices with up to 30 (resp. 600) rows/columns. Our algorithms also supply\ncertifiably near-optimal solutions for larger problem sizes and outperform\nexisting heuristics, by deriving an alternative to the popular nuclear norm\nrelaxation which generalizes the perspective relaxation from vectors to\nmatrices. All in all, our framework, which we name Mixed-Projection Conic\nOptimization, solves low-rank problems to certifiable optimality in a tractable\nand unified fashion.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:59:06 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 20:45:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""], ["Pauphilet", "Jean", ""]]}, {"id": "2009.10396", "submitter": "Fabrice Harel-Canada", "authors": "Kushagra Rastogi and Jonathan Lee and Fabrice Harel-Canada and Aditya\n  Joglekar", "title": "Is Q-Learning Provably Efficient? An Extended Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends the analysis of the theoretical results presented within\nthe paper Is Q-Learning Provably Efficient? by Jin et al. We include a survey\nof related research to contextualize the need for strengthening the theoretical\nguarantees related to perhaps the most important threads of model-free\nreinforcement learning. We also expound upon the reasoning used in the proofs\nto highlight the critical steps leading to the main result showing that\nQ-learning with UCB exploration achieves a sample efficiency that matches the\noptimal regret that can be achieved by any model-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 09:00:25 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Rastogi", "Kushagra", ""], ["Lee", "Jonathan", ""], ["Harel-Canada", "Fabrice", ""], ["Joglekar", "Aditya", ""]]}, {"id": "2009.10401", "submitter": "Qinghua Lu", "authors": "Weishan Zhang, Tao Zhou, Qinghua Lu, Xiao Wang, Chunsheng Zhu, Haoyun\n  Sun, Zhipeng Wang, Sin Kit Lo, Fei-Yue Wang", "title": "Dynamic Fusion based Federated Learning for COVID-19 Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical diagnostic image analysis (e.g., CT scan or X-Ray) using machine\nlearning is an efficient and accurate way to detect COVID-19 infections.\nHowever, sharing diagnostic images across medical institutions is usually not\nallowed due to the concern of patients' privacy. This causes the issue of\ninsufficient datasets for training the image classification model. Federated\nlearning is an emerging privacy-preserving machine learning paradigm that\nproduces an unbiased global model based on the received updates of local models\ntrained by clients without exchanging clients' local data. Nevertheless, the\ndefault setting of federated learning introduces huge communication cost of\ntransferring model updates and can hardly ensure model performance when data\nheterogeneity of clients heavily exists. To improve communication efficiency\nand model performance, in this paper, we propose a novel dynamic fusion-based\nfederated learning approach for medical diagnostic image analysis to detect\nCOVID-19 infections. First, we design an architecture for dynamic fusion-based\nfederated learning systems to analyse medical diagnostic images. Further, we\npresent a dynamic fusion method to dynamically decide the participating clients\naccording to their local model performance and schedule the model fusion-based\non participating clients' training time. In addition, we summarise a category\nof medical diagnostic image datasets for COVID-19 detection, which can be used\nby the machine learning community for image analysis. The evaluation results\nshow that the proposed approach is feasible and performs better than the\ndefault setting of federated learning in terms of model performance,\ncommunication efficiency and fault tolerance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 09:09:10 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 01:38:33 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 09:04:14 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 01:37:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Weishan", ""], ["Zhou", "Tao", ""], ["Lu", "Qinghua", ""], ["Wang", "Xiao", ""], ["Zhu", "Chunsheng", ""], ["Sun", "Haoyun", ""], ["Wang", "Zhipeng", ""], ["Lo", "Sin Kit", ""], ["Wang", "Fei-Yue", ""]]}, {"id": "2009.10453", "submitter": "Daniel Hurtado", "authors": "Daniel Hurtado Ram\\'irez, J. M. Au\\~n\\'on", "title": "Privacy Preserving K-Means Clustering: A Secure Multi-Party Computation\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge discovery is one of the main goals of Artificial Intelligence. This\nKnowledge is usually stored in databases spread in different environments,\nbeing a tedious (or impossible) task to access and extract data from them. To\nthis difficulty we must add that these datasources may contain private data,\ntherefore the information can never leave the source. Privacy Preserving\nMachine Learning (PPML) helps to overcome this difficulty, employing\ncryptographic techniques, allowing knowledge discovery while ensuring data\nprivacy. K-means is one of the data mining techniques used in order to discover\nknowledge, grouping data points in clusters that contain similar features. This\npaper focuses in Privacy Preserving Machine Learning applied to K-means using\nrecent protocols from the field of criptography. The algorithm is applied to\ndifferent scenarios where data may be distributed either horizontally or\nvertically.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:19:24 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ram\u00edrez", "Daniel Hurtado", ""], ["Au\u00f1\u00f3n", "J. M.", ""]]}, {"id": "2009.10467", "submitter": "Ivan Tishchenko", "authors": "Ivan Tishchenko, Sandro Lombardi, Martin R. Oswald, Marc Pollefeys", "title": "Self-Supervised Learning of Non-Rigid Residual Flow and Ego-Motion", "comments": "Accepted to 3DV 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current scene flow methods choose to model scene flow as a per\npoint translation vector without differentiating between static and dynamic\ncomponents of 3D motion. In this work we present an alternative method for\nend-to-end scene flow learning by joint estimation of non-rigid residual flow\nand ego-motion flow for dynamic 3D scenes. We propose to learn the relative\nrigid transformation from a pair of point clouds followed by an iterative\nrefinement. We then learn the non-rigid flow from transformed inputs with the\ndeducted rigid part of the flow. Furthermore, we extend the supervised\nframework with self-supervisory signals based on the temporal consistency\nproperty of a point cloud sequence. Our solution allows both training in a\nsupervised mode complemented by self-supervisory loss terms as well as training\nin a fully self-supervised mode. We demonstrate that decomposition of scene\nflow into non-rigid flow and ego-motion flow along with an introduction of the\nself-supervisory signals allowed us to outperform the current state-of-the-art\nsupervised methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:39:19 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:21:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tishchenko", "Ivan", ""], ["Lombardi", "Sandro", ""], ["Oswald", "Martin R.", ""], ["Pollefeys", "Marc", ""]]}, {"id": "2009.10513", "submitter": "Nijat Mehdiyev", "authors": "Nijat Mehdiyev and Peter Fettke", "title": "Local Post-Hoc Explanations for Predictive Process Monitoring in\n  Manufacturing", "comments": "Accepted for publication in ECIS-2021 Proceedings (initial submission\n  November 18, 2020). This version is an extension of the previous arXiv\n  version", "journal-ref": "ECIS 2021 Research Papers. 35 (2021)\n  https://aisel.aisnet.org/ecis2021_rp/35", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an innovative explainable predictive quality analytics\nsolution to facilitate data-driven decision-making for process planning in\nmanufacturing by combining process mining, machine learning, and explainable\nartificial intelligence (XAI) methods. For this purpose, after integrating the\ntop-floor and shop-floor data obtained from various enterprise information\nsystems, a deep learning model was applied to predict the process outcomes.\nSince this study aims to operationalize the delivered predictive insights by\nembedding them into decision-making processes, it is essential to generate\nrelevant explanations for domain experts. To this end, two complementary local\npost-hoc explanation approaches, Shapley values and Individual Conditional\nExpectation (ICE) plots are adopted, which are expected to enhance the\ndecision-making capabilities by enabling experts to examine explanations from\ndifferent perspectives. After assessing the predictive strength of the applied\ndeep neural network with relevant binary classification evaluation measures, a\ndiscussion of the generated explanations is provided.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:07:17 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 08:58:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mehdiyev", "Nijat", ""], ["Fettke", "Peter", ""]]}, {"id": "2009.10514", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Moun\\^im A. El Yacoubi, Mehdi Ammi", "title": "Integration of Clinical Criteria into the Training of Deep Models:\n  Application to Glucose Prediction for Diabetic People", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard objective functions used during the training of neural-network-based\npredictive models do not consider clinical criteria, leading to models that are\nnot necessarily clinically acceptable. In this study, we look at this problem\nfrom the perspective of the forecasting of future glucose values for diabetic\npeople. In this study, we propose the coherent mean squared glycemic error\n(gcMSE) loss function. It penalizes the model during its training not only of\nthe prediction errors, but also on the predicted variation errors which is\nimportant in glucose prediction. Moreover, it makes possible to adjust the\nweighting of the different areas in the error space to better focus on\ndangerous regions. In order to use the loss function in practice, we propose an\nalgorithm that progressively improves the clinical acceptability of the model,\nso that we can achieve the best tradeoff possible between accuracy and given\nclinical criteria. We evaluate the approaches using two diabetes datasets, one\nhaving type-1 patients and the other type-2 patients. The results show that\nusing the gcMSE loss function, instead of a standard MSE loss function,\nimproves the clinical acceptability of the models. In particular, the\nimprovements are significant in the hypoglycemia region. We also show that this\nincreased clinical acceptability comes at the cost of a decrease in the average\naccuracy of the model. Finally, we show that this tradeoff between accuracy and\nclinical acceptability can be successfully addressed with the proposed\nalgorithm. For given clinical criteria, the algorithm can find the optimal\nsolution that maximizes the accuracy while at the same meeting the criteria.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:05:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 08:05:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["De Bois", "Maxime", ""], ["Yacoubi", "Moun\u00eem A. El", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.10524", "submitter": "Javad Hassannataj Joloudari", "authors": "Javad Hassannataj Joloudari, Mojtaba Haderbadi, Amir Mashmool,\n  Mohammad GhasemiGol, Shahab S., Amir Mosavi", "title": "Early detection of the advanced persistent threat attack using\n  performance analysis of deep learning", "comments": "38 pages, 15 figures, 5 tables", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3029202", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most common and important destructive attacks on the victim system\nis Advanced Persistent Threat (APT)-attack. The APT attacker can achieve his\nhostile goals by obtaining information and gaining financial benefits regarding\nthe infrastructure of a network. One of the solutions to detect a secret APT\nattack is using network traffic. Due to the nature of the APT attack in terms\nof being on the network for a long time and the fact that the network may crash\nbecause of high traffic, it is difficult to detect this type of attack. Hence,\nin this study, machine learning methods such as C5.0 decision tree, Bayesian\nnetwork and deep neural network are used for timely detection and\nclassification of APT-attacks on the NSL-KDD dataset. Moreover, 10-fold cross\nvalidation method is used to experiment these models. As a result, the accuracy\n(ACC) of the C5.0 decision tree, Bayesian network and 6-layer deep learning\nmodels is obtained as 95.64%, 88.37% and 98.85%, respectively, and also, in\nterms of the important criterion of the false positive rate (FPR), the FPR\nvalue for the C5.0 decision tree, Bayesian network and 6-layer deep learning\nmodels is obtained as 2.56, 10.47 and 1.13, respectively. Other criterions such\nas sensitivity, specificity, accuracy, false negative rate and F-measure are\nalso investigated for the models, and the experimental results show that the\ndeep learning model with automatic multi-layered extraction of features has the\nbest performance for timely detection of an APT-attack comparing to other\nclassification models.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:27:35 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Joloudari", "Javad Hassannataj", ""], ["Haderbadi", "Mojtaba", ""], ["Mashmool", "Amir", ""], ["GhasemiGol", "Mohammad", ""], ["S.", "Shahab", ""], ["Mosavi", "Amir", ""]]}, {"id": "2009.10526", "submitter": "Joong-Won Hwang", "authors": "Joong-Won Hwang, Youngwan Lee, Sungchan Oh, Yuseok Bae", "title": "Adversarial Training with Stochastic Weight Average", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training deep neural networks often experience serious\noverfitting problem. Recently, it is explained that the overfitting happens\nbecause the sample complexity of training data is insufficient to generalize\nrobustness. In traditional machine learning, one way to relieve overfitting\nfrom the lack of data is to use ensemble methods. However, adversarial training\nmultiple networks is extremely expensive. Moreover, we found that there is a\ndilemma on choosing target model to generate adversarial examples. Optimizing\nattack to the members of ensemble will be suboptimal attack to the ensemble and\nincurs covariate shift, while attack to ensemble will weaken the members and\nlose the benefit from ensembling. In this paper, we propose adversarial\ntraining with Stochastic weight average (SWA); while performing adversarial\ntraining, we aggregate the temporal weight states in the trajectory of\ntraining. By adopting SWA, the benefit of ensemble can be gained without\ntremendous computational increment and without facing the dilemma. Moreover, we\nfurther improved SWA to be adequate to adversarial training. The empirical\nresults on CIFAR-10, CIFAR-100 and SVHN show that our method can improve the\nrobustness of models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:47:20 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hwang", "Joong-Won", ""], ["Lee", "Youngwan", ""], ["Oh", "Sungchan", ""], ["Bae", "Yuseok", ""]]}, {"id": "2009.10537", "submitter": "Yaguan Qian", "authors": "Yaguan Qian, Qiqi Shao, Jiamin Wang, Xiang Lin, Yankai Guo, Zhaoquan\n  Gu, Bin Wang, Chunming Wu", "title": "EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the boom of edge intelligence, its vulnerability to adversarial attacks\nbecomes an urgent problem. The so-called adversarial example can fool a deep\nlearning model on the edge node to misclassify. Due to the property of\ntransferability, the adversary can easily make a black-box attack using a local\nsubstitute model. Nevertheless, the limitation of resource of edge nodes cannot\nafford a complicated defense mechanism as doing on the cloud data center. To\novercome the challenge, we propose a dynamic defense mechanism, namely EI-MTD.\nIt first obtains robust member models with small size through differential\nknowledge distillation from a complicated teacher model on the cloud data\ncenter. Then, a dynamic scheduling policy based on a Bayesian Stackelberg game\nis applied to the choice of a target model for service. This dynamic defense\ncan prohibit the adversary from selecting an optimal substitute model for\nblack-box attacks. Our experimental result shows that this dynamic scheduling\ncan effectively protect edge intelligence against adversarial attacks under the\nblack-box setting.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:04:18 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 02:44:15 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 01:13:39 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Qian", "Yaguan", ""], ["Shao", "Qiqi", ""], ["Wang", "Jiamin", ""], ["Lin", "Xiang", ""], ["Guo", "Yankai", ""], ["Gu", "Zhaoquan", ""], ["Wang", "Bin", ""], ["Wu", "Chunming", ""]]}, {"id": "2009.10562", "submitter": "Anjukan Kathirgamanathan", "authors": "Anjukan Kathirgamanathan, Kacper Twardowski, Eleni Mangina, Donal Finn", "title": "A Centralised Soft Actor Critic Deep Reinforcement Learning Approach to\n  District Demand Side Management through CityLearn", "comments": "Accepted for ACM BuildSys2020 RLEM'20 Workshop", "journal-ref": null, "doi": "10.1145/3427773.3427869", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising model-free and adaptive controller for\ndemand side management, as part of the future smart grid, at the district\nlevel. This paper presents the results of the algorithm that was submitted for\nthe CityLearn Challenge, which was hosted in early 2020 with the aim of\ndesigning and tuning a reinforcement learning agent to flatten and smooth the\naggregated curve of electrical demand of a district of diverse buildings. The\nproposed solution secured second place in the challenge using a centralised\n'Soft Actor Critic' deep reinforcement learning agent that was able to handle\ncontinuous action spaces. The controller was able to achieve an averaged score\nof 0.967 on the challenge dataset comprising of different buildings and\nclimates. This highlights the potential application of deep reinforcement\nlearning as a plug-and-play style controller, that is capable of handling\ndifferent climates and a heterogenous building stock, for district demand side\nmanagement of buildings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:03:11 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kathirgamanathan", "Anjukan", ""], ["Twardowski", "Kacper", ""], ["Mangina", "Eleni", ""], ["Finn", "Donal", ""]]}, {"id": "2009.10574", "submitter": "Steffen van Bergerem", "authors": "Steffen van Bergerem, Nicole Schweikardt", "title": "Learning Concepts Described by Weight Aggregation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider weighted structures, which extend ordinary relational structures\nby assigning weights, i.e. elements from a particular group or ring, to tuples\npresent in the structure. We introduce an extension of first-order logic that\nallows to aggregate weights of tuples, compare such aggregates, and use them to\nbuild more complex formulas. We provide locality properties of fragments of\nthis logic including Feferman-Vaught decompositions and a Gaifman normal form\nfor a fragment called FOW1, as well as a localisation theorem for a larger\nfragment called FOWA1. This fragment can express concepts from various machine\nlearning scenarios. Using the locality properties, we show that concepts\ndefinable in FOWA1 over a weighted background structure of at most\npolylogarithmic degree are agnostically PAC-learnable in polylogarithmic time\nafter pseudo-linear time preprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:32:42 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["van Bergerem", "Steffen", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "2009.10576", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Emma Pierson, Sherri Rose, Shalmali Joshi, Kadija\n  Ferryman, and Marzyeh Ghassemi", "title": "Ethical Machine Learning in Health Care", "comments": "Annual Reviews in Biomedical Data Science 2021", "journal-ref": null, "doi": "10.1146/annurev-biodatasci-092820-114757", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of machine learning (ML) in health care raises numerous ethical\nconcerns, especially as models can amplify existing health inequities. Here, we\noutline ethical considerations for equitable ML in the advancement of health\ncare. Specifically, we frame ethics of ML in health care through the lens of\nsocial justice. We describe ongoing efforts and outline challenges in a\nproposed pipeline of ethical ML in health, ranging from problem selection to\npost-deployment considerations. We close by summarizing recommendations to\naddress these challenges.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:34:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 12:16:57 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 03:26:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chen", "Irene Y.", ""], ["Pierson", "Emma", ""], ["Rose", "Sherri", ""], ["Joshi", "Shalmali", ""], ["Ferryman", "Kadija", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2009.10588", "submitter": "Guozhang Chen", "authors": "Guozhang Chen, Cheng Kevin Qu, Pulin Gong", "title": "Anomalous diffusion dynamics of learning in deep neural networks", "comments": "10 pages, 8 figures, a new angle to unravel the learning dynamics of\n  SGD in DNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in deep neural networks (DNNs) is implemented through minimizing a\nhighly non-convex loss function, typically by a stochastic gradient descent\n(SGD) method. This learning process can effectively find good wide minima\nwithout being trapped in poor local ones. We present a novel account of how\nsuch effective deep learning emerges through the interactions of the SGD and\nthe geometrical structure of the loss landscape. Rather than being a normal\ndiffusion process (i.e. Brownian motion) as often assumed, we find that the SGD\nexhibits rich, complex dynamics when navigating through the loss landscape;\ninitially, the SGD exhibits anomalous superdiffusion, which attenuates\ngradually and changes to subdiffusion at long times when the solution is\nreached. Such learning dynamics happen ubiquitously in different DNNs such as\nResNet and VGG-like networks and are insensitive to batch size and learning\nrate. The anomalous superdiffusion process during the initial learning phase\nindicates that the motion of SGD along the loss landscape possesses\nintermittent, big jumps; this non-equilibrium property enables the SGD to\nescape from sharp local minima. By adapting the methods developed for studying\nenergy landscapes in complex physical systems, we find that such superdiffusive\nlearning dynamics are due to the interactions of the SGD and the fractal-like\nstructure of the loss landscape. We further develop a simple model to\ndemonstrate the mechanistic role of the fractal loss landscape in enabling the\nSGD to effectively find global minima. Our results thus reveal the\neffectiveness of deep learning from a novel perspective and have implications\nfor designing efficient deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:57:59 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 08:13:24 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Guozhang", ""], ["Qu", "Cheng Kevin", ""], ["Gong", "Pulin", ""]]}, {"id": "2009.10606", "submitter": "Yue Zhao", "authors": "Yue Zhao, Ryan A. Rossi, Leman Akoglu", "title": "Automating Outlier Detection via Meta-Learning", "comments": "21 pages. The code is available at http://github.com/yzhao062/MetaOD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an unsupervised outlier detection (OD) task on a new dataset, how can\nwe automatically select a good outlier detection method and its\nhyperparameter(s) (collectively called a model)? Thus far, model selection for\nOD has been a \"black art\"; as any model evaluation is infeasible due to the\nlack of (i) hold-out data with labels, and (ii) a universal objective function.\nIn this work, we develop the first principled data-driven approach to model\nselection for OD, called MetaOD, based on meta-learning. MetaOD capitalizes on\nthe past performances of a large body of detection models on existing outlier\ndetection benchmark datasets, and carries over this prior experience to\nautomatically select an effective model to be employed on a new dataset without\nusing any labels. To capture task similarity, we introduce specialized\nmeta-features that quantify outlying characteristics of a dataset. Through\ncomprehensive experiments, we show the effectiveness of MetaOD in selecting a\ndetection model that significantly outperforms the most popular outlier\ndetectors (e.g., LOF and iForest) as well as various state-of-the-art\nunsupervised meta-learners while being extremely fast. To foster\nreproducibility and further research on this new problem, we open-source our\nentire meta-learning system, benchmark environment, and testbed datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:14:45 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:44:35 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Zhao", "Yue", ""], ["Rossi", "Ryan A.", ""], ["Akoglu", "Leman", ""]]}, {"id": "2009.10610", "submitter": "Daniel Neider", "authors": "Igor Khmelnitsky, Daniel Neider, Rajarshi Roy, Beno\\^it Barbot,\n  Benedikt Bollig, Alain Finkel, Serge Haddad, Martin Leucker, Lina Ye", "title": "Property-Directed Verification of Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a property-directed approach to verifying recurrent\nneural networks (RNNs). To this end, we learn a deterministic finite automaton\nas a surrogate model from a given RNN using active automata learning. This\nmodel may then be analyzed using model checking as verification technique. The\nterm property-directed reflects the idea that our procedure is guided and\ncontrolled by the given property rather than performing the two steps\nseparately. We show that this not only allows us to discover small\ncounterexamples fast, but also to generalize them by pumping towards faulty\nflows hinting at the underlying error in the RNN.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:15:20 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Khmelnitsky", "Igor", ""], ["Neider", "Daniel", ""], ["Roy", "Rajarshi", ""], ["Barbot", "Beno\u00eet", ""], ["Bollig", "Benedikt", ""], ["Finkel", "Alain", ""], ["Haddad", "Serge", ""], ["Leucker", "Martin", ""], ["Ye", "Lina", ""]]}, {"id": "2009.10616", "submitter": "Anas Blasi", "authors": "Mohammad Awis Al Lababede, Anas H. Blasi, Mohammed A. Alsuwaiket", "title": "Mosques Smart Domes System using Machine Learning Algorithms", "comments": null, "journal-ref": null, "doi": "10.14569/IJACSA.2020.0110347", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of mosques around the world are suffering some problems such as\nventilation and difficulty getting rid of bacteria, especially in rush hours\nwhere congestion in mosques leads to air pollution and spread of bacteria, in\naddition to unpleasant odors and to a state of discomfort during the pray\ntimes, where in most mosques there are no enough windows to ventilate the\nmosque well. This paper aims to solve these problems by building a model of\nsmart mosques domes using weather features and outside temperatures. Machine\nlearning algorithms such as k Nearest Neighbors and Decision Tree were applied\nto predict the state of the domes open or close. The experiments of this paper\nwere applied on Prophet mosque in Saudi Arabia, which basically contains twenty\nseven manually moving domes. Both machine learning algorithms were tested and\nevaluated using different evaluation methods. After comparing the results for\nboth algorithms, DT algorithm was achieved higher accuracy 98% comparing with\n95% accuracy for kNN algorithm. Finally, the results of this study were\npromising and will be helpful for all mosques to use our proposed model for\ncontrolling domes automatically.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 19:51:30 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lababede", "Mohammad Awis Al", ""], ["Blasi", "Anas H.", ""], ["Alsuwaiket", "Mohammed A.", ""]]}, {"id": "2009.10618", "submitter": "Fauzi Adi Rafrastara", "authors": "Fauzi Adi Rafrastara, Qi Deyu", "title": "A Survey and Taxonomy of Distributed Data Mining Research Studies: A\n  Systematic Literature Review", "comments": "19 pages, 14 figures, International Journal of Computer Science and\n  Information Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Data Mining (DM) method has been evolving year by year and as of\ntoday there is also the enhancement of DM technique that can be run several\ntimes faster than the traditional one, called Distributed Data Mining (DDM). It\nis not a new field in data processing actually, but in the recent years many\nresearchers have been paying more attention on this area. Problems: The number\nof publication regarding DDM in high reputation journals and conferences has\nincreased significantly. It makes difficult for researchers to gain a\ncomprehensive view of DDM that require further research. Solution: We conducted\na systematic literature review to map the previous research in DDM field. Our\nobjective is to provide the motivation for new research by identifying the gap\nin DDM field as well as the hot area itself. Result: Our analysis came up with\nsome conclusions by answering 7 research questions proposed in this literature\nreview. In addition, the taxonomy of DDM research area is presented in this\npaper. Finally, this systematic literature review provides the statistic of\ndevelopment of DDM since 2000 to 2015, in which this will help the future\nresearchers to have a comprehensive overview of current situation of DDM.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:58:42 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Rafrastara", "Fauzi Adi", ""], ["Deyu", "Qi", ""]]}, {"id": "2009.10619", "submitter": "Chongshou Li Dr", "authors": "Chongshou Li, Brenda Cheang, Zhixing Luo and Andrew Lim", "title": "An Exponential Factorization Machine with Percentage Error Minimization\n  to Retail Sales Forecasting", "comments": "Accepted by ACM Transactions on Knowledge Discovery from Data (ACM\n  TKDD)", "journal-ref": "ACM Transactions on Knowledge Discovery from Data 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new approach to sales forecasting for new products with\nlong lead time but short product life cycle. These SKUs are usually sold for\none season only, without any replenishments. An exponential factorization\nmachine (EFM) sales forecast model is developed to solve this problem which not\nonly considers SKU attributes, but also pairwise interactions. The EFM model is\nsignificantly different from the original Factorization Machines (FM) from\ntwo-fold: (1) the attribute-level formulation for explanatory variables and (2)\nexponential formulation for the positive response variable. The attribute-level\nformation excludes infeasible intra-attribute interactions and results in more\nefficient feature engineering comparing with the conventional one-hot encoding,\nwhile the exponential formulation is demonstrated more effective than the\nlog-transformation for the positive but not skewed distributed responses. In\norder to estimate the parameters, percentage error squares (PES) and error\nsquares (ES) are minimized by a proposed adaptive batch gradient descent method\nover the training set. Real-world data provided by a footwear retailer in\nSingapore is used for testing the proposed approach. The forecasting\nperformance in terms of both mean absolute percentage error (MAPE) and mean\nabsolute error (MAE) compares favourably with not only off-the-shelf models but\nalso results reported by extant sales and demand forecasting studies. The\neffectiveness of the proposed approach is also demonstrated by two external\npublic datasets. Moreover, we prove the theoretical relationships between PES\nand ES minimization, and present an important property of the PES minimization\nfor regression models; that it trains models to underestimate data. This\nproperty fits the situation of sales forecasting where unit-holding cost is\nmuch greater than the unit-shortage cost.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:21:38 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Li", "Chongshou", ""], ["Cheang", "Brenda", ""], ["Luo", "Zhixing", ""], ["Lim", "Andrew", ""]]}, {"id": "2009.10622", "submitter": "TrungTin Nguyen", "authors": "TrungTin Nguyen, Hien D Nguyen, Faicel Chamroukhi and Geoffrey J\n  McLachlan", "title": "An $l_1$-oracle inequality for the Lasso in mixture-of-experts\n  regression models", "comments": "Corrected typos. Added new Section 4. Discussion and comparisons", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture-of-experts (MoE) models are a popular framework for modeling\nheterogeneity in data, for both regression and classification problems in\nstatistics and machine learning, due to their flexibility and the abundance of\nstatistical estimation and model choice tools. Such flexibility comes from\nallowing the mixture weights (or gating functions) in the MoE model to depend\non the explanatory variables, along with the experts (or component densities).\nThis permits the modeling of data arising from more complex data generating\nprocesses, compared to the classical finite mixtures and finite mixtures of\nregression models, whose mixing parameters are independent of the covariates.\nThe use of MoE models in a high-dimensional setting, when the number of\nexplanatory variables can be much larger than the sample size (i.e., $p\\gg n$),\nis challenging from a computational point of view, and in particular from a\ntheoretical point of view, where the literature is still lacking results in\ndealing with the curse of dimensionality, in both the statistical estimation\nand feature selection. We consider the finite mixture-of-experts model with\nsoft-max gating functions and Gaussian experts for high-dimensional regression\non heterogeneous data, and its $l_1$-regularized estimation via the Lasso. We\nfocus on the Lasso estimation properties rather than its feature selection\nproperties. We provide a lower bound on the regularization parameter of the\nLasso function that ensures an $l_1$-oracle inequality satisfied by the Lasso\nestimator according to the Kullback-Leibler loss.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:23:35 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 17:28:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nguyen", "TrungTin", ""], ["Nguyen", "Hien D", ""], ["Chamroukhi", "Faicel", ""], ["McLachlan", "Geoffrey J", ""]]}, {"id": "2009.10623", "submitter": "Ferran Alet", "authors": "Ferran Alet, Maria Bauza, Kenji Kawaguchi, Nurullah Giray Kuru, Tomas\n  Lozano-Perez, Leslie Pack Kaelbling", "title": "Tailoring: encoding inductive biases by optimizing unsupervised\n  objectives at prediction time", "comments": "NeurIPS 2020 workshops on Interpretable Inductive Biases and\n  Meta-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From CNNs to attention mechanisms, encoding inductive biases into neural\nnetworks has been a fruitful source of improvement in machine learning. Adding\nauxiliary losses to the main objective function is a general way of encoding\nbiases that can help networks learn better representations. However, since\nauxiliary losses are minimized only on training data, they suffer from the same\ngeneralization gap as regular task losses. Moreover, by adding a term to the\nloss function, the model optimizes a different objective than the one we care\nabout. In this work we address both problems: first, we take inspiration from\ntransductive learning and note that, after receiving an input but before making\na prediction, we can fine-tune our networks on any unsupervised loss. We call\nthis process tailoring, because we customize the model to each input to ensure\nour prediction satisfies the inductive bias. Second, we formulate\nmeta-tailoring, a nested optimization similar to that in meta-learning, and\ntrain our models to perform well on the task objective after adapting them\nusing an unsupervised loss.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:26:24 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 00:43:24 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 18:43:40 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Alet", "Ferran", ""], ["Bauza", "Maria", ""], ["Kawaguchi", "Kenji", ""], ["Kuru", "Nurullah Giray", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "2009.10625", "submitter": "Petru Soviany", "authors": "Petru Soviany", "title": "Curriculum Learning with Diversity for Supervised Computer Vision Tasks", "comments": "Accepted at MRC 2020 @ ECAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Curriculum learning techniques are a viable solution for improving the\naccuracy of automatic models, by replacing the traditional random training with\nan easy-to-hard strategy. However, the standard curriculum methodology does not\nautomatically provide improved results, but it is constrained by multiple\nelements like the data distribution or the proposed model. In this paper, we\nintroduce a novel curriculum sampling strategy which takes into consideration\nthe diversity of the training data together with the difficulty of the inputs.\nWe determine the difficulty using a state-of-the-art estimator based on the\nhuman time required for solving a visual search task. We consider this kind of\ndifficulty metric to be better suited for solving general problems, as it is\nnot based on certain task-dependent elements, but more on the context of each\nimage. We ensure the diversity during training, giving higher priority to\nelements from less visited classes. We conduct object detection and instance\nsegmentation experiments on Pascal VOC 2007 and Cityscapes data sets,\nsurpassing both the randomly-trained baseline and the standard curriculum\napproach. We prove that our strategy is very efficient for unbalanced data\nsets, leading to faster convergence and more accurate results, when other\ncurriculum-based strategies fail.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:32:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Soviany", "Petru", ""]]}, {"id": "2009.10627", "submitter": "Antoine Vendeville", "authors": "Antoine Vendeville and Benjamin Guedj and Shi Zhou", "title": "Forecasting elections results via the voter model with stubborn nodes", "comments": "14 pages", "journal-ref": null, "doi": "10.1007/s41109-020-00342-7", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we propose a novel method to forecast the result of elections\nusing only official results of previous ones. It is based on the voter model\nwith stubborn nodes and uses theoretical results developed in a previous work\nof ours. We look at popular vote shares for the Conservative and Labour parties\nin the UK and the Republican and Democrat parties in the US. We are able to\nperform time-evolving estimates of the model parameters and use these to\nforecast the vote shares for each party in any election. We obtain a mean\nabsolute error of 4.74\\%. As a side product, our parameters estimates provide\nmeaningful insight on the political landscape, informing us on the proportion\nof voters that are strong supporters of each of the considered parties.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:36:59 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 18:36:45 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Vendeville", "Antoine", ""], ["Guedj", "Benjamin", ""], ["Zhou", "Shi", ""]]}, {"id": "2009.10632", "submitter": "Armin Moin", "authors": "Armin Moin, Stephan R\\\"ossler, Marouane Sayih, Stephan G\\\"unnemann", "title": "From Things' Modeling Language (ThingML) to Things' Machine Learning\n  (ThingML2)", "comments": "International Conference on Model Driven Engineering Languages and\n  Systems (MODELS) 2020 Poster Companion (Extended Abstract)", "journal-ref": "Proceedings of the 23rd ACM/IEEE International Conference on Model\n  Driven Engineering Languages and Systems: Companion Proceedings, 2020", "doi": "10.1145/3417990.3420057", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we illustrate how to enhance an existing state-of-the-art\nmodeling language and tool for the Internet of Things (IoT), called ThingML, to\nsupport machine learning on the modeling level. To this aim, we extend the\nDomain-Specific Language (DSL) of ThingML, as well as its code generation\nframework. Our DSL allows one to define things, which are in charge of carrying\nout data analytics. Further, our code generators can automatically produce the\ncomplete implementation in Java and Python. The generated Python code is\nresponsible for data analytics and employs APIs of machine learning libraries,\nsuch as Keras, Tensorflow and Scikit Learn. Our prototype is available as open\nsource software on Github.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:44:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Moin", "Armin", ""], ["R\u00f6ssler", "Stephan", ""], ["Sayih", "Marouane", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2009.10633", "submitter": "Armin Moin", "authors": "Armin Moin, Stephan R\\\"ossler, Stephan G\\\"unnemann", "title": "ThingML+ Augmenting Model-Driven Software Engineering for the Internet\n  of Things with Machine Learning", "comments": "Published in Proc. of the International Conference on Model Driven\n  Engineering Languages and Systems (MODELS) 2018 Workshops (MDE4IoT)", "journal-ref": "Proceedings of MODELS 2018 Workshops (MDE4IoT), co-located with\n  the ACM/IEEE 21st International Conference on Model Driven Engineering\n  Languages and Systems (MODELS), Copenhagen, Denmark, 2018", "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the current position of the research project\nML-Quadrat, which aims to extend the methodology, modeling language and tool\nsupport of ThingML - an open source modeling tool for IoT/CPS - to address\nMachine Learning needs for the IoT applications. Currently, ThingML offers a\nmodeling language and tool support for modeling the components of the system,\ntheir communication interfaces as well as their behaviors. The latter is done\nthrough state machines. However, we argue that in many cases IoT/CPS services\ninvolve system components and physical processes, whose behaviors are not well\nunderstood in order to be modeled using state machines. Hence, quite often a\ndata-driven approach that enables inference based on the observed data, e.g.,\nusing Machine Learning is preferred. To this aim, ML-Quadrat integrates the\nnecessary Machine Learning concepts into ThingML both on the modeling level\n(syntax and semantics of the modeling language) and on the code generators\nlevel. We plan to support two target platforms for code generation regarding\nStream Processing and Complex Event Processing, namely Apache SAMOA and Apama.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:45:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Moin", "Armin", ""], ["R\u00f6ssler", "Stephan", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2009.10639", "submitter": "Yi-Shan Lin", "authors": "Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik", "title": "What Do You See? Evaluation of Explainable Artificial Intelligence (XAI)\n  Interpretability through Neural Backdoors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EXplainable AI (XAI) methods have been proposed to interpret how a deep\nneural network predicts inputs through model saliency explanations that\nhighlight the parts of the inputs deemed important to arrive a decision at a\nspecific target. However, it remains challenging to quantify correctness of\ntheir interpretability as current evaluation approaches either require\nsubjective input from humans or incur high computation cost with automated\nevaluation. In this paper, we propose backdoor trigger patterns--hidden\nmalicious functionalities that cause misclassification--to automate the\nevaluation of saliency explanations. Our key observation is that triggers\nprovide ground truth for inputs to evaluate whether the regions identified by\nan XAI method are truly relevant to its output. Since backdoor triggers are the\nmost important features that cause deliberate misclassification, a robust XAI\nmethod should reveal their presence at inference time. We introduce three\ncomplementary metrics for systematic evaluation of explanations that an XAI\nmethod generates and evaluate seven state-of-the-art model-free and\nmodel-specific posthoc methods through 36 models trojaned with specifically\ncrafted triggers using color, shape, texture, location, and size. We discovered\nsix methods that use local explanation and feature relevance fail to completely\nhighlight trigger regions, and only a model-free approach can uncover the\nentire trigger region.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:53:19 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lin", "Yi-Shan", ""], ["Lee", "Wen-Chuan", ""], ["Celik", "Z. Berkay", ""]]}, {"id": "2009.10641", "submitter": "Jes\\'us Daniel Arroyo Reli\\'on", "authors": "Jes\\'us Arroyo, Elizaveta Levina", "title": "Overlapping community detection in networks via sparse spectral\n  decomposition", "comments": null, "journal-ref": null, "doi": "10.1007/s13171-021-00245-4", "report-no": null, "categories": "cs.SI cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating overlapping community memberships in a\nnetwork, where each node can belong to multiple communities. More than a few\ncommunities per node are difficult to both estimate and interpret, so we focus\non sparse node membership vectors. Our algorithm is based on sparse principal\nsubspace estimation with iterative thresholding. The method is computationally\nefficient, with a computational cost equivalent to estimating the leading\neigenvectors of the adjacency matrix, and does not require an additional\nclustering step, unlike spectral clustering methods. We show that a fixed point\nof the algorithm corresponds to correct node memberships under a version of the\nstochastic block model. The methods are evaluated empirically on simulated and\nreal-world networks, showing good statistical performance and computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:31:09 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 06:43:18 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Arroyo", "Jes\u00fas", ""], ["Levina", "Elizaveta", ""]]}, {"id": "2009.10644", "submitter": "Daniel Dunlavy", "authors": "Alexis Cooper and Xin Zhou and Scott Heidbrink and Daniel M. Dunlavy", "title": "Using Neural Architecture Search for Improving Software Flaw Detection\n  in Multimodal Deep Learning Models", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": "SAND2020-10141R", "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software flaw detection using multimodal deep learning models has been\ndemonstrated as a very competitive approach on benchmark problems. In this\nwork, we demonstrate that even better performance can be achieved using neural\narchitecture search (NAS) combined with multimodal learning models. We adapt a\nNAS framework aimed at investigating image classification to the problem of\nsoftware flaw detection and demonstrate improved results on the Juliet Test\nSuite, a popular benchmarking data set for measuring performance of machine\nlearning models in this problem domain.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:59:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cooper", "Alexis", ""], ["Zhou", "Xin", ""], ["Heidbrink", "Scott", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "2009.10645", "submitter": "Chen Zhang", "authors": "Jie Guo, Hao Yan, Chen Zhang, Steven Hoi", "title": "Partially Observable Online Change Detection via Smooth-Sparse\n  Decomposition", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online change detection of high dimensional data streams with\nsparse changes, where only a subset of data streams can be observed at each\nsensing time point due to limited sensing capacities. On the one hand, the\ndetection scheme should be able to deal with partially observable data and\nmeanwhile have efficient detection power for sparse changes. On the other, the\nscheme should be able to adaptively and actively select the most important\nvariables to observe to maximize the detection power. To address these two\npoints, in this paper, we propose a novel detection scheme called CDSSD. In\nparticular, it describes the structure of high dimensional data with sparse\nchanges by smooth-sparse decomposition, whose parameters can be learned via\nspike-slab variational Bayesian inference. Then the posterior Bayes factor,\nwhich incorporates the learned parameters and sparse change information, is\nformulated as a detection statistic. Finally, by formulating the statistic as\nthe reward of a combinatorial multi-armed bandit problem, an adaptive sampling\nstrategy based on Thompson sampling is proposed. The efficacy and applicability\nof our method in practice are demonstrated with numerical studies and a real\ncase study.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:03:04 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Guo", "Jie", ""], ["Yan", "Hao", ""], ["Zhang", "Chen", ""], ["Hoi", "Steven", ""]]}, {"id": "2009.10656", "submitter": "Franyell Silfa", "authors": "Franyell Silfa, Jose Maria Arnau, and Antonio Gonzalez", "title": "E-BATCH: Energy-Efficient and High-Throughput RNN Batching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) inference exhibits low hardware utilization\ndue to the strict data dependencies across time-steps. Batching multiple\nrequests can increase throughput. However, RNN batching requires a large amount\nof padding since the batched input sequences may largely differ in length.\nSchemes that dynamically update the batch every few time-steps avoid padding.\nHowever, they require executing different RNN layers in a short timespan,\ndecreasing energy efficiency. Hence, we propose E-BATCH, a low-latency and\nenergy-efficient batching scheme tailored to RNN accelerators. It consists of a\nruntime system and effective hardware support. The runtime concatenates\nmultiple sequences to create large batches, resulting in substantial energy\nsavings. Furthermore, the accelerator notifies it when the evaluation of a\nsequence is done, so that a new sequence can be immediately added to a batch,\nthus largely reducing the amount of padding. E-BATCH dynamically controls the\nnumber of time-steps evaluated per batch to achieve the best trade-off between\nlatency and energy efficiency for the given hardware platform. We evaluate\nE-BATCH on top of E-PUR and TPU. In E-PUR, E-BATCH improves throughput by 1.8x\nand energy-efficiency by 3.6x, whereas in TPU, it improves throughput by 2.1x\nand energy-efficiency by 1.6x, over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:22:23 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Silfa", "Franyell", ""], ["Arnau", "Jose Maria", ""], ["Gonzalez", "Antonio", ""]]}, {"id": "2009.10670", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Vidya Muthukumar, Ji Xu", "title": "On the proliferation of support vectors in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) is a well-established classification method\nwhose name refers to the particular training examples, called support vectors,\nthat determine the maximum margin separating hyperplane. The SVM classifier is\nknown to enjoy good generalization properties when the number of support\nvectors is small compared to the number of training examples. However, recent\nresearch has shown that in sufficiently high-dimensional linear classification\nproblems, the SVM can generalize well despite a proliferation of support\nvectors where all training examples are support vectors. In this paper, we\nidentify new deterministic equivalences for this phenomenon of support vector\nproliferation, and use them to (1) substantially broaden the conditions under\nwhich the phenomenon occurs in high-dimensional settings, and (2) prove a\nnearly matching converse result.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:45:06 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hsu", "Daniel", ""], ["Muthukumar", "Vidya", ""], ["Xu", "Ji", ""]]}, {"id": "2009.10674", "submitter": "Rohit Singh Dr.", "authors": "Rohit Singh and Doug Sicker", "title": "Ultra-dense Low Data Rate (UDLD) Communication in the THz", "comments": "9 Figures; To be published at ACM NANOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the future, with the advent of Internet of Things (IoT), wireless sensors,\nand multiple 5G killer applications, an indoor room might be filled with\n$1000$s of devices demanding low data rates. Such high-level densification and\nmobility of these devices will overwhelm the system and result in higher\ninterference, frequent outages, and lower coverage. The THz band has a massive\namount of greenfield spectrum to cater to this dense-indoor deployment.\nHowever, a limited coverage range of the THz will require networks to have more\ninfrastructure and depend on non-line-of-sight (NLOS) type communication. This\nform of communication might not be profitable for network operators and can\neven result in inefficient resource utilization for devices demanding low data\nrates. Using distributed device-to-device (D2D) communication in the THz, we\ncan cater to these Ultra-dense Low Data Rate (UDLD) type applications. D2D in\nTHz can be challenging, but with opportunistic allocation and smart learning\nalgorithms, these challenges can be mitigated. We propose a 2-Layered\ndistributed D2D model, where devices use coordinated multi-agent reinforcement\nlearning (MARL) to maximize efficiency and user coverage for dense-indoor\ndeployment. We show that densification and mobility in a network can be used to\nfurther the limited coverage range of THz devices, without the need for extra\ninfrastructure or resources.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:52:58 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Singh", "Rohit", ""], ["Sicker", "Doug", ""]]}, {"id": "2009.10683", "submitter": "Lin Chen", "authors": "Lin Chen, Sheng Xu", "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural\ntangent kernel and the Laplace kernel include the same set of functions, when\nboth kernels are restricted to the sphere $\\mathbb{S}^{d-1}$. Additionally, we\nprove that the exponential power kernel with a smaller power (making the kernel\nless smooth) leads to a larger RKHS, when it is restricted to the sphere\n$\\mathbb{S}^{d-1}$ and when it is defined on the entire $\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:58:26 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 01:32:06 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:49:40 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 06:45:23 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 14:56:31 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chen", "Lin", ""], ["Xu", "Sheng", ""]]}, {"id": "2009.10684", "submitter": "Bruno Taill\\'e", "authors": "Bruno Taill\\'e, Vincent Guigue, Geoffrey Scoutheeten and Patrick\n  Gallinari", "title": "Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite efforts to distinguish three different evaluation setups (Bekoulis et\nal., 2018), numerous end-to-end Relation Extraction (RE) articles present\nunreliable performance comparison to previous work. In this paper, we first\nidentify several patterns of invalid comparisons in published papers and\ndescribe them to avoid their propagation. We then propose a small empirical\nstudy to quantify the impact of the most common mistake and evaluate it leads\nto overestimating the final RE performance by around 5% on ACE05. We also seize\nthis opportunity to study the unexplored ablations of two recent developments:\nthe use of language model pretraining (specifically BERT) and span-level NER.\nThis meta-analysis emphasizes the need for rigor in the report of both the\nevaluation setting and the datasets statistics and we call for unifying the\nevaluation setting in end-to-end RE.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:59:15 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:43:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Taill\u00e9", "Bruno", ""], ["Guigue", "Vincent", ""], ["Scoutheeten", "Geoffrey", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2009.10692", "submitter": "Ramtin Zand", "authors": "Brendan Reidy, Golareh Jalilvand, Tengfei Jiang, Ramtin Zand", "title": "TSV Extrusion Morphology Classification Using Deep Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we utilize deep convolutional neural networks (CNNs) to\nclassify the morphology of through-silicon via (TSV) extrusion in three\ndimensional (3D) integrated circuits (ICs). TSV extrusion is a crucial\nreliability concern which can deform and crack interconnect layers in 3D ICs\nand cause device failures. Herein, the white light interferometry (WLI)\ntechnique is used to obtain the surface profile of the extruded TSVs. We have\ndeveloped a program that uses raw data obtained from WLI to create a TSV\nextrusion morphology dataset, including TSV images with 54x54 pixels that are\nlabeled and categorized into three morphology classes. Four CNN architectures\nwith different network complexities are implemented and trained for TSV\nextrusion morphology classification application. Data augmentation and dropout\napproaches are utilized to realize a balance between overfitting and\nunderfitting in the CNN models. Results obtained show that the CNN model with\noptimized complexity, dropout, and data augmentation can achieve a\nclassification accuracy comparable to that of a human expert.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:05:55 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Reidy", "Brendan", ""], ["Jalilvand", "Golareh", ""], ["Jiang", "Tengfei", ""], ["Zand", "Ramtin", ""]]}, {"id": "2009.10713", "submitter": "Stephan Wojtowytsch", "authors": "Weinan E, Chao Ma, Stephan Wojtowytsch and Lei Wu", "title": "Towards a Mathematical Understanding of Neural Network-Based Machine\n  Learning: what we know and what we don't", "comments": "Review article. Feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this article is to review the achievements made in the last\nfew years towards the understanding of the reasons behind the success and\nsubtleties of neural network-based machine learning. In the tradition of good\nold applied mathematics, we will not only give attention to rigorous\nmathematical results, but also the insight we have gained from careful\nnumerical experiments as well as the analysis of simplified models. Along the\nway, we also list the open problems which we believe to be the most important\ntopics for further study. This is not a complete overview over this quickly\nmoving field, but we hope to provide a perspective which may be helpful\nespecially to new researchers in the area.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:55:47 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:51:11 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 23:36:20 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wojtowytsch", "Stephan", ""], ["Wu", "Lei", ""]]}, {"id": "2009.10717", "submitter": "Margalit Glasgow", "authors": "Margalit Glasgow, Mary Wootters", "title": "Asynchronous Distributed Optimization with Stochastic Delays", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.09638", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asynchronous finite sum minimization in a distributed-data setting\nwith a central parameter server. While asynchrony is well understood in\nparallel settings where the data is accessible by all machines -- e.g.,\nmodifications of variance-reduced gradient algorithms like SAGA work well --\nlittle is known for the distributed-data setting. We develop an algorithm\nADSAGA based on SAGA for the distributed-data setting, in which the data is\npartitioned between many machines. We show that with $m$ machines, under a\nnatural stochastic delay model with an mean delay of $m$, ADSAGA converges in\n$\\tilde{O}\\left(\\left(n + \\sqrt{m}\\kappa\\right)\\log(1/\\epsilon)\\right)$\niterations, where $n$ is the number of component functions, and $\\kappa$ is a\ncondition number. This complexity sits squarely between the complexity\n$\\tilde{O}\\left(\\left(n + \\kappa\\right)\\log(1/\\epsilon)\\right)$ of SAGA\n\\textit{without delays} and the complexity $\\tilde{O}\\left(\\left(n +\nm\\kappa\\right)\\log(1/\\epsilon)\\right)$ of parallel asynchronous algorithms\nwhere the delays are \\textit{arbitrary} (but bounded by $O(m)$), and the data\nis accessible by all. Existing asynchronous algorithms with distributed-data\nsetting and arbitrary delays have only been shown to converge in\n$\\tilde{O}(n^2\\kappa\\log(1/\\epsilon))$ iterations. We empirically compare on\nleast-squares problems the iteration complexity and wallclock performance of\nADSAGA to existing parallel and distributed algorithms, including synchronous\nminibatch algorithms. Our results demonstrate the wallclock advantage of\nvariance-reduced asynchronous approaches over SGD or synchronous approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:59:06 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 05:13:23 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 05:35:10 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Glasgow", "Margalit", ""], ["Wootters", "Mary", ""]]}, {"id": "2009.10748", "submitter": "Ziyi Chen", "authors": "Cheng Chen, Ziyi Chen, Yi Zhou, Bhavya Kailkhura", "title": "FedCluster: Boosting the Convergence of Federated Learning via\n  Cluster-Cycling", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop FedCluster--a novel federated learning framework with improved\noptimization efficiency, and investigate its theoretical convergence\nproperties. The FedCluster groups the devices into multiple clusters that\nperform federated learning cyclically in each learning round. Therefore, each\nlearning round of FedCluster consists of multiple cycles of meta-update that\nboost the overall convergence. In nonconvex optimization, we show that\nFedCluster with the devices implementing the local {stochastic gradient descent\n(SGD)} algorithm achieves a faster convergence rate than the conventional\n{federated averaging (FedAvg)} algorithm in the presence of device-level data\nheterogeneity. We conduct experiments on deep learning applications and\ndemonstrate that FedCluster converges significantly faster than the\nconventional federated learning under diverse levels of device-level data\nheterogeneity for a variety of local optimizers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 18:04:01 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Chen", "Cheng", ""], ["Chen", "Ziyi", ""], ["Zhou", "Yi", ""], ["Kailkhura", "Bhavya", ""]]}, {"id": "2009.10762", "submitter": "Anirudh Som", "authors": "Hongjun Choi, Anirudh Som, Pavan Turaga", "title": "Role of Orthogonality Constraints in Improving Properties of Deep\n  Networks for Image Classification", "comments": "8 figures, 4 tables, 1 pseudo-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep learning models that employ the categorical cross-entropy loss\nare known to perform well at image classification tasks. However, many standard\nmodels thus obtained often exhibit issues like feature redundancy, low\ninterpretability, and poor calibration. A body of recent work has emerged that\nhas tried addressing some of these challenges by proposing the use of new\nregularization functions in addition to the cross-entropy loss. In this paper,\nwe present some surprising findings that emerge from exploring the role of\nsimple orthogonality constraints as a means of imposing physics-motivated\nconstraints common in imaging. We propose an Orthogonal Sphere (OS) regularizer\nthat emerges from physics-based latent-representations under simplifying\nassumptions. Under further simplifying assumptions, the OS constraint can be\nwritten in closed-form as a simple orthonormality term and be used along with\nthe cross-entropy loss function. The findings indicate that orthonormality loss\nfunction results in a) rich and diverse feature representations, b) robustness\nto feature sub-selection, c) better semantic localization in the class\nactivation maps, and d) reduction in model calibration error. We demonstrate\nthe effectiveness of the proposed OS regularization by providing quantitative\nand qualitative results on four benchmark datasets - CIFAR10, CIFAR100, SVHN\nand tiny ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 18:46:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Choi", "Hongjun", ""], ["Som", "Anirudh", ""], ["Turaga", "Pavan", ""]]}, {"id": "2009.10766", "submitter": "SK MD Mosaddek Hossain", "authors": "Sk Mazharul Islam, Sk Md Mosaddek Hossain, and Sumanta Ray", "title": "DTI-SNNFRA: Drug-Target interaction prediction by shared nearest\n  neighbors and fuzzy-rough approximation", "comments": null, "journal-ref": "PLOS ONE 16(2): e0246920. (2021) 1-19", "doi": "10.1371/journal.pone.0246920", "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In-silico prediction of repurposable drugs is an effective drug discovery\nstrategy that supplements de-nevo drug discovery from scratch. Reduced\ndevelopment time, less cost and absence of severe side effects are significant\nadvantages of using drug repositioning. Most recent and most advanced\nartificial intelligence (AI) approaches have boosted drug repurposing in terms\nof throughput and accuracy enormously. However, with the growing number of\ndrugs, targets and their massive interactions produce imbalanced data which may\nnot be suitable as input to the classification model directly. Here, we have\nproposed DTI-SNNFRA, a framework for predicting drug-target interaction (DTI),\nbased on shared nearest neighbour (SNN) and fuzzy-rough approximation (FRA). It\nuses sampling techniques to collectively reduce the vast search space covering\nthe available drugs, targets and millions of interactions between them.\nDTI-SNNFRA operates in two stages: first, it uses SNN followed by a\npartitioning clustering for sampling the search space. Next, it computes the\ndegree of fuzzy-rough approximations and proper degree threshold selection for\nthe negative samples' undersampling from all possible interaction pairs between\ndrugs and targets obtained in the first stage. Finally, classification is\nperformed using the positive and selected negative samples. We have evaluated\nthe efficacy of DTI-SNNFRA using AUC (Area under ROC Curve), Geometric Mean,\nand F1 Score. The model performs exceptionally well with a high prediction\nscore of 0.95 for ROC-AUC. The predicted drug-target interactions are validated\nthrough an existing drug-target database (Connectivity Map (Cmap)).\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:10:10 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:11:33 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 09:10:53 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Islam", "Sk Mazharul", ""], ["Hossain", "Sk Md Mosaddek", ""], ["Ray", "Sumanta", ""]]}, {"id": "2009.10778", "submitter": "Danqing Zhang", "authors": "Danqing Zhang, Tao Li, Haiyang Zhang, Bing Yin", "title": "On Data Augmentation for Extreme Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on data augmentation for the extreme multi-label\nclassification (XMC) problem. One of the most challenging issues of XMC is the\nlong tail label distribution where even strong models suffer from insufficient\nsupervision. To mitigate such label bias, we propose a simple and effective\naugmentation framework and a new state-of-the-art classifier. Our augmentation\nframework takes advantage of the pre-trained GPT-2 model to generate\nlabel-invariant perturbations of the input texts to augment the existing\ntraining data. As a result, it present substantial improvements over baseline\nmodels. Our contributions are two-factored: (1) we introduce a new\nstate-of-the-art classifier that uses label attention with RoBERTa and combine\nit with our augmentation framework for further improvement; (2) we present a\nbroad study on how effective are different augmentation methods in the XMC\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:31:08 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhang", "Danqing", ""], ["Li", "Tao", ""], ["Zhang", "Haiyang", ""], ["Yin", "Bing", ""]]}, {"id": "2009.10790", "submitter": "Seamus Brady", "authors": "Seamus Brady", "title": "Using Unsupervised Learning to Help Discover the Causal Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software outlined in this paper, AitiaExplorer, is an exploratory causal\nanalysis tool which uses unsupervised learning for feature selection in order\nto expedite causal discovery. In this paper the problem space of causality is\nbriefly described and an overview of related research is provided. A problem\nstatement and requirements for the software are outlined. The key requirements\nin the implementation, the key design decisions and the actual implementation\nof AitiaExplorer are discussed. Finally, this implementation is evaluated in\nterms of the problem statement and requirements outlined earlier. It is found\nthat AitiaExplorer meets these requirements and is a useful exploratory causal\nanalysis tool that automatically selects subsets of important features from a\ndataset and creates causal graph candidates for review based on these features.\nThe software is available at https://github.com/corvideon/aitiaexplorer\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:07:19 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Brady", "Seamus", ""]]}, {"id": "2009.10799", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Stein Kristiansen, Thomas Plagemann, Vera\n  Goebel, Knut Liest{\\o}l, Mohan Kankanhalli, Gunn Marit Traaen, Britt\n  {\\O}verland, Harriet Akre, Lars Aaker{\\o}y, Sigurd Steinshamn", "title": "My Health Sensor, my Classifier: Adapting a Trained Classifier to\n  Unlabeled End-User Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an approach for unsupervised domain adaptation (DA)\nwith the constraint, that the labeled source data are not directly available,\nand instead only access to a classifier trained on the source data is provided.\nOur solution, iteratively labels only high confidence sub-regions of the target\ndata distribution, based on the belief of the classifier. Then it iteratively\nlearns new classifiers from the expanding high-confidence dataset. The goal is\nto apply the proposed approach on DA for the task of sleep apnea detection and\nachieve personalization based on the needs of the patient. In a series of\nexperiments with both open and closed sleep monitoring datasets, the proposed\napproach is applied to data from different sensors, for DA between the\ndifferent datasets. The proposed approach outperforms in all experiments the\nclassifier trained in the source domain, with an improvement of the kappa\ncoefficient that varies from 0.012 to 0.242. Additionally, our solution is\napplied to digit classification DA between three well established digit\ndatasets, to investigate the generalizability of the approach, and to allow for\ncomparison with related work. Even without direct access to the source data, it\nachieves good results, and outperforms several well established unsupervised DA\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:27:35 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Kristiansen", "Stein", ""], ["Plagemann", "Thomas", ""], ["Goebel", "Vera", ""], ["Liest\u00f8l", "Knut", ""], ["Kankanhalli", "Mohan", ""], ["Traaen", "Gunn Marit", ""], ["\u00d8verland", "Britt", ""], ["Akre", "Harriet", ""], ["Aaker\u00f8y", "Lars", ""], ["Steinshamn", "Sigurd", ""]]}, {"id": "2009.10800", "submitter": "Susheel Suresh", "authors": "Susheel Suresh and Jennifer Neville", "title": "A Hybrid Model for Learning Embeddings and Logical Rules Simultaneously\n  from Knowledge Graphs", "comments": "10 page extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of knowledge graph (KG) reasoning has been widely explored by\ntraditional rule-based systems and more recently by knowledge graph embedding\nmethods. While logical rules can capture deterministic behavior in a KG they\nare brittle and mining ones that infer facts beyond the known KG is\nchallenging. Probabilistic embedding methods are effective in capturing global\nsoft statistical tendencies and reasoning with them is computationally\nefficient. While embedding representations learned from rich training data are\nexpressive, incompleteness and sparsity in real-world KGs can impact their\neffectiveness. We aim to leverage the complementary properties of both methods\nto develop a hybrid model that learns both high-quality rules and embeddings\nsimultaneously. Our method uses a cross feedback paradigm wherein, an embedding\nmodel is used to guide the search of a rule mining system to mine rules and\ninfer new facts. These new facts are sampled and further used to refine the\nembedding model. Experiments on multiple benchmark datasets show the\neffectiveness of our method over other competitive standalone and hybrid\nbaselines. We also show its efficacy in a sparse KG setting and finally explore\nthe connection with negative sampling.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:29:27 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Suresh", "Susheel", ""], ["Neville", "Jennifer", ""]]}, {"id": "2009.10802", "submitter": "Dimitra Karanatsiou", "authors": "Dimitra Karanatsiou, Pavlos Sermpezis, Jon Gruda, Konstantinos\n  Kafetsios, Ilias Dimitriadis and Athena Vakali", "title": "My tweets bring all the traits to the yard: Predicting personality and\n  relational traits in Online Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users in Online Social Networks (OSN) leaves traces that reflect their\npersonality characteristics. The study of these traces is important for a\nnumber of fields, such as a social science, psychology, OSN, marketing, and\nothers. Despite a marked increase on research in personality prediction on\nbased on online behavior the focus has been heavily on individual personality\ntraits largely neglecting relational facets of personality. This study aims to\naddress this gap by providing a prediction model for a holistic personality\nprofiling in OSNs that included socio-relational traits (attachment\norientations) in combination with standard personality traits. Specifically, we\nfirst designed a feature engineering methodology that extracts a wide range of\nfeatures (accounting for behavior, language, and emotions) from OSN accounts of\nusers. Then, we designed a machine learning model that predicts scores for the\npsychological traits of the users based on the extracted features. The proposed\nmodel architecture is inspired by characteristics embedded in psychological\ntheory, i.e, utilizing interrelations among personality facets, and leads to\nincreased accuracy in comparison with the state of the art approaches. To\ndemonstrate the usefulness of this approach, we applied our model to two\ndatasets, one of random OSN users and one of organizational leaders, and\ncompared their psychological profiles. Our findings demonstrate that the two\ngroups can be clearly separated by only using their psychological profiles,\nwhich opens a promising direction for future research on OSN user\ncharacterization and classification.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:30:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Karanatsiou", "Dimitra", ""], ["Sermpezis", "Pavlos", ""], ["Gruda", "Jon", ""], ["Kafetsios", "Konstantinos", ""], ["Dimitriadis", "Ilias", ""], ["Vakali", "Athena", ""]]}, {"id": "2009.10808", "submitter": "Anuj Tiwari Dr", "authors": "Anuj Tiwari, Arya V. Dadhania, Vijay Avin Balaji Ragunathrao, Edson R.\n  A. Oliveira", "title": "Using Machine Learning to Develop a Novel COVID-19 Vulnerability Index\n  (C19VI)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID19 is now one of the most leading causes of death in the United States.\nSystemic health, social and economic disparities have put the minorities and\neconomically poor communities at a higher risk than others. There is an\nimmediate requirement to develop a reliable measure of county-level\nvulnerabilities that can capture the heterogeneity of both vulnerable\ncommunities and the COVID19 pandemic. This study reports a COVID19\nVulnerability Index (C19VI) for identification and mapping of vulnerable\ncounties in the United States. We proposed a Random Forest machine learning\nbased COVID19 vulnerability model using CDC sociodemographic and\nCOVID19-specific themes. An innovative COVID19 Impact Assessment algorithm was\nalso developed using homogeneity and trend assessment technique for evaluating\nseverity of the pandemic in all counties and train RF model. Developed C19VI\nwas statistically validated and compared with the CDC COVID19 Community\nVulnerability Index (CCVI). Finally, using C19VI along with census data, we\nexplored racial inequalities and economic disparities in COVID19 health\noutcomes amongst different regions in the United States. Our C19VI index\nindicates that 18.30% of the counties falls into very high vulnerability class,\n24.34% in high, 23.32% in moderate, 22.34% in low, and 11.68% in very low.\nFurthermore, C19VI reveals that 75.57% of racial minorities and 82.84% of\neconomically poor communities are very high or high COVID19 vulnerable regions.\nThe proposed approach of vulnerability modeling takes advantage of both the\nwell-established field of statistical analysis and the fast-evolving domain of\nmachine learning. C19VI provides an accurate and more reliable way to measure\ncounty level vulnerability in the United States. This index aims at helping\nemergency planners to develop more effective mitigation strategies especially\nfor the disproportionately impacted communities.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:48:19 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Tiwari", "Anuj", ""], ["Dadhania", "Arya V.", ""], ["Ragunathrao", "Vijay Avin Balaji", ""], ["Oliveira", "Edson R. A.", ""]]}, {"id": "2009.10819", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab, Jaydip Sen, Abhishek Dutta", "title": "Stock Price Prediction Using Machine Learning and LSTM-Based Deep\n  Learning Models", "comments": "The paper has been accepted for publication in the Proceedings of the\n  Second Symposium on Machine Learning and Metaheuristic Algorithms and\n  Applications (SOMMA'20): http://www.acn-conference.org/2020/somma2020/. The\n  paper is 18 pages long, and it contains 8 Figures and 12 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of stock prices has been an important area of research for a long\ntime. While supporters of the efficient market hypothesis believe that it is\nimpossible to predict stock prices accurately, there are formal propositions\ndemonstrating that accurate modeling and designing of appropriate variables may\nlead to models using which stock prices and stock price movement patterns can\nbe very accurately predicted. In this work, we propose an approach of hybrid\nmodeling for stock price prediction building different machine learning and\ndeep learning-based models. For the purpose of our study, we have used NIFTY 50\nindex values of the National Stock Exchange (NSE) of India, during the period\nDecember 29, 2014 till July 31, 2020. We have built eight regression models\nusing the training data that consisted of NIFTY 50 index records during\nDecember 29, 2014 till December 28, 2018. Using these regression models, we\npredicted the open values of NIFTY 50 for the period December 31, 2018 till\nJuly 31, 2020. We, then, augment the predictive power of our forecasting\nframework by building four deep learning-based regression models using long-and\nshort-term memory (LSTM) networks with a novel approach of walk-forward\nvalidation. We exploit the power of LSTM regression models in forecasting the\nfuture NIFTY 50 open values using four different models that differ in their\narchitecture and in the structure of their input data. Extensive results are\npresented on various metrics for the all the regression models. The results\nclearly indicate that the LSTM-based univariate model that uses one-week prior\ndata as input for predicting the next week open value of the NIFTY 50 time\nseries is the most accurate model.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 20:32:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""], ["Dutta", "Abhishek", ""]]}, {"id": "2009.10827", "submitter": "Rui Yu", "authors": "Rui Yu, Zhenyuan Yuan, Minghui Zhu, Zihan Zhou", "title": "Data-Driven Distributed State Estimation and Behavior Modeling in Sensor\n  Networks", "comments": "8 pages, 5 figures. To appear at the IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the prevalence of sensor networks has enabled tracking of the\nstates of dynamic objects for a wide spectrum of applications from autonomous\ndriving to environmental monitoring and urban planning. However, tracking\nreal-world objects often faces two key challenges: First, due to the limitation\nof individual sensors, state estimation needs to be solved in a collaborative\nand distributed manner. Second, the objects' movement behavior is unknown, and\nneeds to be learned using sensor observations. In this work, for the first\ntime, we formally formulate the problem of simultaneous state estimation and\nbehavior learning in a sensor network. We then propose a simple yet effective\nsolution to this new problem by extending the Gaussian process-based Bayes\nfilters (GP-BayesFilters) to an online, distributed setting. The effectiveness\nof the proposed method is evaluated on tracking objects with unknown movement\nbehaviors using both synthetic data and data collected from a multi-robot\nplatform.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 21:31:18 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 15:12:45 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Yu", "Rui", ""], ["Yuan", "Zhenyuan", ""], ["Zhu", "Minghui", ""], ["Zhou", "Zihan", ""]]}, {"id": "2009.10835", "submitter": "Morteza Haghir Chehreghani", "authors": "John Daniel Boss\\'er, Erik S\\\"orstadius, Morteza Haghir Chehreghani", "title": "Model-Centric and Data-Centric Aspects of Active Learning for Neural\n  Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study different data-centric and model-centric aspects of active learning\nwith neural network models. i) We investigate incremental and cumulative\ntraining modes that specify how the currently labeled data are used for\ntraining. ii) Neural networks are models with a large capacity. Thus, we study\nhow active learning depends on the number of epochs and neurons as well as the\nchoice of batch size. iii) We analyze in detail the behavior of query\nstrategies and their corresponding informativeness measures and accordingly\npropose more efficient querying and active learning paradigms. iv) We perform\nstatistical analyses, e.g., on actively learned classes and test error\nestimation, that reveal several insights about active learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 21:58:03 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 22:09:41 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Boss\u00e9r", "John Daniel", ""], ["S\u00f6rstadius", "Erik", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2009.10847", "submitter": "Mikhail Galkin", "authors": "Mikhail Galkin, Priyansh Trivedi, Gaurav Maheshwari, Ricardo Usbeck,\n  Jens Lehmann", "title": "Message Passing for Hyper-Relational Knowledge Graphs", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating\nadditional key-value pairs along with the main triple to disambiguate, or\nrestrict the validity of a fact. In this work, we propose a message passing\nbased graph encoder - StarE capable of modeling such hyper-relational KGs.\nUnlike existing approaches, StarE can encode an arbitrary number of additional\ninformation (qualifiers) along with the main triple while keeping the semantic\nroles of qualifiers and triples intact. We also demonstrate that existing\nbenchmarks for evaluating link prediction (LP) performance on hyper-relational\nKGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset\n- WD50K. Our experiments demonstrate that StarE based LP model outperforms\nexisting approaches across multiple benchmarks. We also confirm that leveraging\nqualifiers is vital for link prediction with gains up to 25 MRR points compared\nto triple-based representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 22:38:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Galkin", "Mikhail", ""], ["Trivedi", "Priyansh", ""], ["Maheshwari", "Gaurav", ""], ["Usbeck", "Ricardo", ""], ["Lehmann", "Jens", ""]]}, {"id": "2009.10858", "submitter": "Sonia Phene", "authors": "Joy Hsu, Sonia Phene, Akinori Mitani, Jieying Luo, Naama Hammel,\n  Jonathan Krause, Rory Sayres", "title": "Improving Medical Annotation Quality to Decrease Labeling Burden Using\n  Stratified Noisy Cross-Validation", "comments": null, "journal-ref": "ACM Conference on Health, Inference, and Learning, April 02-04,\n  2020, Toronto, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning has become increasingly applied to medical imaging data,\nnoise in training labels has emerged as an important challenge. Variability in\ndiagnosis of medical images is well established; in addition, variability in\ntraining and attention to task among medical labelers may exacerbate this\nissue. Methods for identifying and mitigating the impact of low quality labels\nhave been studied, but are not well characterized in medical imaging tasks. For\ninstance, Noisy Cross-Validation splits the training data into halves, and has\nbeen shown to identify low-quality labels in computer vision tasks; but it has\nnot been applied to medical imaging tasks specifically. In this work we\nintroduce Stratified Noisy Cross-Validation (SNCV), an extension of noisy cross\nvalidation. SNCV can provide estimates of confidence in model predictions by\nassigning a quality score to each example; stratify labels to handle class\nimbalance; and identify likely low-quality labels to analyze the causes. We\nassess performance of SNCV on diagnosis of glaucoma suspect risk from retinal\nfundus photographs, a clinically important yet nuanced labeling task. Using\ntraining data from a previously-published deep learning model, we compute a\ncontinuous quality score (QS) for each training example. We relabel 1,277\nlow-QS examples using a trained glaucoma specialist; the new labels agree with\nthe SNCV prediction over the initial label >85% of the time, indicating that\nlow-QS examples mostly reflect labeler errors. We then quantify the impact of\ntraining with only high-QS labels, showing that strong model performance may be\nobtained with many fewer examples. By applying the method to randomly\nsub-sampled training dataset, we show that our method can reduce labelling\nburden by approximately 50% while achieving model performance non-inferior to\nusing the full dataset on multiple held-out test sets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 23:32:59 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hsu", "Joy", ""], ["Phene", "Sonia", ""], ["Mitani", "Akinori", ""], ["Luo", "Jieying", ""], ["Hammel", "Naama", ""], ["Krause", "Jonathan", ""], ["Sayres", "Rory", ""]]}, {"id": "2009.10862", "submitter": "Jie Wang", "authors": "Jie Wang", "title": "An Intuitive Tutorial to Gaussian Processes Regression", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial aims to provide an intuitive understanding of the Gaussian\nprocesses regression. Gaussian processes regression (GPR) models have been\nwidely used in machine learning applications because of their representation\nflexibility and inherently uncertainty measures over predictions. The basic\nconcepts that a Gaussian process is built on, including multivariate normal\ndistribution, kernels, non-parametric models, joint and conditional probability\nwere explained first. Next, the GPR was described concisely together with an\nimplementation of a standard GPR algorithm. Beyond the standard GPR, packages\nto implement state-of-the-art Gaussian processes algorithms were reviewed. This\ntutorial was written in an accessible way to make sure readers without a\nmachine learning background can obtain a good understanding of the GPR basics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 23:57:30 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 17:47:30 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 01:55:41 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Jie", ""]]}, {"id": "2009.10867", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Yiming Ying, Steven Skiena", "title": "Online AUC Optimization for Sparse High-Dimensional Datasets", "comments": "20th IEEE International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Area Under the ROC Curve (AUC) is a widely used performance measure for\nimbalanced classification arising from many application domains where\nhigh-dimensional sparse data is abundant. In such cases, each $d$ dimensional\nsample has only $k$ non-zero features with $k \\ll d$, and data arrives\nsequentially in a streaming form. Current online AUC optimization algorithms\nhave high per-iteration cost $\\mathcal{O}(d)$ and usually produce non-sparse\nsolutions in general, and hence are not suitable for handling the data\nchallenge mentioned above.\n  In this paper, we aim to directly optimize the AUC score for high-dimensional\nsparse datasets under online learning setting and propose a new algorithm,\n\\textsc{FTRL-AUC}. Our proposed algorithm can process data in an online fashion\nwith a much cheaper per-iteration cost $\\mathcal{O}(k)$, making it amenable for\nhigh-dimensional sparse streaming data analysis. Our new algorithmic design\ncritically depends on a novel reformulation of the U-statistics AUC objective\nfunction as the empirical saddle point reformulation, and the innovative\nintroduction of the \"lazy update\" rule so that the per-iteration complexity is\ndramatically reduced from $\\mathcal{O}(d)$ to $\\mathcal{O}(k)$. Furthermore,\n\\textsc{FTRL-AUC} can inherently capture sparsity more effectively by applying\na generalized Follow-The-Regularized-Leader (FTRL) framework.\n  Experiments on real-world datasets demonstrate that \\textsc{FTRL-AUC}\nsignificantly improves both run time and model sparsity while achieving\ncompetitive AUC scores compared with the state-of-the-art methods. Comparison\nwith the online learning method for logistic loss demonstrates that\n\\textsc{FTRL-AUC} achieves higher AUC scores especially when datasets are\nimbalanced.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 00:50:01 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhou", "Baojian", ""], ["Ying", "Yiming", ""], ["Skiena", "Steven", ""]]}, {"id": "2009.10874", "submitter": "Xianbiao Qi", "authors": "Bingcong Li, Xin Tang, Xianbiao Qi, Yihao Chen, Rong Xiao", "title": "Hamming OCR: A Locality Sensitive Hashing Neural Network for Scene Text\n  Recognition", "comments": "9 Pages, 4 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, inspired by Transformer, self-attention-based scene text\nrecognition approaches have achieved outstanding performance. However, we find\nthat the size of model expands rapidly with the lexicon increasing.\nSpecifically, the number of parameters for softmax classification layer and\noutput embedding layer are proportional to the vocabulary size. It hinders the\ndevelopment of a lightweight text recognition model especially applied for\nChinese and multiple languages. Thus, we propose a lightweight scene text\nrecognition model named Hamming OCR. In this model, a novel Hamming classifier,\nwhich adopts locality sensitive hashing (LSH) algorithm to encode each\ncharacter, is proposed to replace the softmax regression and the generated LSH\ncode is directly employed to replace the output embedding. We also present a\nsimplified transformer decoder to reduce the number of parameters by removing\nthe feed-forward network and using cross-layer parameter sharing technique.\nCompared with traditional methods, the number of parameters in both\nclassification and embedding layers is independent on the size of vocabulary,\nwhich significantly reduces the storage requirement without loss of accuracy.\nExperimental results on several datasets, including four public benchmaks and a\nChinese text dataset synthesized by SynthText with more than 20,000 characters,\nshows that Hamming OCR achieves competitive results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:20:19 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Li", "Bingcong", ""], ["Tang", "Xin", ""], ["Qi", "Xianbiao", ""], ["Chen", "Yihao", ""], ["Xiao", "Rong", ""]]}, {"id": "2009.10890", "submitter": "Amin Shojaeighadikolaei", "authors": "Amin Shojaeighadikolaei, Arman Ghasemi, Kailani R. Jones, Alexandru G.\n  Bardas, Morteza Hashemi, Reza Ahmadi", "title": "Demand Responsive Dynamic Pricing Framework for Prosumer Dominated\n  Microgrids using Multiagent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand Response (DR) has a widely recognized potential for improving grid\nstability and reliability while reducing customers energy bills. However, the\nconventional DR techniques come with several shortcomings, such as inability to\nhandle operational uncertainties and incurring customer disutility, impeding\ntheir wide spread adoption in real-world applications. This paper proposes a\nnew multiagent Reinforcement Learning (RL) based decision-making environment\nfor implementing a Real-Time Pricing (RTP) DR technique in a prosumer dominated\nmicrogrid. The proposed technique addresses several shortcomings common to\ntraditional DR methods and provides significant economic benefits to the grid\noperator and prosumers. To show its better efficacy, the proposed DR method is\ncompared to a baseline traditional operation scenario in a small-scale\nmicrogrid system. Finally, investigations on the use of prosumers energy\nstorage capacity in this microgrid highlight the advantages of the proposed\nmethod in establishing a balanced market setup.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:44:57 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Shojaeighadikolaei", "Amin", ""], ["Ghasemi", "Arman", ""], ["Jones", "Kailani R.", ""], ["Bardas", "Alexandru G.", ""], ["Hashemi", "Morteza", ""], ["Ahmadi", "Reza", ""]]}, {"id": "2009.10893", "submitter": "Najeeb Khan", "authors": "Najeeb Khan and Ian Stavness", "title": "Pruning Convolutional Filters using Batch Bridgeout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art computer vision models are rapidly increasing in capacity,\nwhere the number of parameters far exceeds the number required to fit the\ntraining set. This results in better optimization and generalization\nperformance. However, the huge size of contemporary models results in large\ninference costs and limits their use on resource-limited devices. In order to\nreduce inference costs, convolutional filters in trained neural networks could\nbe pruned to reduce the run-time memory and computational requirements during\ninference. However, severe post-training pruning results in degraded\nperformance if the training algorithm results in dense weight vectors. We\npropose the use of Batch Bridgeout, a sparsity inducing stochastic\nregularization scheme, to train neural networks so that they could be pruned\nefficiently with minimal degradation in performance. We evaluate the proposed\nmethod on common computer vision models VGGNet, ResNet, and Wide-ResNet on the\nCIFAR image classification task. For all the networks, experimental results\nshow that Batch Bridgeout trained networks achieve higher accuracy across a\nwide range of pruning intensities compared to Dropout and weight decay\nregularization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:51:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Khan", "Najeeb", ""], ["Stavness", "Ian", ""]]}, {"id": "2009.10897", "submitter": "Chloe Hsu", "authors": "Chloe Ching-Yun Hsu, Celestine Mendler-D\\\"unner, Moritz Hardt", "title": "Revisiting Design Choices in Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximal Policy Optimization (PPO) is a popular deep policy gradient\nalgorithm. In standard implementations, PPO regularizes policy updates with\nclipped probability ratios, and parameterizes policies with either continuous\nGaussian distributions or discrete Softmax distributions. These design choices\nare widely accepted, and motivated by empirical performance comparisons on\nMuJoCo and Atari benchmarks.\n  We revisit these practices outside the regime of current benchmarks, and\nexpose three failure modes of standard PPO. We explain why standard design\nchoices are problematic in these cases, and show that alternative choices of\nsurrogate objectives and policy parameterizations can prevent the failure\nmodes. We hope that our work serves as a reminder that many algorithmic design\nchoices in reinforcement learning are tied to specific simulation environments.\nWe should not implicitly accept these choices as a standard part of a more\ngeneral algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:00:34 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hsu", "Chloe Ching-Yun", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Hardt", "Moritz", ""]]}, {"id": "2009.10905", "submitter": "Amin Shojaeighadikolaei", "authors": "Arman Ghasemi, Amin Shojaeighadikolaei, Kailani Jones, Morteza\n  Hashemi, Alexandru G. Bardas, Reza Ahmadi", "title": "A Multi-Agent Deep Reinforcement Learning Approach for a Distributed\n  Energy Marketplace in Smart Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Reinforcement Learning (RL) based energy market for a\nprosumer dominated microgrid. The proposed market model facilitates a real-time\nand demanddependent dynamic pricing environment, which reduces grid costs and\nimproves the economic benefits for prosumers. Furthermore, this market model\nenables the grid operator to leverage prosumers storage capacity as a\ndispatchable asset for grid support applications. Simulation results based on\nthe Deep QNetwork (DQN) framework demonstrate significant improvements of the\n24-hour accumulative profit for both prosumers and the grid operator, as well\nas major reductions in grid reserve power utilization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:17:51 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ghasemi", "Arman", ""], ["Shojaeighadikolaei", "Amin", ""], ["Jones", "Kailani", ""], ["Hashemi", "Morteza", ""], ["Bardas", "Alexandru G.", ""], ["Ahmadi", "Reza", ""]]}, {"id": "2009.10924", "submitter": "Zhen Zheng", "authors": "Zhen Zheng, Pengzhan Zhao, Guoping Long, Feiwen Zhu, Kai Zhu, Wenyi\n  Zhao, Lansong Diao, Jun Yang, Wei Lin", "title": "FusionStitching: Boosting Memory Intensive Computations for Deep\n  Learning Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show in this work that memory intensive computations can result in severe\nperformance problems due to off-chip memory access and CPU-GPU context switch\noverheads in a wide range of deep learning models. For this problem, current\njust-in-time kernel fusion and code generation techniques have limitations,\nsuch as kernel schedule incompatibilities and rough fusion plan exploration\nstrategies. We propose FusionStitching, a Deep Learning compiler capable of\nfusing memory intensive operators, with varied data dependencies and\nnon-homogeneous parallelism, into large GPU kernels to reduce global memory\naccess and operation scheduling overhead automatically. FusionStitching\nexplores large fusion spaces to decide optimal fusion plans with considerations\nof memory access costs, kernel calls and resource usage constraints. We\nthoroughly study the schemes to stitch operators together for complex\nscenarios. FusionStitching tunes the optimal stitching scheme just-in-time with\na domain-specific cost model efficiently. Experimental results show that\nFusionStitching can reach up to 2.78x speedup compared to TensorFlow and\ncurrent state-of-the-art. Besides these experimental results, we integrated our\napproach into a compiler product and deployed it onto a production cluster for\nAI workloads with thousands of GPUs. The system has been in operation for more\nthan 4 months and saves 7,000 GPU hours on average for approximately 30,000\ntasks per month.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 04:00:53 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zheng", "Zhen", ""], ["Zhao", "Pengzhan", ""], ["Long", "Guoping", ""], ["Zhu", "Feiwen", ""], ["Zhu", "Kai", ""], ["Zhao", "Wenyi", ""], ["Diao", "Lansong", ""], ["Yang", "Jun", ""], ["Lin", "Wei", ""]]}, {"id": "2009.10931", "submitter": "Kang-Lin Hsieh", "authors": "Kanglin Hsieh, Yinyin Wang, Luyao Chen, Zhongming Zhao, Sean Savitz,\n  Xiaoqian Jiang, Jing Tang, Yejin Kim", "title": "Drug Repurposing for COVID-19 using Graph Neural Network with Genetic,\n  Mechanistic, and Epidemiological Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amid the pandemic of 2019 novel coronavirus disease (COVID-19) infected by\nSARS-CoV-2, a vast amount of drug research for prevention and treatment has\nbeen quickly conducted, but these efforts have been unsuccessful thus far. Our\nobjective is to prioritize repurposable drugs using a drug repurposing pipeline\nthat systematically integrates multiple SARS-CoV-2 and drug interactions, deep\ngraph neural networks, and in-vitro/population-based validations. We first\ncollected all the available drugs (n= 3,635) involved in COVID-19 patient\ntreatment through CTDbase. We built a SARS-CoV-2 knowledge graph based on the\ninteractions among virus baits, host genes, pathways, drugs, and phenotypes. A\ndeep graph neural network approach was used to derive the candidate\nrepresentation based on the biological interactions. We prioritized the\ncandidate drugs using clinical trial history, and then validated them with\ntheir genetic profiles, in vitro experimental efficacy, and electronic health\nrecords. We highlight the top 22 drugs including Azithromycin, Atorvastatin,\nAspirin, Acetaminophen, and Albuterol. We further pinpointed drug combinations\nthat may synergistically target COVID-19. In summary, we demonstrated that the\nintegration of extensive interactions, deep neural networks, and rigorous\nvalidation can facilitate the rapid identification of candidate drugs for\nCOVID-19 treatment.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 04:47:59 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hsieh", "Kanglin", ""], ["Wang", "Yinyin", ""], ["Chen", "Luyao", ""], ["Zhao", "Zhongming", ""], ["Savitz", "Sean", ""], ["Jiang", "Xiaoqian", ""], ["Tang", "Jing", ""], ["Kim", "Yejin", ""]]}, {"id": "2009.10951", "submitter": "Junshan Wang", "authors": "Junshan Wang, Guojie Song, Yi Wu, Liang Wang", "title": "Streaming Graph Neural Networks via Continual Learning", "comments": "10 pages, 4 figures, CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411963", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved strong performance in various\napplications. In the real world, network data is usually formed in a streaming\nfashion. The distributions of patterns that refer to neighborhood information\nof nodes may shift over time. The GNN model needs to learn the new patterns\nthat cannot yet be captured. But learning incrementally leads to the\ncatastrophic forgetting problem that historical knowledge is overwritten by\nnewly learned knowledge. Therefore, it is important to train GNN model to learn\nnew patterns and maintain existing patterns simultaneously, which few works\nfocus on. In this paper, we propose a streaming GNN model based on continual\nlearning so that the model is trained incrementally and up-to-date node\nrepresentations can be obtained at each time step. Firstly, we design an\napproximation algorithm to detect new coming patterns efficiently based on\ninformation propagation. Secondly, we combine two perspectives of data\nreplaying and model regularization for existing pattern consolidation.\nSpecially, a hierarchy-importance sampling strategy for nodes is designed and a\nweighted regularization term for GNN parameters is derived, achieving greater\nstability and generalization of knowledge consolidation. Our model is evaluated\non real and synthetic data sets and compared with multiple baselines. The\nresults of node classification prove that our model can efficiently update\nmodel parameters and achieve comparable performance to model retraining. In\naddition, we also conduct a case study on the synthetic data, and carry out\nsome specific analysis for each part of our model, illustrating its ability to\nlearn new knowledge and maintain existing knowledge from different\nperspectives.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 06:52:30 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 06:56:16 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Wang", "Junshan", ""], ["Song", "Guojie", ""], ["Wu", "Yi", ""], ["Wang", "Liang", ""]]}, {"id": "2009.10971", "submitter": "Maxim Chernodub", "authors": "D.L. Boyda, M.N. Chernodub, N.V. Gerasimeniuk, V.A. Goy, S.D.\n  Liubimov, A.V. Molochkov", "title": "Machine-learning physics from unphysics: Finding deconfinement\n  temperature in lattice Yang-Mills theories from outside the scaling window", "comments": "9 pages, 14 figures; v2: discussions added", "journal-ref": "Phys. Rev. D 103, 014509 (2021)", "doi": "10.1103/PhysRevD.103.014509", "report-no": null, "categories": "hep-lat cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the machine learning techniques applied to the lattice gauge\ntheory's critical behavior, particularly to the confinement/deconfinement phase\ntransition in the SU(2) and SU(3) gauge theories. We find that the neural\nnetwork, trained on lattice configurations of gauge fields at an unphysical\nvalue of the lattice parameters as an input, builds up a gauge-invariant\nfunction, and finds correlations with the target observable that is valid in\nthe physical region of the parameter space. In particular, if the algorithm\naimed to predict the Polyakov loop as the deconfining order parameter, it\nbuilds a trace of the gauge group matrices along a closed loop in the time\ndirection. As a result, the neural network, trained at one unphysical value of\nthe lattice coupling $\\beta$ predicts the order parameter in the whole region\nof the $\\beta$ values with good precision. We thus demonstrate that the machine\nlearning techniques may be used as a numerical analog of the analytical\ncontinuation from easily accessible but physically uninteresting regions of the\ncoupling space to the interesting but potentially not accessible regions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:21:40 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 07:53:49 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Boyda", "D. L.", ""], ["Chernodub", "M. N.", ""], ["Gerasimeniuk", "N. V.", ""], ["Goy", "V. A.", ""], ["Liubimov", "S. D.", ""], ["Molochkov", "A. V.", ""]]}, {"id": "2009.10975", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "A Partial Break of the Honeypots Defense to Catch Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent defense proposes to inject \"honeypots\" into neural networks in order\nto detect adversarial attacks. We break the baseline version of this defense by\nreducing the detection true positive rate to 0\\% and the detection AUC to 0.02,\nmaintaining the original distortion bounds. The authors of the original paper\nhave amended the defense in their CCS'20 paper to mitigate this attacks. To aid\nfurther research, we release the complete 2.5 hour keystroke-by-keystroke\nscreen recording of our attack process at\nhttps://nicholas.carlini.com/code/ccs_honeypot_break.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:36:37 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "2009.10976", "submitter": "Dingqing Yang", "authors": "Dingqing Yang, Amin Ghasemazar, Xiaowei Ren, Maximilian Golub, Guy\n  Lemieux, Mieszko Lis", "title": "Procrustes: a Dataflow and Accelerator for Sparse Deep Neural Network\n  Training", "comments": "Appears in the Proceedings of the 53$^\\mathit{rd}$ IEEE/ACM\n  International Symposium on Microarchitecture (MICRO 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of DNN pruning has led to the development of energy-efficient\ninference accelerators that support pruned models with sparse weight and\nactivation tensors. Because the memory layouts and dataflows in these\narchitectures are optimized for the access patterns during\n$\\mathit{inference}$, however, they do not efficiently support the emerging\nsparse $\\mathit{training}$ techniques.\n  In this paper, we demonstrate (a) that accelerating sparse training requires\na co-design approach where algorithms are adapted to suit the constraints of\nhardware, and (b) that hardware for sparse DNN training must tackle constraints\nthat do not arise in inference accelerators. As proof of concept, we adapt a\nsparse training algorithm to be amenable to hardware acceleration; we then\ndevelop dataflow, data layout, and load-balancing techniques to accelerate it.\n  The resulting system is a sparse DNN training accelerator that produces\npruned models with the same accuracy as dense models without first training,\nthen pruning, and finally retraining, a dense model. Compared to training the\nequivalent unpruned models using a state-of-the-art DNN accelerator without\nsparse training support, Procrustes consumes up to 3.26$\\times$ less energy and\noffers up to 4$\\times$ speedup across a range of models, while pruning weights\nby an order of magnitude and maintaining unpruned accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:39:55 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Yang", "Dingqing", ""], ["Ghasemazar", "Amin", ""], ["Ren", "Xiaowei", ""], ["Golub", "Maximilian", ""], ["Lemieux", "Guy", ""], ["Lis", "Mieszko", ""]]}, {"id": "2009.10978", "submitter": "Wonseok Lee", "authors": "Wonseok Lee, Hanbit Lee, Sang-goo Lee", "title": "Semantics-Preserving Adversarial Training", "comments": "Preprint. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a defense technique that improves adversarial\nrobustness of a deep neural network (DNN) by including adversarial examples in\nthe training data. In this paper, we identify an overlooked problem of\nadversarial training in that these adversarial examples often have different\nsemantics than the original data, introducing unintended biases into the model.\nWe hypothesize that such non-semantics-preserving (and resultingly ambiguous)\nadversarial data harm the robustness of the target models. To mitigate such\nunintended semantic changes of adversarial examples, we propose\nsemantics-preserving adversarial training (SPAT) which encourages perturbation\non the pixels that are shared among all classes when generating adversarial\nexamples in the training stage. Experiment results show that SPAT improves\nadversarial robustness and achieves state-of-the-art results in CIFAR-10 and\nCIFAR-100.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:42:14 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lee", "Wonseok", ""], ["Lee", "Hanbit", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2009.10989", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh, Dhruv Gelda, Zhongfang Zhuang, Yan Zheng, Liang\n  Gou, Wei Zhang", "title": "Towards a Flexible Embedding Learning Framework", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a fundamental building block for analyzing\nentities in a database. While the existing embedding learning methods are\neffective in various data mining problems, their applicability is often limited\nbecause these methods have pre-determined assumptions on the type of semantics\ncaptured by the learned embeddings, and the assumptions may not well align with\nspecific downstream tasks. In this work, we propose an embedding learning\nframework that 1) uses an input format that is agnostic to input data type, 2)\nis flexible in terms of the relationships that can be embedded into the learned\nrepresentations, and 3) provides an intuitive pathway to incorporate domain\nknowledge into the embedding learning process. Our proposed framework utilizes\na set of entity-relation-matrices as the input, which quantifies the affinities\namong different entities in the database. Moreover, a sampling mechanism is\ncarefully designed to establish a direct connection between the input and the\ninformation captured by the output embeddings. To complete the representation\nlearning toolbox, we also outline a simple yet effective post-processing\ntechnique to properly visualize the learned embeddings. Our empirical results\ndemonstrate that the proposed framework, in conjunction with a set of relevant\nentity-relation-matrices, outperforms the existing state-of-the-art approaches\nin various data mining tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:00:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""], ["Gelda", "Dhruv", ""], ["Zhuang", "Zhongfang", ""], ["Zheng", "Yan", ""], ["Gou", "Liang", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.10990", "submitter": "Rohun Kshirsagar", "authors": "Rohun Kshirsagar, Li-Yen Hsu, Vatshank Chaturvedi, Charles H.\n  Greenberg, Matthew McClelland, Anushadevi Mohan, Wideet Shende, Nicolas P.\n  Tilmans, Renzo Frigato, Min Guo, Ankit Chheda, Meredith Trotter, Shonket Ray,\n  Arnold Lee, Miguel Alvarado", "title": "Accurate and Interpretable Machine Learning for Transparent Pricing of\n  Health Insurance Plans", "comments": "Accepted for publication in The Thirty-Fifth AAAI Conference on\n  Artificial Intelligence (AAAI-21), in the Innovative Applications of\n  Artificial Intelligence track. This is the extended version with some\n  stylistic fixes from the first posting and complete author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health insurance companies cover half of the United States population through\ncommercial employer-sponsored health plans and pay 1.2 trillion US dollars\nevery year to cover medical expenses for their members. The actuary and\nunderwriter roles at a health insurance company serve to assess which risks to\ntake on and how to price those risks to ensure profitability of the\norganization. While Bayesian hierarchical models are the current standard in\nthe industry to estimate risk, interest in machine learning as a way to improve\nupon these existing methods is increasing. Lumiata, a healthcare analytics\ncompany, ran a study with a large health insurance company in the United\nStates. We evaluated the ability of machine learning models to predict the per\nmember per month cost of employer groups in their next renewal period,\nespecially those groups who will cost less than 95\\% of what an actuarial model\npredicts (groups with \"concession opportunities\"). We developed a sequence of\ntwo models, an individual patient-level and an employer-group-level model, to\npredict the annual per member per month allowed amount for employer groups,\nbased on a population of 14 million patients. Our models performed 20\\% better\nthan the insurance carrier's existing pricing model, and identified 84\\% of the\nconcession opportunities. This study demonstrates the application of a machine\nlearning system to compute an accurate and fair price for health insurance\nproducts and analyzes how explainable machine learning models can exceed\nactuarial models' predictive accuracy while maintaining interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:07:33 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 22:47:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kshirsagar", "Rohun", ""], ["Hsu", "Li-Yen", ""], ["Chaturvedi", "Vatshank", ""], ["Greenberg", "Charles H.", ""], ["McClelland", "Matthew", ""], ["Mohan", "Anushadevi", ""], ["Shende", "Wideet", ""], ["Tilmans", "Nicolas P.", ""], ["Frigato", "Renzo", ""], ["Guo", "Min", ""], ["Chheda", "Ankit", ""], ["Trotter", "Meredith", ""], ["Ray", "Shonket", ""], ["Lee", "Arnold", ""], ["Alvarado", "Miguel", ""]]}, {"id": "2009.10991", "submitter": "Darshana Priyasad Madduma Kankanamalage Don Mr", "authors": "Darshana Priyasad, Tharindu Fernando, Simon Denman, Clinton Fookes,\n  Sridha Sridharan", "title": "Attention Driven Fusion for Multi-Modal Emotion Recognition", "comments": "An updated version of the ICASSP 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a powerful alternative to hand-crafted methods\nfor emotion recognition on combined acoustic and text modalities. Baseline\nsystems model emotion information in text and acoustic modes independently\nusing Deep Convolutional Neural Networks (DCNN) and Recurrent Neural Networks\n(RNN), followed by applying attention, fusion, and classification. In this\npaper, we present a deep learning-based approach to exploit and fuse text and\nacoustic data for emotion classification. We utilize a SincNet layer, based on\nparameterized sinc functions with band-pass filters, to extract acoustic\nfeatures from raw audio followed by a DCNN. This approach learns filter banks\ntuned for emotion recognition and provides more effective features compared to\ndirectly applying convolutions over the raw speech signal. For text processing,\nwe use two branches (a DCNN and a Bi-direction RNN followed by a DCNN) in\nparallel where cross attention is introduced to infer the N-gram level\ncorrelations on hidden representations received from the Bi-RNN. Following\nexisting state-of-the-art, we evaluate the performance of the proposed system\non the IEMOCAP dataset. Experimental results indicate that the proposed system\noutperforms existing methods, achieving 3.5% improvement in weighted accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:07:58 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 22:25:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Priyasad", "Darshana", ""], ["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Fookes", "Clinton", ""], ["Sridharan", "Sridha", ""]]}, {"id": "2009.11044", "submitter": "Dime Kostadinov", "authors": "Dimche Kostadinov and Davide Scaramuzza", "title": "Unsupervised Feature Learning for Event Data: Direct vs Inverse Problem\n  Formulation", "comments": null, "journal-ref": "IAPR IEEE/Computer Society International Conference on Pattern\n  Recognition (ICPR), Milan, 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-based cameras record an asynchronous stream of per-pixel brightness\nchanges. As such, they have numerous advantages over the standard frame-based\ncameras, including high temporal resolution, high dynamic range, and no motion\nblur. Due to the asynchronous nature, efficient learning of compact\nrepresentation for event data is challenging. While it remains not explored the\nextent to which the spatial and temporal event \"information\" is useful for\npattern recognition tasks. In this paper, we focus on single-layer\narchitectures. We analyze the performance of two general problem formulations:\nthe direct and the inverse, for unsupervised feature learning from local event\ndata (local volumes of events described in space-time). We identify and show\nthe main advantages of each approach. Theoretically, we analyze guarantees for\nan optimal solution, possibility for asynchronous, parallel parameter update,\nand the computational complexity. We present numerical experiments for object\nrecognition. We evaluate the solution under the direct and the inverse problem\nand give a comparison with the state-of-the-art methods. Our empirical results\nhighlight the advantages of both approaches for representation learning from\nevent data. We show improvements of up to 9 % in the recognition accuracy\ncompared to the state-of-the-art methods from the same class of methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 10:40:03 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 13:09:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "2009.11050", "submitter": "Alberto Sabater", "authors": "Alberto Sabater, Luis Montesano, Ana C. Murillo", "title": "Robust and efficient post-processing for video object detection", "comments": "Submitted to the International Conference on Intelligent Robots and\n  Systems, IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object recognition in video is an important task for plenty of applications,\nincluding autonomous driving perception, surveillance tasks, wearable devices\nor IoT networks. Object recognition using video data is more challenging than\nusing still images due to blur, occlusions or rare object poses. Specific video\ndetectors with high computational cost or standard image detectors together\nwith a fast post-processing algorithm achieve the current state-of-the-art.\nThis work introduces a novel post-processing pipeline that overcomes some of\nthe limitations of previous post-processing methods by introducing a\nlearning-based similarity evaluation between detections across frames. Our\nmethod improves the results of state-of-the-art specific video detectors,\nspecially regarding fast moving objects, and presents low resource\nrequirements. And applied to efficient still image detectors, such as YOLO,\nprovides comparable results to much more computationally intensive detectors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 10:47:24 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Sabater", "Alberto", ""], ["Montesano", "Luis", ""], ["Murillo", "Ana C.", ""]]}, {"id": "2009.11054", "submitter": "Islem Rekik", "authors": "Islem Mhiri, Mohamed Ali Mahjoub and Islem Rekik", "title": "Supervised Multi-topology Network Cross-diffusion for Population-driven\n  Brain Network Atlas Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating a representative and discriminative brain network atlas (BNA) is a\nnascent research field in mapping a population of brain networks in health and\ndisease. Although limited, existing BNA estimation methods have several\nlimitations. First, they primarily rely on a similarity network diffusion and\nfusion technique, which only considers node degree as a topological measure in\nthe cross-network diffusion process, thereby overlooking rich topological\nmeasures of the brain network (e.g., centrality). Second, both diffusion and\nfusion techniques are implemented in fully unsupervised manner, which might\ndecrease the discriminative power of the estimated BNAs. To fill these gaps, we\npropose a supervised multi-topology network cross-diffusion (SM-netFusion)\nframework for estimating a BNA satisfying : (i) well-representativeness\n(captures shared traits across subjects), (ii) well-centeredness (optimally\nclose to all subjects), and (iii) high discriminativeness (can easily and\nefficiently identify discriminative brain connections that distinguish between\ntwo populations). For a specific class, given the cluster labels of the\ntraining data, we learn a weighted combination of the topological diffusion\nkernels derived from degree, closeness and eigenvector centrality measures in a\nsupervised manner. Specifically, we learn the cross-diffusion process by\nnormalizing the training brain networks using the learned diffusion kernels.\nOur SM-netFusion produces the most centered and representative template in\ncomparison with its variants and state-of-the-art methods and further boosted\nthe classification of autistic subjects by 5-15%. SM-netFusion presents the\nfirst work for supervised network cross-diffusion based on graph topological\nmeasures, which can be further leveraged to design an efficient graph feature\nselection method for training predictive learners in network neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:17:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Mhiri", "Islem", ""], ["Mahjoub", "Mohamed Ali", ""], ["Rekik", "Islem", ""]]}, {"id": "2009.11058", "submitter": "Islem Rekik", "authors": "Alaa Bessadok, Mohamed Ali Mahjoub and Islem Rekik", "title": "Topology-Aware Generative Adversarial Network for Joint Prediction of\n  Multiple Brain Graphs from a Single Brain Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works based on Generative Adversarial Networks (GAN) have been\nrecently proposed to predict a set of medical images from a single modality\n(e.g, FLAIR MRI from T1 MRI). However, such frameworks are primarily designed\nto operate on images, limiting their generalizability to non-Euclidean\ngeometric data such as brain graphs. While a growing number of connectomic\nstudies has demonstrated the promise of including brain graphs for diagnosing\nneurological disorders, no geometric deep learning work was designed for\nmultiple target brain graphs prediction from a source brain graph. Despite the\nmomentum the field of graph generation has gained in the last two years,\nexisting works have two critical drawbacks. First, the bulk of such works aims\nto learn one model for each target domain to generate from a source domain.\nThus, they have a limited scalability in jointly predicting multiple target\ndomains. Second, they merely consider the global topological scale of a graph\n(i.e., graph connectivity structure) and overlook the local topology at the\nnode scale of a graph (e.g., how central a node is in the graph). To meet these\nchallenges, we introduce MultiGraphGAN architecture, which not only predicts\nmultiple brain graphs from a single brain graph but also preserves the\ntopological structure of each target graph to predict. Its three core\ncontributions lie in: (i) designing a graph adversarial auto-encoder for\njointly predicting brain graphs from a single one, (ii) handling the mode\ncollapse problem of GAN by clustering the encoded source graphs and proposing a\ncluster-specific decoder, (iii) introducing a topological loss to force the\nreconstruction of topologically sound target brain graphs. Our MultiGraphGAN\nsignificantly outperformed its variants thereby showing its great potential in\nmulti-view brain graph generation from a single graph.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:23:08 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bessadok", "Alaa", ""], ["Mahjoub", "Mohamed Ali", ""], ["Rekik", "Islem", ""]]}, {"id": "2009.11087", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Shalmali Joshi, Marzyeh Ghassemi, and Rajesh Ranganath", "title": "Probabilistic Machine Learning for Healthcare", "comments": "Annual Reviews of Biomedical Data Science 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning can be used to make sense of healthcare data. Probabilistic\nmachine learning models help provide a complete picture of observed data in\nhealthcare. In this review, we examine how probabilistic machine learning can\nadvance healthcare. We consider challenges in the predictive model building\npipeline where probabilistic models can be beneficial including calibration and\nmissing data. Beyond predictive models, we also investigate the utility of\nprobabilistic machine learning models in phenotyping, in generative models for\nclinical use cases, and in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:14:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Chen", "Irene Y.", ""], ["Joshi", "Shalmali", ""], ["Ghassemi", "Marzyeh", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2009.11094", "submitter": "Tianle Cai", "authors": "Jingtong Su, Yihang Chen, Tianle Cai, Tianhao Wu, Ruiqi Gao, Liwei\n  Wang, Jason D. Lee", "title": "Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot", "comments": "Accepted by NeurIPS 2020. Code available at\n  https://github.com/JingtongSu/sanity-checking-pruning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is a method for reducing test-time computational resource\nrequirements with minimal performance degradation. Conventional wisdom of\npruning algorithms suggests that: (1) Pruning methods exploit information from\ntraining data to find good subnetworks; (2) The architecture of the pruned\nnetwork is crucial for good performance. In this paper, we conduct sanity\nchecks for the above beliefs on several recent unstructured pruning methods and\nsurprisingly find that: (1) A set of methods which aims to find good\nsubnetworks of the randomly-initialized network (which we call \"initial\ntickets\"), hardly exploits any information from the training data; (2) For the\npruned networks obtained by these methods, randomly changing the preserved\nweights in each layer, while keeping the total number of preserved weights\nunchanged per layer, does not affect the final performance. These findings\ninspire us to choose a series of simple \\emph{data-independent} prune ratios\nfor each layer, and randomly prune each layer accordingly to get a subnetwork\n(which we call \"random tickets\"). Experimental results show that our zero-shot\nrandom tickets outperform or attain a similar performance compared to existing\n\"initial tickets\". In addition, we identify one existing pruning method that\npasses our sanity checks. We hybridize the ratios in our random ticket with\nthis method and propose a new method called \"hybrid tickets\", which achieves\nfurther improvement. (Our code is publicly available at\nhttps://github.com/JingtongSu/sanity-checking-pruning)\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:36:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:23:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Su", "Jingtong", ""], ["Chen", "Yihang", ""], ["Cai", "Tianle", ""], ["Wu", "Tianhao", ""], ["Gao", "Ruiqi", ""], ["Wang", "Liwei", ""], ["Lee", "Jason D.", ""]]}, {"id": "2009.11102", "submitter": "Jan Philipp Portisch", "authors": "Sven Hertling, Jan Portisch, Heiko Paulheim", "title": "Supervised Ontology and Instance Matching with MELT", "comments": "accepted at the the Fifteenth International Workshop on Ontology\n  Matching collocated with the 19th International Semantic Web Conference\n  ISWC-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present MELT-ML, a machine learning extension to the\nMatching and EvaLuation Toolkit (MELT) which facilitates the application of\nsupervised learning for ontology and instance matching. Our contributions are\ntwofold: We present an open source machine learning extension to the matching\ntoolkit as well as two supervised learning use cases demonstrating the\ncapabilities of the new extension.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:42:33 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hertling", "Sven", ""], ["Portisch", "Jan", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2009.11110", "submitter": "Islem Rekik", "authors": "Ahmet Serkan Goktas, Alaa Bessadok and Islem Rekik", "title": "Residual Embedding Similarity-Based Network Selection for Predicting\n  Brain Network Evolution Trajectory from a Single Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing predictive frameworks are able to handle Euclidean structured\ndata (i.e, brain images), they might fail to generalize to geometric\nnon-Euclidean data such as brain networks. Besides, these are rooted the sample\nselection step in using Euclidean or learned similarity measure between\nvectorized training and testing brain networks. Such sample connectomic\nrepresentation might include irrelevant and redundant features that could\nmislead the training sample selection step. Undoubtedly, this fails to exploit\nand preserve the topology of the brain connectome. To overcome this major\ndrawback, we propose Residual Embedding Similarity-Based Network selection\n(RESNets) for predicting brain network evolution trajectory from a single\ntimepoint. RESNets first learns a compact geometric embedding of each training\nand testing sample using adversarial connectome embedding network. This nicely\nreduces the high-dimensionality of brain networks while preserving their\ntopological properties via graph convolutional networks. Next, to compute the\nsimilarity between subjects, we introduce the concept of a connectional brain\ntemplate (CBT), a fixed network reference, where we further represent each\ntraining and testing network as a deviation from the reference CBT in the\nembedding space. As such, we select the most similar training subjects to the\ntesting subject at baseline by comparing their learned residual embeddings with\nrespect to the pre-defined CBT. Once the best training samples are selected at\nbaseline, we simply average their corresponding brain networks at follow-up\ntimepoints to predict the evolution trajectory of the testing network. Our\nexperiments on both healthy and disordered brain networks demonstrate the\nsuccess of our proposed method in comparison to RESNets ablated versions and\ntraditional approaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:40:04 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Goktas", "Ahmet Serkan", ""], ["Bessadok", "Alaa", ""], ["Rekik", "Islem", ""]]}, {"id": "2009.11112", "submitter": "Bahrudin Hrnjica PhD", "authors": "Bahrudin Hrnjica", "title": "ANNdotNET -- deep learning tool on .NET Platform", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ANNdotNET is an open source project for deep learning written in C# with\nability to create, train, evaluate and export deep learning models. The project\nconsists of the Graphical User Interface module capable to visually prepare\ndata, fine tune hyper-parameters, design network architecture, evaluate and\ntest trained models. The ANNdotNET introduces the Visual Network Designer,\n(VND) for visually design almost any sequential deep learning network. Beside\nVND, ANNdotNET implements Machine Learning Engine, (MLE) based on CNTK - deep\nlearning framework, with ability to train and evaluate models on GPU. For model\nevaluation ANNdotNET contains rich set of visual and descriptive performance\nparameters, history of the training process and set of export/deployment\noptions. The advantage of using ANNdotNET over the classic code based ML\napproach is more focus on deep learning network design and training process\ninstead of focusing on coding and debugging. It is ideal for engineers not\nfamiliar with supported programming languages. The project is hosted at\ngithub.com/bhrnjica/anndotnet.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:41:08 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hrnjica", "Bahrudin", ""]]}, {"id": "2009.11116", "submitter": "Vahid Shahrivari", "authors": "Vahid Shahrivari, Mohammad Mahdi Darabi, Mohammad Izadi", "title": "Phishing Detection Using Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has become an indispensable part of our life, However, It also\nhas provided opportunities to anonymously perform malicious activities like\nPhishing. Phishers try to deceive their victims by social engineering or\ncreating mock-up websites to steal information such as account ID, username,\npassword from individuals and organizations. Although many methods have been\nproposed to detect phishing websites, Phishers have evolved their methods to\nescape from these detection methods. One of the most successful methods for\ndetecting these malicious activities is Machine Learning. This is because most\nPhishing attacks have some common characteristics which can be identified by\nmachine learning methods. In this paper, we compared the results of multiple\nmachine learning methods for predicting phishing websites.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 11:52:52 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Shahrivari", "Vahid", ""], ["Darabi", "Mohammad Mahdi", ""], ["Izadi", "Mohammad", ""]]}, {"id": "2009.11119", "submitter": "Qi Qin", "authors": "Qi Qin, Wenpeng Hu, Bing Liu", "title": "Text Classification with Novelty Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of detecting novel or unexpected instances in\ntext classification. In traditional text classification, the classes appeared\nin testing must have been seen in training. However, in many applications, this\nis not the case because in testing, we may see unexpected instances that are\nnot from any of the training classes. In this paper, we propose a significantly\nmore effective approach that converts the original problem to a pair-wise\nmatching problem and then outputs how probable two instances belong to the same\nclass. Under this approach, we present two models. The more effective model\nuses two embedding matrices of a pair of instances as two channels of a CNN.\nThe output probabilities from such pairs are used to judge whether a test\ninstance is from a seen class or is novel/unexpected. Experimental results show\nthat the proposed method substantially outperforms the state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:54:34 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Qin", "Qi", ""], ["Hu", "Wenpeng", ""], ["Liu", "Bing", ""]]}, {"id": "2009.11128", "submitter": "Konstantinos Nikolaidis", "authors": "Konstantinos Nikolaidis, Thomas Plagemann, Stein Kristiansen, Vera\n  Goebel, Mohan Kankanhalli", "title": "Using Under-trained Deep Ensembles to Learn Under Extreme Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improper or erroneous labelling can pose a hindrance to reliable\ngeneralization for supervised learning. This can have negative consequences,\nespecially for critical fields such as healthcare. We propose an effective new\napproach for learning under extreme label noise, based on under-trained deep\nensembles. Each ensemble member is trained with a subset of the training data,\nto acquire a general overview of the decision boundary separation, without\nfocusing on potentially erroneous details. The accumulated knowledge of the\nensemble is combined to form new labels, that determine a better class\nseparation than the original labels. A new model is trained with these labels\nto generalize reliably despite the label noise. We focus on a healthcare\nsetting and extensively evaluate our approach on the task of sleep apnea\ndetection. For comparison with related work, we additionally evaluate on the\ntask of digit recognition. In our experiments, we observed performance\nimprovement in accuracy from 6.7\\% up-to 49.3\\% for the task of digit\nclassification and in kappa from 0.02 up-to 0.55 for the task of sleep apnea\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:12:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Nikolaidis", "Konstantinos", ""], ["Plagemann", "Thomas", ""], ["Kristiansen", "Stein", ""], ["Goebel", "Vera", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2009.11129", "submitter": "Saba Nazir", "authors": "Saba Nazir, Taner Cagali, Chris Newell, Mehrnoosh Sadrzadeh", "title": "Cosine Similarity of Multimodal Content Vectors for TV Programmes", "comments": "3 pages, 1 figure, Machine Learning for Media Discovery (ML4MD)\n  Workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal information originates from a variety of sources: audiovisual\nfiles, textual descriptions, and metadata. We show how one can represent the\ncontent encoded by each individual source using vectors, how to combine the\nvectors via middle and late fusion techniques, and how to compute the semantic\nsimilarities between the contents. Our vectorial representations are built from\nspectral features and Bags of Audio Words, for audio, LSI topics and Doc2vec\nembeddings for subtitles, and the categorical features, for metadata. We\nimplement our model on a dataset of BBC TV programmes and evaluate the fused\nrepresentations to provide recommendations. The late fused similarity matrices\nsignificantly improve the precision and diversity of recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:12:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Nazir", "Saba", ""], ["Cagali", "Taner", ""], ["Newell", "Chris", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "2009.11138", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Xin Zhang, Weiming Zhang, Anders S{\\o}gaard", "title": "Worst-Case-Aware Curriculum Learning for Zero and Few Shot Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task transfer learning based on pre-trained language encoders achieves\nstate-of-the-art performance across a range of tasks. Standard approaches\nimplicitly assume the tasks, for which we have training data, are equally\nrepresentative of the tasks we are interested in, an assumption which is often\nhard to justify. This paper presents a more agnostic approach to multi-task\ntransfer learning, which uses automated curriculum learning to minimize a new\nfamily of worst-case-aware losses across tasks. Not only do these losses lead\nto better performance on outlier tasks; they also lead to better performance in\nzero-shot and few-shot transfer settings.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:32:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhang", "Sheng", ""], ["Zhang", "Xin", ""], ["Zhang", "Weiming", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "2009.11162", "submitter": "Benoit Dherin", "authors": "David G.T. Barrett and Benoit Dherin", "title": "Implicit Gradient Regularization", "comments": null, "journal-ref": "Published as a conference paper at ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent can be surprisingly good at optimizing deep neural networks\nwithout overfitting and without explicit regularization. We find that the\ndiscrete steps of gradient descent implicitly regularize models by penalizing\ngradient descent trajectories that have large loss gradients. We call this\nImplicit Gradient Regularization (IGR) and we use backward error analysis to\ncalculate the size of this regularization. We confirm empirically that implicit\ngradient regularization biases gradient descent toward flat minima, where test\nerrors are small and solutions are robust to noisy parameter perturbations.\nFurthermore, we demonstrate that the implicit gradient regularization term can\nbe used as an explicit regularizer, allowing us to control this gradient\nregularization directly. More broadly, our work indicates that backward error\nanalysis is a useful theoretical approach to the perennial question of how\nlearning rate, model size, and parameter regularization interact to determine\nthe properties of overparameterized models optimized with gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 14:17:53 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 12:27:21 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Barrett", "David G. T.", ""], ["Dherin", "Benoit", ""]]}, {"id": "2009.11186", "submitter": "EPTCS", "authors": "Abeer Dyoub (University of L'Aquila, Italy), Stefania Costantini\n  (University of L'Aquila, Italy), Francesca A. Lisi (University of Bari \"A.\n  Moro\", Italy)", "title": "Logic Programming and Machine Ethics", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158. Invited paper for the\n  ICLP2020 Panel on \"Machine Ethics\". arXiv admin note: text overlap with\n  arXiv:1909.08255", "journal-ref": "EPTCS 325, 2020, pp. 6-17", "doi": "10.4204/EPTCS.325.6", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparency is a key requirement for ethical machines. Verified ethical\nbehavior is not enough to establish justified trust in autonomous intelligent\nagents: it needs to be supported by the ability to explain decisions. Logic\nProgramming (LP) has a great potential for developing such perspective ethical\nsystems, as in fact logic rules are easily comprehensible by humans.\nFurthermore, LP is able to model causality, which is crucial for ethical\ndecision making.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:18 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dyoub", "Abeer", "", "University of L'Aquila, Italy"], ["Costantini", "Stefania", "", "University of L'Aquila, Italy"], ["Lisi", "Francesca A.", "", "University of Bari \"A.\n  Moro\", Italy"]]}, {"id": "2009.11189", "submitter": "Weiqing Liu", "authors": "Xiao Yang, Weiqing Liu, Dong Zhou, Jiang Bian and Tie-Yan Liu", "title": "Qlib: An AI-oriented Quantitative Investment Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative investment aims to maximize the return and minimize the risk in\na sequential trading period over a set of financial instruments. Recently,\ninspired by rapid development and great potential of AI technologies in\ngenerating remarkable innovation in quantitative investment, there has been\nincreasing adoption of AI-driven workflow for quantitative research and\npractical investment. In the meantime of enriching the quantitative investment\nmethodology, AI technologies have raised new challenges to the quantitative\ninvestment system. Particularly, the new learning paradigms for quantitative\ninvestment call for an infrastructure upgrade to accommodate the renovated\nworkflow; moreover, the data-driven nature of AI technologies indeed indicates\na requirement of the infrastructure with more powerful performance;\nadditionally, there exist some unique challenges for applying AI technologies\nto solve different tasks in the financial scenarios. To address these\nchallenges and bridge the gap between AI technologies and quantitative\ninvestment, we design and develop Qlib that aims to realize the potential,\nempower the research, and create the value of AI technologies in quantitative\ninvestment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 12:57:10 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Yang", "Xiao", ""], ["Liu", "Weiqing", ""], ["Zhou", "Dong", ""], ["Bian", "Jiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2009.11193", "submitter": "Mathew Halm", "authors": "Samuel Pfrommer and Mathew Halm and Michael Posa", "title": "ContactNets: Learning Discontinuous Contact Dynamics with Smooth,\n  Implicit Representations", "comments": "S.P. and M.H. contributed equally to this work; Accepted to CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common methods for learning robot dynamics assume motion is continuous,\ncausing unrealistic model predictions for systems undergoing discontinuous\nimpact and stiction behavior. In this work, we resolve this conflict with a\nsmooth, implicit encoding of the structure inherent to contact-induced\ndiscontinuities. Our method, ContactNets, learns parameterizations of\ninter-body signed distance and contact-frame Jacobians, a representation that\nis compatible with many simulation, control, and planning environments for\nrobotics. We furthermore circumvent the need to differentiate through stiff or\nnon-smooth dynamics with a novel loss function inspired by the principles of\ncomplementarity and maximum dissipation. Our method can predict realistic\nimpact, non-penetration, and stiction when trained on 60 seconds of real-world\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 14:51:08 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 06:45:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pfrommer", "Samuel", ""], ["Halm", "Mathew", ""], ["Posa", "Michael", ""]]}, {"id": "2009.11208", "submitter": "Mohamed Handaoui", "authors": "Mohamed Handaoui and Jean-Emile Dartois and Jalil Boukhobza and\n  Olivier Barais and Laurent d'Orazio", "title": "ReLeaSER: A Reinforcement Learning Strategy for Optimizing Utilization\n  Of Ephemeral Cloud Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud data center capacities are over-provisioned to handle demand peaks and\nhardware failures which leads to low resources' utilization. One way to improve\nresource utilization and thus reduce the total cost of ownership is to offer\nunused resources (referred to as ephemeral resources) at a lower price.\nHowever, reselling resources needs to meet the expectations of its customers in\nterms of Quality of Service. The goal is so to maximize the amount of reclaimed\nresources while avoiding SLA penalties. To achieve that, cloud providers have\nto estimate their future utilization to provide availability guarantees. The\nprediction should consider a safety margin for resources to react to\nunpredictable workloads. The challenge is to find the safety margin that\nprovides the best trade-off between the amount of resources to reclaim and the\nrisk of SLA violations. Most state-of-the-art solutions consider a fixed safety\nmargin for all types of metrics (e.g., CPU, RAM). However, a unique fixed\nmargin does not consider various workloads variations over time which may lead\nto SLA violations or/and poor utilization. In order to tackle these challenges,\nwe propose ReLeaSER, a Reinforcement Learning strategy for optimizing the\nephemeral resources' utilization in the cloud. ReLeaSER dynamically tunes the\nsafety margin at the host-level for each resource metric. The strategy learns\nfrom past prediction errors (that caused SLA violations). Our solution reduces\nsignificantly the SLA violation penalties on average by 2.7x and up to 3.4x. It\nalso improves considerably the CPs' potential savings by 27.6% on average and\nup to 43.6%.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:19:28 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:23:21 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 09:59:20 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 10:48:38 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Handaoui", "Mohamed", ""], ["Dartois", "Jean-Emile", ""], ["Boukhobza", "Jalil", ""], ["Barais", "Olivier", ""], ["d'Orazio", "Laurent", ""]]}, {"id": "2009.11212", "submitter": "P\\'eter Alm\\'asi", "authors": "P\\'eter Alm\\'asi, R\\'obert Moni, B\\'alint Gyires-T\\'oth", "title": "Robust Reinforcement Learning-based Autonomous Driving Agent for\n  Simulation and Real World", "comments": "\\c{opyright} 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207497", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has been successfully used to solve\ndifferent challenges, e.g. complex board and computer games, recently. However,\nsolving real-world robotics tasks with DRL seems to be a more difficult\nchallenge. The desired approach would be to train the agent in a simulator and\ntransfer it to the real world. Still, models trained in a simulator tend to\nperform poorly in real-world environments due to the differences. In this\npaper, we present a DRL-based algorithm that is capable of performing\nautonomous robot control using Deep Q-Networks (DQN). In our approach, the\nagent is trained in a simulated environment and it is able to navigate both in\na simulated and real-world environment. The method is evaluated in the\nDuckietown environment, where the agent has to follow the lane based on a\nmonocular camera input. The trained agent is able to run on limited hardware\nresources and its performance is comparable to state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:23:54 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Alm\u00e1si", "P\u00e9ter", ""], ["Moni", "R\u00f3bert", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "2009.11218", "submitter": "Kalina Jasinska-Kobus", "authors": "Kalina Jasinska-Kobus, Marek Wydmuch, Krzysztof Dembczynski, Mikhail\n  Kuznetsov, Robert Busa-Fekete", "title": "Probabilistic Label Trees for Extreme Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMLC) is a learning task of tagging\ninstances with a small subset of relevant labels chosen from an extremely large\npool of possible labels. Problems of this scale can be efficiently handled by\norganizing labels as a tree, like in hierarchical softmax used for multi-class\nproblems. In this paper, we thoroughly investigate probabilistic label trees\n(PLTs) which can be treated as a generalization of hierarchical softmax for\nmulti-label problems. We first introduce the PLT model and discuss training and\ninference procedures and their computational costs. Next, we prove the\nconsistency of PLTs for a wide spectrum of performance metrics. To this end, we\nupperbound their regret by a function of surrogate-loss regrets of node\nclassifiers. Furthermore, we consider a problem of training PLTs in a fully\nonline setting, without any prior knowledge of training instances, their\nfeatures, or labels. In this case, both node classifiers and the tree structure\nare trained online. We prove a specific equivalence between the fully online\nalgorithm and an algorithm with a tree structure given in advance. Finally, we\ndiscuss several implementations of PLTs and introduce a new one, napkinXC,\nwhich we empirically evaluate and compare with state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:30:00 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jasinska-Kobus", "Kalina", ""], ["Wydmuch", "Marek", ""], ["Dembczynski", "Krzysztof", ""], ["Kuznetsov", "Mikhail", ""], ["Busa-Fekete", "Robert", ""]]}, {"id": "2009.11222", "submitter": "Zitao Liu", "authors": "Wentao Wang, Guowei Xu, Wenbiao Ding, Gale Yan Huang, Guoliang Li,\n  Jiliang Tang and Zitao Liu", "title": "Representation Learning from Limited Educational Data with Crowdsourced\n  Labels", "comments": "IEEE Transactions on Knowledge and Data Engineering (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning has been proven to play an important role in the\nunprecedented success of machine learning models in numerous tasks, such as\nmachine translation, face recognition and recommendation. The majority of\nexisting representation learning approaches often require a large number of\nconsistent and noise-free labels. However, due to various reasons such as\nbudget constraints and privacy concerns, labels are very limited in many\nreal-world scenarios. Directly applying standard representation learning\napproaches on small labeled data sets will easily run into over-fitting\nproblems and lead to sub-optimal solutions. Even worse, in some domains such as\neducation, the limited labels are usually annotated by multiple workers with\ndiverse expertise, which yields noises and inconsistency in such crowdsourcing\nsettings. In this paper, we propose a novel framework which aims to learn\neffective representations from limited data with crowdsourced labels.\nSpecifically, we design a grouping based deep neural network to learn\nembeddings from a limited number of training samples and present a Bayesian\nconfidence estimator to capture the inconsistency among crowdsourced labels.\nFurthermore, to expedite the training process, we develop a hard example\nselection procedure to adaptively pick up training examples that are\nmisclassified by the model. Extensive experiments conducted on three real-world\ndata sets demonstrate the superiority of our framework on learning\nrepresentations from limited data with crowdsourced labels, comparing with\nvarious state-of-the-art baselines. In addition, we provide a comprehensive\nanalysis on each of the main components of our proposed framework and also\nintroduce the promising results it achieved in our real production to fully\nunderstand the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:34:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Wentao", ""], ["Xu", "Guowei", ""], ["Ding", "Wenbiao", ""], ["Huang", "Gale Yan", ""], ["Li", "Guoliang", ""], ["Tang", "Jiliang", ""], ["Liu", "Zitao", ""]]}, {"id": "2009.11226", "submitter": "Alexander Kalinowski", "authors": "Alexander Kalinowski and Yuan An", "title": "A Comparative Study on Structural and Semantic Properties of Sentence\n  Embeddings", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embeddings encode natural language sentences as low-dimensional\ndense vectors. A great deal of effort has been put into using sentence\nembeddings to improve several important natural language processing tasks.\nRelation extraction is such an NLP task that aims at identifying structured\nrelations defined in a knowledge base from unstructured text. A promising and\nmore efficient approach would be to embed both the text and structured\nknowledge in low-dimensional spaces and discover semantic alignments or\nmappings between them. Although a number of techniques have been proposed in\nthe literature for embedding both sentences and knowledge graphs, little is\nknown about the structural and semantic properties of these embedding spaces in\nterms of relation extraction. In this paper, we investigate the aforementioned\nproperties by evaluating the extent to which sentences carrying similar senses\nare embedded in close proximity sub-spaces, and if we can exploit that\nstructure to align sentences to a knowledge graph. We propose a set of\nexperiments using a widely-used large-scale data set for relation extraction\nand focusing on a set of key sentence embedding methods. We additionally\nprovide the code for reproducing these experiments at\nhttps://github.com/akalino/semantic-structural-sentences. These embedding\nmethods cover a wide variety of techniques ranging from simple word embedding\ncombination to transformer-based BERT-style model. Our experimental results\nshow that different embedding spaces have different degrees of strength for the\nstructural and semantic properties. These results provide useful information\nfor developing embedding-based relation extraction methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:45:32 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kalinowski", "Alexander", ""], ["An", "Yuan", ""]]}, {"id": "2009.11239", "submitter": "Siamak Mehrkanoon", "authors": "Ismail Alaoui Abdellaoui and Siamak Mehrkanoon", "title": "Deep multi-stations weather forecasting: explainable recurrent\n  convolutional neural networks", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning applied to weather forecasting has started gaining popularity\nbecause of the progress achieved by data-driven models. The present paper\ncompares two different deep learning architectures to perform weather\nprediction on daily data gathered from 18 cities across Europe and spanned over\na period of 15 years. We propose the Deep Attention Unistream Multistream\n(DAUM) networks that investigate different types of input representations (i.e.\ntensorial unistream vs. multistream ) as well as the incorporation of the\nattention mechanism. In particular, we show that adding a self-attention block\nwithin the models increases the overall forecasting performance. Furthermore,\nvisualization techniques such as occlusion analysis and score maximization are\nused to give an additional insight on the most important features and cities\nfor predicting a particular target feature of target cities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:22:25 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 14:09:25 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 12:55:24 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 22:09:20 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 15:42:35 GMT"}, {"version": "v6", "created": "Wed, 10 Feb 2021 00:05:10 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Abdellaoui", "Ismail Alaoui", ""], ["Mehrkanoon", "Siamak", ""]]}, {"id": "2009.11243", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, C. Daniel Freeman, Ben Poole, Jascha\n  Sohl-Dickstein", "title": "Tasks, stability, architecture, and compute: Training more effective\n  learned optimizers, and using them to train themselves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much as replacing hand-designed features with learned functions has\nrevolutionized how we solve perceptual tasks, we believe learned algorithms\nwill transform how we train models. In this work we focus on general-purpose\nlearned optimizers capable of training a wide variety of problems with no\nuser-specified hyperparameters. We introduce a new, neural network\nparameterized, hierarchical optimizer with access to additional features such\nas validation loss to enable automatic regularization. Most learned optimizers\nhave been trained on only a single task, or a small number of tasks. We train\nour optimizers on thousands of tasks, making use of orders of magnitude more\ncompute, resulting in optimizers that generalize better to unseen tasks. The\nlearned optimizers not only perform well, but learn behaviors that are distinct\nfrom existing first order optimizers. For instance, they generate update steps\nthat have implicit regularization and adapt as the problem hyperparameters\n(e.g. batch size) or architecture (e.g. neural network width) change. Finally,\nthese learned optimizers show evidence of being useful for out of distribution\ntasks such as training themselves from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:35:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Freeman", "C. Daniel", ""], ["Poole", "Ben", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2009.11248", "submitter": "Swanand Kadhe", "authors": "Swanand Kadhe, Nived Rajaraman, O. Ozan Koyluoglu, Kannan Ramchandran", "title": "FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated\n  Learning", "comments": "Shorter version accepted in ICML Workshop on Federated Learning, July\n  2020, and CCS Workshop on Privacy-Preserving Machine Learning in Practice,\n  November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attacks on federated learning demonstrate that keeping the training\ndata on clients' devices does not provide sufficient privacy, as the model\nparameters shared by clients can leak information about their training data. A\n'secure aggregation' protocol enables the server to aggregate clients' models\nin a privacy-preserving manner. However, existing secure aggregation protocols\nincur high computation/communication costs, especially when the number of model\nparameters is larger than the number of clients participating in an iteration\n-- a typical scenario in federated learning.\n  In this paper, we propose a secure aggregation protocol, FastSecAgg, that is\nefficient in terms of computation and communication, and robust to client\ndropouts. The main building block of FastSecAgg is a novel multi-secret sharing\nscheme, FastShare, based on the Fast Fourier Transform (FFT), which may be of\nindependent interest. FastShare is information-theoretically secure, and\nachieves a trade-off between the number of secrets, privacy threshold, and\ndropout tolerance. Riding on the capabilities of FastShare, we prove that\nFastSecAgg is (i) secure against the server colluding with 'any' subset of some\nconstant fraction (e.g. $\\sim10\\%$) of the clients in the honest-but-curious\nsetting; and (ii) tolerates dropouts of a 'random' subset of some constant\nfraction (e.g. $\\sim10\\%$) of the clients. FastSecAgg achieves significantly\nsmaller computation cost than existing schemes while achieving the same\n(orderwise) communication cost. In addition, it guarantees security against\nadaptive adversaries, which can perform client corruptions dynamically during\nthe execution of the protocol.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:49:02 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kadhe", "Swanand", ""], ["Rajaraman", "Nived", ""], ["Koyluoglu", "O. Ozan", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2009.11253", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Zachary New, Nico Courts, Jung H. Lee, Lauren A.\n  Phillips, Courtney D. Corley, Aaron Tuor, Andrew Avila, Nathan O. Hodas", "title": "Fuzzy Simplicial Networks: A Topology-Inspired Model to Improve Task\n  Generalization in Few-shot Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown great success in settings with massive amounts of\ndata but has struggled when data is limited. Few-shot learning algorithms,\nwhich seek to address this limitation, are designed to generalize well to new\ntasks with limited data. Typically, models are evaluated on unseen classes and\ndatasets that are defined by the same fundamental task as they are trained for\n(e.g. category membership). One can also ask how well a model can generalize to\nfundamentally different tasks within a fixed dataset (for example: moving from\ncategory membership to tasks that involve detecting object orientation or\nquantity). To formalize this kind of shift we define a notion of \"independence\nof tasks\" and identify three new sets of labels for established computer vision\ndatasets that test a model's ability to generalize to tasks which draw on\northogonal attributes in the data. We use these datasets to investigate the\nfailure modes of metric-based few-shot models. Based on our findings, we\nintroduce a new few-shot model called Fuzzy Simplicial Networks (FSN) which\nleverages a construction from topology to more flexibly represent each class\nfrom limited data. In particular, FSN models can not only form multiple\nrepresentations for a given class but can also begin to capture the\nlow-dimensional structure which characterizes class manifolds in the encoded\nspace of deep networks. We show that FSN outperforms state-of-the-art models on\nthe challenging tasks we introduce in this paper while remaining competitive on\nstandard few-shot benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:01:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kvinge", "Henry", ""], ["New", "Zachary", ""], ["Courts", "Nico", ""], ["Lee", "Jung H.", ""], ["Phillips", "Lauren A.", ""], ["Corley", "Courtney D.", ""], ["Tuor", "Aaron", ""], ["Avila", "Andrew", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "2009.11264", "submitter": "Satwik Bhattamishra", "authors": "Satwik Bhattamishra, Kabir Ahuja, Navin Goyal", "title": "On the Ability and Limitations of Transformers to Recognize Formal\n  Languages", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have supplanted recurrent models in a large number of NLP tasks.\nHowever, the differences in their abilities to model different syntactic\nproperties remain largely unknown. Past works suggest that LSTMs generalize\nvery well on regular languages and have close connections with counter\nlanguages. In this work, we systematically study the ability of Transformers to\nmodel such languages as well as the role of its individual components in doing\nso. We first provide a construction of Transformers for a subclass of counter\nlanguages, including well-studied languages such as n-ary Boolean Expressions,\nDyck-1, and its generalizations. In experiments, we find that Transformers do\nwell on this subclass, and their learned mechanism strongly correlates with our\nconstruction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well\nonly on a subset of regular languages with degrading performance as we make\nlanguages more complex according to a well-known measure of complexity. Our\nanalysis also provides insights on the role of self-attention mechanism in\nmodeling certain behaviors and the influence of positional encoding schemes on\nthe learning and generalization abilities of the model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:21:33 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 12:55:37 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bhattamishra", "Satwik", ""], ["Ahuja", "Kabir", ""], ["Goyal", "Navin", ""]]}, {"id": "2009.11277", "submitter": "Liang Wang", "authors": "Liang Wang, Kezhi Wang, Cunhua Pan, Wei Xu, Nauman Aslam and Lajos\n  Hanzo", "title": "Multi-Agent Deep Reinforcement Learning Based Trajectory Planning for\n  Multi-UAV Assisted Mobile Edge Computing", "comments": "Accepted by IEEE Transactions on Cognitive Communications and\n  Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unmanned aerial vehicle (UAV)-aided mobile edge computing (MEC) framework\nis proposed, where several UAVs having different trajectories fly over the\ntarget area and support the user equipments (UEs) on the ground. We aim to\njointly optimize the geographical fairness among all the UEs, the fairness of\neach UAV' UE-load and the overall energy consumption of UEs. The above\noptimization problem includes both integer and continues variables and it is\nchallenging to solve. To address the above problem, a multi-agent deep\nreinforcement learning based trajectory control algorithm is proposed for\nmanaging the trajectory of each UAV independently, where the popular\nMulti-Agent Deep Deterministic Policy Gradient (MADDPG) method is applied.\nGiven the UAVs' trajectories, a low-complexity approach is introduced for\noptimizing the offloading decisions of UEs. We show that our proposed solution\nhas considerable performance over other traditional algorithms, both in terms\nof the fairness for serving UEs, fairness of UE-load at each UAV and energy\nconsumption for all the UEs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:44:07 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Liang", ""], ["Wang", "Kezhi", ""], ["Pan", "Cunhua", ""], ["Xu", "Wei", ""], ["Aslam", "Nauman", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2009.11278", "submitter": "Jaemin Cho", "authors": "Jaemin Cho, Jiasen Lu, Dustin Schwenk, Hannaneh Hajishirzi, Aniruddha\n  Kembhavi", "title": "X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal\n  Transformers", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirroring the success of masked language models, vision-and-language\ncounterparts like ViLBERT, LXMERT and UNITER have achieved state of the art\nperformance on a variety of multimodal discriminative tasks like visual\nquestion answering and visual grounding. Recent work has also successfully\nadapted such models towards the generative task of image captioning. This begs\nthe question: Can these models go the other way and generate images from pieces\nof text? Our analysis of a popular representative from this model family -\nLXMERT - finds that it is unable to generate rich and semantically meaningful\nimagery with its current training setup. We introduce X-LXMERT, an extension to\nLXMERT with training refinements including: discretizing visual\nrepresentations, using uniform masking with a large range of masking ratios and\naligning the right pre-training datasets to the right objectives which enables\nit to paint. X-LXMERT's image generation capabilities rival state of the art\ngenerative models while its question answering and captioning abilities remains\ncomparable to LXMERT. Finally, we demonstrate the generality of these training\nrefinements by adding image generation capabilities into UNITER to produce\nX-UNITER.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:45:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Cho", "Jaemin", ""], ["Lu", "Jiasen", ""], ["Schwenk", "Dustin", ""], ["Hajishirzi", "Hannaneh", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "2009.11279", "submitter": "Udit Bhatia", "authors": "Nidhin Harilal, Udit Bhatia, Mayank Singh", "title": "Augmented Convolutional LSTMs for Generation of High-Resolution Climate\n  Change Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projection of changes in extreme indices of climate variables such as\ntemperature and precipitation are critical to assess the potential impacts of\nclimate change on human-made and natural systems, including critical\ninfrastructures and ecosystems. While impact assessment and adaptation planning\nrely on high-resolution projections (typically in the order of a few\nkilometers), state-of-the-art Earth System Models (ESMs) are available at\nspatial resolutions of few hundreds of kilometers. Current solutions to obtain\nhigh-resolution projections of ESMs include downscaling approaches that\nconsider the information at a coarse-scale to make predictions at local scales.\nComplex and non-linear interdependence among local climate variables (e.g.,\ntemperature and precipitation) and large-scale predictors (e.g., pressure\nfields) motivate the use of neural network-based super-resolution\narchitectures. In this work, we present auxiliary variables informed\nspatio-temporal neural architecture for statistical downscaling. The current\nstudy performs daily downscaling of precipitation variable from an ESM output\nat 1.15 degrees (~115 km) to 0.25 degrees (25 km) over the world's most\nclimatically diversified country, India. We showcase significant improvement\ngain against three popular state-of-the-art baselines with a better ability to\npredict extreme events. To facilitate reproducible research, we make available\nall the codes, processed datasets, and trained models in the public domain.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:52:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Harilal", "Nidhin", ""], ["Bhatia", "Udit", ""], ["Singh", "Mayank", ""]]}, {"id": "2009.11282", "submitter": "Yuxin Chen", "authors": "Yanxi Chen, Cong Ma, H. Vincent Poor, Yuxin Chen", "title": "Learning Mixtures of Low-Rank Models", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning mixtures of low-rank models, i.e.\nreconstructing multiple low-rank matrices from unlabelled linear measurements\nof each. This problem enriches two widely studied settings -- low-rank matrix\nsensing and mixed linear regression -- by bringing latent variables (i.e.\nunknown labels) and structural priors (i.e. low-rank structures) into\nconsideration. To cope with the non-convexity issues arising from unlabelled\nheterogeneous data and low-complexity structure, we develop a three-stage\nmeta-algorithm that is guaranteed to recover the unknown matrices with\nnear-optimal sample and computational complexities under Gaussian designs. In\naddition, the proposed algorithm is provably stable against random noise. We\ncomplement the theoretical studies with empirical evidence that confirms the\nefficacy of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:53:48 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 21:36:55 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chen", "Yanxi", ""], ["Ma", "Cong", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "2009.11285", "submitter": "Kazuma Tsuji", "authors": "Kazuma Tsuji and Taiji Suzuki", "title": "Estimation error analysis of deep learning on the regression problem on\n  the variable exponent Besov space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved notable success in various fields, including image\nand speech recognition. One of the factors in the successful performance of\ndeep learning is its high feature extraction ability. In this study, we focus\non the adaptivity of deep learning; consequently, we treat the variable\nexponent Besov space, which has a different smoothness depending on the input\nlocation $x$. In other words, the difficulty of the estimation is not uniform\nwithin the domain. We analyze the general approximation error of the variable\nexponent Besov space and the approximation and estimation errors of deep\nlearning. We note that the improvement based on adaptivity is remarkable when\nthe region upon which the target function has less smoothness is small and the\ndimension is large. Moreover, the superiority to linear estimators is shown\nwith respect to the convergence rate of the estimation error.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:56:24 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 13:55:47 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 14:14:45 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 14:23:53 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 15:23:23 GMT"}, {"version": "v6", "created": "Wed, 31 Mar 2021 13:24:34 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Tsuji", "Kazuma", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2009.11327", "submitter": "Emmanuel Iarussi", "authors": "Emmanuel Iarussi, Felix Thomsen and Claudio Delrieux", "title": "Generative Modelling of 3D in-silico Spongiosa with Controllable\n  Micro-Structural Parameters", "comments": "Accepted for publication in MICCAI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in vertebral bone micro-structure generally requires costly\nprocedures to obtain physical scans of real bone with a specific pathology\nunder study, since no methods are available yet to generate realistic bone\nstructures in-silico. Here we propose to apply recent advances in generative\nadversarial networks (GANs) to develop such a method. We adapted style-transfer\ntechniques, which have been largely used in other contexts, in order to\ntransfer style between image pairs while preserving its informational content.\nIn a first step, we trained a volumetric generative model in a progressive\nmanner using a Wasserstein objective and gradient penalty (PWGAN-GP) to create\npatches of realistic bone structure in-silico. The training set contained 7660\npurely spongeous bone samples from twelve human vertebrae (T12 or L1) with\nisotropic resolution of 164um and scanned with a high resolution peripheral\nquantitative CT (Scanco XCT). After training, we generated new samples with\ntailored micro-structure properties by optimizing a vector z in the learned\nlatent space. To solve this optimization problem, we formulated a\ndifferentiable goal function that leads to valid samples while compromising the\nappearance (content) with target 3D properties (style). Properties of the\nlearned latent space effectively matched the data distribution. Furthermore, we\nwere able to simulate the resulting bone structure after deterioration or\ntreatment effects of osteoporosis therapies based only on expected changes of\nmicro-structural parameters. Our method allows to generate a virtually infinite\nnumber of patches of realistic bone micro-structure, and thereby likely serves\nfor the development of bone-biomarkers and to simulate bone therapies in\nadvance.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 18:11:47 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Iarussi", "Emmanuel", ""], ["Thomsen", "Felix", ""], ["Delrieux", "Claudio", ""]]}, {"id": "2009.11330", "submitter": "Farzana Beente Yusuf", "authors": "Farzana Beente Yusuf, Vitalii Stebliankin, Giuseppe Vietri, Giri\n  Narasimhan", "title": "Cache Replacement as a MAB with Delayed Feedback and Decaying Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the cache replacement problem, we propose and solve a new variant\nof the well-known multi-armed bandit (MAB), thus providing a solution for\nimproving existing state-of-the-art cache management methods. Each arm (or\nexpert) represents a distinct cache replacement policy, which advises on the\npage to evict from the cache when needed. Feedback on the eviction comes in the\nform of a \"miss\", but at an indeterminate time after the action is taken, and\nthe cost of the eviction is set to be inversely proportional to the response\ntime. The feedback is ignored if it comes after a threshold value for the\ndelay, which we set to be equal to the size of the page eviction history. Thus,\nfor delays beyond the threshold, its cost is assumed to be zero. Consequently,\nwe call this problem with delayed feedback and decaying costs. We introduce an\nadaptive reinforcement learning algorithm EXP4-DFDC that provides a solution to\nthe problem. We derive an optimal learning rate for EXP4-DFDC that defines the\nbalance between exploration and exploitation and proves theoretically that the\nexpected regret of our algorithm is a vanishing quantity as a function of time.\nAs an application, we show that LeCaR, a recent top-performing machine learning\nalgorithm for cache replacement, can be enhanced with adaptive learning using\nour formulations. We present an improved adaptive version of LeCaR, called\nOLeCaR, with the learning rate set as determined by the theoretical derivation\npresented here to minimize regret for EXP4-DFDC. It then follows that LeCaR and\nOLeCaR are theoretically guaranteed to have vanishing regret over time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 18:26:48 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 04:46:15 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 16:52:38 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 04:32:39 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Yusuf", "Farzana Beente", ""], ["Stebliankin", "Vitalii", ""], ["Vietri", "Giuseppe", ""], ["Narasimhan", "Giri", ""]]}, {"id": "2009.11347", "submitter": "Ivan Letteri", "authors": "Ivan Letteri, Antonio Di Cecco, Giuseppe Della Penna", "title": "Dataset Optimization Strategies for MalwareTraffic Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is rapidly becoming one of the most important technology for\nmalware traffic detection, since the continuous evolution of malware requires a\nconstant adaptation and the ability to generalize. However, network traffic\ndatasets are usually oversized and contain redundant and irrelevant\ninformation, and this may dramatically increase the computational cost and\ndecrease the accuracy of most classifiers, with the risk to introduce further\nnoise.\n  We propose two novel dataset optimization strategies which exploit and\ncombine several state-of-the-art approaches in order to achieve an effective\noptimization of the network traffic datasets used to train malware detectors.\nThe first approach is a feature selection technique based on mutual information\nmeasures and sensibility enhancement. The second is a dimensional reduction\ntechnique based autoencoders. Both these approaches have been experimentally\napplied on the MTA-KDD'19 dataset, and the optimized results evaluated and\ncompared using a Multi Layer Perceptron as machine learning model for malware\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:27:22 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Letteri", "Ivan", ""], ["Di Cecco", "Antonio", ""], ["Della Penna", "Giuseppe", ""]]}, {"id": "2009.11348", "submitter": "Krishna Chaitanya Kalagarla", "authors": "Krishna C. Kalagarla, Rahul Jain, Pierluigi Nuzzo", "title": "A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Processes (CMDPs) formalize sequential\ndecision-making problems whose objective is to minimize a cost function while\nsatisfying constraints on various cost functions. In this paper, we consider\nthe setting of episodic fixed-horizon CMDPs. We propose an online algorithm\nwhich leverages the linear programming formulation of finite-horizon CMDP for\nrepeated optimistic planning to provide a probably approximately correct (PAC)\nguarantee on the number of episodes needed to ensure an $\\epsilon$-optimal\npolicy, i.e., with resulting objective value within $\\epsilon$ of the optimal\nvalue and satisfying the constraints within $\\epsilon$-tolerance, with\nprobability at least $1-\\delta$. The number of episodes needed is shown to be\nof the order\n$\\tilde{\\mathcal{O}}\\big(\\frac{|S||A|C^{2}H^{2}}{\\epsilon^{2}}\\log\\frac{1}{\\delta}\\big)$,\nwhere $C$ is the upper bound on the number of possible successor states for a\nstate-action pair. Therefore, if $C \\ll |S|$, the number of episodes needed\nhave a linear dependence on the state and action space sizes $|S|$ and $|A|$,\nrespectively, and quadratic dependence on the time horizon $H$.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:30:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kalagarla", "Krishna C.", ""], ["Jain", "Rahul", ""], ["Nuzzo", "Pierluigi", ""]]}, {"id": "2009.11349", "submitter": "Gil Fidel", "authors": "Gil Fidel, Ron Bitton, Ziv Katzir, Asaf Shabtai", "title": "Adversarial robustness via stochastic regularization of neural\n  activation sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that the input domain of any machine learning\nclassifier is bound to contain adversarial examples. Thus we can no longer hope\nto immune classifiers against adversarial examples and instead can only aim to\nachieve the following two defense goals: 1) making adversarial examples harder\nto find, or 2) weakening their adversarial nature by pushing them further away\nfrom correctly classified data points. Most if not all the previously suggested\ndefense mechanisms attend to just one of those two goals, and as such, could be\nbypassed by adaptive attacks that take the defense mechanism into\nconsideration. In this work we suggest a novel defense mechanism that\nsimultaneously addresses both defense goals: We flatten the gradients of the\nloss surface, making adversarial examples harder to find, using a novel\nstochastic regularization term that explicitly decreases the sensitivity of\nindividual neurons to small input perturbations. In addition, we push the\ndecision boundary away from correctly classified inputs by leveraging Jacobian\nregularization. We present a solid theoretical basis and an empirical testing\nof our suggested approach, demonstrate its superiority over previously\nsuggested defense mechanisms, and show that it is effective against a wide\nrange of adaptive attacks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:31:55 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Fidel", "Gil", ""], ["Bitton", "Ron", ""], ["Katzir", "Ziv", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2009.11353", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov, Andrei Bobu, Maximilien Dreveton", "title": "Higher-Order Spectral Clustering for Geometric Graphs", "comments": "23 pages, 6 figures", "journal-ref": "Journal of Fourier Analysis and Applications, 27:22, 2021", "doi": "10.1007/s00041-021-09825-2", "report-no": null, "categories": "cs.LG cs.SI math.PR math.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The present paper is devoted to clustering geometric graphs. While the\nstandard spectral clustering is often not effective for geometric graphs, we\npresent an effective generalization, which we call higher-order spectral\nclustering. It resembles in concept the classical spectral clustering method\nbut uses for partitioning the eigenvector associated with a higher-order\neigenvalue. We establish the weak consistency of this algorithm for a wide\nclass of geometric graphs which we call Soft Geometric Block Model. A small\nadjustment of the algorithm provides strong consistency. We also show that our\nmethod is effective in numerical experiments even for graphs of modest size.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:51:55 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:57:43 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Bobu", "Andrei", ""], ["Dreveton", "Maximilien", ""]]}, {"id": "2009.11355", "submitter": "Yasmin Salehi", "authors": "Kian Ahrabian, Aarash Feizi, Yasmin Salehi, William L. Hamilton and\n  Avishek Joey Bose", "title": "Structure Aware Negative Sampling in Knowledge Graphs", "comments": "Accepted to EMNLP 2020. Camera-ready submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-dimensional representations for entities and relations in\nknowledge graphs using contrastive estimation represents a scalable and\neffective method for inferring connectivity patterns. A crucial aspect of\ncontrastive learning approaches is the choice of corruption distribution that\ngenerates hard negative samples, which force the embedding model to learn\ndiscriminative representations and find critical characteristics of observed\ndata. While earlier methods either employ too simple corruption distributions,\ni.e. uniform, yielding easy uninformative negatives or sophisticated\nadversarial distributions with challenging optimization schemes, they do not\nexplicitly incorporate known graph structure resulting in suboptimal negatives.\nIn this paper, we propose Structure Aware Negative Sampling (SANS), an\ninexpensive negative sampling strategy that utilizes the rich graph structure\nby selecting negative samples from a node's k-hop neighborhood. Empirically, we\ndemonstrate that SANS finds semantically meaningful negatives and is\ncompetitive with SOTA approaches while requires no additional parameters nor\ndifficult adversarial optimization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:57:00 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 02:23:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Ahrabian", "Kian", ""], ["Feizi", "Aarash", ""], ["Salehi", "Yasmin", ""], ["Hamilton", "William L.", ""], ["Bose", "Avishek Joey", ""]]}, {"id": "2009.11359", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Xuchan Bao, Laurent Lessard, Roger Grosse", "title": "A Unified Analysis of First-Order Methods for Smooth Games via Integral\n  Quadratic Constraints", "comments": "Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of integral quadratic constraints (IQCs) allows the certification\nof exponential convergence of interconnected systems containing nonlinear or\nuncertain elements. In this work, we adapt the IQC theory to study first-order\nmethods for smooth and strongly-monotone games and show how to design tailored\nquadratic constraints to get tight upper bounds of convergence rates. Using\nthis framework, we recover the existing bound for the gradient method~(GD),\nderive sharper bounds for the proximal point method~(PPM) and optimistic\ngradient method~(OG), and provide \\emph{for the first time} a global\nconvergence rate for the negative momentum method~(NM) with an iteration\ncomplexity $\\mathcal{O}(\\kappa^{1.5})$, which matches its known lower bound. In\naddition, for time-varying systems, we prove that the gradient method with\noptimal step size achieves the fastest provable worst-case convergence rate\nwith quadratic Lyapunov functions. Finally, we further extend our analysis to\nstochastic games and study the impact of multiplicative noise on different\nalgorithms. We show that it is impossible for an algorithm with one step of\nmemory to achieve acceleration if it only queries the gradient once per batch\n(in contrast with the stochastic strongly-convex optimization setting, where\nsuch acceleration has been demonstrated). However, we exhibit an algorithm\nwhich achieves acceleration with two gradient queries per batch.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:02:00 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:58:13 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 05:48:47 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 00:53:41 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhang", "Guodong", ""], ["Bao", "Xuchan", ""], ["Lessard", "Laurent", ""], ["Grosse", "Roger", ""]]}, {"id": "2009.11360", "submitter": "Duy Minh Ho Nguyen", "authors": "Thu Nguyen, Duy H. M. Nguyen, Huy Nguyen, Binh T. Nguyen, Bruce A.\n  Wade", "title": "EPEM: Efficient Parameter Estimation for Multiple Class Monotone Missing\n  Data", "comments": "version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of monotone missing data has been broadly studied during the last\ntwo decades and has many applications in different fields such as\nbioinformatics or statistics. Commonly used imputation techniques require\nmultiple iterations through the data before yielding convergence. Moreover,\nthose approaches may introduce extra noises and biases to the subsequent\nmodeling. In this work, we derive exact formulas and propose a novel algorithm\nto compute the maximum likelihood estimators (MLEs) of a multiple class,\nmonotone missing dataset when all the covariance matrices of all categories are\nassumed to be equal, namely EPEM. We then illustrate an application of our\nproposed methods in Linear Discriminant Analysis (LDA). As the computation is\nexact, our EPEM algorithm does not require multiple iterations through the data\nas other imputation approaches, thus promising to handle much less\ntime-consuming than other methods. This effectiveness was validated by\nempirical results when EPEM reduced the error rates significantly and required\na short computation time compared to several imputation-based approaches. We\nalso release all codes and data of our experiments in one GitHub repository to\ncontribute to the research community related to this problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:07:53 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Nguyen", "Thu", ""], ["Nguyen", "Duy H. M.", ""], ["Nguyen", "Huy", ""], ["Nguyen", "Binh T.", ""], ["Wade", "Bruce A.", ""]]}, {"id": "2009.11361", "submitter": "Mohamed Elsayed", "authors": "Mohamed Elsayed, Ahmad A. Aziz El-Banna, Octavia A. Dobre, Wanyi Shiu,\n  and Peiwei Wang", "title": "Low Complexity Neural Network Structures for Self-Interference\n  Cancellation in Full-Duplex Radio", "comments": "13 pages, 4 figures, to be appeared to IEEE Communications Letters", "journal-ref": null, "doi": "10.1109/LCOMM.2020.3024063", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-interference (SI) is considered as a main challenge in full-duplex (FD)\nsystems. Therefore, efficient SI cancelers are required for the influential\ndeployment of FD systems in beyond fifth-generation wireless networks. Existing\nmethods for SI cancellation have mostly considered the polynomial\nrepresentation of the SI signal at the receiver. These methods are shown to\noperate well in practice while requiring high computational complexity.\nAlternatively, neural networks (NNs) are envisioned as promising candidates for\nmodeling the SI signal with reduced computational complexity. Consequently, in\nthis paper, two novel low complexity NN structures, referred to as the\nladder-wise grid structure (LWGS) and moving-window grid structure (MWGS), are\nproposed. The core idea of these two structures is to mimic the non-linearity\nand memory effect introduced to the SI signal in order to achieve proper SI\ncancellation while exhibiting low computational complexity. The simulation\nresults reveal that the LWGS and MWGS NN-based cancelers attain the same\ncancellation performance of the polynomial-based canceler while providing\n49.87% and 34.19% complexity reduction, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:10:08 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Elsayed", "Mohamed", ""], ["El-Banna", "Ahmad A. Aziz", ""], ["Dobre", "Octavia A.", ""], ["Shiu", "Wanyi", ""], ["Wang", "Peiwei", ""]]}, {"id": "2009.11362", "submitter": "Renhao Wang", "authors": "Renhao Wang, Ashutosh Bhudia, Brandon Dos Remedios, Minnie Teng,\n  Raymond Ng", "title": "Dense Forecasting of Wildfire Smoke Particulate Matter Using Sparsity\n  Invariant Convolutional Neural Networks", "comments": "Submitted to the 2020 NeurIPS Workshop on Machine learning in Public\n  Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasts of fine particulate matter (PM 2.5) from wildfire smoke\nare crucial to safeguarding cardiopulmonary public health. Existing forecasting\nsystems are trained on sparse and inaccurate ground truths, and do not take\nsufficient advantage of important spatial inductive biases. In this work, we\npresent a convolutional neural network which preserves sparsity invariance\nthroughout, and leverages multitask learning to perform dense forecasts of PM\n2.5values. We demonstrate that our model outperforms two existing smoke\nforecasting systems during the 2018 and 2019 wildfire season in British\nColumbia, Canada, predicting PM 2.5 at a grid resolution of 10 km, 24 hours in\nadvance with high fidelity. Most interestingly, our model also generalizes to\nmeaningful smoke dispersion patterns despite training with irregularly\ndistributed ground truth PM 2.5 values available in only 0.5% of grid cells.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:13:35 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wang", "Renhao", ""], ["Bhudia", "Ashutosh", ""], ["Remedios", "Brandon Dos", ""], ["Teng", "Minnie", ""], ["Ng", "Raymond", ""]]}, {"id": "2009.11390", "submitter": "Valdimir Jos\\'e Ramon Pieter", "authors": "Valdimir Pieter", "title": "Parameters for the best convergence of an optimization algorithm\n  On-The-Fly", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What really sparked my interest was how certain parameters worked better at\nexecuting and optimization algorithm convergence even though the objective\nformula had no significant differences. Thus the research question stated:\n'Which parameters provides an upmost optimal convergence solution of an\nObjective formula using the on-the-fly method?' This research was done in an\nexperimental concept in which five different algorithms were tested with\ndifferent objective functions to discover which parameter would result well for\nthe best convergence. To find the correct parameter a method called\n'on-the-fly' was applied. I run the experiments with five different\noptimization algorithms. One of the test runs showed that each parameter has an\nincreasing or decreasing convergence accuracy towards the subjective function\ndepending on which specific optimization algorithm you choose. Each parameter\nhas an increasing or decreasing convergence accuracy toward the subjective\nfunction. One of the results in which evolutionary algorithm was applied with\nonly the recombination technique did well at finding the best optimization. As\nwell that some results have an increasing accuracy visualization by combing\nmutation or several parameters in one test performance. In conclusion, each\nalgorithm has its own set of the parameter that converge differently. Also\ndepending on the target formula that is used. This confirms that the fly method\na suitable approach at finding the best parameter. This means manipulations and\nobserve the effects in process to find the right parameter works as long as the\nlearning cost rate decreases over time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:38:28 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Pieter", "Valdimir", ""]]}, {"id": "2009.11394", "submitter": "Tedd Kourkounakis", "authors": "Tedd Kourkounakis, Amirhossein Hajavi, Ali Etemad", "title": "FluentNet: End-to-End Detection of Speech Disfluency with Deep Learning", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong presentation skills are valuable and sought-after in workplace and\nclassroom environments alike. Of the possible improvements to vocal\npresentations, disfluencies and stutters in particular remain one of the most\ncommon and prominent factors of someone's demonstration. Millions of people are\naffected by stuttering and other speech disfluencies, with the majority of the\nworld having experienced mild stutters while communicating under stressful\nconditions. While there has been much research in the field of automatic speech\nrecognition and language models, there lacks the sufficient body of work when\nit comes to disfluency detection and recognition. To this end, we propose an\nend-to-end deep neural network, FluentNet, capable of detecting a number of\ndifferent disfluency types. FluentNet consists of a Squeeze-and-Excitation\nResidual convolutional neural network which facilitate the learning of strong\nspectral frame-level representations, followed by a set of bidirectional long\nshort-term memory layers that aid in learning effective temporal relationships.\nLastly, FluentNet uses an attention mechanism to focus on the important parts\nof speech to obtain a better performance. We perform a number of different\nexperiments, comparisons, and ablation studies to evaluate our model. Our model\nachieves state-of-the-art results by outperforming other solutions in the field\non the publicly available UCLASS dataset. Additionally, we present\nLibriStutter: a disfluency dataset based on the public LibriSpeech dataset with\nsynthesized stutters. We also evaluate FluentNet on this dataset, showing the\nstrong performance of our model versus a number of benchmark techniques.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:51:29 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kourkounakis", "Tedd", ""], ["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "2009.11397", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann, Kira Maag, Mathis Peyron, Natasa Krejic and Hanno\n  Gottschalk", "title": "Detection of Iterative Adversarial Attacks via Counter Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have proven to be powerful tools for processing\nunstructured data. However for high-dimensional data, like images, they are\ninherently vulnerable to adversarial attacks. Small almost invisible\nperturbations added to the input can be used to fool DNNs. Various attacks,\nhardening methods and detection methods have been introduced in recent years.\nNotoriously, Carlini-Wagner (CW) type attacks computed by iterative\nminimization belong to those that are most difficult to detect. In this work we\noutline a mathematical proof that the CW attack can be used as a detector\nitself. That is, under certain assumptions and in the limit of attack\niterations this detector provides asymptotically optimal separation of original\nand attacked images. In numerical experiments, we experimentally validate this\nstatement and furthermore obtain AUROC values up to 99.73% on CIFAR10 and\nImageNet. This is in the upper part of the spectrum of current state-of-the-art\ndetection rates for CW attacks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:54:36 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 14:21:02 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Rottmann", "Matthias", ""], ["Maag", "Kira", ""], ["Peyron", "Mathis", ""], ["Krejic", "Natasa", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "2009.11405", "submitter": "Chen Zhao", "authors": "Chen Zhao, Feng Chen", "title": "Rank-Based Multi-task Learning for Fair Regression", "comments": "2019 IEEE International Conference on Data Mining (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel fairness learning approach for multi-task\nregression models based on a biased training dataset, using a popular\nrank-based non-parametric independence test, i.e., Mann Whitney U statistic,\nfor measuring the dependency between target variable and protected variables.\nTo solve this learning problem efficiently, we first reformulate the problem as\na new non-convex optimization problem, in which a non-convex constraint is\ndefined based on group-wise ranking functions of individual objects. We then\ndevelop an efficient model-training algorithm based on the framework of\nnon-convex alternating direction method of multipliers (NC-ADMM), in which one\nof the main challenges is to implement an efficient projection oracle to the\npreceding non-convex set defined based on ranking functions. Through the\nextensive experiments on both synthetic and real-world datasets, we validated\nthe out-performance of our new approach against several state-of-the-art\ncompetitive methods on several popular metrics relevant to fairness learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:32:57 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Chen", ""], ["Chen", "Feng", ""]]}, {"id": "2009.11406", "submitter": "Chen Zhao", "authors": "Chen Zhao, Feng Chen", "title": "Unfairness Discovery and Prevention For Few-Shot Regression", "comments": "2020 IEEE International Conference on Knowledge Graph (ICKG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fairness in supervised few-shot meta-learning models that are\nsensitive to discrimination (or bias) in historical data. A machine learning\nmodel trained based on biased data tends to make unfair predictions for users\nfrom minority groups. Although this problem has been studied before, existing\nmethods mainly aim to detect and control the dependency effect of the protected\nvariables (e.g. race, gender) on target prediction based on a large amount of\ntraining data. These approaches carry two major drawbacks that (1) lacking\nshowing a global cause-effect visualization for all variables; (2) lacking\ngeneralization of both accuracy and fairness to unseen tasks. In this work, we\nfirst discover discrimination from data using a causal Bayesian knowledge graph\nwhich not only demonstrates the dependency of the protected variable on target\nbut also indicates causal effects between all variables. Next, we develop a\nnovel algorithm based on risk difference in order to quantify the\ndiscriminatory influence for each protected variable in the graph. Furthermore,\nto protect prediction from unfairness, a fast-adapted bias-control approach in\nmeta-learning is proposed, which efficiently mitigates statistical disparity\nfor each task and it thus ensures independence of protected attributes on\npredictions based on biased and few-shot data samples. Distinct from existing\nmeta-learning models, group unfairness of tasks are efficiently reduced by\nleveraging the mean difference between (un)protected groups for regression\nproblems. Through extensive experiments on both synthetic and real-world data\nsets, we demonstrate that our proposed unfairness discovery and prevention\napproaches efficiently detect discrimination and mitigate biases on model\noutput as well as generalize both accuracy and fairness to unseen tasks with a\nlimited amount of training samples.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:34:06 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Chen", ""], ["Chen", "Feng", ""]]}, {"id": "2009.11407", "submitter": "Alexander Rodr\\'iguez", "authors": "Alexander Rodr\\'iguez, Nikhil Muralidhar, Bijaya Adhikari, Anika\n  Tabassum, Naren Ramakrishnan, B. Aditya Prakash", "title": "Steering a Historical Disease Forecasting Model Under a Pandemic: Case\n  of Flu and COVID-19", "comments": "Appears in AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting influenza in a timely manner aids health organizations and\npolicymakers in adequate preparation and decision making. However, effective\ninfluenza forecasting still remains a challenge despite increasing research\ninterest. It is even more challenging amidst the COVID pandemic, when the\ninfluenza-like illness (ILI) counts are affected by various factors such as\nsymptomatic similarities with COVID-19 and shift in healthcare seeking patterns\nof the general population. Under the current pandemic, historical influenza\nmodels carry valuable expertise about the disease dynamics but face\ndifficulties adapting. Therefore, we propose CALI-Net, a neural transfer\nlearning architecture which allows us to 'steer' a historical disease\nforecasting model to new scenarios where flu and COVID co-exist. Our framework\nenables this adaptation by automatically learning when it should emphasize\nlearning from COVID-related signals and when it should learn from the\nhistorical model. Thus, we exploit representations learned from historical ILI\ndata as well as the limited COVID-related signals. Our experiments demonstrate\nthat our approach is successful in adapting a historical forecasting model to\nthe current pandemic. In addition, we show that success in our primary goal,\nadaptation, does not sacrifice overall performance as compared with\nstate-of-the-art influenza forecasting approaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:35:43 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 04:08:35 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Rodr\u00edguez", "Alexander", ""], ["Muralidhar", "Nikhil", ""], ["Adhikari", "Bijaya", ""], ["Tabassum", "Anika", ""], ["Ramakrishnan", "Naren", ""], ["Prakash", "B. Aditya", ""]]}, {"id": "2009.11416", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Sandesh Ghimire, Linwei Wang", "title": "Enhancing Mixup-based Semi-Supervised Learning with Explicit Lipschitz\n  Regularization", "comments": "A shorter version of this work will appear in the ICDM 2020\n  conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of deep learning relies on the availability of large-scale\nannotated data sets, the acquisition of which can be costly, requiring expert\ndomain knowledge. Semi-supervised learning (SSL) mitigates this challenge by\nexploiting the behavior of the neural function on large unlabeled data. The\nsmoothness of the neural function is a commonly used assumption exploited in\nSSL. A successful example is the adoption of mixup strategy in SSL that\nenforces the global smoothness of the neural function by encouraging it to\nbehave linearly when interpolating between training examples. Despite its\nempirical success, however, the theoretical underpinning of how mixup\nregularizes the neural function has not been fully understood. In this paper,\nwe offer a theoretically substantiated proposition that mixup improves the\nsmoothness of the neural function by bounding the Lipschitz constant of the\ngradient function of the neural networks. We then propose that this can be\nstrengthened by simultaneously constraining the Lipschitz constant of the\nneural function itself through adversarial Lipschitz regularization,\nencouraging the neural function to behave linearly while also constraining the\nslope of this linear function. On three benchmark data sets and one real-world\nbiomedical data set, we demonstrate that this combined regularization results\nin improved generalization performance of SSL when learning from a small amount\nof labeled data. We further demonstrate the robustness of the presented method\nagainst single-step adversarial attacks. Our code is available at\nhttps://github.com/Prasanna1991/Mixup-LR.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 23:19:19 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Ghimire", "Sandesh", ""], ["Wang", "Linwei", ""]]}, {"id": "2009.11433", "submitter": "Sayali Kulkarni", "authors": "Sayali Kulkarni, Tomer Gadot, Chen Luo, Tanya Birch, Eric Fegraus", "title": "Unifying data for fine-grained visual species classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wildlife monitoring is crucial to nature conservation and has been done by\nmanual observations from motion-triggered camera traps deployed in the field.\nWidespread adoption of such in-situ sensors has resulted in unprecedented data\nvolumes being collected over the last decade. A significant challenge exists to\nprocess and reliably identify what is in these images efficiently. Advances in\ncomputer vision are poised to provide effective solutions with custom AI models\nbuilt to automatically identify images of interest and label the species in\nthem. Here we outline the data unification effort for the Wildlife Insights\nplatform from various conservation partners, and the challenges involved. Then\nwe present an initial deep convolutional neural network model, trained on 2.9M\nimages across 465 fine-grained species, with a goal to reduce the load on human\nexperts to classify species in images manually. The long-term goal is to enable\nscientists to make conservation recommendations from near real-time analysis of\nspecies abundance and population health.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:04:18 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kulkarni", "Sayali", ""], ["Gadot", "Tomer", ""], ["Luo", "Chen", ""], ["Birch", "Tanya", ""], ["Fegraus", "Eric", ""]]}, {"id": "2009.11436", "submitter": "Daiki Takeuchi", "authors": "Daiki Takeuchi, Yuma Koizumi, Yasunori Ohishi, Noboru Harada, Kunio\n  Kashino", "title": "Effects of Word-frequency based Pre- and Post- Processings for Audio\n  Captioning", "comments": "Accepted to DCASE2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The system we used for Task 6 (Automated Audio Captioning)of the Detection\nand Classification of Acoustic Scenes and Events(DCASE) 2020 Challenge combines\nthree elements, namely, dataaugmentation, multi-task learning, and\npost-processing, for audiocaptioning. The system received the highest\nevaluation scores, butwhich of the individual elements most fully contributed\nto its perfor-mance has not yet been clarified. Here, to asses their\ncontributions,we first conducted an element-wise ablation study on our systemto\nestimate to what extent each element is effective. We then con-ducted a\ndetailed module-wise ablation study to further clarify thekey processing\nmodules for improving accuracy. The results showthat data augmentation and\npost-processing significantly improvethe score in our system. In particular,\nmix-up data augmentationand beam search in post-processing improve SPIDEr by\n0.8 and 1.6points, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:07:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Takeuchi", "Daiki", ""], ["Koizumi", "Yuma", ""], ["Ohishi", "Yasunori", ""], ["Harada", "Noboru", ""], ["Kashino", "Kunio", ""]]}, {"id": "2009.11443", "submitter": "Thai Hung Le", "authors": "Hung Le and Svetha Venkatesh", "title": "Neurocoder: Learning General-Purpose Computation Using Stored Neural\n  Programs", "comments": "22 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks are uniquely adroit at machine learning by\nprocessing data through a network of artificial neurons. The inter-neuronal\nconnection weights represent the learnt Neural Program that instructs the\nnetwork on how to compute the data. However, without an external memory to\nstore Neural Programs, they are restricted to only one, overwriting learnt\nprograms when trained on new data. This is functionally equivalent to a\nspecial-purpose computer. Here we design Neurocoder, an entirely new class of\ngeneral-purpose conditional computational machines in which the neural network\n\"codes\" itself in a data-responsive way by composing relevant programs from a\nset of shareable, modular programs. This can be considered analogous to\nbuilding Lego structures from simple Lego bricks. Notably, our bricks change\ntheir shape through learning. External memory is used to create, store and\nretrieve modular programs. Like today's stored-program computers, Neurocoder\ncan now access diverse programs to process different data. Unlike manually\ncrafted computer programs, Neurocoder creates programs through training.\nIntegrating Neurocoder into current neural architectures, we demonstrate new\ncapacity to learn modular programs, handle severe pattern shifts and remember\nold programs as new ones are learnt, and show substantial performance\nimprovement in solving object recognition, playing video games and continual\nlearning tasks. Such integration with Neurocoder increases the computation\ncapability of any current neural network and endows it with entirely new\ncapacity to reuse simple programs to build complex ones. For the first time a\nNeural Program is treated as a datum in memory, paving the ways for modular,\nrecursive and procedural neural programming.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:39:16 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Le", "Hung", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2009.11459", "submitter": "Nils Jansen", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Ahmadreza Marandi,\n  Marnix Suilen, Ufuk Topcu", "title": "Robust Finite-State Controllers for Uncertain POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertain partially observable Markov decision processes (uPOMDPs) allow the\nprobabilistic transition and observation functions of standard POMDPs to belong\nto a so-called uncertainty set. Such uncertainty, referred to as epistemic\nuncertainty, captures uncountable sets of probability distributions caused by,\nfor instance, a lack of data available. We develop an algorithm to compute\nfinite-memory policies for uPOMDPs that robustly satisfy specifications against\nany admissible distribution. In general, computing such policies is\ntheoretically and practically intractable. We provide an efficient solution to\nthis problem in four steps. (1) We state the underlying problem as a nonconvex\noptimization problem with infinitely many constraints. (2) A dedicated\ndualization scheme yields a dual problem that is still nonconvex but has\nfinitely many constraints. (3) We linearize this dual problem and (4) solve the\nresulting finite linear program to obtain locally optimal solutions to the\noriginal problem. The resulting problem formulation is exponentially smaller\nthan those resulting from existing methods. We demonstrate the applicability of\nour algorithm using large instances of an aircraft collision-avoidance scenario\nand a novel spacecraft motion planning case study.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 02:58:50 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 21:00:38 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Marandi", "Ahmadreza", ""], ["Suilen", "Marnix", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2009.11468", "submitter": "Wenliang Liu", "authors": "Wenliang Liu, Noushin Mehdipour, Calin Belta", "title": "Recurrent Neural Network Controllers for Signal Temporal Logic\n  Specifications Subject to Safety Constraints", "comments": "7 pages, 4 figures, submitted to IEEE Control Systems Letters (L-CSS)\n  with the option to present it to the ACC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework based on Recurrent Neural Networks (RNNs) to determine\nan optimal control strategy for a discrete-time system that is required to\nsatisfy specifications given as Signal Temporal Logic (STL) formulae. RNNs can\nstore information of a system over time, thus, enable us to determine\nsatisfaction of the dynamic temporal requirements specified in STL formulae.\nGiven a STL formula, a dataset of satisfying system executions and\ncorresponding control policies, we can use RNNs to predict a control policy at\neach time based on the current and previous states of system. We use Control\nBarrier Functions (CBFs) to guarantee the safety of the predicted control\npolicy. We validate our theoretical formulation and demonstrate its performance\nin an optimal control problem subject to partially unknown safety constraints\nthrough simulations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:34:02 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Liu", "Wenliang", ""], ["Mehdipour", "Noushin", ""], ["Belta", "Calin", ""]]}, {"id": "2009.11469", "submitter": "Hongwei Zhang", "authors": "Hongwei Zhang, Tijin Yan, Zenjun Xie, Yuanqing Xia, Yuan Zhang", "title": "Revisiting Graph Convolutional Network on Semi-Supervised Node\n  Classification from an Optimization Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have achieved promising performance on\nvarious graph-based tasks. However they suffer from over-smoothing when\nstacking more layers. In this paper, we present a quantitative study on this\nobservation and develop novel insights towards the deeper GCN. First, we\ninterpret the current graph convolutional operations from an optimization\nperspective and argue that over-smoothing is mainly caused by the naive\nfirst-order approximation of the solution to the optimization problem.\nSubsequently, we introduce two metrics to measure the over-smoothing on\nnode-level tasks. Specifically, we calculate the fraction of the pairwise\ndistance between connected and disconnected nodes to the overall distance\nrespectively. Based on our theoretical and empirical analysis, we establish a\nuniversal theoretical framework of GCN from an optimization perspective and\nderive a novel convolutional kernel named GCN+ which has lower parameter amount\nwhile relieving the over-smoothing inherently. Extensive experiments on\nreal-world datasets demonstrate the superior performance of GCN+ over\nstate-of-the-art baseline methods on the node classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:36:43 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 02:00:16 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Hongwei", ""], ["Yan", "Tijin", ""], ["Xie", "Zenjun", ""], ["Xia", "Yuanqing", ""], ["Zhang", "Yuan", ""]]}, {"id": "2009.11479", "submitter": "Yasushi Esaki", "authors": "Yasushi Esaki and Yuta Nakahara and Toshiyasu Matsushima", "title": "Theoretical Analysis of the Advantage of Deepening Neural Networks", "comments": "9 pages, 7 figures; accepted in 19th IEEE International Conference on\n  Machine Learning and Applications (IEEE ICMLA 2020)", "journal-ref": "2020 19th IEEE International Conference on Machine Learning and\n  Applications (ICMLA), pages 479-484", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two new criteria to understand the advantage of deepening neural\nnetworks. It is important to know the expressivity of functions computable by\ndeep neural networks in order to understand the advantage of deepening neural\nnetworks. Unless deep neural networks have enough expressivity, they cannot\nhave good performance even though learning is successful. In this situation,\nthe proposed criteria contribute to understanding the advantage of deepening\nneural networks since they can evaluate the expressivity independently from the\nefficiency of learning. The first criterion shows the approximation accuracy of\ndeep neural networks to the target function. This criterion has the background\nthat the goal of deep learning is approximating the target function by deep\nneural networks. The second criterion shows the property of linear regions of\nfunctions computable by deep neural networks. This criterion has the background\nthat deep neural networks whose activation functions are piecewise linear are\nalso piecewise linear. Furthermore, by the two criteria, we show that to\nincrease layers is more effective than to increase units at each layer on\nimproving the expressivity of deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:10:50 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Esaki", "Yasushi", ""], ["Nakahara", "Yuta", ""], ["Matsushima", "Toshiyasu", ""]]}, {"id": "2009.11491", "submitter": "Anoop Krishnan Upendran Nair", "authors": "Anoop Krishnan, Ali Almadan, Ajita Rattani", "title": "Understanding Fairness of Gender Classification Algorithms Across\n  Gender-Race Groups", "comments": "19th IEEE International Conference On Machine Learning And\n  Applications 2020 | Miami, Florida", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated gender classification has important applications in many domains,\nsuch as demographic research, law enforcement, online advertising, as well as\nhuman-computer interaction. Recent research has questioned the fairness of this\ntechnology across gender and race. Specifically, the majority of the studies\nraised the concern of higher error rates of the face-based gender\nclassification system for darker-skinned people like African-American and for\nwomen. However, to date, the majority of existing studies were limited to\nAfrican-American and Caucasian only. The aim of this paper is to investigate\nthe differential performance of the gender classification algorithms across\ngender-race groups. To this aim, we investigate the impact of (a) architectural\ndifferences in the deep learning algorithms and (b) training set imbalance, as\na potential source of bias causing differential performance across gender and\nrace. Experimental investigations are conducted on two latest large-scale\npublicly available facial attribute datasets, namely, UTKFace and FairFace. The\nexperimental results suggested that the algorithms with architectural\ndifferences varied in performance with consistency towards specific gender-race\ngroups. For instance, for all the algorithms used, Black females (Black race in\ngeneral) always obtained the least accuracy rates. Middle Eastern males and\nLatino females obtained higher accuracy rates most of the time. Training set\nimbalance further widens the gap in the unequal accuracy rates across all\ngender-race groups. Further investigations using facial landmarks suggested\nthat facial morphological differences due to the bone structure influenced by\ngenetic and environmental factors could be the cause of the least performance\nof Black females and Black race, in general.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:56:10 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Krishnan", "Anoop", ""], ["Almadan", "Ali", ""], ["Rattani", "Ajita", ""]]}, {"id": "2009.11500", "submitter": "Jia Zhao", "authors": "Jia Zhao and Jarrod Mau", "title": "Discovery of Governing Equations with Recursive Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model discovery based on existing data has been one of the major focuses of\nmathematical modelers for decades. Despite tremendous achievements of model\nidentification from adequate data, how to unravel the models from limited data\nis less resolved. In this paper, we focus on the model discovery problem when\nthe data is not efficiently sampled in time. This is common due to limited\nexperimental accessibility and labor/resource constraints. Specifically, we\nintroduce a recursive deep neural network (RDNN) for data-driven model\ndiscovery. This recursive approach can retrieve the governing equation in a\nsimple and efficient manner, and it can significantly improve the approximation\naccuracy by increasing the recursive stages. In particular, our proposed\napproach shows superior power when the existing data are sampled with a large\ntime lag, from which the traditional approach might not be able to recover the\nmodel well. Several widely used examples of dynamical systems are used to\nbenchmark this newly proposed recursive approach. Numerical comparisons confirm\nthe effectiveness of this recursive neural network for model discovery.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 05:59:03 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Jia", ""], ["Mau", "Jarrod", ""]]}, {"id": "2009.11501", "submitter": "Ehsan Aghaei", "authors": "Ehsan Aghaei, Waseem Shadid, Ehab Al-Shaer", "title": "ThreatZoom: CVE2CWE using Hierarchical Neural Network", "comments": "This is accepted paper in EAI SecureComm 2020, 16th EAI International\n  Conference on Security and Privacy in Communication Networks", "journal-ref": "EAI SecureComm 2020, 16th EAI International Conference on Security\n  and Privacy in Communication Networks", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Common Vulnerabilities and Exposures (CVE) represent standard means for\nsharing publicly known information security vulnerabilities. One or more CVEs\nare grouped into the Common Weakness Enumeration (CWE) classes for the purpose\nof understanding the software or configuration flaws and potential impacts\nenabled by these vulnerabilities and identifying means to detect or prevent\nexploitation. As the CVE-to-CWE classification is mostly performed manually by\ndomain experts, thousands of critical and new CVEs remain unclassified, yet\nthey are unpatchable. This significantly limits the utility of CVEs and slows\ndown proactive threat mitigation. This paper presents the first automatic tool\nto classify CVEs to CWEs. ThreatZoom uses a novel learning algorithm that\nemploys an adaptive hierarchical neural network which adjusts its weights based\non text analytic scores and classification errors. It automatically estimates\nthe CWE classes corresponding to a CVE instance using both statistical and\nsemantic features extracted from the description of a CVE. This tool is\nrigorously tested by various datasets provided by MITRE and the National\nVulnerability Database (NVD). The accuracy of classifying CVE instances to\ntheir correct CWE classes are 92% (fine-grain) and 94% (coarse-grain) for NVD\ndataset, and 75% (fine-grain) and 90% (coarse-grain) for MITRE dataset, despite\nthe small corpus.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:04:56 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Aghaei", "Ehsan", ""], ["Shadid", "Waseem", ""], ["Al-Shaer", "Ehab", ""]]}, {"id": "2009.11508", "submitter": "Yang Bai", "authors": "Yang Bai and Yuyuan Zeng and Yong Jiang and Yisen Wang and Shu-Tao Xia\n  and Weiwei Guo", "title": "Improving Query Efficiency of Black-box Adversarial Attack", "comments": "Accepted to ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated excellent performance on\nvarious tasks, however they are under the risk of adversarial examples that can\nbe easily generated when the target model is accessible to an attacker\n(white-box setting). As plenty of machine learning models have been deployed\nvia online services that only provide query outputs from inaccessible models\n(e.g. Google Cloud Vision API2), black-box adversarial attacks (inaccessible\ntarget model) are of critical security concerns in practice rather than\nwhite-box ones. However, existing query-based black-box adversarial attacks\noften require excessive model queries to maintain a high attack success rate.\nTherefore, in order to improve query efficiency, we explore the distribution of\nadversarial examples around benign inputs with the help of image structure\ninformation characterized by a Neural Process, and propose a Neural Process\nbased black-box adversarial attack (NP-Attack) in this paper. Extensive\nexperiments show that NP-Attack could greatly decrease the query counts under\nthe black-box setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:22:56 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 07:09:25 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Bai", "Yang", ""], ["Zeng", "Yuyuan", ""], ["Jiang", "Yong", ""], ["Wang", "Yisen", ""], ["Xia", "Shu-Tao", ""], ["Guo", "Weiwei", ""]]}, {"id": "2009.11510", "submitter": "Junshan Wang", "authors": "Junshan Wang, Yilun Jin, Guojie Song, Xiaojun Ma", "title": "EPNE: Evolutionary Pattern Preserving Network Embedding", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information networks are ubiquitous and are ideal for modeling relational\ndata. Networks being sparse and irregular, network embedding algorithms have\ncaught the attention of many researchers, who came up with numerous embeddings\nalgorithms in static networks. Yet in real life, networks constantly evolve\nover time. Hence, evolutionary patterns, namely how nodes develop itself over\ntime, would serve as a powerful complement to static structures in embedding\nnetworks, on which relatively few works focus. In this paper, we propose EPNE,\na temporal network embedding model preserving evolutionary patterns of the\nlocal structure of nodes. In particular, we analyze evolutionary patterns with\nand without periodicity and design strategies correspondingly to model such\npatterns in time-frequency domains based on causal convolutions. In addition,\nwe propose a temporal objective function which is optimized simultaneously with\nproximity ones such that both temporal and structural information are\npreserved. With the adequate modeling of temporal information, our model is\nable to outperform other competitive methods in various prediction tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:31:14 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wang", "Junshan", ""], ["Jin", "Yilun", ""], ["Song", "Guojie", ""], ["Ma", "Xiaojun", ""]]}, {"id": "2009.11522", "submitter": "Mohamed-Amine Lahmeri", "authors": "Mohamed-Amine Lahmeri, Mustafa A.Kishk, and Mohamed-Slim Alouini", "title": "Artificial Intelligence for UAV-enabled Wireless Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are considered as one of the promising\ntechnologies for the next-generation wireless communication networks. Their\nmobility and their ability to establish line of sight (LOS) links with the\nusers made them key solutions for many potential applications. In the same\nvein, artificial intelligence (AI) is growing rapidly nowadays and has been\nvery successful, particularly due to the massive amount of the available data.\nAs a result, a significant part of the research community has started to\nintegrate intelligence at the core of UAVs networks by applying AI algorithms\nin solving several problems in relation to drones. In this article, we provide\na comprehensive overview of some potential applications of AI in UAV-based\nnetworks. We also highlight the limits of the existing works and outline some\npotential future applications of AI for UAV networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 07:11:31 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 12:39:29 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lahmeri", "Mohamed-Amine", ""], ["Kishk", "Mustafa A.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2009.11554", "submitter": "Thanh-An Pham Mr.", "authors": "Fangshu Yang, Thanh-an Pham, Nathalie Brandenberg, Matthias P. Lutolf,\n  Jianwei Ma and Michael Unser", "title": "Robust Phase Unwrapping via Deep Image Prior for Quantitative Phase\n  Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative phase imaging (QPI) is an emerging label-free technique that\nproduces images containing morphological and dynamical information without\ncontrast agents. Unfortunately, the phase is wrapped in most imaging system.\nPhase unwrapping is the computational process that recovers a more informative\nimage. It is particularly challenging with thick and complex samples such as\norganoids. Recent works that rely on supervised training show that deep\nlearning is a powerful method to unwrap the phase; however, supervised\napproaches require large and representative datasets which are difficult to\nobtain for complex biological samples. Inspired by the concept of deep image\npriors, we propose a deep-learning-based method that does not need any training\nset. Our framework relies on an untrained convolutional neural network to\naccurately unwrap the phase while ensuring the consistency of the measurements.\nWe experimentally demonstrate that the proposed method faithfully recovers the\nphase of complex samples on both real and simulated data. Our work paves the\nway to reliable phase imaging of thick and complex samples with QPI.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 08:56:10 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Yang", "Fangshu", ""], ["Pham", "Thanh-an", ""], ["Brandenberg", "Nathalie", ""], ["Lutolf", "Matthias P.", ""], ["Ma", "Jianwei", ""], ["Unser", "Michael", ""]]}, {"id": "2009.11577", "submitter": "Lea Berthomier", "authors": "L\\'ea Berthomier, Bruno Pradel and Lior Perez", "title": "Cloud Cover Nowcasting with Deep Learning", "comments": "6 pages, 11 figures", "journal-ref": "Proceedings of the 2020 Tenth International Conference on Image\n  Processing Theory, Tools and Applications (IPTA), IEEE, Paris, France, 9-12\n  November 2020", "doi": "10.1109/IPTA50016.2020.9286606", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowcasting is a field of meteorology which aims at forecasting weather on a\nshort term of up to a few hours. In the meteorology landscape, this field is\nrather specific as it requires particular techniques, such as data\nextrapolation, where conventional meteorology is generally based on physical\nmodeling. In this paper, we focus on cloud cover nowcasting, which has various\napplication areas such as satellite shots optimisation and photovoltaic energy\nproduction forecast.\n  Following recent deep learning successes on multiple imagery tasks, we\napplied deep convolutionnal neural networks on Meteosat satellite images for\ncloud cover nowcasting. We present the results of several architectures\nspecialized in image segmentation and time series prediction. We selected the\nbest models according to machine learning metrics as well as meteorological\nmetrics. All selected architectures showed significant improvements over\npersistence and the well-known U-Net surpasses AROME physical model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 09:57:29 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 07:23:35 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 11:57:43 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Berthomier", "L\u00e9a", ""], ["Pradel", "Bruno", ""], ["Perez", "Lior", ""]]}, {"id": "2009.11587", "submitter": "Lukman Hakim", "authors": "Shah B. Shrey, Lukman Hakim, Muthusubash Kavitha, Hae Won Kim, Takio\n  Kurita", "title": "Transfer Learning by Cascaded Network to identify and classify lung\n  nodules for cancer detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is one of the most deadly diseases in the world. Detecting such\ntumors at an early stage can be a tedious task. Existing deep learning\narchitecture for lung nodule identification used complex architecture with\nlarge number of parameters. This study developed a cascaded architecture which\ncan accurately segment and classify the benign or malignant lung nodules on\ncomputed tomography (CT) images. The main contribution of this study is to\nintroduce a segmentation network where the first stage trained on a public data\nset can help to recognize the images which included a nodule from any data set\nby means of transfer learning. And the segmentation of a nodule improves the\nsecond stage to classify the nodules into benign and malignant. The proposed\narchitecture outperformed the conventional methods with an area under curve\nvalue of 95.67\\%. The experimental results showed that the classification\naccuracy of 97.96\\% of our proposed architecture outperformed other simple and\ncomplex architectures in classifying lung nodules for lung cancer detection.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 10:35:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Shrey", "Shah B.", ""], ["Hakim", "Lukman", ""], ["Kavitha", "Muthusubash", ""], ["Kim", "Hae Won", ""], ["Kurita", "Takio", ""]]}, {"id": "2009.11598", "submitter": "Jihed Khiari", "authors": "Jihed Khiari and Cristina Olaverri-Monreal", "title": "Boosting Algorithms for Delivery Time Prediction in Transportation\n  Logistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time is a crucial measure in transportation. Accurate travel time\nprediction is also fundamental for operation and advanced information systems.\nA variety of solutions exist for short-term travel time predictions such as\nsolutions that utilize real-time GPS data and optimization methods to track the\npath of a vehicle. However, reliable long-term predictions remain challenging.\nWe show in this paper the applicability and usefulness of travel time i.e.\ndelivery time prediction for postal services. We investigate several methods\nsuch as linear regression models and tree based ensembles such as random\nforest, bagging, and boosting, that allow to predict delivery time by\nconducting extensive experiments and considering many usability scenarios.\nResults reveal that travel time prediction can help mitigate high delays in\npostal services. We show that some boosting algorithms, such as light gradient\nboosting and catboost, have a higher performance in terms of accuracy and\nruntime efficiency than other baselines such as linear regression models,\nbagging regressor and random forest.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 11:01:22 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Khiari", "Jihed", ""], ["Olaverri-Monreal", "Cristina", ""]]}, {"id": "2009.11612", "submitter": "Haitao Lin", "authors": "Zhangyang Gao, Haitao Lin, Stan. Z Li", "title": "Clustering Based on Graph of Density Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data clustering with uneven distribution in high level noise is challenging.\nCurrently, HDBSCAN is considered as the SOTA algorithm for this problem. In\nthis paper, we propose a novel clustering algorithm based on what we call graph\nof density topology (GDT). GDT jointly considers the local and global\nstructures of data samples: firstly forming local clusters based on a density\ngrowing process with a strategy for properly noise handling as well as cluster\nboundary detection; and then estimating a GDT from relationship between local\nclusters in terms of a connectivity measure, givingglobal topological graph.\nThe connectivity, measuring similarity between neighboring local clusters, is\nbased on local clusters rather than individual points, ensuring its robustness\nto even very large noise. Evaluation results on both toy and real-world\ndatasets show that GDT achieves the SOTA performance by far on almost all the\npopular datasets, and has a low time complexity of O(nlogn). The code is\navailable at https://github.com/gaozhangyang/DGC.git.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 11:40:24 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gao", "Zhangyang", ""], ["Lin", "Haitao", ""], ["Li", "Stan. Z", ""]]}, {"id": "2009.11676", "submitter": "Benedikt Hosp", "authors": "Benedikt Hosp, Florian Schultz, Oliver H\\\"oner, Enkelejda Kasneci", "title": "Eye Movement Feature Classification for Soccer Goalkeeper Expertise\n  Identification in Virtual Reality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest research in expertise assessment of soccer players has affirmed\nthe importance of perceptual skills (especially for decision making) by\nfocusing either on high experimental control or on a realistic presentation. To\nassess the perceptual skills of athletes in an optimized manner, we captured\nomnidirectional in-field scenes and showed these to 12 expert, 10 intermediate\nand 13 novice soccer goalkeepers on virtual reality glasses. All scenes were\nshown from the same natural goalkeeper perspective and ended after the return\npass to the goalkeeper. Based on their gaze behavior we classified their\nexpertise with common machine learning techniques. This pilot study shows\npromising results for objective classification of goalkeepers expertise based\non their gaze behaviour and provided valuable insight to inform the design of\ntraining systems to enhance perceptual skills of athletes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:18:41 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 17:22:41 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Hosp", "Benedikt", ""], ["Schultz", "Florian", ""], ["H\u00f6ner", "Oliver", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2009.11677", "submitter": "Gavin Leech", "authors": "Dylan Holden-Sim and Gavin Leech and Laurence Aitchison", "title": "Legally grounded fairness objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has identified a number of formally incompatible operational\nmeasures for the unfairness of a machine learning (ML) system. As these\nmeasures all capture intuitively desirable aspects of a fair system, choosing\n\"the one true\" measure is not possible, and instead a reasonable approach is to\nminimize a weighted combination of measures. However, this simply raises the\nquestion of how to choose the weights. Here, we formulate Legally Grounded\nFairness Objectives (LGFO), which uses signals from the legal system to\nnon-arbitrarily measure the social cost of a specific degree of unfairness. The\nLGFO is the expected damages under a putative lawsuit that might be awarded to\nthose who were wrongly classified, in the sense that the ML system made a\ndecision different to that which would have be made under the court's preferred\nmeasure. Notably, the two quantities necessary to compute the LGFO, the court's\npreferences about fairness measures, and the expected damages, are unknown but\nwell-defined, and can be estimated by legal advice. Further, as the damages\nawarded by the legal system are designed to measure and compensate for the harm\ncaused to an individual by an unfair classification, the LGFO aligns closely\nwith society's estimate of the social cost.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:30:03 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Holden-Sim", "Dylan", ""], ["Leech", "Gavin", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2009.11680", "submitter": "Bin Zhang", "authors": "Bin Zhang, Cen Chen, Li Wang", "title": "Privacy-preserving Transfer Learning via Secure Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of machine learning algorithms often relies on a large amount of\nhigh-quality data to train well-performed models. However, data is a valuable\nresource and are always held by different parties in reality. An effective\nsolution to such a data isolation problem is to employ federated learning,\nwhich allows multiple parties to collaboratively train a model. In this paper,\nwe propose a Secure version of the widely used Maximum Mean Discrepancy (SMMD)\nbased on homomorphic encryption to enable effective knowledge transfer under\nthe data federation setting without compromising the data privacy. The proposed\nSMMD is able to avoid the potential information leakage in transfer learning\nwhen aligning the source and target data distribution. As a result, both the\nsource domain and target domain can fully utilize their data to build more\nscalable models. Experimental results demonstrate that our proposed SMMD is\nsecure and effective.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:34:32 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 03:22:15 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Bin", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""]]}, {"id": "2009.11693", "submitter": "Kristian Gundersen", "authors": "Kristian Gundersen, Seyyed A. Hosseini, Anna Oleynik, Guttorm Alendal", "title": "A Variational Auto-Encoder for Reservoir Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carbon dioxide Capture and Storage (CCS) is an important strategy in\nmitigating anthropogenic CO$_2$ emissions. In order for CCS to be successful,\nlarge quantities of CO$_2$ must be stored and the storage site conformance must\nbe monitored. Here we present a deep learning method to reconstruct pressure\nfields and classify the flux out of the storage formation based on the pressure\ndata from Above Zone Monitoring Interval (AZMI) wells. The deep learning method\nis a version of a semi conditional variational auto-encoder tailored to solve\ntwo tasks: reconstruction of an incremental pressure field and leakage rate\nclassification. The method, predictions and associated uncertainty estimates\nare illustrated on the synthetic data from a high-fidelity heterogeneous 2D\nnumerical reservoir model, which was used to simulate subsurface CO$_2$\nmovement and pressure changes in the AZMI due to a CO$_2$ leakage.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:33:09 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 10:13:04 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gundersen", "Kristian", ""], ["Hosseini", "Seyyed A.", ""], ["Oleynik", "Anna", ""], ["Alendal", "Guttorm", ""]]}, {"id": "2009.11697", "submitter": "Nathan Zhao", "authors": "Nathan Zhao, Beicheng Lou", "title": "Compressed imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analogy to compressed sensing, which allows sample-efficient signal\nreconstruction given prior knowledge of its sparsity in frequency domain, we\npropose to utilize policy simplicity (Occam's Razor) as a prior to enable\nsample-efficient imitation learning. We first demonstrated the feasibility of\nthis scheme on linear case where state-value function can be sampled directly.\nWe also extended the scheme to scenarios where only actions are visible and\nscenarios where the policy is obtained from nonlinear network. The method is\nbenchmarked against behavior cloning and results in significantly higher scores\nwith limited expert demonstrations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:50:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Nathan", ""], ["Lou", "Beicheng", ""]]}, {"id": "2009.11698", "submitter": "Vaishak Belle", "authors": "Vaishak Belle and Ioannis Papantonis", "title": "Principles and Practice of Explainable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) provides many opportunities to improve private\nand public life. Discovering patterns and structures in large troves of data in\nan automated manner is a core component of data science, and currently drives\napplications in diverse areas such as computational biology, law and finance.\nHowever, such a highly positive impact is coupled with significant challenges:\nhow do we understand the decisions suggested by these systems in order that we\ncan trust them? In this report, we focus specifically on data-driven methods --\nmachine learning (ML) and pattern recognition models in particular -- so as to\nsurvey and distill the results and observations from the literature. The\npurpose of this report can be especially appreciated by noting that ML models\nare increasingly deployed in a wide range of businesses. However, with the\nincreasing prevalence and complexity of methods, business stakeholders in the\nvery least have a growing number of concerns about the drawbacks of models,\ndata-specific biases, and so on. Analogously, data science practitioners are\noften not aware about approaches emerging from the academic literature, or may\nstruggle to appreciate the differences between different methods, so end up\nusing industry standards such as SHAP. Here, we have undertaken a survey to\nhelp industry practitioners (but also data scientists more broadly) understand\nthe field of explainable machine learning better and apply the right tools. Our\nlatter sections build a narrative around a putative data scientist, and discuss\nhow she might go about explaining her models by asking the right questions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:50:27 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Belle", "Vaishak", ""], ["Papantonis", "Ioannis", ""]]}, {"id": "2009.11705", "submitter": "Chao Yang", "authors": "Chao Yang, Mingxing Jiang, Zhongwen Guo and Yuan Liu", "title": "Gated Res2Net for Multivariate Time Series Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multivariate time series analysis is an important problem in data mining\nbecause of its widespread applications. With the increase of time series data\navailable for training, implementing deep neural networks in the field of time\nseries analysis is becoming common. Res2Net, a recently proposed backbone, can\nfurther improve the state-of-the-art networks as it improves the multi-scale\nrepresentation ability through connecting different groups of filters. However,\nRes2Net ignores the correlations of the feature maps and lacks the control on\nthe information interaction process. To address that problem, in this paper, we\npropose a backbone convolutional neural network based on the thought of gated\nmechanism and Res2Net, namely Gated Res2Net (GRes2Net), for multivariate time\nseries analysis. The hierarchical residual-like connections are influenced by\ngates whose values are calculated based on the original feature maps, the\nprevious output feature maps and the next input feature maps thus considering\nthe correlations between the feature maps more effectively. Through the\nutilization of gated mechanism, the network can control the process of\ninformation sending hence can better capture and utilize the both the temporal\ninformation and the correlations between the feature maps. We evaluate the\nGRes2Net on four multivariate time series datasets including two classification\ndatasets and two forecasting datasets. The results demonstrate that GRes2Net\nhave better performances over the state-of-the-art methods thus indicating the\nsuperiority\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 01:45:41 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Yang", "Chao", ""], ["Jiang", "Mingxing", ""], ["Guo", "Zhongwen", ""], ["Liu", "Yuan", ""]]}, {"id": "2009.11710", "submitter": "Benedikt Pf\\\"ulb", "authors": "Alexander Gepperth, Benedikt Pf\\\"ulb", "title": "A Rigorous Link Between Self-Organizing Maps and Gaussian Mixture Models", "comments": "10 pages, 2 figures, submitted and accepted at International\n  Conference on Artificial Neural Networks (ICANN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a mathematical treatment of the relation between\nSelf-Organizing Maps (SOMs) and Gaussian Mixture Models (GMMs). We show that\nenergy-based SOM models can be interpreted as performing gradient descent,\nminimizing an approximation to the GMM log-likelihood that is particularly\nvalid for high data dimensionalities. The SOM-like decrease of the neighborhood\nradius can be understood as an annealing procedure ensuring that gradient\ndescent does not get stuck in undesirable local minima. This link allows to\ntreat SOMs as generative probabilistic models, giving a formal justification\nfor using SOMs, e.g., to detect outliers, or for sampling.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:09:04 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gepperth", "Alexander", ""], ["Pf\u00fclb", "Benedikt", ""]]}, {"id": "2009.11713", "submitter": "Ruiyu Xu", "authors": "Ruiyu Xu, Jianguo Wu, Xiaowei Yue and Yongxiang Li", "title": "Online Structural Change-point Detection of High-dimensional Streaming\n  Data via Dynamic Sparse Subspace Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional streaming data are becoming increasingly ubiquitous in many\nfields. They often lie in multiple low-dimensional subspaces, and the manifold\nstructures may change abruptly on the time scale due to pattern shift or\noccurrence of anomalies. However, the problem of detecting the structural\nchanges in a real-time manner has not been well studied. To fill this gap, we\npropose a dynamic sparse subspace learning (DSSL) approach for online\nstructural change-point detection of high-dimensional streaming data. A novel\nmultiple structural change-point model is proposed and it is shown to be\nequivalent to maximizing a posterior under certain conditions. The asymptotic\nproperties of the estimators are investigated. The penalty coefficients in our\nmodel can be selected by AMDL criterion based on some historical data. An\nefficient Pruned Exact Linear Time (PELT) based method is proposed for online\noptimization and change-point detection. The effectiveness of the proposed\nmethod is demonstrated through a simulation study and a real case study using\ngesture data for motion tracking.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:16:18 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 11:45:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Xu", "Ruiyu", ""], ["Wu", "Jianguo", ""], ["Yue", "Xiaowei", ""], ["Li", "Yongxiang", ""]]}, {"id": "2009.11717", "submitter": "John Lagergren", "authors": "John Lagergren, Erica Rutter, Kevin Flores", "title": "Region Growing with Convolutional Neural Networks for Biomedical Image\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a methodology that uses convolutional neural\nnetworks (CNNs) for segmentation by iteratively growing predicted mask regions\nin each coordinate direction. The CNN is used to predict class probability\nscores in a small neighborhood of the center pixel in a tile of an image. We\nuse a threshold on the CNN probability scores to determine whether pixels are\nadded to the region and the iteration continues until no new pixels are added\nto the region. Our method is able to achieve high segmentation accuracy and\npreserve biologically realistic morphological features while leveraging small\namounts of training data and maintaining computational efficiency. Using\nretinal blood vessel images from the DRIVE database we found that our method is\nmore accurate than a fully convolutional semantic segmentation CNN for several\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:53:00 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Lagergren", "John", ""], ["Rutter", "Erica", ""], ["Flores", "Kevin", ""]]}, {"id": "2009.11719", "submitter": "Ming Yan", "authors": "Ming Yan, Xueli Xiao, Joey Tianyi Zhou, Yi Pan", "title": "Deep Neural Networks with Short Circuits for Improved Gradient Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved great success both in computer vision and\nnatural language processing tasks. However, mostly state-of-art methods highly\nrely on external training or computing to improve the performance. To alleviate\nthe external reliance, we proposed a gradient enhancement approach, conducted\nby the short circuit neural connections, to improve the gradient learning of\ndeep neural networks. The proposed short circuit is a unidirectional connection\nthat single back propagates the sensitive from the deep layer to the shallows.\nMoreover, the short circuit formulates to be a gradient truncation of its\ncrossing layers which can plug into the backbone deep neural networks without\nintroducing external training parameters. Extensive experiments demonstrate\ndeep neural networks with our short circuit gain a large margin over the\nbaselines on both computer vision and natural language processing tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:51:37 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Yan", "Ming", ""], ["Xiao", "Xueli", ""], ["Zhou", "Joey Tianyi", ""], ["Pan", "Yi", ""]]}, {"id": "2009.11729", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang", "title": "Interpreting and Boosting Dropout from a Game-Theoretic View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to understand and improve the utility of the dropout\noperation from the perspective of game-theoretic interactions. We prove that\ndropout can suppress the strength of interactions between input variables of\ndeep neural networks (DNNs). The theoretic proof is also verified by various\nexperiments. Furthermore, we find that such interactions were strongly related\nto the over-fitting problem in deep learning. Thus, the utility of dropout can\nbe regarded as decreasing interactions to alleviate the significance of\nover-fitting. Based on this understanding, we propose an interaction loss to\nfurther improve the utility of dropout. Experimental results have shown that\nthe interaction loss can effectively improve the utility of dropout and boost\nthe performance of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:39:42 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 16:45:35 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 10:30:51 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 10:42:04 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhang", "Hao", ""], ["Li", "Sen", ""], ["Ma", "Yinchao", ""], ["Li", "Mingjie", ""], ["Xie", "Yichen", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2009.11732", "submitter": "Lukas Ruff", "authors": "Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr\\'egoire\n  Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, Klaus-Robert\n  M\\\"uller", "title": "A Unifying Review of Deep and Shallow Anomaly Detection", "comments": "40 pages; accepted for publication in the Proceedings of the IEEE;", "journal-ref": "Proceedings of the IEEE (2021) 1-40", "doi": "10.1109/JPROC.2021.3052449", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches to anomaly detection have recently improved the\nstate of the art in detection performance on complex datasets such as large\ncollections of images or text. These results have sparked a renewed interest in\nthe anomaly detection problem and led to the introduction of a great variety of\nnew methods. With the emergence of numerous such methods, including approaches\nbased on generative models, one-class classification, and reconstruction, there\nis a growing need to bring methods of this field into a systematic and unified\nperspective. In this review we aim to identify the common underlying principles\nas well as the assumptions that are often made implicitly by various methods.\nIn particular, we draw connections between classic 'shallow' and novel deep\napproaches and show how this relation might cross-fertilize or extend both\ndirections. We further provide an empirical assessment of major existing\nmethods that is enriched by the use of recent explainability techniques, and\npresent specific worked-through examples together with practical advice.\nFinally, we outline critical open challenges and identify specific paths for\nfuture research in anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:47:54 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 07:46:38 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 12:43:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ruff", "Lukas", ""], ["Kauffmann", "Jacob R.", ""], ["Vandermeulen", "Robert A.", ""], ["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["Kloft", "Marius", ""], ["Dietterich", "Thomas G.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2009.11746", "submitter": "Xianbiao Qi", "authors": "Yihao Chen, Xin Tang, Xianbiao Qi, Chun-Guang Li, Rong Xiao", "title": "Learning Graph Normalization for Graph Neural Networks", "comments": "15 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have attracted considerable attention and have\nemerged as a new promising paradigm to process graph-structured data. GNNs are\nusually stacked to multiple layers and the node representations in each layer\nare computed through propagating and aggregating the neighboring node features\nwith respect to the graph. By stacking to multiple layers, GNNs are able to\ncapture the long-range dependencies among the data on the graph and thus bring\nperformance improvements. To train a GNN with multiple layers effectively, some\nnormalization techniques (e.g., node-wise normalization, batch-wise\nnormalization) are necessary. However, the normalization techniques for GNNs\nare highly task-relevant and different application tasks prefer to different\nnormalization techniques, which is hard to know in advance. To tackle this\ndeficiency, in this paper, we propose to learn graph normalization by\noptimizing a weighted combination of normalization techniques at four different\nlevels, including node-wise normalization, adjacency-wise normalization,\ngraph-wise normalization, and batch-wise normalization, in which the\nadjacency-wise normalization and the graph-wise normalization are newly\nproposed in this paper to take into account the local structure and the global\nstructure on the graph, respectively. By learning the optimal weights, we are\nable to automatically select a single best or a best combination of multiple\nnormalizations for a specific task. We conduct extensive experiments on\nbenchmark datasets for different tasks, including node classification, link\nprediction, graph classification and graph regression, and confirm that the\nlearned graph normalization leads to competitive results and that the learned\nweights suggest the appropriate normalization techniques for the specific task.\nSource code is released here https://github.com/cyh1112/GraphNormalization.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:16:43 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Chen", "Yihao", ""], ["Tang", "Xin", ""], ["Qi", "Xianbiao", ""], ["Li", "Chun-Guang", ""], ["Xiao", "Rong", ""]]}, {"id": "2009.11751", "submitter": "Miguel Araujo", "authors": "Miguel Araujo, Miguel Almeida, Jaime Ferreira, Luis Silva, Pedro\n  Bizarro", "title": "BreachRadar: Automatic Detection of Points-of-Compromise", "comments": "9 pages, 10 figures, published in SIAM's 2017 International\n  Conference on Data Mining (SDM17)", "journal-ref": null, "doi": "10.1137/1.9781611974973.63", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bank transaction fraud results in over $13B annual losses for banks,\nmerchants, and card holders worldwide. Much of this fraud starts with a\nPoint-of-Compromise (a data breach or a skimming operation) where credit and\ndebit card digital information is stolen, resold, and later used to perform\nfraud. We introduce this problem and present an automatic Points-of-Compromise\n(POC) detection procedure. BreachRadar is a distributed alternating algorithm\nthat assigns a probability of being compromised to the different possible\nlocations. We implement this method using Apache Spark and show its linear\nscalability in the number of machines and transactions. BreachRadar is applied\nto two datasets with billions of real transaction records and fraud labels\nwhere we provide multiple examples of real Points-of-Compromise we are able to\ndetect. We further show the effectiveness of our method when injecting\nPoints-of-Compromise in one of these datasets, simultaneously achieving over\n90% precision and recall when only 10% of the cards have been victims of fraud.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:25:14 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Araujo", "Miguel", ""], ["Almeida", "Miguel", ""], ["Ferreira", "Jaime", ""], ["Silva", "Luis", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2009.11762", "submitter": "Chenzhuang Du", "authors": "Chenwei Wu, Chenzhuang Du, Yang Yuan", "title": "Secure Data Sharing With Flow Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical multi-party computation setting, multiple parties jointly\ncompute a function without revealing their own input data. We consider a\nvariant of this problem, where the input data can be shared for machine\nlearning training purposes, but the data are also encrypted so that they cannot\nbe recovered by other parties. We present a rotation based method using flow\nmodel, and theoretically justified its security. We demonstrate the\neffectiveness of our method in different scenarios, including supervised secure\nmodel training, and unsupervised generative model training. Our code is\navailable at https://github.com/ duchenzhuang/flowencrypt.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:40:14 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wu", "Chenwei", ""], ["Du", "Chenzhuang", ""], ["Yuan", "Yang", ""]]}, {"id": "2009.11763", "submitter": "Yunbo Wang", "authors": "Zhiyu Yao, Yunbo Wang, Mingsheng Long, Jianmin Wang", "title": "Unsupervised Transfer Learning for Spatiotemporal Predictive Networks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new research problem of unsupervised transfer learning\nacross multiple spatiotemporal prediction tasks. Unlike most existing transfer\nlearning methods that focus on fixing the discrepancy between supervised tasks,\nwe study how to transfer knowledge from a zoo of unsupervisedly learned models\ntowards another predictive network. Our motivation is that models from\ndifferent sources are expected to understand the complex spatiotemporal\ndynamics from different perspectives, thereby effectively supplementing the new\ntask, even if the task has sufficient training samples. Technically, we propose\na differentiable framework named transferable memory. It adaptively distills\nknowledge from a bank of memory states of multiple pretrained RNNs, and applies\nit to the target network via a novel recurrent structure called the\nTransferable Memory Unit (TMU). Compared with finetuning, our approach yields\nsignificant improvements on three benchmarks for spatiotemporal prediction, and\nbenefits the target task even from less relevant pretext ones.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:40:55 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Yao", "Zhiyu", ""], ["Wang", "Yunbo", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""]]}, {"id": "2009.11782", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha, Magnus Egerstedt, and Saibal Mukhopadhyay", "title": "Neural Identification for Control", "comments": "Copyright 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE Robotics and Automation Letters, vol. 6, no. 3, pp.\n  4648-4655, July 2021", "doi": "10.1109/LRA.2021.3068099", "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for learning control law that stabilizes an unknown\nnonlinear dynamical system at an equilibrium point. We formulate a system\nidentification task in a self-supervised learning setting that jointly learns a\ncontroller and corresponding stable closed-loop dynamics hypothesis. The\ninput-output behavior of the unknown dynamical system under random control\ninputs is used as the supervising signal to train the neural network-based\nsystem model and the controller. The proposed method relies on the Lyapunov\nstability theory to generate a stable closed-loop dynamics hypothesis and\ncorresponding control law. We demonstrate our method on various nonlinear\ncontrol problems such as n-link pendulum balancing and trajectory tracking,\npendulum on cart balancing, and wheeled vehicle path following.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:17:44 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 03:23:22 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 03:40:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Saha", "Priyabrata", ""], ["Egerstedt", "Magnus", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2009.11795", "submitter": "Boon Peng Yap", "authors": "Boon Peng Yap, Andrew Koh and Eng Siong Chng", "title": "Adapting BERT for Word Sense Disambiguation with Gloss Selection\n  Objective and Example Sentences", "comments": "Accepted to appear in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation or transfer learning using pre-trained language models such\nas BERT has proven to be an effective approach for many natural language\nprocessing tasks. In this work, we propose to formulate word sense\ndisambiguation as a relevance ranking task, and fine-tune BERT on sequence-pair\nranking task to select the most probable sense definition given a context\nsentence and a list of candidate sense definitions. We also introduce a data\naugmentation technique for WSD using existing example sentences from WordNet.\nUsing the proposed training objective and data augmentation technique, our\nmodels are able to achieve state-of-the-art results on the English all-words\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:37:04 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 06:06:39 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Yap", "Boon Peng", ""], ["Koh", "Andrew", ""], ["Chng", "Eng Siong", ""]]}, {"id": "2009.11799", "submitter": "Jiwon Seo", "authors": "Sanghyun Kim, Jongmin Park, Jae-Kwan Yun, and Jiwon Seo", "title": "Motion Planning by Reinforcement Learning for an Unmanned Aerial Vehicle\n  in Virtual Open Space with Static Obstacles", "comments": "Submitted to ICCAS 2020", "journal-ref": "2020 20th International Conference on Control, Automation and\n  Systems (ICCAS)", "doi": "10.23919/ICCAS50221.2020.9268253", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we applied reinforcement learning based on the proximal policy\noptimization algorithm to perform motion planning for an unmanned aerial\nvehicle (UAV) in an open space with static obstacles. The application of\nreinforcement learning through a real UAV has several limitations such as time\nand cost; thus, we used the Gazebo simulator to train a virtual quadrotor UAV\nin a virtual environment. As the reinforcement learning progressed, the mean\nreward and goal rate of the model were increased. Furthermore, the test of the\ntrained model shows that the UAV reaches the goal with an 81% goal rate using\nthe simple reward function suggested in this work.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:42:56 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Kim", "Sanghyun", ""], ["Park", "Jongmin", ""], ["Yun", "Jae-Kwan", ""], ["Seo", "Jiwon", ""]]}, {"id": "2009.11811", "submitter": "Bruno Klaus De Aquino Afonso", "authors": "Bruno Klaus de Aquino Afonso, Lilian Berton", "title": "Identifying noisy labels with a transductive semi-supervised\n  leave-one-out filter", "comments": null, "journal-ref": "Pattern Recognition Letters, 2020, ISSN 0167-8655", "doi": "10.1016/j.patrec.2020.09.024", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining data with meaningful labels is often costly and error-prone. In\nthis situation, semi-supervised learning (SSL) approaches are interesting, as\nthey leverage assumptions about the unlabeled data to make up for the limited\namount of labels. However, in real-world situations, we cannot assume that the\nlabeling process is infallible, and the accuracy of many SSL classifiers\ndecreases significantly in the presence of label noise. In this work, we\nintroduce the LGC_LVOF, a leave-one-out filtering approach based on the Local\nand Global Consistency (LGC) algorithm. Our method aims to detect and remove\nwrong labels, and thus can be used as a preprocessing step to any SSL\nclassifier. Given the propagation matrix, detecting noisy labels takes O(cl)\nper step, with c the number of classes and l the number of labels. Moreover,\none does not need to compute the whole propagation matrix, but only an $l$ by\n$l$ submatrix corresponding to interactions between labeled instances. As a\nresult, our approach is best suited to datasets with a large amount of\nunlabeled data but not many labels. Results are provided for a number of\ndatasets, including MNIST and ISOLET. LGCLVOF appears to be equally or more\nprecise than the adapted gradient-based filter. We show that the best-case\naccuracy of the embedding of LGCLVOF into LGC yields performance comparable to\nthe best-case of $\\ell_1$-based classifiers designed to be robust to label\nnoise. We provide a heuristic to choose the number of removed instances.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:50:06 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Afonso", "Bruno Klaus de Aquino", ""], ["Berton", "Lilian", ""]]}, {"id": "2009.11816", "submitter": "Lu Liu", "authors": "Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Attribute Propagation Network for Graph Zero-shot Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of zero-shot learning (ZSL) is to train a model to classify samples\nof classes that were not seen during training. To address this challenging\ntask, most ZSL methods relate unseen test classes to seen(training) classes via\na pre-defined set of attributes that can describe all classes in the same\nsemantic space, so the knowledge learned on the training classes can be adapted\nto unseen classes. In this paper, we aim to optimize the attribute space for\nZSL by training a propagation mechanism to refine the semantic attributes of\neach class based on its neighbors and related classes on a graph of classes. We\nshow that the propagated attributes can produce classifiers for zero-shot\nclasses with significantly improved performance in different ZSL settings. The\ngraph of classes is usually free or very cheap to acquire such as WordNet or\nImageNet classes. When the graph is not provided, given pre-defined semantic\nembeddings of the classes, we can learn a mechanism to generate the graph in an\nend-to-end manner along with the propagation mechanism. However, this\ngraph-aided technique has not been well-explored in the literature. In this\npaper, we introduce the attribute propagation network (APNet), which is\ncomposed of 1) a graph propagation model generating attribute vector for each\nclass and 2) a parameterized nearest neighbor (NN) classifier categorizing an\nimage to the class with the nearest attribute vector to the image's embedding.\nFor better generalization over unseen classes, different from previous methods,\nwe adopt a meta-learning strategy to train the propagation mechanism and the\nsimilarity metric for the NN classifier on multiple sub-graphs, each associated\nwith a classification task over a subset of training classes. In experiments\nwith two zero-shot learning settings and five benchmark datasets, APNet\nachieves either compelling performance or new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:53:40 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2009.11829", "submitter": "Nauman Ahad", "authors": "Nauman Ahad, Mark A. Davenport", "title": "Semi-supervised sequence classification through change point detection", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential sensor data is generated in a wide variety of practical\napplications. A fundamental challenge involves learning effective classifiers\nfor such sequential data. While deep learning has led to impressive performance\ngains in recent years in domains such as speech, this has relied on the\navailability of large datasets of sequences with high-quality labels. In many\napplications, however, the associated class labels are often extremely limited,\nwith precise labelling/segmentation being too expensive to perform at a high\nvolume. However, large amounts of unlabeled data may still be available. In\nthis paper we propose a novel framework for semi-supervised learning in such\ncontexts. In an unsupervised manner, change point detection methods can be used\nto identify points within a sequence corresponding to likely class changes. We\nshow that change points provide examples of similar/dissimilar pairs of\nsequences which, when coupled with labeled, can be used in a semi-supervised\nclassification setting. Leveraging the change points and labeled data, we form\nexamples of similar/dissimilar sequences to train a neural network to learn\nimproved representations for classification. We provide extensive synthetic\nsimulations and show that the learned representations are superior to those\nlearned through an autoencoder and obtain improved results on both simulated\nand real-world human activity recognition datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:23:13 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:50:39 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ahad", "Nauman", ""], ["Davenport", "Mark A.", ""]]}, {"id": "2009.11835", "submitter": "Andre Beckus", "authors": "Andre Beckus and George K. Atia", "title": "Sketch-based community detection in evolving networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an approach for community detection in time-varying networks. At\nits core, this approach maintains a small sketch graph to capture the essential\ncommunity structure found in each snapshot of the full network. We demonstrate\nhow the sketch can be used to explicitly identify six key community events\nwhich typically occur during network evolution: growth, shrinkage, merging,\nsplitting, birth and death. Based on these detection techniques, we formulate a\ncommunity detection algorithm which can process a network concurrently\nexhibiting all processes. One advantage afforded by the sketch-based algorithm\nis the efficient handling of large networks. Whereas detecting events in the\nfull graph may be computationally expensive, the small size of the sketch\nallows changes to be quickly assessed. A second advantage occurs in networks\ncontaining clusters of disproportionate size. The sketch is constructed such\nthat there is equal representation of each cluster, thus reducing the\npossibility that the small clusters are lost in the estimate. We present a new\nstandardized benchmark based on the stochastic block model which models the\naddition and deletion of nodes, as well as the birth and death of communities.\nWhen coupled with existing benchmarks, this new benchmark provides a\ncomprehensive suite of tests encompassing all six community events. We provide\na set of numerical results demonstrating the advantages of our approach both in\nrun time and in the handling of small clusters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:32:57 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Beckus", "Andre", ""], ["Atia", "George K.", ""]]}, {"id": "2009.11839", "submitter": "Ekdeep Singh Lubana", "authors": "Ekdeep Singh Lubana and Robert P. Dick", "title": "A Gradient Flow Framework For Analyzing Network Pruning", "comments": "Accepted at ICLR, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent network pruning methods focus on pruning models early-on in training.\nTo estimate the impact of removing a parameter, these methods use importance\nmeasures that were originally designed to prune trained models. Despite lacking\njustification for their use early-on in training, such measures result in\nsurprisingly low accuracy loss. To better explain this behavior, we develop a\ngeneral framework that uses gradient flow to unify state-of-the-art importance\nmeasures through the norm of model parameters. We use this framework to\ndetermine the relationship between pruning measures and evolution of model\nparameters, establishing several results related to pruning models early-on in\ntraining: (i) magnitude-based pruning removes parameters that contribute least\nto reduction in loss, resulting in models that converge faster than\nmagnitude-agnostic methods; (ii) loss-preservation based pruning preserves\nfirst-order model evolution dynamics and is therefore appropriate for pruning\nminimally trained models; and (iii) gradient-norm based pruning affects\nsecond-order model evolution dynamics, such that increasing gradient norm via\npruning can produce poorly performing models. We validate our claims on several\nVGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100. Code\navailable at https://github.com/EkdeepSLubana/flowandprune.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:37:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 04:51:58 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 03:16:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lubana", "Ekdeep Singh", ""], ["Dick", "Robert P.", ""]]}, {"id": "2009.11848", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Mozhi Zhang, Jingling Li, Simon S. Du, Ken-ichi\n  Kawarabayashi, Stefanie Jegelka", "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how neural networks trained by gradient descent extrapolate, i.e.,\nwhat they learn outside the support of the training distribution. Previous\nworks report mixed empirical results when extrapolating with neural networks:\nwhile feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not\nextrapolate well in certain simple tasks, Graph Neural Networks (GNNs) --\nstructured networks with MLP modules -- have shown some success in more complex\ntasks. Working towards a theoretical explanation, we identify conditions under\nwhich MLPs and GNNs extrapolate well. First, we quantify the observation that\nReLU MLPs quickly converge to linear functions along any direction from the\norigin, which implies that ReLU MLPs do not extrapolate most nonlinear\nfunctions. But, they can provably learn a linear target function when the\ntraining distribution is sufficiently \"diverse\". Second, in connection to\nanalyzing the successes and limitations of GNNs, these results suggest a\nhypothesis for which we provide theoretical and empirical evidence: the success\nof GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or\nedge weights) relies on encoding task-specific non-linearities in the\narchitecture or features. Our theoretical analysis builds on a connection of\nover-parameterized networks to the neural tangent kernel. Empirically, our\ntheory holds across different training settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:48:59 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 03:54:28 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 23:54:16 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2021 19:42:02 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 23:05:49 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Xu", "Keyulu", ""], ["Zhang", "Mozhi", ""], ["Li", "Jingling", ""], ["Du", "Simon S.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2009.11852", "submitter": "Peter Englert", "authors": "Giovanni Sutanto, Isabel M. Rayas Fern\\'andez, Peter Englert, Ragesh\n  K. Ramachandran, Gaurav S. Sukhatme", "title": "Learning Equality Constraints for Motion Planning on Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained robot motion planning is a widely used technique to solve complex\nrobot tasks. We consider the problem of learning representations of constraints\nfrom demonstrations with a deep neural network, which we call Equality\nConstraint Manifold Neural Network (ECoMaNN). The key idea is to learn a\nlevel-set function of the constraint suitable for integration into a\nconstrained sampling-based motion planner. Learning proceeds by aligning\nsubspaces in the network with subspaces of the data. We combine both learned\nconstraints and analytically described constraints into the planner and use a\nprojection-based strategy to find valid points. We evaluate ECoMaNN on its\nrepresentation capabilities of constraint manifolds, the impact of its\nindividual loss terms, and the motions produced when incorporated into a\nplanner.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:54:28 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Sutanto", "Giovanni", ""], ["Fern\u00e1ndez", "Isabel M. Rayas", ""], ["Englert", "Peter", ""], ["Ramachandran", "Ragesh K.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2009.11858", "submitter": "Yazhen Wang", "authors": "Victor Luo and Yazhen Wang", "title": "How Many Factors Influence Minima in SGD?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is often applied to train Deep Neural\nNetworks (DNNs), and research efforts have been devoted to investigate the\nconvergent dynamics of SGD and minima found by SGD. The influencing factors\nidentified in the literature include learning rate, batch size, Hessian, and\ngradient covariance, and stochastic differential equations are used to model\nSGD and establish the relationships among these factors for characterizing\nminima found by SGD. It has been found that the ratio of batch size to learning\nrate is a main factor in highlighting the underlying SGD dynamics; however, the\ninfluence of other important factors such as the Hessian and gradient\ncovariance is not entirely agreed upon. This paper describes the factors and\nrelationships in the recent literature and presents numerical findings on the\nrelationships. In particular, it confirms the four-factor and general\nrelationship results obtained in Wang (2019), while the three-factor and\nassociated relationship results found in Jastrz\\c{e}bski et al. (2018) may not\nhold beyond the considered special case.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:58:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Luo", "Victor", ""], ["Wang", "Yazhen", ""]]}, {"id": "2009.11859", "submitter": "Yue Wang", "authors": "Yue Wang and Alireza Fathi and Jiajun Wu and Thomas Funkhouser and\n  Justin Solomon", "title": "Multi-Frame to Single-Frame: Knowledge Distillation for 3D Object\n  Detection", "comments": "The Workshop on Perception for Autonomous Driving at ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common dilemma in 3D object detection for autonomous driving is that\nhigh-quality, dense point clouds are only available during training, but not\ntesting. We use knowledge distillation to bridge the gap between a model\ntrained on high-quality inputs at training time and another tested on\nlow-quality inputs at inference time. In particular, we design a two-stage\ntraining pipeline for point cloud object detection. First, we train an object\ndetection model on dense point clouds, which are generated from multiple frames\nusing extra information only available at training time. Then, we train the\nmodel's identical counterpart on sparse single-frame point clouds with\nconsistency regularization on features from both models. We show that this\nprocedure improves performance on low-quality data during testing, without\nadditional overhead.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:59:12 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Wang", "Yue", ""], ["Fathi", "Alireza", ""], ["Wu", "Jiajun", ""], ["Funkhouser", "Thomas", ""], ["Solomon", "Justin", ""]]}, {"id": "2009.11892", "submitter": "Xueli Xiao", "authors": "Xueli Xiao, Chunyan Ji, Thosini Bamunu Mudiyanselage, Yi Pan", "title": "PK-GCN: Prior Knowledge Assisted Image Classification using Graph\n  Convolution Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has gained great success in various classification tasks.\nTypically, deep learning models learn underlying features directly from data,\nand no underlying relationship between classes are included. Similarity between\nclasses can influence the performance of classification. In this article, we\npropose a method that incorporates class similarity knowledge into\nconvolutional neural networks models using a graph convolution layer. We\nevaluate our method on two benchmark image datasets: MNIST and CIFAR10, and\nanalyze the results on different data and model sizes. Experimental results\nshow that our model can improve classification accuracy, especially when the\namount of available data is small.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:31:35 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Xiao", "Xueli", ""], ["Ji", "Chunyan", ""], ["Mudiyanselage", "Thosini Bamunu", ""], ["Pan", "Yi", ""]]}, {"id": "2009.11896", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Daiki Kimura, Kartik Talamadupula, Michiaki\n  Tatsubori, Asim Munawar and Ryuki Tachibana", "title": "Bootstrapped Q-learning with Context Relevant Observation Pruning to\n  Generalize in Text-based Games", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Reinforcement Learning (RL) methods for solving Text-Based Games\n(TBGs) often fail to generalize on unseen games, especially in small data\nregimes. To address this issue, we propose Context Relevant Episodic State\nTruncation (CREST) for irrelevant token removal in observation text for\nimproved generalization. Our method first trains a base model using Q-learning,\nwhich typically overfits the training games. The base model's action token\ndistribution is used to perform observation pruning that removes irrelevant\ntokens. A second bootstrapped model is then retrained on the pruned observation\ntext. Our bootstrapped agent shows improved generalization in solving unseen\nTextWorld games, using 10x-20x fewer training games compared to previous\nstate-of-the-art methods despite requiring less number of training episodes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:38:30 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Kimura", "Daiki", ""], ["Talamadupula", "Kartik", ""], ["Tatsubori", "Michiaki", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "2009.11898", "submitter": "Anna Glazkova", "authors": "Anna Glazkova, Yury Egorov, Maksim Glazkov", "title": "A Comparative Study of Feature Types for Age-Based Text Classification", "comments": "Accepted to AIST-2020 (The 9th International Conference on Analysis\n  of Images, Social Networks and Texts)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to automatically determine the age audience of a novel provides\nmany opportunities for the development of information retrieval tools. Firstly,\ndevelopers of book recommendation systems and electronic libraries may be\ninterested in filtering texts by the age of the most likely readers. Further,\nparents may want to select literature for children. Finally, it will be useful\nfor writers and publishers to determine which features influence whether the\ntexts are suitable for children. In this article, we compare the empirical\neffectiveness of various types of linguistic features for the task of age-based\nclassification of fiction texts. For this purpose, we collected a text corpus\nof book previews labeled with one of two categories -- children's or adult. We\nevaluated the following types of features: readability indices, sentiment,\nlexical, grammatical and general features, and publishing attributes. The\nresults obtained show that the features describing the text at the document\nlevel can significantly increase the quality of machine learning models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:41:10 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Glazkova", "Anna", ""], ["Egorov", "Yury", ""], ["Glazkov", "Maksim", ""]]}, {"id": "2009.11905", "submitter": "Muharrem Ugur Yavas", "authors": "M. Ugur Yavas, N. Kemal Ure, Tufan Kumbasar", "title": "A New Approach for Tactical Decision Making in Lane Changing: Sample\n  Efficient Deep Q Learning with a Safety Feedback Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated lane change is one of the most challenging task to be solved of\nhighly automated vehicles due to its safety-critical, uncertain and multi-agent\nnature. This paper presents the novel deployment of the state of art Q learning\nmethod, namely Rainbow DQN, that uses a new safety driven rewarding scheme to\ntackle the issues in an dynamic and uncertain simulation environment. We\npresent various comparative results to show that our novel approach of having\nreward feedback from the safety layer dramatically increases both the agent's\nperformance and sample efficiency. Furthermore, through the novel deployment of\nRainbow DQN, it is shown that more intuition about the agent's actions is\nextracted by examining the distributions of generated Q values of the agents.\nThe proposed algorithm shows superior performance to the baseline algorithm in\nthe challenging scenarios with only 200000 training steps (i.e. equivalent to\n55 hours driving).\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:59:02 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Yavas", "M. Ugur", ""], ["Ure", "N. Kemal", ""], ["Kumbasar", "Tufan", ""]]}, {"id": "2009.11911", "submitter": "Khaza Anuarul Hoque", "authors": "Gautam Raj Mode, Khaza Anuarul Hoque", "title": "Adversarial Examples in Deep Learning for Multivariate Time Series\n  Regression", "comments": "Accepted for publication in the 49th Annual IEEE Applied Imagery\n  Pattern Recognition (AIPR) workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) regression tasks are common in many real-world\ndata mining applications including finance, cybersecurity, energy, healthcare,\nprognostics, and many others. Due to the tremendous success of deep learning\n(DL) algorithms in various domains including image recognition and computer\nvision, researchers started adopting these techniques for solving MTS data\nmining problems, many of which are targeted for safety-critical and\ncost-critical applications. Unfortunately, DL algorithms are known for their\nsusceptibility to adversarial examples which also makes the DL regression\nmodels for MTS forecasting also vulnerable to those attacks. To the best of our\nknowledge, no previous work has explored the vulnerability of DL MTS regression\nmodels to adversarial time series examples, which is an important step,\nspecifically when the forecasting from such models is used in safety-critical\nand cost-critical applications. In this work, we leverage existing adversarial\nattack generation techniques from the image classification domain and craft\nadversarial multivariate time series examples for three state-of-the-art deep\nlearning regression models, specifically Convolutional Neural Network (CNN),\nLong Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). We evaluate our\nstudy using Google stock and household power consumption dataset. The obtained\nresults show that all the evaluated DL regression models are vulnerable to\nadversarial attacks, transferable, and thus can lead to catastrophic\nconsequences in safety-critical and cost-critical domains, such as energy and\nfinance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 19:09:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Mode", "Gautam Raj", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "2009.11921", "submitter": "Hossein Souri", "authors": "Pirazh Khorramshahi, Hossein Souri, Rama Chellappa, and Soheil Feizi", "title": "GANs with Variational Entropy Regularizers: Applications in Mitigating\n  the Mode-Collapse Issue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the success of deep learning, Generative Adversarial Networks\n(GANs) provide a modern approach to learn a probability distribution from\nobserved samples. GANs are often formulated as a zero-sum game between two sets\nof functions; the generator and the discriminator. Although GANs have shown\ngreat potentials in learning complex distributions such as images, they often\nsuffer from the mode collapse issue where the generator fails to capture all\nexisting modes of the input distribution. As a consequence, the diversity of\ngenerated samples is lower than that of the observed ones. To tackle this\nissue, we take an information-theoretic approach and maximize a variational\nlower bound on the entropy of the generated samples to increase their\ndiversity. We call this approach GANs with Variational Entropy Regularizers\n(GAN+VER). Existing remedies for the mode collapse issue in GANs can be easily\ncoupled with our proposed variational entropy regularization. Through extensive\nexperimentation on standard benchmark datasets, we show all the existing\nevaluation metrics highlighting difference of real and generated samples are\nsignificantly improved with GAN+VER.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 19:34:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Khorramshahi", "Pirazh", ""], ["Souri", "Hossein", ""], ["Chellappa", "Rama", ""], ["Feizi", "Soheil", ""]]}, {"id": "2009.11929", "submitter": "Hieu Pham", "authors": "Lawrence Mosley and Hieu Pham and Yogesh Bansal and Eric Hare", "title": "Image-Based Sorghum Head Counting When You Only Look Once", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern trends in digital agriculture have seen a shift towards artificial\nintelligence for crop quality assessment and yield estimation. In this work, we\ndocument how a parameter tuned single-shot object detection algorithm can be\nused to identify and count sorghum head from aerial drone images. Our approach\ninvolves a novel exploratory analysis that identified key structural elements\nof the sorghum images and motivated the selection of parameter-tuned anchor\nboxes that contributed significantly to performance. These insights led to the\ndevelopment of a deep learning model that outperformed the baseline model and\nachieved an out-of-sample mean average precision of 0.95.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 19:50:08 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:01:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mosley", "Lawrence", ""], ["Pham", "Hieu", ""], ["Bansal", "Yogesh", ""], ["Hare", "Eric", ""]]}, {"id": "2009.11931", "submitter": "Sina Akbarian", "authors": "Sina Akbarian, Tania Cawston, Laurent Moreno, Samir Patel, Vanessa\n  Allen, and Elham Dolatabadi", "title": "A Computer Vision Approach to Combat Lyme Disease", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyme disease is an infectious disease transmitted to humans by a bite from an\ninfected Ixodes species (blacklegged ticks). It is one of the fastest growing\nvector-borne illness in North America and is expanding its geographic\nfootprint. Lyme disease treatment is time-sensitive, and can be cured by\nadministering an antibiotic (prophylaxis) to the patient within 72 hours after\na tick bite by the Ixodes species. However, the laboratory-based identification\nof each tick that might carry the bacteria is time-consuming and labour\nintensive and cannot meet the maximum turn-around-time of 72 hours for an\neffective treatment. Early identification of blacklegged ticks using computer\nvision technologies is a potential solution in promptly identifying a tick and\nadministering prophylaxis within a crucial window period. In this work, we\nbuild an automated detection tool that can differentiate blacklegged ticks from\nother ticks species using advanced deep learning and computer vision\napproaches. We demonstrate the classification of tick species using Convolution\nNeural Network (CNN) models, trained end-to-end from tick images directly.\nAdvanced knowledge transfer techniques within teacher-student learning\nframeworks are adopted to improve the performance of classification of tick\nspecies. Our best CNN model achieves 92% accuracy on test set. The tool can be\nintegrated with the geography of exposure to determine the risk of Lyme disease\ninfection and need for prophylaxis treatment.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:00:02 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Akbarian", "Sina", ""], ["Cawston", "Tania", ""], ["Moreno", "Laurent", ""], ["Patel", "Samir", ""], ["Allen", "Vanessa", ""], ["Dolatabadi", "Elham", ""]]}, {"id": "2009.11937", "submitter": "Yidan Qin", "authors": "Yidan Qin, Seyedshams Feyzabadi, Max Allan, Joel W. Burdick, Mahdi\n  Azizian", "title": "daVinciNet: Joint Prediction of Motion and Surgical State in\n  Robot-Assisted Surgery", "comments": "Accepted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique to concurrently and jointly predict the\nfuture trajectories of surgical instruments and the future state(s) of surgical\nsubtasks in robot-assisted surgeries (RAS) using multiple input sources. Such\npredictions are a necessary first step towards shared control and supervised\nautonomy of surgical subtasks. Minute-long surgical subtasks, such as suturing\nor ultrasound scanning, often have distinguishable tool kinematics and visual\nfeatures, and can be described as a series of fine-grained states with\ntransition schematics. We propose daVinciNet - an end-to-end dual-task model\nfor robot motion and surgical state predictions. daVinciNet performs concurrent\nend-effector trajectory and surgical state predictions using features extracted\nfrom multiple data streams, including robot kinematics, endoscopic vision, and\nsystem events. We evaluate our proposed model on an extended Robotic\nIntra-Operative Ultrasound (RIOUS+) imaging dataset collected on a da Vinci Xi\nsurgical system and the JHU-ISI Gesture and Skill Assessment Working Set\n(JIGSAWS). Our model achieves up to 93.85% short-term (0.5s) and 82.11%\nlong-term (2s) state prediction accuracy, as well as 1.07mm short-term and\n5.62mm long-term trajectory prediction error.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:28:06 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Qin", "Yidan", ""], ["Feyzabadi", "Seyedshams", ""], ["Allan", "Max", ""], ["Burdick", "Joel W.", ""], ["Azizian", "Mahdi", ""]]}, {"id": "2009.11942", "submitter": "Kleanthis Malialis", "authors": "Kleanthis Malialis and Christos G. Panayiotou and Marios M. Polycarpou", "title": "Online Learning With Adaptive Rebalancing in Nonstationary Environments", "comments": "Keywords: class imbalance, concept drift, neural networks,\n  nonstationary environments, online learning. in IEEE Transactions on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3017863", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An enormous and ever-growing volume of data is nowadays becoming available in\na sequential fashion in various real-world applications. Learning in\nnonstationary environments constitutes a major challenge, and this problem\nbecomes orders of magnitude more complex in the presence of class imbalance. We\nprovide new insights into learning from nonstationary and imbalanced data in\nonline learning, a largely unexplored area. We propose the novel Adaptive\nREBAlancing (AREBA) algorithm that selectively includes in the training set a\nsubset of the majority and minority examples that appeared so far, while at its\nheart lies an adaptive mechanism to continually maintain the class balance\nbetween the selected examples. We compare AREBA with strong baselines and other\nstate-of-the-art algorithms and perform extensive experimental work in\nscenarios with various class imbalance rates and different concept drift types\non both synthetic and real-world data. AREBA significantly outperforms the rest\nwith respect to both learning speed and learning quality. Our code is made\npublicly available to the scientific community.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:40:04 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Malialis", "Kleanthis", ""], ["Panayiotou", "Christos G.", ""], ["Polycarpou", "Marios M.", ""]]}, {"id": "2009.11961", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin and Grzegorz Dudek and Pawe{\\l} Pe{\\l}ka and\n  Ekaterina Turkina", "title": "N-BEATS neural network for mid-term electricity load forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the mid-term electricity load forecasting problem.\nSolving this problem is necessary for power system operation and planning as\nwell as for negotiating forward contracts in deregulated energy markets. We\nshow that our proposed deep neural network modeling approach based on the deep\nneural architecture is effective at solving the mid-term electricity load\nforecasting problem. Proposed neural network has high expressive power to solve\nnon-linear stochastic forecasting problems with time series including trends,\nseasonality and significant random fluctuations. At the same time, it is simple\nto implement and train, it does not require signal preprocessing, and it is\nequipped with a forecast bias reduction mechanism. We compare our approach\nagainst ten baseline methods, including classical statistical methods, machine\nlearning and hybrid approaches, on 35 monthly electricity demand time series\nfor European countries. The empirical study shows that proposed neural network\nclearly outperforms all competitors in terms of both accuracy and forecast\nbias. Code is available here: https://github.com/boreshkinai/nbeats-midterm.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 21:48:08 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 15:53:55 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 18:02:22 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Dudek", "Grzegorz", ""], ["Pe\u0142ka", "Pawe\u0142", ""], ["Turkina", "Ekaterina", ""]]}, {"id": "2009.11974", "submitter": "Farzana Nasrin", "authors": "Vasileios Maroulas, Cassie Putman Micucci, and Farzana Nasrin", "title": "Bayesian Topological Learning for Classifying the Structure of\n  Biological Networks", "comments": "30 pages and 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actin cytoskeleton networks generate local topological signatures due to the\nnatural variations in the number, size, and shape of holes of the networks.\nPersistent homology is a method that explores these topological properties of\ndata and summarizes them as persistence diagrams. In this work, we analyze and\nclassify these filament networks by transforming them into persistence diagrams\nwhose variability is quantified via a Bayesian framework on the space of\npersistence diagrams. The proposed generalized Bayesian framework adopts an\nindependent and identically distributed cluster point process characterization\nof persistence diagrams and relies on a substitution likelihood argument. This\nframework provides the flexibility to estimate the posterior cardinality\ndistribution of points in a persistence diagram and the posterior spatial\ndistribution simultaneously. We present a closed form of the posteriors under\nthe assumption of Gaussian mixtures and binomials for prior intensity and\ncardinality respectively. Using this posterior calculation, we implement a\nBayes factor algorithm to classify the actin filament networks and benchmark it\nagainst several state-of-the-art classification methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 22:43:03 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Maroulas", "Vasileios", ""], ["Micucci", "Cassie Putman", ""], ["Nasrin", "Farzana", ""]]}, {"id": "2009.11977", "submitter": "Fares Fourati", "authors": "Fares Fourati, Wided Souidene, Rabah Attia", "title": "An original framework for Wheat Head Detection using Deep,\n  Semi-supervised and Ensemble Learning within Global Wheat Head Detection\n  (GWHD) Dataset", "comments": "Canadian Journal of Remote Sensing (2021)", "journal-ref": null, "doi": "10.1080/07038992.2021.1906213", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an original object detection methodology applied to\nGlobal Wheat Head Detection (GWHD) Dataset. We have been through two major\narchitectures of object detection which are FasterRCNN and EfficientDet, in\norder to design a novel and robust wheat head detection model. We emphasize on\noptimizing the performance of our proposed final architectures. Furthermore, we\nhave been through an extensive exploratory data analysis and adapted best data\naugmentation techniques to our context. We use semi supervised learning to\nboost previous supervised models of object detection. Moreover, we put much\neffort on ensemble to achieve higher performance. Finally we use specific\npost-processing techniques to optimize our wheat head detection results. Our\nresults have been submitted to solve a research challenge launched on the GWHD\nDataset which is led by nine research institutes from seven countries. Our\nproposed method was ranked within the top 6% in the above mentioned challenge.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 22:58:40 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Fourati", "Fares", ""], ["Souidene", "Wided", ""], ["Attia", "Rabah", ""]]}, {"id": "2009.11982", "submitter": "Ana Valeria Gonzalez", "authors": "Ana Valeria Gonzalez, Maria Barrett, Rasmus Hvingelby, Kellie Webster,\n  Anders S{\\o}gaard", "title": "Type B Reflexivization as an Unambiguous Testbed for Multilingual\n  Multi-Task Gender Bias", "comments": "To appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The one-sided focus on English in previous studies of gender bias in NLP\nmisses out on opportunities in other languages: English challenge datasets such\nas GAP and WinoGender highlight model preferences that are \"hallucinatory\",\ne.g., disambiguating gender-ambiguous occurrences of 'doctor' as male doctors.\nWe show that for languages with type B reflexivization, e.g., Swedish and\nRussian, we can construct multi-task challenge datasets for detecting gender\nbias that lead to unambiguously wrong model predictions: In these languages,\nthe direct translation of 'the doctor removed his mask' is not ambiguous\nbetween a coreferential reading and a disjoint reading. Instead, the\ncoreferential reading requires a non-gendered pronoun, and the gendered,\npossessive pronouns are anti-reflexive. We present a multilingual, multi-task\nchallenge dataset, which spans four languages and four NLP tasks and focuses\nonly on this phenomenon. We find evidence for gender bias across all\ntask-language combinations and correlate model bias with national labor market\nstatistics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 23:47:18 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 05:12:48 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gonzalez", "Ana Valeria", ""], ["Barrett", "Maria", ""], ["Hvingelby", "Rasmus", ""], ["Webster", "Kellie", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "2009.11990", "submitter": "Youngsoo Choi", "authors": "Youngkyu Kim, Youngsoo Choi, David Widemann, Tarek Zohdi", "title": "A fast and accurate physics-informed neural network reduced order model\n  with shallow masked autoencoder", "comments": "33 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional linear subspace reduced order models (LS-ROMs) are able to\naccelerate physical simulations, in which the intrinsic solution space falls\ninto a subspace with a small dimension, i.e., the solution space has a small\nKolmogorov n-width. However, for physical phenomena not of this type, e.g., any\nadvection-dominated flow phenomena, such as in traffic flow, atmospheric flows,\nand air flow over vehicles, a low-dimensional linear subspace poorly\napproximates the solution. To address cases such as these, we have developed a\nfast and accurate physics-informed neural network ROM, namely nonlinear\nmanifold ROM (NM-ROM), which can better approximate high-fidelity model\nsolutions with a smaller latent space dimension than the LS-ROMs. Our method\ntakes advantage of the existing numerical methods that are used to solve the\ncorresponding full order models. The efficiency is achieved by developing a\nhyper-reduction technique in the context of the NM-ROM. Numerical results show\nthat neural networks can learn a more efficient latent space representation on\nadvection-dominated data from 1D and 2D Burgers' equations. A speedup of up to\n2.6 for 1D Burgers' and a speedup of 11.7 for 2D Burgers' equations are\nachieved with an appropriate treatment of the nonlinear terms through a\nhyper-reduction technique. Finally, a posteriori error bounds for the NM-ROMs\nare derived that take account of the hyper-reduced operators.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 00:48:19 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 21:27:55 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kim", "Youngkyu", ""], ["Choi", "Youngsoo", ""], ["Widemann", "David", ""], ["Zohdi", "Tarek", ""]]}, {"id": "2009.11992", "submitter": "Ravi Patel", "authors": "Ravi G. Patel, Nathaniel A. Trask, Mitchell A. Wood, Eric C. Cyr", "title": "A physics-informed operator regression framework for extracting\n  data-driven continuum models", "comments": "37 pages, 15 figures", "journal-ref": null, "doi": "10.1016/j.cma.2020.113500", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning toward discovery of data-driven models\nrequires careful application of inductive biases to obtain a description of\nphysics which is both accurate and robust. We present here a framework for\ndiscovering continuum models from high fidelity molecular simulation data. Our\napproach applies a neural network parameterization of governing physics in\nmodal space, allowing a characterization of differential operators while\nproviding structure which may be used to impose biases related to symmetry,\nisotropy, and conservation form. We demonstrate the effectiveness of our\nframework for a variety of physics, including local and nonlocal diffusion\nprocesses and single and multiphase flows. For the flow physics we demonstrate\nthis approach leads to a learned operator that generalizes to system\ncharacteristics not included in the training sets, such as variable particle\nsizes, densities, and concentration.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 01:13:51 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Patel", "Ravi G.", ""], ["Trask", "Nathaniel A.", ""], ["Wood", "Mitchell A.", ""], ["Cyr", "Eric C.", ""]]}, {"id": "2009.11997", "submitter": "Yizhou Huang", "authors": "Yizhou Huang, Kevin Xie, Homanga Bharadhwaj and Florian Shkurti", "title": "Continual Model-Based Reinforcement Learning with Hypernetworks", "comments": "7 pages (+2 pages in appendix), 8 figures. To appear in the proc. of\n  the 2021 IEEE International Conference on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective planning in model-based reinforcement learning (MBRL) and\nmodel-predictive control (MPC) relies on the accuracy of the learned dynamics\nmodel. In many instances of MBRL and MPC, this model is assumed to be\nstationary and is periodically re-trained from scratch on state transition\nexperience collected from the beginning of environment interactions. This\nimplies that the time required to train the dynamics model - and the pause\nrequired between plan executions - grows linearly with the size of the\ncollected experience. We argue that this is too slow for lifelong robot\nlearning and propose HyperCRL, a method that continually learns the encountered\ndynamics in a sequence of tasks using task-conditional hypernetworks. Our\nmethod has three main attributes: first, it includes dynamics learning sessions\nthat do not revisit training data from previous tasks, so it only needs to\nstore the most recent fixed-size portion of the state transition experience;\nsecond, it uses fixed-capacity hypernetworks to represent non-stationary and\ntask-aware dynamics; third, it outperforms existing continual learning\nalternatives that rely on fixed-capacity networks, and does competitively with\nbaselines that remember an ever increasing coreset of past experience. We show\nthat HyperCRL is effective in continual model-based reinforcement learning in\nrobot locomotion and manipulation scenarios, such as tasks involving pushing\nand door opening. Our project website with videos is at this link\nhttps://rvl.cs.toronto.edu/blog/2020/hypercrl\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 01:46:26 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 02:46:27 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Huang", "Yizhou", ""], ["Xie", "Kevin", ""], ["Bharadhwaj", "Homanga", ""], ["Shkurti", "Florian", ""]]}, {"id": "2009.11999", "submitter": "Weijian Li", "authors": "Weijian Li, Wei Zhu, E. Ray Dorsey, Jiebo Luo", "title": "Predicting Parkinson's Disease with Multimodal Irregularly Collected\n  Longitudinal Smartphone Data", "comments": "Accepted to ICDM-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinsons Disease is a neurological disorder and prevalent in elderly\npeople. Traditional ways to diagnose the disease rely on in-person subjective\nclinical evaluations on the quality of a set of activity tests. The\nhigh-resolution longitudinal activity data collected by smartphone applications\nnowadays make it possible to conduct remote and convenient health assessment.\nHowever, out-of-lab tests often suffer from poor quality controls as well as\nirregularly collected observations, leading to noisy test results. To address\nthese issues, we propose a novel time-series based approach to predicting\nParkinson's Disease with raw activity test data collected by smartphones in the\nwild. The proposed method first synchronizes discrete activity tests into\nmultimodal features at unified time points. Next, it distills and enriches\nlocal and global representations from noisy data across modalities and temporal\nobservations by two attention modules. With the proposed mechanisms, our model\nis capable of handling noisy observations and at the same time extracting\nrefined temporal features for improved prediction performance. Quantitative and\nqualitative results on a large public dataset demonstrate the effectiveness of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 01:50:15 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 16:10:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Li", "Weijian", ""], ["Zhu", "Wei", ""], ["Dorsey", "E. Ray", ""], ["Luo", "Jiebo", ""]]}, {"id": "2009.12001", "submitter": "Yiyan Li", "authors": "Yiyan Li, Si Zhang, Rongxing Hu, Ning Lu", "title": "A Meta-learning based Distribution System Load Forecasting Model\n  Selection Framework", "comments": "accepted by Applied Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a meta-learning based, automatic distribution system load\nforecasting model selection framework. The framework includes the following\nprocesses: feature extraction, candidate model labeling, offline training, and\nonline model recommendation. Using user load forecasting needs as input\nfeatures, multiple meta-learners are used to rank the available load forecast\nmodels based on their forecasting accuracy. Then, a scoring-voting mechanism\nweights recommendations from each meta-leaner to make the final\nrecommendations. Heterogeneous load forecasting tasks with different temporal\nand technical requirements at different load aggregation levels are set up to\ntrain, validate, and test the performance of the proposed framework. Simulation\nresults demonstrate that the performance of the meta-learning based approach is\nsatisfactory in both seen and unseen forecasting tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 01:53:25 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 21:14:06 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Li", "Yiyan", ""], ["Zhang", "Si", ""], ["Hu", "Rongxing", ""], ["Lu", "Ning", ""]]}, {"id": "2009.12007", "submitter": "Sayak Paul", "authors": "Souradip Chakraborty, Aritra Roy Gosthipaty, Sayak Paul", "title": "G-SimCLR : Self-Supervised Contrastive Learning with Guided Projection\n  via Pseudo Labelling", "comments": "Code available at this URL: https://github.com/ariG23498/G-SimCLR.\n  This paper is accepeted as a workshop paper at\n  https://fuzhenzhuang.github.io/DLKT2020/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the realms of computer vision, it is evident that deep neural networks\nperform better in a supervised setting with a large amount of labeled data. The\nrepresentations learned with supervision are not only of high quality but also\nhelps the model in enhancing its accuracy. However, the collection and\nannotation of a large dataset are costly and time-consuming. To avoid the same,\nthere has been a lot of research going on in the field of unsupervised visual\nrepresentation learning especially in a self-supervised setting. Amongst the\nrecent advancements in self-supervised methods for visual recognition, in\nSimCLR Chen et al. shows that good quality representations can indeed be\nlearned without explicit supervision. In SimCLR, the authors maximize the\nsimilarity of augmentations of the same image and minimize the similarity of\naugmentations of different images. A linear classifier trained with the\nrepresentations learned using this approach yields 76.5% top-1 accuracy on the\nImageNet ILSVRC-2012 dataset. In this work, we propose that, with the\nnormalized temperature-scaled cross-entropy (NT-Xent) loss function (as used in\nSimCLR), it is beneficial to not have images of the same category in the same\nbatch. In an unsupervised setting, the information of images pertaining to the\nsame category is missing. We use the latent space representation of a denoising\nautoencoder trained on the unlabeled dataset and cluster them with k-means to\nobtain pseudo labels. With this apriori information we batch images, where no\ntwo images from the same category are to be found. We report comparable\nperformance enhancements on the CIFAR10 dataset and a subset of the ImageNet\ndataset. We refer to our method as G-SimCLR.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 02:25:37 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chakraborty", "Souradip", ""], ["Gosthipaty", "Aritra Roy", ""], ["Paul", "Sayak", ""]]}, {"id": "2009.12013", "submitter": "Liyan Xu", "authors": "Liyan Xu, Jinho D. Choi", "title": "Revealing the Myth of Higher-Order Inference in Coreference Resolution", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the impact of higher-order inference (HOI) on the task of\ncoreference resolution. HOI has been adapted by almost all recent coreference\nresolution models without taking much investigation on its true effectiveness\nover representation learning. To make a comprehensive analysis, we implement an\nend-to-end coreference system as well as four HOI approaches, attended\nantecedent, entity equalization, span clustering, and cluster merging, where\nthe latter two are our original methods. We find that given a high-performing\nencoder such as SpanBERT, the impact of HOI is negative to marginal, providing\na new perspective of HOI to this task. Our best model using cluster merging\nshows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 03:28:07 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 22:47:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Xu", "Liyan", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2009.12015", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Jose Gomez-Tames, Akimasa Hirata", "title": "Influence of segmentation accuracy in structural MR head scans on\n  electric field computation for TMS and tES", "comments": "Phys. Med. Biol", "journal-ref": "Physics in Medicine and Biology, 2021", "doi": "10.1088/1361-6560/abe223", "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several diagnosis and therapy procedures based on electrostimulation\neffect, the internal physical quantity related to the stimulation is the\ninduced electric field. To estimate the induced electric field in an individual\nhuman model, the segmentation of anatomical imaging, such as (magnetic\nresonance image (MRI) scans, of the corresponding body parts into tissues is\nrequired. Then, electrical properties associated with different annotated\ntissues are assigned to the digital model to generate a volume conductor. An\nopen question is how segmentation accuracy of different tissues would influence\nthe distribution of the induced electric field. In this study, we applied\nparametric segmentation of different tissues to exploit the segmentation of\navailable MRI to generate different quality of head models using deep learning\nneural network architecture, named ForkNet. Then, the induced electric field\nare compared to assess the effect of model segmentation variations.\nComputational results indicate that the influence of segmentation error is\ntissue-dependent. In brain, sensitivity to segmentation accuracy is relatively\nhigh in cerebrospinal fluid (CSF), moderate in gray matter (GM) and low in\nwhite matter for transcranial magnetic stimulation (TMS) and transcranial\nelectrical stimulation (tES). A CSF segmentation accuracy reduction of 10% in\nterms of Dice coefficient (DC) lead to decrease up to 4% in normalized induced\nelectric field in both applications. However, a GM segmentation accuracy\nreduction of 5.6% DC leads to increase of normalized induced electric field up\nto 6%. Opposite trend of electric field variation was found between CSF and GM\nfor both TMS and tES. The finding obtained here would be useful to quantify\npotential uncertainty of computational results.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 03:38:24 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 00:54:14 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Rashed", "Essam A.", ""], ["Gomez-Tames", "Jose", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2009.12027", "submitter": "Krishanu Sarker", "authors": "Krishanu Sarker, Xiulong Yang, Yang Li, Saeid Belkasim and Shihao Ji", "title": "A Unified Plug-and-Play Framework for Effective Data Denoising and\n  Robust Abstention", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Neural Networks (DNNs) highly depends on data quality.\nMoreover, predictive uncertainty makes high performing DNNs risky for\nreal-world deployment. In this paper, we aim to address these two issues by\nproposing a unified filtering framework leveraging underlying data density,\nthat can effectively denoise training data as well as avoid predicting\nuncertain test data points. Our proposed framework leverages underlying data\ndistribution to differentiate between noise and clean data samples without\nrequiring any modification to existing DNN architectures or loss functions.\nExtensive experiments on multiple image classification datasets and multiple\nCNN architectures demonstrate that our simple yet effective framework can\noutperform the state-of-the-art techniques in denoising training data and\nabstaining uncertain test data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:18:08 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Sarker", "Krishanu", ""], ["Yang", "Xiulong", ""], ["Li", "Yang", ""], ["Belkasim", "Saeid", ""], ["Ji", "Shihao", ""]]}, {"id": "2009.12028", "submitter": "Jeremiah Deng", "authors": "Jinyong Hou, Xuejie Ding, Stephen Cranefield, Jeremiah D. Deng", "title": "Deep Adversarial Transition Learning using Cross-Grafted Generative\n  Stacks", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep domain adaptation methods used in computer vision have mainly\nfocused on learning discriminative and domain-invariant features across\ndifferent domains. In this paper, we present a novel \"deep adversarial\ntransition learning\" (DATL) framework that bridges the domain gap by projecting\nthe source and target domains into intermediate, transitional spaces through\nthe employment of adjustable, cross-grafted generative network stacks and\neffective adversarial learning between transitions. Specifically, we construct\nvariational auto-encoders (VAE) for the two domains, and form bidirectional\ntransitions by cross-grafting the VAEs' decoder stacks. Furthermore, generative\nadversarial networks (GAN) are employed for domain adaptation, mapping the\ntarget domain data to the known label space of the source domain. The overall\nadaptation process hence consists of three phases: feature representation\nlearning by VAEs, transitions generation, and transitions alignment by GANs.\nExperimental results demonstrate that our method outperforms the state-of-the\nart on a number of unsupervised domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:25:27 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Hou", "Jinyong", ""], ["Ding", "Xuejie", ""], ["Cranefield", "Stephen", ""], ["Deng", "Jeremiah D.", ""]]}, {"id": "2009.12040", "submitter": "Tao Zhang", "authors": "Tao Zhang, Tianqing Zhu, Jing Li, Mengde Han, Wanlei Zhou, and Philip\n  S. Yu", "title": "Fairness in Semi-supervised Learning: Unlabeled Data Help to Reduce\n  Discrimination", "comments": "This paper has been published in IEEE Transactions on Knowledge and\n  Data Engineering", "journal-ref": null, "doi": "10.1109/TKDE.2020.3002567", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing specter in the rise of machine learning is whether the decisions\nmade by machine learning models are fair. While research is already underway to\nformalize a machine-learning concept of fairness and to design frameworks for\nbuilding fair models with sacrifice in accuracy, most are geared toward either\nsupervised or unsupervised learning. Yet two observations inspired us to wonder\nwhether semi-supervised learning might be useful to solve discrimination\nproblems. First, previous study showed that increasing the size of the training\nset may lead to a better trade-off between fairness and accuracy. Second, the\nmost powerful models today require an enormous of data to train which, in\npractical terms, is likely possible from a combination of labeled and unlabeled\ndata. Hence, in this paper, we present a framework of fair semi-supervised\nlearning in the pre-processing phase, including pseudo labeling to predict\nlabels for unlabeled data, a re-sampling method to obtain multiple fair\ndatasets and lastly, ensemble learning to improve accuracy and decrease\ndiscrimination. A theoretical decomposition analysis of bias, variance and\nnoise highlights the different sources of discrimination and the impact they\nhave on fairness in semi-supervised learning. A set of experiments on\nreal-world and synthetic datasets show that our method is able to use unlabeled\ndata to achieve a better trade-off between accuracy and discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 05:48:56 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Tianqing", ""], ["Li", "Jing", ""], ["Han", "Mengde", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2009.12042", "submitter": "Yohei Kawaguchi", "authors": "Harsh Purohit, Ryo Tanabe, Takashi Endo, Kaori Suefusa, Yuki Nikaido,\n  and Yohei Kawaguchi", "title": "Deep Autoencoding GMM-based Unsupervised Anomaly Detection in Acoustic\n  Signals and its Hyper-parameter Optimization", "comments": "5 pages, to appear in DCASE 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failures or breakdowns in factory machinery can be costly to companies, so\nthere is an increasing demand for automatic machine inspection. Existing\napproaches to acoustic signal-based unsupervised anomaly detection, such as\nthose using a deep autoencoder (DA) or Gaussian mixture model (GMM), have poor\nanomaly-detection performance. In this work, we propose a new method based on a\ndeep autoencoding Gaussian mixture model with hyper-parameter optimization\n(DAGMM-HO). In our method, the DAGMM-HO applies the conventional DAGMM to the\naudio domain for the first time, with the idea that its total optimization on\nreduction of dimensions and statistical modelling will improve the\nanomaly-detection performance. In addition, the DAGMM-HO solves the\nhyper-parameter sensitivity problem of the conventional DAGMM by performing\nhyper-parameter optimization based on the gap statistic and the cumulative\neigenvalues. Our evaluation of the proposed method with experimental data of\nthe industrial fans showed that it significantly outperforms previous\napproaches and achieves up to a 20% improvement based on the standard AUC\nscore.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 06:14:59 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Purohit", "Harsh", ""], ["Tanabe", "Ryo", ""], ["Endo", "Takashi", ""], ["Suefusa", "Kaori", ""], ["Nikaido", "Yuki", ""], ["Kawaguchi", "Yohei", ""]]}, {"id": "2009.12056", "submitter": "Xuguang Wang", "authors": "Xuguang Wang, Linjun Shou, Ming Gong, Nan Duan and Daxin Jiang", "title": "No Answer is Better Than Wrong Answer: A Reflection Model for Document\n  Level Machine Reading Comprehension", "comments": "Accepted by Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Natural Questions (NQ) benchmark set brings new challenges to Machine\nReading Comprehension: the answers are not only at different levels of\ngranularity (long and short), but also of richer types (including no-answer,\nyes/no, single-span and multi-span). In this paper, we target at this challenge\nand handle all answer types systematically. In particular, we propose a novel\napproach called Reflection Net which leverages a two-step training procedure to\nidentify the no-answer and wrong-answer cases. Extensive experiments are\nconducted to verify the effectiveness of our approach. At the time of paper\nwriting (May.~20,~2020), our approach achieved the top 1 on both long and short\nanswer leaderboard, with F1 scores of 77.2 and 64.1, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 06:57:52 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:29:57 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Xuguang", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Duan", "Nan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2009.12061", "submitter": "Yan Zhang", "authors": "Yan Zhang, Ruidan He, Zuozhu Liu, Kwan Hui Lim, Lidong Bing", "title": "An Unsupervised Sentence Embedding Method by Mutual Information\n  Maximization", "comments": "Accepted to EMNLP 2020, code is released", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT is inefficient for sentence-pair tasks such as clustering or semantic\nsearch as it needs to evaluate combinatorially many sentence pairs which is\nvery time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by\nlearning semantically meaningful representations of single sentences, such that\nsimilarity comparison can be easily accessed. However, SBERT is trained on\ncorpus with high-quality labeled sentence pairs, which limits its application\nto tasks where labeled data is extremely scarce. In this paper, we propose a\nlightweight extension on top of BERT and a novel self-supervised learning\nobjective based on mutual information maximization strategies to derive\nmeaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our\nmethod is not restricted by the availability of labeled data, such that it can\nbe applied on different domain-specific corpus. Experimental results show that\nthe proposed method significantly outperforms other unsupervised sentence\nembedding baselines on common semantic textual similarity (STS) tasks and\ndownstream supervised tasks. It also outperforms SBERT in a setting where\nin-domain labeled data is not available, and achieves performance competitive\nwith supervised methods on various tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:16:51 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 03:15:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Yan", ""], ["He", "Ruidan", ""], ["Liu", "Zuozhu", ""], ["Lim", "Kwan Hui", ""], ["Bing", "Lidong", ""]]}, {"id": "2009.12064", "submitter": "Shunsuke Kitada", "authors": "Shunsuke Kitada and Hitoshi Iyatomi", "title": "Attention Meets Perturbations: Robust and Interpretable Attention with\n  Adversarial Training", "comments": "12 pages, 4 figures. Accepted by IEEE Access on Jun. 21, 2021", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3093456", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although attention mechanisms have been applied to a variety of deep learning\nmodels and have been shown to improve the prediction performance, it has been\nreported to be vulnerable to perturbations to the mechanism. To overcome the\nvulnerability to perturbations in the mechanism, we are inspired by adversarial\ntraining (AT), which is a powerful regularization technique for enhancing the\nrobustness of the models. In this paper, we propose a general training\ntechnique for natural language processing tasks, including AT for attention\n(Attention AT) and more interpretable AT for attention (Attention iAT). The\nproposed techniques improved the prediction performance and the model\ninterpretability by exploiting the mechanisms with AT. In particular, Attention\niAT boosts those advantages by introducing adversarial perturbation, which\nenhances the difference in the attention of the sentences. Evaluation\nexperiments with ten open datasets revealed that AT for attention mechanisms,\nespecially Attention iAT, demonstrated (1) the best performance in nine out of\nten tasks and (2) more interpretable attention (i.e., the resulting attention\ncorrelated more strongly with gradient-based word importance) for all tasks.\nAdditionally, the proposed techniques are (3) much less dependent on\nperturbation size in AT. Our code is available at\nhttps://github.com/shunk031/attention-meets-perturbation\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:26:45 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 02:31:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "2009.12068", "submitter": "Jin Yang", "authors": "Gang Peng, Jin Yang, Xinde Lia, Mohammad Omar Khyam", "title": "Deep Reinforcement Learning with a Stage Incentive Mechanism of Dense\n  Reward for Robotic Trajectory Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (This work has been submitted to the IEEE for possible publication. Copyright\nmay be transferred without notice, after which this version may no longer be\naccessible.)\n  To improve the efficiency of deep reinforcement learning (DRL)-based methods\nfor robot manipulator trajectory planning in random working environments, we\npresent three dense reward functions. These rewards differ from the traditional\nsparse reward. First, a posture reward function is proposed to speed up the\nlearning process with a more reasonable trajectory by modeling the distance and\ndirection constraints, which can reduce the blindness of exploration. Second, a\nstride reward function is proposed to improve the stability of the learning\nprocess by modeling the distance and movement distance of joint constraints.\nFinally, in order to further improve learning efficiency, we are inspired by\nthe cognitive process of human behavior and propose a stage incentive\nmechanism, including a hard stage incentive reward function and a soft stage\nincentive reward function. Extensive experiments show that the soft stage\nincentive reward function is able to improve the convergence rate by up to\n46.9% with the state-of-the-art DRL methods. The percentage increase in the\nconvergence mean reward was 4.4-15.5% and the percentage decreases with respect\nto standard deviation were 21.9-63.2%. In the evaluation experiments, the\nsuccess rate of trajectory planning for a robot manipulator reached 99.6%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:36:32 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 04:55:36 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Peng", "Gang", ""], ["Yang", "Jin", ""], ["Lia", "Xinde", ""], ["Khyam", "Mohammad Omar", ""]]}, {"id": "2009.12075", "submitter": "Andrea Bommert", "authors": "Andrea Bommert and J\\\"org Rahnenf\\\"uhrer", "title": "Adjusted Measures for Feature Selection Stability for Data Sets with\n  Similar Features", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-64583-0_19", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For data sets with similar features, for example highly correlated features,\nmost existing stability measures behave in an undesired way: They consider\nfeatures that are almost identical but have different identifiers as different\nfeatures. Existing adjusted stability measures, that is, stability measures\nthat take into account the similarities between features, have major\ntheoretical drawbacks. We introduce new adjusted stability measures that\novercome these drawbacks. We compare them to each other and to existing\nstability measures based on both artificial and real sets of selected features.\nBased on the results, we suggest using one new stability measure that considers\nhighly similar features as exchangeable.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:52:19 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Bommert", "Andrea", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2009.12088", "submitter": "Nicol\\`o Bonettini", "authors": "Sara Mandelli, Nicol\\`o Bonettini, Paolo Bestagini, Stefano Tubaro", "title": "Training CNNs in Presence of JPEG Compression: Multimedia Forensics vs\n  Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have proved very accurate in multiple\ncomputer vision image classification tasks that required visual inspection in\nthe past (e.g., object recognition, face detection, etc.). Motivated by these\nastonishing results, researchers have also started using CNNs to cope with\nimage forensic problems (e.g., camera model identification, tampering\ndetection, etc.). However, in computer vision, image classification methods\ntypically rely on visual cues easily detectable by human eyes. Conversely,\nforensic solutions rely on almost invisible traces that are often very subtle\nand lie in the fine details of the image under analysis. For this reason,\ntraining a CNN to solve a forensic task requires some special care, as common\nprocessing operations (e.g., resampling, compression, etc.) can strongly hinder\nforensic traces. In this work, we focus on the effect that JPEG has on CNN\ntraining considering different computer vision and forensic image\nclassification problems. Specifically, we consider the issues that rise from\nJPEG compression and misalignment of the JPEG grid. We show that it is\nnecessary to consider these effects when generating a training dataset in order\nto properly train a forensic detector not losing generalization capability,\nwhereas it is almost possible to ignore these effects for computer vision\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 08:47:21 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Mandelli", "Sara", ""], ["Bonettini", "Nicol\u00f2", ""], ["Bestagini", "Paolo", ""], ["Tubaro", "Stefano", ""]]}, {"id": "2009.12098", "submitter": "Lukas Heppe", "authors": "Lukas Heppe and Michael Kamp and Linara Adilova and Danny Heinrich and\n  Nico Piatkowski and Katharina Morik", "title": "Resource-Constrained On-Device Learning by Dynamic Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication between data-generating devices is partially responsible\nfor a growing portion of the world's power consumption. Thus reducing\ncommunication is vital, both, from an economical and an ecological perspective.\nFor machine learning, on-device learning avoids sending raw data, which can\nreduce communication substantially. Furthermore, not centralizing the data\nprotects privacy-sensitive data. However, most learning algorithms require\nhardware with high computation power and thus high energy consumption. In\ncontrast, ultra-low-power processors, like FPGAs or micro-controllers, allow\nfor energy-efficient learning of local models. Combined with\ncommunication-efficient distributed learning strategies, this reduces the\noverall energy consumption and enables applications that were yet impossible\ndue to limited energy on local devices. The major challenge is then, that the\nlow-power processors typically only have integer processing capabilities. This\npaper investigates an approach to communication-efficient on-device learning of\ninteger exponential families that can be executed on low-power processors, is\nprivacy-preserving, and effectively minimizes communication. The empirical\nevaluation shows that the approach can reach a model quality comparable to a\ncentrally learned regular model with an order of magnitude less communication.\nComparing the overall energy consumption, this reduces the required energy for\nsolving the machine learning task by a significant amount.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 09:29:10 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Heppe", "Lukas", ""], ["Kamp", "Michael", ""], ["Adilova", "Linara", ""], ["Heinrich", "Danny", ""], ["Piatkowski", "Nico", ""], ["Morik", "Katharina", ""]]}, {"id": "2009.12125", "submitter": "Enrique Garcia-Ceja", "authors": "Enrique Garcia-Ceja, {\\AA}smund Hugo, Brice Morin, Per-Olav Hansen,\n  Espen Martinsen, An Ngoc Lam, {\\O}ystein Haugen", "title": "Towards the Automation of a Chemical Sulphonation Process with Machine\n  Learning", "comments": "Published in: 2019 7th International Conference on Control,\n  Mechatronics and Automation (ICCMA)", "journal-ref": "2019 7th International Conference on Control, Mechatronics and\n  Automation (ICCMA) (pp. 352-357). IEEE", "doi": "10.1109/ICCMA46720.2019.8988752", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the continuous improvement and automation of industrial processes\nhas become a key factor in many fields, and in the chemical industry, it is no\nexception. This translates into a more efficient use of resources, reduced\nproduction time, output of higher quality and reduced waste. Given the\ncomplexity of today's industrial processes, it becomes infeasible to monitor\nand optimize them without the use of information technologies and analytics. In\nrecent years, machine learning methods have been used to automate processes and\nprovide decision support. All of this, based on analyzing large amounts of data\ngenerated in a continuous manner. In this paper, we present the results of\napplying machine learning methods during a chemical sulphonation process with\nthe objective of automating the product quality analysis which currently is\nperformed manually. We used data from process parameters to train different\nmodels including Random Forest, Neural Network and linear regression in order\nto predict product quality values. Our experiments showed that it is possible\nto predict those product quality values with good accuracy, thus, having the\npotential to reduce time. Specifically, the best results were obtained with\nRandom Forest with a mean absolute error of 0.089 and a correlation of 0.978.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 10:56:41 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Garcia-Ceja", "Enrique", ""], ["Hugo", "\u00c5smund", ""], ["Morin", "Brice", ""], ["Hansen", "Per-Olav", ""], ["Martinsen", "Espen", ""], ["Lam", "An Ngoc", ""], ["Haugen", "\u00d8ystein", ""]]}, {"id": "2009.12132", "submitter": "Joris Tavernier", "authors": "Joris Tavernier, Jaak Simm, Adam Arany, Karl Meerbergen, Yves Moreau", "title": "Multilevel Gibbs Sampling for Bayesian Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian regression remains a simple but effective tool based on Bayesian\ninference techniques. For large-scale applications, with complicated posterior\ndistributions, Markov Chain Monte Carlo methods are applied. To improve the\nwell-known computational burden of Markov Chain Monte Carlo approach for\nBayesian regression, we developed a multilevel Gibbs sampler for Bayesian\nregression of linear mixed models. The level hierarchy of data matrices is\ncreated by clustering the features and/or samples of data matrices.\nAdditionally, the use of correlated samples is investigated for variance\nreduction to improve the convergence of the Markov Chain. Testing on a diverse\nset of data sets, speed-up is achieved for almost all of them without\nsignificant loss in predictive performance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:18:17 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Tavernier", "Joris", ""], ["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["Meerbergen", "Karl", ""], ["Moreau", "Yves", ""]]}, {"id": "2009.12133", "submitter": "Enrique Garcia-Ceja", "authors": "Enrique Garcia-Ceja, {\\AA}smund Hugo, Brice Morin, Per-Olav Hansen,\n  Espen Martinsen, An Ngoc Lam, {\\O}ystein Haugen", "title": "A Feature Importance Analysis for Soft-Sensing-Based Predictions in a\n  Chemical Sulphonation Process", "comments": "Accepted for: 3rd IEEE International Conference on Industrial\n  Cyber-Physical Systems (ICPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the results of a feature importance analysis of a\nchemical sulphonation process. The task consists of predicting the\nneutralization number (NT), which is a metric that characterizes the product\nquality of active detergents. The prediction is based on a dataset of\nenvironmental measurements, sampled from an industrial chemical process. We\nused a soft-sensing approach, that is, predicting a variable of interest based\non other process variables, instead of directly sensing the variable of\ninterest. Reasons for doing so range from expensive sensory hardware to harsh\nenvironments, e.g., inside a chemical reactor. The aim of this study was to\nexplore and detect which variables are the most relevant for predicting product\nquality, and to what degree of precision. We trained regression models based on\nlinear regression, regression tree and random forest. A random forest model was\nused to rank the predictor variables by importance. Then, we trained the models\nin a forward-selection style by adding one feature at a time, starting with the\nmost important one. Our results show that it is sufficient to use the top 3\nimportant variables, out of the 8 variables, to achieve satisfactory prediction\nresults. On the other hand, Random Forest obtained the best result when trained\nwith all variables.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:20:06 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Garcia-Ceja", "Enrique", ""], ["Hugo", "\u00c5smund", ""], ["Morin", "Brice", ""], ["Hansen", "Per-Olav", ""], ["Martinsen", "Espen", ""], ["Lam", "An Ngoc", ""], ["Haugen", "\u00d8ystein", ""]]}, {"id": "2009.12141", "submitter": "Thomas Pinder", "authors": "Thomas Pinder, Christopher Nemeth, David Leslie", "title": "Stein Variational Gaussian Processes", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use Stein variational gradient descent (SVGD) to carry out\ninference in Gaussian process (GP) models with non-Gaussian likelihoods and\nlarge data volumes. Markov chain Monte Carlo (MCMC) is extremely\ncomputationally intensive for these situations, but the parametric assumptions\nrequired for efficient variational inference (VI) result in incorrect inference\nwhen they encounter the multi-modal posterior distributions that are common for\nsuch models. SVGD provides a non-parametric alternative to variational\ninference which is substantially faster than MCMC. We prove that for GP models\nwith Lipschitz gradients the SVGD algorithm monotonically decreases the\nKullback-Leibler divergence from the sampling distribution to the true\nposterior. Our method is demonstrated on benchmark problems in both regression\nand classification, a multimodal posterior, and an air quality example with\n550,134 spatiotemporal observations, showing substantial performance\nimprovements over MCMC and VI.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:47:44 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:15:39 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Pinder", "Thomas", ""], ["Nemeth", "Christopher", ""], ["Leslie", "David", ""]]}, {"id": "2009.12146", "submitter": "Tri Minh Nguyen", "authors": "Tri Minh Nguyen, Thin Nguyen, Thao Minh Le, Truyen Tran", "title": "GEFA: Early Fusion Approach in Drug-Target Affinity Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the interaction between a compound and a target is crucial for\nrapid drug repurposing. Deep learning has been successfully applied in\ndrug-target affinity (DTA) problem. However, previous deep learning-based\nmethods ignore modeling the direct interactions between drug and protein\nresidues. This would lead to inaccurate learning of target representation which\nmay change due to the drug binding effects. In addition, previous DTA methods\nlearn protein representation solely based on a small number of protein\nsequences in DTA datasets while neglecting the use of proteins outside of the\nDTA datasets. We propose GEFA (Graph Early Fusion Affinity), a novel\ngraph-in-graph neural network with attention mechanism to address the changes\nin target representation because of the binding effects. Specifically, a drug\nis modeled as a graph of atoms, which then serves as a node in a larger graph\nof residues-drug complex. The resulting model is an expressive deep nested\ngraph neural network. We also use pre-trained protein representation powered by\nthe recent effort of learning contextualized protein representation. The\nexperiments are conducted under different settings to evaluate scenarios such\nas novel drugs or targets. The results demonstrate the effectiveness of the\npre-trained protein embedding and the advantages our GEFA in modeling the\nnested graph for drug-target interaction.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:54:15 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 01:47:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Tri Minh", ""], ["Nguyen", "Thin", ""], ["Le", "Thao Minh", ""], ["Tran", "Truyen", ""]]}, {"id": "2009.12153", "submitter": "Franziska Boenisch", "authors": "Franziska Boenisch", "title": "A Survey on Model Watermarking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models are applied in an increasing variety of domains.\nThe availability of large amounts of data and computational resources\nencourages the development of ever more complex and valuable models. These\nmodels are considered intellectual property of the legitimate parties who have\ntrained them, which makes their protection against stealing, illegitimate\nredistribution, and unauthorized application an urgent need. Digital\nwatermarking presents a strong mechanism for marking model ownership and,\nthereby, offers protection against those threats. The emergence of numerous\nwatermarking schemes and attacks against them is pushed forward by both\nacademia and industry, which motivates a comprehensive survey on this field.\nThis document at hand provides the first extensive literature review on ML\nmodel watermarking schemes and attacks against them. It offers a taxonomy of\nexisting approaches and systemizes general knowledge around them. Furthermore,\nit assembles the security requirements to watermarking approaches and evaluates\nschemes published by the scientific community according to them in order to\npresent systematic shortcomings and vulnerabilities. Thus, it can not only\nserve as valuable guidance in choosing the appropriate scheme for specific\nscenarios, but also act as an entry point into developing new mechanisms that\novercome presented shortcomings, and thereby contribute in advancing the field.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:03:02 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Boenisch", "Franziska", ""]]}, {"id": "2009.12174", "submitter": "Micol Marchetti-Bowick", "authors": "Poornima Kaniarasu, Galen Clark Haynes, Micol Marchetti-Bowick", "title": "Goal-Directed Occupancy Prediction for Lane-Following Actors", "comments": "Published at ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the possible future behaviors of vehicles that drive on shared\nroads is a crucial task for safe autonomous driving. Many existing approaches\nto this problem strive to distill all possible vehicle behaviors into a\nsimplified set of high-level actions. However, these action categories do not\nsuffice to describe the full range of maneuvers possible in the complex road\nnetworks we encounter in the real world. To combat this deficiency, we propose\na new method that leverages the mapped road topology to reason over possible\ngoals and predict the future spatial occupancy of dynamic road actors. We show\nthat our approach is able to accurately predict future occupancy that remains\nconsistent with the mapped lane geometry and naturally captures multi-modality\nbased on the local scene context while also not suffering from the mode\ncollapse problem observed in prior work.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 20:44:59 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Kaniarasu", "Poornima", ""], ["Haynes", "Galen Clark", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "2009.12177", "submitter": "Baptiste Roziere", "authors": "Baptiste Roziere, Nathanal Carraz Rakotonirina, Vlad Hosu, Andry\n  Rasoanaivo, Hanhe Lin, Camille Couprie, Olivier Teytaud", "title": "Tarsier: Evolving Noise Injection in Super-Resolution GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Super-resolution aims at increasing the resolution and level of detail within\nan image. The current state of the art in general single-image super-resolution\nis held by NESRGAN+, which injects a Gaussian noise after each residual layer\nat training time. In this paper, we harness evolutionary methods to improve\nNESRGAN+ by optimizing the noise injection at inference time. More precisely,\nwe use Diagonal CMA to optimize the injected noise according to a novel\ncriterion combining quality assessment and realism. Our results are validated\nby the PIRM perceptual score and a human study. Our method outperforms NESRGAN+\non several standard super-resolution datasets. More generally, our approach can\nbe used to optimize any method based on noise injection.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:29:16 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Roziere", "Baptiste", ""], ["Rakotonirina", "Nathanal Carraz", ""], ["Hosu", "Vlad", ""], ["Rasoanaivo", "Andry", ""], ["Lin", "Hanhe", ""], ["Couprie", "Camille", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2009.12188", "submitter": "Veronica Vilaplana", "authors": "Laura Mora Ballestar and Veronica Vilaplana", "title": "Brain Tumor Segmentation using 3D-CNNs with Uncertainty Estimation", "comments": "Pre-conference paper. Brain Tumor Segmentation (BraTS) Challenge 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation of brain tumors in 3D magnetic resonance images (MRIs) is key to\nassess the diagnostic and treatment of the disease. In recent years,\nconvolutional neural networks (CNNs) have shown improved results in the task.\nHowever, high memory consumption is still a problem in 3D-CNNs. Moreover, most\nmethods do not include uncertainty information, which is specially critical in\nmedical diagnosis. This work proposes a 3D encoder-decoder architecture, based\non V-Net \\cite{vnet} which is trained with patching techniques to reduce memory\nconsumption and decrease the effect of unbalanced data. We also introduce\nvoxel-wise uncertainty, both epistemic and aleatoric using test-time dropout\nand data-augmentation respectively. Uncertainty maps can provide extra\ninformation to expert neurologists, useful for detecting when the model is not\nconfident on the provided segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 10:50:12 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ballestar", "Laura Mora", ""], ["Vilaplana", "Veronica", ""]]}, {"id": "2009.12192", "submitter": "Benjamin Chamberlain", "authors": "Benjamin P. Chamberlain, Emanuele Rossi, Dan Shiebler, Suvash Sedhain,\n  Michael M. Bronstein", "title": "Tuning Word2vec for Large Scale Recommendation Systems", "comments": "11 pages, 4 figures, Fourteenth ACM Conference on Recommender Systems", "journal-ref": "Fourteenth ACM Conference on Recommender Systems (RecSys '20),\n  September 22--26, 2020, Virtual Event, Brazil", "doi": "10.1145/3383313.3418486", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2vec is a powerful machine learning tool that emerged from Natural\nLan-guage Processing (NLP) and is now applied in multiple domains, including\nrecom-mender systems, forecasting, and network analysis. As Word2vec is often\nused offthe shelf, we address the question of whether the default\nhyperparameters are suit-able for recommender systems. The answer is\nemphatically no. In this paper, wefirst elucidate the importance of\nhyperparameter optimization and show that un-constrained optimization yields an\naverage 221% improvement in hit rate over thedefault parameters. However,\nunconstrained optimization leads to hyperparametersettings that are very\nexpensive and not feasible for large scale recommendationtasks. To this end, we\ndemonstrate 138% average improvement in hit rate with aruntime\nbudget-constrained hyperparameter optimization. Furthermore, to\nmakehyperparameter optimization applicable for large scale recommendation\nproblemswhere the target dataset is too large to search over, we investigate\ngeneralizinghyperparameters settings from samples. We show that applying\nconstrained hy-perparameter optimization using only a 10% sample of the data\nstill yields a 91%average improvement in hit rate over the default parameters\nwhen applied to thefull datasets. Finally, we apply hyperparameters learned\nusing our method of con-strained optimization on a sample to the Who To Follow\nrecommendation serviceat Twitter and are able to increase follow rates by 15%.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 10:50:19 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chamberlain", "Benjamin P.", ""], ["Rossi", "Emanuele", ""], ["Shiebler", "Dan", ""], ["Sedhain", "Suvash", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "2009.12193", "submitter": "Xiaoqiong Huang", "authors": "Xiaoqiong Huang, Zejian Chen, Xin Yang, Zhendong Liu, Yuxin Zou,\n  Mingyuan Luo, Wufeng Xue, Dong Ni", "title": "Style-invariant Cardiac Image Segmentation with Test-time Augmentation", "comments": "Accepted by MICCAI STACOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models often suffer from severe performance drop due to the appearance\nshift in the real clinical setting. Most of the existing learning-based methods\nrely on images from multiple sites/vendors or even corresponding labels.\nHowever, collecting enough unknown data to robustly model segmentation cannot\nalways hold since the complex appearance shift caused by imaging factors in\ndaily application. In this paper, we propose a novel style-invariant method for\ncardiac image segmentation. Based on the zero-shot style transfer to remove\nappearance shift and test-time augmentation to explore diverse underlying\nanatomy, our proposed method is effective in combating the appearance shift.\nOur contribution is three-fold. First, inspired by the spirit of universal\nstyle transfer, we develop a zero-shot stylization for content images to\ngenerate stylized images that appearance similarity to the style images.\nSecond, we build up a robust cardiac segmentation model based on the U-Net\nstructure. Our framework mainly consists of two networks during testing: the ST\nnetwork for removing appearance shift and the segmentation network. Third, we\ninvestigate test-time augmentation to explore transformed versions of the\nstylized image for prediction and the results are merged. Notably, our proposed\nframework is fully test-time adaptation. Experiment results demonstrate that\nour methods are promising and generic for generalizing deep segmentation\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 08:27:40 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Huang", "Xiaoqiong", ""], ["Chen", "Zejian", ""], ["Yang", "Xin", ""], ["Liu", "Zhendong", ""], ["Zou", "Yuxin", ""], ["Luo", "Mingyuan", ""], ["Xue", "Wufeng", ""], ["Ni", "Dong", ""]]}, {"id": "2009.12196", "submitter": "Bi-Cun Xu", "authors": "Kai Ming Ting, Bi-Cun Xu, Takashi Washio and Zhi-Hua Zhou", "title": "Isolation Distributional Kernel: A New Tool for Point & Group Anomaly\n  Detection", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Isolation Distributional Kernel as a new way to measure the\nsimilarity between two distributions. Existing approaches based on kernel mean\nembedding, which convert a point kernel to a distributional kernel, have two\nkey issues: the point kernel employed has a feature map with intractable\ndimensionality; and it is {\\em data independent}. This paper shows that\nIsolation Distributional Kernel (IDK), which is based on a {\\em data dependent}\npoint kernel, addresses both key issues. We demonstrate IDK's efficacy and\nefficiency as a new tool for kernel based anomaly detection for both point and\ngroup anomalies. Without explicit learning, using IDK alone outperforms\nexisting kernel based point anomaly detector OCSVM and other kernel mean\nembedding methods that rely on Gaussian kernel. For group anomaly detection,we\nintroduce an IDK based detector called IDK$^2$. It reformulates the problem of\ngroup anomaly detection in input space into the problem of point anomaly\ndetection in Hilbert space, without the need for learning. IDK$^2$ runs orders\nof magnitude faster than group anomaly detector OCSMM.We reveal for the first\ntime that an effective kernel based anomaly detector based on kernel mean\nembedding must employ a characteristic kernel which is data dependent.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:25:43 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ting", "Kai Ming", ""], ["Xu", "Bi-Cun", ""], ["Washio", "Takashi", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2009.12197", "submitter": "Arthur Cruz de Araujo", "authors": "Arthur Cruz de Araujo and Ali Etemad", "title": "End-to-End Prediction of Parcel Delivery Time with Deep Learning for\n  Smart-City Applications", "comments": "14 pages, 21 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The acquisition of massive data on parcel delivery motivates postal operators\nto foster the development of predictive systems to improve customer service.\nPredicting delivery times successive to being shipped out of the final depot,\nreferred to as last-mile prediction, deals with complicating factors such as\ntraffic, drivers' behaviors, and weather. This work studies the use of deep\nlearning for solving a real-world case of last-mile parcel delivery time\nprediction. We present our solution under the IoT paradigm and discuss its\nfeasibility on a cloud-based architecture as a smart city application. We focus\non a large-scale parcel dataset provided by Canada Post, covering the Greater\nToronto Area (GTA). We utilize an origin-destination (OD) formulation, in which\nroutes are not available, but only the start and end delivery points. We\ninvestigate three categories of convolutional-based neural networks and assess\ntheir performances on the task. We further demonstrate how our modeling\noutperforms several baselines, from classical machine learning models to\nreferenced OD solutions. Specifically, we show that a ResNet architecture with\n8 residual blocks displays the best trade-off between performance and\ncomplexity. We perform a thorough error analysis across the data and visualize\nthe deep features learned to better understand the model behavior, making\ninteresting remarks on data predictability. Our work provides an end-to-end\nneural pipeline that leverages parcel OD data as well as weather to accurately\npredict delivery durations. We believe that our system has the potential not\nonly to improve user experience by better modeling their anticipation but also\nto aid last-mile postal logistics as a whole.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:35:25 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 03:51:04 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["de Araujo", "Arthur Cruz", ""], ["Etemad", "Ali", ""]]}, {"id": "2009.12200", "submitter": "Umut \\\"Ozkaya", "authors": "H\\\"useyin Duysak, Umut \\\"Ozkaya and Enes Yi\\u{g}it", "title": "Grain Surface Classification via Machine Learning Methods", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, radar signals were analyzed to classify grain surface types by\nusing machine learning methods. Radar backscatter signals were recorded using a\nvector network analyzer between 18-40 GHz. A total of 5681 measurements of A\nscan signals were collected. The proposed method framework consists of two\nparts. First Order Statistical features are obtained by applying Fast Fourier\nTransform (FFT), Discrete Cosine Transform (DCT), Discrete Wavelet Transform\n(DWT) on backscatter signals in the first part of the framework. Classification\nprocess of these features was carried out with Support Vector Machine (SVM). In\nthe second part of the proposed framework, two dimensional matrices in complex\nform were obtained by applying Short Time Fourier Transform (STFT) on the\nsignals. Gray-Level Co-Occurrence Matrix (GLCM) and Gray-Level Run-Length\nMatrix (GLRLM) were obtained and feature extraction process was completed.\nClassification process was carried out with DVM. 10-k cross validation was\napplied. The highest performance was achieved with STFT+GLCM+SVM.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:24:51 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Duysak", "H\u00fcseyin", ""], ["\u00d6zkaya", "Umut", ""], ["Yi\u011fit", "Enes", ""]]}, {"id": "2009.12202", "submitter": "Yun Zhao", "authors": "Yun Zhao, Franklin Ly, Qinghang Hong, Zhuowei Cheng, Tyler Santander,\n  Henry T. Yang, Paul K. Hansma, and Linda Petzold", "title": "How Much Does It Hurt: A Deep Learning Framework for Chronic Pain Score\n  Assessment", "comments": "ICDM 2020 workshop (DMBIH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic pain is defined as pain that lasts or recurs for more than 3 to 6\nmonths, often long after the injury or illness that initially caused the pain\nhas healed. The \"gold standard\" for chronic pain assessment remains self report\nand clinical assessment via a biopsychosocial interview, since there has been\nno device that can measure it. A device to measure pain would be useful not\nonly for clinical assessment, but potentially also as a biofeedback device\nleading to pain reduction. In this paper we propose an end-to-end deep learning\nframework for chronic pain score assessment. Our deep learning framework splits\nthe long time-course data samples into shorter sequences, and uses Consensus\nPrediction to classify the results. We evaluate the performance of our\nframework on two chronic pain score datasets collected from two iterations of\nprototype Pain Meters that we have developed to help chronic pain subjects\nbetter understand their health condition.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 23:29:57 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhao", "Yun", ""], ["Ly", "Franklin", ""], ["Hong", "Qinghang", ""], ["Cheng", "Zhuowei", ""], ["Santander", "Tyler", ""], ["Yang", "Henry T.", ""], ["Hansma", "Paul K.", ""], ["Petzold", "Linda", ""]]}, {"id": "2009.12228", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Andr\\'as Gy\\\"orgy", "title": "Mirror Descent and the Information Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a connection between the stability of mirror descent and the\ninformation ratio by Russo and Van Roy [2014]. Our analysis shows that mirror\ndescent with suitable loss estimators and exploratory distributions enjoys the\nsame bound on the adversarial regret as the bounds on the Bayesian regret for\ninformation-directed sampling. Along the way, we develop the theory for\ninformation-directed sampling and provide an efficient algorithm for\nadversarial bandits for which the regret upper bound matches exactly the best\nknown information-theoretic upper bound.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:17:38 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Lattimore", "Tor", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""]]}, {"id": "2009.12244", "submitter": "Sari Sadiya", "authors": "Sari Saba-Sadiya, Tuka Alhanai, Taosheng Liu, Mohammad M. Ghassemi", "title": "EEG Channel Interpolation Using Deep Encoder-decoder Netwoks", "comments": null, "journal-ref": "2020 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrode \"pop\" artifacts originate from the spontaneous loss of connectivity\nbetween a surface and an electrode. Electroencephalography (EEG) uses a dense\narray of electrodes, hence \"popped\" segments are among the most pervasive type\nof artifact seen during the collection of EEG data. In many cases, the\ncontinuity of EEG data is critical for downstream applications (e.g. brain\nmachine interface) and requires that popped segments be accurately\ninterpolated. In this paper we frame the interpolation problem as a\nself-learning task using a deep encoder-decoder network. We compare our\napproach against contemporary interpolation methods on a publicly available EEG\ndata set. Our approach exhibited a minimum of ~15% improvement over\ncontemporary approaches when tested on subjects and tasks not used during model\ntraining. We demonstrate how our model's performance can be enhanced further on\nnovel subjects and tasks using transfer learning. All code and data associated\nwith this study is open-source to enable ease of extension and practical use.\nTo our knowledge, this work is the first solution to the EEG interpolation\nproblem that uses deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 21:57:41 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 23:16:12 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Saba-Sadiya", "Sari", ""], ["Alhanai", "Tuka", ""], ["Liu", "Taosheng", ""], ["Ghassemi", "Mohammad M.", ""]]}, {"id": "2009.12246", "submitter": "Alec Kirkley", "authors": "Alec Kirkley and George T. Cantwell and M. E. J. Newman", "title": "Belief propagation for networks with loops", "comments": null, "journal-ref": "Science Advances 7, eabf1211 (2021)", "doi": "10.1126/sciadv.abf1211", "report-no": null, "categories": "cond-mat.stat-mech cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation is a widely used message passing method for the solution\nof probabilistic models on networks such as epidemic models, spin models, and\nBayesian graphical models, but it suffers from the serious shortcoming that it\nworks poorly in the common case of networks that contain short loops. Here we\nprovide a solution to this long-standing problem, deriving a belief propagation\nmethod that allows for fast calculation of probability distributions in systems\nwith short loops, potentially with high density, as well as giving expressions\nfor the entropy and partition function, which are notoriously difficult\nquantities to compute. Using the Ising model as an example, we show that our\napproach gives excellent results on both real and synthetic networks, improving\nsignificantly on standard message passing methods. We also discuss potential\napplications of our method to a variety of other problems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:07:05 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 04:39:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kirkley", "Alec", ""], ["Cantwell", "George T.", ""], ["Newman", "M. E. J.", ""]]}, {"id": "2009.12263", "submitter": "Tim Besard", "authors": "Thomas Faingnaert, Tim Besard, Bjorn De Sutter", "title": "Flexible Performant GEMM Kernels on GPUs", "comments": "This paper was submitted to IEEE TPDS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General Matrix Multiplication or GEMM kernels take center place in high\nperformance computing and machine learning. Recent NVIDIA GPUs include GEMM\naccelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by\nthe two-language problem: it requires either low-level programming which\nimplies low programmer productivity or using libraries that only offer a\nlimited set of components. Because rephrasing algorithms in terms of\nestablished components often introduces overhead, the libraries' lack of\nflexibility limits the freedom to explore new algorithms. Researchers using\nGEMMs can hence not enjoy programming productivity, high performance, and\nresearch flexibility at once.\n  In this paper we solve this problem. We present three sets of abstractions\nand interfaces to program GEMMs within the scientific Julia programming\nlanguage. The interfaces and abstractions are co-designed for researchers'\nneeds and Julia's features to achieve sufficient separation of concerns and\nflexibility to easily extend basic GEMMs in many different ways without paying\na performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS\nand CUTLASS, we demonstrate that our performance is mostly on par with, and in\nsome cases even exceeds, the libraries, without having to write a single line\nof code in CUDA C++ or assembly, and without facing flexibility limitations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:29:08 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 12:41:57 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 06:43:53 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Faingnaert", "Thomas", ""], ["Besard", "Tim", ""], ["De Sutter", "Bjorn", ""]]}, {"id": "2009.12280", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Silas {\\O}rting, Erik B Dam", "title": "Locally orderless tensor networks for classifying two- and\n  three-dimensional medical images", "comments": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) (see https://melba-journal.org). Source code at\n  https://github.com/raghavian/LoTeNet_pytorch/", "journal-ref": "Journal of Machine Learning for Biomedical Imaging. 2021:5. pp\n  1-21. Special Issue: Medical Imaging with Deep Learning (MIDL) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tensor networks are factorisations of high rank tensors into networks of\nlower rank tensors and have primarily been used to analyse quantum many-body\nproblems. Tensor networks have seen a recent surge of interest in relation to\nsupervised learning tasks with a focus on image classification. In this work,\nwe improve upon the matrix product state (MPS) tensor networks that can operate\non one-dimensional vectors to be useful for working with 2D and 3D medical\nimages. We treat small image regions as orderless, squeeze their spatial\ninformation into feature dimensions and then perform MPS operations on these\nlocally orderless regions. These local representations are then aggregated in a\nhierarchical manner to retain global structure. The proposed locally orderless\ntensor network (LoTeNet) is compared with relevant methods on three datasets.\nThe architecture of LoTeNet is fixed in all experiments and we show it requires\nlesser computational resources to attain performance on par or superior to the\ncompared methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:05:02 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 20:45:47 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Selvan", "Raghavendra", ""], ["\u00d8rting", "Silas", ""], ["Dam", "Erik B", ""]]}, {"id": "2009.12293", "submitter": "Yuke Zhu", "authors": "Yuke Zhu and Josiah Wong and Ajay Mandlekar and Roberto\n  Mart\\'in-Mart\\'in", "title": "robosuite: A Modular Simulation Framework and Benchmark for Robot\n  Learning", "comments": "For more information, please visit https://robosuite.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  robosuite is a simulation framework for robot learning powered by the MuJoCo\nphysics engine. It offers a modular design for creating robotic tasks as well\nas a suite of benchmark environments for reproducible research. This paper\ndiscusses the key system modules and the benchmark environments of our new\nrelease robosuite v1.0.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:32:31 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhu", "Yuke", ""], ["Wong", "Josiah", ""], ["Mandlekar", "Ajay", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""]]}, {"id": "2009.12303", "submitter": "Prasetya Ajie Utama", "authors": "Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych", "title": "Towards Debiasing NLU Models from Unknown Biases", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLU models often exploit biases to achieve high dataset-specific performance\nwithout properly learning the intended task. Recently proposed debiasing\nmethods are shown to be effective in mitigating this tendency. However, these\nmethods rely on a major assumption that the types of bias should be known\na-priori, which limits their application to many NLU tasks and datasets. In\nthis work, we present the first step to bridge this gap by introducing a\nself-debiasing framework that prevents models from mainly utilizing biases\nwithout knowing them in advance. The proposed framework is general and\ncomplementary to the existing debiasing methods. We show that it allows these\nexisting methods to retain the improvement on the challenge datasets (i.e.,\nsets of examples designed to expose models' reliance on biases) without\nspecifically targeting certain biases. Furthermore, the evaluation suggests\nthat applying the framework results in improved overall robustness.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:49:39 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 11:00:39 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 11:52:22 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 12:37:27 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Utama", "Prasetya Ajie", ""], ["Moosavi", "Nafise Sadat", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2009.12316", "submitter": "Xin Qian", "authors": "Xin Qian, Ryan A. Rossi, Fan Du, Sungchul Kim, Eunyee Koh, Sana Malik,\n  Tak Yeon Lee, Joel Chan", "title": "ML-based Visualization Recommendation: Learning to Recommend\n  Visualizations from Data", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualization recommendation seeks to generate, score, and recommend to users\nuseful visualizations automatically, and are fundamentally important for\nexploring and gaining insights into a new or existing dataset quickly. In this\nwork, we propose the first end-to-end ML-based visualization recommendation\nsystem that takes as input a large corpus of datasets and visualizations,\nlearns a model based on this data. Then, given a new unseen dataset from an\narbitrary user, the model automatically generates visualizations for that new\ndataset, derive scores for the visualizations, and output a list of recommended\nvisualizations to the user ordered by effectiveness. We also describe an\nevaluation framework to quantitatively evaluate visualization recommendation\nmodels learned from a large corpus of visualizations and datasets. Through\nquantitative experiments, a user study, and qualitative analysis, we show that\nour end-to-end ML-based system recommends more effective and useful\nvisualizations compared to existing state-of-the-art rule-based systems.\nFinally, we observed a strong preference by the human experts in our user study\ntowards the visualizations recommended by our ML-based system as opposed to the\nrule-based system (5.92 from a 7-point Likert scale compared to only 3.45).\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:13:29 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Qian", "Xin", ""], ["Rossi", "Ryan A.", ""], ["Du", "Fan", ""], ["Kim", "Sungchul", ""], ["Koh", "Eunyee", ""], ["Malik", "Sana", ""], ["Lee", "Tak Yeon", ""], ["Chan", "Joel", ""]]}, {"id": "2009.12318", "submitter": "John Wu", "authors": "John F. Wu and J. E. G. Peek", "title": "Predicting galaxy spectra from images with hybrid convolutional neural\n  networks", "comments": "5 pages, 2 figures, accepted to the Machine Learning and the Physical\n  Sciences workshop at NeurIPS 2020. Code available at\n  https://github.com/jwuphysics/predicting-spectra-from-images/", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Galaxies can be described by features of their optical spectra such as oxygen\nemission lines, or morphological features such as spiral arms. Although\nspectroscopy provides a rich description of the physical processes that govern\ngalaxy evolution, spectroscopic data are observationally expensive to obtain.\nFor the first time, we are able to robustly predict galaxy spectra directly\nfrom broad-band imaging. We present a powerful new approach using a hybrid\nconvolutional neural network with deconvolution instead of batch normalization;\nthis hybrid CNN outperforms other models in our tests. The learned mapping\nbetween galaxy imaging and spectra will be transformative for future wide-field\nsurveys, such as with the Vera C. Rubin Observatory and Nancy Grace Roman Space\nTelescope, by multiplying the scientific returns for spectroscopically-limited\ngalaxy samples.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:16:16 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 18:21:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wu", "John F.", ""], ["Peek", "J. E. G.", ""]]}, {"id": "2009.12325", "submitter": "Ahmed Ben Said", "authors": "Ahmed Ben Said, Abdelkarim Erradi, Hussein Aly, Abdelmonem Mohamed", "title": "Predicting COVID-19 cases using Bidirectional LSTM on multivariate time\n  series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: To assist policy makers in taking adequate decisions to stop the\nspread of COVID-19 pandemic, accurate forecasting of the disease propagation is\nof paramount importance. Materials and Methods: This paper presents a deep\nlearning approach to forecast the cumulative number of COVID-19 cases using\nBidirectional Long Short-Term Memory (Bi-LSTM) network applied to multivariate\ntime series. Unlike other forecasting techniques, our proposed approach first\ngroups the countries having similar demographic and socioeconomic aspects and\nhealth sector indicators using K-Means clustering algorithm. The cumulative\ncases data for each clustered countries enriched with data related to the\nlockdown measures are fed to the Bidirectional LSTM to train the forecasting\nmodel. Results: We validate the effectiveness of the proposed approach by\nstudying the disease outbreak in Qatar. Quantitative evaluation, using multiple\nevaluation metrics, shows that the proposed technique outperforms state-of-art\nforecasting approaches. Conclusion: Using data of multiple countries in\naddition to lockdown measures improve accuracy of the forecast of daily\ncumulative COVID-19 cases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:53:05 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Said", "Ahmed Ben", ""], ["Erradi", "Abdelkarim", ""], ["Aly", "Hussein", ""], ["Mohamed", "Abdelmonem", ""]]}, {"id": "2009.12326", "submitter": "Yuxuan Zhao", "authors": "Yuxuan Zhao, Eric Landgrebe, Eliot Shekhtman and Madeleine Udell", "title": "Online Missing Value Imputation and Correlation Change Detection for\n  Mixed-type Data via Gaussian Copula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data science algorithms require complete observations, yet many datasets\ncontain missing values. Hence missing value imputation is crucial for\nreal-world data science workflows. For practical applications, imputation\nalgorithms should produce imputations that match the true data distribution,\nhandle mixed data containing ordinal, boolean, and continuous variables, and\nscale to large datasets. In this work we develop a new online imputation\nalgorithm for mixed data using the Gaussian copula. The online Gaussian copula\nmodel produces meets all the desiderata: its imputations match the data\ndistribution even for mixed data, and it scales well, achieving up to an order\nof magnitude speedup over its offline counterpart. The online algorithm can\nhandle streaming or sequential data and can adapt to a changing data\ndistribution. By fitting the copula model to online data, we also provide a new\nmethod to detect a change in the correlational structure of multivariate mixed\ndata with missing values. Experimental results on synthetic and real world data\nvalidate the performance of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:27:47 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhao", "Yuxuan", ""], ["Landgrebe", "Eric", ""], ["Shekhtman", "Eliot", ""], ["Udell", "Madeleine", ""]]}, {"id": "2009.12355", "submitter": "Zhi Li", "authors": "Gan Zhou, Zhi Li, Meng Fu, Yanjun Feng, Xingyao Wang and Chengwei\n  Huang", "title": "Sequence-to-Sequence Load Disaggregation Using Multi-Scale Residual\n  Neural Network", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased demand on economy and efficiency of measurement\ntechnology, Non-Intrusive Load Monitoring (NILM) has received more and more\nattention as a cost-effective way to monitor electricity and provide feedback\nto users. Deep neural networks has been shown a great potential in the field of\nload disaggregation. In this paper, firstly, a new convolutional model based on\nresidual blocks is proposed to avoid the degradation problem which traditional\nnetworks more or less suffer from when network layers are increased in order to\nlearn more complex features. Secondly, we propose dilated convolution to\ncurtail the excessive quantity of model parameters and obtain bigger receptive\nfield, and multi-scale structure to learn mixed data features in a more\ntargeted way. Thirdly, we give details about generating training and test set\nunder certain rules. Finally, the algorithm is tested on real-house public\ndataset, UK-DALE, with three existing neural networks. The results are compared\nand analysed, the proposed model shows improvements on F1 score, MAE as well as\nmodel complexity across different appliances.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 17:41:28 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhou", "Gan", ""], ["Li", "Zhi", ""], ["Fu", "Meng", ""], ["Feng", "Yanjun", ""], ["Wang", "Xingyao", ""], ["Huang", "Chengwei", ""]]}, {"id": "2009.12360", "submitter": "Dan Li", "authors": "Dan Li, Paritosh Ramanan, Nagi Gebraeel, and Kamran Paynabar", "title": "Deep Learning based Covert Attack Identification for Industrial Control\n  Systems", "comments": "Accepted in IEEE ICMLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity of Industrial Control Systems (ICS) is drawing significant\nconcerns as data communication increasingly leverages wireless networks. A lot\nof data-driven methods were developed for detecting cyberattacks, but few are\nfocused on distinguishing them from equipment faults. In this paper, we develop\na data-driven framework that can be used to detect, diagnose, and localize a\ntype of cyberattack called covert attacks on smart grids. The framework has a\nhybrid design that combines an autoencoder, a recurrent neural network (RNN)\nwith a Long-Short-Term-Memory (LSTM) layer, and a Deep Neural Network (DNN).\nThis data-driven framework considers the temporal behavior of a generic\nphysical system that extracts features from the time series of the sensor\nmeasurements that can be used for detecting covert attacks, distinguishing them\nfrom equipment faults, as well as localize the attack/fault. We evaluate the\nperformance of the proposed method through a realistic simulation study on the\nIEEE 14-bus model as a typical example of ICS. We compare the performance of\nthe proposed method with the traditional model-based method to show its\napplicability and efficacy.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 17:48:43 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Li", "Dan", ""], ["Ramanan", "Paritosh", ""], ["Gebraeel", "Nagi", ""], ["Paynabar", "Kamran", ""]]}, {"id": "2009.12362", "submitter": "Xiaojun Chang", "authors": "Caixia Yan, Xiaojun Chang, Minnan Luo, Qinghua Zheng, Xiaoqin Zhang,\n  Zhihui Li and Feiping Nie", "title": "Self-Weighted Robust LDA for Multiclass Classification with Edge Classes", "comments": "17 pages, has been accepted by ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear discriminant analysis (LDA) is a popular technique to learn the most\ndiscriminative features for multi-class classification. A vast majority of\nexisting LDA algorithms are prone to be dominated by the class with very large\ndeviation from the others, i.e., edge class, which occurs frequently in\nmulti-class classification. First, the existence of edge classes often makes\nthe total mean biased in the calculation of between-class scatter matrix.\nSecond, the exploitation of l2-norm based between-class distance criterion\nmagnifies the extremely large distance corresponding to edge class. In this\nregard, a novel self-weighted robust LDA with l21-norm based pairwise\nbetween-class distance criterion, called SWRLDA, is proposed for multi-class\nclassification especially with edge classes. SWRLDA can automatically avoid the\noptimal mean calculation and simultaneously learn adaptive weights for each\nclass pair without setting any additional parameter. An efficient re-weighted\nalgorithm is exploited to derive the global optimum of the challenging l21-norm\nmaximization problem. The proposed SWRLDA is easy to implement, and converges\nfast in practice. Extensive experiments demonstrate that SWRLDA performs\nfavorably against other compared methods on both synthetic and real-world\ndatasets, while presenting superior computational efficiency in comparison with\nother techniques.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:32:55 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Yan", "Caixia", ""], ["Chang", "Xiaojun", ""], ["Luo", "Minnan", ""], ["Zheng", "Qinghua", ""], ["Zhang", "Xiaoqin", ""], ["Li", "Zhihui", ""], ["Nie", "Feiping", ""]]}, {"id": "2009.12368", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Generate Novel Molecules With Target Properties Using Conditional\n  Generative Models", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug discovery using deep learning has attracted a lot of attention of late\nas it has obvious advantages like higher efficiency, less manual guessing and\nfaster process time. In this paper, we present a novel neural network for\ngenerating small molecules similar to the ones in the training set. Our network\nconsists of an encoder made up of bi-GRU layers for converting the input\nsamples to a latent space, predictor for enhancing the capability of encoder\nmade up of 1D-CNN layers and a decoder comprised of uni-GRU layers for\nreconstructing the samples from the latent space representation. Condition\nvector in latent space is used for generating molecules with the desired\nproperties. We present the loss functions used for training our network,\nexperimental details and property prediction metrics. Our network outperforms\nprevious methods using Molecular weight, LogP and Quantitative Estimation of\nDrug-likeness as the evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 18:59:26 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2009.12406", "submitter": "Utkarsh Sarawgi", "authors": "Utkarsh Sarawgi, Wazeer Zulfikar, Rishab Khincha, Pattie Maes", "title": "Why have a Unified Predictive Uncertainty? Disentangling it using Deep\n  Split Ensembles", "comments": "9 pages including references, + 10 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding and quantifying uncertainty in black box Neural Networks (NNs)\nis critical when deployed in real-world settings such as healthcare. Recent\nworks using Bayesian and non-Bayesian methods have shown how a unified\npredictive uncertainty can be modelled for NNs. Decomposing this uncertainty to\ndisentangle the granular sources of heteroscedasticity in data provides rich\ninformation about its underlying causes. We propose a conceptually simple\nnon-Bayesian approach, deep split ensemble, to disentangle the predictive\nuncertainties using a multivariate Gaussian mixture model. The NNs are trained\nwith clusters of input features, for uncertainty estimates per cluster. We\nevaluate our approach on a series of benchmark regression datasets, while also\ncomparing with unified uncertainty methods. Extensive analyses using dataset\nshits and empirical rule highlight our inherently well-calibrated models. Our\nwork further demonstrates its applicability in a multi-modal setting using a\nbenchmark Alzheimer's dataset and also shows how deep split ensembles can\nhighlight hidden modality-specific biases. The minimal changes required to NNs\nand the training procedure, and the high flexibility to group features into\nclusters makes it readily deployable and useful. The source code is available\nat https://github.com/wazeerzulfikar/deep-split-ensembles\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:15:26 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sarawgi", "Utkarsh", ""], ["Zulfikar", "Wazeer", ""], ["Khincha", "Rishab", ""], ["Maes", "Pattie", ""]]}, {"id": "2009.12408", "submitter": "Mads Vinding", "authors": "Mads Sloth Vinding, Christoph Stefan Aigner, Sebastian Schmitter,\n  Torben Ellegaard Lund", "title": "DeepControl: 2D RF pulses facilitating $B_1^+$ inhomogeneity and $B_0$\n  off-resonance compensation in vivo at 7T", "comments": "5+2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: Rapid 2D RF pulse design with subject specific $B_1^+$ inhomogeneity\nand $B_0$ off-resonance compensation at 7 T predicted from convolutional neural\nnetworks is presented.\n  Methods: The convolution neural network was trained on half a million\nsingle-channel transmit, 2D RF pulses optimized with an optimal control method\nusing artificial 2D targets, $B_1^+$ and $B_0$ maps. Predicted pulses were\ntested in a phantom and in vivo at 7 T with measured $B_1^+$ and $B_0$ maps\nfrom a high-resolution GRE sequence.\n  Results: Pulse prediction by the trained convolutional neural network was\ndone on the fly during the MR session in approximately 9 ms for multiple hand\ndrawn ROIs and the measured $B_1^+$ and $B_0$ maps. Compensation of $B_1^+$\ninhomogeneity and $B_0$ off-resonances has been confirmed in the phantom and in\nvivo experiments. The reconstructed image data agrees well with the simulations\nusing the acquired $B_1^+$ and $B_0$ maps and the 2D RF pulse predicted by the\nconvolutional neural networks is as good as the conventional RF pulse obtained\nby optimal control.\n  Conclusion: The proposed convolutional neural network based 2D RF pulse\ndesign method predicts 2D RF pulses with an excellent excitation pattern and\ncompensated $B_1^+$ and $B_0$ variations at 7 T. The rapid 2D RF pulse\nprediction (9 ms) enables subject-specific high-quality 2D RF pulses without\nthe need to run lengthy optimizations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:34:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Vinding", "Mads Sloth", ""], ["Aigner", "Christoph Stefan", ""], ["Schmitter", "Sebastian", ""], ["Lund", "Torben Ellegaard", ""]]}, {"id": "2009.12415", "submitter": "Haruna Isah", "authors": "Ruoran Liu, Haruna Isah, Farhana Zulkernine", "title": "A Big Data Lake for Multilevel Streaming Analytics", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large organizations are seeking to create new architectures and scalable\nplatforms to effectively handle data management challenges due to the explosive\nnature of data rarely seen in the past. These data management challenges are\nlargely posed by the availability of streaming data at high velocity from\nvarious sources in multiple formats. The changes in data paradigm have led to\nthe emergence of new data analytics and management architecture. This paper\nfocuses on storing high volume, velocity and variety data in the raw formats in\na data storage architecture called a data lake. First, we present our study on\nthe limitations of traditional data warehouses in handling recent changes in\ndata paradigms. We discuss and compare different open source and commercial\nplatforms that can be used to develop a data lake. We then describe our\nend-to-end data lake design and implementation approach using the Hadoop\nDistributed File System (HDFS) on the Hadoop Data Platform (HDP). Finally, we\npresent a real-world data lake development use case for data stream ingestion,\nstaging, and multilevel streaming analytics which combines structured and\nunstructured data. This study can serve as a guide for individuals or\norganizations planning to implement a data lake solution for their use cases.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:57:21 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Ruoran", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""]]}, {"id": "2009.12419", "submitter": "Mikhail Romanov", "authors": "Mikhail Romanov, Nikolay Patatkin, Anna Vorontsova, Sergey Nikolenko,\n  Anton Konushin, Dmitry Senyushkin", "title": "Towards General Purpose Geometry-Preserving Single-View Depth Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-view depth estimation (SVDE) plays a crucial role in scene\nunderstanding for AR applications, 3D modeling, and robotics, providing the\ngeometry of a scene based on a single image. Recent works have shown that a\nsuccessful solution strongly relies on the diversity and volume of training\ndata. This data can be sourced from stereo movies and photos. However, they do\nnot provide geometrically complete depth maps (as disparities contain unknown\nshift value). Therefore, existing models trained on this data are not able to\nrecover correct 3D representations. Our work shows that a model trained on this\ndata along with conventional datasets can gain accuracy while predicting\ncorrect scene geometry. Surprisingly, only a small portion of geometrically\ncorrect depth maps are required to train a model that performs equally to a\nmodel trained on the full geometrically correct dataset. After that, we train\ncomputationally efficient models on a mixture of datasets using the proposed\nmethod. Through quantitative comparison on completely unseen datasets and\nqualitative comparison of 3D point clouds, we show that our model defines the\nnew state of the art in general-purpose SVDE.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:06:13 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 20:30:35 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Romanov", "Mikhail", ""], ["Patatkin", "Nikolay", ""], ["Vorontsova", "Anna", ""], ["Nikolenko", "Sergey", ""], ["Konushin", "Anton", ""], ["Senyushkin", "Dmitry", ""]]}, {"id": "2009.12421", "submitter": "Victor Prokhorov", "authors": "Victor Prokhorov, Yingzhen Li, Ehsan Shareghi, Nigel Collier", "title": "Learning Sparse Sentence Encoding without Supervision: An Exploration of\n  Sparsity in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been long known that sparsity is an effective inductive bias for\nlearning efficient representation of data in vectors with fixed dimensionality,\nand it has been explored in many areas of representation learning. Of\nparticular interest to this work is the investigation of the sparsity within\nthe VAE framework which has been explored a lot in the image domain, but has\nbeen lacking even a basic level of exploration in NLP. Additionally, NLP is\nalso lagging behind in terms of learning sparse representations of large units\nof text e.g., sentences. We use the VAEs that induce sparse latent\nrepresentations of large units of text to address the aforementioned\nshortcomings. First, we move in this direction by measuring the success of\nunsupervised state-of-the-art (SOTA) and other strong VAE-based sparsification\nbaselines for text and propose a hierarchical sparse VAE model to address the\nstability issue of SOTA. Then, we look at the implications of sparsity on text\nclassification across 3 datasets, and highlight a link between performance of\nsparse latent representations on downstream tasks and its ability to encode\ntask-related information.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:08:32 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 23:43:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Prokhorov", "Victor", ""], ["Li", "Yingzhen", ""], ["Shareghi", "Ehsan", ""], ["Collier", "Nigel", ""]]}, {"id": "2009.12430", "submitter": "Saeed Ranjbar Alvar", "authors": "Saeed Ranjbar Alvar and Ivan V. Baji\\'c", "title": "Pareto-Optimal Bit Allocation for Collaborative Intelligence", "comments": null, "journal-ref": "IEEE Trans. Image Processing, vol. 30, pp. 3348-3361, Feb. 2021", "doi": "10.1109/TIP.2021.3060875", "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies, collaborative intelligence (CI) has emerged as a promising\nframework for deployment of Artificial Intelligence (AI)-based services on\nmobile/edge devices. In CI, the AI model (a deep neural network) is split\nbetween the edge and the cloud, and intermediate features are sent from the\nedge sub-model to the cloud sub-model. In this paper, we study bit allocation\nfor feature coding in multi-stream CI systems. We model task distortion as a\nfunction of rate using convex surfaces similar to those found in\ndistortion-rate theory. Using such models, we are able to provide closed-form\nbit allocation solutions for single-task systems and scalarized multi-task\nsystems. Moreover, we provide analytical characterization of the full Pareto\nset for 2-stream k-task systems, and bounds on the Pareto set for 3-stream\n2-task systems. Analytical results are examined on a variety of DNN models from\nthe literature to demonstrate wide applicability of the results\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:48:33 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 23:41:16 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Alvar", "Saeed Ranjbar", ""], ["Baji\u0107", "Ivan V.", ""]]}, {"id": "2009.12443", "submitter": "Fazeleh Hoseini", "authors": "Fazeleh S.Hoseini, Sadegh Rahrovani, Morteza Haghir Chehreghani", "title": "A Generic Framework for Clustering Vehicle Motion Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of autonomous vehicles requires having access to a large\namount of data in the concerning driving scenarios. However, manual annotation\nof such driving scenarios is costly and subject to the errors in the rule-based\ntrajectory labeling systems. To address this issue, we propose an effective\nnon-parametric trajectory clustering framework consisting of five stages: (1)\naligning trajectories and quantifying their pairwise temporal dissimilarities,\n(2) embedding the trajectory-based dissimilarities into a vector space, (3)\nextracting transitive relations, (4) embedding the transitive relations into a\nnew vector space, and (5) clustering the trajectories with an optimal number of\nclusters. We investigate and evaluate the proposed framework on a challenging\nreal-world dataset consisting of annotated trajectories. We observe that the\nproposed framework achieves promising results, despite the complexity caused by\nhaving trajectories of varying length. Furthermore, we extend the framework to\nvalidate the augmentation of the real dataset with synthetic data generated by\na Generative Adversarial Network (GAN) where we examine whether the generated\ntrajectories are consistent with the true underlying clusters.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 21:46:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Hoseini", "Fazeleh S.", ""], ["Rahrovani", "Sadegh", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2009.12462", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Symbolic Relational Deep Reinforcement Learning based on Graph Neural\n  Networks", "comments": "RL4RealLife @ ICML2021; code available at\n  https://github.com/jaromiru/sr-drl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on reinforcement learning (RL) in relational problems that are\nnaturally defined in terms of objects, their relations, and manipulations.\nThese problems are characterized by variable state and action spaces, and\nfinding a fixed-length representation, required by most existing RL methods, is\ndifficult, if not impossible. We present a deep RL framework based on graph\nneural networks and auto-regressive policy decomposition that naturally works\nwith these problems and is completely domain-independent. We demonstrate the\nframework in three very distinct domains and we report the method's competitive\nperformance and impressive zero-shot generalization over different problem\nsizes. In goal-oriented BlockWorld, we demonstrate multi-parameter actions with\npre-conditions. In SysAdmin, we show how to select multiple objects\nsimultaneously. In the classical planning domain of Sokoban, the method trained\nexclusively on 10x10 problems with three boxes solves 89% of 15x15 problems\nwith five boxes.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 22:41:04 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 20:02:52 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 14:05:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "2009.12463", "submitter": "Bruno Barbosa", "authors": "Bruno Henrique Groenner Barbosa, Nan Xu, Hassan Askari, Amir Khajepour", "title": "Lateral Force Prediction using Gaussian Process Regression for\n  Intelligent Tire Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamic behavior of tires and their interactions with road\nplays an important role in designing integrated vehicle control strategies.\nAccordingly, having access to reliable information about the tire-road\ninteractions through tire embedded sensors is very demanding for developing\nenhanced vehicle control systems. Thus, the main objectives of the present\nresearch work are i. to analyze data from an experimental accelerometer-based\nintelligent tire acquired over a wide range of maneuvers, with different\nvertical loads, velocities, and high slip angles; and ii. to develop a lateral\nforce predictor based on a machine learning tool, more specifically the\nGaussian Process Regression (GPR) technique. It is delineated that the proposed\nintelligent tire system can provide reliable information about the tire-road\ninteractions even in the case of high slip angles. Besides, the lateral forces\nmodel based on GPR can predict forces with acceptable accuracy and provide\nlevel of uncertainties that can be very useful for designing vehicle control\nstrategies.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 22:41:24 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Barbosa", "Bruno Henrique Groenner", ""], ["Xu", "Nan", ""], ["Askari", "Hassan", ""], ["Khajepour", "Amir", ""]]}, {"id": "2009.12469", "submitter": "Hoda Eldardiry", "authors": "Hongjie Chen, Ryan A. Rossi, Kanak Mahadik, and Hoda Eldardiry", "title": "A Context Integrated Relational Spatio-Temporal Model for Demand and\n  Supply Forecasting", "comments": "9 pages, 6 figures, submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for demand forecasting only focus on modeling the\ntemporal dependency. However, forecasting on spatio-temporal data requires\nmodeling of complex nonlinear relational and spatial dependencies. In addition,\ndynamic contextual information can have a significant impact on the demand\nvalues, and therefore needs to be captured. For example, in a bike-sharing\nsystem, bike usage can be impacted by weather. Existing methods assume the\ncontextual impact is fixed. However, we note that the contextual impact evolves\nover time. We propose a novel context integrated relational model, Context\nIntegrated Graph Neural Network (CIGNN), which leverages the temporal,\nrelational, spatial, and dynamic contextual dependencies for multi-step ahead\ndemand forecasting. Our approach considers the demand network over various\ngeographical locations and represents the network as a graph. We define a\ndemand graph, where nodes represent demand time-series, and context graphs (one\nfor each type of context), where nodes represent contextual time-series.\nAssuming that various contexts evolve and have a dynamic impact on the\nfluctuation of demand, our proposed CIGNN model employs a fusion mechanism that\njointly learns from all available types of contextual information. To the best\nof our knowledge, this is the first approach that integrates dynamic contexts\nwith graph neural networks for spatio-temporal demand forecasting, thereby\nincreasing prediction accuracy. We present empirical results on two real-world\ndatasets, demonstrating that CIGNN consistently outperforms state-of-the-art\nbaselines, in both periodic and irregular time-series networks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 22:55:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Hongjie", ""], ["Rossi", "Ryan A.", ""], ["Mahadik", "Kanak", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12478", "submitter": "Joshua Galita", "authors": "Sumeet Menon (1), Joshua Galita (1), David Chapman (1), Aryya\n  Gangopadhyay (1), Jayalakshmi Mangalagiri (1), Phuong Nguyen (1), Yaacov\n  Yesha (1), Yelena Yesha (1), Babak Saboury (1 and 2), Michael Morris (1, 2,\n  and 3) ((1) University of Maryland, Baltimore County, (2) National Institutes\n  of Health Clinical Center, (3) Networking Health)", "title": "Generating Realistic COVID19 X-rays with a Mean Teacher + Transfer\n  Learning GAN", "comments": "10 pages, 11 figures, 2 tables; Submitted to IEEE BigData 2020\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 is a novel infectious disease responsible for over 800K deaths\nworldwide as of August 2020. The need for rapid testing is a high priority and\nalternative testing strategies including X-ray image classification are a\npromising area of research. However, at present, public datasets for COVID19\nx-ray images have low data volumes, making it challenging to develop accurate\nimage classifiers. Several recent papers have made use of Generative\nAdversarial Networks (GANs) in order to increase the training data volumes. But\nrealistic synthetic COVID19 X-rays remain challenging to generate. We present a\nnovel Mean Teacher + Transfer GAN (MTT-GAN) that generates COVID19 chest X-ray\nimages of high quality. In order to create a more accurate GAN, we employ\ntransfer learning from the Kaggle Pneumonia X-Ray dataset, a highly relevant\ndata source orders of magnitude larger than public COVID19 datasets.\nFurthermore, we employ the Mean Teacher algorithm as a constraint to improve\nstability of training. Our qualitative analysis shows that the MTT-GAN\ngenerates X-ray images that are greatly superior to a baseline GAN and visually\ncomparable to real X-rays. Although board-certified radiologists can\ndistinguish MTT-GAN fakes from real COVID19 X-rays. Quantitative analysis shows\nthat MTT-GAN greatly improves the accuracy of both a binary COVID19 classifier\nas well as a multi-class Pneumonia classifier as compared to a baseline GAN.\nOur classification accuracy is favourable as compared to recently reported\nresults in the literature for similar binary and multi-class COVID19 screening\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 00:05:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Menon", "Sumeet", "", "1 and 2"], ["Galita", "Joshua", "", "1 and 2"], ["Chapman", "David", "", "1 and 2"], ["Gangopadhyay", "Aryya", "", "1 and 2"], ["Mangalagiri", "Jayalakshmi", "", "1 and 2"], ["Nguyen", "Phuong", "", "1 and 2"], ["Yesha", "Yaacov", "", "1 and 2"], ["Yesha", "Yelena", "", "1 and 2"], ["Saboury", "Babak", "", "1 and 2"], ["Morris", "Michael", "", "1, 2,\n  and 3"]]}, {"id": "2009.12480", "submitter": "David Burth Kurka", "authors": "David Burth Kurka and Deniz G\\\"und\\\"uz", "title": "Bandwidth-Agile Image Transmission with Deep Joint Source-Channel Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.IV eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose deep learning based communication methods for adaptive-bandwidth\ntransmission of images over wireless channels. We consider the scenario in\nwhich images are transmitted progressively in layers over time or frequency,\nand such layers can be aggregated by receivers in order to increase the quality\nof their reconstructions. We investigate two scenarios, one in which the layers\nare sent sequentially, and incrementally contribute to the refinement of a\nreconstruction, and another in which the layers are independent and can be\nretrieved in any order. Those scenarios correspond to the well known problems\nof \\textit{successive refinement} and \\textit{multiple descriptions},\nrespectively, in the context of joint source-channel coding (JSCC). We propose\nDeepJSCC-$l$, an innovative solution that uses convolutional autoencoders, and\npresent three architectures with different complexity trade-offs. To the best\nof our knowledge, this is the first practical multiple-description JSCC scheme\ndeveloped and tested for practical information sources and channels. Numerical\nresults show that DeepJSCC-$l$ can learn to transmit the source progressively\nwith negligible losses in the end-to-end performance compared with a single\ntransmission. Moreover, DeepJSCC-$l$ has comparable performance with state of\nthe art digital progressive transmission schemes in the challenging low\nsignal-to-noise ratio (SNR) and small bandwidth regimes, with the additional\nadvantage of graceful degradation with channel SNR.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 00:11:50 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 00:37:10 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kurka", "David Burth", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "2009.12494", "submitter": "Ziwen Zhuang", "authors": "Jianren Wang, Ziwen Zhuang, Hang Zhao", "title": "SEMI: Self-supervised Exploration via Multisensory Incongruity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient exploration is a long-standing problem in reinforcement learning.\nIn this work, we introduce a self-supervised exploration policy by\nincentivizing the agent to maximize multisensory incongruity, which can be\nmeasured in two aspects: perception incongruity and action incongruity. The\nformer represents the uncertainty in multisensory fusion model, while the\nlatter represents the uncertainty in an agent's policy. Specifically, an\nalignment predictor is trained to detect whether multiple sensory inputs are\naligned, the error of which is used to measure perception incongruity. The\npolicy takes the multisensory observations with sensory-wise dropout as input\nand outputs actions for exploration. The variance of actions is further used to\nmeasure action incongruity. Our formulation allows the agent to learn skills by\nexploring in a self-supervised manner without any external rewards. Besides,\nour method enables the agent to learn a compact multimodal representation from\nhard examples, which further improves the sample efficiency of our policy\nlearning. We demonstrate the efficacy of this formulation across a variety of\nbenchmark environments including object manipulation and audio-visual games.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 01:20:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Jianren", ""], ["Zhuang", "Ziwen", ""], ["Zhao", "Hang", ""]]}, {"id": "2009.12498", "submitter": "Mark Greaves", "authors": "Gianluca Longoni (1), Ryan LaMothe (1), Jeremy Teuton (1), Mark\n  Greaves (1), Nicole Nichols (1), William Smith (1) ((1) Pacific Northwest\n  National Laboratory)", "title": "Machine Learning Algorithms for Active Monitoring of High Performance\n  Computing as a Service (HPCaaS) Cloud Environments", "comments": "9 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing provides ubiquitous and on-demand access to vast\nreconfigurable resources that can meet any computational need. Many service\nmodels are available, but the Infrastructure as a Service (IaaS) model is\nparticularly suited to operate as a high performance computing (HPC) platform,\nby networking large numbers of cloud computing nodes. We used the Pacific\nNorthwest National Laboratory (PNNL) cloud computing environment to perform our\nexperiments. A number of cloud computing providers such as Amazon Web Services,\nMicrosoft Azure, or IBM Cloud, offer flexible and scalable computing resources.\nThis paper explores the viability identifying types of engineering applications\nrunning on a cloud infrastructure configured as an HPC platform using privacy\npreserving features as input to statistical models. The engineering\napplications considered in this work include MCNP6, a radiation transport code\ndeveloped by Los Alamos National Laboratory, OpenFOAM, an open source\ncomputational fluid dynamics code, and CADO-NFS, a numerical implementation of\nthe general number field sieve algorithm used for prime number factorization.\nOur experiments use the OpenStack cloud management tool to create a cloud HPC\nenvironment and the privacy preserving Ceilometer billing meters as\nclassification features to demonstrate identification of these applications.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 01:29:19 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Longoni", "Gianluca", ""], ["LaMothe", "Ryan", ""], ["Teuton", "Jeremy", ""], ["Greaves", "Mark", ""], ["Nichols", "Nicole", ""], ["Smith", "William", ""]]}, {"id": "2009.12501", "submitter": "Yassine Yaakoubi", "authors": "Yassine Yaakoubi, Fran\\c{c}ois Soumis, Simon Lacoste-Julien", "title": "Flight-connection Prediction for Airline Crew Scheduling to Construct\n  Initial Clusters for OR Optimizer", "comments": "First publication on the \"Cahiers du GERAD\" series in April 2019", "journal-ref": null, "doi": null, "report-no": "G-2019-26", "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a case study of using machine learning classification algorithms\nto initialize a large-scale commercial solver (GENCOL) based on column\ngeneration in the context of the airline crew pairing problem, where small\nsavings of as little as 1% translate to increasing annual revenue by dozens of\nmillions of dollars in a large airline. Under the imitation learning framework,\nwe focus on the problem of predicting the next connecting flight of a crew,\nframed as a multiclass classification problem trained from historical data, and\ndesign an adapted neural network approach that achieves high accuracy (99.7%\noverall or 82.5% on harder instances). We demonstrate the usefulness of our\napproach by using simple heuristics to combine the flight-connection\npredictions to form initial crew-pairing clusters that can be fed in the GENCOL\nsolver, yielding a 10x speed improvement and up to 0.2% cost saving.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 01:32:07 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 22:30:17 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Yaakoubi", "Yassine", ""], ["Soumis", "Fran\u00e7ois", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2009.12511", "submitter": "Guangyu Xi", "authors": "Guangyu Xi, Chao Tao and Yuan Zhou", "title": "Near-Optimal MNL Bandits Under Risk Criteria", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study MNL bandits, which is a variant of the traditional multi-armed\nbandit problem, under risk criteria. Unlike the ordinary expected revenue, risk\ncriteria are more general goals widely used in industries and bussiness. We\ndesign algorithms for a broad class of risk criteria, including but not limited\nto the well-known conditional value-at-risk, Sharpe ratio and entropy risk, and\nprove that they suffer a near-optimal regret. As a complement, we also conduct\nexperiments with both synthetic and real data to show the empirical performance\nof our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 03:24:40 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 04:24:36 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 02:22:23 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Xi", "Guangyu", ""], ["Tao", "Chao", ""], ["Zhou", "Yuan", ""]]}, {"id": "2009.12517", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Thanh Vu and Tu Dinh Nguyen and Dinh Phung", "title": "QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and effective embedding model, named QuatRE, to learn\nquaternion embeddings for entities and relations in knowledge graphs. QuatRE\naims to enhance correlations between head and tail entities given a relation\nwithin the Quaternion space with Hamilton product. QuatRE achieves this by\nassociating each relation with two quaternion vectors which are used to rotate\nthe quaternion embeddings of the head and tail entities, respectively. To\nobtain the triple score, QuatRE rotates the rotated embedding of the head\nentity using the normalized quaternion embedding of the relation, followed by a\nquaternion-inner product with the rotated embedding of the tail entity.\nExperimental results show that our QuatRE outperforms up-to-date embedding\nmodels on well-known benchmark datasets for knowledge graph completion.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 04:44:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "2009.12518", "submitter": "Serban Stan", "authors": "Serban Stan, Mohammad Rostami", "title": "Unsupervised Model Adaptation for Continual Semantic Segmentation", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm for adapting a semantic segmentation model that is\ntrained using a labeled source domain to generalize well in an unlabeled target\ndomain. A similar problem has been studied extensively in the unsupervised\ndomain adaptation (UDA) literature, but existing UDA algorithms require access\nto both the source domain labeled data and the target domain unlabeled data for\ntraining a domain agnostic semantic segmentation model. Relaxing this\nconstraint enables a user to adapt pretrained models to generalize in a target\ndomain, without requiring access to source data. To this end, we learn a\nprototypical distribution for the source domain in an intermediate embedding\nspace. This distribution encodes the abstract knowledge that is learned from\nthe source domain. We then use this distribution for aligning the target domain\ndistribution with the source domain distribution in the embedding space. We\nprovide theoretical analysis and explain conditions under which our algorithm\nis effective. Experiments on benchmark adaptation task demonstrate our method\nachieves competitive performance even compared with joint UDA approaches.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 04:55:50 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 08:09:52 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Stan", "Serban", ""], ["Rostami", "Mohammad", ""]]}, {"id": "2009.12525", "submitter": "Xiaolong Zhong", "authors": "Xiaolong Zhong and Zhong Yin", "title": "Cross-individual Recognition of Emotions by a Dynamic Entropy based on\n  Pattern Learning with EEG features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of the electroencephalogram (EEG) and machine learning approaches to\nrecognize emotions can facilitate affective human computer interactions.\nHowever, the type of EEG data constitutes an obstacle for cross-individual EEG\nfeature modelling and classification. To address this issue, we propose a\ndeep-learning framework denoted as a dynamic entropy-based pattern learning\n(DEPL) to abstract informative indicators pertaining to the neurophysiological\nfeatures among multiple individuals. DEPL enhanced the capability of\nrepresentations generated by a deep convolutional neural network by modelling\nthe interdependencies between the cortical locations of dynamical entropy based\nfeatures. The effectiveness of the DEPL has been validated with two public\ndatabases, commonly referred to as the DEAP and MAHNOB-HCI multimodal tagging\ndatabases. Specifically, the leave one subject out training and testing\nparadigm has been applied. Numerous experiments on EEG emotion recognition\ndemonstrate that the proposed DEPL is superior to those traditional machine\nlearning (ML) methods, and could learn between electrode dependencies w.r.t.\ndifferent emotions, which is meaningful for developing the effective\nhuman-computer interaction systems by adapting to human emotions in the real\nworld applications.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 07:22:07 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 08:03:28 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Zhong", "Xiaolong", ""], ["Yin", "Zhong", ""]]}, {"id": "2009.12546", "submitter": "Alfred Sch\\\"ottl", "authors": "Alfred Sch\\\"ottl", "title": "A light-weight method to foster the (Grad)CAM interpretability and\n  explainability of classification networks", "comments": "2020 10th International Conference on Advanced Computer Information\n  Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a light-weight method which allows to improve the explainability\nof localized classification networks. The method considers (Grad)CAM maps\nduring the training process by modification of the training loss and does not\nrequire additional structural elements. It is demonstrated that the (Grad)CAM\ninterpretability, as measured by several indicators, can be improved in this\nway. Since the method shall be applicable on embedded systems and on standard\ndeeper architectures, it essentially takes advantage of second order\nderivatives during the training and does not require additional model layers.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 09:15:28 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sch\u00f6ttl", "Alfred", ""]]}, {"id": "2009.12562", "submitter": "Ferdinando Fioretto", "authors": "Cuong Tran, Ferdinando Fioretto, Pascal Van Hentenryck", "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical concern in data-driven decision making is to build models whose\noutcomes do not discriminate against some demographic groups, including gender,\nethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of\nthe sensitive attributes is essential, while, in practice, these attributes may\nnot be available due to legal and ethical requirements. To address this\nchallenge, this paper studies a model that protects the privacy of the\nindividuals sensitive information while also allowing it to learn\nnon-discriminatory predictors. The method relies on the notion of differential\nprivacy and the use of Lagrangian duality to design neural networks that can\naccommodate fairness constraints while guaranteeing the privacy of sensitive\nattributes. The paper analyses the tension between accuracy, privacy, and\nfairness and the experimental evaluation illustrates the benefits of the\nproposed model on several prediction tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 10:50:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tran", "Cuong", ""], ["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2009.12565", "submitter": "Shashwat Aggarwal", "authors": "Shashwat Aggarwal, Ramesh Singh", "title": "Metaphor Detection using Deep Contextualized Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metaphors are ubiquitous in natural language, and their detection plays an\nessential role in many natural language processing tasks, such as language\nunderstanding, sentiment analysis, etc. Most existing approaches for metaphor\ndetection rely on complex, hand-crafted and fine-tuned feature pipelines, which\ngreatly limit their applicability. In this work, we present an end-to-end\nmethod composed of deep contextualized word embeddings, bidirectional LSTMs and\nmulti-head attention mechanism to address the task of automatic metaphor\ndetection. Our method, unlike many other existing approaches, requires only the\nraw text sequences as input features to detect the metaphoricity of a phrase.\nWe compare the performance of our method against the existing baselines on two\nbenchmark datasets, TroFi, and MOH-X respectively. Experimental evaluations\nconfirm the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:00:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aggarwal", "Shashwat", ""], ["Singh", "Ramesh", ""]]}, {"id": "2009.12566", "submitter": "Hmayag Partamian", "authors": "Mohammad Mansour, Fouad Khnaisser and Hmayag Partamian", "title": "An Explainable Model for EEG Seizure Detection based on Connectivity\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy which is characterized by seizures is studied using EEG signals by\nrecording the electrical activity of the brain. Different types of\ncommunication between different parts of the brain are characterized by many\nstate of the art connectivity measures which can be directed and undirected. We\npropose to employ a set of undirected (spectral matrix, the inverse of the\nspectral matrix, coherence, partial coherence, and phaselocking value) and\ndirected features (directed coherence, the partial directed coherence) to learn\na deep neural network that detects whether a particular data window belongs to\na seizure or not, which is a new approach to standard seizure classification.\nTaking our data as a sequence of ten sub-windows, we aim at designing an\noptimal deep learning model using attention, CNN, BiLstm, and fully connected\nlayers. We also compute the relevance using the weights of the learned model\nbased on the activation values of the receptive fields at a particular layer.\nOur best model architecture resulted in 97.03% accuracy using balanced MITBIH\ndata subset. Also, we were able to explain the relevance of each feature across\nall patients. We were able to experimentally validate some of the scientific\nfacts concerning seizures by studying the impact of the contributions of the\nactivations on the decision.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:07:30 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mansour", "Mohammad", ""], ["Khnaisser", "Fouad", ""], ["Partamian", "Hmayag", ""]]}, {"id": "2009.12569", "submitter": "Hongfeng You", "authors": "Hongfeng You, Long Yu, Shengwei Tian, Xiang Ma, Yan Xing and Xiaojie\n  Ma", "title": "DT-Net: A novel network based on multi-directional integrated\n  convolution and threshold convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since medical image data sets contain few samples and singular features,\nlesions are viewed as highly similar to other tissues. The traditional neural\nnetwork has a limited ability to learn features. Even if a host of feature maps\nis expanded to obtain more semantic information, the accuracy of segmenting the\nfinal medical image is slightly improved, and the features are excessively\nredundant. To solve the above problems, in this paper, we propose a novel\nend-to-end semantic segmentation algorithm, DT-Net, and use two new convolution\nstrategies to better achieve end-to-end semantic segmentation of medical\nimages. 1. In the feature mining and feature fusion stage, we construct a\nmulti-directional integrated convolution (MDIC). The core idea is to use the\nmulti-scale convolution to enhance the local multi-directional feature maps to\ngenerate enhanced feature maps and to mine the generated features that contain\nmore semantics without increasing the number of feature maps. 2. We also aim to\nfurther excavate and retain more meaningful deep features reduce a host of\nnoise features in the training process. Therefore, we propose a convolution\nthresholding strategy. The central idea is to set a threshold to eliminate a\nlarge number of redundant features and reduce computational complexity. Through\nthe two strategies proposed above, the algorithm proposed in this paper\nproduces state-of-the-art results on two public medical image datasets. We\nprove in detail that our proposed strategy plays an important role in feature\nmining and eliminating redundant features. Compared with the existing semantic\nsegmentation algorithms, our proposed algorithm has better robustness.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:12:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["You", "Hongfeng", ""], ["Yu", "Long", ""], ["Tian", "Shengwei", ""], ["Ma", "Xiang", ""], ["Xing", "Yan", ""], ["Ma", "Xiaojie", ""]]}, {"id": "2009.12570", "submitter": "Enrico Pomarico", "authors": "Enrico Pomarico, C\\'edric Schmidt, Florian Chays, David Nguyen,\n  Arielle Planchette, Audrey Tissot, Adrien Roux, St\\'ephane Pag\\`es, Laura\n  Batti, Christoph Clausen, Theo Lasser, Aleksandra Radenovic, Bruno\n  Sanguinetti, and J\\'er\\^ome Extermann", "title": "Quantifying the effect of image compression on supervised learning\n  applications in optical microscopy", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive growth of data throughput in optical microscopy has triggered\na widespread use of supervised learning (SL) models running on compressed image\ndatasets for efficient automated analysis. However, since lossy image\ncompression risks to produce unpredictable artifacts, quantifying the effect of\ndata compression on SL applications is of pivotal importance to assess their\nreliability, especially for clinical use. We propose an experimental method to\nevaluate the tolerability of image compression distortions in 2D and 3D cell\nsegmentation SL tasks: predictions on compressed data are compared to the raw\npredictive uncertainty, which is numerically estimated from the raw noise\nstatistics measured through sensor calibration. We show that predictions on\nobject- and image-specific segmentation parameters can be altered by up to 15%\nand more than 10 standard deviations after 16-to-8 bits downsampling or JPEG\ncompression. In contrast, a recently developed lossless compression algorithm\nprovides a prediction spread which is statistically equivalent to that stemming\nfrom raw noise, while providing a compression ratio of up to 10:1. By setting a\nlower bound to the SL predictive uncertainty, our technique can be generalized\nto validate a variety of data analysis pipelines in SL-assisted fields.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:25:57 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Pomarico", "Enrico", ""], ["Schmidt", "C\u00e9dric", ""], ["Chays", "Florian", ""], ["Nguyen", "David", ""], ["Planchette", "Arielle", ""], ["Tissot", "Audrey", ""], ["Roux", "Adrien", ""], ["Pag\u00e8s", "St\u00e9phane", ""], ["Batti", "Laura", ""], ["Clausen", "Christoph", ""], ["Lasser", "Theo", ""], ["Radenovic", "Aleksandra", ""], ["Sanguinetti", "Bruno", ""], ["Extermann", "J\u00e9r\u00f4me", ""]]}, {"id": "2009.12575", "submitter": "Xiaowei Jia", "authors": "Xiaowei Jia, Jacob Zwart, Jeffrey Sadler, Alison Appling, Samantha\n  Oliver, Steven Markstrom, Jared Willard, Shaoming Xu, Michael Steinbach,\n  Jordan Read, and Vipin Kumar", "title": "Physics-Guided Recurrent Graph Networks for Predicting Flow and\n  Temperature in River Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a physics-guided machine learning approach that combines\nadvanced machine learning models and physics-based models to improve the\nprediction of water flow and temperature in river networks. We first build a\nrecurrent graph network model to capture the interactions among multiple\nsegments in the river network. Then we present a pre-training technique which\ntransfers knowledge from physics-based models to initialize the machine\nlearning model and learn the physics of streamflow and thermodynamics. We also\npropose a new loss function that balances the performance over different river\nsegments. We demonstrate the effectiveness of the proposed method in predicting\ntemperature and streamflow in a subset of the Delaware River Basin. In\nparticular, we show that the proposed method brings a 33\\%/14\\% improvement\nover the state-of-the-art physics-based model and 24\\%/14\\% over traditional\nmachine learning models (e.g., Long-Short Term Memory Neural Network) in\ntemperature/streamflow prediction using very sparse (0.1\\%) observation data\nfor training. The proposed method has also been shown to produce better\nperformance when generalized to different seasons or river segments with\ndifferent streamflow ranges.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:46:51 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 18:00:55 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Jia", "Xiaowei", ""], ["Zwart", "Jacob", ""], ["Sadler", "Jeffrey", ""], ["Appling", "Alison", ""], ["Oliver", "Samantha", ""], ["Markstrom", "Steven", ""], ["Willard", "Jared", ""], ["Xu", "Shaoming", ""], ["Steinbach", "Michael", ""], ["Read", "Jordan", ""], ["Kumar", "Vipin", ""]]}, {"id": "2009.12576", "submitter": "Minhae Kwon", "authors": "Minhae Kwon, Saurabh Daptardar, Paul Schrater, Xaq Pitkow", "title": "Inverse Rational Control with Partially Observable Continuous Nonlinear\n  Dynamics", "comments": "NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in neuroscience is how the brain creates an internal\nmodel of the world to guide actions using sequences of ambiguous sensory\ninformation. This is naturally formulated as a reinforcement learning problem\nunder partial observations, where an agent must estimate relevant latent\nvariables in the world from its evidence, anticipate possible future states,\nand choose actions that optimize total expected reward. This problem can be\nsolved by control theory, which allows us to find the optimal actions for a\ngiven system dynamics and objective function. However, animals often appear to\nbehave suboptimally. Why? We hypothesize that animals have their own flawed\ninternal model of the world, and choose actions with the highest expected\nsubjective reward according to that flawed model. We describe this behavior as\nrational but not optimal. The problem of Inverse Rational Control (IRC) aims to\nidentify which internal model would best explain an agent's actions. Our\ncontribution here generalizes past work on Inverse Rational Control which\nsolved this problem for discrete control in partially observable Markov\ndecision processes. Here we accommodate continuous nonlinear dynamics and\ncontinuous actions, and impute sensory observations corrupted by unknown noise\nthat is private to the animal. We first build an optimal Bayesian agent that\nlearns an optimal policy generalized over the entire model space of dynamics\nand subjective rewards using deep reinforcement learning. Crucially, this\nallows us to compute a likelihood over models for experimentally observable\naction trajectories acquired from a suboptimal agent. We then find the model\nparameters that maximize the likelihood using gradient ascent.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:47:48 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:09:41 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Kwon", "Minhae", ""], ["Daptardar", "Saurabh", ""], ["Schrater", "Paul", ""], ["Pitkow", "Xaq", ""]]}, {"id": "2009.12583", "submitter": "J\\\"org Bornschein", "authors": "Jorg Bornschein, Francesco Visin, Simon Osindero", "title": "Small Data, Big Decisions: Model Selection in the Small-Data Regime", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine (ICML 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly overparametrized neural networks can display curiously strong\ngeneralization performance - a phenomenon that has recently garnered a wealth\nof theoretical and empirical research in order to better understand it. In\ncontrast to most previous work, which typically considers the performance as a\nfunction of the model size, in this paper we empirically study the\ngeneralization performance as the size of the training set varies over multiple\norders of magnitude. These systematic experiments lead to some interesting and\npotentially very useful observations; perhaps most notably that training on\nsmaller subsets of the data can lead to more reliable model selection decisions\nwhilst simultaneously enjoying smaller computational costs. Our experiments\nfurthermore allow us to estimate Minimum Description Lengths for common\ndatasets given modern neural network architectures, thereby paving the way for\nprincipled model selection taking into account Occams-razor.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 12:52:56 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bornschein", "Jorg", ""], ["Visin", "Francesco", ""], ["Osindero", "Simon", ""]]}, {"id": "2009.12585", "submitter": "Francisco Nurudin Alvarez Gonzalez", "authors": "Nurudin Alvarez-Gonzalez, Andreas Kaltenbrunner, Vicen\\c{c} G\\'omez", "title": "Inductive Graph Embeddings through Locality Encodings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning embeddings from large-scale networks is an open challenge. Despite\nthe overwhelming number of existing methods, is is unclear how to exploit\nnetwork structure in a way that generalizes easily to unseen nodes, edges or\ngraphs. In this work, we look at the problem of finding inductive network\nembeddings in large networks without domain-dependent node/edge attributes. We\npropose to use a set of basic predefined local encodings as the basis of a\nlearning algorithm. In particular, we consider the degree frequencies at\ndifferent distances from a node, which can be computed efficiently for\nrelatively short distances and a large number of nodes. Interestingly, the\nresulting embeddings generalize well across unseen or distant regions in the\nnetwork, both in unsupervised settings, when combined with language model\nlearning, as well as in supervised tasks, when used as additional features in a\nneural network. Despite its simplicity, this method achieves state-of-the-art\nperformance in tasks such as role detection, link prediction and node\nclassification, and represents an inductive network embedding method directly\napplicable to large unattributed networks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:09:11 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Alvarez-Gonzalez", "Nurudin", ""], ["Kaltenbrunner", "Andreas", ""], ["G\u00f3mez", "Vicen\u00e7", ""]]}, {"id": "2009.12591", "submitter": "Jiayu Shang", "authors": "Du Nan, Jiayu Shang, Yanni Sun", "title": "ProDOMA: improve PROtein DOMAin classification for third-generation\n  sequencing reads using deep learning", "comments": "13 pages, 8 figures (three of them are gourped in Figre. 6)", "journal-ref": "BMC Genomics volume 22, Article number: 251 (2021)", "doi": "10.1186/s12864-021-07468-7", "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: With the development of third-generation sequencing technologies,\npeople are able to obtain DNA sequences with lengths from 10s to 100s of kb.\nThese long reads allow protein domain annotation without assembly, thus can\nproduce important insights into the biological functions of the underlying\ndata. However, the high error rate in third-generation sequencing data raises a\nnew challenge to established domain analysis pipelines. The state-of-the-art\nmethods are not optimized for noisy reads and have shown unsatisfactory\naccuracy of domain classification in third-generation sequencing data. New\ncomputational methods are still needed to improve the performance of domain\nprediction in long noisy reads. Results: In this work, we introduce ProDOMA, a\ndeep learning model that conducts domain classification for third-generation\nsequencing reads. It uses deep neural networks with 3-frame translation\nencoding to learn conserved features from partially correct translations. In\naddition, we formulate our problem as an open-set problem and thus our model\ncan reject unrelated DNA reads such as those from noncoding regions. In the\nexperiments on simulated reads of protein coding sequences and real reads from\nthe human genome, our model outperforms HMMER and DeepFam on protein domain\nclassification. In summary, ProDOMA is a useful end-to-end protein domain\nanalysis tool for long noisy reads without relying on error correction.\nAvailability: The source code and the trained model are freely available at\nhttps://github.com/strideradu/ProDOMA. Contact: yannisun@cityu.edu.hk\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:30:54 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nan", "Du", ""], ["Shang", "Jiayu", ""], ["Sun", "Yanni", ""]]}, {"id": "2009.12602", "submitter": "David Calhas", "authors": "David Calhas and Rui Henriques", "title": "fMRI Multiple Missing Values Imputation Regularized by a Recurrent\n  Denoiser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) is a neuroimaging technique with\npivotal importance due to its scientific and clinical applications. As with any\nwidely used imaging modality, there is a need to ensure the quality of the\nsame, with missing values being highly frequent due to the presence of\nartifacts or sub-optimal imaging resolutions. Our work focus on missing values\nimputation on multivariate signal data. To do so, a new imputation method is\nproposed consisting on two major steps: spatial-dependent signal imputation and\ntime-dependent regularization of the imputed signal. A novel layer, to be used\nin deep learning architectures, is proposed in this work, bringing back the\nconcept of chained equations for multiple imputation. Finally, a recurrent\nlayer is applied to tune the signal, such that it captures its true patterns.\nBoth operations yield an improved robustness against state-of-the-art\nalternatives.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:56:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Calhas", "David", ""], ["Henriques", "Rui", ""]]}, {"id": "2009.12604", "submitter": "Andreea-Ioana Deac", "authors": "Andreea Deac, Pierre-Luc Bacon, Jian Tang", "title": "Graph neural induction of value iteration", "comments": "ICML GRL+ 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning tasks can benefit from explicit planning based on\nan internal model of the environment. Previously, such planning components have\nbeen incorporated through a neural network that partially aligns with the\ncomputational graph of value iteration. Such network have so far been focused\non restrictive environments (e.g. grid-worlds), and modelled the planning\nprocedure only indirectly. We relax these constraints, proposing a graph neural\nnetwork (GNN) that executes the value iteration (VI) algorithm, across\narbitrary environment models, with direct supervision on the intermediate steps\nof VI. The results indicate that GNNs are able to model value iteration\naccurately, recovering favourable metrics and policies across a variety of\nout-of-distribution tests. This suggests that GNN executors with strong\nsupervision are a viable component within deep reinforcement learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:09:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Deac", "Andreea", ""], ["Bacon", "Pierre-Luc", ""], ["Tang", "Jian", ""]]}, {"id": "2009.12610", "submitter": "YoungGon Kim", "authors": "Young-Gon Kim, Kyungsang Kim, Dufan Wu, Hui Ren, Won Young Tak, Soo\n  Young Park, Yu Rim Lee, Min Kyu Kang, Jung Gil Park, Byung Seok Kim, Woo Jin\n  Chung, Mannudeep K. Kalra, Quanzheng Li", "title": "Deep Learning-based Four-region Lung Segmentation in Chest Radiography\n  for COVID-19 Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose. Imaging plays an important role in assessing severity of COVID 19\npneumonia. However, semantic interpretation of chest radiography (CXR) findings\ndoes not include quantitative description of radiographic opacities. Most\ncurrent AI assisted CXR image analysis framework do not quantify for regional\nvariations of disease. To address these, we proposed a four region lung\nsegmentation method to assist accurate quantification of COVID 19 pneumonia.\nMethods. A segmentation model to separate left and right lung is firstly\napplied, and then a carina and left hilum detection network is used, which are\nthe clinical landmarks to separate the upper and lower lungs. To improve the\nsegmentation performance of COVID 19 images, ensemble strategy incorporating\nfive models is exploited. Using each region, we evaluated the clinical\nrelevance of the proposed method with the Radiographic Assessment of the\nQuality of Lung Edema (RALE). Results. The proposed ensemble strategy showed\ndice score of 0.900, which is significantly higher than conventional methods\n(0.854 0.889). Mean intensities of segmented four regions indicate positive\ncorrelation to the extent and density scores of pulmonary opacities under the\nRALE framework. Conclusion. A deep learning based model in CXR can accurately\nsegment and quantify regional distribution of pulmonary opacities in patients\nwith COVID 19 pneumonia.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:32:13 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kim", "Young-Gon", ""], ["Kim", "Kyungsang", ""], ["Wu", "Dufan", ""], ["Ren", "Hui", ""], ["Tak", "Won Young", ""], ["Park", "Soo Young", ""], ["Lee", "Yu Rim", ""], ["Kang", "Min Kyu", ""], ["Park", "Jung Gil", ""], ["Kim", "Byung Seok", ""], ["Chung", "Woo Jin", ""], ["Kalra", "Mannudeep K.", ""], ["Li", "Quanzheng", ""]]}, {"id": "2009.12612", "submitter": "Greg Anderson", "authors": "Greg Anderson, Abhinav Verma, Isil Dillig, Swarat Chaudhuri", "title": "Neurosymbolic Reinforcement Learning with Formally Verified Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Revel, a partially neural reinforcement learning (RL) framework\nfor provably safe exploration in continuous state and action spaces. A key\nchallenge for provably safe deep RL is that repeatedly verifying neural\nnetworks within a learning loop is computationally infeasible. We address this\nchallenge using two policy classes: a general, neurosymbolic class with\napproximate gradients and a more restricted class of symbolic policies that\nallows efficient verification. Our learning algorithm is a mirror descent over\npolicies: in each iteration, it safely lifts a symbolic policy into the\nneurosymbolic space, performs safe gradient updates to the resulting policy,\nand projects the updated policy into the safe symbolic subset, all without\nrequiring explicit verification of neural networks. Our empirical results show\nthat Revel enforces safe exploration in many scenarios in which Constrained\nPolicy Optimization does not, and that it can discover policies that outperform\nthose learned through prior approaches to verified exploration.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:51:04 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:02:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Anderson", "Greg", ""], ["Verma", "Abhinav", ""], ["Dillig", "Isil", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "2009.12622", "submitter": "Maha Jarallah Althobaiti", "authors": "Maha J. Althobaiti", "title": "Automatic Arabic Dialect Identification Systems for Written Texts: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic dialect identification is a specific task of natural language\nprocessing, aiming to automatically predict the Arabic dialect of a given text.\nArabic dialect identification is the first step in various natural language\nprocessing applications such as machine translation, multilingual\ntext-to-speech synthesis, and cross-language text generation. Therefore, in the\nlast decade, interest has increased in addressing the problem of Arabic dialect\nidentification. In this paper, we present a comprehensive survey of Arabic\ndialect identification research in written texts. We first define the problem\nand its challenges. Then, the survey extensively discusses in a critical manner\nmany aspects related to Arabic dialect identification task. So, we review the\ntraditional machine learning methods, deep learning architectures, and complex\nlearning approaches to Arabic dialect identification. We also detail the\nfeatures and techniques for feature representations used to train the proposed\nsystems. Moreover, we illustrate the taxonomy of Arabic dialects studied in the\nliterature, the various levels of text processing at which Arabic dialect\nidentification are conducted (e.g., token, sentence, and document level), as\nwell as the available annotated resources, including evaluation benchmark\ncorpora. Open challenges and issues are discussed at the end of the survey.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 15:33:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Althobaiti", "Maha J.", ""]]}, {"id": "2009.12634", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim Ahmed, Marcos Quinones-Grueiro, Gautam Biswas", "title": "Complementary Meta-Reinforcement Learning for Fault-Adaptive Control", "comments": "Accepted to PHM Conference 2020", "journal-ref": "Annual Conference of the PHM Society. Vol. 12. No. 1. 2020", "doi": "10.36001/phmconf.2020.v12i1.1289", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faults are endemic to all systems. Adaptive fault-tolerant control maintains\ndegraded performance when faults occur as opposed to unsafe conditions or\ncatastrophic events. In systems with abrupt faults and strict time constraints,\nit is imperative for control to adapt quickly to system changes to maintain\nsystem operations. We present a meta-reinforcement learning approach that\nquickly adapts its control policy to changing conditions. The approach builds\nupon model-agnostic meta learning (MAML). The controller maintains a complement\nof prior policies learned under system faults. This \"library\" is evaluated on a\nsystem after a new fault to initialize the new policy. This contrasts with\nMAML, where the controller derives intermediate policies anew, sampled from a\ndistribution of similar systems, to initialize a new policy. Our approach\nimproves sample efficiency of the reinforcement learning process. We evaluate\nour approach on an aircraft fuel transfer system under abrupt faults.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 16:30:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ahmed", "Ibrahim", ""], ["Quinones-Grueiro", "Marcos", ""], ["Biswas", "Gautam", ""]]}, {"id": "2009.12656", "submitter": "Yiwen Meng", "authors": "Yiwen Meng, William Speier, Michael K. Ong and Corey W. Arnold", "title": "Bidirectional Representation Learning from Transformers using Multimodal\n  Electronic Health Record Data to Predict Depression", "comments": "in IEEE Journal of Biomedical and Health Informatics (2021)", "journal-ref": null, "doi": "10.1109/JBHI.2021.3063721", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in machine learning algorithms have had a beneficial impact on\nrepresentation learning, classification, and prediction models built using\nelectronic health record (EHR) data. Effort has been put both on increasing\nmodels' overall performance as well as improving their interpretability,\nparticularly regarding the decision-making process. In this study, we present a\ntemporal deep learning model to perform bidirectional representation learning\non EHR sequences with a transformer architecture to predict future diagnosis of\ndepression. This model is able to aggregate five heterogenous and\nhigh-dimensional data sources from the EHR and process them in a temporal\nmanner for chronic disease prediction at various prediction windows. We applied\nthe current trend of pretraining and fine-tuning on EHR data to outperform the\ncurrent state-of-the-art in chronic disease prediction, and to demonstrate the\nunderlying relation between EHR codes in the sequence. The model generated the\nhighest increases of precision-recall area under the curve (PRAUC) from 0.70 to\n0.76 in depression prediction compared to the best baseline model. Furthermore,\nthe self-attention weights in each sequence quantitatively demonstrated the\ninner relationship between various codes, which improved the model's\ninterpretability. These results demonstrate the model's ability to utilize\nheterogeneous EHR data to predict depression while achieving high accuracy and\ninterpretability, which may facilitate constructing clinical decision support\nsystems in the future for chronic disease screening and early detection.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 17:56:37 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 16:54:52 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 00:37:39 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 05:04:12 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Meng", "Yiwen", ""], ["Speier", "William", ""], ["Ong", "Michael K.", ""], ["Arnold", "Corey W.", ""]]}, {"id": "2009.12658", "submitter": "Hossein Sharifi Noghabi", "authors": "Hossein Sharifi-Noghabi, Hossein Asghari, Nazanin Mehrasa, Martin\n  Ester", "title": "Domain Generalization via Semi-supervised Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of domain generalization is to learn from multiple source domains to\ngeneralize to unseen target domains under distribution discrepancy. Current\nstate-of-the-art methods in this area are fully supervised, but for many\nreal-world problems it is hardly possible to obtain enough labeled samples. In\nthis paper, we propose the first method of domain generalization to leverage\nunlabeled samples, combining of meta learning's episodic training and\nsemi-supervised learning, called DGSML. DGSML employs an entropy-based\npseudo-labeling approach to assign labels to unlabeled samples and then\nutilizes a novel discrepancy loss to ensure that class centroids before and\nafter labeling unlabeled samples are close to each other. To learn a\ndomain-invariant representation, it also utilizes a novel alignment loss to\nensure that the distance between pairs of class centroids, computed after\nadding the unlabeled samples, is preserved across different domains. DGSML is\ntrained by a meta learning approach to mimic the distribution shift between the\ninput source domains and unseen target domains. Experimental results on\nbenchmark datasets indicate that DGSML outperforms state-of-the-art domain\ngeneralization and semi-supervised learning methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 18:05:04 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 07:47:30 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sharifi-Noghabi", "Hossein", ""], ["Asghari", "Hossein", ""], ["Mehrasa", "Nazanin", ""], ["Ester", "Martin", ""]]}, {"id": "2009.12667", "submitter": "Harish Doddi", "authors": "Harish Doddi, Deepjyoti Deka, Saurav Talukdar and Murti Salapaka", "title": "Estimating Linear Dynamical Networks of Cyclostationary Processes", "comments": "14 pages, Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology learning is an important problem in dynamical systems with\nimplications to security and optimal control. The majority of prior work in\nconsistent topology estimation relies on dynamical systems excited by\ntemporally uncorrelated processes. In this article, we present a novel\nalgorithm for guaranteed topology learning, in networks that are excited by\ntemporally colored, cyclostationary processes. Furthermore, unlike prior work,\nthe framework applies to linear dynamic system with complex valued\ndependencies. In the second part of the article, we analyze conditions for\nconsistent topology learning for bidirected radial networks when a subset of\nthe network is unobserved. Here, few agents are unobserved and the full\ntopology along with unobserved nodes are recovered from observed agents data\nalone. Our theoretical contributions are validated on test networks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 18:54:50 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Doddi", "Harish", ""], ["Deka", "Deepjyoti", ""], ["Talukdar", "Saurav", ""], ["Salapaka", "Murti", ""]]}, {"id": "2009.12675", "submitter": "Chen Zhao", "authors": "Chen Zhao, Feng Chen, Zhuoyi Wang, Latifur Khan", "title": "A Primal-Dual Subgradient Approachfor Fair Meta Learning", "comments": "20th IEEE International Conference on Data Mining (ICDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning to generalize to unseen classes during training,\nknown as few-shot classification, has attracted considerable attention.\nInitialization based methods, such as the gradient-based model agnostic\nmeta-learning (MAML), tackle the few-shot learning problem by \"learning to\nfine-tune\". The goal of these approaches is to learn proper model\ninitialization, so that the classifiers for new classes can be learned from a\nfew labeled examples with a small number of gradient update steps. Few shot\nmeta-learning is well-known with its fast-adapted capability and accuracy\ngeneralization onto unseen tasks. Learning fairly with unbiased outcomes is\nanother significant hallmark of human intelligence, which is rarely touched in\nfew-shot meta-learning. In this work, we propose a Primal-Dual Fair\nMeta-learning framework, namely PDFM, which learns to train fair machine\nlearning models using only a few examples based on data from related tasks. The\nkey idea is to learn a good initialization of a fair model's primal and dual\nparameters so that it can adapt to a new fair learning task via a few gradient\nupdate steps. Instead of manually tuning the dual parameters as hyperparameters\nvia a grid search, PDFM optimizes the initialization of the primal and dual\nparameters jointly for fair meta-learning via a subgradient primal-dual\napproach. We further instantiate examples of bias controlling using mean\ndifference and decision boundary covariance as fairness constraints to each\ntask for supervised regression and classification, respectively. We demonstrate\nthe versatility of our proposed approach by applying our approach to various\nreal-world datasets. Our experiments show substantial improvements over the\nbest prior work for this setting.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 19:47:38 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 18:36:07 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 04:00:20 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zhao", "Chen", ""], ["Chen", "Feng", ""], ["Wang", "Zhuoyi", ""], ["Khan", "Latifur", ""]]}, {"id": "2009.12681", "submitter": "Hoda Eldardiry", "authors": "Chenhan Yuan, Ryan Rossi, Andrew Katz, and Hoda Eldardiry", "title": "Clustering-based Unsupervised Generative Relation Extraction", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of unsupervised relation extraction.\nExisting probabilistic generative model-based relation extraction methods work\nby extracting sentence features and using these features as inputs to train a\ngenerative model. This model is then used to cluster similar relations.\nHowever, these methods do not consider correlations between sentences with the\nsame entity pair during training, which can negatively impact model\nperformance. To address this issue, we propose a Clustering-based Unsupervised\ngenerative Relation Extraction (CURE) framework that leverages an\n\"Encoder-Decoder\" architecture to perform self-supervised learning so the\nencoder can extract relation information. Given multiple sentences with the\nsame entity pair as inputs, self-supervised learning is deployed by predicting\nthe shortest path between entity pairs on the dependency graph of one of the\nsentences. After that, we extract the relation information using the\nwell-trained encoder. Then, entity pairs that share the same relation are\nclustered based on their corresponding relation information. Each cluster is\nlabeled with a few words based on the words in the shortest paths corresponding\nto the entity pairs in each cluster. These cluster labels also describe the\nmeaning of these relation clusters. We compare the triplets extracted by our\nproposed framework (CURE) and baseline methods with a ground-truth Knowledge\nBase. Experimental results show that our model performs better than\nstate-of-the-art models on both New York Times (NYT) and United Nations\nParallel Corpus (UNPC) standard datasets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:36:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuan", "Chenhan", ""], ["Rossi", "Ryan", ""], ["Katz", "Andrew", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12682", "submitter": "He Sun", "authors": "He Sun, Zhun Deng, Hui Chen, David C. Parkes", "title": "Decision-Aware Conditional GANs for Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the decision-aware time-series conditional generative\nadversarial network (DAT-CGAN) as a method for time-series generation. The\nframework adopts a multi-Wasserstein loss on structured decision-related\nquantities, capturing the heterogeneity of decision-related data and providing\nnew effectiveness in supporting the decision processes of end users. We improve\nsample efficiency through an overlapped block-sampling method, and provide a\ntheoretical characterization of the generalization properties of DAT-CGAN. The\nframework is demonstrated on financial time series for a multi-time-step\nportfolio choice problem. We demonstrate better generative quality in regard to\nunderlying data and different decision-related quantities than strong,\nGAN-based baselines.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:37:38 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 00:16:35 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 20:18:47 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Sun", "He", ""], ["Deng", "Zhun", ""], ["Chen", "Hui", ""], ["Parkes", "David C.", ""]]}, {"id": "2009.12683", "submitter": "Hoda Eldardiry", "authors": "Chenhan Yuan, Ryan Rossi, Andrew Katz, and Hoda Eldardiry", "title": "Reinforcement Learning-based N-ary Cross-Sentence Relation Extraction", "comments": "10 pages, 3 figures, submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The models of n-ary cross sentence relation extraction based on distant\nsupervision assume that consecutive sentences mentioning n entities describe\nthe relation of these n entities. However, on one hand, this assumption\nintroduces noisy labeled data and harms the models' performance. On the other\nhand, some non-consecutive sentences also describe one relation and these\nsentences cannot be labeled under this assumption. In this paper, we relax this\nstrong assumption by a weaker distant supervision assumption to address the\nsecond issue and propose a novel sentence distribution estimator model to\naddress the first problem. This estimator selects correctly labeled sentences\nto alleviate the effect of noisy data is a two-level agent reinforcement\nlearning model. In addition, a novel universal relation extractor with a hybrid\napproach of attention mechanism and PCNN is proposed such that it can be\ndeployed in any tasks, including consecutive and nonconsecutive sentences.\nExperiments demonstrate that the proposed model can reduce the impact of noisy\ndata and achieve better performance on general n-ary cross sentence relation\nextraction task compared to baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:39:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuan", "Chenhan", ""], ["Rossi", "Ryan", ""], ["Katz", "Andrew", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12684", "submitter": "Jonathan Reiner", "authors": "Jonathan Reiner, Guy Azran, Gal Hyams", "title": "MicroAnalyzer: A Python Tool for Automated Bacterial Analysis with\n  Fluorescence Microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluorescence microscopy is a widely used method among cell biologists for\nstudying the localization and co-localization of fluorescent protein. For\nmicrobial cell biologists, these studies often include tedious and\ntime-consuming manual segmentation of bacteria and of the fluorescence clusters\nor working with multiple programs. Here, we present MicroAnalyzer - a tool that\nautomates these tasks by providing an end-to-end platform for microscope image\nanalysis. While such tools do exist, they are costly, black-boxed programs.\nMicroanalyzer offers an open-source alternative to these tools, allowing\nflexibility and expandability by advanced users. MicroAnalyzer provides\naccurate cell and fluorescence cluster segmentation based on state-of-the-art\ndeep-learning segmentation models, combined with ad-hoc post-processing and\nColicoords - an open-source cell image analysis tool for calculating general\ncell and fluorescence measurements. Using these methods, it performs better\nthan generic approaches since the dynamic nature of neural networks allows for\na quick adaptation to experiment restrictions and assumptions. Other existing\ntools do not consider experiment assumptions, nor do they provide fluorescence\ncluster detection without the need for any specialized equipment. The key goal\nof MicroAnalyzer is to automate the entire process of cell and fluorescence\nimage analysis \"from microscope to database\", meaning it does not require any\nfurther input from the researcher except for the initial deep-learning model\ntraining. In this fashion, it allows the researchers to concentrate on the\nbigger picture instead of granular, eye-straining labor\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:45:19 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Reiner", "Jonathan", ""], ["Azran", "Guy", ""], ["Hyams", "Gal", ""]]}, {"id": "2009.12690", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and George Yin", "title": "Adaptive Non-reversible Stochastic Gradient Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that adding any skew symmetric matrix to the gradient of\nLangevin dynamics algorithm results in a non-reversible diffusion with improved\nconvergence rate. This paper presents a gradient algorithm to adaptively\noptimize the choice of the skew symmetric matrix. The resulting algorithm\ninvolves a non-reversible diffusion algorithm cross coupled with a stochastic\ngradient algorithm that adapts the skew symmetric matrix. The algorithm uses\nthe same data as the classical Langevin algorithm. A weak convergence proof is\ngiven for the optimality of the choice of the skew symmetric matrix. The\nimproved convergence rate of the algorithm is illustrated numerically in\nBayesian learning and tracking examples.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 21:34:01 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Yin", "George", ""]]}, {"id": "2009.12698", "submitter": "Aysen Degerli", "authors": "Aysen Degerli, Mete Ahishali, Mehmet Yamac, Serkan Kiranyaz, Muhammad\n  E. H. Chowdhury, Khalid Hameed, Tahir Hamid, Rashid Mazhar, and Moncef\n  Gabbouj", "title": "COVID-19 Infection Map Generation and Detection from Chest X-Ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis has become a necessity for accurate and immediate\ncoronavirus disease 2019 (COVID-19) detection to aid treatment and prevent the\nspread of the virus. Numerous studies have proposed to use Deep Learning\ntechniques for COVID-19 diagnosis. However, they have used very limited chest\nX-ray (CXR) image repositories for evaluation with a small number, a few\nhundreds, of COVID-19 samples. Moreover, these methods can neither localize nor\ngrade the severity of COVID-19 infection. For this purpose, recent studies\nproposed to explore the activation maps of deep networks. However, they remain\ninaccurate for localizing the actual infestation making them unreliable for\nclinical use. This study proposes a novel method for the joint localization,\nseverity grading, and detection of COVID-19 from CXR images by generating the\nso-called infection maps. To accomplish this, we have compiled the largest\ndataset with 119,316 CXR images including 2951 COVID-19 samples, where the\nannotation of the ground-truth segmentation masks is performed on CXRs by a\nnovel collaborative human-machine approach. Furthermore, we publicly release\nthe first CXR dataset with the ground-truth segmentation masks of the COVID-19\ninfected regions. A detailed set of experiments show that state-of-the-art\nsegmentation networks can learn to localize COVID-19 infection with an F1-score\nof 83.20%, which is significantly superior to the activation maps created by\nthe previous methods. Finally, the proposed approach achieved a COVID-19\ndetection performance with 94.96% sensitivity and 99.88% specificity.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:20:05 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 20:17:40 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Degerli", "Aysen", ""], ["Ahishali", "Mete", ""], ["Yamac", "Mehmet", ""], ["Kiranyaz", "Serkan", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Hameed", "Khalid", ""], ["Hamid", "Tahir", ""], ["Mazhar", "Rashid", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.12702", "submitter": "Konstantinos Kogkalidis", "authors": "Konstantinos Kogkalidis, Michael Moortgat, Richard Moot", "title": "Neural Proof Nets", "comments": "14 pages, CoNLL2020", "journal-ref": "Proceedings of the 24th Conference on Computational Natural\n  Language Learning (2020)", "doi": "10.18653/v1/2020.conll-1.3", "report-no": null, "categories": "cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear logic and the linear {\\lambda}-calculus have a long standing tradition\nin the study of natural language form and meaning. Among the proof calculi of\nlinear logic, proof nets are of particular interest, offering an attractive\ngeometric representation of derivations that is unburdened by the bureaucratic\ncomplications of conventional prooftheoretic formats. Building on recent\nadvances in set-theoretic learning, we propose a neural variant of proof nets\nbased on Sinkhorn networks, which allows us to translate parsing as the problem\nof extracting syntactic primitives and permuting them into alignment. Our\nmethodology induces a batch-efficient, end-to-end differentiable architecture\nthat actualizes a formally grounded yet highly efficient neuro-symbolic parser.\nWe test our approach on {\\AE}Thel, a dataset of type-logical derivations for\nwritten Dutch, where it manages to correctly transcribe raw text sentences into\nproofs and terms of the linear {\\lambda}-calculus with an accuracy of as high\nas 70%.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:48:47 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kogkalidis", "Konstantinos", ""], ["Moortgat", "Michael", ""], ["Moot", "Richard", ""]]}, {"id": "2009.12703", "submitter": "Truong Nguyen", "authors": "Truong Nguyen, Guangye Chen, and Luis Chacon", "title": "An Adaptive EM Accelerator for Unsupervised Learning of Gaussian Mixture\n  Models", "comments": "19 pages (single column), 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an Anderson Acceleration (AA) scheme for the adaptive\nExpectation-Maximization (EM) algorithm for unsupervised learning a finite\nmixture model from multivariate data (Figueiredo and Jain 2002). The proposed\nalgorithm is able to determine the optimal number of mixture components\nautonomously, and converges to the optimal solution much faster than its\nnon-accelerated version. The success of the AA-based algorithm stems from\nseveral developments rather than a single breakthrough (and without these, our\ntests demonstrate that AA fails catastrophically). To begin, we ensure the\nmonotonicity of the likelihood function (a the key feature of the standard EM\nalgorithm) with a recently proposed monotonicity-control algorithm (Henderson\nand Varahdan 2019), enhanced by a novel monotonicity test with little overhead.\nWe propose nimble strategies for AA to preserve the positive definiteness of\nthe Gaussian weights and covariance matrices strictly, and to conserve up to\nthe second moments of the observed data set exactly. Finally, we employ a\nK-means clustering algorithm using the gap statistic to avoid excessively\noverestimating the initial number of components, thereby maximizing\nperformance. We demonstrate the accuracy and efficiency of the algorithm with\nseveral synthetic data sets that are mixtures of Gaussians distributions of\nknown number of components, as well as data sets generated from\nparticle-in-cell simulations. Our numerical results demonstrate speed-ups with\nrespect to non-accelerated EM of up to 60X when the exact number of mixture\ncomponents is known, and between a few and more than an order of magnitude with\ncomponent adaptivity.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:55:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Truong", ""], ["Chen", "Guangye", ""], ["Chacon", "Luis", ""]]}, {"id": "2009.12710", "submitter": "Zeren Shui", "authors": "Zeren Shui, George Karypis", "title": "Heterogeneous Molecular Graph Neural Networks for Predicting Molecule\n  Properties", "comments": "To appear as a conference paper at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As they carry great potential for modeling complex interactions, graph neural\nnetwork (GNN)-based methods have been widely used to predict quantum mechanical\nproperties of molecules. Most of the existing methods treat molecules as\nmolecular graphs in which atoms are modeled as nodes. They characterize each\natom's chemical environment by modeling its pairwise interactions with other\natoms in the molecule. Although these methods achieve a great success, limited\namount of works explicitly take many-body interactions, i.e., interactions\nbetween three and more atoms, into consideration. In this paper, we introduce a\nnovel graph representation of molecules, heterogeneous molecular graph (HMG) in\nwhich nodes and edges are of various types, to model many-body interactions.\nHMGs have the potential to carry complex geometric information. To leverage the\nrich information stored in HMGs for chemical prediction problems, we build\nheterogeneous molecular graph neural networks (HMGNN) on the basis of a neural\nmessage passing scheme. HMGNN incorporates global molecule representations and\nan attention mechanism into the prediction process. The predictions of HMGNN\nare invariant to translation and rotation of atom coordinates, and permutation\nof atom indices. Our model achieves state-of-the-art performance in 9 out of 12\ntasks on the QM9 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 23:29:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shui", "Zeren", ""], ["Karypis", "George", ""]]}, {"id": "2009.12711", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "Local and non-local dependency learning and emergence of rule-like\n  representations in speech data by Deep Convolutional Generative Adversarial\n  Networks", "comments": "In press at Computer Speech & Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper argues that training GANs on local and non-local dependencies in\nspeech data offers insights into how deep neural networks discretize continuous\ndata and how symbolic-like rule-based morphophonological processes emerge in a\ndeep convolutional architecture. Acquisition of speech has recently been\nmodeled as a dependency between latent space and data generated by GANs in\nBegu\\v{s} (2020b; arXiv:2006.03965), who models learning of a simple local\nallophonic distribution. We extend this approach to test learning of local and\nnon-local phonological processes that include approximations of morphological\nprocesses. We further parallel outputs of the model to results of a behavioral\nexperiment where human subjects are trained on the data used for training the\nGAN network. Four main conclusions emerge: (i) the networks provide useful\ninformation for computational models of speech acquisition even if trained on a\ncomparatively small dataset of an artificial grammar learning experiment; (ii)\nlocal processes are easier to learn than non-local processes, which matches\nboth behavioral data in human subjects and typology in the world's languages.\nThis paper also proposes (iii) how we can actively observe the network's\nprogress in learning and explore the effect of training steps on learning\nrepresentations by keeping latent space constant across different training\nsteps. Finally, this paper shows that (iv) the network learns to encode the\npresence of a prefix with a single latent variable; by interpolating this\nvariable, we can actively observe the operation of a non-local phonological\nprocess. The proposed technique for retrieving learning representations has\ngeneral implications for our understanding of how GANs discretize continuous\nspeech data and suggests that rule-like generalizations in the training data\nare represented as an interaction between variables in the network's latent\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 00:02:34 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 07:28:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2009.12718", "submitter": "Abhinav Aggarwal", "authors": "Nan Xu, Oluwaseyi Feyisetan, Abhinav Aggarwal, Zekun Xu, Nathanael\n  Teissier", "title": "Differentially Private Adversarial Robustness Through Randomized\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks, despite their great success in diverse domains, are\nprovably sensitive to small perturbations on correctly classified examples and\nlead to erroneous predictions. Recently, it was proposed that this behavior can\nbe combatted by optimizing the worst case loss function over all possible\nsubstitutions of training examples. However, this can be prone to weighing\nunlikely substitutions higher, limiting the accuracy gain. In this paper, we\nstudy adversarial robustness through randomized perturbations, which has two\nimmediate advantages: (1) by ensuring that substitution likelihood is weighted\nby the proximity to the original word, we circumvent optimizing the worst case\nguarantees and achieve performance gains; and (2) the calibrated randomness\nimparts differentially-private model training, which additionally improves\nrobustness against adversarial attacks on the model outputs. Our approach uses\na novel density-based mechanism based on truncated Gumbel noise, which ensures\ntraining on substitutions of both rare and dense words in the vocabulary while\nmaintaining semantic similarity for model robustness.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 00:58:32 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Nan", ""], ["Feyisetan", "Oluwaseyi", ""], ["Aggarwal", "Abhinav", ""], ["Xu", "Zekun", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2009.12724", "submitter": "Shixian Wen", "authors": "Shixian Wen, Amanda Rios, Laurent Itti", "title": "Beneficial Perturbations Network for Defending Adversarial Examples", "comments": "submitted to ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can be fooled by adversarial attacks: adding carefully\ncomputed small adversarial perturbations to clean inputs can cause\nmisclassification on state-of-the-art machine learning models. The reason is\nthat neural networks fail to accommodate the distribution drift of the input\ndata caused by adversarial perturbations. Here, we present a new solution -\nBeneficial Perturbation Network (BPN) - to defend against adversarial attacks\nby fixing the distribution drift. During training, BPN generates and leverages\nbeneficial perturbations (somewhat opposite to well-known adversarial\nperturbations) by adding new, out-of-network biasing units. Biasing units\ninfluence the parameter space of the network, to preempt and neutralize future\nadversarial perturbations on input data samples. To achieve this, BPN creates\nreverse adversarial attacks during training, with very little cost, by\nrecycling the training gradients already computed. Reverse attacks are captured\nby the biasing units, and the biases can in turn effectively defend against\nfuture adversarial examples. Reverse attacks are a shortcut, i.e., they affect\nthe network's parameters without requiring instantiation of adversarial\nexamples that could assist training. We provide comprehensive empirical\nevidence showing that 1) BPN is robust to adversarial examples and is much more\nrunning memory and computationally efficient compared to classical adversarial\ntraining. 2) BPN can defend against adversarial examples with negligible\nadditional computation and parameter costs compared to training only on clean\nexamples; 3) BPN hurts the accuracy on clean examples much less than classic\nadversarial training; 4) BPN can improve the generalization of the network 5)\nBPN trained only with Fast Gradient Sign Attack can generalize to defend PGD\nattacks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 02:05:26 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 07:25:51 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wen", "Shixian", ""], ["Rios", "Amanda", ""], ["Itti", "Laurent", ""]]}, {"id": "2009.12727", "submitter": "Javier Turek", "authors": "Shivangi Mahto, Vy A. Vo, Javier S. Turek, Alexander G. Huth", "title": "Multi-timescale Representation Learning in LSTM Language Models", "comments": null, "journal-ref": "International Conference on Learning Representations 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models must capture statistical dependencies between words at\ntimescales ranging from very short to very long. Earlier work has demonstrated\nthat dependencies in natural language tend to decay with distance between words\naccording to a power law. However, it is unclear how this knowledge can be used\nfor analyzing or designing neural network language models. In this work, we\nderived a theory for how the memory gating mechanism in long short-term memory\n(LSTM) language models can capture power law decay. We found that unit\ntimescales within an LSTM, which are determined by the forget gate bias, should\nfollow an Inverse Gamma distribution. Experiments then showed that LSTM\nlanguage models trained on natural English text learn to approximate this\ntheoretical distribution. Further, we found that explicitly imposing the\ntheoretical distribution upon the model during training yielded better language\nmodel perplexity overall, with particular improvements for predicting\nlow-frequency (rare) words. Moreover, the explicit multi-timescale model\nselectively routes information about different types of words through units\nwith different timescales, potentially improving model interpretability. These\nresults demonstrate the importance of careful, theoretically-motivated analysis\nof memory and timescale in language models.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 02:13:38 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 00:06:08 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Mahto", "Shivangi", ""], ["Vo", "Vy A.", ""], ["Turek", "Javier S.", ""], ["Huth", "Alexander G.", ""]]}, {"id": "2009.12735", "submitter": "Hainan Zhang", "authors": "Hainan Zhang, Yanyan Lan, Liang Pang, Hongshen Chen, Zhuoye Ding and\n  Dawei Yin", "title": "Modeling Topical Relevance for Multi-Turn Dialogue Generation", "comments": null, "journal-ref": "the 29th International Joint Conference on Artificial\n  Intelligence(IJCAI 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic drift is a common phenomenon in multi-turn dialogue. Therefore, an\nideal dialogue generation models should be able to capture the topic\ninformation of each context, detect the relevant context, and produce\nappropriate responses accordingly. However, existing models usually use word or\nsentence level similarities to detect the relevant contexts, which fail to well\ncapture the topical level relevance. In this paper, we propose a new model,\nnamed STAR-BTM, to tackle this problem. Firstly, the Biterm Topic Model is\npre-trained on the whole training dataset. Then, the topic level attention\nweights are computed based on the topic representation of each context.\nFinally, the attention weights and the topic distribution are utilized in the\ndecoding process to generate the corresponding responses. Experimental results\non both Chinese customer services data and English Ubuntu dialogue data show\nthat STAR-BTM significantly outperforms several state-of-the-art methods, in\nterms of both metric-based and human evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 03:33:22 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Hainan", ""], ["Lan", "Yanyan", ""], ["Pang", "Liang", ""], ["Chen", "Hongshen", ""], ["Ding", "Zhuoye", ""], ["Yin", "Dawei", ""]]}, {"id": "2009.12740", "submitter": "Shengzhe Xu", "authors": "Shengzhe Xu, Manish Marwah, Naren Ramakrishnan", "title": "STAN: Synthetic Network Traffic Generation using Autoregressive Neural\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved great success in recent years. However,\nlarge amounts of data are typically required to train such models. While some\ntypes of data, such as images, videos, and text, are easier to find, data in\ncertain domains is difficult to obtain. For instance, cybersecurity\napplications routinely use network traffic data which organizations are\nreluctant to share, even internally, due to privacy reasons. An alternative is\nto use synthetically generated data; however, most existing data generating\nmethods lack the ability to capture complex dependency structures that are\nusually prevalent in real data by assuming independence either temporally or\nbetween attributes. This paper presents our approach called STAN, Synthetic\nNetwork Traffic Generation using Autoregressive Neural models, to generate\nrealistic synthetic network traffic data. Our novel autoregressive neural\narchitecture captures both temporal dependence and dependence between\nattributes at any given time. It integrates convolutional neural layers (CNN)\nwith mixture density layers (MDN) and softmax layers to model both continuous\nand discrete variables. We evaluate performance of STAN by training it on both\na simulated dataset and a real network traffic data set. Multiple metrics are\nused to compare the generated data with real data and with data generated via\nseveral baseline methods. Finally, to answer the question -- can real network\ntraffic data be substituted with synthetic data to train models of comparable\naccuracy -- we consider two commonly used models for anomaly detection in such\ndata, and compare F1/MSE measures of models trained on real data and those on\nincreasing proportions of generated data. The results show only a small decline\nin accuracy of models trained solely on synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 04:20:02 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Shengzhe", ""], ["Marwah", "Manish", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "2009.12745", "submitter": "Ho Ling Li", "authors": "Ho Ling Li", "title": "Faster Biological Gradient Descent Learning", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Back-propagation is a popular machine learning algorithm that uses gradient\ndescent in training neural networks for supervised learning, but can be very\nslow. A number of algorithms have been developed to speed up convergence and\nimprove robustness of the learning. However, they are complicated to implement\nbiologically as they require information from previous updates. Inspired by\nsynaptic competition in biology, we have come up with a simple and local\ngradient descent optimization algorithm that can reduce training time, with no\ndemand on past details. Our algorithm, named dynamic learning rate (DLR), works\nsimilarly to the traditional gradient descent used in back-propagation, except\nthat instead of having a uniform learning rate across all synapses, the\nlearning rate depends on the current neuronal connection weights. Our algorithm\nis found to speed up learning, particularly for small networks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 05:26:56 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Li", "Ho Ling", ""]]}, {"id": "2009.12747", "submitter": "Ali Risheh", "authors": "A. Risheh, A. Jalili, E. Nazerfard", "title": "Smart Irrigation IoT Solution using Transfer Learning for Neural\n  Networks", "comments": "8 pages, 11 figures, International Conference on Computer and\n  Knowledge Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a reliable system for smart irrigation of\ngreenhouses using artificial neural networks, and an IoT architecture. Our\nsolution uses four sensors in different layers of soil to predict future\nmoisture. Using a dataset we collected by running experiments on different\nsoils, we show high performance of neural networks compared to existing\nalternative method of support vector regression. To reduce the processing power\nof neural network for the IoT edge devices, we propose using transfer learning.\nTransfer learning also speeds up training performance with small amount of\ntraining data, and allows integrating climate sensors to a pre-trained model,\nwhich are the other two challenges of smart irrigation of greenhouses. Our\nproposed IoT architecture shows a complete solution for smart irrigation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 05:31:19 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Risheh", "A.", ""], ["Jalili", "A.", ""], ["Nazerfard", "E.", ""]]}, {"id": "2009.12755", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Qiang Wu", "title": "A Statistical Learning Assessment of Huber Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the triumphs and milestones of robust statistics, Huber regression\nplays an important role in robust inference and estimation. It has also been\nfinding a great variety of applications in machine learning. In a parametric\nsetup, it has been extensively studied. However, in the statistical learning\ncontext where a function is typically learned in a nonparametric way, there is\nstill a lack of theoretical understanding of how Huber regression estimators\nlearn the conditional mean function and why it works in the absence of\nlight-tailed noise assumptions. To address these fundamental questions, we\nconduct an assessment of Huber regression from a statistical learning\nviewpoint. First, we show that the usual risk consistency property of Huber\nregression estimators, which is usually pursued in machine learning, cannot\nguarantee their learnability in mean regression. Second, we argue that Huber\nregression should be implemented in an adaptive way to perform mean regression,\nimplying that one needs to tune the scale parameter in accordance with the\nsample size and the moment condition of the noise. Third, with an adaptive\nchoice of the scale parameter, we demonstrate that Huber regression estimators\ncan be asymptotic mean regression calibrated under $(1+\\epsilon)$-moment\nconditions ($\\epsilon>0$). Last but not least, under the same moment\nconditions, we establish almost sure convergence rates for Huber regression\nestimators. Note that the $(1+\\epsilon)$-moment conditions accommodate the\nspecial case where the response variable possesses infinite variance and so the\nestablished convergence rates justify the robustness feature of Huber\nregression estimators. In the above senses, the present study provides a\nsystematic statistical learning assessment of Huber regression estimators and\njustifies their merits in terms of robustness from a theoretical viewpoint.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 06:08:21 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Feng", "Yunlong", ""], ["Wu", "Qiang", ""]]}, {"id": "2009.12765", "submitter": "Damai Dai", "authors": "Damai Dai, Hua Zheng, Fuli Luo, Pengcheng Yang, Baobao Chang, Zhifang\n  Sui", "title": "Inductively Representing Out-of-Knowledge-Graph Entities by Optimal\n  Estimation Under Translational Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Knowledge Graph Completion (KGC) assumes that all test entities\nappear during training. However, in real-world scenarios, Knowledge Graphs (KG)\nevolve fast with out-of-knowledge-graph (OOKG) entities added frequently, and\nwe need to represent these entities efficiently. Most existing Knowledge Graph\nEmbedding (KGE) methods cannot represent OOKG entities without costly\nretraining on the whole KG. To enhance efficiency, we propose a simple and\neffective method that inductively represents OOKG entities by their optimal\nestimation under translational assumptions. Given pretrained embeddings of the\nin-knowledge-graph (IKG) entities, our method needs no additional learning.\nExperimental results show that our method outperforms the state-of-the-art\nmethods with higher efficiency on two KGC tasks with OOKG entities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 07:12:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Dai", "Damai", ""], ["Zheng", "Hua", ""], ["Luo", "Fuli", ""], ["Yang", "Pengcheng", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2009.12770", "submitter": "Deepak Gupta", "authors": "Deepak Gupta, Swati Suman, Asif Ekbal", "title": "Hierarchical Deep Multi-modal Network for Medical Visual Question\n  Answering", "comments": "Accepted for publication at Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Visual Question Answering in Medical domain (VQA-Med) plays an important role\nin providing medical assistance to the end-users. These users are expected to\nraise either a straightforward question with a Yes/No answer or a challenging\nquestion that requires a detailed and descriptive answer. The existing\ntechniques in VQA-Med fail to distinguish between the different question types\nsometimes complicates the simpler problems, or over-simplifies the complicated\nones. It is certainly true that for different question types, several distinct\nsystems can lead to confusion and discomfort for the end-users. To address this\nissue, we propose a hierarchical deep multi-modal network that analyzes and\nclassifies end-user questions/queries and then incorporates a query-specific\napproach for answer prediction. We refer our proposed approach as Hierarchical\nQuestion Segregation based Visual Question Answering, in short HQS-VQA. Our\ncontributions are three-fold, viz. firstly, we propose a question segregation\n(QS) technique for VQAMed; secondly, we integrate the QS model to the\nhierarchical deep multi-modal neural network to generate proper answers to the\nqueries related to medical images; and thirdly, we study the impact of QS in\nMedical-VQA by comparing the performance of the proposed model with QS and a\nmodel without QS. We evaluate the performance of our proposed model on two\nbenchmark datasets, viz. RAD and CLEF18. Experimental results show that our\nproposed HQS-VQA technique outperforms the baseline models with significant\nmargins. We also conduct a detailed quantitative and qualitative analysis of\nthe obtained results and discover potential causes of errors and their\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 07:24:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gupta", "Deepak", ""], ["Suman", "Swati", ""], ["Ekbal", "Asif", ""]]}, {"id": "2009.12780", "submitter": "Anna Jenul", "authors": "Anna Jenul, Stefan Schrunner, Kristian Hovde Liland, Ulf Geir Indahl,\n  Cecilia Marie Futsaether, Oliver Tomic", "title": "RENT -- Repeated Elastic Net Technique for Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an essential step in data science pipelines to reduce\nthe complexity of models trained on large datasets. While a major part of\nfeature selection research focuses on optimizing predictive performance, there\nare only few studies that investigate the integration of feature selection\nstability into the feature selection process. Taking advantage of feature\nselection stability has the potential to enhance interpretability of machine\nlearning models whilst maintaining predictive performance. In this study we\npresent the RENT feature selector for binary classification and regression\nproblems. The proposed methodology is based on an ensemble of elastic net\nregularized models, trained on unique subsets of the dataset. RENT selects\nfeatures based on three criteria evaluating the weight distributions of\nfeatures across all elementary models. Compared to conventional approaches,\nRENT simultaneously performs high-quality feature selection while gathering\nuseful information for model interpretation. In addition, the proposed\nensemble-based selection criteria guarantee robustness of the model by\nselecting features with high stability. In an experimental evaluation, we\ncompare feature selection quality on eight multivariate datasets: six for\nbinary classification and two for regression. We benchmark RENT against six\nestablished feature selectors. In terms of both, number of features selected\nand predictive performance, RENT delivers on-par results with the best\nperforming competitors. The additional information on stability provided by\nRENT can be integrated in an exploratory post-hoc analysis for further insight\nas demonstrated in a use-case from the healthcare domain.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 07:55:52 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 15:55:58 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Jenul", "Anna", ""], ["Schrunner", "Stefan", ""], ["Liland", "Kristian Hovde", ""], ["Indahl", "Ulf Geir", ""], ["Futsaether", "Cecilia Marie", ""], ["Tomic", "Oliver", ""]]}, {"id": "2009.12783", "submitter": "Dirk Pesch", "authors": "Leila Sedghi, Zohaib Ijaz, Md. Noor-A-Rahim, Kritchai Witheephanich,\n  Dirk Pesch", "title": "Machine Learning in Event-Triggered Control: Recent Advances and Open\n  Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Control Systems (NCSs) have attracted much interest over the past\ndecade as part of a move towards more decentralised control applications and\nthe rise of cyberphysical system applications. Many practical NCSs face the\nchallenges of limited communication bandwidth resources, reliability and lack\nof knowledge of network dynamics, particularly when wireless networks are\ninvolved. Machine learning (ML) combined with event-triggered control (ETC) has\nthe potential to ease some of these challenges. For example, ML can be used to\novercome the problem of a lack of network models by learning system behaviour\nor adapt to dynamically changing models by continually learning model dynamics.\nETC can help to conserve bandwidth resources by communicating only when needed\nor when resources are available. Here, we present a review of the literature on\nwork that combines ML and ETC. The literature on supervised, semi-supervised,\nunsupervised and reinforcement learning based approaches such as deep\nreinforcement learning and statistical learning in combination with ETC is\nexplored. Furthermore, the difference between the application of these learning\nalgorithms on model-based and model-free systems are discussed. Following the\nanalysis of the literature, we highlight open research questions and challenges\nrelated to ML-based ETC and propose approaches to possible solutions to these\nchallenges.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 08:11:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sedghi", "Leila", ""], ["Ijaz", "Zohaib", ""], ["Noor-A-Rahim", "Md.", ""], ["Witheephanich", "Kritchai", ""], ["Pesch", "Dirk", ""]]}, {"id": "2009.12787", "submitter": "Tomer Sery", "authors": "Tomer Sery, Nir Shlezinger, Kobi Cohen and Yonina C. Eldar", "title": "Over-the-Air Federated Learning from Heterogeneous Data", "comments": "15 pages, 8 figures. Part of the results were accepted to be\n  presented in the 2020 IEEE Global Communications Conference (GLOBECOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a framework for distributed learning of\ncentralized models. In FL, a set of edge devices train a model using their\nlocal data, while repeatedly exchanging their trained updates with a central\nserver. This procedure allows tuning a centralized model in a distributed\nfashion without having the users share their possibly private data. In this\npaper, we focus on over-the-air (OTA) FL, which has been suggested recently to\nreduce the communication overhead of FL due to the repeated transmissions of\nthe model updates by a large number of users over the wireless channel. In OTA\nFL, all users simultaneously transmit their updates as analog signals over a\nmultiple access channel, and the server receives a superposition of the analog\ntransmitted signals. However, this approach results in the channel noise\ndirectly affecting the optimization procedure, which may degrade the accuracy\nof the trained model. We develop a Convergent OTA FL (COTAF) algorithm which\nenhances the common local stochastic gradient descent (SGD) FL algorithm,\nintroducing precoding at the users and scaling at the server, which gradually\nmitigates the effect of the noise. We analyze the convergence of COTAF to the\nloss minimizing model and quantify the effect of a statistically heterogeneous\nsetup, i.e. when the training data of each user obeys a different distribution.\nOur analysis reveals the ability of COTAF to achieve a convergence rate similar\nto that achievable over error-free channels. Our simulations demonstrate the\nimproved convergence of COTAF over vanilla OTA local SGD for training using\nnon-synthetic datasets. Furthermore, we numerically show that the precoding\ninduced by COTAF notably improves the convergence rate and the accuracy of\nmodels trained via OTA FL.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 08:28:25 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:37:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Sery", "Tomer", ""], ["Shlezinger", "Nir", ""], ["Cohen", "Kobi", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2009.12789", "submitter": "Yann Dubois", "authors": "Yann Dubois, Douwe Kiela, David J. Schwab, Ramakrishna Vedantam", "title": "Learning Optimal Representations with the Decodable Information\n  Bottleneck", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of characterizing and finding optimal representations\nfor supervised learning. Traditionally, this question has been tackled using\nthe Information Bottleneck, which compresses the inputs while retaining\ninformation about the targets, in a decoder-agnostic fashion. In machine\nlearning, however, our goal is not compression but rather generalization, which\nis intimately linked to the predictive family or decoder of interest (e.g.\nlinear classifier). We propose the Decodable Information Bottleneck (DIB) that\nconsiders information retention and compression from the perspective of the\ndesired predictive family. As a result, DIB gives rise to representations that\nare optimal in terms of expected test performance and can be estimated with\nguarantees. Empirically, we show that the framework can be used to enforce a\nsmall generalization gap on downstream classifiers and to predict the\ngeneralization ability of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 08:33:08 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 09:22:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dubois", "Yann", ""], ["Kiela", "Douwe", ""], ["Schwab", "David J.", ""], ["Vedantam", "Ramakrishna", ""]]}, {"id": "2009.12795", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "NN-EVCLUS: Neural Network-based Evidential Clustering", "comments": null, "journal-ref": "Information Sciences, Volume 572, Pages 297-330, 2021", "doi": "10.1016/j.ins.2021.05.011", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidential clustering is an approach to clustering based on the use of\nDempster-Shafer mass functions to represent cluster-membership uncertainty. In\nthis paper, we introduce a neural-network based evidential clustering\nalgorithm, called NN-EVCLUS, which learns a mapping from attribute vectors to\nmass functions, in such a way that more similar inputs are mapped to output\nmass functions with a lower degree of conflict. The neural network can be\npaired with a one-class support vector machine to make it robust to outliers\nand allow for novelty detection. The network is trained to minimize the\ndiscrepancy between dissimilarities and degrees of conflict for all or some\nobject pairs. Additional terms can be added to the loss function to account for\npairwise constraints or labeled data, which can also be used to adapt the\nmetric. Comparative experiments show the superiority of N-EVCLUS over\nstate-of-the-art evidential clustering algorithms for a range of unsupervised\nand constrained clustering tasks involving both attribute and dissimilarity\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 09:05:41 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 01:56:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "2009.12812", "submitter": "Wei Zhang", "authors": "Wei Zhang, Lu Hou, Yichun Yin, Lifeng Shang, Xiao Chen, Xin Jiang, Qun\n  Liu", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based pre-training models like BERT have achieved remarkable\nperformance in many natural language processing tasks.However, these models are\nboth computation and memory expensive, hindering their deployment to\nresource-constrained devices. In this work, we propose TernaryBERT, which\nternarizes the weights in a fine-tuned BERT model. Specifically, we use both\napproximation-based and loss-aware ternarization methods and empirically\ninvestigate the ternarization granularity of different parts of BERT. Moreover,\nto reduce the accuracy degradation caused by the lower capacity of low bits, we\nleverage the knowledge distillation technique in the training process.\nExperiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT\noutperforms the other BERT quantization methods, and even achieves comparable\nperformance as the full-precision model while being 14.9x smaller.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 10:17:28 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 01:56:35 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 07:24:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhang", "Wei", ""], ["Hou", "Lu", ""], ["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Chen", "Xiao", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""]]}, {"id": "2009.12820", "submitter": "Neta Shoham", "authors": "Neta Shoham and Haim Avron", "title": "Experimental Design for Overparameterized Learning with Application to\n  Single Shot Deep Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance exhibited by modern machine learning models hinges\non the ability to train such models on a very large amounts of labeled data.\nHowever, since access to large volumes of labeled data is often limited or\nexpensive, it is desirable to alleviate this bottleneck by carefully curating\nthe training set. Optimal experimental design is a well-established paradigm\nfor selecting data point to be labeled so to maximally inform the learning\nprocess. Unfortunately, classical theory on optimal experimental design focuses\non selecting examples in order to learn underparameterized (and thus,\nnon-interpolative) models, while modern machine learning models such as deep\nneural networks are overparameterized, and oftentimes are trained to be\ninterpolative. As such, classical experimental design methods are not\napplicable in many modern learning setups. Indeed, the predictive performance\nof underparameterized models tends to be variance dominated, so classical\nexperimental design focuses on variance reduction, while the predictive\nperformance of overparameterized models can also be, as is shown in this paper,\nbias dominated or of mixed nature. In this paper we propose a design strategy\nthat is well suited for overparameterized regression and interpolation, and we\ndemonstrate the applicability of our method in the context of deep learning by\nproposing a new algorithm for single shot deep active learning.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 11:27:49 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 13:42:14 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 18:46:07 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Shoham", "Neta", ""], ["Avron", "Haim", ""]]}, {"id": "2009.12821", "submitter": "Virginia Aglietti", "authors": "Virginia Aglietti, Theodoros Damoulas, Mauricio \\'Alvarez, Javier\n  Gonz\\'alez", "title": "Multi-task Causal Learning with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of learning the correlation structure of a set\nof intervention functions defined on the directed acyclic graph (DAG) of a\ncausal model. This is useful when we are interested in jointly learning the\ncausal effects of interventions on different subsets of variables in a DAG,\nwhich is common in field such as healthcare or operations research. We propose\nthe first multi-task causal Gaussian process (GP) model, which we call DAG-GP,\nthat allows for information sharing across continuous interventions and across\nexperiments on different variables. DAG-GP accommodates different assumptions\nin terms of data availability and captures the correlation between functions\nlying in input spaces of different dimensionality via a well-defined integral\noperator. We give theoretical results detailing when and how the DAG-GP model\ncan be formulated depending on the DAG. We test both the quality of its\npredictions and its calibrated uncertainties. Compared to single-task models,\nDAG-GP achieves the best fitting performance in a variety of real and synthetic\nsettings. In addition, it helps to select optimal interventions faster than\ncompeting approaches when used within sequential decision making frameworks,\nlike active learning or Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 11:33:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aglietti", "Virginia", ""], ["Damoulas", "Theodoros", ""], ["\u00c1lvarez", "Mauricio", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "2009.12829", "submitter": "Yufei Wang", "authors": "Haoliang Li, YuFei Wang, Renjie Wan, Shiqi Wang, Tie-Qiang Li, Alex C.\n  Kot", "title": "Domain Generalization for Medical Imaging Classification with\n  Linear-Dependency Regularization", "comments": "Accepted by NeurIPS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we have witnessed great progress in the field of medical imaging\nclassification by adopting deep neural networks. However, the recent advanced\nmodels still require accessing sufficiently large and representative datasets\nfor training, which is often unfeasible in clinically realistic environments.\nWhen trained on limited datasets, the deep neural network is lack of\ngeneralization capability, as the trained deep neural network on data within a\ncertain distribution (e.g. the data captured by a certain device vendor or\npatient population) may not be able to generalize to the data with another\ndistribution.\n  In this paper, we introduce a simple but effective approach to improve the\ngeneralization capability of deep neural networks in the field of medical\nimaging classification. Motivated by the observation that the domain\nvariability of the medical images is to some extent compact, we propose to\nlearn a representative feature space through variational encoding with a novel\nlinear-dependency regularization term to capture the shareable information\namong medical data collected from different domains. As a result, the trained\nneural network is expected to equip with better generalization capability to\nthe \"unseen\" medical data. Experimental results on two challenging medical\nimaging classification tasks indicate that our method can achieve better\ncross-domain generalization capability compared with state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 12:30:30 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 03:38:27 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 10:28:49 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Li", "Haoliang", ""], ["Wang", "YuFei", ""], ["Wan", "Renjie", ""], ["Wang", "Shiqi", ""], ["Li", "Tie-Qiang", ""], ["Kot", "Alex C.", ""]]}, {"id": "2009.12831", "submitter": "Atreyee Kundu", "authors": "Atreyee Kundu and Pavithra Prabhakar", "title": "Learning event-driven switched linear systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an automata theoretic learning algorithm for the identification of\nblack-box switched linear systems whose switching logics are event-driven. A\nswitched system is expressed by a deterministic finite automaton (FA) whose\nnode labels are the subsystem matrices. With information about the dimensions\nof the matrices and the set of events, and with access to two oracles, that can\nsimulate the system on a given input, and provide counter-examples when given\nan incorrect hypothesis automaton, we provide an algorithm that outputs the\nunknown FA. Our algorithm first uses the oracle to obtain the node labels of\nthe system run on a given input sequence of events, and then extends Angluin's\n\\(L^*\\)-algorithm to determine the FA that accepts the language of the given\nFA. We demonstrate the performance of our learning algorithm on a set of\nbenchmark examples.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 12:32:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kundu", "Atreyee", ""], ["Prabhakar", "Pavithra", ""]]}, {"id": "2009.12835", "submitter": "Adi Hanuka", "authors": "A. Hanuka, C. Emma, T. Maxwell, A. Fisher, B. Jacobson, M. J. Hogan,\n  and Z. Huang", "title": "Accurate and confident prediction of electron beam longitudinal\n  properties using spectral virtual diagnostics", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-021-82473-0", "report-no": null, "categories": "physics.acc-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal phase space (LPS) provides a critical information about electron\nbeam dynamics for various scientific applications. For example, it can give\ninsight into the high-brightness X-ray radiation from a free electron laser.\nExisting diagnostics are invasive, and often times cannot operate at the\nrequired resolution. In this work we present a machine learning-based Virtual\nDiagnostic (VD) tool to accurately predict the LPS for every shot using\nspectral information collected non-destructively from the radiation of\nrelativistic electron beam. We demonstrate the tool's accuracy for three\ndifferent case studies with experimental or simulated data. For each case, we\nintroduce a method to increase the confidence in the VD tool. We anticipate\nthat spectral VD would improve the setup and understanding of experimental\nconfigurations at DOE's user facilities as well as data sorting and analysis.\nThe spectral VD can provide confident knowledge of the longitudinal bunch\nproperties at the next generation of high-repetition rate linear accelerators\nwhile reducing the load on data storage, readout and streaming requirements.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 13:02:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hanuka", "A.", ""], ["Emma", "C.", ""], ["Maxwell", "T.", ""], ["Fisher", "A.", ""], ["Jacobson", "B.", ""], ["Hogan", "M. J.", ""], ["Huang", "Z.", ""]]}, {"id": "2009.12836", "submitter": "Lei Huang", "authors": "Lei Huang, Jie Qin, Yi Zhou, Fan Zhu, Li Liu, Ling Shao", "title": "Normalization Techniques in Training DNNs: Methodology, Analysis and\n  Application", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization techniques are essential for accelerating the training and\nimproving the generalization of deep neural networks (DNNs), and have\nsuccessfully been used in various applications. This paper reviews and comments\non the past, present and future of normalization methods in the context of DNN\ntraining. We provide a unified picture of the main motivation behind different\napproaches from the perspective of optimization, and present a taxonomy for\nunderstanding the similarities and differences between them. Specifically, we\ndecompose the pipeline of the most representative normalizing activation\nmethods into three components: the normalization area partitioning,\nnormalization operation and normalization representation recovery. In doing so,\nwe provide insight for designing new normalization technique. Finally, we\ndiscuss the current progress in understanding normalization methods, and\nprovide a comprehensive review of the applications of normalization for\nparticular tasks, in which it can effectively solve the key issues.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 13:06:52 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Huang", "Lei", ""], ["Qin", "Jie", ""], ["Zhou", "Yi", ""], ["Zhu", "Fan", ""], ["Liu", "Li", ""], ["Shao", "Ling", ""]]}, {"id": "2009.12856", "submitter": "Ben Henghes", "authors": "B. Henghes, O. Lahav, D. W. Gerdes, E. Lin, R. Morgan, T. M. C.\n  Abbott, M. Aguena, S. Allam, J. Annis, S. Avila, E. Bertin, D. Brooks, D. L.\n  Burke, A. CarneroRosell, M. CarrascoKind, J. Carretero, C. Conselice, M.\n  Costanzi, L. N. da Costa, J. DeVicente, S. Desai, H. T. Diehl, P. Doel, S.\n  Everett, I. Ferrero, J. Frieman, J. Garc\\'ia-Bellido, E. Gaztanaga, D. Gruen,\n  R. A. Gruendl, J. Gschwend, G. Gutierrez, W. G. Hartley, S. R. Hinton, K.\n  Honscheid, B. Hoyle, D. J. James, K. Kuehn, N. Kuropatkin, J. L. Marshall, P.\n  Melchior, F. Menanteau, R. Miquel, R. L. C. Ogando, A. Palmese, F.\n  Paz-Chinch\\'on, A. A. Plazas, A. K. Romer, C. S\\'anchez, E. Sanchez, V.\n  Scarpine, M. Schubnell, S. Serrano, M. Smith, M. Soares-Santos, E. Suchyta,\n  G. Tarle, C. To, and R. D. Wilkinson (DES collaboration)", "title": "Machine Learning for Searching the Dark Energy Survey for\n  Trans-Neptunian Objects", "comments": "Published in PASP, 16 pages, 6 figures", "journal-ref": "PASP 133 014501 (2021)", "doi": "10.1088/1538-3873/abcaea", "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate how implementing machine learning could improve\nthe efficiency of the search for Trans-Neptunian Objects (TNOs) within Dark\nEnergy Survey (DES) data when used alongside orbit fitting. The discovery of\nmultiple TNOs that appear to show a similarity in their orbital parameters has\nled to the suggestion that one or more undetected planets, an as yet\nundiscovered \"Planet 9\", may be present in the outer Solar System. DES is well\nplaced to detect such a planet and has already been used to discover many other\nTNOs. Here, we perform tests on eight different supervised machine learning\nalgorithms, using a dataset consisting of simulated TNOs buried within real DES\nnoise data. We found that the best performing classifier was the Random Forest\nwhich, when optimised, performed well at detecting the rare objects. We achieve\nan area under the receiver operating characteristic (ROC) curve, (AUC) $= 0.996\n\\pm 0.001$. After optimizing the decision threshold of the Random Forest, we\nachieve a recall of 0.96 while maintaining a precision of 0.80. Finally, by\nusing the optimized classifier to pre-select objects, we are able to run the\norbit-fitting stage of our detection pipeline five times faster.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 14:36:37 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:51:59 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Henghes", "B.", "", "DES collaboration"], ["Lahav", "O.", "", "DES collaboration"], ["Gerdes", "D. W.", "", "DES collaboration"], ["Lin", "E.", "", "DES collaboration"], ["Morgan", "R.", "", "DES collaboration"], ["Abbott", "T. M. C.", "", "DES collaboration"], ["Aguena", "M.", "", "DES collaboration"], ["Allam", "S.", "", "DES collaboration"], ["Annis", "J.", "", "DES collaboration"], ["Avila", "S.", "", "DES collaboration"], ["Bertin", "E.", "", "DES collaboration"], ["Brooks", "D.", "", "DES collaboration"], ["Burke", "D. L.", "", "DES collaboration"], ["CarneroRosell", "A.", "", "DES collaboration"], ["CarrascoKind", "M.", "", "DES collaboration"], ["Carretero", "J.", "", "DES collaboration"], ["Conselice", "C.", "", "DES collaboration"], ["Costanzi", "M.", "", "DES collaboration"], ["da Costa", "L. N.", "", "DES collaboration"], ["DeVicente", "J.", "", "DES collaboration"], ["Desai", "S.", "", "DES collaboration"], ["Diehl", "H. T.", "", "DES collaboration"], ["Doel", "P.", "", "DES collaboration"], ["Everett", "S.", "", "DES collaboration"], ["Ferrero", "I.", "", "DES collaboration"], ["Frieman", "J.", "", "DES collaboration"], ["Garc\u00eda-Bellido", "J.", "", "DES collaboration"], ["Gaztanaga", "E.", "", "DES collaboration"], ["Gruen", "D.", "", "DES collaboration"], ["Gruendl", "R. A.", "", "DES collaboration"], ["Gschwend", "J.", "", "DES collaboration"], ["Gutierrez", "G.", "", "DES collaboration"], ["Hartley", "W. G.", "", "DES collaboration"], ["Hinton", "S. R.", "", "DES collaboration"], ["Honscheid", "K.", "", "DES collaboration"], ["Hoyle", "B.", "", "DES collaboration"], ["James", "D. J.", "", "DES collaboration"], ["Kuehn", "K.", "", "DES collaboration"], ["Kuropatkin", "N.", "", "DES collaboration"], ["Marshall", "J. L.", "", "DES collaboration"], ["Melchior", "P.", "", "DES collaboration"], ["Menanteau", "F.", "", "DES collaboration"], ["Miquel", "R.", "", "DES collaboration"], ["Ogando", "R. L. C.", "", "DES collaboration"], ["Palmese", "A.", "", "DES collaboration"], ["Paz-Chinch\u00f3n", "F.", "", "DES collaboration"], ["Plazas", "A. A.", "", "DES collaboration"], ["Romer", "A. K.", "", "DES collaboration"], ["S\u00e1nchez", "C.", "", "DES collaboration"], ["Sanchez", "E.", "", "DES collaboration"], ["Scarpine", "V.", "", "DES collaboration"], ["Schubnell", "M.", "", "DES collaboration"], ["Serrano", "S.", "", "DES collaboration"], ["Smith", "M.", "", "DES collaboration"], ["Soares-Santos", "M.", "", "DES collaboration"], ["Suchyta", "E.", "", "DES collaboration"], ["Tarle", "G.", "", "DES collaboration"], ["To", "C.", "", "DES collaboration"], ["Wilkinson", "R. D.", "", "DES collaboration"]]}, {"id": "2009.12864", "submitter": "Lei M. Zhang", "authors": "Lei M. Zhang, Matthias Plappert, Wojciech Zaremba", "title": "Predicting Sim-to-Real Transfer with Probabilistic Dynamics Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to predict the sim-to-real transfer performance of RL\npolicies. Our transfer metric simplifies the selection of training setups (such\nas algorithm, hyperparameters, randomizations) and policies in simulation,\nwithout the need for extensive and time-consuming real-world rollouts. A\nprobabilistic dynamics model is trained alongside the policy and evaluated on a\nfixed set of real-world trajectories to obtain the transfer metric. Experiments\nshow that the transfer metric is highly correlated with policy performance in\nboth simulated and real-world robotic environments for complex manipulation\ntasks. We further show that the transfer metric can predict the effect of\ntraining setups on policy transfer performance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:06:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Lei M.", ""], ["Plappert", "Matthias", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2009.12873", "submitter": "Ziyang Wang", "authors": "Ziyang Wang, Zhengdong Zhang, Irina Voiculescu", "title": "RAR-U-Net: a Residual Encoder to Attention Decoder by Residual\n  Connections Framework for Spine Segmentation under Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation algorithms for medical images are widely studied for various\nclinical and research purposes. In this paper, we propose a new and efficient\nmethod for medical image segmentation under noisy labels. The method operates\nunder a deep learning paradigm, incorporating four novel contributions.\nFirstly, a residual interconnection is explored in different scale encoders to\ntransfer gradient information efficiently. Secondly, four copy-and-crop\nconnections are replaced by residual-block-based concatenation to alleviate the\ndisparity between encoders and decoders. Thirdly, convolutional attention\nmodules for feature refinement are studied on all scale decoders. Finally, an\nadaptive denoising learning strategy (ADL) is introduced into the training\nprocess to avoid too much influence from the noisy labels. Experimental results\nare illustrated on a publicly available benchmark database of spine CTs. Our\nproposed method achieves competitive performance against other state-of-the-art\nmethods over a variety of different evaluation measures.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:32:50 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 16:06:22 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 09:29:20 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 21:53:28 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Ziyang", ""], ["Zhang", "Zhengdong", ""], ["Voiculescu", "Irina", ""]]}, {"id": "2009.12875", "submitter": "Julian Busch", "authors": "Julian Busch, Evgeniy Faerman, Matthias Schubert and Thomas Seidl", "title": "Learning Self-Expression Metrics for Scalable and Inductive Subspace\n  Clustering", "comments": null, "journal-ref": "NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and\n  Practice", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering has established itself as a state-of-the-art approach to\nclustering high-dimensional data. In particular, methods relying on the\nself-expressiveness property have recently proved especially successful.\nHowever, they suffer from two major shortcomings: First, a quadratic-size\ncoefficient matrix is learned directly, preventing these methods from scaling\nbeyond small datasets. Secondly, the trained models are transductive and thus\ncannot be used to cluster out-of-sample data unseen during training. Instead of\nlearning self-expression coefficients directly, we propose a novel metric\nlearning approach to learn instead a subspace affinity function using a siamese\nneural network architecture. Consequently, our model benefits from a constant\nnumber of parameters and a constant-size memory footprint, allowing it to scale\nto considerably larger datasets. In addition, we can formally show that out\nmodel is still able to exactly recover subspace clusters given an independence\nassumption. The siamese architecture in combination with a novel geometric\nclassifier further makes our model inductive, allowing it to cluster\nout-of-sample data. Additionally, non-linear clusters can be detected by simply\nadding an auto-encoder module to the architecture. The whole model can then be\ntrained end-to-end in a self-supervised manner. This work in progress reports\npromising preliminary results on the MNIST dataset. In the spirit of\nreproducible research, me make all code publicly available. In future work we\nplan to investigate several extensions of our model and to expand experimental\nevaluation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:40:12 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 00:06:37 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Busch", "Julian", ""], ["Faerman", "Evgeniy", ""], ["Schubert", "Matthias", ""], ["Seidl", "Thomas", ""]]}, {"id": "2009.12894", "submitter": "Bryar Shareef", "authors": "Bryar Shareef, Alex Vakanski, Min Xian, Phoebe E. Freer", "title": "ESTAN: Enhanced Small Tumor-Aware Network for Breast Ultrasound Image\n  Segmentation", "comments": "9 pages, 4 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast tumor segmentation is a critical task in computer-aided diagnosis\n(CAD) systems for breast cancer detection because accurate tumor size, shape\nand location are important for further tumor quantification and classification.\nHowever, segmenting small tumors in ultrasound images is challenging, due to\nthe speckle noise, varying tumor shapes and sizes among patients, and the\nexistence of tumor-like image regions. Recently, deep learning-based approaches\nhave achieved great success for biomedical image analysis, but current\nstate-of-the-art approaches achieve poor performance for segmenting small\nbreast tumors. In this paper, we propose a novel deep neural network\narchitecture, namely Enhanced Small Tumor-Aware Network (ESTAN), to accurately\nand robustly segment breast tumors. ESTAN introduces two encoders to extract\nand fuse image context information at different scales and utilizes\nrow-column-wise kernels in the encoder to adapt to breast anatomy. We validate\nthe proposed approach and compare it to nine state-of-the-art approaches on\nthree public breast ultrasound datasets using seven quantitative metrics. The\nresults demonstrate that the proposed approach achieves the best overall\nperformance and outperforms all other approaches on small tumor segmentation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 16:42:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shareef", "Bryar", ""], ["Vakanski", "Alex", ""], ["Xian", "Min", ""], ["Freer", "Phoebe E.", ""]]}, {"id": "2009.12916", "submitter": "Micol Marchetti-Bowick", "authors": "Sumit Kumar, Yiming Gu, Jerrick Hoang, Galen Clark Haynes, Micol\n  Marchetti-Bowick", "title": "Interaction-Based Trajectory Prediction Over a Hybrid Traffic Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior prediction of traffic actors is an essential component of any\nreal-world self-driving system. Actors' long-term behaviors tend to be governed\nby their interactions with other actors or traffic elements (traffic lights,\nstop signs) in the scene. To capture this highly complex structure of\ninteractions, we propose to use a hybrid graph whose nodes represent both the\ntraffic actors as well as the static and dynamic traffic elements present in\nthe scene. The different modes of temporal interaction (e.g., stopping and\ngoing) among actors and traffic elements are explicitly modeled by graph edges.\nThis explicit reasoning about discrete interaction types not only helps in\npredicting future motion, but also enhances the interpretability of the model,\nwhich is important for safety-critical applications such as autonomous driving.\nWe predict actors' trajectories and interaction types using a graph neural\nnetwork, which is trained in a semi-supervised manner. We show that our\nproposed model, TrafficGraphNet, achieves state-of-the-art trajectory\nprediction accuracy while maintaining a high level of interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:20:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kumar", "Sumit", ""], ["Gu", "Yiming", ""], ["Hoang", "Jerrick", ""], ["Haynes", "Galen Clark", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "2009.12919", "submitter": "Simiao Ren", "authors": "Simiao Ren, Willie Padilla, Jordan Malof", "title": "Benchmarking deep inverse models over time, and the neural-adjoint\n  method", "comments": "Preprint. For camera-ready version please visit\n  https://proceedings.neurips.cc//paper_files/paper/2020/hash/007ff380ee5ac49ffc34442f5c2a2b86-Abstract.html", "journal-ref": "NeurIPS proceedings (2020) 33, p38-48", "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of solving generic inverse problems, where one wishes to\ndetermine the hidden parameters of a natural system that will give rise to a\nparticular set of measurements. Recently many new approaches based upon deep\nlearning have arisen generating impressive results. We conceptualize these\nmodels as different schemes for efficiently, but randomly, exploring the space\nof possible inverse solutions. As a result, the accuracy of each approach\nshould be evaluated as a function of time rather than a single estimated\nsolution, as is often done now. Using this metric, we compare several\nstate-of-the-art inverse modeling approaches on four benchmark tasks: two\nexisting tasks, one simple task for visualization and one new task from\nmetamaterial design. Finally, inspired by our conception of the inverse\nproblem, we explore a solution that uses a deep learning model to approximate\nthe forward model, and then uses backpropagation to search for good inverse\nsolutions. This approach, termed the neural-adjoint, achieves the best\nperformance in many scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:32:06 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:04:03 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 18:16:06 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ren", "Simiao", ""], ["Padilla", "Willie", ""], ["Malof", "Jordan", ""]]}, {"id": "2009.12920", "submitter": "Yining Wang", "authors": "Xi Chen and David Simchi-Levi and Yining Wang", "title": "Privacy-Preserving Dynamic Personalized Pricing with Demand Learning", "comments": "Final version. Accepted to Management Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of e-commerce has made detailed customers' personal\ninformation readily accessible to retailers, and this information has been\nwidely used in pricing decisions. When involving personalized information, how\nto protect the privacy of such information becomes a critical issue in\npractice. In this paper, we consider a dynamic pricing problem over $T$ time\nperiods with an \\emph{unknown} demand function of posted price and personalized\ninformation. At each time $t$, the retailer observes an arriving customer's\npersonal information and offers a price. The customer then makes the purchase\ndecision, which will be utilized by the retailer to learn the underlying demand\nfunction. There is potentially a serious privacy concern during this process: a\nthird party agent might infer the personalized information and purchase\ndecisions from price changes from the pricing system. Using the fundamental\nframework of differential privacy from computer science, we develop a\nprivacy-preserving dynamic pricing policy, which tries to maximize the retailer\nrevenue while avoiding information leakage of individual customer's information\nand purchasing decisions. To this end, we first introduce a notion of\n\\emph{anticipating} $(\\varepsilon, \\delta)$-differential privacy that is\ntailored to dynamic pricing problem. Our policy achieves both the privacy\nguarantee and the performance guarantee in terms of regret. Roughly speaking,\nfor $d$-dimensional personalized information, our algorithm achieves the\nexpected regret at the order of $\\tilde{O}(\\varepsilon^{-1} \\sqrt{d^3 T})$,\nwhen the customers' information is adversarially chosen. For stochastic\npersonalized information, the regret bound can be further improved to\n$\\tilde{O}(\\sqrt{d^2T} + \\varepsilon^{-2} d^2)$\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:32:34 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 18:53:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Xi", ""], ["Simchi-Levi", "David", ""], ["Wang", "Yining", ""]]}, {"id": "2009.12922", "submitter": "Olga Poppe", "authors": "Olga Poppe, Tayo Amuneke, Dalitso Banda, Aritra De, Ari Green, Manon\n  Knoertzer, Ehi Nosakhare, Karthik Rajendran, Deepak Shankargouda, Meina Wang,\n  Alan Au, Carlo Curino, Qun Guo, Alekh Jindal, Ajay Kalhan, Morgan Oslake,\n  Sonia Parchani, Vijay Ramani, Raj Sellappan, Saikat Sen, Sheetal Shrotri,\n  Soundararajan Srinivasan, Ping Xia, Shize Xu, Alicia Yang, Yiwen Zhu", "title": "Seagull: An Infrastructure for Load Prediction and Optimized Resource\n  Allocation", "comments": "Technical report for the paper in VLDB 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microsoft Azure is dedicated to guarantee high quality of service to its\ncustomers, in particular, during periods of high customer activity, while\ncontrolling cost. We employ a Data Science (DS) driven solution to predict user\nload and leverage these predictions to optimize resource allocation. To this\nend, we built the Seagull infrastructure that processes per-server telemetry,\nvalidates the data, trains and deploys ML models. The models are used to\npredict customer load per server (24h into the future), and optimize service\noperations. Seagull continually re-evaluates accuracy of predictions, fallback\nto previously known good models and triggers alerts as appropriate. We deployed\nthis infrastructure in production for PostgreSQL and MySQL servers across all\nAzure regions, and applied it to the problem of scheduling server backups\nduring low-load time. This minimizes interference with user-induced load and\nimproves customer experience.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:41:32 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 19:22:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Poppe", "Olga", ""], ["Amuneke", "Tayo", ""], ["Banda", "Dalitso", ""], ["De", "Aritra", ""], ["Green", "Ari", ""], ["Knoertzer", "Manon", ""], ["Nosakhare", "Ehi", ""], ["Rajendran", "Karthik", ""], ["Shankargouda", "Deepak", ""], ["Wang", "Meina", ""], ["Au", "Alan", ""], ["Curino", "Carlo", ""], ["Guo", "Qun", ""], ["Jindal", "Alekh", ""], ["Kalhan", "Ajay", ""], ["Oslake", "Morgan", ""], ["Parchani", "Sonia", ""], ["Ramani", "Vijay", ""], ["Sellappan", "Raj", ""], ["Sen", "Saikat", ""], ["Shrotri", "Sheetal", ""], ["Srinivasan", "Soundararajan", ""], ["Xia", "Ping", ""], ["Xu", "Shize", ""], ["Yang", "Alicia", ""], ["Zhu", "Yiwen", ""]]}, {"id": "2009.12923", "submitter": "Wasiq Khan Dr", "authors": "Wasiq Khan, Abir Hussain, Sohail Ahmed Khan, Mohammed Al-Jumailey,\n  Raheel Nawaz, Panos Liatsis", "title": "Analysing the impact of global demographic characteristics over the\n  COVID-19 spread using class rule mining and pattern matching", "comments": "Diversity in global death rate due to COVID-19 and Variant of Concern\n  202012/01 (VOC 202012/01)", "journal-ref": "Royal Society Open Science, 27 January 2021, Volume 8, Issue 1", "doi": "10.1098/rsos.201823", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the coronavirus disease (COVID-19) outbreak in December 2019, studies\nhave been addressing diverse aspects in relation to COVID-19 and Variant of\nConcern 202012/01 (VOC 202012/01) such as potential symptoms and predictive\ntools. However, limited work has been performed towards the modelling of\ncomplex associations between the combined demographic attributes and varying\nnature of the COVID-19 infections across the globe. This study presents an\nintelligent approach to investigate the multi-dimensional associations between\ndemographic attributes and COVID-19 global variations. We gather multiple\ndemographic attributes and COVID-19 infection data (by 8 January 2021) from\nreliable sources, which are then processed by intelligent algorithms to\nidentify the significant associations and patterns within the data. Statistical\nresults and experts' reports indicate strong associations between COVID-19\nseverity levels across the globe and certain demographic attributes, e.g.\nfemale smokers, when combined together with other attributes. The outcomes will\naid the understanding of the dynamics of disease spread and its progression,\nwhich in turn may support policy makers, medical specialists and society, in\nbetter understanding and effective management of the disease.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:43:18 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 06:54:37 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 11:07:45 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Khan", "Wasiq", ""], ["Hussain", "Abir", ""], ["Khan", "Sohail Ahmed", ""], ["Al-Jumailey", "Mohammed", ""], ["Nawaz", "Raheel", ""], ["Liatsis", "Panos", ""]]}, {"id": "2009.12928", "submitter": "Manohar Kaul", "authors": "Manohar Kaul and Dai Tamaki", "title": "A Weighted Quiver Kernel using Functor Homology", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose a new homological method to study weighted directed\nnetworks. Our model of such networks is a directed graph $Q$ equipped with a\nweight function $w$ on the set $Q_{1}$ of arrows in $Q$. We require that the\nrange $W$ of our weight function is equipped with an addition or a\nmultiplication, i.e., $W$ is a monoid in the mathematical terminology. When $W$\nis equipped with a representation on a vector space $M$, the standard method of\nhomological algebra allows us to define the homology groups $H_{*}(Q,w;M)$. It\nis known that when $Q$ has no oriented cycles, $H_{n}(Q,w;M)=0$ for $n\\ge 2$\nand $H_{1}(Q,w;M)$ can be easily computed. This fact allows us to define a new\ngraph kernel for weighted directed graphs. We made two sample computations with\nreal data and found that our method is practically applicable.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 19:35:28 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kaul", "Manohar", ""], ["Tamaki", "Dai", ""]]}, {"id": "2009.12939", "submitter": "Jean Barbier Dr.", "authors": "Jean Barbier, Dmitry Panchenko, Manuel S\\'aenz", "title": "Strong replica symmetry for high-dimensional disordered log-concave\n  Gibbs measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.dis-nn cs.IT cs.LG math-ph math.IT math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generic class of log-concave, possibly random, (Gibbs)\nmeasures. We prove the concentration of an infinite family of order parameters\ncalled multioverlaps. Because they completely parametrise the quenched Gibbs\nmeasure of the system, this implies a simple representation of the asymptotic\nGibbs measures, as well as the decoupling of the variables in a strong sense.\nThese results may prove themselves useful in several contexts. In particular in\nmachine learning and high-dimensional inference, log-concave measures appear in\nconvex empirical risk minimisation, maximum a-posteriori inference or\nM-estimation. We believe that they may be applicable in establishing some type\nof \"replica symmetric formulas\" for the free energy, inference or\ngeneralisation error in such settings.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 20:24:58 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 18:24:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Barbier", "Jean", ""], ["Panchenko", "Dmitry", ""], ["S\u00e1enz", "Manuel", ""]]}, {"id": "2009.12947", "submitter": "Romain Lopez", "authors": "Romain Lopez and Inderjit S. Dhillon and Michael I. Jordan", "title": "Learning from eXtreme Bandit Feedback", "comments": null, "journal-ref": "AAAI Conference on Artificial Intelligence 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of batch learning from bandit feedback in the setting of\nextremely large action spaces. Learning from extreme bandit feedback is\nubiquitous in recommendation systems, in which billions of decisions are made\nover sets consisting of millions of choices in a single day, yielding massive\nobservational data. In these large-scale real-world applications, supervised\nlearning frameworks such as eXtreme Multi-label Classification (XMC) are widely\nused despite the fact that they incur significant biases due to the mismatch\nbetween bandit feedback and supervised labels. Such biases can be mitigated by\nimportance sampling techniques, but these techniques suffer from impractical\nvariance when dealing with a large number of actions. In this paper, we\nintroduce a selective importance sampling estimator (sIS) that operates in a\nsignificantly more favorable bias-variance regime. The sIS estimator is\nobtained by performing importance sampling on the conditional expectation of\nthe reward with respect to a small subset of actions for each instance (a form\nof Rao-Blackwellization). We employ this estimator in a novel algorithmic\nprocedure -- named Policy Optimization for eXtreme Models (POXM) -- for\nlearning from bandit feedback on XMC tasks. In POXM, the selected actions for\nthe sIS estimator are the top-p actions of the logging policy, where p is\nadjusted from the data and is significantly smaller than the size of the action\nspace. We use a supervised-to-bandit conversion on three XMC datasets to\nbenchmark our POXM method against three competing methods: BanditNet, a\npreviously applied partial matching pruning strategy, and a supervised learning\nbaseline. Whereas BanditNet sometimes improves marginally over the logging\npolicy, our experiments show that POXM systematically and significantly\nimproves over all baselines.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 20:47:25 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 22:58:15 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Lopez", "Romain", ""], ["Dhillon", "Inderjit S.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2009.12966", "submitter": "Bruno Klaus de Aquino Afonso", "authors": "Bruno Klaus de Aquino Afonso, Lilian Berton", "title": "Analysis of label noise in graph-based semi-supervised learning", "comments": null, "journal-ref": null, "doi": "10.1145/3341105.3374013", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, one must acquire labels to help supervise a model that\nwill be able to generalize to unseen data. However, the labeling process can be\ntedious, long, costly, and error-prone. It is often the case that most of our\ndata is unlabeled. Semi-supervised learning (SSL) alleviates that by making\nstrong assumptions about the relation between the labels and the input data\ndistribution. This paradigm has been successful in practice, but most SSL\nalgorithms end up fully trusting the few available labels. In real life, both\nhumans and automated systems are prone to mistakes; it is essential that our\nalgorithms are able to work with labels that are both few and also unreliable.\nOur work aims to perform an extensive empirical evaluation of existing\ngraph-based semi-supervised algorithms, like Gaussian Fields and Harmonic\nFunctions, Local and Global Consistency, Laplacian Eigenmaps, Graph\nTransduction Through Alternating Minimization. To do that, we compare the\naccuracy of classifiers while varying the amount of labeled data and label\nnoise for many different samples. Our results show that, if the dataset is\nconsistent with SSL assumptions, we are able to detect the noisiest instances,\nalthough this gets harder when the number of available labels decreases. Also,\nthe Laplacian Eigenmaps algorithm performed better than label propagation when\nthe data came from high-dimensional clusters.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:13:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Afonso", "Bruno Klaus de Aquino", ""], ["Berton", "Lilian", ""]]}, {"id": "2009.12969", "submitter": "Yifang Liu", "authors": "Yifang Liu, Zhentao Xu, Qiyuan An, Yang Yi, Yanzhi Wang, Trevor Hastie", "title": "Simultaneous Relevance and Diversity: A New Recommendation Inference\n  Approach", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance and diversity are both important to the success of recommender\nsystems, as they help users to discover from a large pool of items a compact\nset of candidates that are not only interesting but exploratory as well. The\nchallenge is that relevance and diversity usually act as two competing\nobjectives in conventional recommender systems, which necessities the classic\ntrade-off between exploitation and exploration. Traditionally, higher diversity\noften means sacrifice on relevance and vice versa. We propose a new approach,\nheterogeneous inference, which extends the general collaborative filtering (CF)\nby introducing a new way of CF inference, negative-to-positive. Heterogeneous\ninference achieves divergent relevance, where relevance and diversity support\neach other as two collaborating objectives in one recommendation model, and\nwhere recommendation diversity is an inherent outcome of the relevance\ninference process. Benefiting from its succinctness and flexibility, our\napproach is applicable to a wide range of recommendation scenarios/use-cases at\nvarious sophistication levels. Our analysis and experiments on public datasets\nand real-world production data show that our approach outperforms existing\nmethods on relevance and diversity simultaneously.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:20:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Yifang", ""], ["Xu", "Zhentao", ""], ["An", "Qiyuan", ""], ["Yi", "Yang", ""], ["Wang", "Yanzhi", ""], ["Hastie", "Trevor", ""]]}, {"id": "2009.12976", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog, Po-Ling Loh", "title": "Robust regression with covariate filtering: Heavy tails and adversarial\n  contamination", "comments": "V2: Adds new results for unknown covariance matrix (Theorem 3.13),\n  Gaussian design (Remark 3.12), and Simulations (Section 7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of linear regression where both covariates and responses\nare potentially (i) heavy-tailed and (ii) adversarially contaminated. Several\ncomputationally efficient estimators have been proposed for the simpler setting\nwhere the covariates are sub-Gaussian and uncontaminated; however, these\nestimators may fail when the covariates are either heavy-tailed or contain\noutliers. In this work, we show how to modify the Huber regression, least\ntrimmed squares, and least absolute deviation estimators to obtain estimators\nwhich are simultaneously computationally and statistically efficient in the\nstronger contamination model. Our approach is quite simple, and consists of\napplying a filtering algorithm to the covariates, and then applying the\nclassical robust regression estimators to the remaining data. We show that the\nHuber regression estimator achieves near-optimal error rates in this setting,\nwhereas the least trimmed squares and least absolute deviation estimators can\nbe made to achieve near-optimal error after applying a postprocessing step.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:48:48 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 16:40:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "2009.12981", "submitter": "Tim Sainburg", "authors": "Tim Sainburg, Leland McInnes, Timothy Q Gentner", "title": "Parametric UMAP embeddings for representation and semi-supervised\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UMAP is a non-parametric graph-based dimensionality reduction algorithm using\napplied Riemannian geometry and algebraic topology to find low-dimensional\nembeddings of structured data. The UMAP algorithm consists of two steps: (1)\nCompute a graphical representation of a dataset (fuzzy simplicial complex), and\n(2) Through stochastic gradient descent, optimize a low-dimensional embedding\nof the graph. Here, we extend the second step of UMAP to a parametric\noptimization over neural network weights, learning a parametric relationship\nbetween data and embedding. We first demonstrate that Parametric UMAP performs\ncomparably to its non-parametric counterpart while conferring the benefit of a\nlearned parametric mapping (e.g. fast online embeddings for new data). We then\nexplore UMAP as a regularization, constraining the latent distribution of\nautoencoders, parametrically varying global structure preservation, and\nimproving classifier accuracy for semi-supervised learning by capturing\nstructure in unlabeled data. Google Colab walkthrough:\nhttps://colab.research.google.com/drive/1WkXVZ5pnMrm17m0YgmtoNjM_XHdnE5Vp?usp=sharing\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 23:45:00 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 00:49:12 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 04:46:06 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sainburg", "Tim", ""], ["McInnes", "Leland", ""], ["Gentner", "Timothy Q", ""]]}, {"id": "2009.12991", "submitter": "Kaihua Tang", "authors": "Kaihua Tang, Jianqiang Huang, Hanwang Zhang", "title": "Long-Tailed Classification by Keeping the Good and Removing the Bad\n  Momentum Causal Effect", "comments": "This paper is accepted by NeurIPS 2020. The code is available on\n  GitHub: https://github.com/KaihuaTang/Long-Tailed-Recognition.pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the class size grows, maintaining a balanced dataset across many classes\nis challenging because the data are long-tailed in nature; it is even\nimpossible when the sample-of-interest co-exists with each other in one\ncollectable unit, e.g., multiple visual instances in one image. Therefore,\nlong-tailed classification is the key to deep learning at scale. However,\nexisting methods are mainly based on re-weighting/re-sampling heuristics that\nlack a fundamental theory. In this paper, we establish a causal inference\nframework, which not only unravels the whys of previous methods, but also\nderives a new principled solution. Specifically, our theory shows that the SGD\nmomentum is essentially a confounder in long-tailed classification. On one\nhand, it has a harmful causal effect that misleads the tail prediction biased\ntowards the head. On the other hand, its induced mediation also benefits the\nrepresentation learning and head prediction. Our framework elegantly\ndisentangles the paradoxical effects of the momentum, by pursuing the direct\ncausal effect caused by an input sample. In particular, we use causal\nintervention in training, and counterfactual reasoning in inference, to remove\nthe \"bad\" while keep the \"good\". We achieve new state-of-the-arts on three\nlong-tailed visual recognition benchmarks: Long-tailed CIFAR-10/-100,\nImageNet-LT for image classification and LVIS for instance segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 00:32:11 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 03:36:22 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 12:02:59 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 04:10:13 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tang", "Kaihua", ""], ["Huang", "Jianqiang", ""], ["Zhang", "Hanwang", ""]]}, {"id": "2009.12997", "submitter": "Haoding Meng Souray", "authors": "Haoding Meng, Qingcheng Zeng, Xiaoyang Fang, Zhexin Liang", "title": "Fancy Man Lauches Zippo at WNUT 2020 Shared Task-1: A Bert Case Model\n  for Wet Lab Entity Extraction", "comments": "EMNLP2020 WNUT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic or semi-automatic conversion of protocols specifying steps in\nperforming a lab procedure into machine-readable format benefits biological\nresearch a lot. These noisy, dense, and domain-specific lab protocols\nprocessing draws more and more interests with the development of deep learning.\nThis paper presents our teamwork on WNUT 2020 shared task-1: wet lab entity\nextract, that we conducted studies in several models, including a BiLSTM CRF\nmodel and a Bert case model which can be used to complete wet lab entity\nextraction. And we mainly discussed the performance differences of \\textbf{Bert\ncase} under different situations such as \\emph{transformers} versions, case\nsensitivity that may don't get enough attention before.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:05:08 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Meng", "Haoding", ""], ["Zeng", "Qingcheng", ""], ["Fang", "Xiaoyang", ""], ["Liang", "Zhexin", ""]]}, {"id": "2009.12999", "submitter": "Shaoming Song", "authors": "Shaoming Song, Yunfeng Shao, Jian Li", "title": "Loosely Coupled Federated Learning Over Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) was proposed to achieve collaborative machine\nlearning among various clients without uploading private data. However, due to\nmodel aggregation strategies, existing frameworks require strict model\nhomogeneity, limiting the application in more complicated scenarios. Besides,\nthe communication cost of FL's model and gradient transmission is extremely\nhigh. This paper proposes Loosely Coupled Federated Learning (LC-FL), a\nframework using generative models as transmission media to achieve low\ncommunication cost and heterogeneous federated learning. LC-FL can be applied\non scenarios where clients possess different kinds of machine learning models.\nExperiments on real-world datasets covering different multiparty scenarios\ndemonstrate the effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:09:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Song", "Shaoming", ""], ["Shao", "Yunfeng", ""], ["Li", "Jian", ""]]}, {"id": "2009.13000", "submitter": "Zhongqi Yue", "authors": "Zhongqi Yue and Hanwang Zhang and Qianru Sun and Xian-Sheng Hua", "title": "Interventional Few-Shot Learning", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We uncover an ever-overlooked deficiency in the prevailing Few-Shot Learning\n(FSL) methods: the pre-trained knowledge is indeed a confounder that limits the\nperformance. This finding is rooted from our causal assumption: a Structural\nCausal Model (SCM) for the causalities among the pre-trained knowledge, sample\nfeatures, and labels. Thanks to it, we propose a novel FSL paradigm:\nInterventional Few-Shot Learning (IFSL). Specifically, we develop three\neffective IFSL algorithmic implementations based on the backdoor adjustment,\nwhich is essentially a causal intervention towards the SCM of many-shot\nlearning: the upper-bound of FSL in a causal view. It is worth noting that the\ncontribution of IFSL is orthogonal to existing fine-tuning and meta-learning\nbased FSL methods, hence IFSL can improve all of them, achieving a new\n1-/5-shot state-of-the-art on \\textit{mini}ImageNet, \\textit{tiered}ImageNet,\nand cross-domain CUB. Code is released at https://github.com/yue-zhongqi/ifsl.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:16:54 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 06:51:09 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Yue", "Zhongqi", ""], ["Zhang", "Hanwang", ""], ["Sun", "Qianru", ""], ["Hua", "Xian-Sheng", ""]]}, {"id": "2009.13003", "submitter": "Yu Chen", "authors": "Yu Chen, Zhenming Liu, Bin Ren, Xin Jin", "title": "On Efficient Constructions of Checkpoints", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Efficient construction of checkpoints/snapshots is a critical tool for\ntraining and diagnosing deep learning models. In this paper, we propose a lossy\ncompression scheme for checkpoint constructions (called LC-Checkpoint).\nLC-Checkpoint simultaneously maximizes the compression rate and optimizes the\nrecovery speed, under the assumption that SGD is used to train the model.\nLC-Checkpointuses quantization and priority promotion to store the most crucial\ninformation for SGD to recover, and then uses a Huffman coding to leverage the\nnon-uniform distribution of the gradient scales. Our extensive experiments show\nthat LC-Checkpoint achieves a compression rate up to $28\\times$ and recovery\nspeedup up to $5.77\\times$ over a state-of-the-art algorithm (SCAR).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:20:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Yu", ""], ["Liu", "Zhenming", ""], ["Ren", "Bin", ""], ["Jin", "Xin", ""]]}, {"id": "2009.13008", "submitter": "Anjul Tyagi", "authors": "Anjul Tyagi, Cong Xie, Klaus Mueller", "title": "Visual Steering for One-Shot Deep Neural Network Synthesis", "comments": "9 pages, submitted to IEEE Transactions on Visualization and Computer\n  Graphics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in the area of deep learning have shown the effectiveness\nof very large neural networks in several applications. However, as these deep\nneural networks continue to grow in size, it becomes more and more difficult to\nconfigure their many parameters to obtain good results. Presently, analysts\nmust experiment with many different configurations and parameter settings,\nwhich is labor-intensive and time-consuming. On the other hand, the capacity of\nfully automated techniques for neural network architecture search is limited\nwithout the domain knowledge of human experts. To deal with the problem, we\nformulate the task of neural network architecture optimization as a graph space\nexploration, based on the one-shot architecture search technique. In this\napproach, a super-graph of all candidate architectures is trained in one-shot\nand the optimal neural network is identified as a sub-graph. In this paper, we\npresent a framework that allows analysts to effectively build the solution\nsub-graph space and guide the network search by injecting their domain\nknowledge. Starting with the network architecture space composed of basic\nneural network components, analysts are empowered to effectively select the\nmost promising components via our one-shot search scheme. Applying this\ntechnique in an iterative manner allows analysts to converge to the best\nperforming neural network architecture for a given application. During the\nexploration, analysts can use their domain knowledge aided by cues provided\nfrom a scatterplot visualization of the search space to edit different\ncomponents and guide the search for faster convergence. We designed our\ninterface in collaboration with several deep learning researchers and its final\neffectiveness is evaluated with a user study and two case studies.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:48:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tyagi", "Anjul", ""], ["Xie", "Cong", ""], ["Mueller", "Klaus", ""]]}, {"id": "2009.13011", "submitter": "Dandan Guo", "authors": "Dandan Guo, Bo Chen (Senior Member, IEEE), Wenchao Chen, Chaojie Wang,\n  Hongwei Liu (Member, IEEE), and Mingyuan Zhou", "title": "Variational Temporal Deep Generative Model for Radar HRRP Target\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3027470", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a recurrent gamma belief network (rGBN) for radar automatic target\nrecognition (RATR) based on high-resolution range profile (HRRP), which\ncharacterizes the temporal dependence across the range cells of HRRP. The\nproposed rGBN adopts a hierarchy of gamma distributions to build its temporal\ndeep generative model. For scalable training and fast out-of-sample prediction,\nwe propose the hybrid of a stochastic-gradient Markov chain Monte Carlo (MCMC)\nand a recurrent variational inference model to perform posterior inference. To\nutilize the label information to extract more discriminative latent\nrepresentations, we further propose supervised rGBN to jointly model the HRRP\nsamples and their corresponding labels. Experimental results on synthetic and\nmeasured HRRP data show that the proposed models are efficient in computation,\nhave good classification accuracy and generalization ability, and provide\nhighly interpretable multi-stochastic-layer latent structure.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:03:51 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Guo", "Dandan", "", "Senior Member, IEEE"], ["Chen", "Bo", "", "Senior Member, IEEE"], ["Chen", "Wenchao", "", "Member, IEEE"], ["Wang", "Chaojie", "", "Member, IEEE"], ["Liu", "Hongwei", "", "Member, IEEE"], ["Zhou", "Mingyuan", ""]]}, {"id": "2009.13013", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Xiaopeng Lu, Kyusong Lee", "title": "SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer\n  Matching Retrieval", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SPARTA, a novel neural retrieval method that shows great promise\nin performance, generalization, and interpretability for open-domain question\nanswering. Unlike many neural ranking methods that use dense vector nearest\nneighbor search, SPARTA learns a sparse representation that can be efficiently\nimplemented as an Inverted Index. The resulting representation enables scalable\nneural retrieval that does not require expensive approximate vector search and\nleads to better performance than its dense counterpart. We validated our\napproaches on 4 open-domain question answering (OpenQA) tasks and 11 retrieval\nquestion answering (ReQA) tasks. SPARTA achieves new state-of-the-art results\nacross a variety of open-domain question answering tasks in both English and\nChinese datasets, including open SQuAD, Natuarl Question, CMRC and etc.\nAnalysis also confirms that the proposed method creates human interpretable\nrepresentation and allows flexible control over the trade-off between\nperformance and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:11:02 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Lu", "Xiaopeng", ""], ["Lee", "Kyusong", ""]]}, {"id": "2009.13016", "submitter": "Krishnakumar Balasubramanian", "authors": "Abhishek Roy, Krishnakumar Balasubramanian, Saeed Ghadimi, Prasant\n  Mohapatra", "title": "Escaping Saddle-Points Faster under Interpolation-like Conditions", "comments": "To appear in NeurIPS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that under over-parametrization several standard\nstochastic optimization algorithms escape saddle-points and converge to\nlocal-minimizers much faster. One of the fundamental aspects of\nover-parametrized models is that they are capable of interpolating the training\ndata. We show that, under interpolation-like assumptions satisfied by the\nstochastic gradients in an over-parametrization setting, the first-order oracle\ncomplexity of Perturbed Stochastic Gradient Descent (PSGD) algorithm to reach\nan $\\epsilon$-local-minimizer, matches the corresponding deterministic rate of\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{2})$. We next analyze Stochastic\nCubic-Regularized Newton (SCRN) algorithm under interpolation-like conditions,\nand show that the oracle complexity to reach an $\\epsilon$-local-minimizer\nunder interpolation-like conditions, is\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{2.5})$. While this obtained complexity is\nbetter than the corresponding complexity of either PSGD, or SCRN without\ninterpolation-like assumptions, it does not match the rate of\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{1.5})$ corresponding to deterministic\nCubic-Regularized Newton method. It seems further Hessian-based\ninterpolation-like assumptions are necessary to bridge this gap. We also\ndiscuss the corresponding improved complexities in the zeroth-order settings.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:15:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Roy", "Abhishek", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2009.13028", "submitter": "Haochen Liu", "authors": "Haochen Liu, Wentao Wang, Yiqi Wang, Hui Liu, Zitao Liu and Jiliang\n  Tang", "title": "Mitigating Gender Bias for Neural Dialogue Generation with Adversarial\n  Learning", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems play an increasingly important role in various aspects of\nour daily life. It is evident from recent research that dialogue systems\ntrained on human conversation data are biased. In particular, they can produce\nresponses that reflect people's gender prejudice. Many debiasing methods have\nbeen developed for various NLP tasks, such as word embedding. However, they are\nnot directly applicable to dialogue systems because they are likely to force\ndialogue models to generate similar responses for different genders. This\ngreatly degrades the diversity of the generated responses and immensely hurts\nthe performance of the dialogue models. In this paper, we propose a novel\nadversarial learning framework Debiased-Chat to train dialogue models free from\ngender bias while keeping their performance. Extensive experiments on two\nreal-world conversation datasets show that our framework significantly reduces\ngender bias in dialogue models while maintaining the response quality. The\nimplementation of the proposed framework is released.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:46:59 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 19:36:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Haochen", ""], ["Wang", "Wentao", ""], ["Wang", "Yiqi", ""], ["Liu", "Hui", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "2009.13032", "submitter": "Hong Zhao", "authors": "Hong Zhao", "title": "Inferring Global Dynamics Using a Learning Machine", "comments": "12 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1905.08313", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a segment of time series of a system at a particular set of parameter\nvalues, can one infers the global behavior of the system in its parameter\nspace? Here we show that by using a learning machine we can achieve such a goal\nto a certain extent. It is found that following an appropriate training\nstrategy that monotonously decreases the cost function, the learning machine in\ndifferent training stage can mimic the system at different parameter set.\nConsequently, the global dynamical properties of the system is subsequently\nrevealed, usually in the simple-to-complex order. The underlying mechanism is\nattributed to the training strategy, which causes the learning machine to\ncollapse to a qualitatively equivalent system of the system behind the time\nseries. Thus, the learning machine opens up a novel way to probe the global\ndynamical properties of a black-box system without artificially establish the\nequations of motion. The given illustrating examples include a representative\nmodel of low-dimensional nonlinear dynamical systems and a spatiotemporal model\nof reaction-diffusion systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:54:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Hong", ""]]}, {"id": "2009.13033", "submitter": "Chang Liao", "authors": "Chang Liao, Yao Cheng, Chengfang Fang, Jie Shi", "title": "Where Does the Robustness Come from? A Study of the Transformation-based\n  Ensemble Defence", "comments": "The 27th ACM Conference on Computer and Communications Security (CCS)\n  Workshop, AISec 2020", "journal-ref": "the 13th ACM Workshop on Artificial Intelligence and Security 2020", "doi": "10.1145/3411508.3421380", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide a thorough study on the effectiveness of the\ntransformation-based ensemble defence for image classification and its reasons.\nIt has been empirically shown that they can enhance the robustness against\nevasion attacks, while there is little analysis on the reasons. In particular,\nit is not clear whether the robustness improvement is a result of\ntransformation or ensemble. In this paper, we design two adaptive attacks to\nbetter evaluate the transformation-based ensemble defence. We conduct\nexperiments to show that 1) the transferability of adversarial examples exists\namong the models trained on data records after different reversible\ntransformations; 2) the robustness gained through transformation-based ensemble\nis limited; 3) this limited robustness is mainly from the irreversible\ntransformations rather than the ensemble of a number of models; and 4) blindly\nincreasing the number of sub-models in a transformation-based ensemble does not\nbring extra robustness gain.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:55:56 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 09:16:18 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Liao", "Chang", ""], ["Cheng", "Yao", ""], ["Fang", "Chengfang", ""], ["Shi", "Jie", ""]]}, {"id": "2009.13038", "submitter": "Zhou Xianchen", "authors": "Xianchen Zhou, Yaoyun Zeng, Hongxia Wang", "title": "RoGAT: a robust GNN combined revised GAT with adjusted graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks(GNNs) are useful deep learning models to deal with the\nnon-Euclid data. However, recent works show that GNNs are vulnerable to\nadversarial attacks. Small perturbations can lead to poor performance in many\nGNNs, such as Graph attention networks(GATs). Therefore, enhancing the\nrobustness of GNNs is a critical problem.\n  Robust GAT(RoGAT) is proposed to improve the robustness of GNNs in this\npaper, . Note that the original GAT uses the attention mechanism for different\nedges but is still sensitive to the perturbation, RoGAT adjusts the edges'\nweight to adjust the attention scores progressively. Firstly, RoGAT tunes the\nedges weight based on the assumption that the adjacent nodes should have\nsimilar nodes. Secondly, RoGAT further tunes the features to eliminate\nfeature's noises since even for the clean graph, there exists some unreasonable\ndata. Then, we trained the adjusted GAT model to defense the adversarial\nattacks. Different experiments against targeted and untargeted attacks\ndemonstrate that RoGAT outperforms significantly than most the state-of-the-art\ndefense methods. The implementation of RoGAT based on the DeepRobust repository\nfor adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:10:09 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 08:32:45 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhou", "Xianchen", ""], ["Zeng", "Yaoyun", ""], ["Wang", "Hongxia", ""]]}, {"id": "2009.13040", "submitter": "Yudong Chen", "authors": "Yudong Chen and Xumei Xi", "title": "Likelihood Landscape and Local Minima Structures of Gaussian Mixture\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the landscape of the population negative\nlog-likelihood function of Gaussian Mixture Models with a general number of\ncomponents. Due to nonconvexity, there exist multiple local minima that are not\nglobally optimal, even when the mixture is well-separated. We show that all\nlocal minima share the same form of structure that partially identifies the\ncomponent centers of the true mixture, in the sense that each local minimum\ninvolves a non-overlapping combination of fitting multiple Gaussians to a\nsingle true component and fitting a single Gaussian to multiple true\ncomponents. Our results apply to the setting where the true mixture components\nsatisfy a certain separation condition, and are valid even when the number of\ncomponents is over-or under-specified. For Gaussian mixtures with three\ncomponents, we obtain sharper results in terms of the scaling with the\nseparation between the components.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:23:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Yudong", ""], ["Xi", "Xumei", ""]]}, {"id": "2009.13044", "submitter": "Yixing Xu", "authors": "Yixing Xu, Chang Xu, Xinghao Chen, Wei Zhang, Chunjing Xu, Yunhe Wang", "title": "Kernel Based Progressive Distillation for Adder Neural Networks", "comments": "Accepted by NeurIPS 2020, spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adder Neural Networks (ANNs) which only contain additions bring us a new way\nof developing deep neural networks with low energy consumption. Unfortunately,\nthere is an accuracy drop when replacing all convolution filters by adder\nfilters. The main reason here is the optimization difficulty of ANNs using\n$\\ell_1$-norm, in which the estimation of gradient in back propagation is\ninaccurate. In this paper, we present a novel method for further improving the\nperformance of ANNs without increasing the trainable parameters via a\nprogressive kernel based knowledge distillation (PKKD) method. A convolutional\nneural network (CNN) with the same architecture is simultaneously initialized\nand trained as a teacher network, features and weights of ANN and CNN will be\ntransformed to a new space to eliminate the accuracy drop. The similarity is\nconducted in a higher-dimensional space to disentangle the difference of their\ndistributions using a kernel based method. Finally, the desired ANN is learned\nbased on the information from both the ground-truth and teacher, progressively.\nThe effectiveness of the proposed method for learning ANN with higher\nperformance is then well-verified on several benchmarks. For instance, the\nANN-50 trained using the proposed PKKD method obtains a 76.8\\% top-1 accuracy\non ImageNet dataset, which is 0.6\\% higher than that of the ResNet-50.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:29:19 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 07:11:37 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 03:39:58 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Xu", "Yixing", ""], ["Xu", "Chang", ""], ["Chen", "Xinghao", ""], ["Zhang", "Wei", ""], ["Xu", "Chunjing", ""], ["Wang", "Yunhe", ""]]}, {"id": "2009.13051", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Benjamin Black, Ananth Hari,\n  Caroline Horsch, Luis Santos", "title": "Agent Environment Cycle Games", "comments": "This work of this paper has been merged into the paper \"PettingZoo:\n  Gym for Multi-Agent Reinforcement Learning\" arXiv:2009.14471", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially Observable Stochastic Games (POSGs) are the most general and common\nmodel of games used in Multi-Agent Reinforcement Learning (MARL). We argue that\nthe POSG model is conceptually ill suited to software MARL environments, and\noffer case studies from the literature where this mismatch has led to severely\nunexpected behavior. In response to this, we introduce the Agent Environment\nCycle Games (AEC Games) model, which is more representative of software\nimplementation. We then prove it's as an equivalent model to POSGs. The AEC\ngames model is also uniquely useful in that it can elegantly represent both all\nforms of MARL environments, whereas for example POSGs cannot elegantly\nrepresent strictly turn based games like chess.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:02:08 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 19:06:59 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 14:24:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Black", "Benjamin", ""], ["Hari", "Ananth", ""], ["Horsch", "Caroline", ""], ["Santos", "Luis", ""]]}, {"id": "2009.13059", "submitter": "Shashwat Aggarwal", "authors": "Shashwat Aggarwal, Ramesh Singh", "title": "Visual Exploration and Knowledge Discovery from Biomedical Dark Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data visualization techniques proffer efficient means to organize and present\ndata in graphically appealing formats, which not only speeds up the process of\ndecision making and pattern recognition but also enables decision-makers to\nfully understand data insights and make informed decisions. Over time, with the\nrise in technological and computational resources, there has been an\nexponential increase in the world's scientific knowledge. However, most of it\nlacks structure and cannot be easily categorized and imported into regular\ndatabases. This type of data is often termed as Dark Data. Data visualization\ntechniques provide a promising solution to explore such data by allowing quick\ncomprehension of information, the discovery of emerging trends, identification\nof relationships and patterns, etc. In this empirical research study, we use\nthe rich corpus of PubMed comprising of more than 30 million citations from\nbiomedical literature to visually explore and understand the underlying\nkey-insights using various information visualization techniques. We employ a\nnatural language processing based pipeline to discover knowledge out of the\nbiomedical dark data. The pipeline comprises of different lexical analysis\ntechniques like Topic Modeling to extract inherent topics and major focus\nareas, Network Graphs to study the relationships between various entities like\nscientific documents and journals, researchers, and, keywords and terms, etc.\nWith this analytical research, we aim to proffer a potential solution to\novercome the problem of analyzing overwhelming amounts of information and\ndiminish the limitation of human cognition and perception in handling and\nexamining such large volumes of data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:27:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aggarwal", "Shashwat", ""], ["Singh", "Ramesh", ""]]}, {"id": "2009.13062", "submitter": "Joo Seong Jeong", "authors": "Joo Seong Jeong, Soojeong Kim, Gyeong-In Yu, Yunseong Lee, Byung-Gon\n  Chun", "title": "Accelerating Multi-Model Inference by Merging DNNs of Different Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardized DNN models that have been proved to perform well on machine\nlearning tasks are widely used and often adopted as-is to solve downstream\ntasks, forming the transfer learning paradigm. However, when serving multiple\ninstances of such DNN models from a cluster of GPU servers, existing techniques\nto improve GPU utilization such as batching are inapplicable because models\noften do not share weights due to fine-tuning. We propose NetFuse, a technique\nof merging multiple DNN models that share the same architecture but have\ndifferent weights and different inputs. NetFuse is made possible by replacing\noperations with more general counterparts that allow a set of weights to be\nassociated with only a certain set of inputs. Experiments on ResNet-50,\nResNeXt-50, BERT, and XLNet show that NetFuse can speed up DNN inference time\nup to 3.6x on a NVIDIA V100 GPU, and up to 3.0x on a TITAN Xp GPU when merging\n32 model instances, while only using up a small additional amount of GPU\nmemory.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:33:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Jeong", "Joo Seong", ""], ["Kim", "Soojeong", ""], ["Yu", "Gyeong-In", ""], ["Lee", "Yunseong", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "2009.13092", "submitter": "Masahiro Kato", "authors": "Masahiro Kato and Shota Yasui", "title": "Learning Classifiers under Delayed Feedback with a Time Window\n  Assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training a binary classifier under delayed feedback (DF\nLearning). In DF Learning, we first receive negative samples; subsequently,\nsome samples turn positive. This problem is conceivable in various real-world\napplications such as online advertisements, where the user action takes place\nlong after the first click. Owing to the delayed feedback, simply separating\nthe positive and negative data causes a sample selection bias. One solution is\nto assume that a long time window after first observing a sample reduces the\nsample selection bias. However, existing studies report that only using a\nportion of all samples based on the time window assumption yields suboptimal\nperformance, and the use of all samples along with the time window assumption\nimproves empirical performance. Extending these existing studies, we propose a\nmethod with an unbiased and convex empirical risk constructed from the whole\nsamples under the time window assumption. We provide experimental results to\ndemonstrate the effectiveness of the proposed method using a real traffic log\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:20:24 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kato", "Masahiro", ""], ["Yasui", "Shota", ""]]}, {"id": "2009.13093", "submitter": "Neng Wan", "authors": "Neng Wan, Dapeng Li, and Naira Hovakimyan", "title": "f-Divergence Variational Inference", "comments": "Dapeng Li and Neng Wan contributed equally to this paper.\n  Supplementary material is attached. The links to code are provided in the\n  paper, supplementary material and reference list. To appear in Advances in\n  Neural Information Processing Systems 33 (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the $f$-divergence variational inference ($f$-VI) that\ngeneralizes variational inference to all $f$-divergences. Initiated from\nminimizing a crafty surrogate $f$-divergence that shares the statistical\nconsistency with the $f$-divergence, the $f$-VI framework not only unifies a\nnumber of existing VI methods, e.g. Kullback-Leibler VI, R\\'{e}nyi's\n$\\alpha$-VI, and $\\chi$-VI, but offers a standardized toolkit for VI subject to\narbitrary divergences from $f$-divergence family. A general $f$-variational\nbound is derived and provides a sandwich estimate of marginal likelihood (or\nevidence). The development of the $f$-VI unfolds with a stochastic optimization\nscheme that utilizes the reparameterization trick, importance weighting and\nMonte Carlo approximation; a mean-field approximation scheme that generalizes\nthe well-known coordinate ascent variational inference (CAVI) is also proposed\nfor $f$-VI. Empirical examples, including variational autoencoders and Bayesian\nneural networks, are provided to demonstrate the effectiveness and the wide\napplicability of $f$-VI.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:22:05 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:53:24 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 04:47:37 GMT"}, {"version": "v4", "created": "Sat, 3 Apr 2021 16:33:25 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wan", "Neng", ""], ["Li", "Dapeng", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "2009.13094", "submitter": "Takashi Mori", "authors": "Takashi Mori, Masahito Ueda", "title": "Improved generalization by noise enhancement", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that noise in stochastic gradient descent\n(SGD) is closely related to generalization: A larger SGD noise, if not too\nlarge, results in better generalization. Since the covariance of the SGD noise\nis proportional to $\\eta^2/B$, where $\\eta$ is the learning rate and $B$ is the\nminibatch size of SGD, the SGD noise has so far been controlled by changing\n$\\eta$ and/or $B$. However, too large $\\eta$ results in instability in the\ntraining dynamics and a small $B$ prevents scalable parallel computation. It is\nthus desirable to develop a method of controlling the SGD noise without\nchanging $\\eta$ and $B$. In this paper, we propose a method that achieves this\ngoal using ``noise enhancement'', which is easily implemented in practice. We\nexpound the underlying theoretical idea and demonstrate that the noise\nenhancement actually improves generalization for real datasets. It turns out\nthat large-batch training with the noise enhancement even shows better\ngeneralization compared with small-batch training.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 06:29:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mori", "Takashi", ""], ["Ueda", "Masahito", ""]]}, {"id": "2009.13101", "submitter": "R\\'emi Eyraud", "authors": "Remi Eyraud and Stephane Ayache", "title": "Distillation of Weighted Automata from Recurrent Neural Networks using a\n  Spectral Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper is an attempt to bridge the gap between deep learning and\ngrammatical inference. Indeed, it provides an algorithm to extract a\n(stochastic) formal language from any recurrent neural network trained for\nlanguage modelling. In detail, the algorithm uses the already trained network\nas an oracle -- and thus does not require the access to the inner\nrepresentation of the black-box -- and applies a spectral approach to infer a\nweighted automaton.\n  As weighted automata compute linear functions, they are computationally more\nefficient than neural networks and thus the nature of the approach is the one\nof knowledge distillation. We detail experiments on 62 data sets (both\nsynthetic and from real-world applications) that allow an in-depth study of the\nabilities of the proposed algorithm. The results show the WA we extract are\ngood approximations of the RNN, validating the approach. Moreover, we show how\nthe process provides interesting insights toward the behavior of RNN learned on\ndata, enlarging the scope of this work to the one of explainability of deep\nlearning models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:04:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Eyraud", "Remi", ""], ["Ayache", "Stephane", ""]]}, {"id": "2009.13102", "submitter": "Xian Li", "authors": "Xian Li, Asa Cooper Stickland, Yuqing Tang, and Xiang Kong", "title": "Deep Transformers with Latent Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer model has achieved state-of-the-art performance in many\nsequence modeling tasks. However, how to leverage model capacity with large or\nvariable depths is still an open challenge. We present a probabilistic\nframework to automatically learn which layer(s) to use by learning the\nposterior distributions of layer selection. As an extension of this framework,\nwe propose a novel method to train one shared Transformer network for\nmultilingual machine translation with different layer selection posteriors for\neach language pair. The proposed method alleviates the vanishing gradient issue\nand enables stable training of deep Transformers (e.g. 100 layers). We evaluate\non WMT English-German machine translation and masked language modeling tasks,\nwhere our method outperforms existing approaches for training deeper\nTransformers. Experiments on multilingual machine translation demonstrate that\nthis approach can effectively leverage increased model capacity and bring\nuniversal improvement for both many-to-one and one-to-many translation with\ndiverse language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:13:23 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:50:56 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Xian", ""], ["Stickland", "Asa Cooper", ""], ["Tang", "Yuqing", ""], ["Kong", "Xiang", ""]]}, {"id": "2009.13116", "submitter": "Anh Khoa Ngo Ho", "authors": "Anh Khoa Ngo Ho (LIMSI), Fran\\c{c}ois Yvon", "title": "Neural Baselines for Word Alignment", "comments": "The 16th International Workshop on Spoken Language Translation, Nov\n  2019, Hong Kong, Hong Kong SAR China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word alignments identify translational correspondences between words in a\nparallel sentence pair and is used, for instance, to learn bilingual\ndictionaries, to train statistical machine translation systems , or to perform\nquality estimation. In most areas of natural language processing, neural\nnetwork models nowadays constitute the preferred approach, a situation that\nmight also apply to word alignment models. In this work, we study and\ncomprehensively evaluate neural models for unsupervised word alignment for four\nlanguage pairs, contrasting several variants of neural models. We show that in\nmost settings, neural versions of the IBM-1 and hidden Markov models vastly\noutperform their discrete counterparts. We also analyze typical alignment\nerrors of the baselines that our models overcome to illustrate the benefits-and\nthe limitations-of these new models for morphologically rich languages.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:51:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ho", "Anh Khoa Ngo", "", "LIMSI"], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "2009.13117", "submitter": "Anh Khoa Ngo Ho", "authors": "Anh Khoa Ngo Ho (LIMSI), Fran\\c{c}ois Yvon", "title": "Generative latent neural models for automatic word alignment", "comments": null, "journal-ref": "The Association for Machine Translation in the Americas, Oct 2020,\n  Florida, United States", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word alignments identify translational correspondences between words in a\nparallel sentence pair and are used, for instance, to learn bilingual\ndictionaries, to train statistical machine translation systems or to perform\nquality estimation. Variational autoencoders have been recently used in various\nof natural language processing to learn in an unsupervised way latent\nrepresentations that are useful for language generation tasks. In this paper,\nwe study these models for the task of word alignment and propose and assess\nseveral evolutions of a vanilla variational autoencoders. We demonstrate that\nthese techniques can yield competitive results as compared to Giza++ and to a\nstrong neural network alignment system for two language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:54:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ho", "Anh Khoa Ngo", "", "LIMSI"], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "2009.13134", "submitter": "Yuanfei Huang", "authors": "Yuanfei Huang, Jie Li, Xinbo Gao, Yanting Hu, Wen Lu", "title": "Interpretable Detail-Fidelity Attention Network for Single Image\n  Super-Resolution", "comments": "14 pages, submitted to IEEE Transactions, codes are available at\n  https://github.com/YuanfeiHuang/DeFiAN", "journal-ref": null, "doi": "10.1109/TIP.2021.3050856", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from the strong capabilities of deep CNNs for feature\nrepresentation and nonlinear mapping, deep-learning-based methods have achieved\nexcellent performance in single image super-resolution. However, most existing\nSR methods depend on the high capacity of networks which is initially designed\nfor visual recognition, and rarely consider the initial intention of\nsuper-resolution for detail fidelity. Aiming at pursuing this intention, there\nare two challenging issues to be solved: (1) learning appropriate operators\nwhich is adaptive to the diverse characteristics of smoothes and details; (2)\nimproving the ability of model to preserve the low-frequency smoothes and\nreconstruct the high-frequency details. To solve them, we propose a purposeful\nand interpretable detail-fidelity attention network to progressively process\nthese smoothes and details in divide-and-conquer manner, which is a novel and\nspecific prospect of image super-resolution for the purpose on improving the\ndetail fidelity, instead of blindly designing or employing the deep CNNs\narchitectures for merely feature representation in local receptive fields.\nParticularly, we propose a Hessian filtering for interpretable feature\nrepresentation which is high-profile for detail inference, a dilated\nencoder-decoder and a distribution alignment cell to improve the inferred\nHessian features in morphological manner and statistical manner respectively.\nExtensive experiments demonstrate that the proposed methods achieve superior\nperformances over the state-of-the-art methods quantitatively and\nqualitatively. Code is available at https://github.com/YuanfeiHuang/DeFiAN.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:31:23 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Huang", "Yuanfei", ""], ["Li", "Jie", ""], ["Gao", "Xinbo", ""], ["Hu", "Yanting", ""], ["Lu", "Wen", ""]]}, {"id": "2009.13144", "submitter": "Mirsalar Kamari Mr.", "authors": "Mirsalar Kamari and Oguz Gunes", "title": "Segmentation and Analysis of a Sketched Truss Frame Using Morphological\n  Image Processing Techniques", "comments": null, "journal-ref": "Conference: (ICCACS) International Conference On Civil\n  Engineering, Architecture and Cityscape, July 2016, Istanbul, Turkey", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of computational tools to analyze and assess the building\ncapacities has had a major impact in civil engineering. The interaction with\nthe structural software packages is becoming easier and the modeling tools are\nbecoming smarter by automating the users role during their interaction with the\nsoftware. One of the difficulties and the most time consuming steps involved in\nthe structural modeling is defining the geometry of the structure to provide\nthe analysis. This paper is dedicated to the development of a methodology to\nautomate analysis of a hand sketched or computer generated truss frame drawn on\na piece of paper. First, we focus on the segmentation methodologies for hand\nsketched truss components using the morphological image processing techniques,\nand then we provide a real time analysis of the truss. We visualize and augment\nthe results on the input image to facilitate the public understanding of the\ntruss geometry and internal forces. MATLAB is used as the programming language\nfor the image processing purposes, and the truss is analyzed using Sap2000 API\nto integrate with MATLAB to provide a convenient structural analysis. This\npaper highlights the potential of the automation of the structural analysis\nusing image processing to quickly assess the efficiency of structural systems.\nFurther development of this framework is likely to revolutionize the way that\nstructures are modeled and analyzed.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:50:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kamari", "Mirsalar", ""], ["Gunes", "Oguz", ""]]}, {"id": "2009.13145", "submitter": "Yifei Huang", "authors": "Yifei Huang, Yaodong Yu, Hongyang Zhang, Yi Ma, Yuan Yao", "title": "Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated\n  Gradients", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a provably stable architecture for Neural Ordinary\nDifferential Equations (ODEs) which achieves non-trivial adversarial robustness\nunder white-box adversarial attacks even when the network is trained naturally.\nFor most existing defense methods withstanding strong white-box attacks, to\nimprove robustness of neural networks, they need to be trained adversarially,\nhence have to strike a trade-off between natural accuracy and adversarial\nrobustness. Inspired by dynamical system theory, we design a stabilized neural\nODE network named SONet whose ODE blocks are skew-symmetric and proved to be\ninput-output stable. With natural training, SONet can achieve comparable\nrobustness with the state-of-the-art adversarial defense methods, without\nsacrificing natural accuracy. Even replacing only the first layer of a ResNet\nby such a ODE block can exhibit further improvement in robustness, e.g., under\nPGD-20 ($\\ell_\\infty=0.031$) attack on CIFAR-10 dataset, it achieves 91.57\\%\nand natural accuracy and 62.35\\% robust accuracy, while a counterpart\narchitecture of ResNet trained with TRADES achieves natural and robust accuracy\n76.29\\% and 45.24\\%, respectively. To understand possible reasons behind this\nsurprisingly good result, we further explore the possible mechanism underlying\nsuch an adversarial robustness. We show that the adaptive stepsize numerical\nODE solver, DOPRI5, has a gradient masking effect that fails the PGD attacks\nwhich are sensitive to gradient information of training loss; on the other\nhand, it cannot fool the CW attack of robust gradients and the SPSA attack that\nis gradient-free. This provides a new explanation that the adversarial\nrobustness of ODE-based networks mainly comes from the obfuscated gradients in\nnumerical ODE solvers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:51:42 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 04:14:08 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Huang", "Yifei", ""], ["Yu", "Yaodong", ""], ["Zhang", "Hongyang", ""], ["Ma", "Yi", ""], ["Yao", "Yuan", ""]]}, {"id": "2009.13146", "submitter": "William Agnew", "authors": "William Agnew, Christopher Xie, Aaron Walsman, Octavian Murad, Caelen\n  Wang, Pedro Domingos, Siddhartha Srinivasa", "title": "Amodal 3D Reconstruction for Robotic Manipulation via Stability and\n  Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based 3D object reconstruction enables single- or few-shot\nestimation of 3D object models. For robotics, this holds the potential to allow\nmodel-based methods to rapidly adapt to novel objects and scenes. Existing 3D\nreconstruction techniques optimize for visual reconstruction fidelity,\ntypically measured by chamfer distance or voxel IOU. We find that when applied\nto realistic, cluttered robotics environments, these systems produce\nreconstructions with low physical realism, resulting in poor task performance\nwhen used for model-based control. We propose ARM, an amodal 3D reconstruction\nsystem that introduces (1) a stability prior over object shapes, (2) a\nconnectivity prior, and (3) a multi-channel input representation that allows\nfor reasoning over relationships between groups of objects. By using these\npriors over the physical properties of objects, our system improves\nreconstruction quality not just by standard visual metrics, but also\nperformance of model-based control on a variety of robotics manipulation tasks\nin challenging, cluttered environments. Code is available at\ngithub.com/wagnew3/ARM.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:52:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Agnew", "William", ""], ["Xie", "Christopher", ""], ["Walsman", "Aaron", ""], ["Murad", "Octavian", ""], ["Wang", "Caelen", ""], ["Domingos", "Pedro", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "2009.13154", "submitter": "Matias Quintana", "authors": "Matias Quintana, Stefano Schiavon, Kwok Wai Tham, and Clayton Miller", "title": "Balancing thermal comfort datasets: We GAN, but should we?", "comments": "10 pages, submitted and accepted to BuildSys'20\n  (http://buildsys.acm.org/2020/)", "journal-ref": null, "doi": "10.1145/3408308.3427612", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thermal comfort assessment for the built environment has become more\navailable to analysts and researchers due to the proliferation of sensors and\nsubjective feedback methods. These data can be used for modeling comfort\nbehavior to support design and operations towards energy efficiency and\nwell-being. By nature, occupant subjective feedback is imbalanced as indoor\nconditions are designed for comfort, and responses indicating otherwise are\nless common. This situation creates a scenario for the machine learning\nworkflow where class balancing as a pre-processing step might be valuable for\ndeveloping predictive thermal comfort classification models with\nhigh-performance. This paper investigates the various thermal comfort dataset\nclass balancing techniques from the literature and proposes a modified\nconditional Generative Adversarial Network (GAN), $\\texttt{comfortGAN}$, to\naddress this imbalance scenario. These approaches are applied to three publicly\navailable datasets, ranging from 30 and 67 participants to a global collection\nof thermal comfort datasets, with 1,474; 2,067; and 66,397 data points,\nrespectively. This work finds that a classification model trained on a balanced\ndataset, comprised of real and generated samples from $\\texttt{comfortGAN}$,\nhas higher performance (increase between 4% and 17% in classification accuracy)\nthan other augmentation methods tested. However, when classes representing\ndiscomfort are merged and reduced to three, better imbalanced performance is\nexpected, and the additional increase in performance by $\\texttt{comfortGAN}$\nshrinks to 1-2%. These results illustrate that class balancing for thermal\ncomfort modeling is beneficial using advanced techniques such as GANs, but its\nvalue is diminished in certain scenarios. A discussion is provided to assist\npotential users in determining which scenarios this process is useful and which\nmethod works best.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:09:34 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Quintana", "Matias", ""], ["Schiavon", "Stefano", ""], ["Tham", "Kwok Wai", ""], ["Miller", "Clayton", ""]]}, {"id": "2009.13161", "submitter": "Douglas Meneghetti", "authors": "Douglas De Rizzo Meneghetti and Reinaldo Augusto da Costa Bianchi", "title": "Towards Heterogeneous Multi-Agent Reinforcement Learning with Graph\n  Neural Networks", "comments": "Published and presented at the XVI Encontro Nacional de\n  Intelig\\^encia Artificial e Computacional (ENIAC). Fixed notation", "journal-ref": null, "doi": "10.5753/eniac.2020.12161", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes a neural network architecture that learns policies for\nmultiple agent classes in a heterogeneous multi-agent reinforcement setting.\nThe proposed network uses directed labeled graph representations for states,\nencodes feature vectors of different sizes for different entity classes, uses\nrelational graph convolution layers to model different communication channels\nbetween entity types and learns distinct policies for different agent classes,\nsharing parameters wherever possible. Results have shown that specializing the\ncommunication channels between entity classes is a promising step to achieve\nhigher performance in environments composed of heterogeneous entities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:15:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 22:47:17 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 20:47:02 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Meneghetti", "Douglas De Rizzo", ""], ["Bianchi", "Reinaldo Augusto da Costa", ""]]}, {"id": "2009.13165", "submitter": "Gardave Bhumbra", "authors": "Gardave S Bhumbra", "title": "Quantal synaptic dilution enhances sparse encoding and dropout\n  regularisation in deep networks", "comments": "23 pages, 8 figures, including Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a technique that silences the activity of units stochastically\nwhile training deep networks to reduce overfitting. Here we introduce Quantal\nSynaptic Dilution (QSD), a biologically plausible model of dropout\nregularisation based on the quantal properties of neuronal synapses, that\nincorporates heterogeneities in response magnitudes and release probabilities\nfor vesicular quanta. QSD outperforms standard dropout in ReLU multilayer\nperceptrons, with enhanced sparse encoding at test time when dropout masks are\nreplaced with identity functions, without shifts in trainable weight or bias\ndistributions. For convolutional networks, the method also improves\ngeneralisation in computer vision tasks with and without inclusion of\nadditional forms of regularisation. QSD also outperforms standard dropout in\nrecurrent networks for language modelling and sentiment analysis. An advantage\nof QSD over many variations of dropout is that it can be implemented generally\nin all conventional deep networks where standard dropout is applicable.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:29:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bhumbra", "Gardave S", ""]]}, {"id": "2009.13166", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Jian-Guang Lou, Bin Zhou, Dongmei Zhang", "title": "Incomplete Utterance Rewriting as Semantic Segmentation", "comments": "To appear in EMNLP 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years the task of incomplete utterance rewriting has raised a large\nattention. Previous works usually shape it as a machine translation task and\nemploy sequence to sequence based architecture with copy mechanism. In this\npaper, we present a novel and extensive approach, which formulates it as a\nsemantic segmentation task. Instead of generating from scratch, such a\nformulation introduces edit operations and shapes the problem as prediction of\na word-level edit matrix. Benefiting from being able to capture both local and\nglobal information, our approach achieves state-of-the-art performance on\nseveral public datasets. Furthermore, our approach is four times faster than\nthe standard approach in inference.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:29:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Zhou", "Bin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2009.13180", "submitter": "Trent Kyono", "authors": "Trent Kyono, Yao Zhang, Mihaela van der Schaar", "title": "CASTLE: Regularization via Auxiliary Causal Graph Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization improves generalization of supervised models to out-of-sample\ndata. Prior works have shown that prediction in the causal direction (effect\nfrom cause) results in lower testing error than the anti-causal direction.\nHowever, existing regularization methods are agnostic of causality. We\nintroduce Causal Structure Learning (CASTLE) regularization and propose to\nregularize a neural network by jointly learning the causal relationships\nbetween variables. CASTLE learns the causal directed acyclical graph (DAG) as\nan adjacency matrix embedded in the neural network's input layers, thereby\nfacilitating the discovery of optimal predictors. Furthermore, CASTLE\nefficiently reconstructs only the features in the causal DAG that have a causal\nneighbor, whereas reconstruction-based regularizers suboptimally reconstruct\nall input features. We provide a theoretical generalization bound for our\napproach and conduct experiments on a plethora of synthetic and real publicly\navailable datasets demonstrating that CASTLE consistently leads to better\nout-of-sample predictions as compared to other popular benchmark regularizers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:49:38 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kyono", "Trent", ""], ["Zhang", "Yao", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2009.13181", "submitter": "Camille-Sovanneary Gauthier", "authors": "Camille-Sovanneary Gauthier, Romaric Gaudel and Elisa Fromont", "title": "Position-Based Multiple-Play Bandits with Thompson Sampling", "comments": "Accepted at IDA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-play bandits aim at displaying relevant items at relevant positions\non a web page. We introduce a new bandit-based algorithm, PB-MHB, for online\nrecommender systems which uses the Thompson sampling framework. This algorithm\nhandles a display setting governed by the position-based model. Our sampling\nmethod does not require as input the probability of a user to look at a given\nposition in the web page which is, in practice, very difficult to obtain.\nExperiments on simulated and real datasets show that our method, with fewer\nprior information, deliver better recommendations than state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:50:53 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 10:06:13 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 16:28:21 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Gauthier", "Camille-Sovanneary", ""], ["Gaudel", "Romaric", ""], ["Fromont", "Elisa", ""]]}, {"id": "2009.13211", "submitter": "Eoin Delaney", "authors": "Eoin Delaney, Derek Greene, Mark T. Keane", "title": "Instance-based Counterfactual Explanations for Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a rapidly expanding focus on explaining the\npredictions made by black-box AI systems that handle image and tabular data.\nHowever, considerably less attention has been paid to explaining the\npredictions of opaque AI systems handling time series data. In this paper, we\nadvance a novel model-agnostic, case-based technique -- Native Guide -- that\ngenerates counterfactual explanations for time series classifiers. Given a\nquery time series, $T_{q}$, for which a black-box classification system\npredicts class, $c$, a counterfactual time series explanation shows how $T_{q}$\ncould change, such that the system predicts an alternative class, $c'$. The\nproposed instance-based technique adapts existing counterfactual instances in\nthe case-base by highlighting and modifying discriminative areas of the time\nseries that underlie the classification. Quantitative and qualitative results\nfrom two comparative experiments indicate that Native Guide generates\nplausible, proximal, sparse and diverse explanations that are better than those\nproduced by key benchmark counterfactual methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:52:48 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 13:46:51 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Delaney", "Eoin", ""], ["Greene", "Derek", ""], ["Keane", "Mark T.", ""]]}, {"id": "2009.13232", "submitter": "Atandra Burman", "authors": "Atandra Burman, Jitto Titus, David Gbadebo, Melissa Burman", "title": "ECGDetect: Detecting Ischemia via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronary artery disease(CAD) is the most common type of heart disease and the\nleading cause of death worldwide[1]. A progressive state of this disease marked\nby plaque rupture and clot formation in the coronary arteries, also known as an\nacute coronary syndrome (ACS), is a condition of the heart associated with\nsudden, reduced blood flow caused due to partial or full occlusion of coronary\nvasculature that normally perfuses the myocardium and nerve bundles,\ncompromising the proper functioning of the heart. Often manifesting with pain\nor tightness in the chest as the second most common cause of emergency\ndepartment visits in the United States, it is imperative to detect ACS at the\nearliest. This is particularly relevant to diabetic patients at home, that may\nnot feel classic chest pain symptoms, and are susceptible to silent myocardial\ninjury. In this study, we developed the RCE- ECG-Detect algorithm, a machine\nlearning model to detect the morphological patterns in significant ST change\nassociated with myocardial ischemia. We developed the RCE- ECG-Detect using\ndata from the LTST database which has a sufficiently large sample set to train\na reliable model. We validated the predictive performance of the machine\nlearning model on a holdout test set collected using RCE's ECG wearable. Our\ndeep neural network model, equipped with convolution layers, achieves 90.31%\nROC-AUC, 89.34% sensitivity, 87.81% specificity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 11:57:26 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Burman", "Atandra", ""], ["Titus", "Jitto", ""], ["Gbadebo", "David", ""], ["Burman", "Melissa", ""]]}, {"id": "2009.13233", "submitter": "Aaqib Saeed", "authors": "Aaqib Saeed, Victor Ungureanu, Beat Gfeller", "title": "Sense and Learn: Self-Supervision for Omnipresent Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning general-purpose representations from multisensor data produced by\nthe omnipresent sensing systems (or IoT in general) has numerous applications\nin diverse use areas. Existing purely supervised end-to-end deep learning\ntechniques depend on the availability of a massive amount of well-curated data,\nacquiring which is notoriously difficult but required to achieve a sufficient\nlevel of generalization on a task of interest. In this work, we leverage the\nself-supervised learning paradigm towards realizing the vision of continual\nlearning from unlabeled inputs. We present a generalized framework named Sense\nand Learn for representation or feature learning from raw sensory data. It\nconsists of eight auxiliary tasks that can learn high-level and broadly useful\nfeatures entirely from unannotated data without any human involvement in the\ntedious labeling process. We demonstrate the efficacy of our approach on\nseveral publicly available datasets from different domains and in various\nsettings, including linear separability, semi-supervised or few shot learning,\nand transfer learning. Our methodology achieves results that are competitive\nwith the supervised approaches and close the gap through fine-tuning a network\nwhile learning the downstream tasks in most cases. In particular, we show that\nthe self-supervised network can be utilized as initialization to significantly\nboost the performance in a low-data regime with as few as 5 labeled instances\nper class, which is of high practical importance to real-world problems.\nLikewise, the learned representations with self-supervision are found to be\nhighly transferable between related datasets, even when few labeled instances\nare available from the target domains. The self-learning nature of our\nmethodology opens up exciting possibilities for on-device continual learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 11:57:43 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Saeed", "Aaqib", ""], ["Ungureanu", "Victor", ""], ["Gfeller", "Beat", ""]]}, {"id": "2009.13239", "submitter": "Joan Puigcerver", "authors": "Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Cedric Renggli,\n  Andr\\'e Susano Pinto, Sylvain Gelly, Daniel Keysers, Neil Houlsby", "title": "Scalable Transfer Learning with Expert Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer of pre-trained representations can improve sample efficiency and\nreduce computational requirements for new tasks. However, representations used\nfor transfer are usually generic, and are not tailored to a particular\ndistribution of downstream tasks. We explore the use of expert representations\nfor transfer with a simple, yet effective, strategy. We train a diverse set of\nexperts by exploiting existing label structures, and use cheap-to-compute\nperformance proxies to select the relevant expert for each target task. This\nstrategy scales the process of transferring to new tasks, since it does not\nrevisit the pre-training data during transfer. Accordingly, it requires little\nextra compute per target task, and results in a speed-up of 2-3 orders of\nmagnitude compared to competing approaches. Further, we provide an\nadapter-based architecture able to compress many experts into a single model.\nWe evaluate our approach on two different data sources and demonstrate that it\noutperforms baselines on over 20 diverse vision tasks in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:07:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Puigcerver", "Joan", ""], ["Riquelme", "Carlos", ""], ["Mustafa", "Basil", ""], ["Renggli", "Cedric", ""], ["Pinto", "Andr\u00e9 Susano", ""], ["Gelly", "Sylvain", ""], ["Keysers", "Daniel", ""], ["Houlsby", "Neil", ""]]}, {"id": "2009.13240", "submitter": "Rui Xu", "authors": "Rui Xu, Minghao Guo, Jiaqi Wang, Xiaoxiao Li, Bolei Zhou, Chen Change\n  Loy", "title": "Texture Memory-Augmented Deep Patch-Based Image Inpainting", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patch-based methods and deep networks have been employed to tackle image\ninpainting problem, with their own strengths and weaknesses. Patch-based\nmethods are capable of restoring a missing region with high-quality texture\nthrough searching nearest neighbor patches from the unmasked regions. However,\nthese methods bring problematic contents when recovering large missing regions.\nDeep networks, on the other hand, show promising results in completing large\nregions. Nonetheless, the results often lack faithful and sharp details that\nresemble the surrounding area. By bringing together the best of both paradigms,\nwe propose a new deep inpainting framework where texture generation is guided\nby a texture memory of patch samples extracted from unmasked regions. The\nframework has a novel design that allows texture memory retrieval to be trained\nend-to-end with the deep inpainting network. In addition, we introduce a patch\ndistribution loss to encourage high-quality patch synthesis. The proposed\nmethod shows superior performance both qualitatively and quantitatively on\nthree challenging image benchmarks, i.e., Places, CelebA-HQ, and Paris\nStreet-View datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:09:08 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Rui", ""], ["Guo", "Minghao", ""], ["Wang", "Jiaqi", ""], ["Li", "Xiaoxiao", ""], ["Zhou", "Bolei", ""], ["Loy", "Chen Change", ""]]}, {"id": "2009.13248", "submitter": "Przemyslaw Biecek", "authors": "Szymon Maksymiuk, Alicja Gosiewska, Przemyslaw Biecek", "title": "Landscape of R packages for eXplainable Artificial Intelligence", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing availability of data and computing power fuels the development of\npredictive models. In order to ensure the safe and effective functioning of\nsuch models, we need methods for exploration, debugging, and validation. New\nmethods and tools for this purpose are being developed within the eXplainable\nArtificial Intelligence (XAI) subdomain of machine learning. In this work (1)\nwe present the taxonomy of methods for model explanations, (2) we identify and\ncompare 27 packages available in R to perform XAI analysis, (3) we present an\nexample of an application of particular packages, (4) we acknowledge recent\ntrends in XAI. The article is primarily devoted to the tools available in R,\nbut since it is easy to integrate the Python code, we will also show examples\nfor the most popular libraries from Python.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:54:57 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 09:28:06 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 20:59:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Maksymiuk", "Szymon", ""], ["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2009.13249", "submitter": "Qianliang Wu", "authors": "Qianliang Wu and Tong Zhang and Zhen Cui and Jian Yang", "title": "Interest-Behaviour Multiplicative Network for Resource-limited\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource constraints, e.g. limited product inventory or financial strength,\nmay affect consumers' choices or preferences in some recommendation tasks but\nare usually ignored in previous recommendation methods. In this paper, we aim\nto mine the cue of user preferences in resource-limited recommendation tasks,\nfor which purpose we specifically build a large used car transaction dataset\npossessing resource-limitation characteristics. Accordingly, we propose an\ninterest-behavior multiplicative network to predict the user's future\ninteraction based on dynamic connections between users and items. To describe\nthe user-item connection dynamically, mutually-recursive recurrent neural\nnetworks (MRRNNs) are introduced to capture interactive long-term dependencies,\nand meantime effective representations of users and items are obtained. To\nfurther take the resource limitation into consideration, a resource-limited\nbranch is built to specifically explore the influence of resource variation on\nuser preferences. Finally, mutual information is introduced to measure the\nsimilarity between the user action and fused features to predict future\ninteraction, where the fused features come from both MRRNNs and\nresource-limited branches. We test the performance on the built used car\ntransaction dataset as well as the Tmall dataset, and the experimental results\nverify the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:11:13 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:14:35 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 11:59:18 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 03:08:00 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wu", "Qianliang", ""], ["Zhang", "Tong", ""], ["Cui", "Zhen", ""], ["Yang", "Jian", ""]]}, {"id": "2009.13250", "submitter": "Nathaniel Bastian PhD", "authors": "Tyler J. Shipp, Daniel J. Clouse, Michael J. De Lucia, Metin B.\n  Ahiskali, Kai Steverson, Jonathan M. Mullin, Nathaniel D. Bastian", "title": "Advancing the Research and Development of Assured Artificial\n  Intelligence and Machine Learning Capabilities", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) and machine learning (ML) have become\nincreasingly vital in the development of novel defense and intelligence\ncapabilities across all domains of warfare. An adversarial AI (A2I) and\nadversarial ML (AML) attack seeks to deceive and manipulate AI/ML models. It is\nimperative that AI/ML models can defend against these attacks. A2I/AML defenses\nwill help provide the necessary assurance of these advanced capabilities that\nuse AI/ML models. The A2I Working Group (A2IWG) seeks to advance the research\nand development of assured AI/ML capabilities via new A2I/AML defenses by\nfostering a collaborative environment across the U.S. Department of Defense and\nU.S. Intelligence Community. The A2IWG aims to identify specific challenges\nthat it can help solve or address more directly, with initial focus on three\ntopics: AI Trusted Robustness, AI System Security, and AI/ML Architecture\nVulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 20:12:14 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shipp", "Tyler J.", ""], ["Clouse", "Daniel J.", ""], ["De Lucia", "Michael J.", ""], ["Ahiskali", "Metin B.", ""], ["Steverson", "Kai", ""], ["Mullin", "Jonathan M.", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2009.13251", "submitter": "Efr\\'en Rama-Maneiro", "authors": "Efr\\'en Rama-Maneiro, Juan C. Vidal, Manuel Lama", "title": "Deep Learning for Predictive Business Process Monitoring: Review and\n  Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive monitoring of business processes is concerned with the prediction\nof ongoing cases on a business process. Lately, the popularity of deep learning\ntechniques has propitiated an ever-growing set of approaches focused on\npredictive monitoring based on these techniques. However, the high disparity of\nprocess logs and experimental setups used to evaluate these approaches makes it\nespecially difficult to make a fair comparison. Furthermore, it also difficults\nthe selection of the most suitable approach to solve a specific problem. In\nthis paper, we provide both a systematic literature review of approaches that\nuse deep learning to tackle the predictive monitoring tasks. In addition, we\nperformed an exhaustive experimental evaluation of 10 different approaches over\n12 publicly available process logs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:30:23 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 10:07:42 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 11:03:04 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Rama-Maneiro", "Efr\u00e9n", ""], ["Vidal", "Juan C.", ""], ["Lama", "Manuel", ""]]}, {"id": "2009.13252", "submitter": "Xueping Peng", "authors": "Xueping Peng, Guodong Long, Tao Shen, Sen Wang, Jing Jiang, Chengqi\n  Zhang", "title": "BiteNet: Bidirectional Temporal Encoder Network to Predict Medical\n  Outcomes", "comments": "10 pages, 8 figures, accepted by IEEE ICDM 2020. arXiv admin note:\n  substantial text overlap with arXiv:2006.10516", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) are longitudinal records of a patient's\ninteractions with healthcare systems. A patient's EHR data is organized as a\nthree-level hierarchy from top to bottom: patient journey - all the experiences\nof diagnoses and treatments over a period of time; individual visit - a set of\nmedical codes in a particular visit; and medical code - a specific record in\nthe form of medical codes. As EHRs begin to amass in millions, the potential\nbenefits, which these data might hold for medical research and medical outcome\nprediction, are staggering - including, for example, predicting future\nadmissions to hospitals, diagnosing illnesses or determining the efficacy of\nmedical treatments. Each of these analytics tasks requires a domain knowledge\nextraction method to transform the hierarchical patient journey into a vector\nrepresentation for further prediction procedure. The representations should\nembed a sequence of visits and a set of medical codes with a specific\ntimestamp, which are crucial to any downstream prediction tasks. Hence,\nexpressively powerful representations are appealing to boost learning\nperformance. To this end, we propose a novel self-attention mechanism that\ncaptures the contextual dependency and temporal relationships within a\npatient's healthcare journey. An end-to-end bidirectional temporal encoder\nnetwork (BiteNet) then learns representations of the patient's journeys, based\nsolely on the proposed attention mechanism. We have evaluated the effectiveness\nof our methods on two supervised prediction and two unsupervised clustering\ntasks with a real-world EHR dataset. The empirical results demonstrate the\nproposed BiteNet model produces higher-quality representations than\nstate-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 00:42:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Peng", "Xueping", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Wang", "Sen", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2009.13264", "submitter": "Tariq Khan Dr", "authors": "Tariq M. Khan and Antonio Robles-Kelly", "title": "A Derivative-free Method for Quantum Perceptron Training in\n  Multi-layered Neural Networks", "comments": "9 pages, 2 figures, Accepted in ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a gradient-free approach for training multi-layered\nneural networks based upon quantum perceptrons. Here, we depart from the\nclassical perceptron and the elemental operations on quantum bits, i.e. qubits,\nso as to formulate the problem in terms of quantum perceptrons. We then make\nuse of measurable operators to define the states of the network in a manner\nconsistent with a Markov process. This yields a Dirac-Von Neumann formulation\nconsistent with quantum mechanics. Moreover, the formulation presented here has\nthe advantage of having a computational efficiency devoid of the number of\nlayers in the network. This, paired with the natural efficiency of quantum\ncomputing, can imply a significant improvement in efficiency, particularly for\ndeep networks. Finally, but not least, the developments here are quite general\nin nature since the approach presented here can also be used for\nquantum-inspired neural networks implemented on conventional computers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:38:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Khan", "Tariq M.", ""], ["Robles-Kelly", "Antonio", ""]]}, {"id": "2009.13265", "submitter": "Laurence Illing Midgley", "authors": "Laurence Illing Midgley", "title": "Deep Reinforcement Learning for Process Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the application of reinforcement learning (RL) to\nprocess synthesis by presenting Distillation Gym, a set of RL environments in\nwhich an RL agent is tasked with designing a distillation train, given a user\ndefined multi-component feed stream. Distillation Gym interfaces with a process\nsimulator (COCO and ChemSep) to simulate the environment. A demonstration of\ntwo distillation problem examples are discussed in this paper (a Benzene,\nToluene, P-xylene separation problem and a hydrocarbon separation problem), in\nwhich a deep RL agent is successfully able to learn within Distillation Gym to\nproduce reasonable designs. Finally, this paper proposes the creation of\nChemical Engineering Gym, an all-purpose reinforcement learning software\ntoolkit for chemical engineering process synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 11:34:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Midgley", "Laurence Illing", ""]]}, {"id": "2009.13266", "submitter": "Xinyue Zheng", "authors": "Xinyue Zheng, Peng Wang, Qigang Wang, Zhongchao Shi", "title": "Disentangled Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has shown its great potential in various areas\nrecently. However, existing methods rely heavily on a black-box controller to\nsearch architectures, which suffers from the serious problem of lacking\ninterpretability. In this paper, we propose disentangled neural architecture\nsearch (DNAS) which disentangles the hidden representation of the controller\ninto semantically meaningful concepts, making the neural architecture search\nprocess interpretable. Based on systematical study, we discover the correlation\nbetween network architecture and its performance, and propose a dense-sampling\nstrategy to conduct a targeted search in promising regions that may generate\nwell-performing architectures. We show that: 1) DNAS successfully disentangles\nthe architecture representations, including operation selection, skip\nconnections, and number of layers. 2) Benefiting from interpretability, DNAS\ncan find excellent architectures under different FLOPS restrictions flexibly.\n3) Dense-sampling leads to neural architecture search with higher efficiency\nand better performance. On the NASBench-101 dataset, DNAS achieves\nstate-of-the-art performance of 94.21% using less than 1/13 computational cost\nof baseline methods. On ImageNet dataset, DNAS discovers the competitive\narchitectures that achieves 22.7% test error. our method provides a new\nperspective of understanding neural architecture search.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:35:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zheng", "Xinyue", ""], ["Wang", "Peng", ""], ["Wang", "Qigang", ""], ["Shi", "Zhongchao", ""]]}, {"id": "2009.13267", "submitter": "Pedram Rooshenas", "authors": "Sumanta Bhattacharyya, Amirmohammad Rooshenas, Subhajit Naskar, Simeng\n  Sun, Mohit Iyyer, Andrew McCallum", "title": "Energy-Based Reranking: Improving Neural Machine Translation Using\n  Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrepancy between maximum likelihood estimation (MLE) and task measures\nsuch as BLEU score has been studied before for autoregressive neural machine\ntranslation (NMT) and resulted in alternative training algorithms (Ranzato et\nal., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,\nMLE training remains the de facto approach for autoregressive NMT because of\nits computational efficiency and stability. Despite this mismatch between the\ntraining objective and task measure, we notice that the samples drawn from an\nMLE-based trained NMT support the desired distribution -- there are samples\nwith much higher BLEU score comparing to the beam decoding output. To benefit\nfrom this observation, we train an energy-based model to mimic the behavior of\nthe task measure (i.e., the energy-based model assigns lower energy to samples\nwith higher BLEU score), which is resulted in a re-ranking algorithm based on\nthe samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal\nenergy models (over target sentence) and joint energy models (over both source\nand target sentences). Our EBR with the joint energy model consistently\nimproves the performance of the Transformer-based NMT: +4 BLEU points on\nIWSLT'14 German-English, +3.0 BELU points on Sinhala-English, +1.2 BLEU on\nWMT'16 English-German tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:50:52 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 04:57:59 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 05:39:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bhattacharyya", "Sumanta", ""], ["Rooshenas", "Amirmohammad", ""], ["Naskar", "Subhajit", ""], ["Sun", "Simeng", ""], ["Iyyer", "Mohit", ""], ["McCallum", "Andrew", ""]]}, {"id": "2009.13269", "submitter": "Deniz Gunduz", "authors": "Deniz Gunduz, David Burth Kurka, Mikolaj Jankowski, Mohammad Mohammadi\n  Amiri, Emre Ozfatura, and Sreejith Sreekumar", "title": "Communicate to Learn at the Edge", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bringing the success of modern machine learning (ML) techniques to mobile\ndevices can enable many new services and businesses, but also poses significant\ntechnical and research challenges. Two factors that are critical for the\nsuccess of ML algorithms are massive amounts of data and processing power, both\nof which are plentiful, yet highly distributed at the network edge. Moreover,\nedge devices are connected through bandwidth- and power-limited wireless links\nthat suffer from noise, time-variations, and interference. Information and\ncoding theory have laid the foundations of reliable and efficient\ncommunications in the presence of channel imperfections, whose application in\nmodern wireless networks have been a tremendous success. However, there is a\nclear disconnect between the current coding and communication schemes, and the\nML algorithms deployed at the network edge. In this paper, we challenge the\ncurrent approach that treats these problems separately, and argue for a joint\ncommunication and learning paradigm for both the training and inference stages\nof edge learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:33:31 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gunduz", "Deniz", ""], ["Kurka", "David Burth", ""], ["Jankowski", "Mikolaj", ""], ["Amiri", "Mohammad Mohammadi", ""], ["Ozfatura", "Emre", ""], ["Sreekumar", "Sreejith", ""]]}, {"id": "2009.13270", "submitter": "Rajiv Movva", "authors": "Rajiv Movva, Jason Y. Zhao", "title": "Dissecting Lottery Ticket Transformers: Structural and Behavioral Study\n  of Sparse Neural Machine Translation", "comments": "Camera-ready for BlackboxNLP @ EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent work on the lottery ticket hypothesis has produced highly sparse\nTransformers for NMT while maintaining BLEU. However, it is unclear how such\npruning techniques affect a model's learned representations. By probing\nTransformers with more and more low-magnitude weights pruned away, we find that\ncomplex semantic information is first to be degraded. Analysis of internal\nactivations reveals that higher layers diverge most over the course of pruning,\ngradually becoming less complex than their dense counterparts. Meanwhile, early\nlayers of sparse models begin to perform more encoding. Attention mechanisms\nremain remarkably consistent as sparsity increases.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:08:45 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 18:55:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Movva", "Rajiv", ""], ["Zhao", "Jason Y.", ""]]}, {"id": "2009.13271", "submitter": "Kin Ho Lo", "authors": "K. H. Lo", "title": "Embedding and generation of indoor climbing routes with variational\n  autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent increase in popularity of indoor climbing allows possible applications\nof deep learning algorthms to classify and generate climbing routes. In this\nwork, we employ a variational autoencoder to climbing routes in a standardized\ntraining apparatus MoonBoard, a well-known training tool within the climbing\ncommunity. By sampling the encoded latent space, it is observed that the\nalgorithm can generate high quality climbing routes. 22 generated problems are\nuploaded to the Moonboard app for user review. This algorithm could serve as a\nfirst step to facilitate indoor climbing route setting.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 23:23:04 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lo", "K. H.", ""]]}, {"id": "2009.13272", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun, Cicero Nogueira dos Santos, Jason Krone, Bing Xiang", "title": "Augmented Natural Language for Generative Sequence Labeling", "comments": "To appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative framework for joint sequence labeling and\nsentence-level classification. Our model performs multiple sequence labeling\ntasks at once using a single, shared natural language output space. Unlike\nprior discriminative methods, our model naturally incorporates label semantics\nand shares knowledge across tasks. Our framework is general purpose, performing\nwell on few-shot, low-resource, and high-resource tasks. We demonstrate these\nadvantages on popular named entity recognition, slot labeling, and intent\nclassification benchmarks. We set a new state-of-the-art for few-shot slot\nlabeling, improving substantially upon the previous 5-shot ($75.0\\% \\rightarrow\n90.9\\%$) and 1-shot ($70.4\\% \\rightarrow 81.0\\%$) state-of-the-art results.\nFurthermore, our model generates large improvements ($46.27\\% \\rightarrow\n63.83\\%$) in low-resource slot labeling over a BERT baseline by incorporating\nlabel semantics. We also maintain competitive results on high-resource tasks,\nperforming within two points of the state-of-the-art on all tasks and setting a\nnew state-of-the-art on the SNIPS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:23:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Santos", "Cicero Nogueira dos", ""], ["Krone", "Jason", ""], ["Xiang", "Bing", ""]]}, {"id": "2009.13280", "submitter": "Jae Yong Lee", "authors": "Jae Yong Lee, Jin Woo Jang, Hyung Ju Hwang", "title": "The model reduction of the Vlasov-Poisson-Fokker-Planck system to the\n  Poisson-Nernst-Planck system via the Deep Neural Network Approach", "comments": "49 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.AP physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model reduction of a mesoscopic kinetic dynamics to a macroscopic\ncontinuum dynamics has been one of the fundamental questions in mathematical\nphysics since Hilbert's time. In this paper, we consider a diagram of the\ndiffusion limit from the Vlasov-Poisson-Fokker-Planck (VPFP) system on a\nbounded interval with the specular reflection boundary condition to the\nPoisson-Nernst-Planck (PNP) system with the no-flux boundary condition. We\nprovide a Deep Learning algorithm to simulate the VPFP system and the PNP\nsystem by computing the time-asymptotic behaviors of the solution and the\nphysical quantities. We analyze the convergence of the neural network solution\nof the VPFP system to that of the PNP system via the Asymptotic-Preserving (AP)\nscheme. Also, we provide several theoretical evidence that the Deep Neural\nNetwork (DNN) solutions to the VPFP and the PNP systems converge to the a\npriori classical solutions of each system if the total loss function vanishes.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:46:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lee", "Jae Yong", ""], ["Jang", "Jin Woo", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "2009.13291", "submitter": "Roberto Molinaro", "authors": "Siddhartha Mishra and Roberto Molinaro", "title": "Physics Informed Neural Networks for Simulating Radiative Transfer", "comments": null, "journal-ref": null, "doi": "10.1016/j.jqsrt.2021.107705", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel machine learning algorithm for simulating radiative\ntransfer. Our algorithm is based on physics informed neural networks (PINNs),\nwhich are trained by minimizing the residual of the underlying radiative\ntranfer equations. We present extensive experiments and theoretical error\nestimates to demonstrate that PINNs provide a very easy to implement, fast,\nrobust and accurate method for simulating radiative transfer. We also present a\nPINN based algorithm for simulating inverse problems for radiative transfer\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:07:02 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 12:42:59 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mishra", "Siddhartha", ""], ["Molinaro", "Roberto", ""]]}, {"id": "2009.13292", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Oren Barkan, Avi Caciularu, Noam Razin, Ori Katz and\n  Noam Koenigstein", "title": "RecoBERT: A Catalog Language Model for Text-Based Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models that utilize extensive self-supervised pre-training from\nunlabeled text, have recently shown to significantly advance the\nstate-of-the-art performance in a variety of language understanding tasks.\nHowever, it is yet unclear if and how these recent models can be harnessed for\nconducting text-based recommendations. In this work, we introduce RecoBERT, a\nBERT-based approach for learning catalog-specialized language models for\ntext-based item recommendations. We suggest novel training and inference\nprocedures for scoring similarities between pairs of items, that don't require\nitem similarity labels. Both the training and the inference techniques were\ndesigned to utilize the unlabeled structure of textual catalogs, and minimize\nthe discrepancy between them. By incorporating four scores during inference,\nRecoBERT can infer text-based item-to-item similarities more accurately than\nother techniques. In addition, we introduce a new language understanding task\nfor wine recommendations using similarities based on professional wine reviews.\nAs an additional contribution, we publish annotated recommendations dataset\ncrafted by human wine experts. Finally, we evaluate RecoBERT and compare it to\nvarious state-of-the-art NLP models on wine and fashion recommendations tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:23:38 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Malkiel", "Itzik", ""], ["Barkan", "Oren", ""], ["Caciularu", "Avi", ""], ["Razin", "Noam", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2009.13294", "submitter": "Rohit Rawat", "authors": "Rohit Rawat", "title": "Virtual Proximity Citation (VCP): A Supervised Deep Learning Method to\n  Relate Uncited Papers On Grounds of Citation Proximity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Citation based approaches have seen good progress for recommending research\npapers using citations in the paper. Citation proximity analysis which uses the\nin-text citation proximity to find relatedness between two research papers is\nbetter than co-citation analysis and bibliographic analysis. However, one\ncommon problem which exists in each approach is that paper should be well\ncited. If documents are not cited properly or not cited at all, then using\nthese approaches will not be helpful. To overcome the problem, this paper\ndiscusses the approach Virtual Citation Proximity (VCP) which uses Siamese\nNeural Network along with the notion of citation proximity analysis and\ncontent-based filtering. To train this model, the actual distance between the\ntwo citations in a document is used as ground truth, this distance is the word\ncount between the two citations. VCP is trained on Wikipedia articles for which\nthe actual word count is available which is used to calculate the similarity\nbetween the documents. This can be used to calculate relatedness between two\ndocuments in a way they would have been cited in the proximity even if the\ndocuments are uncited. This approach has shown a great improvement in\npredicting proximity with basic neural networks over the approach which uses\nthe Average Citation Proximity index value as the ground truth. This can be\nimproved by using a complex neural network and proper hyper tuning of\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:24:00 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rawat", "Rohit", ""]]}, {"id": "2009.13295", "submitter": "Pepa Atanasova", "authors": "Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, Isabelle\n  Augenstein", "title": "A Diagnostic Study of Explainability Techniques for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in machine learning have introduced models that approach\nhuman performance at the cost of increased architectural complexity. Efforts to\nmake the rationales behind the models' predictions transparent have inspired an\nabundance of new explainability techniques. Provided with an already trained\nmodel, they compute saliency scores for the words of an input instance.\nHowever, there exists no definitive guide on (i) how to choose such a technique\ngiven a particular application task and model architecture, and (ii) the\nbenefits and drawbacks of using each such technique. In this paper, we develop\na comprehensive list of diagnostic properties for evaluating existing\nexplainability techniques. We then employ the proposed list to compare a set of\ndiverse explainability techniques on downstream text classification tasks and\nneural network architectures. We also compare the saliency scores assigned by\nthe explainability techniques with human annotations of salient input regions\nto find relations between a model's performance and the agreement of its\nrationales with human ones. Overall, we find that the gradient-based\nexplanations perform best across tasks and model architectures, and we present\nfurther insights into the properties of the reviewed explainability techniques.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:01:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Atanasova", "Pepa", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.13299", "submitter": "Shuqing Bian", "authors": "Shuqing Bian, Xu Chen, Wayne Xin Zhao, Kun Zhou, Yupeng Hou, Yang\n  Song, Tao Zhang and Ji-Rong Wen", "title": "Learning to Match Jobs with Resumes from Sparse Interaction Data using\n  Multi-View Co-Teaching Network", "comments": null, "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing growth of online recruitment data, job-resume\nmatching has become an important task to automatically match jobs with suitable\nresumes. This task is typically casted as a supervised text matching problem.\nSupervised learning is powerful when the labeled data is sufficient. However,\non online recruitment platforms, job-resume interaction data is sparse and\nnoisy, which affects the performance of job-resume match algorithms. To\nalleviate these problems, in this paper, we propose a novel multi-view\nco-teaching network from sparse interaction data for job-resume matching. Our\nnetwork consists of two major components, namely text-based matching model and\nrelation-based matching model. The two parts capture semantic compatibility in\ntwo different views, and complement each other. In order to address the\nchallenges from sparse and noisy data, we design two specific strategies to\ncombine the two components. First, two components share the learned parameters\nor representations, so that the original representations of each component can\nbe enhanced. More importantly, we adopt a co-teaching mechanism to reduce the\ninfluence of noise in training data. The core idea is to let the two components\nhelp each other by selecting more reliable training instances. The two\nstrategies focus on representation enhancement and data enhancement,\nrespectively. Compared with pure text-based matching models, the proposed\napproach is able to learn better data representations from limited or even\nsparse interaction data, which is more resistible to noise in training data.\nExperiment results have demonstrated that our model is able to outperform\nstate-of-the-art methods for job-resume matching.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 03:09:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bian", "Shuqing", ""], ["Chen", "Xu", ""], ["Zhao", "Wayne Xin", ""], ["Zhou", "Kun", ""], ["Hou", "Yupeng", ""], ["Song", "Yang", ""], ["Zhang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2009.13303", "submitter": "Jorge Pe\\~na Queralta", "authors": "Wenshuai Zhao, Jorge Pe\\~na Queralta, Tomi Westerlund", "title": "Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a\n  Survey", "comments": "Accepted to the 2020 IEEE Symposium Series on Computational\n  Intelligence", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI),\n  2020, pp. 737-744", "doi": "10.1109/SSCI47803.2020.9308468.", "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently seen huge success across multiple\nareas in the robotics domain. Owing to the limitations of gathering real-world\ndata, i.e., sample inefficiency and the cost of collecting it, simulation\nenvironments are utilized for training the different agents. This not only aids\nin providing a potentially infinite data source, but also alleviates safety\nconcerns with real robots. Nonetheless, the gap between the simulated and real\nworlds degrades the performance of the policies once the models are transferred\ninto real robots. Multiple research efforts are therefore now being directed\ntowards closing this sim-to-real gap and accomplish more efficient policy\ntransfer. Recent years have seen the emergence of multiple methods applicable\nto different domains, but there is a lack, to the best of our knowledge, of a\ncomprehensive review summarizing and putting into context the different\nmethods. In this survey paper, we cover the fundamental background behind\nsim-to-real transfer in deep reinforcement learning and overview the main\nmethods being utilized at the moment: domain randomization, domain adaptation,\nimitation learning, meta-learning and knowledge distillation. We categorize\nsome of the most relevant recent works, and outline the main application\nscenarios. Finally, we discuss the main opportunities and challenges of the\ndifferent approaches and point to the most promising directions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 21:05:46 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 09:00:05 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Queralta", "Jorge Pe\u00f1a", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2009.13311", "submitter": "Olivier Teytaud", "authors": "Baptiste Roziere and Fabien Teytaud and Vlad Hosu and Hanhe Lin and\n  Jeremy Rapin and Mariia Zameshina and Olivier Teytaud", "title": "EvolGAN: Evolutionary Generative Adversarial Networks", "comments": "accepted ACCV oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use a quality estimator and evolutionary methods to search the\nlatent space of generative adversarial networks trained on small, difficult\ndatasets, or both. The new method leads to the generation of significantly\nhigher quality images while preserving the original generator's diversity.\nHuman raters preferred an image from the new version with frequency 83.7pc for\nCats, 74pc for FashionGen, 70.4pc for Horses, and 69.2pc for Artworks, and\nminor improvements for the already excellent GANs for faces. This approach\napplies to any quality scorer and GAN generator.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 13:31:13 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Roziere", "Baptiste", ""], ["Teytaud", "Fabien", ""], ["Hosu", "Vlad", ""], ["Lin", "Hanhe", ""], ["Rapin", "Jeremy", ""], ["Zameshina", "Mariia", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2009.13317", "submitter": "Huy Nguyen", "authors": "Huy L. Nguyen", "title": "A note on differentially private clustering with large additive error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we describe a simple approach to obtain a differentially\nprivate algorithm for k-clustering with nearly the same multiplicative factor\nas any non-private counterpart at the cost of a large polynomial additive\nerror. The approach is the combination of a simple geometric observation\nindependent of privacy consideration and any existing private algorithm with a\nconstant approximation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 13:40:04 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Huy L.", ""]]}, {"id": "2009.13320", "submitter": "Halla Sigurthorsdottir", "authors": "Halla Sigurthorsdottir, J\\'er\\^ome Van Zaen, Ricard Delgado-Gonzalo,\n  Mathieu Lemay", "title": "ECG Classification with a Convolutional Recurrent Neural Network", "comments": "4 pages, 3 figures, presented at Computing in Cardiology 2020, under\n  review for conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a convolutional recurrent neural network to classify 12-lead ECG\nsignals for the challenge of PhysioNet/ Computing in Cardiology 2020 as team\nPink Irish Hat. The model combines convolutional and recurrent layers, takes\nsliding windows of ECG signals as input and yields the probability of each\nclass as output. The convolutional part extracts features from each sliding\nwindow. The bi-directional gated recurrent unit (GRU) layer and an attention\nlayer aggregate these features from all windows into a single feature vector.\nFinally, a dense layer outputs class probabilities. The final decision is made\nusing test time augmentation (TTA) and an optimized decision threshold. Several\nhyperparameters of our architecture were optimized, the most important of which\nturned out to be the choice of optimizer and the number of filters per\nconvolutional layer. Our network achieved a challenge score of 0.511 on the\nhidden validation set and 0.167 on the full hidden test set, ranking us 23rd\nout of 41 in the official ranking.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 13:41:59 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 13:21:21 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Sigurthorsdottir", "Halla", ""], ["Van Zaen", "J\u00e9r\u00f4me", ""], ["Delgado-Gonzalo", "Ricard", ""], ["Lemay", "Mathieu", ""]]}, {"id": "2009.13323", "submitter": "Philippe Burlina", "authors": "Philippe M. Burlina, William Paul, Phil A. Mathew, Neil J. Joshi,\n  Alison W. Rebman, John N. Aucott", "title": "AI Progress in Skin Lesion Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine progress in the use of AI for detecting skin lesions, with\nparticular emphasis on the erythema migrans rash of acute Lyme disease, and\nother lesions, such as those from conditions like herpes zoster (shingles),\ntinea corporis, erythema multiforme, cellulitis, insect bites, or tick bites.\nWe discuss important challenges for these applications, in particular the\nproblems of AI bias regarding the lack of skin images in dark skinned\nindividuals, being able to accurately detect, delineate, and segment lesions or\nregions of interest compared to normal skin in images, and low shot learning\n(addressing classification with a paucity of training images). Solving these\nproblems ranges from being highly desirable requirements -- e.g. for\ndelineation, which may be useful to disambiguate between similar types of\nlesions, and perform improved diagnostics -- or required, as is the case for AI\nde-biasing, to allow for the deployment of fair AI techniques in the clinic for\nskin lesion analysis. For the problem of low shot learning in particular, we\nreport skin analysis algorithms that gracefully degrade and still perform well\nat low shots, when compared to baseline algorithms: when using a little as 10\ntraining exemplars per class, the baseline DL algorithm performance\nsignificantly degrades, with accuracy of 56.41%, close to chance, whereas the\nbest performing low shot algorithm yields an accuracy of 85.26%.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 13:44:50 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 16:58:15 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Burlina", "Philippe M.", ""], ["Paul", "William", ""], ["Mathew", "Phil A.", ""], ["Joshi", "Neil J.", ""], ["Rebman", "Alison W.", ""], ["Aucott", "John N.", ""]]}, {"id": "2009.13333", "submitter": "Lei Huang", "authors": "Lei Huang, Yi Zhou, Li Liu, Fan Zhu, Ling Shao", "title": "Group Whitening: Balancing Learning Efficiency and Representational\n  Capacity", "comments": "V4: camera version of CVPR 2021. Code available at:\n  https://github.com/huangleiBuaa/GroupWhitening", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization (BN) is an important technique commonly incorporated into\ndeep learning models to perform standardization within mini-batches. The merits\nof BN in improving a model's learning efficiency can be further amplified by\napplying whitening, while its drawbacks in estimating population statistics for\ninference can be avoided through group normalization (GN). This paper proposes\ngroup whitening (GW), which exploits the advantages of the whitening operation\nand avoids the disadvantages of normalization within mini-batches. In addition,\nwe analyze the constraints imposed on features by normalization, and show how\nthe batch size (group number) affects the performance of batch (group)\nnormalized networks, from the perspective of model's representational capacity.\nThis analysis provides theoretical guidance for applying GW in practice.\nFinally, we apply the proposed GW to ResNet and ResNeXt architectures and\nconduct experiments on the ImageNet and COCO benchmarks. Results show that GW\nconsistently improves the performance of different architectures, with absolute\ngains of $1.02\\%$ $\\sim$ $1.49\\%$ in top-1 accuracy on ImageNet and $1.82\\%$\n$\\sim$ $3.21\\%$ in bounding box AP on COCO.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:00:07 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 12:29:51 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 09:46:16 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 04:17:27 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Huang", "Lei", ""], ["Zhou", "Yi", ""], ["Liu", "Li", ""], ["Zhu", "Fan", ""], ["Shao", "Ling", ""]]}, {"id": "2009.13339", "submitter": "Abhishek Sharma", "authors": "Abhishek Sharma and Maks Ovsjanikov", "title": "Weakly Supervised Deep Functional Map for Shape Matching", "comments": "Accepted to appear in proceedings of Neurips 2020. Code available at:\n  \\url{https://github.com/Not-IITian/Weakly-supervised-Functional-map}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of deep functional maps have been proposed recently, from fully\nsupervised to totally unsupervised, with a range of loss functions as well as\ndifferent regularization terms. However, it is still not clear what are minimum\ningredients of a deep functional map pipeline and whether such ingredients\nunify or generalize all recent work on deep functional maps. We show\nempirically minimum components for obtaining state of the art results with\ndifferent loss functions, supervised as well as unsupervised. Furthermore, we\npropose a novel framework designed for both full-to-full as well as partial to\nfull shape matching that achieves state of the art results on several benchmark\ndatasets outperforming even the fully supervised methods by a significant\nmargin. Our code is publicly available at\nhttps://github.com/Not-IITian/Weakly-supervised-Functional-map\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:06:46 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Sharma", "Abhishek", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2009.13357", "submitter": "Risheng Liu", "authors": "Yaohua Liu, Risheng Liu", "title": "BOML: A Modularized Bilevel Optimization Library in Python for Meta\n  Learning", "comments": "six pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning (a.k.a. learning to learn) has recently emerged as a promising\nparadigm for a variety of applications. There are now many meta-learning\nmethods, each focusing on different modeling aspects of base and meta learners,\nbut all can be (re)formulated as specific bilevel optimization problems. This\nwork presents BOML, a modularized optimization library that unifies several\nmeta-learning algorithms into a common bilevel optimization framework. It\nprovides a hierarchical optimization pipeline together with a variety of\niteration modules, which can be used to solve the mainstream categories of\nmeta-learning methods, such as meta-feature-based and meta-initialization-based\nformulations. The library is written in Python and is available at\nhttps://github.com/dut-media-lab/BOML.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:21:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Yaohua", ""], ["Liu", "Risheng", ""]]}, {"id": "2009.13366", "submitter": "Giorgos Vernikos", "authors": "Giorgos Vernikos, Katerina Margatina, Alexandra Chronopoulou, Ion\n  Androutsopoulos", "title": "Domain Adversarial Fine-Tuning as an Effective Regularizer", "comments": "EMNLP 2020, Findings of EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Processing (NLP), pretrained language models (LMs) that\nare transferred to downstream tasks have been recently shown to achieve\nstate-of-the-art results. However, standard fine-tuning can degrade the\ngeneral-domain representations captured during pretraining. To address this\nissue, we introduce a new regularization technique, AFTER; domain Adversarial\nFine-Tuning as an Effective Regularizer. Specifically, we complement the\ntask-specific loss used during fine-tuning with an adversarial objective. This\nadditional loss term is related to an adversarial classifier, that aims to\ndiscriminate between in-domain and out-of-domain text representations.\nIn-domain refers to the labeled dataset of the task at hand while out-of-domain\nrefers to unlabeled data from a different domain. Intuitively, the adversarial\nclassifier acts as a regularizer which prevents the model from overfitting to\nthe task-specific domain. Empirical results on various natural language\nunderstanding tasks show that AFTER leads to improved performance compared to\nstandard fine-tuning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:35:06 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 23:56:19 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Vernikos", "Giorgos", ""], ["Margatina", "Katerina", ""], ["Chronopoulou", "Alexandra", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "2009.13370", "submitter": "Lan Truong", "authors": "Lan V. Truong", "title": "Replica Analysis of the Linear Model with Markov or Hidden Markov Signal\n  Priors", "comments": "Add MCMC simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper estimates free energy, average mutual information, and minimum\nmean square error (MMSE) of a linear model under two assumptions: (1) the\nsource is generated by a Markov chain, (2) the source is generated via a hidden\nMarkov model. Our estimates are based on the replica method in statistical\nphysics. We show that under the posterior mean estimator, the linear model with\nMarkov sources or hidden Markov sources is decoupled into single-input AWGN\nchannels with state information available at both encoder and decoder where the\nstate distribution follows the left Perron-Frobenius eigenvector with unit\nManhattan norm of the stochastic matrix of Markov chains. Numerical results\nshow that the free energies and MSEs obtained via the replica method closely\napproximate to their counterparts achieved by the Metropolis-Hastings algorithm\nor some well-known approximate message passing algorithms in the research\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:38:52 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 15:13:35 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Truong", "Lan V.", ""]]}, {"id": "2009.13375", "submitter": "Antonios Maronikolakis", "authors": "Antonis Maronikolakis, Hinrich Schutze, Mark Stevenson", "title": "Identifying Automatically Generated Headlines using Transformers", "comments": "NLP4IF 2021 Proceedings, NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:48:27 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 11:52:01 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 09:39:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Maronikolakis", "Antonis", ""], ["Schutze", "Hinrich", ""], ["Stevenson", "Mark", ""]]}, {"id": "2009.13380", "submitter": "Federico Tavella", "authors": "Federico Tavella, Alberto Giaretta, Mauro Conti, Sasitharan\n  Balasubramaniam", "title": "A Machine Learning-based Approach to Detect Threats in Bio-Cyber DNA\n  Storage Systems", "comments": "12 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data storage is one of the main computing issues of this century. Not only\nstorage devices are converging to strict physical limits, but also the amount\nof data generated by users is growing at an unbelievable rate. To face these\nchallenges, data centres grew constantly over the past decades. However, this\ngrowth comes with a price, particularly from the environmental point of view.\nAmong various promising media, DNA is one of the most fascinating candidate. In\nour previous work, we have proposed an automated archival architecture which\nuses bioengineered bacteria to store and retrieve data, previously encoded into\nDNA. This storage technique is one example of how biological media can deliver\npower-efficient storing solutions. The similarities between these biological\nmedia and classical ones can also be a drawback, as malicious parties might\nreplicate traditional attacks on the former archival system, using biological\ninstruments and techniques. In this paper, first we analyse the main\ncharacteristics of our storage system and the different types of attacks that\ncould be executed on it. Then, aiming at identifying on-going attacks, we\npropose and evaluate detection techniques, which rely on traditional metrics\nand machine learning algorithms. We identify and adapt two suitable metrics for\nthis purpose, namely generalized entropy and information distance. Moreover,\nour trained models achieve an AUROC over 0.99 and AUPRC over 0.91.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:55:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tavella", "Federico", ""], ["Giaretta", "Alberto", ""], ["Conti", "Mauro", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "2009.13384", "submitter": "Michael B\\\"ucker", "authors": "Michael B\\\"ucker and Gero Szepannek and Alicja Gosiewska and\n  Przemyslaw Biecek", "title": "Transparency, Auditability and eXplainability of Machine Learning Models\n  in Credit Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.GN q-fin.EC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major requirement for credit scoring models is to provide a maximally\naccurate risk prediction. Additionally, regulators demand these models to be\ntransparent and auditable. Thus, in credit scoring, very simple predictive\nmodels such as logistic regression or decision trees are still widely used and\nthe superior predictive power of modern machine learning algorithms cannot be\nfully leveraged. Significant potential is therefore missed, leading to higher\nreserves or more credit defaults. This paper works out different dimensions\nthat have to be considered for making credit scoring models understandable and\npresents a framework for making ``black box'' machine learning models\ntransparent, auditable and explainable. Following this framework, we present an\noverview of techniques, demonstrate how they can be applied in credit scoring\nand how results compare to the interpretability of score cards. A real world\ncase study shows that a comparable degree of interpretability can be achieved\nwhile machine learning techniques keep their ability to improve predictive\npower.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:00:13 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["B\u00fccker", "Michael", ""], ["Szepannek", "Gero", ""], ["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2009.13401", "submitter": "Wenhao Yu", "authors": "Xiangyu Dong, Wenhao Yu, Chenguang Zhu, Meng Jiang", "title": "Injecting Entity Types into Entity-Guided Text Generation", "comments": "Preprint; Code is available at: https://github.com/wyu97/InjType", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent successes in deep generative modeling have led to significant advances\nin natural language generation (NLG). Incorporating entities into neural\ngeneration models has demonstrated great improvements by assisting to infer the\nsummary topic and to generate coherent content. In order to enhance the role of\nentity in NLG, in this paper, we aim to model the entity type in the decoding\nphase to generate contextual words accurately. We develop a novel NLG model to\nproduce a target sequence (i.e., a news article) based on a given list of\nentities. The generation quality depends significantly on whether the input\nentities are logically connected and expressed in the output. Our model has a\nmulti-step decoder that injects the entity types into the process of entity\nmention generation. It first predicts the token of being a contextual word or\nan entity, then if an entity, predicts the entity mention. It effectively\nembeds the entity's meaning into hidden states, making the generated words\nprecise. Experiments on two public datasets demonstrate type injection performs\nbetter than type embedding concatenation baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:19:28 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 15:50:26 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Dong", "Xiangyu", ""], ["Yu", "Wenhao", ""], ["Zhu", "Chenguang", ""], ["Jiang", "Meng", ""]]}, {"id": "2009.13402", "submitter": "Sana Yasin", "authors": "Sana Yasin, Syed Asad Hussain, Sinem Aslan, Imran Raza, Muhammad\n  Muzammel, Alice Othmani", "title": "EEG based Major Depressive disorder and Bipolar disorder detection using\n  Neural Networks: A review", "comments": "29 pages,2 figures and 18 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mental disorders represent critical public health challenges as they are\nleading contributors to the global burden of disease and intensely influence\nsocial and financial welfare of individuals. The present comprehensive review\nconcentrate on the two mental disorders: Major depressive Disorder (MDD) and\nBipolar Disorder (BD) with noteworthy publications during the last ten years.\nThere is a big need nowadays for phenotypic characterization of psychiatric\ndisorders with biomarkers. Electroencephalography (EEG) signals could offer a\nrich signature for MDD and BD and then they could improve understanding of\npathophysiological mechanisms underling these mental disorders. In this review,\nwe focus on the literature works adopting neural networks fed by EEG signals.\nAmong those studies using EEG and neural networks, we have discussed a variety\nof EEG based protocols, biomarkers and public datasets for depression and\nbipolar disorder detection. We conclude with a discussion and valuable\nrecommendations that will help to improve the reliability of developed models\nand for more accurate and more deterministic computational intelligence based\nsystems in psychiatry. This review will prove to be a structured and valuable\ninitial point for the researchers working on depression and bipolar disorders\nrecognition by using EEG signals.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:19:54 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 18:58:54 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Yasin", "Sana", ""], ["Hussain", "Syed Asad", ""], ["Aslan", "Sinem", ""], ["Raza", "Imran", ""], ["Muzammel", "Muhammad", ""], ["Othmani", "Alice", ""]]}, {"id": "2009.13405", "submitter": "Aymen Al Marjani", "authors": "Aymen Al Marjani and Alexandre Proutiere", "title": "Adaptive Sampling for Best Policy Identification in Markov Decision\n  Processes", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of best-policy identification in discounted Markov\nDecision Processes (MDPs) when the learner has access to a generative model.\nThe objective is to devise a learning algorithm returning the best policy as\nearly as possible. We first derive a problem-specific lower bound of the sample\ncomplexity satisfied by any learning algorithm. This lower bound corresponds to\nan optimal sample allocation that solves a non-convex program, and hence, is\nhard to exploit in the design of efficient algorithms. We then provide a simple\nand tight upper bound of the sample complexity lower bound, whose corresponding\nnearly-optimal sample allocation becomes explicit. The upper bound depends on\nspecific functionals of the MDP such as the sub-optimality gaps and the\nvariance of the next-state value function, and thus really captures the\nhardness of the MDP. Finally, we devise KLB-TS (KL Ball Track-and-Stop), an\nalgorithm tracking this nearly-optimal allocation, and provide asymptotic\nguarantees for its sample complexity (both almost surely and in expectation).\nThe advantages of KLB-TS against state-of-the-art algorithms are discussed and\nillustrated numerically.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:22:24 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:15:58 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 15:45:40 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 16:40:20 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Marjani", "Aymen Al", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2009.13415", "submitter": "Juntao Huang", "authors": "Juntao Huang, Zhiting Ma, Yizhou Zhou, Wen-An Yong", "title": "Learning Thermodynamically Stable and Galilean Invariant Partial\n  Differential Equations for Non-equilibrium Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA physics.flu-dyn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we develop a method for learning interpretable,\nthermodynamically stable and Galilean invariant partial differential equations\n(PDEs) based on the Conservation-dissipation Formalism of irreversible\nthermodynamics. As governing equations for non-equilibrium flows in one\ndimension, the learned PDEs are parameterized by fully-connected neural\nnetworks and satisfy the conservation-dissipation principle automatically. In\nparticular, they are hyperbolic balance laws and Galilean invariant. The\ntraining data are generated from a kinetic model with smooth initial data.\nNumerical results indicate that the learned PDEs can achieve good accuracy in a\nwide range of Knudsen numbers. Remarkably, the learned dynamics can give\nsatisfactory results with randomly sampled discontinuous initial data and Sod's\nshock tube problem although it is trained only with smooth initial data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:31:16 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 19:43:18 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Huang", "Juntao", ""], ["Ma", "Zhiting", ""], ["Zhou", "Yizhou", ""], ["Yong", "Wen-An", ""]]}, {"id": "2009.13420", "submitter": "K K Thyagharajan", "authors": "S.D. Lalitha, K.K. Thyagharajan", "title": "A Study on Lip Localization Techniques used for Lip reading from a Video", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper some of the different techniques used to localize the lips from\nthe face are discussed and compared along with its processing steps. Lip\nlocalization is the basic step needed to read the lips for extracting visual\ninformation from the video input. The techniques could be applied on asymmetric\nlips and also on the mouth with visible teeth, tongue & mouth with moustache.\nIn the process of Lip reading the following steps are generally used. They are,\ninitially locating lips in the first frame of the video input, then tracking\nthe lips in the following frames using the resulting pixel points of initial\nstep and at last converting the tracked lip model to its corresponding matched\nletter to give the visual information. A new proposal is also initiated from\nthe discussed techniques. The lip reading is useful in Automatic Speech\nRecognition when the audio is absent or present low with or without noise in\nthe communication systems. Human Computer communication also will require\nspeech recognition.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:36:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lalitha", "S. D.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.13436", "submitter": "Davide Nitti", "authors": "Etienne Perot, Pierre de Tournemire, Davide Nitti, Jonathan Masci,\n  Amos Sironi", "title": "Learning to Detect Objects with a 1 Megapixel Event Camera", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event cameras encode visual information with high temporal precision, low\ndata-rate, and high-dynamic range. Thanks to these characteristics, event\ncameras are particularly suited for scenarios with high motion, challenging\nlighting conditions and requiring low latency. However, due to the novelty of\nthe field, the performance of event-based systems on many vision tasks is still\nlower compared to conventional frame-based solutions. The main reasons for this\nperformance gap are: the lower spatial resolution of event sensors, compared to\nframe cameras; the lack of large-scale training datasets; the absence of well\nestablished deep learning architectures for event-based processing. In this\npaper, we address all these problems in the context of an event-based object\ndetection task. First, we publicly release the first high-resolution\nlarge-scale dataset for object detection. The dataset contains more than 14\nhours recordings of a 1 megapixel event camera, in automotive scenarios,\ntogether with 25M bounding boxes of cars, pedestrians, and two-wheelers,\nlabeled at high frequency. Second, we introduce a novel recurrent architecture\nfor event-based detection and a temporal consistency loss for better-behaved\ntraining. The ability to compactly represent the sequence of events into the\ninternal memory of the model is essential to achieve high accuracy. Our model\noutperforms by a large margin feed-forward event-based architectures. Moreover,\nour method does not require any reconstruction of intensity images from events,\nshowing that training directly from raw events is possible, more efficient, and\nmore accurate than passing through an intermediate intensity image. Experiments\non the dataset introduced in this work, for which events and gray level images\nare available, show performance on par with that of highly tuned and studied\nframe-based detectors.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:03:59 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 15:41:24 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Perot", "Etienne", ""], ["de Tournemire", "Pierre", ""], ["Nitti", "Davide", ""], ["Masci", "Jonathan", ""], ["Sironi", "Amos", ""]]}, {"id": "2009.13437", "submitter": "Bernat Coma-Puig", "authors": "Bernat Coma-Puig, Josep Carmona", "title": "An Iterative Approach based on Explainability to Improve the Learning of\n  Fraud Detection Models", "comments": "14 pages, 6 figures. Pre-Print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing predictive models in utility companies to detect Non-Technical\nLosses (i.e. fraud and other meter problems) is challenging: the data available\nis biased, and the algorithms usually used are black-boxes that can not be\neither easily trusted or understood by the stakeholders. In this work, we\nexplain our approach to mitigate these problems in a real supervised system to\ndetect non-technical losses for an international utility company from Spain.\nThis approach exploits human knowledge (e.g. from the data scientists or the\ncompany's stakeholders), and the information provided by explanatory methods to\nimplement smart feature engineering. This simple, efficient method that can be\neasily implemented in other industrial projects is tested in a real dataset and\nthe results evidence that the derived prediction model is better in terms of\naccuracy, interpretability, robustness and flexibility.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:04:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Coma-Puig", "Bernat", ""], ["Carmona", "Josep", ""]]}, {"id": "2009.13447", "submitter": "Lexing Ying", "authors": "Jing An, Lexing Ying, Yuhua Zhu", "title": "Why resampling outperforms reweighting for correcting sampling bias with\n  stochastic gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data set sampled from a certain population is biased if the subgroups of\nthe population are sampled at proportions that are significantly different from\ntheir underlying proportions. Training machine learning models on biased data\nsets requires correction techniques to compensate for the bias. We consider two\ncommonly-used techniques, resampling and reweighting, that rebalance the\nproportions of the subgroups to maintain the desired objective function. Though\nstatistically equivalent, it has been observed that resampling outperforms\nreweighting when combined with stochastic gradient algorithms. By analyzing\nillustrative examples, we explain the reason behind this phenomenon using tools\nfrom dynamical stability and stochastic asymptotics. We also present\nexperiments from regression, classification, and off-policy prediction to\ndemonstrate that this is a general phenomenon. We argue that it is imperative\nto consider the objective function design and the optimization algorithm\ntogether while addressing the sampling bias.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:12:38 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 07:57:53 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["An", "Jing", ""], ["Ying", "Lexing", ""], ["Zhu", "Yuhua", ""]]}, {"id": "2009.13453", "submitter": "Toshiaki Koike-Akino", "authors": "Mo Han, Ozan Ozdenizci, Toshiaki Koike-Akino, Ye Wang, Deniz Erdogmus", "title": "Universal Physiological Representation Learning with Soft-Disentangled\n  Rateless Autoencoders", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human computer interaction (HCI) involves a multidisciplinary fusion of\ntechnologies, through which the control of external devices could be achieved\nby monitoring physiological status of users. However, physiological biosignals\noften vary across users and recording sessions due to unstable physical/mental\nconditions and task-irrelevant activities. To deal with this challenge, we\npropose a method of adversarial feature encoding with the concept of a Rateless\nAutoencoder (RAE), in order to exploit disentangled, nuisance-robust, and\nuniversal representations. We achieve a good trade-off between user-specific\nand task-relevant features by making use of the stochastic disentanglement of\nthe latent representations by adopting additional adversarial networks. The\nproposed model is applicable to a wider range of unknown users and tasks as\nwell as different classifiers. Results on cross-subject transfer evaluations\nshow the advantages of the proposed framework, with up to an 11.6% improvement\nin the average subject-transfer classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:25:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Han", "Mo", ""], ["Ozdenizci", "Ozan", ""], ["Koike-Akino", "Toshiaki", ""], ["Wang", "Ye", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2009.13472", "submitter": "Matthew Vowels", "authors": "Matthew James Vowels and Necati Cihan Camgoz and Richard Bowden", "title": "Targeted VAE: Variational and Targeted Learning for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undertaking causal inference with observational data is incredibly useful\nacross a wide range of tasks including the development of medical treatments,\nadvertisements and marketing, and policy making. There are two significant\nchallenges associated with undertaking causal inference using observational\ndata: treatment assignment heterogeneity (i.e., differences between the treated\nand untreated groups), and an absence of counterfactual data (i.e., not knowing\nwhat would have happened if an individual who did get treatment, were instead\nto have not been treated). We address these two challenges by combining\nstructured inference and targeted learning. In terms of structure, we factorize\nthe joint distribution into risk, confounding, instrumental, and miscellaneous\nfactors, and in terms of targeted learning, we apply a regularizer derived from\nthe influence curve in order to reduce residual bias. An ablation study is\nundertaken, and an evaluation on benchmark datasets demonstrates that TVAE has\ncompetitive and state of the art performance across.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:55:24 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 17:35:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vowels", "Matthew James", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2009.13480", "submitter": "Amirhossein Hajavi", "authors": "Amirhossein Hajavi, Ali Etemad", "title": "Siamese Capsule Network for End-to-End Speaker Recognition In The Wild", "comments": "Submitted to ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an end-to-end deep model for speaker verification in the wild. Our\nmodel uses thin-ResNet for extracting speaker embeddings from utterances and a\nSiamese capsule network and dynamic routing as the Back-end to calculate a\nsimilarity score between the embeddings. We conduct a series of experiments and\ncomparisons on our model to state-of-the-art solutions, showing that our model\noutperforms all the other models using substantially less amount of training\ndata. We also perform additional experiments to study the impact of different\nspeaker embeddings on the Siamese capsule network. We show that the best\nperformance is achieved by using embeddings obtained directly from the feature\naggregation module of the Front-end and passing them to higher capsules using\ndynamic routing.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:11:11 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "2009.13498", "submitter": "Josimar Chire Saire", "authors": "Diana C. Roca Arroyo, Josimar E. Chire Saire", "title": "Parameter Experimental Analysis of the Reservoirs Observers using Echo\n  State Network Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems has a variety of applications for the new information\ngenerated during the time. Many phenomenons like physical, chemical or social\nare not static, then an analysis over the time is necessary. In this work, an\nexperimental analysis of parameters of the model Echo State Network is\nperformed and the influence of the kind of Complex Network is explored to\nunderstand the influence on the performance. The experiments are performed\nusing the Rossler attractor.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:45:52 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Arroyo", "Diana C. Roca", ""], ["Saire", "Josimar E. Chire", ""]]}, {"id": "2009.13500", "submitter": "Stephan Wojtowytsch", "authors": "Weinan E and Stephan Wojtowytsch", "title": "A priori estimates for classification problems using neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider binary and multi-class classification problems using hypothesis\nclasses of neural networks. For a given hypothesis class, we use Rademacher\ncomplexity estimates and direct approximation theorems to obtain a priori error\nestimates for regularized loss functionals.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:47:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["E", "Weinan", ""], ["Wojtowytsch", "Stephan", ""]]}, {"id": "2009.13501", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Sandeep Kumar, Shilpak Banerjee, Ashish Kumar Pandey", "title": "EIS -- a family of activation functions combining Exponential, ISRU, and\n  Softplus", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions play a pivotal role in the function learning using\nneural networks. The non-linearity in the learned function is achieved by\nrepeated use of the activation function. Over the years, numerous activation\nfunctions have been proposed to improve accuracy in several tasks. Basic\nfunctions like ReLU, Sigmoid, Tanh, or Softplus have been favorite among the\ndeep learning community because of their simplicity. In recent years, several\nnovel activation functions arising from these basic functions have been\nproposed, which have improved accuracy in some challenging datasets. We propose\na five hyper-parameters family of activation functions, namely EIS, defined as,\n\\[ \\frac{x(\\ln(1+e^x))^\\alpha}{\\sqrt{\\beta+\\gamma x^2}+\\delta e^{-\\theta x}}.\n\\] We show examples of activation functions from the EIS family which\noutperform widely used activation functions on some well known datasets and\nmodels. For example, $\\frac{x\\ln(1+e^x)}{x+1.16e^{-x}}$ beats ReLU by 0.89\\% in\nDenseNet-169, 0.24\\% in Inception V3 in CIFAR100 dataset while 1.13\\% in\nInception V3, 0.13\\% in DenseNet-169, 0.94\\% in SimpleNet model in CIFAR10\ndataset. Also, $\\frac{x\\ln(1+e^x)}{\\sqrt{1+x^2}}$ beats ReLU by 1.68\\% in\nDenseNet-169, 0.30\\% in Inception V3 in CIFAR100 dataset while 1.0\\% in\nInception V3, 0.15\\% in DenseNet-169, 1.13\\% in SimpleNet model in CIFAR10\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:48:24 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 15:51:12 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Biswas", "Koushik", ""], ["Kumar", "Sandeep", ""], ["Banerjee", "Shilpak", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2009.13503", "submitter": "Zihan Zhang", "authors": "Zihan Zhang, Xiangyang Ji, Simon S. Du", "title": "Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal\n  Algorithm Escaping the Curse of Horizon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic reinforcement learning and contextual bandits are two widely studied\nsequential decision-making problems. Episodic reinforcement learning\ngeneralizes contextual bandits and is often perceived to be more difficult due\nto long planning horizon and unknown state-dependent transitions. The current\npaper shows that the long planning horizon and the unknown state-dependent\ntransitions (at most) pose little additional difficulty on sample complexity.\n  We consider the episodic reinforcement learning with $S$ states, $A$ actions,\nplanning horizon $H$, total reward bounded by $1$, and the agent plays for $K$\nepisodes. We propose a new algorithm, \\textbf{M}onotonic \\textbf{V}alue\n\\textbf{P}ropagation (MVP), which relies on a new Bernstein-type bonus.\nCompared to existing bonus constructions, the new bonus is tighter since it is\nbased on a well-designed monotonic value function. In particular, the\n\\emph{constants} in the bonus should be subtly setting to ensure optimism and\nmonotonicity.\n  We show MVP enjoys an $O\\left(\\left(\\sqrt{SAK} + S^2A\\right) \\poly\\log\n\\left(SAHK\\right)\\right)$ regret, approaching the\n$\\Omega\\left(\\sqrt{SAK}\\right)$ lower bound of \\emph{contextual bandits} up to\nlogarithmic terms. Notably, this result 1) \\emph{exponentially} improves the\nstate-of-the-art polynomial-time algorithms by Dann et al. [2019] and Zanette\net al. [2019] in terms of the dependency on $H$, and 2) \\emph{exponentially}\nimproves the running time in [Wang et al. 2020] and significantly improves the\ndependency on $S$, $A$ and $K$ in sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:52:32 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 07:06:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Zihan", ""], ["Ji", "Xiangyang", ""], ["Du", "Simon S.", ""]]}, {"id": "2009.13504", "submitter": "Peiyuan Liao", "authors": "Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon,\n  Stefanie Jegelka, Ruslan Salakhutdinov", "title": "Information Obfuscation of Graph Neural Networks", "comments": "ICML 2021; Code is available at https://github.com/liaopeiyuan/GAL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:55:04 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:34:52 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 16:27:46 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 06:25:27 GMT"}, {"version": "v5", "created": "Sun, 13 Jun 2021 05:35:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liao", "Peiyuan", ""], ["Zhao", "Han", ""], ["Xu", "Keyulu", ""], ["Jaakkola", "Tommi", ""], ["Gordon", "Geoffrey", ""], ["Jegelka", "Stefanie", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2009.13509", "submitter": "Daniel Wu", "authors": "Daniel J Wu, Andrew C Yang, Vinay U Prabhu", "title": "Afro-MNIST: Synthetic generation of MNIST-style datasets for\n  low-resource languages", "comments": "10 pages, 11 figures, presented as a workshop paper at Practical\n  Machine Learning for Developing Countries @ ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Afro-MNIST, a set of synthetic MNIST-style datasets for four\northographies used in Afro-Asiatic and Niger-Congo languages: Ge`ez (Ethiopic),\nVai, Osmanya, and N'Ko. These datasets serve as \"drop-in\" replacements for\nMNIST. We also describe and open-source a method for synthetic MNIST-style\ndataset generation from single examples of each digit. These datasets can be\nfound at https://github.com/Daniel-Wu/AfroMNIST. We hope that MNIST-style\ndatasets will be developed for other numeral systems, and that these datasets\nvitalize machine learning education in underrepresented nations in the research\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:57:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wu", "Daniel J", ""], ["Yang", "Andrew C", ""], ["Prabhu", "Vinay U", ""]]}, {"id": "2009.13510", "submitter": "Uri Stemmer", "authors": "Amos Beimel, Iftach Haitner, Kobbi Nissim, Uri Stemmer", "title": "On the Round Complexity of the Shuffle Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shuffle model of differential privacy was proposed as a viable model for\nperforming distributed differentially private computations. Informally, the\nmodel consists of an untrusted analyzer that receives messages sent by\nparticipating parties via a shuffle functionality, the latter potentially\ndisassociates messages from their senders. Prior work focused on one-round\ndifferentially private shuffle model protocols, demonstrating that\nfunctionalities such as addition and histograms can be performed in this model\nwith accuracy levels similar to that of the curator model of differential\nprivacy, where the computation is performed by a fully trusted party.\n  Focusing on the round complexity of the shuffle model, we ask in this work\nwhat can be computed in the shuffle model of differential privacy with two\nrounds. Ishai et al. [FOCS 2006] showed how to use one round of the shuffle to\nestablish secret keys between every two parties. Using this primitive to\nsimulate a general secure multi-party protocol increases its round complexity\nby one. We show how two parties can use one round of the shuffle to send secret\nmessages without having to first establish a secret key, hence retaining round\ncomplexity. Combining this primitive with the two-round semi-honest protocol of\nApplebaun et al. [TCC 2018], we obtain that every randomized functionality can\nbe computed in the shuffle model with an honest majority, in merely two rounds.\nThis includes any differentially private computation. We then move to examine\ndifferentially private computations in the shuffle model that (i) do not\nrequire the assumption of an honest majority, or (ii) do not admit one-round\nprotocols, even with an honest majority. For that, we introduce two\ncomputational tasks: the common-element problem and the nested-common-element\nproblem, for which we show separations between one-round and two-round\nprotocols.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:57:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Beimel", "Amos", ""], ["Haitner", "Iftach", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "2009.13511", "submitter": "Esteban Vilca", "authors": "Esteban Wilfredo Vilca Zu\\~niga, Liang Zhao", "title": "A new network-base high-level data classification methodology (Quipus)\n  by modeling attribute-attribute interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-level classification algorithms focus on the interactions between\ninstances. These produce a new form to evaluate and classify data. In this\nprocess, the core is a complex network building methodology. The current\nmethodologies use variations of kNN to produce these graphs. However, these\ntechniques ignore some hidden patterns between attributes and require\nnormalization to be accurate. In this paper, we propose a new methodology for\nnetwork building based on attribute-attribute interactions that do not require\nnormalization. The current results show us that this approach improves the\naccuracy of the high-level classification algorithm based on betweenness\ncentrality.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:58:12 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zu\u00f1iga", "Esteban Wilfredo Vilca", ""], ["Zhao", "Liang", ""]]}, {"id": "2009.13512", "submitter": "Sitan Chen", "authors": "Sitan Chen, Adam R. Klivans, Raghu Meka", "title": "Learning Deep ReLU Networks Is Fixed-Parameter Tractable", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an unknown ReLU network with respect to\nGaussian inputs and obtain the first nontrivial results for networks of depth\nmore than two. We give an algorithm whose running time is a fixed polynomial in\nthe ambient dimension and some (exponentially large) function of only the\nnetwork's parameters.\n  Our bounds depend on the number of hidden units, depth, spectral norm of the\nweight matrices, and Lipschitz constant of the overall network (we show that\nsome dependence on the Lipschitz constant is necessary). We also give a bound\nthat is doubly exponential in the size of the network but is independent of\nspectral norm. These results provably cannot be obtained using gradient-based\nmethods and give the first example of a class of efficiently learnable neural\nnetworks that gradient descent will fail to learn.\n  In contrast, prior work for learning networks of depth three or higher\nrequires exponential time in the ambient dimension, even when the above\nparameters are bounded by a constant. Additionally, all prior work for the\ndepth-two case requires well-conditioned weights and/or positive coefficients\nto obtain efficient run-times. Our algorithm does not require these\nassumptions.\n  Our main technical tool is a type of filtered PCA that can be used to\niteratively recover an approximate basis for the subspace spanned by the hidden\nunits in the first layer. Our analysis leverages new structural results on\nlattice polynomials from tropical geometry.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:58:43 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Sitan", ""], ["Klivans", "Adam R.", ""], ["Meka", "Raghu", ""]]}, {"id": "2009.13516", "submitter": "Chen Zhao", "authors": "Chen Zhao, Changbin Li, Jincheng Li, Feng Chen", "title": "Fair Meta-Learning For Few-Shot Classification", "comments": "2020 IEEE International Conference on Knowledge Graph (ICKG). arXiv\n  admin note: text overlap with arXiv:2009.11406", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence nowadays plays an increasingly prominent role in our\nlife since decisions that were once made by humans are now delegated to\nautomated systems. A machine learning algorithm trained based on biased data,\nhowever, tends to make unfair predictions. Developing classification algorithms\nthat are fair with respect to protected attributes of the data thus becomes an\nimportant problem. Motivated by concerns surrounding the fairness effects of\nsharing and few-shot machine learning tools, such as the Model Agnostic\nMeta-Learning framework, we propose a novel fair fast-adapted few-shot\nmeta-learning approach that efficiently mitigates biases during meta-train by\nensuring controlling the decision boundary covariance that between the\nprotected variable and the signed distance from the feature vectors to the\ndecision boundary. Through extensive experiments on two real-world image\nbenchmarks over three state-of-the-art meta-learning algorithms, we empirically\ndemonstrate that our proposed approach efficiently mitigates biases on model\noutput and generalizes both accuracy and fairness to unseen tasks with a\nlimited amount of training samples.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:33:47 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Chen", ""], ["Li", "Changbin", ""], ["Li", "Jincheng", ""], ["Chen", "Feng", ""]]}, {"id": "2009.13560", "submitter": "Stefan Schwarz", "authors": "Stefan Schwarz", "title": "Recursive CSI Quantization of Time-Correlated MIMO Channels by Deep\n  Learning Classification", "comments": "accepted with minor revision for publication in IEEE Signal\n  Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2020.3028184", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communications, limited channel state information (CSI) feedback is a\ncentral tool to support advanced single- and multi-user MIMO\nbeamforming/precoding. To achieve a given CSI quality, the CSI quantization\ncodebook size has to grow exponentially with the number of antennas, leading to\nquantization complexity, as well as, feedback overhead issues for larger MIMO\nsystems. We have recently proposed a multi-stage recursive Grassmannian\nquantizer that enables a significant complexity reduction of CSI quantization.\nIn this paper, we show that this recursive quantizer can effectively be\ncombined with deep learning classification to further reduce the complexity,\nand that it can exploit temporal channel correlations to reduce the CSI\nfeedback overhead.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:19:02 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Schwarz", "Stefan", ""]]}, {"id": "2009.13562", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Bryn Marie Reinstadler, Una-May O'Reilly", "title": "STRATA: Building Robustness with a Simple Method for Generating\n  Black-box Adversarial Attacks for Models of Code", "comments": "13 pages, 3 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are imperceptible perturbations in the input to a neural\nmodel that result in misclassification. Generating adversarial examples for\nsource code poses an additional challenge compared to the domains of images and\nnatural language, because source code perturbations must adhere to strict\nsemantic guidelines so the resulting programs retain the functional meaning of\nthe code. We propose a simple and efficient black-box method for generating\nstate-of-the-art adversarial examples on models of code. Our method generates\nuntargeted and targeted attacks, and empirically outperforms competing\ngradient-based methods with less information and less computational effort. We\nalso use adversarial training to construct a model robust to these attacks; our\nattack reduces the F1 score of code2seq by 42%. Adversarial training brings the\nF1 score on adversarial examples up to 99% of baseline.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:21:19 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Springer", "Jacob M.", ""], ["Reinstadler", "Bryn Marie", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2009.13566", "submitter": "Jiong Zhu", "authors": "Jiong Zhu, Ryan A. Rossi, Anup Rao, Tung Mai, Nedim Lipka, Nesreen K.\n  Ahmed, Danai Koutra", "title": "Graph Neural Networks with Heterophily", "comments": "Proceedings version of AAAI 2021 with appendix and additional typo\n  fixes; 12 pages, 4 figures", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence. 35,\n  12 (May 2021), 11168-11176", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have proven to be useful for many different\npractical applications. However, many existing GNN models have implicitly\nassumed homophily among the nodes connected in the graph, and therefore have\nlargely overlooked the important setting of heterophily, where most connected\nnodes are from different classes. In this work, we propose a novel framework\ncalled CPGNN that generalizes GNNs for graphs with either homophily or\nheterophily. The proposed framework incorporates an interpretable compatibility\nmatrix for modeling the heterophily or homophily level in the graph, which can\nbe learned in an end-to-end fashion, enabling it to go beyond the assumption of\nstrong homophily. Theoretically, we show that replacing the compatibility\nmatrix in our framework with the identity (which represents pure homophily)\nreduces to GCN. Our extensive experiments demonstrate the effectiveness of our\napproach in more realistic and challenging experimental settings with\nsignificantly less training data compared to previous works: CPGNN variants\nachieve state-of-the-art results in heterophily settings with or without\ncontextual node features, while maintaining comparable performance in homophily\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:29:36 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 08:19:28 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 19:54:57 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhu", "Jiong", ""], ["Rossi", "Ryan A.", ""], ["Rao", "Anup", ""], ["Mai", "Tung", ""], ["Lipka", "Nedim", ""], ["Ahmed", "Nesreen K.", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.13579", "submitter": "Ruo Yu Tao", "authors": "Ruo Yu Tao, Vincent Fran\\c{c}ois-Lavet, Joelle Pineau", "title": "Novelty Search in Representational Space for Sample Efficient\n  Exploration", "comments": "10 pages + references + appendix. Oral presentation at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for efficient exploration which leverages a\nlow-dimensional encoding of the environment learned with a combination of\nmodel-based and model-free objectives. Our approach uses intrinsic rewards that\nare based on the distance of nearest neighbors in the low dimensional\nrepresentational space to gauge novelty. We then leverage these intrinsic\nrewards for sample-efficient exploration with planning routines in\nrepresentational space for hard exploration tasks with sparse rewards. One key\nelement of our approach is the use of information theoretic principles to shape\nour representations in a way so that our novelty reward goes beyond pixel\nsimilarity. We test our approach on a number of maze tasks, as well as a\ncontrol problem and show that our exploration approach is more sample-efficient\ncompared to strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:51:52 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 19:48:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tao", "Ruo Yu", ""], ["Fran\u00e7ois-Lavet", "Vincent", ""], ["Pineau", "Joelle", ""]]}, {"id": "2009.13580", "submitter": "Vikash Gupta", "authors": "Vikash Gupta and Clayton Taylor and Sarah Bonnet and Luciano M.\n  Prevedello and Jeffrey Hawley and Richard D White and Mona G Flores and\n  Barbaros Selnur Erdal", "title": "Deep Learning-Based Automatic Detection of Poorly Positioned Mammograms\n  to Minimize Patient Return Visits for Repeat Imaging: A Real-World\n  Application", "comments": "12 pages, 13 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Screening mammograms are a routine imaging exam performed to detect breast\ncancer in its early stages to reduce morbidity and mortality attributed to this\ndisease. In order to maximize the efficacy of breast cancer screening programs,\nproper mammographic positioning is paramount. Proper positioning ensures\nadequate visualization of breast tissue and is necessary for effective breast\ncancer detection. Therefore, breast-imaging radiologists must assess each\nmammogram for the adequacy of positioning before providing a final\ninterpretation of the examination; this often necessitates return patient\nvisits for additional imaging. In this paper, we propose a deep\nlearning-algorithm method that mimics and automates this decision-making\nprocess to identify poorly positioned mammograms. Our objective for this\nalgorithm is to assist mammography technologists in recognizing inadequately\npositioned mammograms real-time, improve the quality of mammographic\npositioning and performance, and ultimately reducing repeat visits for patients\nwith initially inadequate imaging. The proposed model showed a true positive\nrate for detecting correct positioning of 91.35% in the mediolateral oblique\nview and 95.11% in the craniocaudal view. In addition to these results, we also\npresent an automatically generated report which can aid the mammography\ntechnologist in taking corrective measures during the patient visit.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:54:53 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gupta", "Vikash", ""], ["Taylor", "Clayton", ""], ["Bonnet", "Sarah", ""], ["Prevedello", "Luciano M.", ""], ["Hawley", "Jeffrey", ""], ["White", "Richard D", ""], ["Flores", "Mona G", ""], ["Erdal", "Barbaros Selnur", ""]]}, {"id": "2009.13586", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma", "title": "Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for\n  Nonconvex Stochastic Optimization", "comments": "Fixed errors in convergence analysis. 29 pages (plus appendix), 6\n  figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Apollo, a quasi-Newton method for nonconvex\nstochastic optimization, which dynamically incorporates the curvature of the\nloss function by approximating the Hessian via a diagonal matrix. Importantly,\nthe update and storage of the diagonal approximation of Hessian is as efficient\nas adaptive first-order optimization methods with linear complexity for both\ntime and memory. To handle nonconvexity, we replace the Hessian with its\nrectified absolute value, which is guaranteed to be positive-definite.\nExperiments on three tasks of vision and language show that Apollo achieves\nsignificant improvements over other stochastic optimization methods, including\nSGD and variants of Adam, in term of both convergence speed and generalization\nperformance. The implementation of the algorithm is available at\nhttps://github.com/XuezheMax/apollo.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:07:02 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 07:45:24 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 05:47:47 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 06:57:57 GMT"}, {"version": "v5", "created": "Fri, 2 Apr 2021 05:41:25 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ma", "Xuezhe", ""]]}, {"id": "2009.13598", "submitter": "Chen Zhong", "authors": "Chen Zhong, M. Cenk Gursoy, and Senem Velipasalar", "title": "Anomaly Detection and Sampling Cost Control via Hierarchical GANs", "comments": "6 pages, 7 figures, has been accepted by Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection incurs certain sampling and sensing costs and therefore it\nis of great importance to strike a balance between the detection accuracy and\nthese costs. In this work, we study anomaly detection by considering the\ndetection of threshold crossings in a stochastic time series without the\nknowledge of its statistics. To reduce the sampling cost in this detection\nprocess, we propose the use of hierarchical generative adversarial networks\n(GANs) to perform nonuniform sampling. In order to improve the detection\naccuracy and reduce the delay in detection, we introduce a buffer zone in the\noperation of the proposed GAN-based detector. In the experiments, we analyze\nthe performance of the proposed hierarchical GAN detector considering the\nmetrics of detection delay, miss rates, average cost of error, and sampling\nratio. We identify the tradeoffs in the performance as the buffer zone sizes\nand the number of GAN levels in the hierarchy vary. We also compare the\nperformance with that of a sampling policy that approximately minimizes the sum\nof average costs of sampling and error given the parameters of the stochastic\nprocess. We demonstrate that the proposed GAN-based detector can have\nsignificant performance improvements in terms of detection delay and average\ncost of error with a larger buffer zone but at the cost of increased sampling\nrates.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:39:51 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zhong", "Chen", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "2009.13602", "submitter": "Mahboobeh Parsapoor", "authors": "Jonathan Smith, Borna Ghotbi, Seungeun Yi, Mahboobeh Parsapoor", "title": "Non-Pharmaceutical Intervention Discovery with Topic Modeling", "comments": "ML for Global Health (ICML 2020 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of discovering categories of non-pharmaceutical\ninterventions during the evolving COVID-19 pandemic. We explore topic modeling\non two corpora with national and international scope. These models discover\nexisting categories when compared with human intervention labels while reduced\nhuman effort needed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:37:00 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Smith", "Jonathan", ""], ["Ghotbi", "Borna", ""], ["Yi", "Seungeun", ""], ["Parsapoor", "Mahboobeh", ""]]}, {"id": "2009.13609", "submitter": "Lin Song", "authors": "Lin Song, Neng Wan, Aditya Gahlawat, Naira Hovakimyan, and Evangelos\n  A. Theodorou", "title": "Compositionality of Linearly Solvable Optimal Control in Networked\n  Multi-Agent Systems", "comments": "Accepted to the 2021 American Control Conference (ACC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the methodology of generalizing the optimal control\nlaw from learned component tasks to unlearned composite tasks on Multi-Agent\nSystems (MASs), by using the linearity composition principle of linearly\nsolvable optimal control (LSOC) problems. The proposed approach achieves both\nthe compositionality and optimality of control actions simultaneously within\nthe cooperative MAS framework in both discrete- and continuous-time in a\nsample-efficient manner, which reduces the burden of re-computation of the\noptimal control solutions for the new task on the MASs. We investigate the\napplication of the proposed approach on the MAS with coordination between\nagents. The experiments show feasible results in investigated scenarios,\nincluding both discrete and continuous dynamical systems for task\ngeneralization without resampling.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:21:48 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 19:33:28 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Song", "Lin", ""], ["Wan", "Neng", ""], ["Gahlawat", "Aditya", ""], ["Hovakimyan", "Naira", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2009.13634", "submitter": "Zeyu Fu", "authors": "Zeyu Fu, Yang Sun, Xiangyu Zhang, Scott Stainton, Shaun Barney, Jeffry\n  Hogg, William Innes and Satnam Dlay", "title": "MPG-Net: Multi-Prediction Guided Network for Segmentation of Retinal\n  Layers in OCT Images", "comments": "EUSIPCO2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical coherence tomography (OCT) is a commonly-used method of extracting\nhigh resolution retinal information. Moreover there is an increasing demand for\nthe automated retinal layer segmentation which facilitates the retinal disease\ndiagnosis. In this paper, we propose a novel multiprediction guided attention\nnetwork (MPG-Net) for automated retinal layer segmentation in OCT images. The\nproposed method consists of two major steps to strengthen the discriminative\npower of a U-shape Fully convolutional network (FCN) for reliable automated\nsegmentation. Firstly, the feature refinement module which adaptively\nre-weights the feature channels is exploited in the encoder to capture more\ninformative features and discard information in irrelevant regions.\nFurthermore, we propose a multi-prediction guided attention mechanism which\nprovides pixel-wise semantic prediction guidance to better recover the\nsegmentation mask at each scale. This mechanism which transforms the deep\nsupervision to supervised attention is able to guide feature aggregation with\nmore semantic information between intermediate layers. Experiments on the\npublicly available Duke OCT dataset confirm the effectiveness of the proposed\nmethod as well as an improved performance over other state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 21:22:22 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Fu", "Zeyu", ""], ["Sun", "Yang", ""], ["Zhang", "Xiangyu", ""], ["Stainton", "Scott", ""], ["Barney", "Shaun", ""], ["Hogg", "Jeffry", ""], ["Innes", "William", ""], ["Dlay", "Satnam", ""]]}, {"id": "2009.13635", "submitter": "Zeyu Fu", "authors": "Zeyu Fu, Jianbo Jiao, Michael Suttie, J. Alison Noble", "title": "Cross-Task Representation Learning for Anatomical Landmark Detection", "comments": "MICCAI-MLMI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is an increasing demand for automatically detecting\nanatomical landmarks which provide rich structural information to facilitate\nsubsequent medical image analysis. Current methods related to this task often\nleverage the power of deep neural networks, while a major challenge in fine\ntuning such models in medical applications arises from insufficient number of\nlabeled samples. To address this, we propose to regularize the knowledge\ntransfer across source and target tasks through cross-task representation\nlearning. The proposed method is demonstrated for extracting facial anatomical\nlandmarks which facilitate the diagnosis of fetal alcohol syndrome. The source\nand target tasks in this work are face recognition and landmark detection,\nrespectively. The main idea of the proposed method is to retain the feature\nrepresentations of the source model on the target task data, and to leverage\nthem as an additional source of supervisory signals for regularizing the target\nmodel learning, thereby improving its performance under limited training\nsamples. Concretely, we present two approaches for the proposed representation\nlearning by constraining either final or intermediate model features on the\ntarget model. Experimental results on a clinical face image dataset demonstrate\nthat the proposed approach works well with few labeled data, and outperforms\nother compared approaches.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 21:22:49 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Fu", "Zeyu", ""], ["Jiao", "Jianbo", ""], ["Suttie", "Michael", ""], ["Noble", "J. Alison", ""]]}, {"id": "2009.13655", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Jean Maillard, Akshat Shrivastava, Keith Diedrick,\n  Mike Haeger, Haoran Li, Yashar Mehdad, Ves Stoyanov, Anuj Kumar, Mike Lewis,\n  Sonal Gupta", "title": "Conversational Semantic Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structured representation for semantic parsing in task-oriented assistant\nsystems is geared towards simple understanding of one-turn queries. Due to the\nlimitations of the representation, the session-based properties such as\nco-reference resolution and context carryover are processed downstream in a\npipelined system. In this paper, we propose a semantic representation for such\ntask-oriented conversational systems that can represent concepts such as\nco-reference and context carryover, enabling comprehensive understanding of\nqueries in a session. We release a new session-based, compositional\ntask-oriented parsing dataset of 20k sessions consisting of 60k utterances.\nUnlike Dialog State Tracking Challenges, the queries in the dataset have\ncompositional forms. We propose a new family of Seq2Seq models for the\nsession-based parsing above, which achieve better or comparable performance to\nthe current state-of-the-art on ATIS, SNIPS, TOP and DSTC2. Notably, we improve\nthe best known results on DSTC2 by up to 5 points for slot-carryover.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:08:00 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Maillard", "Jean", ""], ["Shrivastava", "Akshat", ""], ["Diedrick", "Keith", ""], ["Haeger", "Mike", ""], ["Li", "Haoran", ""], ["Mehdad", "Yashar", ""], ["Stoyanov", "Ves", ""], ["Kumar", "Anuj", ""], ["Lewis", "Mike", ""], ["Gupta", "Sonal", ""]]}, {"id": "2009.13664", "submitter": "Eugene Tam", "authors": "Eugene Tam, Shenfei Jiang, Paul Duan, Shawn Meng, Yue Pang, Cayden\n  Huang, Yi Han, Jacke Xie, Yuanjun Cui, Jinsong Yu, Minggui Lu", "title": "Breaking the Memory Wall for AI Chip with a New Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in deep learning have led to the widespread adoption of\nartificial intelligence (AI) in applications such as computer vision and\nnatural language processing. As neural networks become deeper and larger, AI\nmodeling demands outstrip the capabilities of conventional chip architectures.\nMemory bandwidth falls behind processing power. Energy consumption comes to\ndominate the total cost of ownership. Currently, memory capacity is\ninsufficient to support the most advanced NLP models. In this work, we present\na 3D AI chip, called Sunrise, with near-memory computing architecture to\naddress these three challenges. This distributed, near-memory computing\narchitecture allows us to tear down the performance-limiting memory wall with\nan abundance of data bandwidth. We achieve the same level of energy efficiency\non 40nm technology as competing chips on 7nm technology. By moving to similar\ntechnologies as other AI chips, we project to achieve more than ten times the\nenergy efficiency, seven times the performance of the current state-of-the-art\nchips, and twenty times of memory capacity as compared with the best chip in\neach benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:34:10 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Tam", "Eugene", ""], ["Jiang", "Shenfei", ""], ["Duan", "Paul", ""], ["Meng", "Shawn", ""], ["Pang", "Yue", ""], ["Huang", "Cayden", ""], ["Han", "Yi", ""], ["Xie", "Jacke", ""], ["Cui", "Yuanjun", ""], ["Yu", "Jinsong", ""], ["Lu", "Minggui", ""]]}, {"id": "2009.13675", "submitter": "Fahad Alhomayani", "authors": "Fahad Alhomayani and Mohammad Mahoor", "title": "Deep Learning-based Symbolic Indoor Positioning using the Serving eNodeB", "comments": "- accepted paper (ICMLA 2020) - dataset and code:\n  https://doi.org/10.6084/m9.figshare.13010387.v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel indoor positioning method designed for\nresidential apartments. The proposed method makes use of cellular signals\nemitting from a serving eNodeB which eliminates the need for specialized\npositioning infrastructure. Additionally, it utilizes Denoising Autoencoders to\nmitigate the effects of cellular signal loss. We evaluated the proposed method\nusing real-world data collected from two different smartphones inside a\nrepresentative apartment of eight symbolic spaces. Experimental results verify\nthat the proposed method outperforms conventional symbolic indoor positioning\ntechniques in various performance metrics. To promote reproducibility and\nfoster new research efforts, we made all the data and codes associated with\nthis work publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 23:00:28 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Alhomayani", "Fahad", ""], ["Mahoor", "Mohammad", ""]]}, {"id": "2009.13682", "submitter": "Xiaowei Hu", "authors": "Xiaowei Hu, Xi Yin, Kevin Lin, Lijuan Wang, Lei Zhang, Jianfeng Gao,\n  Zicheng Liu", "title": "VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is highly desirable yet challenging to generate image captions that can\ndescribe novel objects which are unseen in caption-labeled training data, a\ncapability that is evaluated in the novel object captioning challenge (nocaps).\nIn this challenge, no additional image-caption training data, other thanCOCO\nCaptions, is allowed for model training. Thus, conventional Vision-Language\nPre-training (VLP) methods cannot be applied. This paper presents VIsual\nVOcabulary pretraining (VIVO) that performs pre-training in the absence of\ncaption annotations. By breaking the dependency of paired image-caption\ntraining data in VLP, VIVO can leverage large amounts of paired image-tag data\nto learn a visual vocabulary. This is done by pre-training a multi-layer\nTransformer model that learns to align image-level tags with their\ncorresponding image region features. To address the unordered nature of image\ntags, VIVO uses a Hungarian matching loss with masked tag prediction to conduct\npre-training. We validate the effectiveness of VIVO by fine-tuning the\npre-trained model for image captioning. In addition, we perform an analysis of\nthe visual-text alignment inferred by our model. The results show that our\nmodel can not only generate fluent image captions that describe novel objects,\nbut also identify the locations of these objects. Our single model has achieved\nnew state-of-the-art results on nocaps and surpassed the human CIDEr score.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 23:20:02 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 20:01:10 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hu", "Xiaowei", ""], ["Yin", "Xi", ""], ["Lin", "Kevin", ""], ["Wang", "Lijuan", ""], ["Zhang", "Lei", ""], ["Gao", "Jianfeng", ""], ["Liu", "Zicheng", ""]]}, {"id": "2009.13689", "submitter": "Olga Ohrimenko", "authors": "Sajin Sasy and Olga Ohrimenko", "title": "Oblivious Sampling Algorithms for Private Data Analysis", "comments": "Appeared in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study secure and privacy-preserving data analysis based on queries\nexecuted on samples from a dataset. Trusted execution environments (TEEs) can\nbe used to protect the content of the data during query computation, while\nsupporting differential-private (DP) queries in TEEs provides record privacy\nwhen query output is revealed. Support for sample-based queries is attractive\ndue to \\emph{privacy amplification} since not all dataset is used to answer a\nquery but only a small subset. However, extracting data samples with TEEs while\nproving strong DP guarantees is not trivial as secrecy of sample indices has to\nbe preserved. To this end, we design efficient secure variants of common\nsampling algorithms. Experimentally we show that accuracy of models trained\nwith shuffling and sampling is the same for differentially private models for\nMNIST and CIFAR-10, while sampling provides stronger privacy guarantees than\nshuffling.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 23:45:30 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sasy", "Sajin", ""], ["Ohrimenko", "Olga", ""]]}, {"id": "2009.13697", "submitter": "Mengyuan Lee", "authors": "Mengyuan Lee, Seyyedali Hosseinalipour, Christopher G. Brinton,\n  Guanding Yu, and Huaiyu Dai", "title": "A Fast Graph Neural Network-Based Method for Winner Determination in\n  Multi-Unit Combinatorial Auctions", "comments": "Accepted by Transactions on Cloud Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combinatorial auction (CA) is an efficient mechanism for resource\nallocation in different fields, including cloud computing. It can obtain high\neconomic efficiency and user flexibility by allowing bidders to submit bids for\ncombinations of different items instead of only for individual items. However,\nthe problem of allocating items among the bidders to maximize the auctioneers\"\nrevenue, i.e., the winner determination problem (WDP), is NP-complete to solve\nand inapproximable. Existing works for WDPs are generally based on mathematical\noptimization techniques and most of them focus on the single-unit WDP, where\neach item only has one unit. On the contrary, few works consider the multi-unit\nWDP in which each item may have multiple units. Given that the multi-unit WDP\nis more complicated but prevalent in cloud computing, we propose leveraging\nmachine learning (ML) techniques to develop a novel low-complexity algorithm\nfor solving this problem with negligible revenue loss. Specifically, we model\nthe multi-unit WDP as an augmented bipartite bid-item graph and use a graph\nneural network (GNN) with half-convolution operations to learn the probability\nof each bid belonging to the optimal allocation. To improve the sample\ngeneration efficiency and decrease the number of needed labeled instances, we\npropose two different sample generation processes. We also develop two novel\ngraph-based post-processing algorithms to transform the outputs of the GNN into\nfeasible solutions. Through simulations on both synthetic instances and a\nspecific virtual machine (VM) allocation problem in a cloud computing platform,\nwe validate that our proposed method can approach optimal performance with low\ncomplexity and has good generalization ability in terms of problem size and\nuser-type distribution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 00:22:37 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:31:41 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lee", "Mengyuan", ""], ["Hosseinalipour", "Seyyedali", ""], ["Brinton", "Christopher G.", ""], ["Yu", "Guanding", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2009.13702", "submitter": "Ping Lang", "authors": "Ping Lang, Xiongjun Fu, Marco Martorella, Jian Dong, Rui Qin, Xianpeng\n  Meng and Min Xie", "title": "A Comprehensive Survey of Machine Learning Applied to Radar Signal\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern radar systems have high requirements in terms of accuracy, robustness\nand real-time capability when operating on increasingly complex electromagnetic\nenvironments. Traditional radar signal processing (RSP) methods have shown some\nlimitations when meeting such requirements, particularly in matters of target\nclassification. With the rapid development of machine learning (ML), especially\ndeep learning, radar researchers have started integrating these new methods\nwhen solving RSP-related problems. This paper aims at helping researchers and\npractitioners to better understand the application of ML techniques to\nRSP-related problems by providing a comprehensive, structured and reasoned\nliterature overview of ML-based RSP techniques. This work is amply introduced\nby providing general elements of ML-based RSP and by stating the motivations\nbehind them. The main applications of ML-based RSP are then analysed and\nstructured based on the application field. This paper then concludes with a\nseries of open questions and proposed research directions, in order to indicate\ncurrent gaps and potential future solutions and trends.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 00:30:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lang", "Ping", ""], ["Fu", "Xiongjun", ""], ["Martorella", "Marco", ""], ["Dong", "Jian", ""], ["Qin", "Rui", ""], ["Meng", "Xianpeng", ""], ["Xie", "Min", ""]]}, {"id": "2009.13711", "submitter": "Chenguang Zhao", "authors": "Chenguang Zhao, Xiaorong Hu, Gang Wang", "title": "PDLight: A Deep Reinforcement Learning Traffic Light Control Algorithm\n  with Pressure and Dynamic Light Duration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing ineffective and inflexible traffic light control at urban\nintersections can often lead to congestion in traffic flows and cause numerous\nproblems, such as long delay and waste of energy. How to find the optimal\nsignal timing strategy is a significant challenge in urban traffic management.\nIn this paper, we propose PDlight, a deep reinforcement learning (DRL) traffic\nlight control algorithm with a novel reward as PRCOL (Pressure with Remaining\nCapacity of Outgoing Lane). Serving as an improvement over the pressure used in\ntraffic control algorithms, PRCOL considers not only the number of vehicles on\nthe incoming lane but also the remaining capacity of the outgoing lane.\nSimulation results using both synthetic and real-world data-sets show that the\nproposed PDlight yields lower average travel time compared with several\nstate-of-the-art algorithms, PressLight and Colight, under both fixed and\ndynamic green light duration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:07:49 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zhao", "Chenguang", ""], ["Hu", "Xiaorong", ""], ["Wang", "Gang", ""]]}, {"id": "2009.13714", "submitter": "Pu Zhao", "authors": "Pu Zhao, Sijia Liu, Parikshit Ram, Songtao Lu, Yuguang Yao, Djallel\n  Bouneffouf, Xue Lin", "title": "Learned Fine-Tuner for Incongruous Few-Shot Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Model-agnostic meta-learning (MAML) effectively meta-learns an initialization\nof model parameters for few-shot learning where all learning problems share the\nsame format of model parameters -- congruous meta-learning. However, there are\nfew-shot learning scenarios, such as adversarial attack design, where different\nyet related few-shot learning problems may not share any optimizee variables,\nnecessitating incongruous meta-learning. We extend MAML to this setting -- a\nLearned Fine Tuner (LFT) is used to replace hand-designed optimizers (such as\nSGD) for the task-specific fine-tuning. Here, MAML instead meta-learns the\nparameters of this LFT across incongruous tasks leveraging the\nlearning-to-optimize (L2O) framework such that models fine-tuned with LFT (even\nfrom random initializations) adapt quickly to new tasks. As novel\ncontributions, we show that the use of LFT within MAML (i) offers the\ncapability to tackle few-shot learning tasks by meta-learning across\nincongruous yet related problems and (ii) can efficiently work with first-order\nand derivative-free few-shot learning problems. Theoretically, we quantify the\ndifference between LFT (for MAML) and L2O. Empirically, we demonstrate the\neffectiveness of LFT through a novel application of generating universal\nadversarial attacks across different image sources and sizes in the few-shot\nlearning regime.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:23:20 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 00:47:28 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 17:42:57 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Ram", "Parikshit", ""], ["Lu", "Songtao", ""], ["Yao", "Yuguang", ""], ["Bouneffouf", "Djallel", ""], ["Lin", "Xue", ""]]}, {"id": "2009.13716", "submitter": "Qing Tian", "authors": "Qing Tian, Tal Arbel, James J. Clark", "title": "Grow-Push-Prune: aligning deep discriminants for effective structural\n  network compression", "comments": "title changed, unimportant figures/tables moved to the appendix,\n  typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of today's popular deep architectures are hand-engineered to be\ngeneralists. However, this design procedure usually leads to massive redundant,\nuseless, or even harmful features for specific tasks. Unnecessarily high\ncomplexities render deep nets impractical for many real-world applications,\nespecially those without powerful GPU support. In this paper, we attempt to\nderive task-dependent compact models from a deep discriminant analysis\nperspective. We propose an iterative and proactive approach for classification\ntasks which alternates between (1) a pushing step, with an objective to\nsimultaneously maximize class separation, penalize co-variances, and push deep\ndiscriminants into alignment with a compact set of neurons, and (2) a pruning\nstep, which discards less useful or even interfering neurons. Deconvolution is\nadopted to reverse 'unimportant' filters' effects and recover useful\ncontributing sources. A simple network growing strategy based on the basic\nInception module is proposed for challenging tasks requiring larger capacity\nthan what the base net can offer. Experiments on the MNIST, CIFAR10, and\nImageNet datasets demonstrate our approach's efficacy. On ImageNet, by pushing\nand pruning our grown Inception-88 model, we achieve more accurate models than\nInception nets generated during growing, residual nets, and popular compact\nnets at similar sizes. We also show that our grown Inception nets (without\nhard-coded dimension alignment) clearly outperform residual nets of similar\ncomplexities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:29:23 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:44:41 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Tian", "Qing", ""], ["Arbel", "Tal", ""], ["Clark", "James J.", ""]]}, {"id": "2009.13720", "submitter": "Sharan Raja", "authors": "Sharan Raja, Rudraksh Tuwani", "title": "Adversarial Attacks Against Deep Learning Systems for ICD-9 Code\n  Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manual annotation of ICD-9 codes is a time consuming and error-prone process.\nDeep learning based systems tackling the problem of automated ICD-9 coding have\nachieved competitive performance. Given the increased proliferation of\nelectronic medical records, such automated systems are expected to eventually\nreplace human coders. In this work, we investigate how a simple typo-based\nadversarial attack strategy can impact the performance of state-of-the-art\nmodels for the task of predicting the top 50 most frequent ICD-9 codes from\ndischarge summaries. Preliminary results indicate that a malicious adversary,\nusing gradient information, can craft specific perturbations, that appear as\nregular human typos, for less than 3% of words in the discharge summary to\nsignificantly affect the performance of the baseline model.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:45:11 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Raja", "Sharan", ""], ["Tuwani", "Rudraksh", ""]]}, {"id": "2009.13729", "submitter": "Ethan Manilow", "authors": "Ethan Manilow, Bryan Pardo", "title": "Bespoke Neural Networks for Score-Informed Source Separation", "comments": "ISMIR 2020 - Late Breaking Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a simple method that can separate arbitrary\nmusical instruments from an audio mixture. Given an unaligned MIDI\ntranscription for a target instrument from an input mixture, we synthesize new\nmixtures from the midi transcription that sound similar to the mixture to be\nseparated. This lets us create a labeled training set to train a network on the\nspecific bespoke task. When this model applied to the original mixture, we\ndemonstrate that this method can: 1) successfully separate out the desired\ninstrument with access to only unaligned MIDI, 2) separate arbitrary\ninstruments, and 3) get results in a fraction of the time of existing methods.\nWe encourage readers to listen to the demos posted here: https://git.io/JUu5q.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 02:09:23 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Manilow", "Ethan", ""], ["Pardo", "Bryan", ""]]}, {"id": "2009.13734", "submitter": "Mohammad Esmaeili", "authors": "Mohammad Esmaeili, and Aria Nosratinia", "title": "Semi-Supervised Node Classification by Graph Convolutional Networks and\n  Extracted Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nodes of a graph existing in a cluster are more likely to connect to each\nother than with other nodes in the graph. Then revealing some information about\nsome nodes, the structure of the graph (graph edges) provides this opportunity\nto know more information about other nodes. From this perspective, this paper\nrevisits the node classification task in a semi-supervised scenario by graph\nconvolutional networks (GCNs). The goal is to benefit from the flow of\ninformation that circulates around the revealed node labels. The contribution\nof this paper is twofold. First, this paper provides a method for extracting\nside information from a graph realization. Then a new GCN architecture is\npresented that combines the output of traditional GCN and the extracted side\ninformation. Another contribution of this paper is relevant to non-graph\nobservations (independent side information) that exists beside a graph\nrealization in many applications. Indeed, the extracted side information can be\nreplaced by a sequence of side information that is independent of the graph\nstructure. For both cases, the experiments on synthetic and real-world datasets\ndemonstrate that the proposed model achieves a higher prediction accuracy in\ncomparison to the existing state-of-the-art methods for the node classification\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 02:38:58 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 19:18:33 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Esmaeili", "Mohammad", ""], ["Nosratinia", "Aria", ""]]}, {"id": "2009.13736", "submitter": "Yunshu Du", "authors": "Yunshu Du, Garrett Warnell, Assefaw Gebremedhin, Peter Stone, Matthew\n  E. Taylor", "title": "Lucid Dreaming for Experience Replay: Refreshing Past States with the\n  Current Policy", "comments": "29 pages (with appendices), 8 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay (ER) improves the data efficiency of off-policy\nreinforcement learning (RL) algorithms by allowing an agent to store and reuse\nits past experiences in a replay buffer. While many techniques have been\nproposed to enhance ER by biasing how experiences are sampled from the buffer,\nthus far they have not considered strategies for refreshing experiences inside\nthe buffer. In this work, we introduce Lucid Dreaming for Experience Replay\n(LiDER), a conceptually new framework that allows replay experiences to be\nrefreshed by leveraging the agent's current policy. LiDER consists of three\nsteps: First, LiDER moves an agent back to a past state. Second, from that\nstate, LiDER then lets the agent execute a sequence of actions by following its\ncurrent policy -- as if the agent were \"dreaming\" about the past and can try\nout different behaviors to encounter new experiences in the dream. Third, LiDER\nstores and reuses the new experience if it turned out better than what the\nagent previously experienced, i.e., to refresh its memories. LiDER is designed\nto be easily incorporated into off-policy, multi-worker RL algorithms that use\nER; we present in this work a case study of applying LiDER to an actor-critic\nbased algorithm. Results show LiDER consistently improves performance over the\nbaseline in six Atari 2600 games. Our open-source implementation of LiDER and\nthe data used to generate all plots in this work are available at\ngithub.com/duyunshu/lucid-dreaming-for-exp-replay.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 02:54:11 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 19:54:39 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 23:43:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Du", "Yunshu", ""], ["Warnell", "Garrett", ""], ["Gebremedhin", "Assefaw", ""], ["Stone", "Peter", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2009.13743", "submitter": "Leonardo Ramos Thomas", "authors": "Leonardo Ramos, Bernardo Morales", "title": "SwiftFace: Real-Time Face Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision is a field of artificial intelligence that trains computers\nto interpret the visual world in a way similar to that of humans. Due to the\nrapid advancements in technology and the increasing availability of\nsufficiently large training datasets, the topics within computer vision have\nexperienced a steep growth in the last decade. Among them, one of the most\npromising fields is face detection. Being used daily in a wide variety of\nfields; from mobile apps and augmented reality for entertainment purposes, to\nsocial studies and security cameras; designing high-performance models for face\ndetection is crucial. On top of that, with the aforementioned growth in face\ndetection technologies, precision and accuracy are no longer the only relevant\nfactors: for real-time face detection, speed of detection is essential.\nSwiftFace is a novel deep learning model created solely to be a fast face\ndetection model. By focusing only on detecting faces, SwiftFace performs 30%\nfaster than current state-of-the-art face detection models. Code available at\nhttps://github.com/leo7r/swiftface\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 03:09:29 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Ramos", "Leonardo", ""], ["Morales", "Bernardo", ""]]}, {"id": "2009.13749", "submitter": "Ting-Jui Chang", "authors": "Ting-Jui Chang, Shahin Shahrampour", "title": "Distributed Online Linear Quadratic Control for Linear Time-invariant\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical linear quadratic (LQ) control centers around linear time-invariant\n(LTI) systems, where the control-state pairs introduce a quadratic cost with\ntime-invariant parameters. Recent advancement in online optimization and\ncontrol has provided novel tools to study LQ problems that are robust to\ntime-varying cost parameters. Inspired by this line of research, we study the\ndistributed online LQ problem for identical LTI systems. Consider a multi-agent\nnetwork where each agent is modeled as an LTI system. The LTI systems are\nassociated with decoupled, time-varying quadratic costs that are revealed\nsequentially. The goal of the network is to make the control sequence of all\nagents competitive to that of the best centralized policy in hindsight,\ncaptured by the notion of regret. We develop a distributed variant of the\nonline LQ algorithm, which runs distributed online gradient descent with a\nprojection to a semi-definite programming (SDP) to generate controllers. We\nestablish a regret bound scaling as the square root of the finite time-horizon,\nimplying that agents reach consensus as time grows. We further provide\nnumerical experiments verifying our theoretical result.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 03:30:49 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Chang", "Ting-Jui", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2009.13752", "submitter": "Shuang Zeng", "authors": "Shuang Zeng, Runxin Xu, Baobao Chang and Lei Li", "title": "Double Graph Based Reasoning for Document-level Relation Extraction", "comments": "Accepted as long paper to appear at the EMNLP 2020 main conference,\n  11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Document-level relation extraction aims to extract relations among entities\nwithin a document. Different from sentence-level relation extraction, it\nrequires reasoning over multiple sentences across a document. In this paper, we\npropose Graph Aggregation-and-Inference Network (GAIN) featuring double graphs.\nGAIN first constructs a heterogeneous mention-level graph (hMG) to model\ncomplex interaction among different mentions across the document. It also\nconstructs an entity-level graph (EG), based on which we propose a novel path\nreasoning mechanism to infer relations between entities. Experiments on the\npublic dataset, DocRED, show GAIN achieves a significant performance\nimprovement (2.85 on F1) over the previous state-of-the-art. Our code is\navailable at https://github.com/DreamInvoker/GAIN .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 03:41:01 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zeng", "Shuang", ""], ["Xu", "Runxin", ""], ["Chang", "Baobao", ""], ["Li", "Lei", ""]]}, {"id": "2009.13772", "submitter": "Kai-En Yang", "authors": "Kai-En Yang, Chia-Yu Tsai, Hung-Hao Shen, Chen-Feng Chiang, Feng-Ming\n  Tsai, Chung-An Wang, Yiju Ting, Chia-Shun Yeh, and Chin-Tang Lai", "title": "Fast Design Space Adaptation with Deep Reinforcement Learning for Analog\n  Circuit Sizing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for design space search on analog circuit sizing\nusing deep reinforcement learning (DRL). Nowadays, analog circuit design is a\nmanual routine that requires heavy design efforts due to the absence of\nautomation tools, motivating the urge to develop one. Prior approaches cast\nthis process as an optimization problem. They use global search strategies\nbased on DRL with complex network architectures. Nonetheless, the models are\nhard to converge and neglected various working conditions of PVT (process,\nvoltage, temperature).In this work, we reduce the problem to a constraint\nsatisfaction problem, where a local strategy is adopted. Thus, a simple\nfeed-forward network with few layers can be used to implement a model-based\nreinforcement learning agent. To evaluate the value of the our framework in\nproduction, we cooperate with R&Ds in an IC design company. On circuits with\nTSMC advanced 5 and 6nm process, our agents can deliver PPA (performance,\npower, area) beyond human level. Furthermore, the product will be taped out in\nthe near future.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:13:15 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 01:08:49 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 03:40:05 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Yang", "Kai-En", ""], ["Tsai", "Chia-Yu", ""], ["Shen", "Hung-Hao", ""], ["Chiang", "Chen-Feng", ""], ["Tsai", "Feng-Ming", ""], ["Wang", "Chung-An", ""], ["Ting", "Yiju", ""], ["Yeh", "Chia-Shun", ""], ["Lai", "Chin-Tang", ""]]}, {"id": "2009.13792", "submitter": "K K Thyagharajan", "authors": "S. D. Lalitha, K. K. Thyagharajan", "title": "Micro-Facial Expression Recognition in Video Based on Optimal\n  Convolutional Neural Network (MFEOCNN) Algorithm", "comments": "19 pages, 10 figures, \"for published version see\n  https://www.ijeat.org/wp-content/uploads/papers/v9i1/A9802109119.pdf\"", "journal-ref": null, "doi": "10.35940/ijeat.A9802.109119", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expression is a standout amongst the most imperative features of human\nemotion recognition. For demonstrating the emotional states facial expressions\nare utilized by the people. In any case, recognition of facial expressions has\npersisted a testing and intriguing issue with regards to PC vision. Recognizing\nthe Micro-Facial expression in video sequence is the main objective of the\nproposed approach. For efficient recognition, the proposed method utilizes the\noptimal convolution neural network. Here the proposed method considering the\ninput dataset is the CK+ dataset. At first, by means of Adaptive median\nfiltering preprocessing is performed in the input image. From the preprocessed\noutput, the extracted features are Geometric features, Histogram of Oriented\nGradients features and Local binary pattern features. The novelty of the\nproposed method is, with the help of Modified Lion Optimization (MLO)\nalgorithm, the optimal features are selected from the extracted features. In a\nshorter computational time, it has the benefits of rapidly focalizing and\neffectively acknowledging with the aim of getting an overall arrangement or\nidea. Finally, the recognition is done by Convolution Neural network (CNN).\nThen the performance of the proposed MFEOCNN method is analysed in terms of\nfalse measures and recognition accuracy. This kind of emotion recognition is\nmainly used in medicine, marketing, E-learning, entertainment, law and\nmonitoring. From the simulation, we know that the proposed approach achieves\nmaximum recognition accuracy of 99.2% with minimum Mean Absolute Error (MAE)\nvalue. These results are compared with the existing for MicroFacial Expression\nBased Deep-Rooted Learning (MFEDRL), Convolutional Neural Network with Lion\nOptimization (CNN+LO) and Convolutional Neural Network (CNN) without\noptimization. The simulation of the proposed method is done in the working\nplatform of MATLAB.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 05:56:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lalitha", "S. D.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.13794", "submitter": "Weiran Yao", "authors": "Weiran Yao, Sean Qian", "title": "From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction\n  Using Social Media Data", "comments": null, "journal-ref": "Transportation research part C: emerging technologies 124 (2021):\n  102938", "doi": "10.1016/j.trc.2020.102938", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of traditional traffic prediction methods is often\nextremely limited when forecasting traffic dynamics in early morning. The\nreason is that traffic can break down drastically during the early morning\ncommute, and the time and duration of this break-down vary substantially from\nday to day. Early morning traffic forecast is crucial to inform morning-commute\ntraffic management, but they are generally challenging to predict in advance,\nparticularly by midnight. In this paper, we propose to mine Twitter messages as\na probing method to understand the impacts of people's work and rest patterns\nin the evening/midnight of the previous day to the next-day morning traffic.\nThe model is tested on freeway networks in Pittsburgh as experiments. The\nresulting relationship is surprisingly simple and powerful. We find that, in\ngeneral, the earlier people rest as indicated from Tweets, the more congested\nroads will be in the next morning. The occurrence of big events in the evening\nbefore, represented by higher or lower tweet sentiment than normal, often\nimplies lower travel demand in the next morning than normal days. Besides,\npeople's tweeting activities in the night before and early morning are\nstatistically associated with congestion in morning peak hours. We make use of\nsuch relationships to build a predictive framework which forecasts morning\ncommute congestion using people's tweeting profiles extracted by 5 am or as\nlate as the midnight prior to the morning. The Pittsburgh study supports that\nour framework can precisely predict morning congestion, particularly for some\nroad segments upstream of roadway bottlenecks with large day-to-day congestion\nvariation. Our approach considerably outperforms those existing methods without\nTwitter message features, and it can learn meaningful representation of demand\nfrom tweeting profiles that offer managerial insights.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:02:33 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 17:56:25 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Yao", "Weiran", ""], ["Qian", "Sean", ""]]}, {"id": "2009.13801", "submitter": "Asif Salim", "authors": "Asif Salim and Sumitra S", "title": "Framework for Designing Filters of Spectral Graph Convolutional Neural\n  Networks in the Context of Regularization Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNNs) have been widely used in graph\nlearning. It has been observed that the smoothness functional on graphs can be\ndefined in terms of the graph Laplacian. This fact points out in the direction\nof using Laplacian in deriving regularization operators on graphs and its\nconsequent use with spectral GCNN filter designs. In this work, we explore the\nregularization properties of graph Laplacian and proposed a generalized\nframework for regularized filter designs in spectral GCNNs. We found that the\nfilters used in many state-of-the-art GCNNs can be derived as a special case of\nthe framework we developed. We designed new filters that are associated with\nwell-defined regularization behavior and tested their performance on\nsemi-supervised node classification tasks. Their performance was found to be\nsuperior to that of the other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:19:08 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Salim", "Asif", ""], ["S", "Sumitra", ""]]}, {"id": "2009.13803", "submitter": "Qingbei Guo", "authors": "Qingbei Guo and Xiao-Jun Wu and Josef Kittler and Zhiquan Feng", "title": "Self-grouping Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although group convolution operators are increasingly used in deep\nconvolutional neural networks to improve the computational efficiency and to\nreduce the number of parameters, most existing methods construct their group\nconvolution architectures by a predefined partitioning of the filters of each\nconvolutional layer into multiple regular filter groups with an equal spatial\ngroup size and data-independence, which prevents a full exploitation of their\npotential. To tackle this issue, we propose a novel method of designing\nself-grouping convolutional neural networks, called SG-CNN, in which the\nfilters of each convolutional layer group themselves based on the similarity of\ntheir importance vectors. Concretely, for each filter, we first evaluate the\nimportance value of their input channels to identify the importance vectors,\nand then group these vectors by clustering. Using the resulting\n\\emph{data-dependent} centroids, we prune the less important connections, which\nimplicitly minimizes the accuracy loss of the pruning, thus yielding a set of\n\\emph{diverse} group convolution filters. Subsequently, we develop two\nfine-tuning schemes, i.e. (1) both local and global fine-tuning and (2) global\nonly fine-tuning, which experimentally deliver comparable results, to recover\nthe recognition capacity of the pruned network. Comprehensive experiments\ncarried out on the CIFAR-10/100 and ImageNet datasets demonstrate that our\nself-grouping convolution method adapts to various state-of-the-art CNN\narchitectures, such as ResNet and DenseNet, and delivers superior performance\nin terms of compression ratio, speedup and recognition accuracy. We demonstrate\nthe ability of SG-CNN to generalise by transfer learning, including domain\nadaption and object detection, showing competitive results. Our source code is\navailable at https://github.com/QingbeiGuo/SG-CNN.git.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:24:32 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Guo", "Qingbei", ""], ["Wu", "Xiao-Jun", ""], ["Kittler", "Josef", ""], ["Feng", "Zhiquan", ""]]}, {"id": "2009.13807", "submitter": "Renjie Wu", "authors": "Renjie Wu, Eamonn J. Keogh", "title": "Current Time Series Anomaly Detection Benchmarks are Flawed and are\n  Creating the Illusion of Progress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series anomaly detection has been a perennially important topic in data\nscience, with papers dating back to the 1950s. However, in recent years there\nhas been an explosion of interest in this topic, much of it driven by the\nsuccess of deep learning in other domains and for other time series tasks. Most\nof these papers test on one or more of a handful of popular benchmark datasets,\ncreated by Yahoo, Numenta, NASA, etc. In this work we make a surprising claim.\nThe majority of the individual exemplars in these datasets suffer from one or\nmore of four flaws. Because of these four flaws, we believe that many published\ncomparisons of anomaly detection algorithms may be unreliable, and more\nimportantly, much of the apparent progress in recent years may be illusionary.\nIn addition to demonstrating these claims, with this paper we introduce the UCR\nTime Series Anomaly Datasets. We believe that this resource will perform a\nsimilar role as the UCR Time Series Classification Archive, by providing the\ncommunity with a benchmark that allows meaningful comparisons between\napproaches and a meaningful gauge of overall progress.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:29:04 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 18:49:13 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 20:40:27 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wu", "Renjie", ""], ["Keogh", "Eamonn J.", ""]]}, {"id": "2009.13824", "submitter": "Laura Doerr", "authors": "Laura D\\\"orr, Felix Brandt, Martin Pouls, Alexander Naumann", "title": "An Image Processing Pipeline for Automated Packaging Structure\n  Recognition", "comments": "To be published in: \"Forum Bildverarbeitung 2020\", KIT Scientific\n  Publishing, Karlsruhe", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dispatching and receiving logistics goods, as well as transportation itself,\ninvolve a high amount of manual efforts. The transported goods, including their\npackaging and labeling, need to be double-checked, verified or recognized at\nmany supply chain network points. These processes hold automation potentials,\nwhich we aim to exploit using computer vision techniques. More precisely, we\npropose a cognitive system for the fully automated recognition of packaging\nstructures for standardized logistics shipments based on single RGB images. Our\ncontribution contains descriptions of a suitable system design and its\nevaluation on relevant real-world data. Further, we discuss our algorithmic\nchoices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:26:08 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["D\u00f6rr", "Laura", ""], ["Brandt", "Felix", ""], ["Pouls", "Martin", ""], ["Naumann", "Alexander", ""]]}, {"id": "2009.13826", "submitter": "Yanlin Li", "authors": "Yanlin Li, Shi An, Ruisheng Zhang", "title": "EEMC: Embedding Enhanced Multi-tag Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently occurred representation learning make an attractive performance\nin NLP and complex network, it is becoming a fundamental technology in machine\nlearning and data mining. How to use representation learning to improve the\nperformance of classifiers is a very significance research direction. We using\nrepresentation learning technology to map raw data(node of graph) to a\nlow-dimensional feature space. In this space, each raw data obtained a lower\ndimensional vector representation, we do some simple linear operations for\nthose vectors to produce some virtual data, using those vectors and virtual\ndata to training multi-tag classifier. After that we measured the performance\nof classifier by F1 score(Macro% F1 and Micro% F1). Our method make Macro F1\nrise from 28 % - 450% and make average F1 score rise from 12 % - 224%. By\ncontrast, we trained the classifier directly with the lower dimensional vector,\nand measured the performance of classifiers. We validate our algorithm on three\npublic data sets, we found that the virtual data helped the classifier greatly\nimprove the F1 score. Therefore, our algorithm is a effective way to improve\nthe performance of classifier. These result suggest that the virtual data\ngenerated by simple linear operation, in representation space, still retains\nthe information of the raw data. It's also have great significance to the\nlearning of small sample data sets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:29:34 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Li", "Yanlin", ""], ["An", "Shi", ""], ["Zhang", "Ruisheng", ""]]}, {"id": "2009.13828", "submitter": "Katharina Eggensperger", "authors": "Katharina Eggensperger, Kai Haase, Philipp M\\\"uller, Marius Lindauer\n  and Frank Hutter", "title": "Neural Model-based Optimization with Right-Censored Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields of study, we only observe lower bounds on the true response\nvalue of some experiments. When fitting a regression model to predict the\ndistribution of the outcomes, we cannot simply drop these right-censored\nobservations, but need to properly model them. In this work, we focus on the\nconcept of censored data in the light of model-based optimization where\nprematurely terminating evaluations (and thus generating right-censored data)\nis a key factor for efficiency, e.g., when searching for an algorithm\nconfiguration that minimizes runtime of the algorithm at hand. Neural networks\n(NNs) have been demonstrated to work well at the core of model-based\noptimization procedures and here we extend them to handle these censored\nobservations. We propose (i)~a loss function based on the Tobit model to\nincorporate censored samples into training and (ii) use an ensemble of networks\nto model the posterior distribution. To nevertheless be efficient in terms of\noptimization-overhead, we propose to use Thompson sampling s.t. we only need to\ntrain a single NN in each iteration. Our experiments show that our trained\nregression models achieve a better predictive quality than several baselines\nand that our approach achieves new state-of-the-art performance for model-based\noptimization on two optimization problems: minimizing the solution time of a\nSAT solver and the time-to-accuracy of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:32:30 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Eggensperger", "Katharina", ""], ["Haase", "Kai", ""], ["M\u00fcller", "Philipp", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "2009.13831", "submitter": "Milo\\v{s} Simi\\'c", "authors": "Milo\\v{s} Simi\\'c", "title": "Testing for Normality with Neural Networks", "comments": "49 pages, 10 figures; corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we treat the problem of testing for normality as a binary\nclassification problem and construct a feedforward neural network that can\nsuccessfully detect normal distributions by inspecting small samples from them.\nThe numerical experiments conducted on small samples with no more than 100\nelements indicated that the neural network which we trained was more accurate\nand far more powerful than the most frequently used and most powerful standard\ntests of normality: Shapiro-Wilk, Anderson-Darling, Lilliefors and\nJarque-Berra, as well as the kernel tests of goodness-of-fit. The neural\nnetwork had the AUROC score of almost 1, which corresponds to the perfect\nbinary classifier. Additionally, the network's accuracy was higher than 96% on\na set of larger samples with 250-1000 elements. Since the normality of data is\nan assumption of numerous techniques for analysis and inference, the neural\nnetwork constructed in this study has a very high potential for use in everyday\npractice of statistics, data analysis and machine learning in both science and\nindustry.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:35:40 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 07:47:22 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Simi\u0107", "Milo\u0161", ""]]}, {"id": "2009.13836", "submitter": "Abon Chaudhuri", "authors": "Theban Stanley, Nihar Vanjara, Yanxin Pan, Ekaterina Pirogova, Swagata\n  Chakraborty, Abon Chaudhuri", "title": "SIR: Similar Image Retrieval for Product Search in E-Commerce", "comments": "Accepted in 13th International Conference on Similarity Search and\n  Applications, SISAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a similar image retrieval (SIR) platform that is used to quickly\ndiscover visually similar products in a catalog of millions. Given the size,\ndiversity, and dynamism of our catalog, product search poses many challenges.\nIt can be addressed by building supervised models to tagging product images\nwith labels representing themes and later retrieving them by labels. This\napproach suffices for common and perennial themes like \"white shirt\" or\n\"lifestyle image of TV\". It does not work for new themes such as\n\"e-cigarettes\", hard-to-define ones such as \"image with a promotional badge\",\nor the ones with short relevance span such as \"Halloween costumes\". SIR is\nideal for such cases because it allows us to search by an example, not a\npre-defined theme. We describe the steps - embedding computation, encoding, and\nindexing - that power the approximate nearest neighbor search back-end. We also\nhighlight two applications of SIR. The first one is related to the detection of\nproducts with various types of potentially objectionable themes. This\napplication is run with a sense of urgency, hence the typical time frame to\ntrain and bootstrap a model is not permitted. Also, these themes are often\nshort-lived based on current trends, hence spending resources to build a\nlasting model is not justified. The second application is a variant item\ndetection system where SIR helps discover visual variants that are hard to find\nthrough text search. We analyze the performance of SIR in the context of these\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:53:03 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Stanley", "Theban", ""], ["Vanjara", "Nihar", ""], ["Pan", "Yanxin", ""], ["Pirogova", "Ekaterina", ""], ["Chakraborty", "Swagata", ""], ["Chaudhuri", "Abon", ""]]}, {"id": "2009.13852", "submitter": "Seamus Anderson", "authors": "Seamus Anderson, Martin Towner, Phil Bland, Christopher Haikings,\n  William Volante, Eleanor Sansom, Hadrien Devillepoix, Patrick Shober,\n  Benjamin Hartig, Martin Cupak, Trent Jansen-Sturgeon, Robert Howie, Gretchen\n  Benedix, Geoff Deacon", "title": "Machine Learning for Semi-Automated Meteorite Recovery", "comments": "15 pages, 3 figures, 2 tables", "journal-ref": null, "doi": "10.1111/maps.13593", "report-no": null, "categories": "astro-ph.EP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology for recovering meteorite falls observed and\nconstrained by fireball networks, using drones and machine learning algorithms.\nThis approach uses images of the local terrain for a given fall site to train\nan artificial neural network, designed to detect meteorite candidates. We have\nfield tested our methodology to show a meteorite detection rate between 75-97%,\nwhile also providing an efficient mechanism to eliminate false-positives. Our\ntests at a number of locations within Western Australia also showcase the\nability for this training scheme to generalize a model to learn localized\nterrain features. Our model-training approach was also able to correctly\nidentify 3 meteorites in their native fall sites, that were found using\ntraditional searching techniques. Our methodology will be used to recover\nmeteorite falls in a wide range of locations within globe-spanning fireball\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:27:41 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Anderson", "Seamus", ""], ["Towner", "Martin", ""], ["Bland", "Phil", ""], ["Haikings", "Christopher", ""], ["Volante", "William", ""], ["Sansom", "Eleanor", ""], ["Devillepoix", "Hadrien", ""], ["Shober", "Patrick", ""], ["Hartig", "Benjamin", ""], ["Cupak", "Martin", ""], ["Jansen-Sturgeon", "Trent", ""], ["Howie", "Robert", ""], ["Benedix", "Gretchen", ""], ["Deacon", "Geoff", ""]]}, {"id": "2009.13853", "submitter": "Adrian Englhardt", "authors": "Adrian Englhardt, Holger Trittenbach, Daniel Kottke, Bernhard Sick,\n  and Klemens B\\\"ohm", "title": "Efficient SVDD Sampling with Approximation Guarantees for the Decision\n  Boundary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Data Description (SVDD) is a popular one-class classifiers for\nanomaly and novelty detection. But despite its effectiveness, SVDD does not\nscale well with data size. To avoid prohibitive training times, sampling\nmethods select small subsets of the training data on which SVDD trains a\ndecision boundary hopefully equivalent to the one obtained on the full data\nset. According to the literature, a good sample should therefore contain\nso-called boundary observations that SVDD would select as support vectors on\nthe full data set. However, non-boundary observations also are essential to not\nfragment contiguous inlier regions and avoid poor classification accuracy.\nOther aspects, such as selecting a sufficiently representative sample, are\nimportant as well. But existing sampling methods largely overlook them,\nresulting in poor classification accuracy. In this article, we study how to\nselect a sample considering these points. Our approach is to frame SVDD\nsampling as an optimization problem, where constraints guarantee that sampling\nindeed approximates the original decision boundary. We then propose RAPID, an\nefficient algorithm to solve this optimization problem. RAPID does not require\nany tuning of parameters, is easy to implement and scales well to large data\nsets. We evaluate our approach on real-world and synthetic data. Our evaluation\nis the most comprehensive one for SVDD sampling so far. Our results show that\nRAPID outperforms its competitors in classification accuracy, in sample size,\nand in runtime.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:28:01 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Englhardt", "Adrian", ""], ["Trittenbach", "Holger", ""], ["Kottke", "Daniel", ""], ["Sick", "Bernhard", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "2009.13856", "submitter": "Maayan Shuvi", "authors": "Maayan Shuvi, Noa Fish, Kfir Aberman, Ariel Shamir, Daniel Cohen-Or", "title": "Neural Alignment for Face De-pixelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple method to reconstruct a high-resolution video from a\nface-video, where the identity of a person is obscured by pixelization. This\nconcealment method is popular because the viewer can still perceive a human\nface figure and the overall head motion. However, we show in our experiments\nthat a fairly good approximation of the original video can be reconstructed in\na way that compromises anonymity. Our system exploits the simultaneous\nsimilarity and small disparity between close-by video frames depicting a human\nface, and employs a spatial transformation component that learns the alignment\nbetween the pixelated frames. Each frame, supported by its aligned surrounding\nframes, is first encoded, then decoded to a higher resolution. Reconstruction\nand perceptual losses promote adherence to the ground-truth, and an adversarial\nloss assists in maintaining domain faithfulness. There is no need for explicit\ntemporal coherency loss as it is maintained implicitly by the alignment of\nneighboring frames and reconstruction. Although simple, our framework\nsynthesizes high-quality face reconstructions, demonstrating that given the\nstatistical prior of a human face, multiple aligned pixelated frames contain\nsufficient information to reconstruct a high-quality approximation of the\noriginal signal.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:29:15 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shuvi", "Maayan", ""], ["Fish", "Noa", ""], ["Aberman", "Kfir", ""], ["Shamir", "Ariel", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2009.13863", "submitter": "Zhaoyang Zhang", "authors": "Zhuojun Tian, Zhaoyang Zhang, Jue Wang, Xiaoming Chen, Wei Wang, and\n  Huaiyu Dai", "title": "Distributed ADMM with Synergetic Communication and Computation", "comments": "Accepted for publication in IEEE TCOM", "journal-ref": null, "doi": "10.1109/TCOMM.2020.3027032", "report-no": null, "categories": "eess.SP cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel distributed alternating direction method of\nmultipliers (ADMM) algorithm with synergetic communication and computation,\ncalled SCCD-ADMM, to reduce the total communication and computation cost of the\nsystem. Explicitly, in the proposed algorithm, each node interacts with only\npart of its neighboring nodes, the number of which is progressively determined\naccording to a heuristic searching procedure, which takes into account both the\npredicted convergence rate and the communication and computation costs at each\niteration, resulting in a trade-off between communication and computation. Then\nthe node chooses its neighboring nodes according to an importance sampling\ndistribution derived theoretically to minimize the variance with the latest\ninformation it locally stores. Finally, the node updates its local information\nwith a new update rule which adapts to the number of communication nodes. We\nprove the convergence of the proposed algorithm and provide an upper bound of\nthe convergence variance brought by randomness. Extensive simulations validate\nthe excellent performances of the proposed algorithm in terms of convergence\nrate and variance, the overall communication and computation cost, the impact\nof network topology as well as the time for evaluation, in comparison with the\ntraditional counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:36:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Tian", "Zhuojun", ""], ["Zhang", "Zhaoyang", ""], ["Wang", "Jue", ""], ["Chen", "Xiaoming", ""], ["Wang", "Wei", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2009.13881", "submitter": "Stephan Eckstein", "authors": "Stephan Eckstein", "title": "Lipschitz neural networks are dense in the set of all Lipschitz\n  functions", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note shows that, for a fixed Lipschitz constant $L > 0$, one layer\nneural networks that are $L$-Lipschitz are dense in the set of all\n$L$-Lipschitz functions with respect to the uniform norm on bounded sets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:15:45 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Eckstein", "Stephan", ""]]}, {"id": "2009.13888", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh, Dan Jurafsky", "title": "Utility is in the Eye of the User: A Critique of NLP Leaderboards", "comments": "EMNLP 2020 (updated with additional references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarks such as GLUE have helped drive advances in NLP by incentivizing\nthe creation of more accurate models. While this leaderboard paradigm has been\nremarkably successful, a historical focus on performance-based evaluation has\nbeen at the expense of other qualities that the NLP community values in models,\nsuch as compactness, fairness, and energy efficiency. In this opinion paper, we\nstudy the divergence between what is incentivized by leaderboards and what is\nuseful in practice through the lens of microeconomic theory. We frame both the\nleaderboard and NLP practitioners as consumers and the benefit they get from a\nmodel as its utility to them. With this framing, we formalize how leaderboards\n-- in their current form -- can be poor proxies for the NLP community at large.\nFor example, a highly inefficient model would provide less utility to\npractitioners but not to a leaderboard, since it is a cost that only the former\nmust bear. To allow practitioners to better estimate a model's utility to them,\nwe advocate for more transparency on leaderboards, such as the reporting of\nstatistics that are of practical concern (e.g., model size, energy efficiency,\nand inference latency).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:25:31 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 23:04:29 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 00:40:13 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 06:22:32 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ethayarajh", "Kawin", ""], ["Jurafsky", "Dan", ""]]}, {"id": "2009.13891", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Chen Chen, Xidong Feng, Dong Li,\n  Wulong Liu", "title": "Towards Effective Context for Meta-Reinforcement Learning: an Approach\n  based on Contrastive Learning", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context, the embedding of previous collected trajectories, is a powerful\nconstruct for Meta-Reinforcement Learning (Meta-RL) algorithms. By conditioning\non an effective context, Meta-RL policies can easily generalize to new tasks\nwithin a few adaptation steps. We argue that improving the quality of context\ninvolves answering two questions: 1. How to train a compact and sufficient\nencoder that can embed the task-specific information contained in prior\ntrajectories? 2. How to collect informative trajectories of which the\ncorresponding context reflects the specification of tasks? To this end, we\npropose a novel Meta-RL framework called CCM (Contrastive learning augmented\nContext-based Meta-RL). We first focus on the contrastive nature behind\ndifferent tasks and leverage it to train a compact and sufficient context\nencoder. Further, we train a separate exploration policy and theoretically\nderive a new information-gain-based objective which aims to collect informative\ntrajectories in a few steps. Empirically, we evaluate our approaches on common\nbenchmarks as well as several complex sparse-reward environments. The\nexperimental results show that CCM outperforms state-of-the-art algorithms by\naddressing previously mentioned problems respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:29:18 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:10:03 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 08:48:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Chen", "Chen", ""], ["Feng", "Xidong", ""], ["Li", "Dong", ""], ["Liu", "Wulong", ""]]}, {"id": "2009.13895", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "Ben Day, C\\u{a}t\\u{a}lina Cangea, Arian R. Jamasb, Pietro Li\\`o", "title": "Message Passing Neural Processes", "comments": "18 pages, 6 figures. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Processes (NPs) are powerful and flexible models able to incorporate\nuncertainty when representing stochastic processes, while maintaining a linear\ntime complexity. However, NPs produce a latent description by aggregating\nindependent representations of context points and lack the ability to exploit\nrelational information present in many datasets. This renders NPs ineffective\nin settings where the stochastic process is primarily governed by neighbourhood\nrules, such as cellular automata (CA), and limits performance for any task\nwhere relational information remains unused. We address this shortcoming by\nintroducing Message Passing Neural Processes (MPNPs), the first class of NPs\nthat explicitly makes use of relational structure within the model. Our\nevaluation shows that MPNPs thrive at lower sampling rates, on existing\nbenchmarks and newly-proposed CA and Cora-Branched tasks. We further report\nstrong generalisation over density-based CA rule-sets and significant gains in\nchallenging arbitrary-labelling and few-shot learning setups.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:40:09 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Day", "Ben", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Jamasb", "Arian R.", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2009.13929", "submitter": "Shahabodin Khadivizand", "authors": "Shahabodin Khadivi Zand", "title": "Towards Intelligent Risk-based Customer Segmentation in Banking", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business Processes, i.e., a set of coordinated tasks and activities to\nachieve a business goal, and their continuous improvements are key to the\noperation of any organization. In banking, business processes are increasingly\ndynamic as various technologies have made dynamic processes more prevalent. For\nexample, customer segmentation, i.e., the process of grouping related customers\nbased on common activities and behaviors, could be a data-driven and\nknowledge-intensive process. In this paper, we present an intelligent\ndata-driven pipeline composed of a set of processing elements to move\ncustomers' data from one system to another, transforming the data into the\ncontextualized data and knowledge along the way. The goal is to present a novel\nintelligent customer segmentation process which automates the feature\nengineering, i.e., the process of using (banking) domain knowledge to extract\nfeatures from raw data via data mining techniques, in the banking domain. We\nadopt a typical scenario for analyzing customer transaction records, to\nhighlight how the presented approach can significantly improve the quality of\nrisk-based customer segmentation in the absence of feature engineering.As\nresult, our proposed method is able to achieve accuracy of 91% compared to\nclassical approaches in terms of detecting, identifying and classifying\ntransaction to the right classification.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:22:04 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zand", "Shahabodin Khadivi", ""]]}, {"id": "2009.13935", "submitter": "Gencer Sumbul", "authors": "Hichame Yessou, Gencer Sumbul, Beg\\\"um Demir", "title": "A Comparative Study of Deep Learning Loss Functions for Multi-Label\n  Remote Sensing Image Classification", "comments": "Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2020. For code visit:\n  https://gitlab.tubit.tu-berlin.de/rsim/RS-MLC-Losses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes and compares different deep learning loss functions in\nthe framework of multi-label remote sensing (RS) image scene classification\nproblems. We consider seven loss functions: 1) cross-entropy loss; 2) focal\nloss; 3) weighted cross-entropy loss; 4) Hamming loss; 5) Huber loss; 6)\nranking loss; and 7) sparseMax loss. All the considered loss functions are\nanalyzed for the first time in RS. After a theoretical analysis, an\nexperimental analysis is carried out to compare the considered loss functions\nin terms of their: 1) overall accuracy; 2) class imbalance awareness (for which\nthe number of samples associated to each class significantly varies); 3)\nconvexibility and differentiability; and 4) learning efficiency (i.e.,\nconvergence speed). On the basis of our analysis, some guidelines are derived\nfor a proper selection of a loss function in multi-label RS scene\nclassification problems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:35:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Yessou", "Hichame", ""], ["Sumbul", "Gencer", ""], ["Demir", "Beg\u00fcm", ""]]}, {"id": "2009.13939", "submitter": "Diogo Pernes", "authors": "Diogo Pernes and Jaime S. Cardoso", "title": "Tackling unsupervised multi-source domain adaptation with optimism and\n  consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been known for a while that the problem of multi-source domain\nadaptation can be regarded as a single source domain adaptation task where the\nsource domain corresponds to a mixture of the original source domains.\nNonetheless, how to adjust the mixture distribution weights remains an open\nquestion. Moreover, most existing work on this topic focuses only on minimizing\nthe error on the source domains and achieving domain-invariant representations,\nwhich is insufficient to ensure low error on the target domain. In this work,\nwe present a novel framework that addresses both problems and beats the current\nstate of the art by using a mildly optimistic objective function and\nconsistency regularization on the target samples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:55:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Pernes", "Diogo", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "2009.13940", "submitter": "Cristian Cioflan", "authors": "Cristian Cioflan, Radu Timofte", "title": "MS-RANAS: Multi-Scale Resource-Aware Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has proved effective in offering\noutperforming alternatives to handcrafted neural networks. In this paper we\nanalyse the benefits of NAS for image classification tasks under strict\ncomputational constraints. Our aim is to automate the design of highly\nefficient deep neural networks, capable of offering fast and accurate\npredictions and that could be deployed on a low-memory, low-power\nsystem-on-chip. The task thus becomes a three-party trade-off between accuracy,\ncomputational complexity, and memory requirements. To address this concern, we\npropose Multi-Scale Resource-Aware Neural Architecture Search (MS-RANAS). We\nemploy a one-shot architecture search approach in order to obtain a reduced\nsearch cost and we focus on an anytime prediction setting. Through the usage of\nmultiple-scaled features and early classifiers, we achieved state-of-the-art\nresults in terms of accuracy-speed trade-off.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:56:01 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Cioflan", "Cristian", ""], ["Timofte", "Radu", ""]]}, {"id": "2009.13946", "submitter": "Harshdeep Singh", "authors": "Harshdeep Singh, Nicholas McCarthy, Qurrat Ul Ain, Jeremiah Hayes", "title": "ChemoVerse: Manifold traversal of latent spaces for novel molecule\n  discovery", "comments": "5 pages, 2 figures, Presented in First workshop on Applied Deep\n  Generative Networks - ECAI 2020 (\"link for the workshop:\n  https://sites.google.com/view/adgn-20/home\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to design a more potent and effective chemical entity, it is\nessential to identify molecular structures with the desired chemical\nproperties. Recent advances in generative models using neural networks and\nmachine learning are being widely used by many emerging startups and\nresearchers in this domain to design virtual libraries of drug-like compounds.\nAlthough these models can help a scientist to produce novel molecular\nstructures rapidly, the challenge still exists in the intelligent exploration\nof the latent spaces of generative models, thereby reducing the randomness in\nthe generative procedure. In this work we present a manifold traversal with\nheuristic search to explore the latent chemical space. Different heuristics and\nscores such as the Tanimoto coefficient, synthetic accessibility, binding\nactivity, and QED drug-likeness can be incorporated to increase the validity\nand proximity for desired molecular properties of the generated molecules. For\nevaluating the manifold traversal exploration, we produce the latent chemical\nspace using various generative models such as grammar variational autoencoders\n(with and without attention) as they deal with the randomized generation and\nvalidity of compounds. With this novel traversal method, we are able to find\nmore unseen compounds and more specific regions to mine in the latent space.\nFinally, these components are brought together in a simple platform allowing\nusers to perform search, visualization and selection of novel generated\ncompounds.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:11:40 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Singh", "Harshdeep", ""], ["McCarthy", "Nicholas", ""], ["Ain", "Qurrat Ul", ""], ["Hayes", "Jeremiah", ""]]}, {"id": "2009.13961", "submitter": "Claudio Flores", "authors": "Claudio Cardoso Flores and Marcelo Cunha Medeiros", "title": "Online Action Learning in High Dimensions: A New Exploration Rule for\n  Contextual $\\epsilon_t$-Greedy Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit problems are pervasive in various fields of research and are also\npresent in several practical applications. Examples, including dynamic pricing\nand assortment and the design of auctions and incentives, permeate a large\nnumber of sequential treatment experiments. Different applications impose\ndistinct levels of restrictions on viable actions. Some favor diversity of\noutcomes, while others require harmful actions to be closely monitored or\nmainly avoided. In this paper, we extend one of the most popular bandit\nsolutions, the original $\\epsilon_t$-greedy heuristics, to high-dimensional\ncontexts. Moreover, we introduce a competing exploration mechanism that counts\nwith searching sets based on order statistics. We view our proposals as\nalternatives for cases where pluralism is valued or, in the opposite direction,\ncases where the end-user should carefully tune the range of exploration of new\nactions. We find reasonable bounds for the cumulative regret of a decaying\n$\\epsilon_t$-greedy heuristic in both cases and we provide an upper bound for\nthe initialization phase that implies the regret bounds when order statistics\nare considered to be at most equal but mostly better than the case when random\nsearching is the sole exploration mechanism. Additionally, we show that\nend-users have sufficient flexibility to avoid harmful actions since any\ncardinality for the higher-order statistics can be used to achieve an stricter\nupper bound. We illustrate the algorithms proposed in this paper both with\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:25:05 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 03:15:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Flores", "Claudio Cardoso", ""], ["Medeiros", "Marcelo Cunha", ""]]}, {"id": "2009.13962", "submitter": "Diane Bouchacourt", "authors": "Christina Heinze-Deml and Diane Bouchacourt", "title": "Think before you act: A simple baseline for compositional generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrarily to humans who have the ability to recombine familiar expressions\nto create novel ones, modern neural networks struggle to do so. This has been\nemphasized recently with the introduction of the benchmark dataset \"gSCAN\"\n(Ruis et al. 2020), aiming to evaluate models' performance at compositional\ngeneralization in grounded language understanding. In this work, we challenge\nthe gSCAN benchmark by proposing a simple model that achieves surprisingly good\nperformance on two of the gSCAN test splits. Our model is based on the\nobservation that, to succeed on gSCAN tasks, the agent must (i) identify the\ntarget object (think) before (ii) navigating to it successfully (act).\nConcretely, we propose an attention-inspired modification of the baseline model\nfrom (Ruis et al. 2020), together with an auxiliary loss, that takes into\naccount the sequential nature of steps (i) and (ii). While two compositional\ntasks are trivially solved with our approach, we also find that the other tasks\nremain unsolved, validating the relevance of gSCAN as a benchmark for\nevaluating models' compositional abilities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:27:12 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 07:11:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["Bouchacourt", "Diane", ""]]}, {"id": "2009.13975", "submitter": "Alessandro Brusaferri Eng.", "authors": "Alessandro Brusaferri and Matteo Matteucci and Stefano Spinelli", "title": "Identification of Probability weighted ARX models with arbitrary domains", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hybrid system identification is a key tool to achieve reliable models of\nCyber-Physical Systems from data. PieceWise Affine models guarantees universal\napproximation, local linearity and equivalence to other classes of hybrid\nsystem. Still, PWA identification is a challenging problem, requiring the\nconcurrent solution of regression and classification tasks. In this work, we\nfocus on the identification of PieceWise Auto Regressive with eXogenous input\nmodels with arbitrary regions (NPWARX), thus not restricted to polyhedral\ndomains, and characterized by discontinuous maps. To this end, we propose a\nmethod based on a probabilistic mixture model, where the discrete state is\nrepresented through a multinomial distribution conditioned by the input\nregressors. The architecture is conceived following the Mixture of Expert\nconcept, developed within the machine learning field. To achieve nonlinear\npartitioning, we parametrize the discriminant function using a neural network.\nThen, the parameters of both the ARX submodels and the classifier are\nconcurrently estimated by maximizing the likelihood of the overall model using\nExpectation Maximization. The proposed method is demonstrated on a nonlinear\npiece-wise problem with discontinuous maps.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:50:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Brusaferri", "Alessandro", ""], ["Matteucci", "Matteo", ""], ["Spinelli", "Stefano", ""]]}, {"id": "2009.13977", "submitter": "Alexander Mathiasen Mr", "authors": "Alexander Mathiasen, Frederik Hvilsh{\\o}j, Jakob R{\\o}dsgaard\n  J{\\o}rgensen, Anshul Nasery, Davide Mottin", "title": "What if Neural Networks had SVDs?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various Neural Networks employ time-consuming matrix operations like matrix\ninversion. Many such matrix operations are faster to compute given the Singular\nValue Decomposition (SVD). Previous work allows using the SVD in Neural\nNetworks without computing it. In theory, the techniques can speed up matrix\noperations, however, in practice, they are not fast enough. We present an\nalgorithm that is fast enough to speed up several matrix operations. The\nalgorithm increases the degree of parallelism of an underlying matrix\nmultiplication $H\\cdot X$ where $H$ is an orthogonal matrix represented by a\nproduct of Householder matrices. Code is available at\nwww.github.com/AlexanderMath/fasth .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:58:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mathiasen", "Alexander", ""], ["Hvilsh\u00f8j", "Frederik", ""], ["J\u00f8rgensen", "Jakob R\u00f8dsgaard", ""], ["Nasery", "Anshul", ""], ["Mottin", "Davide", ""]]}, {"id": "2009.13982", "submitter": "Xinyue Liang", "authors": "Xinyue Liang, Alireza M. Javid, Mikael Skoglund, Saikat Chatterjee", "title": "A Low Complexity Decentralized Neural Net with Centralized Equivalence\n  using Layer-wise Learning", "comments": "Accepted to The International Joint Conference on Neural Networks\n  (IJCNN) 2020, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a low complexity decentralized learning algorithm to train a\nrecently proposed large neural network in distributed processing nodes\n(workers). We assume the communication network between the workers is\nsynchronized and can be modeled as a doubly-stochastic mixing matrix without\nhaving any master node. In our setup, the training data is distributed among\nthe workers but is not shared in the training process due to privacy and\nsecurity concerns. Using alternating-direction-method-of-multipliers (ADMM)\nalong with a layerwise convex optimization approach, we propose a decentralized\nlearning algorithm which enjoys low computational complexity and communication\ncost among the workers. We show that it is possible to achieve equivalent\nlearning performance as if the data is available in a single place. Finally, we\nexperimentally illustrate the time complexity and convergence behavior of the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:08:12 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Liang", "Xinyue", ""], ["Javid", "Alireza M.", ""], ["Skoglund", "Mikael", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2009.13984", "submitter": "Raymond Lee", "authors": "Nuobei Shi, Qin Zeng and Raymond Lee", "title": "The design and implementation of Language Learning Chatbot with XAI\n  using Ontology and Transfer Learning", "comments": "19 pages, 20 figures, published paper in International Conference on\n  NLP & Big Data (NLPD 2020)", "journal-ref": "Dhinaharan Nagamalai et al. (Eds): CSEIT, WiMoNe, NCS, CIoT, CMLA,\n  DMSE, NLPD - 2020 pp. 305-323, 2020. CS & IT - CSCP 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a transfer learning-based English language\nlearning chatbot, whose output generated by GPT-2 can be explained by\ncorresponding ontology graph rooted by fine-tuning dataset. We design three\nlevels for systematically English learning, including phonetics level for\nspeech recognition and pronunciation correction, semantic level for specific\ndomain conversation, and the simulation of free-style conversation in English -\nthe highest level of language chatbot communication as free-style conversation\nagent. For academic contribution, we implement the ontology graph to explain\nthe performance of free-style conversation, following the concept of XAI\n(Explainable Artificial Intelligence) to visualize the connections of neural\nnetwork in bionics, and explain the output sentence from language model. From\nimplementation perspective, our Language Learning agent integrated the\nmini-program in WeChat as front-end, and fine-tuned GPT-2 model of transfer\nlearning as back-end to interpret the responses by ontology graph.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:11:40 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shi", "Nuobei", ""], ["Zeng", "Qin", ""], ["Lee", "Raymond", ""]]}, {"id": "2009.13987", "submitter": "Lukas Ruff", "authors": "Michael Joswig, Marek Kaluba, Lukas Ruff", "title": "Geometric Disentanglement by Random Convex Polytopes", "comments": "23 pages, preprint; extended experiments and theoretical analysis of\n  RPD in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.MG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new geometric method for measuring the quality of\nrepresentations obtained from deep learning. Our approach, called Random\nPolytope Descriptor, provides an efficient description of data points based on\nthe construction of random convex polytopes. We demonstrate the use of our\ntechnique by qualitatively comparing the behavior of classic and regularized\nautoencoders. This reveals that applying regularization to autoencoder networks\nmay decrease the out-of-distribution detection performance in latent space.\nWhile our technique is similar in spirit to $k$-means clustering, we achieve\nsignificantly better false positive/negative balance in clustering tasks on\nautoencoded datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:16:26 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 07:39:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Joswig", "Michael", ""], ["Kaluba", "Marek", ""], ["Ruff", "Lukas", ""]]}, {"id": "2009.13988", "submitter": "\\\"Ozgecan \\\"Ozdogan", "authors": "\\\"Ozgecan \\\"Ozdogan, Emil Bj\\\"ornson", "title": "Deep Learning-based Phase Reconfiguration for Intelligent Reflecting\n  Surfaces", "comments": "5 pages, 4 figures. To be presented at Asilomar Conference on\n  Signals, Systems, and Computers 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflecting surfaces (IRSs), consisting of reconfigurable\nmetamaterials, have recently attracted attention as a promising cost-effective\ntechnology that can bring new features to wireless communications. These\nsurfaces can be used to partially control the propagation environment and can\npotentially provide a power gain that is proportional to the square of the\nnumber of IRS elements when configured in a proper way. However, the\nconfiguration of the local phase matrix at the IRSs can be quite a challenging\ntask since they are purposely designed to not have any active components,\ntherefore, they are not able to process any pilot signal. In addition, a large\nnumber of elements at the IRS may create a huge training overhead. In this\npaper, we present a deep learning (DL) approach for phase reconfiguration at an\nIRS in order to learn and make use of the local propagation environment. The\nproposed method uses the received pilot signals reflected through the IRS to\ntrain the deep feedforward network. The performance of the proposed approach is\nevaluated and the numerical results are presented.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:18:24 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["\u00d6zdogan", "\u00d6zgecan", ""], ["Bj\u00f6rnson", "Emil", ""]]}, {"id": "2009.13998", "submitter": "Christopher Harshaw", "authors": "Moran Feldman, Christopher Harshaw, Amin Karbasi", "title": "How Do You Want Your Greedy: Simultaneous or Repeated?", "comments": "Included analysis of RepeatedGreedy and open source Julia package", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SimultaneousGreedys, a deterministic algorithm for constrained\nsubmodular maximization. At a high level, the algorithm maintains $\\ell$\nsolutions and greedily updates them in a simultaneous fashion.\nSimultaneousGreedys achieves the tightest known approximation guarantees for\nboth $k$-extendible systems and the more general $k$-systems, which are\n$(k+1)^2/k = k + \\mathcal{O}(1)$ and $(1 + \\sqrt{k+2})^2 = k +\n\\mathcal{O}(\\sqrt{k})$, respectively. This is in contrast to previous\nalgorithms, which are designed to provide tight approximation guarantees in one\nsetting, but not both. We also improve the analysis of RepeatedGreedy, showing\nthat it achieves an approximation ratio of $k + \\mathcal{O}(\\sqrt{k})$ for\n$k$-systems when allowed to run for $\\mathcal{O}(\\sqrt{k})$ iterations, an\nimprovement in both the runtime and approximation over previous analyses. We\ndemonstrate that both algorithms may be modified to run in nearly linear time\nwith an arbitrarily small loss in the approximation.\n  Both SimultaneousGreedys and RepeatedGreedy are flexible enough to\nincorporate the intersection of $m$ additional knapsack constraints, while\nretaining similar approximation guarantees: both algorithms yield an\napproximation guarantee of roughly $k + 2m + \\mathcal{O}(\\sqrt{k+m})$ for\n$k$-systems and SimultaneousGreedys enjoys an improved approximation guarantee\nof $k+2m + \\mathcal{O}(\\sqrt{m})$ for $k$-extendible systems. To complement our\nalgorithmic contributions, we provide a hardness result which states that no\nalgorithm making polynomially many oracle queries can achieve an approximation\nbetter than $k + 1/2 + \\varepsilon$. We also present SubmodularGreedy.jl, a\nJulia package which implements these algorithms and may be downloaded at\nhttps://github.com/crharshaw/SubmodularGreedy.jl . Finally, we test the\neffectiveness of these algorithms on real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:34:09 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 18:02:50 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Feldman", "Moran", ""], ["Harshaw", "Christopher", ""], ["Karbasi", "Amin", ""]]}, {"id": "2009.14001", "submitter": "Antoine Pirovano", "authors": "Antoine Pirovano and Hippolyte Heuberger and Sylvain Berlemont and\n  Sa\\\"id Ladjal and Isabelle Bloch", "title": "Improving Interpretability for Computer-aided Diagnosis tools on Whole\n  Slide Imaging with Multiple Instance Learning and Gradient-based Explanations", "comments": "8 pages (references excluded), 3 figures, presented in iMIMIC\n  Workshop at MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are widely used for medical applications to assist\nmedical doctors in their daily routines. While performances reach expert's\nlevel, interpretability (highlight how and what a trained model learned and why\nit makes a specific decision) is the next important challenge that deep\nlearning methods need to answer to be fully integrated in the medical field. In\nthis paper, we address the question of interpretability in the context of whole\nslide images (WSI) classification. We formalize the design of WSI\nclassification architectures and propose a piece-wise interpretability\napproach, relying on gradient-based methods, feature visualization and multiple\ninstance learning context. We aim at explaining how the decision is made based\non tile level scoring, how these tile scores are decided and which features are\nused and relevant for the task. After training two WSI classification\narchitectures on Camelyon-16 WSI dataset, highlighting discriminative features\nlearned, and validating our approach with pathologists, we propose a novel\nmanner of computing interpretability slide-level heat-maps, based on the\nextracted features, that improves tile-level classification performances by\nmore than 29% for AUC.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:39:27 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Pirovano", "Antoine", ""], ["Heuberger", "Hippolyte", ""], ["Berlemont", "Sylvain", ""], ["Ladjal", "Sa\u00efd", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2009.14024", "submitter": "Pierre-Luc Delisle", "authors": "Pierre-Luc Delisle, Benoit Anctil-Robitaille, Christian Desrosiers and\n  Herve Lombaert", "title": "Realistic Image Normalization for Multi-Domain Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image normalization is a building block in medical image analysis.\nConventional approaches are customarily utilized on a per-dataset basis. This\nstrategy, however, prevents the current normalization algorithms from fully\nexploiting the complex joint information available across multiple datasets.\nConsequently, ignoring such joint information has a direct impact on the\nperformance of segmentation algorithms. This paper proposes to revisit the\nconventional image normalization approach by instead learning a common\nnormalizing function across multiple datasets. Jointly normalizing multiple\ndatasets is shown to yield consistent normalized images as well as an improved\nimage segmentation. To do so, a fully automated adversarial and task-driven\nnormalization approach is employed as it facilitates the training of realistic\nand interpretable images while keeping performance on-par with the\nstate-of-the-art. The adversarial training of our network aims at finding the\noptimal transfer function to improve both the segmentation accuracy and the\ngeneration of realistic images. We evaluated the performance of our normalizer\non both infant and adult brains images from the iSEG, MRBrainS and ABIDE\ndatasets. Results reveal the potential of our normalization approach for\nsegmentation, with Dice improvements of up to 57.5% over our baseline. Our\nmethod can also enhance data availability by increasing the number of samples\navailable when learning from multiple imaging domains.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:57:04 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 14:24:44 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 19:15:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Delisle", "Pierre-Luc", ""], ["Anctil-Robitaille", "Benoit", ""], ["Desrosiers", "Christian", ""], ["Lombaert", "Herve", ""]]}, {"id": "2009.14025", "submitter": "Sungchul Choi", "authors": "Hyeonju Lee, Jongho Lee, Minji An, Gunil Park, Sungchul Choi", "title": "Machine-Learning Approach to Analyze the Status of Forklift Vehicles\n  with Irregular Movement in a Shipyard", "comments": "I withdraw this paper because an error in the experiment has been\n  found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large shipyards, the management of equipment, which are used for building\na variety of ships, is critical. Because orders vary year to year, shipyard\nmanagers are required to determine methods to make the most of their limited\nresources. A particular difficulty that arises because of the nature and size\nof shipyards is the management of moving vehicles. In recent years,\nshipbuilding companies have attempted to manage and track the locations and\nmovements of vehicles using Global Positioning System (GPS) modules. However,\nbecause certain vehicles, such as forklifts, roam irregularly around a yard,\nidentifying their working status without being onsite is difficult. Location\ninformation alone is not sufficient to determine whether a vehicle is working,\nmoving, waiting, or resting. This study proposes an approach based on machine\nlearning to identify the work status of each forklift. We use the DBSCAN and\nk-means algorithms to identify the area in which a particular forklift is\noperating and the type of work it is performing. We developed a business\nintelligence system to collect information from forklifts equipped with GPS and\nInternet of Things (IoT) devices. The system provides visual information on the\nstatus of individual forklifts and helps in the efficient management of their\nmovements within large shipyards.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:58:24 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 04:20:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Lee", "Hyeonju", ""], ["Lee", "Jongho", ""], ["An", "Minji", ""], ["Park", "Gunil", ""], ["Choi", "Sungchul", ""]]}, {"id": "2009.14045", "submitter": "Resul Tugay", "authors": "Bekir Berker T\\\"urker, Resul Tugay, \\c{S}ule \\\"O\\u{g}\\\"ud\\\"uc\\\"u,\n  \\.Ipek K{\\i}z{\\i}l", "title": "Hotel Recommendation System Based on User Profiles and Collaborative\n  Filtering", "comments": "in Turkish language, UBMK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, people start to use online reservation systems to plan their\nvacations since they have vast amount of choices available. Selecting when and\nwhere to go from this large-scale options is getting harder. In addition,\nsometimes consumers can miss the better options due to the wealth of\ninformation to be found on the online reservation systems. In this sense,\npersonalized services such as recommender systems play a crucial role in\ndecision making. Two traditional recommendation techniques are content-based\nand collaborative filtering. While both methods have their advantages, they\nalso have certain disadvantages, some of which can be solved by combining both\ntechniques to improve the quality of the recommendation. The resulting system\nis known as a hybrid recommender system. This paper presents a new hybrid hotel\nrecommendation system that has been developed by combining content-based and\ncollaborative filtering approaches that recommends customer the hotel they need\nand save them from time loss.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:57:54 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["T\u00fcrker", "Bekir Berker", ""], ["Tugay", "Resul", ""], ["\u00d6\u011f\u00fcd\u00fcc\u00fc", "\u015eule", ""], ["K\u0131z\u0131l", "\u0130pek", ""]]}, {"id": "2009.14050", "submitter": "Thomas Griffiths", "authors": "Thomas L. Griffiths", "title": "Understanding Human Intelligence through Human Limitations", "comments": "In press at Trends in Cognitive Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence provides the opportunity to ask\nthe question of what is unique about human intelligence, but with a new\ncomparison class. I argue that we can understand human intelligence, and the\nways in which it may differ from artificial intelligence, by considering the\ncharacteristics of the kind of computational problems that human minds have to\nsolve. I claim that these problems acquire their structure from three\nfundamental limitations that apply to human beings: limited time, limited\ncomputation, and limited communication. From these limitations we can derive\nmany of the properties we associate with human intelligence, such as rapid\nlearning, the ability to break down problems into parts, and the capacity for\ncumulative cultural evolution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 14:37:12 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Griffiths", "Thomas L.", ""]]}, {"id": "2009.14061", "submitter": "Shonosuke Harada", "authors": "Shonosuke Harada and Hisashi Kashima", "title": "GraphITE: Estimating Individual Effects of Graph-structured Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outcome estimation of treatments for target individuals is an important\nfoundation for decision making based on causal relations. Most existing outcome\nestimation methods deal with binary or multiple-choice treatments; however, in\nsome applications, the number of treatments can be significantly large, while\nthe treatments themselves have rich information. In this study, we considered\none important instance of such cases: the outcome estimation problem of\ngraph-structured treatments such as drugs. Owing to the large number of\npossible treatments, the counterfactual nature of observational data that\nappears in conventional treatment effect estimation becomes more of a concern\nfor this problem. Our proposed method, GraphITE (pronounced \"graphite\") learns\nthe representations of graph-structured treatments using graph neural networks\nwhile mitigating observation biases using Hilbert-Schmidt Independence\nCriterion regularization, which increases the independence of the\nrepresentations of the targets and treatments. Experiments on two real-world\ndatasets show that GraphITE outperforms baselines, especially in cases with a\nlarge number of treatments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 14:49:30 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 03:28:00 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Harada", "Shonosuke", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2009.14068", "submitter": "Felix Meister", "authors": "Felix Meister, Tiziano Passerini, Chlo\\'e Audigier, \\`Eric Lluch,\n  Viorel Mihalef, Hiroshi Ashikaga, Andreas Maier, Henry Halperin, Tommaso\n  Mansi", "title": "Graph convolutional regression of cardiac depolarization from sparse\n  endocardial maps", "comments": "Accepted at the MICCAI 2020 Workshop Statistical Atlases and\n  Computational Modeling of the Heart (STACOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroanatomic mapping as routinely acquired in ablation therapy of\nventricular tachycardia is the gold standard method to identify the\narrhythmogenic substrate. To reduce the acquisition time and still provide maps\nwith high spatial resolution, we propose a novel deep learning method based on\ngraph convolutional neural networks to estimate the depolarization time in the\nmyocardium, given sparse catheter data on the left ventricular endocardium,\nECG, and magnetic resonance images. The training set consists of data produced\nby a computational model of cardiac electrophysiology on a large cohort of\nsynthetically generated geometries of ischemic hearts. The predicted\ndepolarization pattern has good agreement with activation times computed by the\ncardiac electrophysiology model in a validation set of five swine heart\ngeometries with complex scar and border zone morphologies. The mean absolute\nerror hereby measures 8 ms on the entire myocardium when providing 50\\% of the\nendocardial ground truth in over 500 computed depolarization patterns.\nFurthermore, when considering a complete animal data set with high density\nelectroanatomic mapping data as reference, the neural network can accurately\nreproduce the endocardial depolarization pattern, even when a small percentage\nof measurements are provided as input features (mean absolute error of 7 ms\nwith 50\\% of input samples). The results show that the proposed method, trained\non synthetically generated data, may generalize to real data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:21:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Meister", "Felix", ""], ["Passerini", "Tiziano", ""], ["Audigier", "Chlo\u00e9", ""], ["Lluch", "\u00c8ric", ""], ["Mihalef", "Viorel", ""], ["Ashikaga", "Hiroshi", ""], ["Maier", "Andreas", ""], ["Halperin", "Henry", ""], ["Mansi", "Tommaso", ""]]}, {"id": "2009.14073", "submitter": "Alessandro Brusaferri Eng.", "authors": "Alessandro Brusaferri and Matteo Matteucci and Stefano Spinelli", "title": "Estimation of Switched Markov Polynomial NARX models", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work targets the identification of a class of models for hybrid\ndynamical systems characterized by nonlinear autoregressive exogenous (NARX)\ncomponents, with finite-dimensional polynomial expansions, and by a Markovian\nswitching mechanism. The estimation of the model parameters is performed under\na probabilistic framework via Expectation Maximization, including submodel\ncoefficients, hidden state values and transition probabilities. Discrete mode\nclassification and NARX regression tasks are disentangled within the\niterations. Soft-labels are assigned to latent states on the trajectories by\naveraging over the state posteriors and updated using the parametrization\nobtained from the previous maximization phase. Then, NARXs parameters are\nrepeatedly fitted by solving weighted regression subproblems through a cyclical\ncoordinate descent approach with coordinate-wise minimization. Moreover, we\ninvestigate a two stage selection scheme, based on a l1-norm bridge estimation\nfollowed by hard-thresholding, to achieve parsimonious models through selection\nof the polynomial expansion. The proposed approach is demonstrated on a SMNARX\nproblem composed by three nonlinear sub-models with specific regressors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:00:47 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Brusaferri", "Alessandro", ""], ["Matteucci", "Matteo", ""], ["Spinelli", "Stefano", ""]]}, {"id": "2009.14075", "submitter": "Alexander Mathiasen Mr", "authors": "Alexander Mathiasen, Frederik Hvilsh{\\o}j", "title": "Backpropagating through Fr\\'echet Inception Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fr\\'echet Inception Distance (FID) has been used to evaluate hundreds of\ngenerative models. We introduce FastFID, which can efficiently train generative\nmodels with FID as a loss function. Using FID as an additional loss for\nGenerative Adversarial Networks improves their FID.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:04:40 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 16:01:12 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Mathiasen", "Alexander", ""], ["Hvilsh\u00f8j", "Frederik", ""]]}, {"id": "2009.14096", "submitter": "Min Qian", "authors": "Min Qian and Yan-Fu Li", "title": "Weakly Supervised-Based Oversampling for High Imbalance and High\n  Dimensionality Data Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of industrial datasets, imbalanced classification has\nbecome a common problem in several application domains. Oversampling is an\neffective method to solve imbalanced classification. One of the main challenges\nof the existing oversampling methods is to accurately label the new synthetic\nsamples. Inaccurate labels of the synthetic samples would distort the\ndistribution of the dataset and possibly worsen the classification performance.\nThis paper introduces the idea of weakly supervised learning to handle the\ninaccurate labeling of synthetic samples caused by traditional oversampling\nmethods. Graph semi-supervised SMOTE is developed to improve the credibility of\nthe synthetic samples' labels. In addition, we propose cost-sensitive\nneighborhood components analysis for high dimensional datasets and bootstrap\nbased ensemble framework for highly imbalanced datasets. The proposed method\nhas achieved good classification performance on 8 synthetic datasets and 3\nreal-world datasets, especially for high imbalance and high dimensionality\nproblems. The average performances and robustness are better than the benchmark\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:26:34 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:54:49 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Qian", "Min", ""], ["Li", "Yan-Fu", ""]]}, {"id": "2009.14108", "submitter": "Markus Hofmarcher", "authors": "Vihang P. Patil, Markus Hofmarcher, Marius-Constantin Dinu, Matthias\n  Dorfer, Patrick M. Blies, Johannes Brandstetter, Jose A. Arjona-Medina, Sepp\n  Hochreiter", "title": "Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning algorithms require a large number of samples to solve\ncomplex tasks with sparse and delayed rewards. Complex tasks can often be\nhierarchically decomposed into sub-tasks. A step in the Q-function can be\nassociated with solving a sub-task, where the expectation of the return\nincreases. RUDDER has been introduced to identify these steps and then\nredistribute reward to them, thus immediately giving reward if sub-tasks are\nsolved. Since the problem of delayed rewards is mitigated, learning is\nconsiderably sped up. However, for complex tasks, current exploration\nstrategies as deployed in RUDDER struggle with discovering episodes with high\nrewards. Therefore, we assume that episodes with high rewards are given as\ndemonstrations and do not have to be discovered by exploration. Typically the\nnumber of demonstrations is small and RUDDER's LSTM model as a deep learning\nmethod does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER\nwith two major modifications. First, Align-RUDDER assumes that episodes with\nhigh rewards are given as demonstrations, replacing RUDDER's safe exploration\nand lessons replay buffer. Second, we replace RUDDER's LSTM model by a profile\nmodel that is obtained from multiple sequence alignment of demonstrations.\nProfile models can be constructed from as few as two demonstrations as known\nfrom bioinformatics. Align-RUDDER inherits the concept of reward\nredistribution, which considerably reduces the delay of rewards, thus speeding\nup learning. Align-RUDDER outperforms competitors on complex artificial tasks\nwith delayed reward and few demonstrations. On the MineCraft ObtainDiamond\ntask, Align-RUDDER is able to mine a diamond, though not frequently. Github:\nhttps://github.com/ml-jku/align-rudder, YouTube: https://youtu.be/HO-_8ZUl-UY\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:48:02 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Patil", "Vihang P.", ""], ["Hofmarcher", "Markus", ""], ["Dinu", "Marius-Constantin", ""], ["Dorfer", "Matthias", ""], ["Blies", "Patrick M.", ""], ["Brandstetter", "Johannes", ""], ["Arjona-Medina", "Jose A.", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2009.14111", "submitter": "Jaehoon Koo", "authors": "Jaehoon Koo, Diego Klabjan, Jean Utke", "title": "Inverse Classification with Limited Budget and Maximum Number of\n  Perturbed Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent machine learning research focuses on developing new classifiers\nfor the sake of improving classification accuracy. With many well-performing\nstate-of-the-art classifiers available, there is a growing need for\nunderstanding interpretability of a classifier necessitated by practical\npurposes such as to find the best diet recommendation for a diabetes patient.\nInverse classification is a post modeling process to find changes in input\nfeatures of samples to alter the initially predicted class. It is useful in\nmany business applications to determine how to adjust a sample input data such\nthat the classifier predicts it to be in a desired class. In real world\napplications, a budget on perturbations of samples corresponding to customers\nor patients is usually considered, and in this setting, the number of\nsuccessfully perturbed samples is key to increase benefits. In this study, we\npropose a new framework to solve inverse classification that maximizes the\nnumber of perturbed samples subject to a per-feature-budget limits and\nfavorable classification classes of the perturbed samples. We design algorithms\nto solve this optimization problem based on gradient methods, stochastic\nprocesses, Lagrangian relaxations, and the Gumbel trick. In experiments, we\nfind that our algorithms based on stochastic processes exhibit an excellent\nperformance in different budget settings and they scale well.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:52:10 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Koo", "Jaehoon", ""], ["Klabjan", "Diego", ""], ["Utke", "Jean", ""]]}, {"id": "2009.14114", "submitter": "Cyrille W. Combettes", "authors": "Cyrille W. Combettes and Christoph Spiegel and Sebastian Pokutta", "title": "Projection-Free Adaptive Gradients for Large-Scale Optimization", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity in large-scale optimization can lie in both handling the\nobjective function and handling the constraint set. In this respect, stochastic\nFrank-Wolfe algorithms occupy a unique position as they alleviate both\ncomputational burdens, by querying only approximate first-order information\nfrom the objective and by maintaining feasibility of the iterates without using\nprojections. In this paper, we improve the quality of their first-order\ninformation by blending in adaptive gradients. We derive convergence rates and\ndemonstrate the computational advantage of our method over the state-of-the-art\nstochastic Frank-Wolfe algorithms on both convex and nonconvex objectives. The\nexperiments further show that our method can improve the performance of\nadaptive gradient algorithms for constrained optimization.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:56:12 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 16:10:26 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 14:38:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Combettes", "Cyrille W.", ""], ["Spiegel", "Christoph", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2009.14119", "submitter": "Tal Ridnik", "authors": "Emanuel Ben-Baruch, Tal Ridnik, Nadav Zamir, Asaf Noy, Itamar\n  Friedman, Matan Protter, Lihi Zelnik-Manor", "title": "Asymmetric Loss For Multi-Label Classification", "comments": "Accepted to ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a typical multi-label setting, a picture contains on average few positive\nlabels, and many negative ones. This positive-negative imbalance dominates the\noptimization process, and can lead to under-emphasizing gradients from positive\nlabels during training, resulting in poor accuracy. In this paper, we introduce\na novel asymmetric loss (\"ASL\"), which operates differently on positive and\nnegative samples. The loss enables to dynamically down-weights and\nhard-thresholds easy negative samples, while also discarding possibly\nmislabeled samples. We demonstrate how ASL can balance the probabilities of\ndifferent samples, and how this balancing is translated to better mAP scores.\nWith ASL, we reach state-of-the-art results on multiple popular multi-label\ndatasets: MS-COCO, Pascal-VOC, NUS-WIDE and Open Images. We also demonstrate\nASL applicability for other tasks, such as single-label classification and\nobject detection. ASL is effective, easy to implement, and does not increase\nthe training time or complexity.\n  Implementation is available at: https://github.com/Alibaba-MIIL/ASL.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:08:19 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 14:50:30 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 06:54:56 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 15:02:43 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ben-Baruch", "Emanuel", ""], ["Ridnik", "Tal", ""], ["Zamir", "Nadav", ""], ["Noy", "Asaf", ""], ["Friedman", "Itamar", ""], ["Protter", "Matan", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "2009.14133", "submitter": "David Calhas", "authors": "David Calhas, Rui Henriques", "title": "EEG to fMRI Synthesis: Is Deep Learning a candidate?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances on signal, image and video generation underly major breakthroughs on\ngenerative medical imaging tasks, including Brain Image Synthesis. Still, the\nextent to which functional Magnetic Ressonance Imaging (fMRI) can be mapped\nfrom the brain electrophysiology remains largely unexplored. This work provides\nthe first comprehensive view on how to use state-of-the-art principles from\nNeural Processing to synthesize fMRI data from electroencephalographic (EEG)\ndata. Given the distinct spatiotemporal nature of haemodynamic and\nelectrophysiological signals, this problem is formulated as the task of\nlearning a mapping function between multivariate time series with highly\ndissimilar structures. A comparison of state-of-the-art synthesis approaches,\nincluding Autoencoders, Generative Adversarial Networks and Pairwise Learning,\nis undertaken. Results highlight the feasibility of EEG to fMRI brain image\nmappings, pinpointing the role of current advances in Machine Learning and\nshowing the relevance of upcoming contributions to further improve performance.\nEEG to fMRI synthesis offers a way to enhance and augment brain image data, and\nguarantee access to more affordable, portable and long-lasting protocols of\nbrain activity monitoring. The code used in this manuscript is available in\nGithub and the datasets are open source.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:29:20 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Calhas", "David", ""], ["Henriques", "Rui", ""]]}, {"id": "2009.14136", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay", "title": "Time your hedge with Deep Reinforcement Learning", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an asset manager plan the optimal timing for her/his hedging strategies\ngiven market conditions? The standard approach based on Markowitz or other more\nor less sophisticated financial rules aims to find the best portfolio\nallocation thanks to forecasted expected returns and risk but fails to fully\nrelate market conditions to hedging strategies decision. In contrast, Deep\nReinforcement Learning (DRL) can tackle this challenge by creating a dynamic\ndependency between market information and hedging strategies allocation\ndecisions. In this paper, we present a realistic and augmented DRL framework\nthat: (i) uses additional contextual information to decide an action, (ii) has\na one period lag between observations and actions to account for one day lag\nturnover of common asset managers to rebalance their hedge, (iii) is fully\ntested in terms of stability and robustness thanks to a repetitive train test\nmethod called anchored walk forward training, similar in spirit to k fold cross\nvalidation for time series and (iv) allows managing leverage of our hedging\nstrategy. Our experiment for an augmented asset manager interested in sizing\nand timing his hedges shows that our approach achieves superior returns and\nlower risk.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:43:41 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:56:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ungari", "Sandrine", ""], ["Mukhopadhyay", "Abhishek", ""]]}, {"id": "2009.14138", "submitter": "Qimin Liu", "authors": "Qimin Liu and Fang Liu", "title": "Selective Cascade of Residual ExtraTrees", "comments": "To appear in SN Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel tree-based ensemble method named Selective Cascade of\nResidual ExtraTrees (SCORE). SCORE draws inspiration from representation\nlearning, incorporates regularized regression with variable selection features,\nand utilizes boosting to improve prediction and reduce generalization errors.\nWe also develop a variable importance measure to increase the explainability of\nSCORE. Our computer experiments show that SCORE provides comparable or superior\nperformance in prediction against ExtraTrees, random forest, gradient boosting\nmachine, and neural networks; and the proposed variable importance measure for\nSCORE is comparable to studied benchmark methods. Finally, the predictive\nperformance of SCORE remains stable across hyper-parameter values, suggesting\npotential robustness to hyperparameter specification.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:31:37 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Liu", "Qimin", ""], ["Liu", "Fang", ""]]}, {"id": "2009.14146", "submitter": "Jessie James Suarez", "authors": "Jessie James P. Suarez, Prospero C. Naval Jr", "title": "A Survey on Deep Learning Techniques for Video Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in videos is a problem that has been studied for more than\na decade. This area has piqued the interest of researchers due to its wide\napplicability. Because of this, there has been a wide array of approaches that\nhave been proposed throughout the years and these approaches range from\nstatistical-based approaches to machine learning-based approaches. Numerous\nsurveys have already been conducted on this area but this paper focuses on\nproviding an overview on the recent advances in the field of anomaly detection\nusing Deep Learning. Deep Learning has been applied successfully in many fields\nof artificial intelligence such as computer vision, natural language processing\nand more. This survey, however, focuses on how Deep Learning has improved and\nprovided more insights to the area of video anomaly detection. This paper\nprovides a categorization of the different Deep Learning approaches with\nrespect to their objectives. Additionally, it also discusses the commonly used\ndatasets along with the common evaluation metrics. Afterwards, a discussion\nsynthesizing all of the recent approaches is made to provide direction and\npossible areas for future research.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:40:46 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Suarez", "Jessie James P.", ""], ["Naval", "Prospero C.", "Jr"]]}, {"id": "2009.14148", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh, Mattia Rigotti", "title": "Unbalanced Sobolev Descent", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Unbalanced Sobolev Descent (USD), a particle descent algorithm\nfor transporting a high dimensional source distribution to a target\ndistribution that does not necessarily have the same mass. We define the\nSobolev-Fisher discrepancy between distributions and show that it relates to\nadvection-reaction transport equations and the Wasserstein-Fisher-Rao metric\nbetween distributions. USD transports particles along gradient flows of the\nwitness function of the Sobolev-Fisher discrepancy (advection step) and\nreweighs the mass of particles with respect to this witness function (reaction\nstep). The reaction step can be thought of as a birth-death process of the\nparticles with rate of growth proportional to the witness function. When the\nSobolev-Fisher witness function is estimated in a Reproducing Kernel Hilbert\nSpace (RKHS), under mild assumptions we show that USD converges asymptotically\n(in the limit of infinite particles) to the target distribution in the Maximum\nMean Discrepancy (MMD) sense. We then give two methods to estimate the\nSobolev-Fisher witness with neural networks, resulting in two Neural USD\nalgorithms. The first one implements the reaction step with mirror descent on\nthe weights, while the second implements it through a birth-death process of\nparticles. We show on synthetic examples that USD transports distributions with\nor without conservation of mass faster than previous particle descent\nalgorithms, and finally demonstrate its use for molecular biology analyses\nwhere our method is naturally suited to match developmental stages of\npopulations of differentiating cells based on their single-cell RNA sequencing\nprofile. Code is available at https://github.com/ibm/usd .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:43:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mroueh", "Youssef", ""], ["Rigotti", "Mattia", ""]]}, {"id": "2009.14167", "submitter": "Zhe Gan", "authors": "Siqi Sun, Zhe Gan, Yu Cheng, Yuwei Fang, Shuohang Wang, Jingjing Liu", "title": "Contrastive Distillation on Intermediate Representations for Language\n  Model Compression", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing language model compression methods mostly use a simple L2 loss to\ndistill knowledge in the intermediate representations of a large BERT model to\na smaller one. Although widely used, this objective by design assumes that all\nthe dimensions of hidden representations are independent, failing to capture\nimportant structural knowledge in the intermediate layers of the teacher\nnetwork. To achieve better distillation efficacy, we propose Contrastive\nDistillation on Intermediate Representations (CoDIR), a principled knowledge\ndistillation framework where the student is trained to distill knowledge\nthrough intermediate layers of the teacher via a contrastive objective. By\nlearning to distinguish positive sample from a large set of negative samples,\nCoDIR facilitates the student's exploitation of rich information in teacher's\nhidden layers. CoDIR can be readily applied to compress large-scale language\nmodels in both pre-training and finetuning stages, and achieves superb\nperformance on the GLUE benchmark, outperforming state-of-the-art compression\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:31:43 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sun", "Siqi", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Fang", "Yuwei", ""], ["Wang", "Shuohang", ""], ["Liu", "Jingjing", ""]]}, {"id": "2009.14168", "submitter": "Charu Sharma", "authors": "Charu Sharma, Manohar Kaul", "title": "Self-Supervised Few-Shot Learning on Point Clouds", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability of massive point clouds coupled with their utility\nin a wide variety of applications such as robotics, shape synthesis, and\nself-driving cars has attracted increased attention from both industry and\nacademia. Recently, deep neural networks operating on labeled point clouds have\nshown promising results on supervised learning tasks like classification and\nsegmentation. However, supervised learning leads to the cumbersome task of\nannotating the point clouds. To combat this problem, we propose two novel\nself-supervised pre-training tasks that encode a hierarchical partitioning of\nthe point clouds using a cover-tree, where point cloud subsets lie within balls\nof varying radii at each level of the cover-tree. Furthermore, our\nself-supervised learning network is restricted to pre-train on the support set\n(comprising of scarce training examples) used to train the downstream network\nin a few-shot learning (FSL) setting. Finally, the fully-trained\nself-supervised network's point embeddings are input to the downstream task's\nnetwork. We present a comprehensive empirical evaluation of our method on both\ndownstream classification and segmentation tasks and show that supervised\nmethods pre-trained with our self-supervised learning method significantly\nimprove the accuracy of state-of-the-art methods. Additionally, our method also\noutperforms previous unsupervised methods in downstream classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:32:44 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sharma", "Charu", ""], ["Kaul", "Manohar", ""]]}, {"id": "2009.14194", "submitter": "Emmanuel Dufourq Dr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "Deep Evolution for Facial Emotion Recognition", "comments": "Conference of the South African Institute of Computer Scientists and\n  Information Technologists 2020", "journal-ref": null, "doi": "10.1145/3410886.3410892", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep facial expression recognition faces two challenges that both stem from\nthe large number of trainable parameters: long training times and a lack of\ninterpretability. We propose a novel method based on evolutionary algorithms,\nthat deals with both challenges by massively reducing the number of trainable\nparameters, whilst simultaneously retaining classification performance, and in\nsome cases achieving superior performance. We are robustly able to reduce the\nnumber of parameters on average by 95% (e.g. from 2M to 100k parameters) with\nno loss in classification accuracy. The algorithm learns to choose small\npatches from the image, relative to the nose, which carry the most important\ninformation about emotion, and which coincide with typical human choices of\nimportant features. Our work implements a novel form attention and shows that\nevolutionary algorithms are a valuable addition to machine learning in the deep\nlearning era, both for reducing the number of parameters for facial expression\nrecognition and for providing interpretable features that can help reduce bias.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:58:09 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:21:18 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "2009.14244", "submitter": "Benyamin Ghojogh", "authors": "Parisa Abdolrahim Poorheravi, Benyamin Ghojogh, Vincent Gaudet, Fakhri\n  Karray, Mark Crowley", "title": "Acceleration of Large Margin Metric Learning for Nearest Neighbor\n  Classification Using Triplet Mining and Stratified Sampling", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning is one of the techniques in manifold learning with the goal\nof finding a projection subspace for increasing and decreasing the inter- and\nintra-class variances, respectively. Some of the metric learning methods are\nbased on triplet learning with anchor-positive-negative triplets. Large margin\nmetric learning for nearest neighbor classification is one of the fundamental\nmethods to do this. Recently, Siamese networks have been introduced with the\ntriplet loss. Many triplet mining methods have been developed for Siamese\nnetworks; however, these techniques have not been applied on the triplets of\nlarge margin metric learning for nearest neighbor classification. In this work,\ninspired by the mining methods for Siamese networks, we propose several triplet\nmining techniques for large margin metric learning. Moreover, a hierarchical\napproach is proposed, for acceleration and scalability of optimization, where\ntriplets are selected by stratified sampling in hierarchical hyper-spheres. We\nanalyze the proposed methods on three publicly available datasets, i.e., Fisher\nIris, ORL faces, and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:24:34 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Poorheravi", "Parisa Abdolrahim", ""], ["Ghojogh", "Benyamin", ""], ["Gaudet", "Vincent", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2009.14248", "submitter": "Seongmin Lee", "authors": "Seongmin Lee, Hyunsik Jeon and U Kang", "title": "Ensemble Multi-Source Domain Adaptation with Pseudolabels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given multiple source datasets with labels, how can we train a target model\nwith no labeled data? Multi-source domain adaptation (MSDA) aims to train a\nmodel using multiple source datasets different from a target dataset in the\nabsence of target data labels. MSDA is a crucial problem applicable to many\npractical cases where labels for the target data are unavailable due to privacy\nissues. Existing MSDA frameworks are limited since they align data without\nconsidering conditional distributions p(x|y) of each domain. They also miss a\nlot of target label information by not considering the target label at all and\nrelying on only one feature extractor. In this paper, we propose Ensemble\nMulti-source Domain Adaptation with Pseudolabels (EnMDAP), a novel method for\nmulti-source domain adaptation. EnMDAP exploits label-wise moment matching to\nalign conditional distributions p(x|y), using pseudolabels for the unavailable\ntarget labels, and introduces ensemble learning theme by using multiple feature\nextractors for accurate domain adaptation. Extensive experiments show that\nEnMDAP provides the state-of-the-art performance for multi-source domain\nadaptation tasks in both of image domains and text domains.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:29:49 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lee", "Seongmin", ""], ["Jeon", "Hyunsik", ""], ["Kang", "U", ""]]}, {"id": "2009.14250", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Qiang Wu", "title": "A Framework of Learning Through Empirical Gain Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop in this paper a framework of empirical gain maximization (EGM) to\naddress the robust regression problem where heavy-tailed noise or outliers may\npresent in the response variable. The idea of EGM is to approximate the density\nfunction of the noise distribution instead of approximating the truth function\ndirectly as usual. Unlike the classical maximum likelihood estimation that\nencourages equal importance of all observations and could be problematic in the\npresence of abnormal observations, EGM schemes can be interpreted from a\nminimum distance estimation viewpoint and allow the ignorance of those\nobservations. Furthermore, it is shown that several well-known robust nonconvex\nregression paradigms, such as Tukey regression and truncated least square\nregression, can be reformulated into this new framework. We then develop a\nlearning theory for EGM, by means of which a unified analysis can be conducted\nfor these well-established but not fully-understood regression approaches.\nResulting from the new framework, a novel interpretation of existing bounded\nnonconvex loss functions can be concluded. Within this new framework, the two\nseemingly irrelevant terminologies, the well-known Tukey's biweight loss for\nrobust regression and the triweight kernel for nonparametric smoothing, are\nclosely related. More precisely, it is shown that the Tukey's biweight loss can\nbe derived from the triweight kernel. Similarly, other frequently employed\nbounded nonconvex loss functions in machine learning such as the truncated\nsquare loss, the Geman-McClure loss, and the exponential squared loss can also\nbe reformulated from certain smoothing kernels in statistics. In addition, the\nnew framework enables us to devise new bounded nonconvex loss functions for\nrobust learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:36:26 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 03:07:01 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Feng", "Yunlong", ""], ["Wu", "Qiang", ""]]}, {"id": "2009.14257", "submitter": "Huaqing Xiong", "authors": "Huaqing Xiong, Lin Zhao, Yingbin Liang, Wei Zhang", "title": "Finite-Time Analysis for Double Q-learning", "comments": "Accepted to NeurIPS 2020. The camera-ready version will include\n  additional updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Q-learning is one of the most successful algorithms for finding the\nbest action-value function (and thus the optimal policy) in reinforcement\nlearning, its implementation often suffers from large overestimation of\nQ-function values incurred by random sampling. The double Q-learning algorithm\nproposed in~\\citet{hasselt2010double} overcomes such an overestimation issue by\nrandomly switching the update between two Q-estimators, and has thus gained\nsignificant popularity in practice. However, the theoretical understanding of\ndouble Q-learning is rather limited. So far only the asymptotic convergence has\nbeen established, which does not characterize how fast the algorithm converges.\nIn this paper, we provide the first non-asymptotic (i.e., finite-time) analysis\nfor double Q-learning. We show that both synchronous and asynchronous double\nQ-learning are guaranteed to converge to an $\\epsilon$-accurate neighborhood of\nthe global optimum by taking $\\tilde{\\Omega}\\left(\\left(\n\\frac{1}{(1-\\gamma)^6\\epsilon^2}\\right)^{\\frac{1}{\\omega}}\n+\\left(\\frac{1}{1-\\gamma}\\right)^{\\frac{1}{1-\\omega}}\\right)$ iterations, where\n$\\omega\\in(0,1)$ is the decay parameter of the learning rate, and $\\gamma$ is\nthe discount factor. Our analysis develops novel techniques to derive\nfinite-time bounds on the difference between two inter-connected stochastic\nprocesses, which is new to the literature of stochastic approximation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:48:21 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 14:13:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xiong", "Huaqing", ""], ["Zhao", "Lin", ""], ["Liang", "Yingbin", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.14260", "submitter": "Freddy Lecue", "authors": "Nicholas Halliwell, Freddy Lecue", "title": "Trustworthy Convolutional Neural Networks: A Gradient Penalized-based\n  Approach", "comments": "13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are commonly used for image\nclassification. Saliency methods are examples of approaches that can be used to\ninterpret CNNs post hoc, identifying the most relevant pixels for a prediction\nfollowing the gradients flow. Even though CNNs can correctly classify images,\nthe underlying saliency maps could be erroneous in many cases. This can result\nin skepticism as to the validity of the model or its interpretation. We propose\na novel approach for training trustworthy CNNs by penalizing parameter choices\nthat result in inaccurate saliency maps generated during training. We add a\npenalty term for inaccurate saliency maps produced when the predicted label is\ncorrect, a penalty term for accurate saliency maps produced when the predicted\nlabel is incorrect, and a regularization term penalizing overly confident\nsaliency maps. Experiments show increased classification performance, user\nengagement, and trust.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:56:40 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Halliwell", "Nicholas", ""], ["Lecue", "Freddy", ""]]}, {"id": "2009.14262", "submitter": "Jiaqi Wang", "authors": "Chacha Chen, Chieh-Yang Huang, Yaqi Hou, Yang Shi, Enyan Dai, Jiaqi\n  Wang", "title": "TEST_POSITIVE at W-NUT 2020 Shared Task-3: Joint Event Multi-task\n  Learning for Slot Filling in Noisy Text", "comments": "6 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competition of extracting COVID-19 events from Twitter is to develop\nsystems that can automatically extract related events from tweets. The built\nsystem should identify different pre-defined slots for each event, in order to\nanswer important questions (e.g., Who is tested positive? What is the age of\nthe person? Where is he/she?). To tackle these challenges, we propose the Joint\nEvent Multi-task Learning (JOELIN) model. Through a unified global learning\nframework, we make use of all the training data across different events to\nlearn and fine-tune the language model. Moreover, we implement a type-aware\npost-processing procedure using named entity recognition (NER) to further\nfilter the predictions. JOELIN outperforms the BERT baseline by 17.2% in micro\nF1.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 19:08:45 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chen", "Chacha", ""], ["Huang", "Chieh-Yang", ""], ["Hou", "Yaqi", ""], ["Shi", "Yang", ""], ["Dai", "Enyan", ""], ["Wang", "Jiaqi", ""]]}, {"id": "2009.14280", "submitter": "Yusheng Jiao", "authors": "Yusheng Jiao, Feng Ling, Sina Heydari, Nicolas Heess, Josh Merel and\n  Eva Kanso", "title": "Learning to swim in potential flow", "comments": null, "journal-ref": "Phys. Rev. Fluids 6, 050505 (2021)", "doi": "10.1103/PhysRevFluids.6.050505", "report-no": null, "categories": "q-bio.QM cs.LG physics.flu-dyn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fish swim by undulating their bodies. These propulsive motions require\ncoordinated shape changes of a body that interacts with its fluid environment,\nbut the specific shape coordination that leads to robust turning and swimming\nmotions remains unclear. To address the problem of underwater motion planning,\nwe propose a simple model of a three-link fish swimming in a potential flow\nenvironment and we use model-free reinforcement learning for shape control. We\narrive at optimal shape changes for two swimming tasks: swimming in a desired\ndirection and swimming towards a known target. This fish model belongs to a\nclass of problems in geometric mechanics, known as driftless dynamical systems,\nwhich allow us to analyze the swimming behavior in terms of geometric phases\nover the shape space of the fish. These geometric methods are less intuitive in\nthe presence of drift. Here, we use the shape space analysis as a tool for\nassessing, visualizing, and interpreting the control policies obtained via\nreinforcement learning in the absence of drift. We then examine the robustness\nof these policies to drift-related perturbations. Although the fish has no\ndirect control over the drift itself, it learns to take advantage of the\npresence of moderate drift to reach its target.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 06:31:27 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 23:59:01 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Jiao", "Yusheng", ""], ["Ling", "Feng", ""], ["Heydari", "Sina", ""], ["Heess", "Nicolas", ""], ["Merel", "Josh", ""], ["Kanso", "Eva", ""]]}, {"id": "2009.14308", "submitter": "Nan Ding", "authors": "Nan Ding, Xinjie Fan, Zhenzhong Lan, Dale Schuurmans, Radu Soricut", "title": "Attention that does not Explain Away", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models based on the Transformer architecture have achieved better accuracy\nthan the ones based on competing architectures for a large set of tasks. A\nunique feature of the Transformer is its universal application of a\nself-attention mechanism, which allows for free information flow at arbitrary\ndistances. Following a probabilistic view of the attention via the Gaussian\nmixture model, we find empirical evidence that the Transformer attention tends\nto \"explain away\" certain input neurons. To compensate for this, we propose a\ndoubly-normalized attention scheme that is simple to implement and provides\ntheoretical guarantees for avoiding the \"explaining away\" effect without\nintroducing significant computational or memory cost. Empirically, we show that\nthe new attention schemes result in improved performance on several well-known\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:05:39 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ding", "Nan", ""], ["Fan", "Xinjie", ""], ["Lan", "Zhenzhong", ""], ["Schuurmans", "Dale", ""], ["Soricut", "Radu", ""]]}, {"id": "2009.14310", "submitter": "J\\'er\\^ome-Alexis Chevalier", "authors": "J\\'er\\^ome-Alexis Chevalier, Alexandre Gramfort, Joseph Salmon,\n  Bertrand Thirion", "title": "Statistical control for spatio-temporal MEG/EEG source imaging with\n  desparsified multi-task Lasso", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting where and when brain regions activate in a cognitive task or in a\ngiven clinical condition is the promise of non-invasive techniques like\nmagnetoencephalography (MEG) or electroencephalography (EEG). This problem,\nreferred to as source localization, or source imaging, poses however a\nhigh-dimensional statistical inference challenge. While sparsity promoting\nregularizations have been proposed to address the regression problem, it\nremains unclear how to ensure statistical control of false detections.\nMoreover, M/EEG source imaging requires to work with spatio-temporal data and\nautocorrelated noise. To deal with this, we adapt the desparsified Lasso\nestimator -- an estimator tailored for high dimensional linear model that\nasymptotically follows a Gaussian distribution under sparsity and moderate\nfeature correlation assumptions -- to temporal data corrupted with\nautocorrelated noise. We call it the desparsified multi-task Lasso (d-MTLasso).\nWe combine d-MTLasso with spatially constrained clustering to reduce data\ndimension and with ensembling to mitigate the arbitrary choice of clustering;\nthe resulting estimator is called ensemble of clustered desparsified multi-task\nLasso (ecd-MTLasso). With respect to the current procedures, the two advantages\nof ecd-MTLasso are that i)it offers statistical guarantees and ii)it allows to\ntrade spatial specificity for sensitivity, leading to a powerful adaptive\nmethod. Extensive simulations on realistic head geometries, as well as\nempirical results on various MEG datasets, demonstrate the high recovery\nperformance of ecd-MTLasso and its primary practical benefit: offer a\nstatistically principled way to threshold MEG/EEG source maps.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:17:16 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:49:36 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chevalier", "J\u00e9r\u00f4me-Alexis", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""], ["Thirion", "Bertrand", ""]]}, {"id": "2009.14311", "submitter": "Dong Quan Nguyen", "authors": "Dong Quan Ngoc Nguyen, Lin Xing, and Lizhen Lin", "title": "Weight Prediction for Variants of Weighted Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weighted directed network (WDN) is a directed graph in which each edge is\nassociated to a unique value called weight. These networks are very suitable\nfor modeling real-world social networks in which there is an assessment of one\nvertex toward other vertices. One of the main problems studied in this paper is\nprediction of edge weights in such networks. We introduce, for the first time,\na metric geometry approach to studying edge weight prediction in WDNs. We\nmodify a usual notion of WDNs, and introduce a new type of WDNs which we coin\nthe term \\textit{almost-weighted directed networks} (AWDNs). AWDNs can capture\nthe weight information of a network from a given training set. We then\nconstruct a class of metrics (or distances) for AWDNs which equips such\nnetworks with a metric space structure. Using the metric geometry structure of\nAWDNs, we propose modified $k$ nearest neighbors (kNN) methods and modified\nsupport-vector machine (SVM) methods which will then be used to predict edge\nweights in AWDNs. In many real-world datasets, in addition to edge weights, one\ncan also associate weights to vertices which capture information of vertices;\nassociation of weights to vertices especially plays an important role in graph\nembedding problems. Adopting a similar approach, we introduce two new types of\ndirected networks in which weights are associated to either a subset of origin\nvertices or a subset of terminal vertices . We, for the first time, construct\nnovel classes of metrics on such networks, and based on these new metrics\npropose modified $k$NN and SVM methods for predicting weights of origins and\nterminals in these networks. We provide experimental results on several\nreal-world datasets, using our geometric methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:18:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Nguyen", "Dong Quan Ngoc", ""], ["Xing", "Lin", ""], ["Lin", "Lizhen", ""]]}, {"id": "2009.14326", "submitter": "B Debnath", "authors": "B Debnath, M O'brien, S Kumar, A Behera", "title": "Attention-Driven Body Pose Encoding for Human Activity Recognition", "comments": "This paper has been accepted for publication at the IAPR\n  IEEE/Computer Society International Conference on Pattern Recognition (ICPR),\n  Milan, 2021", "journal-ref": "IAPR IEEE/Computer Society International Conference on Pattern\n  Recognition (ICPR), Milan, 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a novel attention-based body pose encoding for human\nactivity recognition that presents a enriched representation of body-pose that\nis learned. The enriched data complements the 3D body joint position data and\nimproves model performance. In this paper, we propose a novel approach that\nlearns enhanced feature representations from a given sequence of 3D body\njoints. To achieve this encoding, the approach exploits 1) a spatial stream\nwhich encodes the spatial relationship between various body joints at each time\npoint to learn spatial structure involving the spatial distribution of\ndifferent body joints 2) a temporal stream that learns the temporal variation\nof individual body joints over the entire sequence duration to present a\ntemporally enhanced representation. Afterwards, these two pose streams are\nfused with a multi-head attention mechanism. % adapted from neural machine\ntranslation. We also capture the contextual information from the RGB video\nstream using a Inception-ResNet-V2 model combined with a multi-head attention\nand a bidirectional Long Short-Term Memory (LSTM) network. %Moreover, we whose\nperformance is enhanced through the multi-head attention mechanism. Finally,\nthe RGB video stream is combined with the fused body pose stream to give a\nnovel end-to-end deep model for effective human activity recognition.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:17:17 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 17:53:46 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Debnath", "B", ""], ["O'brien", "M", ""], ["Kumar", "S", ""], ["Behera", "A", ""]]}, {"id": "2009.14332", "submitter": "Guangtao Wang", "authors": "Guangtao Wang, Rex Ying, Jing Huang, Jure Leskovec", "title": "Multi-hop Attention based Graph Neural Network", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention mechanism in graph neural networks (GNNs) led to\nstate-of-the-art performance on many graph representation learning tasks.\nCurrently, at every layer, attention is computed between connected pairs of\nnodes and depends solely on the representation of the two nodes. However, such\nattention mechanism does not account for nodes that are not directly connected\nbut provide important network context. Here we propose Multi-hop Attention\nGraph Neural Network (MAGNA), a principled way to incorporate multi-hop context\ninformation into every layer of attention computation. MAGNA diffuses the\nattention scores across the network, which increases the receptive field for\nevery layer of the GNN. Unlike previous approaches, MAGNA uses a diffusion\nprior on attention values, to efficiently account for all paths between the\npair of disconnected nodes. We demonstrate in theory and experiments that MAGNA\ncaptures large-scale structural information in every layer, and has a low-pass\neffect that eliminates noisy high-frequency information from graph data.\nExperimental results on node classification as well as the knowledge graph\ncompletion benchmarks show that MAGNA achieves state-of-the-art results: MAGNA\nachieves up to 5.7 percent relative error reduction over the previous\nstate-of-the-art on Cora, Citeseer, and Pubmed. MAGNA also obtains the best\nperformance on a large-scale Open Graph Benchmark dataset. On knowledge graph\ncompletion MAGNA advances state-of-the-art on WN18RR and FB15k-237 across four\ndifferent performance metrics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:41:19 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 00:45:07 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 04:51:02 GMT"}, {"version": "v4", "created": "Sat, 15 May 2021 18:31:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Guangtao", ""], ["Ying", "Rex", ""], ["Huang", "Jing", ""], ["Leskovec", "Jure", ""]]}, {"id": "2009.14337", "submitter": "Guangmo Tong", "authors": "Guangmo Tong", "title": "StratLearner: Learning a Strategy for Misinformation Prevention in\n  Social Networks", "comments": "NeurIPS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a combinatorial optimization problem taking an input, can we learn a\nstrategy to solve it from the examples of input-solution pairs without knowing\nits objective function? In this paper, we consider such a setting and study the\nmisinformation prevention problem. Given the examples of attacker-protector\npairs, our goal is to learn a strategy to compute protectors against future\nattackers, without the need of knowing the underlying diffusion model. To this\nend, we design a structured prediction framework, where the main idea is to\nparameterize the scoring function using random features constructed through\ndistance functions on randomly sampled subgraphs, which leads to a kernelized\nscoring function with weights learnable via the large margin method. Evidenced\nby experiments, our method can produce near-optimal protectors without using\nany information of the diffusion model, and it outperforms other possible\ngraph-based and learning-based methods by an evident margin.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:58:33 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Tong", "Guangmo", ""]]}, {"id": "2009.14343", "submitter": "Abhishek Sharma", "authors": "Abhishek Sharma and Maks Ovsjanikov", "title": "Geometric Matrix Completion: A Functional View", "comments": "Accepted at GRL workshop, ICML'20. Code:\n  \\url{https://github.com/Not-IITian/functional-matrix-completion}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a totally functional view of geometric matrix completion problem.\nDifferently from existing work, we propose a novel regularization inspired from\nthe functional map literature that is more interpretable and theoretically\nsound. On synthetic tasks with strong underlying geometric structure, our\nframework outperforms state of the art by a huge margin (two order of\nmagnitude) demonstrating the potential of our approach. On real datasets, we\nachieve state-of-the-art results at a fraction of the computational effort of\nprevious methods. Our code is publicly available at\nhttps://github.com/Not-IITian/functional-matrix-completion\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 23:23:04 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sharma", "Abhishek", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2009.14373", "submitter": "Chien-Hsun Lai", "authors": "Chien-Hsun Lai, Yu-Shuen Wang", "title": "Facilitate the Parametric Dimension Reduction by Gradient Clipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend a well-known dimension reduction method, t-distributed stochastic\nneighbor embedding (t-SNE), from non-parametric to parametric by training\nneural networks. The main advantage of a parametric technique is the\ngeneralization of handling new data, which is particularly beneficial for\nstreaming data exploration. However, training a neural network to optimize the\nt-SNE objective function frequently fails. Previous methods overcome this\nproblem by pre-training and then fine-tuning the network. We found that the\ntraining failure comes from the gradient exploding problem, which occurs when\ndata points distant in high-dimensional space are projected to nearby embedding\npositions. Accordingly, we applied the gradient clipping method to solve the\nproblem. Since the networks are trained by directly optimizing the t-SNE\nobjective function, our method achieves an embedding quality that is compatible\nwith the non-parametric t-SNE while enjoying the ability of generalization. Due\nto mini-batch network training, our parametric dimension reduction method is\nhighly efficient. We further extended other non-parametric state-of-the-art\napproaches, such as LargeVis and UMAP, to the parametric versions. Experiment\nresults demonstrate the feasibility of our method. Considering its\npracticability, we will soon release the codes for public use.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:21:22 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lai", "Chien-Hsun", ""], ["Wang", "Yu-Shuen", ""]]}, {"id": "2009.14379", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Atsutoshi Kumagai", "title": "Few-shot Learning for Time-series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is important for many applications. Forecasting\nmodels are usually trained using time-series data in a specific target task.\nHowever, sufficient data in the target task might be unavailable, which leads\nto performance degradation. In this paper, we propose a few-shot learning\nmethod that forecasts a future value of a time-series in a target task given a\nfew time-series in the target task. Our model is trained using time-series data\nin multiple training tasks that are different from target tasks. Our model uses\na few time-series to build a forecasting function based on a recurrent neural\nnetwork with an attention mechanism. With the attention mechanism, we can\nretrieve useful patterns in a small number of time-series for the current\nsituation. Our model is trained by minimizing an expected test error of\nforecasting next timestep values. We demonstrate the effectiveness of the\nproposed method using 90 time-series datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:32:22 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Kumagai", "Atsutoshi", ""]]}, {"id": "2009.14385", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mahmoud Famouri, and Mohammad Javad Shafiee", "title": "AttendNets: Tiny Deep Image Recognition Neural Networks for the Edge via\n  Visual Attention Condensers", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While significant advances in deep learning has resulted in state-of-the-art\nperformance across a large number of complex visual perception tasks, the\nwidespread deployment of deep neural networks for TinyML applications involving\non-device, low-power image recognition remains a big challenge given the\ncomplexity of deep neural networks. In this study, we introduce AttendNets,\nlow-precision, highly compact deep neural networks tailored for on-device image\nrecognition. More specifically, AttendNets possess deep self-attention\narchitectures based on visual attention condensers, which extends on the\nrecently introduced stand-alone attention condensers to improve spatial-channel\nselective attention. Furthermore, AttendNets have unique machine-designed\nmacroarchitecture and microarchitecture designs achieved via a machine-driven\ndesign exploration strategy. Experimental results on ImageNet$_{50}$ benchmark\ndataset for the task of on-device image recognition showed that AttendNets have\nsignificantly lower architectural and computational complexity when compared to\nseveral deep neural networks in research literature designed for efficiency\nwhile achieving highest accuracies (with the smallest AttendNet achieving\n$\\sim$7.2% higher accuracy, while requiring $\\sim$3$\\times$ fewer multiply-add\noperations, $\\sim$4.17$\\times$ fewer parameters, and $\\sim$16.7$\\times$ lower\nweight memory requirements than MobileNet-V1). Based on these promising\nresults, AttendNets illustrate the effectiveness of visual attention condensers\nas building blocks for enabling various on-device visual perception tasks for\nTinyML applications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:53:17 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wong", "Alexander", ""], ["Famouri", "Mahmoud", ""], ["Shafiee", "Mohammad Javad", ""]]}, {"id": "2009.14386", "submitter": "Hong-Kwang Jeff Kuo", "authors": "Hong-Kwang J. Kuo, Zolt\\'an T\\\"uske, Samuel Thomas, Yinghui Huang,\n  Kartik Audhkhasi, Brian Kingsbury, Gakuto Kurata, Zvi Kons, Ron Hoory, and\n  Luis Lastras", "title": "End-to-End Spoken Language Understanding Without Full Transcripts", "comments": "5 pages, to be published in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential component of spoken language understanding (SLU) is slot\nfilling: representing the meaning of a spoken utterance using semantic entity\nlabels. In this paper, we develop end-to-end (E2E) spoken language\nunderstanding systems that directly convert speech input to semantic entities\nand investigate if these E2E SLU models can be trained solely on semantic\nentity annotations without word-for-word transcripts. Training such models is\nvery useful as they can drastically reduce the cost of data collection. We\ncreated two types of such speech-to-entities models, a CTC model and an\nattention-based encoder-decoder model, by adapting models trained originally\nfor speech recognition. Given that our experiments involve speech input, these\nsystems need to recognize both the entity label and words representing the\nentity value correctly. For our speech-to-entities experiments on the ATIS\ncorpus, both the CTC and attention models showed impressive ability to skip\nnon-entity words: there was little degradation when trained on just entities\nversus full transcripts. We also explored the scenario where the entities are\nin an order not necessarily related to spoken order in the utterance. With its\nability to do re-ordering, the attention model did remarkably well, achieving\nonly about 2% degradation in speech-to-bag-of-entities F1 score.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:54:13 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kuo", "Hong-Kwang J.", ""], ["T\u00fcske", "Zolt\u00e1n", ""], ["Thomas", "Samuel", ""], ["Huang", "Yinghui", ""], ["Audhkhasi", "Kartik", ""], ["Kingsbury", "Brian", ""], ["Kurata", "Gakuto", ""], ["Kons", "Zvi", ""], ["Hoory", "Ron", ""], ["Lastras", "Luis", ""]]}, {"id": "2009.14389", "submitter": "Liang Du", "authors": "Liang Du, Haiying Zhang, Xin Ren, Xiaolin Lv", "title": "Manifold Adaptive Multiple Kernel K-Means for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple kernel methods based on k-means aims to integrate a group of kernels\nto improve the performance of kernel k-means clustering. However, we observe\nthat most existing multiple kernel k-means methods exploit the nonlinear\nrelationship within kernels, whereas the local manifold structure among\nmultiple kernel space is not sufficiently considered. In this paper, we adopt\nthe manifold adaptive kernel, instead of the original kernel, to integrate the\nlocal manifold structure of kernels. Thus, the induced multiple manifold\nadaptive kernels not only reflect the nonlinear relationship but also the local\nmanifold structure. We then perform multiple kernel clustering within the\nmultiple kernel k-means clustering framework. It has been verified that the\nproposed method outperforms several state-of-the-art baseline methods on a\nvariety of data sets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:07:53 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Du", "Liang", ""], ["Zhang", "Haiying", ""], ["Ren", "Xin", ""], ["Lv", "Xiaolin", ""]]}, {"id": "2009.14393", "submitter": "Braden Kronheim", "authors": "Braden Kronheim, Michelle Kuchera, and Harrison Prosper", "title": "TensorBNN: Bayesian Inference for Neural Networks using Tensorflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TensorBNN is a new package based on TensorFlow that implements Bayesian\ninference for modern neural network models. The posterior density of neural\nnetwork model parameters is represented as a point cloud sampled using\nHamiltonian Monte Carlo. The TensorBNN package leverages TensorFlow's\narchitecture and training features as well as its ability to use modern\ngraphics processing units (GPU) in both the training and prediction stages.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:20:53 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 20:51:14 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Kronheim", "Braden", ""], ["Kuchera", "Michelle", ""], ["Prosper", "Harrison", ""]]}, {"id": "2009.14397", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Francis Bach", "title": "Deep Equals Shallow for ReLU Networks in Kernel Regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are often considered to be more expressive than shallow ones in\nterms of approximation. Indeed, certain functions can be approximated by deep\nnetworks provably more efficiently than by shallow ones, however, no tractable\nalgorithms are known for learning such deep models. Separately, a recent line\nof work has shown that deep networks trained with gradient descent may behave\nlike (tractable) kernel methods in a certain over-parameterized regime, where\nthe kernel is determined by the architecture and initialization, and this paper\nfocuses on approximation for such kernels. We show that for ReLU activations,\nthe kernels derived from deep fully-connected networks have essentially the\nsame approximation properties as their shallow two-layer counterpart, namely\nthe same eigenvalue decay for the corresponding integral operator. This\nhighlights the limitations of the kernel framework for understanding the\nbenefits of such deep architectures. Our main theoretical result relies on\ncharacterizing such eigenvalue decays through differentiability properties of\nthe kernel function, which also easily applies to the study of other kernels\ndefined on the sphere.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:37:43 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 16:54:31 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 22:25:45 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Bietti", "Alberto", ""], ["Bach", "Francis", ""]]}, {"id": "2009.14416", "submitter": "Qi Qian", "authors": "Qi Qian, Hao Li, Juhua Hu", "title": "Efficient Kernel Transfer in Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is an effective way for model compression in deep\nlearning. Given a large model (i.e., teacher model), it aims to improve the\nperformance of a compact model (i.e., student model) by transferring the\ninformation from the teacher. An essential challenge in knowledge distillation\nis to identify the appropriate information to transfer. In early works, only\nthe final output of the teacher model is used as the soft label to help the\ntraining of student models. Recently, the information from intermediate layers\nis also adopted for better distillation. In this work, we aim to optimize the\nprocess of knowledge distillation from the perspective of kernel matrix. The\noutput of each layer in a neural network can be considered as a new feature\nspace generated by applying a kernel function on original images. Hence, we\npropose to transfer the corresponding kernel matrix (i.e., Gram matrix) from\nteacher models to student models for distillation. However, the size of the\nwhole kernel matrix is quadratic to the number of examples. To improve the\nefficiency, we decompose the original kernel matrix with Nystr{\\\"{o}}m method\nand then transfer the partial matrix obtained with landmark points, whose size\nis linear in the number of examples. More importantly, our theoretical analysis\nshows that the difference between the original kernel matrices of teacher and\nstudent can be well bounded by that of their corresponding partial matrices.\nFinally, a new strategy of generating appropriate landmark points is proposed\nfor better distillation. The empirical study on benchmark data sets\ndemonstrates the effectiveness of the proposed algorithm. Code will be\nreleased.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:03:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Qian", "Qi", ""], ["Li", "Hao", ""], ["Hu", "Juhua", ""]]}, {"id": "2009.14431", "submitter": "Shuhang Chen", "authors": "Shuhang Chen, Adithya Devraj, Andrey Bernstein and Sean Meyn", "title": "Accelerating Optimization and Reinforcement Learning with\n  Quasi-Stochastic Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ODE method has been a workhorse for algorithm design and analysis since\nthe introduction of the stochastic approximation. It is now understood that\nconvergence theory amounts to establishing robustness of Euler approximations\nfor ODEs, while theory of rates of convergence requires finer analysis. This\npaper sets out to extend this theory to quasi-stochastic approximation, based\non algorithms in which the \"noise\" is based on deterministic signals. The main\nresults are obtained under minimal assumptions: the usual Lipschitz conditions\nfor ODE vector fields, and it is assumed that there is a well defined\nlinearization near the optimal parameter $\\theta^*$, with Hurwitz linearization\nmatrix $A^*$.\n  The main contributions are summarized as follows:\n  (i) If the algorithm gain is $a_t=g/(1+t)^\\rho$ with $g>0$ and\n$\\rho\\in(0,1)$, then the rate of convergence of the algorithm is $1/t^\\rho$.\nThere is also a well defined \"finite-$t$\" approximation: \\[\na_t^{-1}\\{\\Theta_t-\\theta^*\\}=\\bar{Y}+\\Xi^{\\mathrm{I}}_t+o(1) \\] where\n$\\bar{Y}\\in\\mathbb{R}^d$ is a vector identified in the paper, and\n$\\{\\Xi^{\\mathrm{I}}_t\\}$ is bounded with zero temporal mean.\n  (ii) With gain $a_t = g/(1+t)$ the results are not as sharp: the rate of\nconvergence $1/t$ holds only if $I + g A^*$ is Hurwitz.\n  (iii) Based on the Ruppert-Polyak averaging of stochastic approximation, one\nwould expect that a convergence rate of $1/t$ can be obtained by averaging: \\[\n\\Theta^{\\text{RP}}_T=\\frac{1}{T}\\int_{0}^T \\Theta_t\\,dt \\] where the estimates\n$\\{\\Theta_t\\}$ are obtained using the gain in (i). The preceding sharp bounds\nimply that averaging results in $1/t$ convergence rate if and only if\n$\\bar{Y}=\\sf 0$. This condition holds if the noise is additive, but appears to\nfail in general.\n  (iv) The theory is illustrated with applications to gradient-free\noptimization and policy gradient algorithms for reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:44:45 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 04:39:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Chen", "Shuhang", ""], ["Devraj", "Adithya", ""], ["Bernstein", "Andrey", ""], ["Meyn", "Sean", ""]]}, {"id": "2009.14436", "submitter": "Jianjun Yuan", "authors": "Jianjun Yuan", "title": "Online Convex Optimization in Changing Environments and its Application\n  to Resource Allocation", "comments": "phd thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of the big data, we create and collect lots of data from all\ndifferent kinds of sources: the Internet, the sensors, the consumer market, and\nso on. Many of the data are coming sequentially, and would like to be processed\nand understood quickly. One classic way of analyzing data is based on batch\nprocessing, in which the data is stored and analyzed in an offline fashion.\nHowever, when the volume of the data is too large, it is much more difficult\nand time-consuming to do batch processing than sequential processing. What's\nmore, sequential data is usually changing dynamically, and needs to be\nunderstood on-the-fly in order to capture the changes. Online Convex\nOptimization (OCO) is a popular framework that matches the above sequential\ndata processing requirement. Applications using OCO include online routing,\nonline auctions, online classification and regression, as well as online\nresource allocation. Due to the general applicability of OCO to the sequential\ndata and the rigorous theoretical guarantee, it has attracted lots of\nresearchers to develop useful algorithms to fulfill different needs. In this\nthesis, we show our contributions to OCO's development by designing algorithms\nto adapt to changing environments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:53:59 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Yuan", "Jianjun", ""]]}, {"id": "2009.14441", "submitter": "Shay Deutsch Dr.", "authors": "Shay Deutsch, Stefano Soatto", "title": "Spectral Embedding of Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an unsupervised graph embedding that trades off local node\nsimilarity and connectivity, and global structure. The embedding is based on a\ngeneralized graph Laplacian, whose eigenvectors compactly capture both network\nstructure and neighborhood proximity in a single representation. The key idea\nis to transform the given graph into one whose weights measure the centrality\nof an edge by the fraction of the number of shortest paths that pass through\nthat edge, and employ its spectral proprieties in the representation. Testing\nthe resulting graph network representation shows significant improvement over\nthe sate of the art in data analysis tasks including social networks and\nmaterial science. We also test our method on node classification from the\nhuman-SARS CoV-2 protein-protein interactome.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:59:10 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Deutsch", "Shay", ""], ["Soatto", "Stefano", ""]]}, {"id": "2009.14444", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck and Yuanzhi Li and Dheeraj Nagaraj", "title": "A law of robustness for two-layers neural networks", "comments": "18 pages, 3 figures. V2: improved Theorem 4 (weaker version of the\n  Conjecture with $n$ replaced by $d$) from ReLU with no bias term in V1, to\n  arbitrary non-linearities (even data-dependent) in V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of the inherent tradeoffs between the size of a neural\nnetwork and its robustness, as measured by its Lipschitz constant. We make a\nprecise conjecture that, for any Lipschitz activation function and for most\ndatasets, any two-layers neural network with $k$ neurons that perfectly fit the\ndata must have its Lipschitz constant larger (up to a constant) than\n$\\sqrt{n/k}$ where $n$ is the number of datapoints. In particular, this\nconjecture implies that overparametrization is necessary for robustness, since\nit means that one needs roughly one neuron per datapoint to ensure a\n$O(1)$-Lipschitz network, while mere data fitting of $d$-dimensional data\nrequires only one neuron per $d$ datapoints. We prove a weaker version of this\nconjecture when the Lipschitz constant is replaced by an upper bound on it\nbased on the spectral norm of the weight matrix. We also prove the conjecture\nin the high-dimensional regime $n \\approx d$ (which we also refer to as the\nundercomplete case, since only $k \\leq d$ is relevant here). Finally we prove\nthe conjecture for polynomial activation functions of degree $p$ when $n\n\\approx d^p$. We complement these findings with experimental evidence\nsupporting the conjecture.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:13:12 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 23:59:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Li", "Yuanzhi", ""], ["Nagaraj", "Dheeraj", ""]]}, {"id": "2009.14445", "submitter": "Soroush Vosoughi Dr", "authors": "Weicheng Ma, Ruibo Liu, Lili Wang and Soroush Vosoughi", "title": "Towards Improved Model Design for Authorship Identification: A Survey on\n  Writing Style Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship identification tasks, which rely heavily on linguistic styles,\nhave always been an important part of Natural Language Understanding (NLU)\nresearch. While other tasks based on linguistic style understanding benefit\nfrom deep learning methods, these methods have not behaved as well as\ntraditional machine learning methods in many authorship-based tasks. With these\ntasks becoming more and more challenging, however, traditional machine learning\nmethods based on handcrafted feature sets are already approaching their\nperformance limits. Thus, in order to inspire future applications of deep\nlearning methods in authorship-based tasks in ways that benefit the extraction\nof stylistic features, we survey authorship-based tasks and other tasks related\nto writing style understanding. We first describe our survey results on the\ncurrent state of research in both sets of tasks and summarize existing\nachievements and problems in authorship-related tasks. We then describe\noutstanding methods in style-related tasks in general and analyze how they are\nused in combination in the top-performing models. We are optimistic about the\napplicability of these models to authorship-based tasks and hope our survey\nwill help advance research in this field.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:17:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ma", "Weicheng", ""], ["Liu", "Ruibo", ""], ["Wang", "Lili", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2009.14448", "submitter": "Jayaraman J. Thiagarajan", "authors": "Bindya Venkatesh and Jayaraman J. Thiagarajan", "title": "Ask-n-Learn: Active Learning via Reliable Gradient Representations for\n  Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive models rely on human supervision in the form of labeled\ntraining data. Obtaining large amounts of annotated training data can be\nexpensive and time consuming, and this becomes a critical bottleneck while\nbuilding such models in practice. In such scenarios, active learning (AL)\nstrategies are used to achieve faster convergence in terms of labeling efforts.\nExisting active learning employ a variety of heuristics based on uncertainty\nand diversity to select query samples. Despite their wide-spread use, in\npractice, their performance is limited by a number of factors including\nnon-calibrated uncertainties, insufficient trade-off between data exploration\nand exploitation, presence of confirmation bias etc. In order to address these\nchallenges, we propose Ask-n-Learn, an active learning approach based on\ngradient embeddings obtained using the pesudo-labels estimated in each\niteration of the algorithm. More importantly, we advocate the use of prediction\ncalibration to obtain reliable gradient embeddings, and propose a data\naugmentation strategy to alleviate the effects of confirmation bias during\npseudo-labeling. Through empirical studies on benchmark image classification\ntasks (CIFAR-10, SVHN, Fashion-MNIST, MNIST), we demonstrate significant\nimprovements over state-of-the-art baselines, including the recently proposed\nBADGE algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:19:56 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Venkatesh", "Bindya", ""], ["Thiagarajan", "Jayaraman J.", ""]]}, {"id": "2009.14454", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Vivek Narayanaswamy, Rushil Anirudh,\n  Peer-Timo Bremer and Andreas Spanias", "title": "Accurate and Robust Feature Importance Estimation under Distribution\n  Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing reliance on the outcomes of black-box models in critical\napplications, post-hoc explainability tools that do not require access to the\nmodel internals are often used to enable humans understand and trust these\nmodels. In particular, we focus on the class of methods that can reveal the\ninfluence of input features on the predicted outputs. Despite their wide-spread\nadoption, existing methods are known to suffer from one or more of the\nfollowing challenges: computational complexities, large uncertainties and most\nimportantly, inability to handle real-world domain shifts. In this paper, we\npropose PRoFILE, a novel feature importance estimation method that addresses\nall these challenges. Through the use of a loss estimator jointly trained with\nthe predictive model and a causal objective, PRoFILE can accurately estimate\nthe feature importance scores even under complex distribution shifts, without\nany additional re-training. To this end, we also develop learning strategies\nfor training the loss estimator, namely contrastive and dropout calibration,\nand find that it can effectively detect distribution shifts. Using empirical\nstudies on several benchmark image and non-image data, we show significant\nimprovements over state-of-the-art approaches, both in terms of fidelity and\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:29:01 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Narayanaswamy", "Vivek", ""], ["Anirudh", "Rushil", ""], ["Bremer", "Peer-Timo", ""], ["Spanias", "Andreas", ""]]}, {"id": "2009.14455", "submitter": "Jayaraman J. Thiagarajan", "authors": "Uday Shankar Shanthamallu, Jayaraman J. Thiagarajan and Andreas\n  Spanias", "title": "Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs), a generalization of neural networks to\ngraph-structured data, are often implemented using message passes between\nentities of a graph. While GNNs are effective for node classification, link\nprediction and graph classification, they are vulnerable to adversarial\nattacks, i.e., a small perturbation to the structure can lead to a non-trivial\nperformance degradation. In this work, we propose Uncertainty Matching GNN\n(UM-GNN), that is aimed at improving the robustness of GNN models, particularly\nagainst poisoning attacks to the graph structure, by leveraging epistemic\nuncertainties from the message passing framework. More specifically, we propose\nto build a surrogate predictor that does not directly access the graph\nstructure, but systematically extracts reliable knowledge from a standard GNN\nthrough a novel uncertainty-matching strategy. Interestingly, this uncoupling\nmakes UM-GNN immune to evasion attacks by design, and achieves significantly\nimproved robustness against poisoning attacks. Using empirical studies with\nstandard benchmarks and a suite of global and target attacks, we demonstrate\nthe effectiveness of UM-GNN, when compared to existing baselines including the\nstate-of-the-art robust GCN.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:29:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Shanthamallu", "Uday Shankar", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Spanias", "Andreas", ""]]}, {"id": "2009.14456", "submitter": "Weihao Tan", "authors": "Weihao Tan, Devdhar Patel, Robert Kozma", "title": "Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven\n  Spiking Neural Networks", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have great potential for energy-efficient\nimplementation of Deep Neural Networks (DNNs) on dedicated neuromorphic\nhardware. Recent studies demonstrated competitive performance of SNNs compared\nwith DNNs on image classification tasks, including CIFAR-10 and ImageNet data.\nThe present work focuses on using SNNs in combination with deep reinforcement\nlearning in ATARI games, which involves additional complexity as compared to\nimage classification. We review the theory of converting DNNs to SNNs and\nextending the conversion to Deep Q-Networks (DQNs). We propose a robust\nrepresentation of the firing rate to reduce the error during the conversion\nprocess. In addition, we introduce a new metric to evaluate the conversion\nprocess by comparing the decisions made by the DQN and SNN, respectively. We\nalso analyze how the simulation time and parameter normalization influence the\nperformance of converted SNNs. We achieve competitive scores on 17\ntop-performing Atari games. To the best of our knowledge, our work is the first\nto achieve state-of-the-art performance on multiple Atari games with SNNs. Our\nwork serves as a benchmark for the conversion of DQNs to SNNs and paves the way\nfor further research on solving reinforcement learning tasks with SNNs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:37:59 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 01:21:48 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Tan", "Weihao", ""], ["Patel", "Devdhar", ""], ["Kozma", "Robert", ""]]}, {"id": "2009.14457", "submitter": "Subhojeet Pramanik", "authors": "Subhojeet Pramanik, Shashank Mujumdar, Hima Patel", "title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework\n  for Document Representation Learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-task learning-based framework that utilizes\na combination of self-supervised and supervised pre-training tasks to learn a\ngeneric document representation. We design the network architecture and the\npre-training tasks to incorporate the multi-modal document information across\ntext, layout, and image dimensions and allow the network to work with\nmulti-page documents. We showcase the applicability of our pre-training\nframework on a variety of different real-world document tasks such as document\nclassification, document information extraction, and document retrieval. We\nconduct exhaustive experiments to compare performance against different\nablations of our framework and state-of-the-art baselines. We discuss the\ncurrent limitations and next steps for our work.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:39:04 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pramanik", "Subhojeet", ""], ["Mujumdar", "Shashank", ""], ["Patel", "Hima", ""]]}, {"id": "2009.14459", "submitter": "Mireille Makary", "authors": "Reda Khalaf and Mireille Makary", "title": "LEBANONUPRISING: a thorough study of Lebanese tweets", "comments": "9 pages, published at the CMLA 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies showed a huge interest in social networks sentiment analysis.\nTwitter, which is a microblogging service, can be a great source of information\non how the users feel about a certain topic, or what their opinion is regarding\na social, economic and even political matter. On October 17, Lebanon witnessed\nthe start of a revolution; the LebanonUprising hashtag became viral on Twitter.\nA dataset consisting of a 100,0000 tweets was collected between 18 and 21\nOctober. In this paper, we conducted a sentiment analysis study for the tweets\nin spoken Lebanese Arabic related to the LebanonUprising hashtag using\ndifferent machine learning algorithms. The dataset was manually annotated to\nmeasure the precision and recall metrics and to compare between the different\nalgorithms. Furthermore, the work completed in this paper provides two more\ncontributions. The first is related to building a Lebanese to Modern Standard\nArabic mapping dictionary that was used for the preprocessing of the tweets and\nthe second is an attempt to move from sentiment analysis to emotion detection\nusing emojis, and the two emotions we tried to predict were the \"sarcastic\" and\n\"funny\" emotions. We built a training set from the tweets collected in October\n2019 and then we used this set to predict sentiments and emotions of the tweets\nwe collected between May and August 2020. The analysis we conducted shows the\nvariation in sentiments, emotions and users between the two datasets. The\nresults we obtained seem satisfactory especially considering that there was no\nprevious or similar work done involving Lebanese Arabic tweets, to our\nknowledge.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:50:08 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Khalaf", "Reda", ""], ["Makary", "Mireille", ""]]}, {"id": "2009.14471", "submitter": "Justin Terry", "authors": "J. K. Terry, Benjamin Black, Nathaniel Grammel, Mario Jayakumar,\n  Ananth Hari, Ryan Sullivan, Luis Santos, Rodrigo Perez, Caroline Horsch,\n  Clemens Dieffendahl, Niall L. Williams, Yashas Lokesh, Praveen Ravi", "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the PettingZoo library and the accompanying Agent\nEnvironment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets\nof multi-agent environments with a universal, elegant Python API. PettingZoo\nwas developed with the goal of accelerating research in Multi-Agent\nReinforcement Learning (\"MARL\"), by making work more interchangeable,\naccessible and reproducible akin to what OpenAI's Gym library did for\nsingle-agent reinforcement learning. PettingZoo's API, while inheriting many\nfeatures of Gym, is unique amongst MARL APIs in that it's based around the\nnovel AEC games model. We argue, in part through case studies on major problems\nin popular MARL environments, that the popular game models are poor conceptual\nmodels of the games commonly used with MARL, that they promote severe bugs that\nare hard to detect, and that the AEC games model addresses these problems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 06:42:09 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 20:04:22 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 08:02:06 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 22:34:21 GMT"}, {"version": "v5", "created": "Thu, 25 Feb 2021 22:08:03 GMT"}, {"version": "v6", "created": "Wed, 16 Jun 2021 00:18:34 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Terry", "J. K.", ""], ["Black", "Benjamin", ""], ["Grammel", "Nathaniel", ""], ["Jayakumar", "Mario", ""], ["Hari", "Ananth", ""], ["Sullivan", "Ryan", ""], ["Santos", "Luis", ""], ["Perez", "Rodrigo", ""], ["Horsch", "Caroline", ""], ["Dieffendahl", "Clemens", ""], ["Williams", "Niall L.", ""], ["Lokesh", "Yashas", ""], ["Ravi", "Praveen", ""]]}, {"id": "2009.14487", "submitter": "Arash Akbarinia", "authors": "Arash Akbarinia, Raquel Gil-Rodr\\'iguez, Alban Flachot and Matteo\n  Toscani", "title": "The Utility of Decorrelating Colour Spaces in Vector Quantised\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector quantised variational autoencoders (VQ-VAE) are characterised by three\nmain components: 1) encoding visual data, 2) assigning $k$ different vectors in\nthe so-called embedding space, and 3) decoding the learnt features. While\nimages are often represented in RGB colour space, the specific organisation of\ncolours in other spaces also offer interesting features, e.g. CIE L*a*b*\ndecorrelates chromaticity into opponent axes. In this article, we propose\ncolour space conversion, a simple quasi-unsupervised task, to enforce a network\nlearning structured representations. To this end, we trained several instances\nof VQ-VAE whose input is an image in one colour space, and its output in\nanother, e.g. from RGB to CIE L*a*b* (in total five colour spaces were\nconsidered). We examined the finite embedding space of trained networks in\norder to disentangle the colour representation in VQ-VAE models. Our analysis\nsuggests that certain vectors encode hue and others luminance information. We\nfurther evaluated the quality of reconstructed images at low-level using\npixel-wise colour metrics, and at high-level by inputting them to image\nclassification and scene segmentation networks. We conducted experiments in\nthree benchmark datasets: ImageNet, COCO and CelebA. Our results show, with\nrespect to the baseline network (whose input and output are RGB), colour\nconversion to decorrelated spaces obtains 1-2 Delta-E lower colour difference\nand 5-10% higher classification accuracy. We also observed that the learnt\nembedding space is easier to interpret in colour opponent models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 07:44:01 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Akbarinia", "Arash", ""], ["Gil-Rodr\u00edguez", "Raquel", ""], ["Flachot", "Alban", ""], ["Toscani", "Matteo", ""]]}, {"id": "2009.14499", "submitter": "Ashad Kabir", "authors": "Md Delowar Hossain, Muhammad Ashad Kabir, Adnan Anwar, Md Zahidul\n  Islam", "title": "Detecting Autism Spectrum Disorder using Machine Learning", "comments": null, "journal-ref": "Health information science and systems, 2021", "doi": "10.1007/s13755-021-00145-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorder (ASD), which is a neuro development disorder, is\noften accompanied by sensory issues such an over sensitivity or under\nsensitivity to sounds and smells or touch. Although its main cause is genetics\nin nature, early detection and treatment can help to improve the conditions. In\nrecent years, machine learning based intelligent diagnosis has been evolved to\ncomplement the traditional clinical methods which can be time consuming and\nexpensive. The focus of this paper is to find out the most significant traits\nand automate the diagnosis process using available classification techniques\nfor improved diagnosis purpose. We have analyzed ASD datasets of Toddler,\nChild, Adolescent and Adult. We determine the best performing classifier for\nthese binary datasets using the evaluation metrics recall, precision,\nF-measures and classification errors. Our finding shows that Sequential minimal\noptimization (SMO) based Support Vector Machines (SVM) classifier outperforms\nall other benchmark machine learning algorithms in terms of accuracy during the\ndetection of ASD cases and produces less classification errors compared to\nother algorithms. Also, we find that Relief Attributes algorithm is the best to\nidentify the most significant attributes in ASD datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:33:12 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hossain", "Md Delowar", ""], ["Kabir", "Muhammad Ashad", ""], ["Anwar", "Adnan", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "2009.14502", "submitter": "Yoonho Boo", "authors": "Yoonho Boo, Sungho Shin, Jungwook Choi, and Wonyong Sung", "title": "Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantization of deep neural networks (QDNNs) has been actively studied\nfor deployment in edge devices. Recent studies employ the knowledge\ndistillation (KD) method to improve the performance of quantized networks. In\nthis study, we propose stochastic precision ensemble training for QDNNs (SPEQ).\nSPEQ is a knowledge distillation training scheme; however, the teacher is\nformed by sharing the model parameters of the student network. We obtain the\nsoft labels of the teacher by changing the bit precision of the activation\nstochastically at each layer of the forward-pass computation. The student model\nis trained with these soft labels to reduce the activation quantization noise.\nThe cosine similarity loss is employed, instead of the KL-divergence, for KD\ntraining. As the teacher model changes continuously by random bit-precision\nassignment, it exploits the effect of stochastic ensemble KD. SPEQ outperforms\nthe existing quantization training methods in various tasks, such as image\nclassification, question-answering, and transfer learning without the need for\ncumbersome teacher networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:38:37 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Boo", "Yoonho", ""], ["Shin", "Sungho", ""], ["Choi", "Jungwook", ""], ["Sung", "Wonyong", ""]]}, {"id": "2009.14510", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Peng Xu, Zhaojiang Lin, Pascale Fung", "title": "Cross-lingual Spoken Language Understanding with Regularized\n  Representation Alignment", "comments": "EMNLP-2020 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the promising results of current cross-lingual models for spoken\nlanguage understanding systems, they still suffer from imperfect cross-lingual\nrepresentation alignments between the source and target languages, which makes\nthe performance sub-optimal. To cope with this issue, we propose a\nregularization approach to further align word-level and sentence-level\nrepresentations across languages without any external resource. First, we\nregularize the representation of user utterances based on their corresponding\nlabels. Second, we regularize the latent variable model (Liu et al., 2019) by\nleveraging adversarial training to disentangle the latent variables.\nExperiments on the cross-lingual spoken language understanding task show that\nour model outperforms current state-of-the-art methods in both few-shot and\nzero-shot scenarios, and our model, trained on a few-shot setting with only 3\\%\nof the target language training data, achieves comparable performance to the\nsupervised training with all the training data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:56:53 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Xu", "Peng", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.14523", "submitter": "Dominik Schiller", "authors": "Dominik Schiller, Silvan Mertes, Elisabeth Andr\\'e", "title": "Embedded Emotions -- A Data Driven Approach to Learn Transferable\n  Feature Representations from Raw Speech Input for Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to automatic emotion recognition are relying on the\napplication of handcrafted features. More recently however the advent of deep\nlearning enabled algorithms to learn meaningful representations of input data\nautomatically. In this paper, we investigate the applicability of transferring\nknowledge learned from large text and audio corpora to the task of automatic\nemotion recognition. To evaluate the practicability of our approach, we are\ntaking part in this year's Interspeech ComParE Elderly Emotion Sub-Challenge,\nwhere the goal is to classify spoken narratives of elderly people with respect\nto the emotion of the speaker. Our results show that the learned feature\nrepresentations can be effectively applied for classifying emotions from spoken\nlanguage. We found the performance of the features extracted from the audio\nsignal to be not as consistent as those that have been extracted from the\ntranscripts. While the acoustic features achieved best in class results on the\ndevelopment set, when compared to the baseline systems, their performance\ndropped considerably on the test set of the challenge. The features extracted\nfrom the text form, however, are showing promising results on both sets and are\noutperforming the official baseline by 5.7 percentage points unweighted average\nrecall.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:18:31 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Schiller", "Dominik", ""], ["Mertes", "Silvan", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "2009.14524", "submitter": "Deniz Beker", "authors": "Deniz Beker, Hiroharu Kato, Mihai Adrian Morariu, Takahiro Ando, Toru\n  Matsuoka, Wadim Kehl, Adrien Gaidon", "title": "Monocular Differentiable Rendering for Self-Supervised 3D Object\n  Detection", "comments": "20 pages, Supplementary material included, Published in ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object detection from monocular images is an ill-posed problem due to the\nprojective entanglement of depth and scale. To overcome this ambiguity, we\npresent a novel self-supervised method for textured 3D shape reconstruction and\npose estimation of rigid objects with the help of strong shape priors and 2D\ninstance masks. Our method predicts the 3D location and meshes of each object\nin an image using differentiable rendering and a self-supervised objective\nderived from a pretrained monocular depth estimation network. We use the KITTI\n3D object detection dataset to evaluate the accuracy of the method. Experiments\ndemonstrate that we can effectively use noisy monocular depth and\ndifferentiable rendering as an alternative to expensive 3D ground-truth labels\nor LiDAR information.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:21:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Beker", "Deniz", ""], ["Kato", "Hiroharu", ""], ["Morariu", "Mihai Adrian", ""], ["Ando", "Takahiro", ""], ["Matsuoka", "Toru", ""], ["Kehl", "Wadim", ""], ["Gaidon", "Adrien", ""]]}, {"id": "2009.14547", "submitter": "Yingxue Pang", "authors": "Yingxue Pang, Xin Li, Xin Jin, Yaojun Wu, Jianzhao Liu, Sen Liu, and\n  Zhibo Chen", "title": "FAN: Frequency Aggregation Network for Real Image Super-resolution", "comments": "14 pages, 7 figures, presented as a workshop paper at AIM 2020\n  Challenge @ ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single image super-resolution (SISR) aims to recover the high-resolution (HR)\nimage from its low-resolution (LR) input image. With the development of deep\nlearning, SISR has achieved great progress. However, It is still a challenge to\nrestore the real-world LR image with complicated authentic degradations.\nTherefore, we propose FAN, a frequency aggregation network, to address the\nreal-world image super-resolu-tion problem. Specifically, we extract different\nfrequencies of the LR image and pass them to a channel attention-grouped\nresidual dense network (CA-GRDB) individually to output corresponding feature\nmaps. And then aggregating these residual dense feature maps adaptively to\nrecover the HR image with enhanced details and textures. We conduct extensive\nexperiments quantitatively and qualitatively to verify that our FAN performs\nwell on the real image super-resolution task of AIM 2020 challenge. According\nto the released final results, our team SR-IM achieves the fourth place on the\nX4 track with PSNR of 31.1735 and SSIM of 0.8728.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 10:18:41 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pang", "Yingxue", ""], ["Li", "Xin", ""], ["Jin", "Xin", ""], ["Wu", "Yaojun", ""], ["Liu", "Jianzhao", ""], ["Liu", "Sen", ""], ["Chen", "Zhibo", ""]]}, {"id": "2009.14552", "submitter": "Chaosheng Dong", "authors": "Chaosheng Dong, Bo Zeng", "title": "Wasserstein Distributionally Robust Inverse Multiobjective Optimization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse multiobjective optimization provides a general framework for the\nunsupervised learning task of inferring parameters of a multiobjective decision\nmaking problem (DMP), based on a set of observed decisions from the human\nexpert. However, the performance of this framework relies critically on the\navailability of an accurate DMP, sufficient decisions of high quality, and a\nparameter space that contains enough information about the DMP. To hedge\nagainst the uncertainties in the hypothetical DMP, the data, and the parameter\nspace, we investigate in this paper the distributionally robust approach for\ninverse multiobjective optimization. Specifically, we leverage the Wasserstein\nmetric to construct a ball centered at the empirical distribution of these\ndecisions. We then formulate a Wasserstein distributionally robust inverse\nmultiobjective optimization problem (WRO-IMOP) that minimizes a worst-case\nexpected loss function, where the worst case is taken over all distributions in\nthe Wasserstein ball. We show that the excess risk of the WRO-IMOP estimator\nhas a sub-linear convergence rate. Furthermore, we propose the semi-infinite\nreformulations of the WRO-IMOP and develop a cutting-plane algorithm that\nconverges to an approximate solution in finite iterations. Finally, we\ndemonstrate the effectiveness of our method on both a synthetic multiobjective\nquadratic program and a real world portfolio optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 10:44:07 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Dong", "Chaosheng", ""], ["Zeng", "Bo", ""]]}, {"id": "2009.14554", "submitter": "Alexander Mathiasen Mr", "authors": "Alexander Mathiasen and Frederik Hvilsh{\\o}j", "title": "One Reflection Suffice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal weight matrices are used in many areas of deep learning. Much\nprevious work attempt to alleviate the additional computational resources it\nrequires to constrain weight matrices to be orthogonal. One popular approach\nutilizes *many* Householder reflections. The only practical drawback is that\nmany reflections cause low GPU utilization. We mitigate this final drawback by\nproving that *one* reflection is sufficient, if the reflection is computed by\nan auxiliary neural network.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 10:52:27 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Mathiasen", "Alexander", ""], ["Hvilsh\u00f8j", "Frederik", ""]]}, {"id": "2009.14572", "submitter": "Sandro Lera", "authors": "Delilah Donick and Sandro Claudio Lera", "title": "Uncovering Feature Interdependencies in High-Noise Environments with\n  Stepwise Lookahead Decision Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, random forests are built from \"greedy\" decision trees which\neach consider only one split at a time during their construction. The\nsub-optimality of greedy implementation has been well-known, yet mainstream\nadoption of more sophisticated tree building algorithms has been lacking. We\nexamine under what circumstances an implementation of less greedy decision\ntrees actually yields outperformance. To this end, a \"stepwise lookahead\"\nvariation of the random forest algorithm is presented for its ability to better\nuncover binary feature interdependencies. In contrast to the greedy approach,\nthe decision trees included in this random forest algorithm, each\nsimultaneously consider three split nodes in tiers of depth two. It is\ndemonstrated on synthetic data and financial price time series that the\nlookahead version significantly outperforms the greedy one when (a) certain\nnon-linear relationships between feature-pairs are present and (b) if the\nsignal-to-noise ratio is particularly low. A long-short trading strategy for\ncopper futures is then backtested by training both greedy and stepwise\nlookahead random forests to predict the signs of daily price returns. The\nresulting superior performance of the lookahead algorithm is at least partially\nexplained by the presence of \"XOR-like\" relationships between long-term and\nshort-term technical indicators. More generally, across all examined datasets,\nwhen no such relationships between features are present, performance across\nrandom forests is similar. Given its enhanced ability to understand the\nfeature-interdependencies present in complex systems, this lookahead variation\nis a useful extension to the toolkit of data scientists, in particular for\nfinancial machine learning, where conditions (a) and (b) are typically met.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:31:10 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 01:54:54 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 14:11:33 GMT"}, {"version": "v4", "created": "Mon, 1 Feb 2021 04:21:00 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 14:24:26 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Donick", "Delilah", ""], ["Lera", "Sandro Claudio", ""]]}, {"id": "2009.14573", "submitter": "Takato Yasuno", "authors": "Takato Yasuno, Akira Ishii, Masazumi Amakata", "title": "Rain-Code Fusion : Code-to-code ConvLSTM Forecasting Spatiotemporal\n  Precipitation", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, flood damage has become a social problem owing to unexperienced\nweather conditions arising from climate change. An immediate response to heavy\nrain is important for the mitigation of economic losses and also for rapid\nrecovery. Spatiotemporal precipitation forecasts may enhance the accuracy of\ndam inflow prediction, more than 6 hours forward for flood damage mitigation.\nHowever, the ordinary ConvLSTM has the limitation of predictable range more\nthan 3-timesteps in real-world precipitation forecasting owing to the\nirreducible bias between target prediction and ground-truth value. This paper\nproposes a rain-code approach for spatiotemporal precipitation code-to-code\nforecasting. We propose a novel rainy feature that represents a temporal rainy\nprocess using multi-frame fusion for the timestep reduction. We perform\nrain-code studies with various term ranges based on the standard ConvLSTM. We\napplied to a dam region within the Japanese rainy term hourly precipitation\ndata, under 2006 to 2019 approximately 127 thousands hours, every year from May\nto October. We apply the radar analysis hourly data on the central broader\nregion with an area of 136 x 148 km2 . Finally we have provided sensitivity\nstudies between the rain-code size and hourly accuracy within the several\nforecasting range.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:33:45 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 05:51:53 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 04:38:39 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 13:13:17 GMT"}, {"version": "v5", "created": "Mon, 23 Nov 2020 12:16:58 GMT"}, {"version": "v6", "created": "Mon, 1 Mar 2021 11:49:45 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yasuno", "Takato", ""], ["Ishii", "Akira", ""], ["Amakata", "Masazumi", ""]]}, {"id": "2009.14575", "submitter": "Yassine Laguel", "authors": "Yassine Laguel, J\\'er\\^ome Malick and Zaid Harchaoui", "title": "First-order Optimization for Superquantile-based Supervised Learning", "comments": "6 pages, 2 figures, 2 tables, presented at IEEE MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical supervised learning via empirical risk (or negative log-likelihood)\nminimization hinges upon the assumption that the testing distribution coincides\nwith the training distribution. This assumption can be challenged in modern\napplications of machine learning in which learning machines may operate at\nprediction time with testing data whose distribution departs from the one of\nthe training data. We revisit the superquantile regression method by proposing\na first-order optimization algorithm to minimize a superquantile-based learning\nobjective. The proposed algorithm is based on smoothing the superquantile\nfunction by infimal convolution. Promising numerical results illustrate the\ninterest of the approach towards safer supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:43:45 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 09:11:20 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Laguel", "Yassine", ""], ["Malick", "J\u00e9r\u00f4me", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2009.14588", "submitter": "Maxim Panov", "authors": "Ivan Sukharev, Valentina Shumovskaia, Kirill Fedyanin, Maxim Panov and\n  Dmitry Berestnev", "title": "EWS-GCN: Edge Weight-Shared Graph Convolutional Network for\n  Transactional Banking Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss how modern deep learning approaches can be applied\nto the credit scoring of bank clients. We show that information about\nconnections between clients based on money transfers between them allows us to\nsignificantly improve the quality of credit scoring compared to the approaches\nusing information about the target client solely. As a final solution, we\ndevelop a new graph neural network model EWS-GCN that combines ideas of graph\nconvolutional and recurrent neural networks via attention mechanism. The\nresulting model allows for robust training and efficient processing of\nlarge-scale data. We also demonstrate that our model outperforms the\nstate-of-the-art graph neural networks achieving excellent results\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:09:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Sukharev", "Ivan", ""], ["Shumovskaia", "Valentina", ""], ["Fedyanin", "Kirill", ""], ["Panov", "Maxim", ""], ["Berestnev", "Dmitry", ""]]}, {"id": "2009.14589", "submitter": "Xuemin Chen", "authors": "Mingchi Zhang, Xuemin Chen and Wei Li", "title": "Hidden Markov Models for Pipeline Damage Detection Using Piezoelectric\n  Transducers", "comments": null, "journal-ref": "Journal of Civil Structural Health Monitoring (2021)", "doi": "10.1007/s13349-021-00481-0", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oil and gas pipeline leakages lead to not only enormous economic loss but\nalso environmental disasters. How to detect the pipeline damages including\nleakages and cracks has attracted much research attention. One of the promising\nleakage detection method is to use lead zirconate titanate (PZT) transducers to\ndetect the negative pressure wave when leakage occurs. PZT transducers can\ngenerate and detect guided stress waves for crack detection also. However, the\nnegative pressure waves or guided stress waves may not be easily detected with\nenvironmental interference, e.g., the oil and gas pipelines in offshore\nenvironment. In this paper, a Gaussian mixture model based hidden Markov model\n(GMM-HMM) method is proposed to detect the pipeline leakage and crack depth in\nchanging environment and time-varying operational conditions. Leakages in\ndifferent sections or crack depths are considered as different states in hidden\nMarkov models (HMM). Laboratory experiments show that the GMM-HMM method can\nrecognize the crack depth and leakage of pipeline such as whether there is a\nleakage, where the leakage is.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:10:43 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhang", "Mingchi", ""], ["Chen", "Xuemin", ""], ["Li", "Wei", ""]]}, {"id": "2009.14593", "submitter": "Ben Day", "authors": "Vijja Wichitwechkarn, Ben Day, Cristian Bodnar, Matthew Wales, Pietro\n  Li\\`o", "title": "The Role of Isomorphism Classes in Multi-Relational Datasets", "comments": "7 pages main text, 1 page of references and an ethics statement, 3\n  pages of appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-interaction systems abound in nature, from colloidal suspensions to\ngene regulatory circuits. These systems can produce complex dynamics and graph\nneural networks have been proposed as a method to extract underlying\ninteractions and predict how systems will evolve. The current training and\nevaluation procedures for these models through the use of synthetic\nmulti-relational datasets however are agnostic to interaction network\nisomorphism classes, which produce identical dynamics up to initial conditions.\nWe extensively analyse how isomorphism class awareness affects these models,\nfocusing on neural relational inference (NRI) models, which are unique in\nexplicitly inferring interactions to predict dynamics in the unsupervised\nsetting. Specifically, we demonstrate that isomorphism leakage overestimates\nperformance in multi-relational inference and that sampling biases present in\nthe multi-interaction network generation process can impair generalisation. To\nremedy this, we propose isomorphism-aware synthetic benchmarks for model\nevaluation. We use these benchmarks to test generalisation abilities and\ndemonstrate the existence of a threshold sampling frequency of isomorphism\nclasses for successful learning. In addition, we demonstrate that isomorphism\nclasses can be utilised through a simple prioritisation scheme to improve model\nperformance, stability during training and reduce training time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:15:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wichitwechkarn", "Vijja", ""], ["Day", "Ben", ""], ["Bodnar", "Cristian", ""], ["Wales", "Matthew", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2009.14596", "submitter": "Lei Wu", "authors": "Weinan E", "title": "Machine Learning and Computational Mathematics", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0185", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based machine learning is capable of approximating functions\nin very high dimension with unprecedented efficiency and accuracy. This has\nopened up many exciting new possibilities, not just in traditional areas of\nartificial intelligence, but also in scientific computing and computational\nscience. At the same time, machine learning has also acquired the reputation of\nbeing a set of \"black box\" type of tricks, without fundamental principles. This\nhas been a real obstacle for making further progress in machine learning. In\nthis article, we try to address the following two very important questions: (1)\nHow machine learning has already impacted and will further impact computational\nmathematics, scientific computing and computational science? (2) How\ncomputational mathematics, particularly numerical analysis, {can} impact\nmachine learning? We describe some of the most important progress that has been\nmade on these issues. Our hope is to put things into a perspective that will\nhelp to integrate machine learning with computational mathematics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 23:16:46 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["E", "Weinan", ""]]}, {"id": "2009.14606", "submitter": "Katharina Rombach", "authors": "Katharina Rombach, Gabriel Michau and Olga Fink", "title": "Improving Generalization of Deep Fault Detection Models in the Presence\n  of Mislabeled Data", "comments": "12 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mislabeled samples are ubiquitous in real-world datasets as rule-based or\nexpert labeling is usually based on incorrect assumptions or subject to biased\nopinions. Neural networks can \"memorize\" these mislabeled samples and, as a\nresult, exhibit poor generalization. This poses a critical issue in fault\ndetection applications, where not only the training but also the validation\ndatasets are prone to contain mislabeled samples. In this work, we propose a\nnovel two-step framework for robust training with label noise. In the first\nstep, we identify outliers (including the mislabeled samples) based on the\nupdate in the hypothesis space. In the second step, we propose different\napproaches to modifying the training data based on the identified outliers and\na data augmentation technique. Contrary to previous approaches, we aim at\nfinding a robust solution that is suitable for real-world applications, such as\nfault detection, where no clean, \"noise-free\" validation dataset is available.\nUnder an approximate assumption about the upper limit of the label noise, we\nsignificantly improve the generalization ability of the model trained under\nmassive label noise.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:33:25 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Rombach", "Katharina", ""], ["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2009.14610", "submitter": "R\\'emy Garnier", "authors": "R\\'emy Garnier", "title": "Concurrent Neural Network : A model of competition between times series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competition between times series often arises in sales prediction, when\nsimilar products are on sale on a marketplace. This article provides a model of\nthe presence of cannibalization between times series. This model creates a\n\"competitiveness\" function that depends on external features such as price and\nmargin. It also provides a theoretical guaranty on the error of the model under\nsome reasonable conditions, and implement this model using a neural network to\ncompute this competitiveness function. This implementation outperforms other\ntraditional time series methods and classical neural networks for market share\nprediction on a real-world data set.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:34:56 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 13:43:00 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Garnier", "R\u00e9my", ""]]}, {"id": "2009.14614", "submitter": "Adam Zadro\\.zny", "authors": "Katarzyna Ward\\k{e}ga, Adam Zadro\\.zny, Martin Beroiz, Richard\n  Camuccio and Mario C. D\\'iaz", "title": "Detecting optical transients using artificial neural networks and\n  reference images from different surveys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To search for optical counterparts to gravitational waves, it is crucial to\ndevelop an efficient follow-up method that allows for both a quick telescopic\nscan of the event localization region and search through the resulting image\ndata for plausible optical transients. We present a method to detect these\ntransients based on an artificial neural network. We describe the architecture\nof two networks capable of comparing images of the same part of the sky taken\nby different telescopes. One image corresponds to the epoch in which a\npotential transient could exist; the other is a reference image of an earlier\nepoch. We use data obtained by the Dr. Cristina V. Torres Memorial Astronomical\nObservatory and archival reference images from the Sloan Digital Sky Survey. We\ntrained a convolutional neural network and a dense layer network on simulated\nsource samples and tested the trained networks on samples created from real\nimage data. Autonomous detection methods replace the standard process of\ndetecting transients, which is normally achieved by source extraction of a\ndifference image followed by human inspection of the detected candidates.\nReplacing the human inspection component with an entirely autonomous method\nwould allow for a rapid and automatic follow-up of interesting targets of\nopportunity. The method will be further tested on telescopes participating in\nthe Transient Optical Robotic Observatory of the South Collaboration.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:16:54 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ward\u0119ga", "Katarzyna", ""], ["Zadro\u017cny", "Adam", ""], ["Beroiz", "Martin", ""], ["Camuccio", "Richard", ""], ["D\u00edaz", "Mario C.", ""]]}, {"id": "2009.14623", "submitter": "Arash Mohammadi", "authors": "Parnian Afshar, Shahin Heidarian, Nastaran Enshaei, Farnoosh\n  Naderkhani, Moezedin Javad Rafiee, Anastasia Oikonomou, Faranak Babaki Fard,\n  Kaveh Samimi, Konstantinos N. Plataniotis, Arash Mohammadi", "title": "COVID-CT-MD: COVID-19 Computed Tomography (CT) Scan Dataset Applicable\n  in Machine Learning and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel Coronavirus (COVID-19) has drastically overwhelmed more than 200\ncountries affecting millions and claiming almost 1 million lives, since its\nemergence in late 2019. This highly contagious disease can easily spread, and\nif not controlled in a timely fashion, can rapidly incapacitate healthcare\nsystems. The current standard diagnosis method, the Reverse Transcription\nPolymerase Chain Reaction (RT- PCR), is time consuming, and subject to low\nsensitivity. Chest Radiograph (CXR), the first imaging modality to be used, is\nreadily available and gives immediate results. However, it has notoriously\nlower sensitivity than Computed Tomography (CT), which can be used efficiently\nto complement other diagnostic methods. This paper introduces a new COVID-19 CT\nscan dataset, referred to as COVID-CT-MD, consisting of not only COVID-19\ncases, but also healthy and subjects infected by Community Acquired Pneumonia\n(CAP). COVID-CT-MD dataset, which is accompanied with lobe-level, slice-level\nand patient-level labels, has the potential to facilitate the COVID-19\nresearch, in particular COVID-CT-MD can assist in development of advanced\nMachine Learning (ML) and Deep Neural Network (DNN) based solutions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:42:07 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Afshar", "Parnian", ""], ["Heidarian", "Shahin", ""], ["Enshaei", "Nastaran", ""], ["Naderkhani", "Farnoosh", ""], ["Rafiee", "Moezedin Javad", ""], ["Oikonomou", "Anastasia", ""], ["Fard", "Faranak Babaki", ""], ["Samimi", "Kaveh", ""], ["Plataniotis", "Konstantinos N.", ""], ["Mohammadi", "Arash", ""]]}, {"id": "2009.14627", "submitter": "Chenguang Zhao", "authors": "Xiaorong Hu, Chenguang Zhao, Gang Wang", "title": "A Traffic Light Dynamic Control Algorithm with Deep Reinforcement\n  Learning Based on GNN Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's intelligent traffic light control system is based on the current road\ntraffic conditions for traffic regulation. However, these approaches cannot\nexploit the future traffic information in advance. In this paper, we propose\nGPlight, a deep reinforcement learning (DRL) algorithm integrated with graph\nneural network (GNN) , to relieve the traffic congestion for multi-intersection\nintelligent traffic control system. In GPlight, the graph neural network (GNN)\nis first used to predict the future short-term traffic flow at the\nintersections. Then, the results of traffic flow prediction are used in traffic\nlight control, and the agent combines the predicted results with the observed\ncurrent traffic conditions to dynamically control the phase and duration of the\ntraffic lights at the intersection. Experiments on both synthetic and two\nreal-world data-sets of Hangzhou and New-York verify the effectiveness and\nrationality of the GPlight algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:09:24 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Hu", "Xiaorong", ""], ["Zhao", "Chenguang", ""], ["Wang", "Gang", ""]]}, {"id": "2009.14635", "submitter": "Kourosh Meshgi", "authors": "Kourosh Meshgi, Maryam Sadat Mirzaei", "title": "Adversarial Semi-Supervised Multi-Domain Tracking", "comments": "Accepted for ACCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks for multi-domain learning empowers an effective combination\nof information from different domains by sharing and co-learning the\nparameters. In visual tracking, the emerging features in shared layers of a\nmulti-domain tracker, trained on various sequences, are crucial for tracking in\nunseen videos. Yet, in a fully shared architecture, some of the emerging\nfeatures are useful only in a specific domain, reducing the generalization of\nthe learned feature representation. We propose a semi-supervised learning\nscheme to separate domain-invariant and domain-specific features using\nadversarial learning, to encourage mutual exclusion between them, and to\nleverage self-supervised learning for enhancing the shared features using the\nunlabeled reservoir. By employing these features and training dedicated layers\nfor each sequence, we build a tracker that performs exceptionally on different\ntypes of videos.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:47:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Meshgi", "Kourosh", ""], ["Mirzaei", "Maryam Sadat", ""]]}, {"id": "2009.14639", "submitter": "Okan K\\\"op\\\"ukl\\\"u", "authors": "Okan K\\\"op\\\"ukl\\\"u, Stefan H\\\"ormann, Fabian Herzog, Hakan Cevikalp,\n  Gerhard Rigoll", "title": "Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks with 3D kernels (3D CNNs) currently achieve\nstate-of-the-art results in video recognition tasks due to their supremacy in\nextracting spatiotemporal features within video frames. There have been many\nsuccessful 3D CNN architectures surpassing the state-of-the-art results\nsuccessively. However, nearly all of them are designed to operate offline\ncreating several serious handicaps during online operation. Firstly,\nconventional 3D CNNs are not dynamic since their output features represent the\ncomplete input clip instead of the most recent frame in the clip. Secondly,\nthey are not temporal resolution-preserving due to their inherent temporal\ndownsampling. Lastly, 3D CNNs are constrained to be used with fixed temporal\ninput size limiting their flexibility. In order to address these drawbacks, we\npropose dissected 3D CNNs, where the intermediate volumes of the network are\ndissected and propagated over depth (time) dimension for future calculations,\nsubstantially reducing the number of computations at online operation. For\naction classification, the dissected version of ResNet models performs 74-90%\nfewer computations at online operation while achieving $\\sim$5% better\nclassification accuracy on the Kinetics-600 dataset than conventional 3D ResNet\nmodels. Moreover, the advantages of dissected 3D CNNs are demonstrated by\ndeploying our approach onto several vision tasks, which consistently improved\nthe performance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:48:52 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["K\u00f6p\u00fckl\u00fc", "Okan", ""], ["H\u00f6rmann", "Stefan", ""], ["Herzog", "Fabian", ""], ["Cevikalp", "Hakan", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "2009.14645", "submitter": "Pier Carlo Berri", "authors": "Pier Carlo Berri, Matteo D.L. Dalla Vedova, Laura Mainini", "title": "Computational framework for real-time diagnostics and prognostics of\n  aircraft actuation systems", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics and Health Management (PHM) are emerging approaches to product\nlife cycle that will maintain system safety and improve reliability, while\nreducing operating and maintenance costs. This is particularly relevant for\naerospace systems, where high levels of integrity and high performances are\nrequired at the same time. We propose a novel strategy for the nearly real-time\nFault Detection and Identification (FDI) of a dynamical assembly, and for the\nestimation of Remaining Useful Life (RUL) of the system. The availability of a\ntimely estimate of the health status of the system will allow for an informed\nadaptive planning of maintenance and a dynamical reconfiguration of the mission\nprofile, reducing operating costs and improving reliability. This work\naddresses the three phases of the prognostic flow - namely (1) signal\nacquisition, (2) Fault Detection and Identification, and (3) Remaining Useful\nLife estimation - and introduces a computationally efficient procedure suitable\nfor real-time, on-board execution. To achieve this goal, we propose to combine\ninformation from physical models of different fidelity with machine learning\ntechniques to obtain efficient representations (surrogate models) suitable for\nnearly real-time applications. Additionally, we propose an importance sampling\nstrategy and a novel approach to model damage propagation for dynamical\nsystems. The methodology is assessed for the FDI and RUL estimation of an\naircraft electromechanical actuator (EMA) for secondary flight controls. The\nresults show that the proposed method allows for a high precision in the\nevaluation of the system RUL, while outperforming common model-based techniques\nin terms of computational time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:53:07 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Berri", "Pier Carlo", ""], ["Vedova", "Matteo D. L. Dalla", ""], ["Mainini", "Laura", ""]]}, {"id": "2009.14660", "submitter": "Okan K\\\"op\\\"ukl\\\"u", "authors": "Okan K\\\"op\\\"ukl\\\"u, Jiapeng Zheng, Hang Xu, Gerhard Rigoll", "title": "Driver Anomaly Detection: A Dataset and Contrastive Learning Approach", "comments": "Accepted to IEEE Winter Conference on Applications of Computer Vision\n  (WACV 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distracted drivers are more likely to fail to anticipate hazards, which\nresult in car accidents. Therefore, detecting anomalies in drivers' actions\n(i.e., any action deviating from normal driving) contains the utmost importance\nto reduce driver-related accidents. However, there are unbounded many anomalous\nactions that a driver can do while driving, which leads to an 'open set\nrecognition' problem. Accordingly, instead of recognizing a set of anomalous\nactions that are commonly defined by previous dataset providers, in this work,\nwe propose a contrastive learning approach to learn a metric to differentiate\nnormal driving from anomalous driving. For this task, we introduce a new\nvideo-based benchmark, the Driver Anomaly Detection (DAD) dataset, which\ncontains normal driving videos together with a set of anomalous actions in its\ntraining set. In the test set of the DAD dataset, there are unseen anomalous\nactions that still need to be winnowed out from normal driving. Our method\nreaches 0.9673 AUC on the test set, demonstrating the effectiveness of the\ncontrastive learning approach on the anomaly detection task. Our dataset, codes\nand pre-trained models are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:23:21 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 15:00:06 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["K\u00f6p\u00fckl\u00fc", "Okan", ""], ["Zheng", "Jiapeng", ""], ["Xu", "Hang", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "2009.14665", "submitter": "Yujie Li", "authors": "Jiqian Dong, Sikai Chen, Yujie Li, Runjia Du, Aaron Steinfeld, Samuel\n  Labi", "title": "Facilitating Connected Autonomous Vehicle Operations Using\n  Space-weighted Information Fusion and Deep Reinforcement Learning Based\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectivity aspect of connected autonomous vehicles (CAV) is beneficial\nbecause it facilitates dissemination of traffic-related information to vehicles\nthrough Vehicle-to-External (V2X) communication. Onboard sensing equipment\nincluding LiDAR and camera can reasonably characterize the traffic environment\nin the immediate locality of the CAV. However, their performance is limited by\ntheir sensor range (SR). On the other hand, longer-range information is helpful\nfor characterizing imminent conditions downstream. By contemporaneously\ncoalescing the short- and long-range information, the CAV can construct\ncomprehensively its surrounding environment and thereby facilitate informed,\nsafe, and effective movement planning in the short-term (local decisions\nincluding lane change) and long-term (route choice). In this paper, we describe\na Deep Reinforcement Learning based approach that integrates the data collected\nthrough sensing and connectivity capabilities from other vehicles located in\nthe proximity of the CAV and from those located further downstream, and we use\nthe fused data to guide lane changing, a specific context of CAV operations. In\naddition, recognizing the importance of the connectivity range (CR) to the\nperformance of not only the algorithm but also of the vehicle in the actual\ndriving environment, the paper carried out a case study. The case study\ndemonstrates the application of the proposed algorithm and duly identifies the\nappropriate CR for each level of prevailing traffic density. It is expected\nthat implementation of the algorithm in CAVs can enhance the safety and\nmobility associated with CAV driving operations. From a general perspective,\nits implementation can provide guidance to connectivity equipment manufacturers\nand CAV operators, regarding the default CR settings for CAVs or the\nrecommended CR setting in a given traffic environment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:38:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Dong", "Jiqian", ""], ["Chen", "Sikai", ""], ["Li", "Yujie", ""], ["Du", "Runjia", ""], ["Steinfeld", "Aaron", ""], ["Labi", "Samuel", ""]]}, {"id": "2009.14668", "submitter": "Che-Jui Chang", "authors": "Che-Jui Chang", "title": "Transfer Learning from Monolingual ASR to Transcription-free\n  Cross-lingual Voice Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual voice conversion (VC) is a task that aims to synthesize target\nvoices with the same content while source and target speakers speak in\ndifferent languages. Its challenge lies in the fact that the source and target\ndata are naturally non-parallel, and it is even difficult to bridge the gaps\nbetween languages with no transcriptions provided. In this paper, we focus on\nknowledge transfer from monolin-gual ASR to cross-lingual VC, in order to\naddress the con-tent mismatch problem. To achieve this, we first train a\nmonolingual acoustic model for the source language, use it to extract phonetic\nfeatures for all the speech in the VC dataset, and then train a Seq2Seq\nconversion model to pre-dict the mel-spectrograms. We successfully address\ncross-lingual VC without any transcription or language-specific knowledge for\nforeign speech. We experiment this on Voice Conversion Challenge 2020 datasets\nand show that our speaker-dependent conversion model outperforms the zero-shot\nbaseline, achieving MOS of 3.83 and 3.54 in speech quality and speaker\nsimilarity for cross-lingual conversion. When compared to Cascade ASR-TTS\nmethod, our proposed one significantly reduces the MOS drop be-tween intra- and\ncross-lingual conversion.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:44:35 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chang", "Che-Jui", ""]]}, {"id": "2009.14670", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat and Bogdan Gabrys", "title": "An Online Learning Algorithm for a Neuro-Fuzzy Classifier with\n  Mixed-Attribute Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  General fuzzy min-max neural network (GFMMNN) is one of the efficient\nneuro-fuzzy systems for data classification. However, one of the downsides of\nits original learning algorithms is the inability to handle and learn from the\nmixed-attribute data. While categorical features encoding methods can be used\nwith the GFMMNN learning algorithms, they exhibit a lot of shortcomings. Other\napproaches proposed in the literature are not suitable for on-line learning as\nthey require entire training data available in the learning phase. With the\nrapid change in the volume and velocity of streaming data in many application\nareas, it is increasingly required that the constructed models can learn and\nadapt to the continuous data changes in real-time without the need for their\nfull retraining or access to the historical data. This paper proposes an\nextended online learning algorithm for the GFMMNN. The proposed method can\nhandle the datasets with both continuous and categorical features. The\nextensive experiments confirmed superior and stable classification performance\nof the proposed approach in comparison to other relevant learning algorithms\nfor the GFMM model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:45:36 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2009.14679", "submitter": "Mark Gluzman", "authors": "Jiekun Feng, Mark Gluzman, J. G. Dai", "title": "Scalable Deep Reinforcement Learning for Ride-Hailing", "comments": null, "journal-ref": "IEEE Control Systems Letters, vol. 5, no. 6, pp. 2060-2065, 2021", "doi": "10.1109/LCSYS.2020.3046995", "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-hailing services, such as Didi Chuxing, Lyft, and Uber, arrange\nthousands of cars to meet ride requests throughout the day. We consider a\nMarkov decision process (MDP) model of a ride-hailing service system, framing\nit as a reinforcement learning (RL) problem. The simultaneous control of many\nagents (cars) presents a challenge for the MDP optimization because the action\nspace grows exponentially with the number of cars. We propose a special\ndecomposition for the MDP actions by sequentially assigning tasks to the\ndrivers. The new actions structure resolves the scalability problem and enables\nthe use of deep RL algorithms for control policy optimization. We demonstrate\nthe benefit of our proposed decomposition with a numerical experiment based on\nreal data from Didi Chuxing.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 20:07:12 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Feng", "Jiekun", ""], ["Gluzman", "Mark", ""], ["Dai", "J. G.", ""]]}, {"id": "2009.14695", "submitter": "Carlos Perales-Gonzalez", "authors": "Carlos Perales-Gonz\\'alez", "title": "Global convergence of Negative Correlation Extreme Learning Machine", "comments": "Jupyter Notebook associated in\n  https://github.com/cperales/pyridge/blob/ncelm/NCELM_convergence.ipynb", "journal-ref": "Neural Process Lett (2021)", "doi": "10.1007/s11063-021-10492-z", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble approaches introduced in the Extreme Learning Machine (ELM)\nliterature mainly come from methods that relies on data sampling procedures,\nunder the assumption that the training data are heterogeneously enough to set\nup diverse base learners. To overcome this assumption, it was proposed an ELM\nensemble method based on the Negative Correlation Learning (NCL) framework,\ncalled Negative Correlation Extreme Learning Machine (NCELM). This model works\nin two stages: i) different ELMs are generated as base learners with random\nweights in the hidden layer, and ii) a NCL penalty term with the information of\nthe ensemble prediction is introduced in each ELM minimization problem,\nupdating the base learners, iii) second step is iterated until the ensemble\nconverges.\n  Although this NCL ensemble method was validated by an experimental study with\nmultiple benchmark datasets, no information was given on the conditions about\nthis convergence. This paper mathematically presents the sufficient conditions\nto guarantee the global convergence of NCELM. The update of the ensemble in\neach iteration is defined as a contraction mapping function, and through Banach\ntheorem, global convergence of the ensemble is proved.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:18:10 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 09:18:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Perales-Gonz\u00e1lez", "Carlos", ""]]}, {"id": "2009.14701", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski, Xiao Yu Wang, and Alexander Wong", "title": "Where Does Trust Break Down? A Quantitative Trust Analysis of Deep\n  Neural Networks via Trust Matrix and Conditional Trust Densities", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances and successes in deep learning in recent years have led to\nconsiderable efforts and investments into its widespread ubiquitous adoption\nfor a wide variety of applications, ranging from personal assistants and\nintelligent navigation to search and product recommendation in e-commerce. With\nthis tremendous rise in deep learning adoption comes questions about the\ntrustworthiness of the deep neural networks that power these applications.\nMotivated to answer such questions, there has been a very recent interest in\ntrust quantification. In this work, we introduce the concept of trust matrix, a\nnovel trust quantification strategy that leverages the recently introduced\nquestion-answer trust metric by Wong et al. to provide deeper, more detailed\ninsights into where trust breaks down for a given deep neural network given a\nset of questions. More specifically, a trust matrix defines the expected\nquestion-answer trust for a given actor-oracle answer scenario, allowing one to\nquickly spot areas of low trust that needs to be addressed to improve the\ntrustworthiness of a deep neural network. The proposed trust matrix is simple\nto calculate, humanly interpretable, and to the best of the authors' knowledge\nis the first to study trust at the actor-oracle answer level. We further extend\nthe concept of trust densities with the notion of conditional trust densities.\nWe experimentally leverage trust matrices to study several well-known deep\nneural network architectures for image recognition, and further study the trust\ndensity and conditional trust densities for an interesting actor-oracle answer\nscenario. The results illustrate that trust matrices, along with conditional\ntrust densities, can be useful tools in addition to the existing suite of trust\nquantification metrics for guiding practitioners and regulators in creating and\ncertifying deep learning solutions for trusted operation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:33:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wang", "Xiao Yu", ""], ["Wong", "Alexander", ""]]}, {"id": "2009.14702", "submitter": "Vincent Gripon", "authors": "Vincent Gripon, Matthias L\\\"owe, Franck Vermet", "title": "Some Remarks on Replicated Simulated Annealing", "comments": null, "journal-ref": null, "doi": "10.1007/s10955-021-02727-z", "report-no": null, "categories": "cs.LG cs.NE math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently authors have introduced the idea of training discrete weights neural\nnetworks using a mix between classical simulated annealing and a replica ansatz\nknown from the statistical physics literature. Among other points, they claim\ntheir method is able to find robust configurations. In this paper, we analyze\nthis so-called \"replicated simulated annealing\" algorithm. In particular, we\nexplicit criteria to guarantee its convergence, and study when it successfully\nsamples from configurations. We also perform experiments using synthetic and\nreal data bases.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:33:53 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:41:03 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gripon", "Vincent", ""], ["L\u00f6we", "Matthias", ""], ["Vermet", "Franck", ""]]}, {"id": "2009.14711", "submitter": "Mel Vecerik", "authors": "Mel Vecerik, Jean-Baptiste Regli, Oleg Sushkov, David Barker, Rugile\n  Pevceviciute, Thomas Roth\\\"orl, Christopher Schuster, Raia Hadsell, Lourdes\n  Agapito, Jonathan Scholz", "title": "S3K: Self-Supervised Semantic Keypoints for Robotic Manipulation via\n  Multi-View Consistency", "comments": "11 pages, supplementary material available at:\n  https://sites.google.com/view/2020-s3k/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot's ability to act is fundamentally constrained by what it can\nperceive. Many existing approaches to visual representation learning utilize\ngeneral-purpose training criteria, e.g. image reconstruction, smoothness in\nlatent space, or usefulness for control, or else make use of large datasets\nannotated with specific features (bounding boxes, segmentations, etc.).\nHowever, both approaches often struggle to capture the fine-detail required for\nprecision tasks on specific objects, e.g. grasping and mating a plug and\nsocket. We argue that these difficulties arise from a lack of geometric\nstructure in these models. In this work we advocate semantic 3D keypoints as a\nvisual representation, and present a semi-supervised training objective that\ncan allow instance or category-level keypoints to be trained to 1-5\nmillimeter-accuracy with minimal supervision. Furthermore, unlike local\ntexture-based approaches, our model integrates contextual information from a\nlarge area and is therefore robust to occlusion, noise, and lack of discernible\ntexture. We demonstrate that this ability to locate semantic keypoints enables\nhigh level scripting of human understandable behaviours. Finally we show that\nthese keypoints provide a good way to define reward functions for reinforcement\nlearning and are a good representation for training agents.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:44:54 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 10:42:41 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Vecerik", "Mel", ""], ["Regli", "Jean-Baptiste", ""], ["Sushkov", "Oleg", ""], ["Barker", "David", ""], ["Pevceviciute", "Rugile", ""], ["Roth\u00f6rl", "Thomas", ""], ["Schuster", "Christopher", ""], ["Hadsell", "Raia", ""], ["Agapito", "Lourdes", ""], ["Scholz", "Jonathan", ""]]}, {"id": "2009.14712", "submitter": "Mathis Hoffmann", "authors": "Mathis Hoffmann, Claudia Buerhop-Lutz, Luca Reeb, Tobias Pickel, Thilo\n  Winkler, Bernd Doll, Tobias W\\\"urfl, Ian Marius Peters, Christoph Brabec,\n  Andreas Maier and Vincent Christlein", "title": "Deep Learning-based Pipeline for Module Power Prediction from EL\n  Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated inspection plays an important role in monitoring large-scale\nphotovoltaic power plants. Commonly, electroluminescense measurements are used\nto identify various types of defects on solar modules but have not been used to\ndetermine the power of a module. However, knowledge of the power at maximum\npower point is important as well, since drops in the power of a single module\ncan affect the performance of an entire string. By now, this is commonly\ndetermined by measurements that require to discontact or even dismount the\nmodule, rendering a regular inspection of individual modules infeasible. In\nthis work, we bridge the gap between electroluminescense measurements and the\npower determination of a module. We compile a large dataset of 719\nelectroluminescense measurementsof modules at various stages of degradation,\nespecially cell cracks and fractures, and the corresponding power at maximum\npower point. Here,we focus on inactive regions and cracks as the predominant\ntype of defect. We set up a baseline regression model to predict the power from\nelectroluminescense measurements with a mean absolute error of 9.0+/-3.7$W_P$\n(4.0+/-8.4%). Then, we show that deep-learning can be used to train a model\nthat performs significantly better (7.3+/-2.7$W_P$ or 3.2+/-6.5%) and propose a\nvariant of class activation maps to obtain the per cell power loss, as\npredicted by the model. With this work, we aim to open a new research topic.\nTherefore, we publicly release the dataset, the code and trained models to\nempower other researchers to compare against our results. Finally, we present a\nthorough evaluation of certain boundary conditions like the dataset size and an\nautomated preprocessing pipeline for on-site measurements showing multiple\nmodules at once.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:46:47 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 10:25:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hoffmann", "Mathis", ""], ["Buerhop-Lutz", "Claudia", ""], ["Reeb", "Luca", ""], ["Pickel", "Tobias", ""], ["Winkler", "Thilo", ""], ["Doll", "Bernd", ""], ["W\u00fcrfl", "Tobias", ""], ["Peters", "Ian Marius", ""], ["Brabec", "Christoph", ""], ["Maier", "Andreas", ""], ["Christlein", "Vincent", ""]]}, {"id": "2009.14720", "submitter": "Huanrui Yang", "authors": "Huanrui Yang, Jingyang Zhang, Hongliang Dong, Nathan Inkawhich, Andrew\n  Gardner, Andrew Touchet, Wesley Wilkes, Heath Berry, Hai Li", "title": "DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of\n  Ensembles", "comments": "To be appeared in NeurIPS 2020 conference (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research finds CNN models for image classification demonstrate\noverlapped adversarial vulnerabilities: adversarial attacks can mislead CNN\nmodels with small perturbations, which can effectively transfer between\ndifferent models trained on the same dataset. Adversarial training, as a\ngeneral robustness improvement technique, eliminates the vulnerability in a\nsingle model by forcing it to learn robust features. The process is hard, often\nrequires models with large capacity, and suffers from significant loss on clean\ndata accuracy. Alternatively, ensemble methods are proposed to induce\nsub-models with diverse outputs against a transfer adversarial example, making\nthe ensemble robust against transfer attacks even if each sub-model is\nindividually non-robust. Only small clean accuracy drop is observed in the\nprocess. However, previous ensemble training methods are not efficacious in\ninducing such diversity and thus ineffective on reaching robust ensemble. We\npropose DVERGE, which isolates the adversarial vulnerability in each sub-model\nby distilling non-robust features, and diversifies the adversarial\nvulnerability to induce diverse outputs against a transfer attack. The novel\ndiversity metric and training procedure enables DVERGE to achieve higher\nrobustness against transfer attacks comparing to previous ensemble methods, and\nenables the improved robustness when more sub-models are added to the ensemble.\nThe code of this work is available at https://github.com/zjysteven/DVERGE\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:57:35 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 16:35:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yang", "Huanrui", ""], ["Zhang", "Jingyang", ""], ["Dong", "Hongliang", ""], ["Inkawhich", "Nathan", ""], ["Gardner", "Andrew", ""], ["Touchet", "Andrew", ""], ["Wilkes", "Wesley", ""], ["Berry", "Heath", ""], ["Li", "Hai", ""]]}, {"id": "2009.14722", "submitter": "Guoqing Luo", "authors": "Guoqing Luo, Jiaxin Pan, Min Peng", "title": "RDSGAN: Rank-based Distant Supervision Relation Extraction with\n  Generative Adversarial Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision has been widely used for relation extraction but suffers\nfrom noise labeling problem. Neural network models are proposed to denoise with\nattention mechanism but cannot eliminate noisy data due to its non-zero\nweights. Hard decision is proposed to remove wrongly-labeled instances from the\npositive set though causes loss of useful information contained in removed\ninstances. In this paper, we propose a novel generative neural framework named\nRDSGAN (Rank-based Distant Supervision GAN) which automatically generates valid\ninstances for distant supervision relation extraction. Our framework combines\nsoft attention and hard decision to learn the distribution of true positive\ninstances via adversarial training and selects valid instances conforming to\nthe distribution via rank-based distant supervision, which addresses the false\npositive problem. Experimental results show the superiority of our framework\nover strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:59:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Luo", "Guoqing", ""], ["Pan", "Jiaxin", ""], ["Peng", "Min", ""]]}, {"id": "2009.14730", "submitter": "Fang-Yi Yu", "authors": "Grant Schoenebeck and Fang-Yi Yu", "title": "Learning and Strongly Truthful Multi-Task Peer Prediction: A Variational\n  Approach", "comments": "39 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer prediction mechanisms incentivize agents to truthfully report their\nsignals even in the absence of verification by comparing agents' reports with\nthose of their peers. In the detail-free multi-task setting, agents respond to\nmultiple independent and identically distributed tasks, and the mechanism does\nnot know the prior distribution of agents' signals. The goal is to provide an\n$\\epsilon$-strongly truthful mechanism where truth-telling rewards agents\n\"strictly\" more than any other strategy profile (with $\\epsilon$ additive\nerror), and to do so while requiring as few tasks as possible. We design a\nfamily of mechanisms with a scoring function that maps a pair of reports to a\nscore. The mechanism is strongly truthful if the scoring function is \"prior\nideal,\" and $\\epsilon$-strongly truthful as long as the scoring function is\nsufficiently close to the ideal one. This reduces the above mechanism design\nproblem to a learning problem -- specifically learning an ideal scoring\nfunction. We leverage this reduction to obtain the following three results. 1)\nWe show how to derive good bounds on the number of tasks required for different\ntypes of priors. Our reduction applies to myriad continuous signal space\nsettings. This is the first peer-prediction mechanism on continuous signals\ndesigned for the multi-task setting. 2) We show how to turn a soft-predictor of\nan agent's signals (given the other agents' signals) into a mechanism. This\nallows the practical use of machine learning algorithms that give good results\neven when many agents provide noisy information. 3) For finite signal spaces,\nwe obtain $\\epsilon$-strongly truthful mechanisms on any stochastically\nrelevant prior, which is the maximal possible prior. In contrast, prior work\nonly achieves a weaker notion of truthfulness (informed truthfulness) or\nrequires stronger assumptions on the prior.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:09:56 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Schoenebeck", "Grant", ""], ["Yu", "Fang-Yi", ""]]}, {"id": "2009.14737", "submitter": "Keyu Tian", "authors": "Keyu Tian, Chen Lin, Ming Sun, Luping Zhou, Junjie Yan, Wanli Ouyang", "title": "Improving Auto-Augment via Augmentation-Wise Weight Sharing", "comments": "Accepted to NeurIPS 2020 (Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress on automatically searching augmentation policies has\nboosted the performance substantially for various tasks. A key component of\nautomatic augmentation search is the evaluation process for a particular\naugmentation policy, which is utilized to return reward and usually runs\nthousands of times. A plain evaluation process, which includes full model\ntraining and validation, would be time-consuming. To achieve efficiency, many\nchoose to sacrifice evaluation reliability for speed. In this paper, we dive\ninto the dynamics of augmented training of the model. This inspires us to\ndesign a powerful and efficient proxy task based on the Augmentation-Wise\nWeight Sharing (AWS) to form a fast yet accurate evaluation process in an\nelegant way. Comprehensive analysis verifies the superiority of this approach\nin terms of effectiveness and efficiency. The augmentation policies found by\nour method achieve superior accuracies compared with existing auto-augmentation\nsearch methods. On CIFAR-10, we achieve a top-1 error rate of 1.24%, which is\ncurrently the best performing single model without extra training data. On\nImageNet, we get a top-1 error rate of 20.36% for ResNet-50, which leads to\n3.34% absolute error rate reduction over the baseline augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:23:12 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 15:12:47 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tian", "Keyu", ""], ["Lin", "Chen", ""], ["Sun", "Ming", ""], ["Zhou", "Luping", ""], ["Yan", "Junjie", ""], ["Ouyang", "Wanli", ""]]}, {"id": "2009.14738", "submitter": "Yulong Pei", "authors": "Yulong Pei, Tianjin Huang, Werner van Ipenburg, Mykola Pechenizkiy", "title": "ResGCN: Attention-based Deep Residual Modeling for Anomaly Detection on\n  Attributed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively detecting anomalous nodes in attributed networks is crucial for\nthe success of many real-world applications such as fraud and intrusion\ndetection. Existing approaches have difficulties with three major issues:\nsparsity and nonlinearity capturing, residual modeling, and network smoothing.\nWe propose Residual Graph Convolutional Network (ResGCN), an attention-based\ndeep residual modeling approach that can tackle these issues: modeling the\nattributed networks with GCN allows to capture the sparsity and nonlinearity;\nutilizing a deep neural network allows to directly learn residual from the\ninput, and a residual-based attention mechanism reduces the adverse effect from\nanomalous nodes and prevents over-smoothing. Extensive experiments on several\nreal-world attributed networks demonstrate the effectiveness of ResGCN in\ndetecting anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:24:51 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pei", "Yulong", ""], ["Huang", "Tianjin", ""], ["van Ipenburg", "Werner", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2009.14774", "submitter": "Gleb Novikov", "authors": "Tommaso d'Orsi, Gleb Novikov, David Steurer", "title": "Consistent regression when oblivious outliers overwhelm", "comments": "To appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a robust linear regression model $y=X\\beta^* + \\eta$, where an\nadversary oblivious to the design $X\\in \\mathbb{R}^{n\\times d}$ may choose\n$\\eta$ to corrupt all but an $\\alpha$ fraction of the observations $y$ in an\narbitrary way. Prior to our work, even for Gaussian $X$, no estimator for\n$\\beta^*$ was known to be consistent in this model except for quadratic sample\nsize $n \\gtrsim (d/\\alpha)^2$ or for logarithmic inlier fraction $\\alpha\\ge\n1/\\log n$. We show that consistent estimation is possible with nearly linear\nsample size and inverse-polynomial inlier fraction. Concretely, we show that\nthe Huber loss estimator is consistent for every sample size $n=\n\\omega(d/\\alpha^2)$ and achieves an error rate of $O(d/\\alpha^2n)^{1/2}$. Both\nbounds are optimal (up to constant factors). Our results extend to designs far\nbeyond the Gaussian case and only require the column span of $X$ to not contain\napproximately sparse vectors). (similar to the kind of assumption commonly made\nabout the kernel space for compressed sensing). We provide two technically\nsimilar proofs. One proof is phrased in terms of strong convexity, extending\nwork of [Tsakonas et al.'14], and particularly short. The other proof\nhighlights a connection between the Huber loss estimator and high-dimensional\nmedian computations. In the special case of Gaussian designs, this connection\nleads us to a strikingly simple algorithm based on computing coordinate-wise\nmedians that achieves optimal guarantees in nearly-linear time, and that can\nexploit sparsity of $\\beta^*$. The model studied here also captures\nheavy-tailed noise distributions that may not even have a first moment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:21:34 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 17:20:11 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["d'Orsi", "Tommaso", ""], ["Novikov", "Gleb", ""], ["Steurer", "David", ""]]}, {"id": "2009.14775", "submitter": "Neng Wan", "authors": "Neng Wan, Aditya Gahlawat, Naira Hovakimyan, Evangelos A. Theodorou,\n  and Petros G. Voulgaris", "title": "Cooperative Path Integral Control for Stochastic Multi-Agent Systems", "comments": "To appear in American Control Conference 2021, New Orleans, LA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed stochastic optimal control solution is presented for\ncooperative multi-agent systems. The network of agents is partitioned into\nmultiple factorial subsystems, each of which consists of a central agent and\nneighboring agents. Local control actions that rely only on agents' local\nobservations are designed to optimize the joint cost functions of subsystems.\nWhen solving for the local control actions, the joint optimality equation for\neach subsystem is cast as a linear partial differential equation and solved\nusing the Feynman-Kac formula. The solution and the optimal control action are\nthen formulated as path integrals and approximated by a Monte-Carlo method.\nNumerical verification is provided through a simulation example consisting of a\nteam of cooperative UAVs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:24:14 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 03:28:03 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wan", "Neng", ""], ["Gahlawat", "Aditya", ""], ["Hovakimyan", "Naira", ""], ["Theodorou", "Evangelos A.", ""], ["Voulgaris", "Petros G.", ""]]}, {"id": "2009.14776", "submitter": "Ting Yao", "authors": "Qi Cai and Yu Wang and Yingwei Pan and Ting Yao and Tao Mei", "title": "Joint Contrastive Learning with Infinite Possibilities", "comments": "NeurIPS 2020 Spotlight; Code is publicly available at:\n  https://github.com/caiqi/Joint-Contrastive-Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores useful modifications of the recent development in\ncontrastive learning via novel probabilistic modeling. We derive a particular\nform of contrastive loss named Joint Contrastive Learning (JCL). JCL implicitly\ninvolves the simultaneous learning of an infinite number of query-key pairs,\nwhich poses tighter constraints when searching for invariant features. We\nderive an upper bound on this formulation that allows analytical solutions in\nan end-to-end training manner. While JCL is practically effective in numerous\ncomputer vision applications, we also theoretically unveil the certain\nmechanisms that govern the behavior of JCL. We demonstrate that the proposed\nformulation harbors an innate agency that strongly favors similarity within\neach instance-specific class, and therefore remains advantageous when searching\nfor discriminative features among distinct instances. We evaluate these\nproposals on multiple benchmarks, demonstrating considerable improvements over\nexisting algorithms. Code is publicly available at:\nhttps://github.com/caiqi/Joint-Contrastive-Learning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:24:21 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 13:27:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cai", "Qi", ""], ["Wang", "Yu", ""], ["Pan", "Yingwei", ""], ["Yao", "Ting", ""], ["Mei", "Tao", ""]]}, {"id": "2009.14783", "submitter": "Yifan Ding", "authors": "Yifan Ding, Nicholas Botzer and Tim Weninger", "title": "HetSeq: Distributed GPU Training on Heterogeneous Infrastructure", "comments": "7 pages, 3 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning systems like PyTorch and Tensorflow are able to train\nenormous models with billions (or trillions) of parameters on a distributed\ninfrastructure. These systems require that the internal nodes have the same\nmemory capacity and compute performance. Unfortunately, most organizations,\nespecially universities, have a piecemeal approach to purchasing computer\nsystems resulting in a heterogeneous infrastructure, which cannot be used to\ncompute large models. The present work describes HetSeq, a software package\nadapted from the popular PyTorch package that provides the capability to train\nlarge neural network models on heterogeneous infrastructure. Experiments with\ntransformer translation and BERT language model shows that HetSeq scales over\nheterogeneous systems. HetSeq can be easily extended to other models like image\nclassification. Package with supported document is publicly available at\nhttps://github.com/yifding/hetseq.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:57:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ding", "Yifan", ""], ["Botzer", "Nicholas", ""], ["Weninger", "Tim", ""]]}, {"id": "2009.14786", "submitter": "Nicolas Gontier", "authors": "Nicolas Gontier and Koustuv Sinha and Siva Reddy and Christopher Pal", "title": "Measuring Systematic Generalization in Neural Proof Generation with\n  Transformers", "comments": "NeurIPS 2020; 17 pages; 9 figures; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in understanding how well Transformer language models\n(TLMs) can perform reasoning tasks when trained on knowledge encoded in the\nform of natural language. We investigate their systematic generalization\nabilities on a logical reasoning task in natural language, which involves\nreasoning over relationships between entities grounded in first-order logical\nproofs. Specifically, we perform soft theorem-proving by leveraging TLMs to\ngenerate natural language proofs. We test the generated proofs for logical\nconsistency, along with the accuracy of the final inference. We observe\nlength-generalization issues when evaluated on longer-than-trained sequences.\nHowever, we observe TLMs improve their generalization performance after being\nexposed to longer, exhaustive proofs. In addition, we discover that TLMs are\nable to generalize better using backward-chaining proofs compared to their\nforward-chaining counterparts, while they find it easier to generate forward\nchaining proofs. We observe that models that are not trained to generate proofs\nare better at generalizing to problems based on longer proofs. This suggests\nthat Transformers have efficient internal reasoning strategies that are harder\nto interpret. These results highlight the systematic generalization behavior of\nTLMs in the context of logical reasoning, and we believe this work motivates\ndeeper inspection of their underlying reasoning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:54:37 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:31:11 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gontier", "Nicolas", ""], ["Sinha", "Koustuv", ""], ["Reddy", "Siva", ""], ["Pal", "Christopher", ""]]}, {"id": "2009.14788", "submitter": "Matteo Ronchetti", "authors": "Matteo Ronchetti", "title": "TorchRadon: Fast Differentiable Routines for Computed Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents TorchRadon -- an open source CUDA library which contains a\nset of differentiable routines for solving computed tomography (CT)\nreconstruction problems. The library is designed to help researchers working on\nCT problems to combine deep learning and model-based approaches. The package is\ndeveloped as a PyTorch extension and can be seamlessly integrated into existing\ndeep learning training code. Compared to the existing Astra Toolbox, TorchRadon\nis up to 125 faster. The operators implemented by TorchRadon allow the\ncomputation of gradients using PyTorch backward(), and can therefore be easily\ninserted inside existing neural networks architectures. Because of its speed\nand GPU support, TorchRadon can also be effectively used as a fast backend for\nthe implementation of iterative algorithms. This paper presents the main\nfunctionalities of the library, compares results with existing libraries and\nprovides examples of usage.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:20:22 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ronchetti", "Matteo", ""]]}, {"id": "2009.14794", "submitter": "Xingyou Song", "authors": "Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou\n  Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz\n  Mohiuddin, Lukasz Kaiser, David Belanger, Lucy Colwell, Adrian Weller", "title": "Rethinking Attention with Performers", "comments": "Published as a conference paper + oral presentation at ICLR 2021. 38\n  pages. See\n  https://github.com/google-research/google-research/tree/master/protein_lm for\n  protein language model code, and\n  https://github.com/google-research/google-research/tree/master/performer for\n  Performer code. See\n  https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html\n  for Google AI Blog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Performers, Transformer architectures which can estimate regular\n(softmax) full-rank-attention Transformers with provable accuracy, but using\nonly linear (as opposed to quadratic) space and time complexity, without\nrelying on any priors such as sparsity or low-rankness. To approximate softmax\nattention-kernels, Performers use a novel Fast Attention Via positive\nOrthogonal Random features approach (FAVOR+), which may be of independent\ninterest for scalable kernel methods. FAVOR+ can be also used to efficiently\nmodel kernelizable attention mechanisms beyond softmax. This representational\npower is crucial to accurately compare softmax with other kernels for the first\ntime on large-scale tasks, beyond the reach of regular Transformers, and\ninvestigate optimal attention-kernels. Performers are linear architectures\nfully compatible with regular Transformers and with strong theoretical\nguarantees: unbiased or nearly-unbiased estimation of the attention matrix,\nuniform convergence and low estimation variance. We tested Performers on a rich\nset of tasks stretching from pixel-prediction through text models to protein\nsequence modeling. We demonstrate competitive results with other examined\nefficient sparse and dense attention methods, showcasing effectiveness of the\nnovel attention-learning paradigm leveraged by Performers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:09:09 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 21:40:24 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 16:26:47 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Likhosherstov", "Valerii", ""], ["Dohan", "David", ""], ["Song", "Xingyou", ""], ["Gane", "Andreea", ""], ["Sarlos", "Tamas", ""], ["Hawkins", "Peter", ""], ["Davis", "Jared", ""], ["Mohiuddin", "Afroz", ""], ["Kaiser", "Lukasz", ""], ["Belanger", "David", ""], ["Colwell", "Lucy", ""], ["Weller", "Adrian", ""]]}, {"id": "2009.14799", "submitter": "Carson Eisenach", "authors": "Carson Eisenach and Yagna Patel and Dhruv Madeka", "title": "MQTransformer: Multi-Horizon Forecasts with Context Dependent and\n  Feedback-Aware Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural forecasting have produced major improvements in\naccuracy for probabilistic demand prediction. In this work, we propose novel\nimprovements to the current state of the art by incorporating changes inspired\nby recent advances in Transformer architectures for Natural Language\nProcessing. We develop a novel decoder-encoder attention for context-alignment,\nimproving forecasting accuracy by allowing the network to study its own history\nbased on the context for which it is producing a forecast. We also present a\nnovel positional encoding that allows the neural network to learn\ncontext-dependent seasonality functions as well as arbitrary holiday distances.\nFinally we show that the current state of the art MQ-Forecaster (Wen et al.,\n2017) models display excess variability by failing to leverage previous errors\nin the forecast to improve accuracy. We propose a novel decoder-self attention\nscheme for forecasting that produces significant improvements in the excess\nvariation of the forecast.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:12:46 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 23:06:45 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 21:14:11 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Eisenach", "Carson", ""], ["Patel", "Yagna", ""], ["Madeka", "Dhruv", ""]]}, {"id": "2009.14820", "submitter": "Tanner Fiez", "authors": "Tanner Fiez, Lillian Ratliff", "title": "Gradient Descent-Ascent Provably Converges to Strict Local Minmax\n  Equilibria with a Finite Timescale Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role that a finite timescale separation parameter $\\tau$ has on\ngradient descent-ascent in two-player non-convex, non-concave zero-sum games\nwhere the learning rate of player 1 is denoted by $\\gamma_1$ and the learning\nrate of player 2 is defined to be $\\gamma_2=\\tau\\gamma_1$. Existing work\nanalyzing the role of timescale separation in gradient descent-ascent has\nprimarily focused on the edge cases of players sharing a learning rate ($\\tau\n=1$) and the maximizing player approximately converging between each update of\nthe minimizing player ($\\tau \\rightarrow \\infty$). For the parameter choice of\n$\\tau=1$, it is known that the learning dynamics are not guaranteed to converge\nto a game-theoretically meaningful equilibria in general. In contrast, Jin et\nal. (2020) showed that the stable critical points of gradient descent-ascent\ncoincide with the set of strict local minmax equilibria as\n$\\tau\\rightarrow\\infty$. In this work, we bridge the gap between past work by\nshowing there exists a finite timescale separation parameter $\\tau^{\\ast}$ such\nthat $x^{\\ast}$ is a stable critical point of gradient descent-ascent for all\n$\\tau \\in (\\tau^{\\ast}, \\infty)$ if and only if it is a strict local minmax\nequilibrium. Moreover, we provide an explicit construction for computing\n$\\tau^{\\ast}$ along with corresponding convergence rates and results under\ndeterministic and stochastic gradient feedback. The convergence results we\npresent are complemented by a non-convergence result: given a critical point\n$x^{\\ast}$ that is not a strict local minmax equilibrium, then there exists a\nfinite timescale separation $\\tau_0$ such that $x^{\\ast}$ is unstable for all\n$\\tau\\in (\\tau_0, \\infty)$. Finally, we empirically demonstrate on the CIFAR-10\nand CelebA datasets the significant impact timescale separation has on training\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:51:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Fiez", "Tanner", ""], ["Ratliff", "Lillian", ""]]}, {"id": "2009.14822", "submitter": "Ikhyun Cho", "authors": "Ikhyun Cho, U Kang", "title": "Pea-KD: Parameter-efficient and Accurate Knowledge Distillation on BERT", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently compress a model while maintaining its performance?\nKnowledge Distillation (KD) is one of the widely known methods for model\ncompression. In essence, KD trains a smaller student model based on a larger\nteacher model and tries to retain the teacher model's level of performance as\nmuch as possible. However, existing KD methods suffer from the following\nlimitations. First, since the student model is smaller in absolute size, it\ninherently lacks model capacity. Second, the absence of an initial guide for\nthe student model makes it difficult for the student to imitate the teacher\nmodel to its fullest. Conventional KD methods yield low performance due to\nthese limitations. In this paper, we propose Pea-KD (Parameter-efficient and\naccurate Knowledge Distillation), a novel approach to KD. Pea-KD consists of\ntwo main parts: Shuffled Parameter Sharing (SPS) and Pretraining with Teacher's\nPredictions (PTP). Using this combination, we are capable of alleviating the\nKD's limitations. SPS is a new parameter sharing method that increases the\nstudent model capacity. PTP is a KD-specialized initialization method, which\ncan act as a good initial guide for the student. When combined, this method\nyields a significant increase in student model's performance. Experiments\nconducted on BERT with different datasets and tasks show that the proposed\napproach improves the student model's performance by 4.4\\% on average in four\nGLUE tasks, outperforming existing KD baselines by significant margins.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:52:15 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 09:43:34 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cho", "Ikhyun", ""], ["Kang", "U", ""]]}, {"id": "2009.14825", "submitter": "Natalia Ares", "authors": "V. Nguyen, S.B. Orbell, D.T. Lennon, H. Moon, F. Vigneau, L.C.\n  Camenzind, L. Yu, D.M. Zumb\\\"uhl, G.A.D. Briggs, M.A. Osborne, D. Sejdinovic,\n  and N. Ares", "title": "Deep Reinforcement Learning for Efficient Measurement of Quantum Devices", "comments": null, "journal-ref": null, "doi": "10.1038/s41534-021-00434-x", "report-no": null, "categories": "cond-mat.mes-hall cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is an emerging machine learning approach which\ncan teach a computer to learn from their actions and rewards similar to the way\nhumans learn from experience. It offers many advantages in automating decision\nprocesses to navigate large parameter spaces. This paper proposes a novel\napproach to the efficient measurement of quantum devices based on deep\nreinforcement learning. We focus on double quantum dot devices, demonstrating\nthe fully automatic identification of specific transport features called bias\ntriangles. Measurements targeting these features are difficult to automate,\nsince bias triangles are found in otherwise featureless regions of the\nparameter space. Our algorithm identifies bias triangles in a mean time of less\nthan 30 minutes, and sometimes as little as 1 minute. This approach, based on\ndueling deep Q-networks, can be adapted to a broad range of devices and target\ntransport features. This is a crucial demonstration of the utility of deep\nreinforcement learning for decision making in the measurement and operation of\nquantum devices.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:55:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Nguyen", "V.", ""], ["Orbell", "S. B.", ""], ["Lennon", "D. T.", ""], ["Moon", "H.", ""], ["Vigneau", "F.", ""], ["Camenzind", "L. C.", ""], ["Yu", "L.", ""], ["Zumb\u00fchl", "D. M.", ""], ["Briggs", "G. A. D.", ""], ["Osborne", "M. A.", ""], ["Sejdinovic", "D.", ""], ["Ares", "N.", ""]]}]