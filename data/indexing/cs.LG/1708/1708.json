[{"id": "1708.00002", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Gautam Kamath, John Wright", "title": "Which Distribution Distances are Sublinearly Testable?", "comments": "To appear in SODA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given samples from an unknown distribution $p$ and a description of a\ndistribution $q$, are $p$ and $q$ close or far? This question of \"identity\ntesting\" has received significant attention in the case of testing whether $p$\nand $q$ are equal or far in total variation distance. However, in recent work,\nthe following questions have been been critical to solving problems at the\nfrontiers of distribution testing:\n  -Alternative Distances: Can we test whether $p$ and $q$ are far in other\ndistances, say Hellinger?\n  -Tolerance: Can we test when $p$ and $q$ are close, rather than equal? And if\nso, close in which distances?\n  Motivated by these questions, we characterize the complexity of distribution\ntesting under a variety of distances, including total variation, $\\ell_2$,\nHellinger, Kullback-Leibler, and $\\chi^2$. For each pair of distances $d_1$ and\n$d_2$, we study the complexity of testing if $p$ and $q$ are close in $d_1$\nversus far in $d_2$, with a focus on identifying which problems allow strongly\nsublinear testers (i.e., those with complexity $O(n^{1 - \\gamma})$ for some\n$\\gamma > 0$ where $n$ is the size of the support of the distributions $p$ and\n$q$). We provide matching upper and lower bounds for each case. We also study\nthese questions in the case where we only have samples from $q$ (equivalence\ntesting), showing qualitative differences from identity testing in terms of\nwhen tolerance can be achieved. Our algorithms fall into the classical paradigm\nof $\\chi^2$-statistics, but require crucial changes to handle the challenges\nintroduced by each distance we consider. Finally, we survey other recent\nresults in an attempt to serve as a reference for the complexity of various\ndistribution testing problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 18:00:00 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 02:44:14 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Kamath", "Gautam", ""], ["Wright", "John", ""]]}, {"id": "1708.00049", "submitter": "Richard Phillips", "authors": "Richard L. Phillips, Kyu Hyun Chang and Sorelle A. Friedler", "title": "Interpretable Active Learning", "comments": "13 pages, 8 figures, presented at 2018 Conference on Fairness,\n  Accountability, and Transparency (FAT*), New York, New York, USA. Proceedings\n  of the 1st Conference on Fairness, Accountability and Transparency, PMLR\n  81:49-61, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning has long been a topic of study in machine learning. However,\nas increasingly complex and opaque models have become standard practice, the\nprocess of active learning, too, has become more opaque. There has been little\ninvestigation into interpreting what specific trends and patterns an active\nlearning strategy may be exploring. This work expands on the Local\nInterpretable Model-agnostic Explanations framework (LIME) to provide\nexplanations for active learning recommendations. We demonstrate how LIME can\nbe used to generate locally faithful explanations for an active learning\nstrategy, and how these explanations can be used to understand how different\nmodels and datasets explore a problem space over time. In order to quantify the\nper-subgroup differences in how an active learning strategy queries spatial\nregions, we introduce a notion of uncertainty bias (based on disparate impact)\nto measure the discrepancy in the confidence for a model's predictions between\none subgroup and another. Using the uncertainty bias measure, we show that our\nquery explanations accurately reflect the subgroup focus of the active learning\nqueries, allowing for an interpretable explanation of what is being learned as\npoints with similar sources of uncertainty have their uncertainty bias\nresolved. We demonstrate that this technique can be applied to track\nuncertainty bias over user-defined clusters or automatically generated clusters\nbased on the source of uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 19:46:59 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 02:45:50 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Phillips", "Richard L.", ""], ["Chang", "Kyu Hyun", ""], ["Friedler", "Sorelle A.", ""]]}, {"id": "1708.00052", "submitter": "Evgenii Zheltonozhskii", "authors": "Chaim Baskin, Natan Liss, Evgenii Zheltonozhskii, Alex M. Bronshtein,\n  Avi Mendelson", "title": "Streaming Architecture for Large-Scale Quantized Neural Networks on an\n  FPGA-Based Dataflow Platform", "comments": "Will appear in RAW 2018", "journal-ref": null, "doi": "10.1109/IPDPSW.2018.00032", "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are used by different applications that are\nexecuted on a range of computer architectures, from IoT devices to\nsupercomputers. The footprint of these networks is huge as well as their\ncomputational and communication needs. In order to ease the pressure on\nresources, research indicates that in many cases a low precision representation\n(1-2 bit per parameter) of weights and other parameters can achieve similar\naccuracy while requiring less resources. Using quantized values enables the use\nof FPGAs to run NNs, since FPGAs are well fitted to these primitives; e.g.,\nFPGAs provide efficient support for bitwise operations and can work with\narbitrary-precision representation of numbers.\n  This paper presents a new streaming architecture for running QNNs on FPGAs.\nThe proposed architecture scales out better than alternatives, allowing us to\ntake advantage of systems with multiple FPGAs. We also included support for\nskip connections, that are used in state-of-the art NNs, and shown that our\narchitecture allows to add those connections almost for free. All this allowed\nus to implement an 18-layer ResNet for 224x224 images classification, achieving\n57.5% top-1 accuracy.\n  In addition, we implemented a full-sized quantized AlexNet. In contrast to\nprevious works, we use 2-bit activations instead of 1-bit ones, which improves\nAlexNet's top-1 accuracy from 41.8% to 51.03% for the ImageNet classification.\nBoth AlexNet and ResNet can handle 1000-class real-time classification on an\nFPGA.\n  Our implementation of ResNet-18 consumes 5x less power and is 4x slower for\nImageNet, when compared to the same NN on the latest Nvidia GPUs. Smaller NNs,\nthat fit a single FPGA, are running faster then on GPUs on small (32x32)\ninputs, while consuming up to 20x less energy and power.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 19:53:48 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 11:44:36 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 13:20:13 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Baskin", "Chaim", ""], ["Liss", "Natan", ""], ["Zheltonozhskii", "Evgenii", ""], ["Bronshtein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1708.00059", "submitter": "Min Ye", "authors": "Min Ye and Alexander Barg", "title": "Asymptotically optimal private estimation under mean square loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimax estimation problem of a discrete distribution with\nsupport size $k$ under locally differential privacy constraints. A\nprivatization scheme is applied to each raw sample independently, and we need\nto estimate the distribution of the raw samples from the privatized samples. A\npositive number $\\epsilon$ measures the privacy level of a privatization\nscheme.\n  In our previous work (arXiv:1702.00610), we proposed a family of new\nprivatization schemes and the corresponding estimator. We also proved that our\nscheme and estimator are order optimal in the regime $e^{\\epsilon} \\ll k$ under\nboth $\\ell_2^2$ and $\\ell_1$ loss. In other words, for a large number of\nsamples the worst-case estimation loss of our scheme was shown to differ from\nthe optimal value by at most a constant factor. In this paper, we eliminate\nthis gap by showing asymptotic optimality of the proposed scheme and estimator\nunder the $\\ell_2^2$ (mean square) loss. More precisely, we show that for any\n$k$ and $\\epsilon,$ the ratio between the worst-case estimation loss of our\nscheme and the optimal value approaches $1$ as the number of samples tends to\ninfinity.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 20:31:03 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Ye", "Min", ""], ["Barg", "Alexander", ""]]}, {"id": "1708.00065", "submitter": "Yang Li", "authors": "Yang Li, Nan Du, Samy Bengio", "title": "Time-Dependent Representation for Neural Event Sequence Prediction", "comments": "9 pages and 2 pages of references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing sequence prediction methods are mostly concerned with\ntime-independent sequences, in which the actual time span between events is\nirrelevant and the distance between events is simply the difference between\ntheir order positions in the sequence. While this time-independent view of\nsequences is applicable for data such as natural languages, e.g., dealing with\nwords in a sentence, it is inappropriate and inefficient for many real world\nevents that are observed and collected at unequally spaced points of time as\nthey naturally arise, e.g., when a person goes to a grocery store or makes a\nphone call. The time span between events can carry important information about\nthe sequence dependence of human behaviors. In this work, we propose a set of\nmethods for using time in sequence prediction. Because neural sequence models\nsuch as RNN are more amenable for handling token-like input, we propose two\nmethods for time-dependent event representation, based on the intuition on how\ntime is tokenized in everyday life and previous work on embedding\ncontextualization. We also introduce two methods for using next event duration\nas regularization for training a sequence prediction model. We discuss these\nmethods based on recurrent neural nets. We evaluate these methods as well as\nbaseline models on five datasets that resemble a variety of sequence prediction\ntasks. The experiments revealed that the proposed methods offer accuracy gain\nover baseline models in a range of settings.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 20:36:37 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 21:24:24 GMT"}, {"version": "v3", "created": "Mon, 22 Jan 2018 22:24:04 GMT"}, {"version": "v4", "created": "Fri, 20 Jul 2018 00:49:34 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Li", "Yang", ""], ["Du", "Nan", ""], ["Bengio", "Samy", ""]]}, {"id": "1708.00069", "submitter": "Peng Zheng", "authors": "Peng Zheng, Aleksandr Y. Aravkin, Karthikeyan Natesan Ramamurthy and\n  Jayaraman Jayaraman Thiagarajan", "title": "Learning Robust Representations for Computer Vision", "comments": "8 pages, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning techniques in computer vision often require learning\nlatent representations, such as low-dimensional linear and non-linear\nsubspaces. Noise and outliers in the data can frustrate these approaches by\nobscuring the latent spaces.\n  Our main goal is deeper understanding and new development of robust\napproaches for representation learning. We provide a new interpretation for\nexisting robust approaches and present two specific contributions: a new robust\nPCA approach, which can separate foreground features from dynamic background,\nand a novel robust spectral clustering method, that can cluster facial images\nwith high accuracy. Both contributions show superior performance to standard\nmethods on real-world test sets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 20:50:01 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Zheng", "Peng", ""], ["Aravkin", "Aleksandr Y.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Thiagarajan", "Jayaraman Jayaraman", ""]]}, {"id": "1708.00075", "submitter": "Cyril Zhang", "authors": "Elad Hazan, Karan Singh, Cyril Zhang", "title": "Efficient Regret Minimization in Non-Convex Games", "comments": "Published as a conference paper at ICML 2017", "journal-ref": null, "doi": null, "report-no": "PMLR 70:1433-1441", "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider regret minimization in repeated games with non-convex loss\nfunctions. Minimizing the standard notion of regret is computationally\nintractable. Thus, we define a natural notion of regret which permits efficient\noptimization and generalizes offline guarantees for convergence to an\napproximate local optimum. We give gradient-based methods that achieve optimal\nregret, which in turn guarantee convergence to equilibrium in this framework.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 21:23:29 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Hazan", "Elad", ""], ["Singh", "Karan", ""], ["Zhang", "Cyril", ""]]}, {"id": "1708.00077", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Nadezhda Chirkova, Dmitry Vetrov", "title": "Bayesian Sparsification of Recurrent Neural Networks", "comments": "Published in Workshop on Learning to Generate Natural Language, ICML,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks show state-of-the-art results in many text analysis\ntasks but often require a lot of memory to store their weights. Recently\nproposed Sparse Variational Dropout eliminates the majority of the weights in a\nfeed-forward neural network without significant loss of quality. We apply this\ntechnique to sparsify recurrent neural networks. To account for recurrent\nspecifics we also rely on Binary Variational Dropout for RNN. We report 99.5%\nsparsity level on sentiment analysis task without a quality drop and up to 87%\nsparsity level on language modeling task with slight loss of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 21:33:42 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Chirkova", "Nadezhda", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1708.00088", "submitter": "Philip Bachman", "authors": "Philip Bachman, Alessandro Sordoni and Adam Trischler", "title": "Learning Algorithms for Active Learning", "comments": "Accepted for publication at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model that learns active learning algorithms via metalearning.\nFor a distribution of related tasks, our model jointly learns: a data\nrepresentation, an item selection heuristic, and a method for constructing\nprediction functions from labeled training sets. Our model uses the item\nselection heuristic to gather labeled training sets from which to construct\nprediction functions. Using the Omniglot and MovieLens datasets, we test our\nmodel in synthetic and practical settings.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 22:26:54 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Bachman", "Philip", ""], ["Sordoni", "Alessandro", ""], ["Trischler", "Adam", ""]]}, {"id": "1708.00102", "submitter": "Lucas Lehnert", "authors": "Lucas Lehnert, Stefanie Tellex, and Michael L. Littman", "title": "Advantages and Limitations of using Successor Features for Transfer in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One question central to Reinforcement Learning is how to learn a feature\nrepresentation that supports algorithm scaling and re-use of learned\ninformation from different tasks. Successor Features approach this problem by\nlearning a feature representation that satisfies a temporal constraint. We\npresent an implementation of an approach that decouples the feature\nrepresentation from the reward function, making it suitable for transferring\nknowledge between domains. We then assess the advantages and limitations of\nusing Successor Features for transfer.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 23:36:18 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lehnert", "Lucas", ""], ["Tellex", "Stefanie", ""], ["Littman", "Michael L.", ""]]}, {"id": "1708.00107", "submitter": "Bryan McCann", "authors": "Bryan McCann, James Bradbury, Caiming Xiong and Richard Socher", "title": "Learned in Translation: Contextualized Word Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision has benefited from initializing multiple deep layers with\nweights pretrained on large supervised training sets like ImageNet. Natural\nlanguage processing (NLP) typically sees initialization of only the lowest\nlayer of deep models with pretrained word vectors. In this paper, we use a deep\nLSTM encoder from an attentional sequence-to-sequence model trained for machine\ntranslation (MT) to contextualize word vectors. We show that adding these\ncontext vectors (CoVe) improves performance over using only unsupervised word\nand character vectors on a wide variety of common NLP tasks: sentiment analysis\n(SST, IMDb), question classification (TREC), entailment (SNLI), and question\nanswering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe\nimproves performance of our baseline models to the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 00:05:34 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 13:15:06 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["McCann", "Bryan", ""], ["Bradbury", "James", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1708.00111", "submitter": "Kartik Goyal", "authors": "Kartik Goyal, Graham Neubig, Chris Dyer and Taylor Berg-Kirkpatrick", "title": "A Continuous Relaxation of Beam Search for End-to-end Training of Neural\n  Sequence Models", "comments": "Updated for clarity and notational consistency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is a desirable choice of test-time decoding algorithm for neural\nsequence models because it potentially avoids search errors made by simpler\ngreedy methods. However, typical cross entropy training procedures for these\nmodels do not directly consider the behaviour of the final decoding method. As\na result, for cross-entropy trained models, beam decoding can sometimes yield\nreduced test performance when compared with greedy decoding. In order to train\nmodels that can more effectively make use of beam search, we propose a new\ntraining procedure that focuses on the final loss metric (e.g. Hamming loss)\nevaluated on the output of beam search. While well-defined, this \"direct loss\"\nobjective is itself discontinuous and thus difficult to optimize. Hence, in our\napproach, we form a sub-differentiable surrogate objective by introducing a\nnovel continuous approximation of the beam search decoding procedure. In\nexperiments, we show that optimizing this new training objective yields\nsubstantially better results on two sequence tasks (Named Entity Recognition\nand CCG Supertagging) when compared with both cross entropy trained greedy\ndecoding and cross entropy trained beam decoding baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 00:16:08 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 19:29:30 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Goyal", "Kartik", ""], ["Neubig", "Graham", ""], ["Dyer", "Chris", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1708.00112", "submitter": "Benjamin Lengerich", "authors": "Benjamin J. Lengerich, Andrew L. Maas, Christopher Potts", "title": "Retrofitting Distributional Embeddings to Knowledge Graphs with\n  Functional Relations", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are a versatile framework to encode richly structured data\nrelationships, but it can be challenging to combine these graphs with\nunstructured data. Methods for retrofitting pre-trained entity representations\nto the structure of a knowledge graph typically assume that entities are\nembedded in a connected space and that relations imply similarity. However,\nuseful knowledge graphs often contain diverse entities and relations (with\npotentially disjoint underlying corpora) which do not accord with these\nassumptions. To overcome these limitations, we present Functional Retrofitting,\na framework that generalizes current retrofitting methods by explicitly\nmodeling pairwise relations. Our framework can directly incorporate a variety\nof pairwise penalty functions previously developed for knowledge graph\ncompletion. Further, it allows users to encode, learn, and extract information\nabout relation semantics. We present both linear and neural instantiations of\nthe framework. Functional Retrofitting significantly outperforms existing\nretrofitting methods on complex knowledge graphs and loses no accuracy on\nsimpler graphs (in which relations do imply similarity). Finally, we\ndemonstrate the utility of the framework by predicting new drug--disease\ntreatment pairs in a large, complex health knowledge graph.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 00:23:03 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 18:13:26 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2018 13:01:49 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Lengerich", "Benjamin J.", ""], ["Maas", "Andrew L.", ""], ["Potts", "Christopher", ""]]}, {"id": "1708.00117", "submitter": "Andre Xian Ming Chang", "authors": "Andre Xian Ming Chang, Aliasger Zaidy, Vinayak Gokhale, Eugenio\n  Culurciello", "title": "Compiling Deep Learning Models for Custom Hardware Accelerators", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) are the core of most state-of-the-art\ndeep learning algorithms specialized for object detection and classification.\nCNNs are both computationally complex and embarrassingly parallel. Two\nproperties that leave room for potential software and hardware optimizations\nfor embedded systems. Given a programmable hardware accelerator with a CNN\noriented custom instructions set, the compiler's task is to exploit the\nhardware's full potential, while abiding with the hardware constraints and\nmaintaining generality to run different CNN models with varying workload\nproperties. Snowflake is an efficient and scalable hardware accelerator\nimplemented on programmable logic devices. It implements a control pipeline for\na custom instruction set. The goal of this paper is to present Snowflake's\ncompiler that generates machine level instructions from Torch7 model\ndescription files. The main software design points explored in this work are:\nmodel structure parsing, CNN workload breakdown, loop rearrangement for memory\nbandwidth optimizations and memory access balancing. The performance achieved\nby compiler generated instructions matches against hand optimized code for\nconvolution layers. Generated instructions also efficiently execute AlexNet and\nResNet18 inference on Snowflake. Snowflake with $256$ processing units was\nsynthesized on Xilinx's Zynq XC7Z045 FPGA. At $250$ MHz, AlexNet achieved in\n$93.6$ frames/s and $1.2$ GB/s of off-chip memory bandwidth, and $21.4$\nframes/s and $2.2$ GB/s for ResNet18. Total on-chip power is $5$ W.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 01:01:18 GMT"}, {"version": "v2", "created": "Sun, 10 Dec 2017 18:12:33 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Chang", "Andre Xian Ming", ""], ["Zaidy", "Aliasger", ""], ["Gokhale", "Vinayak", ""], ["Culurciello", "Eugenio", ""]]}, {"id": "1708.00130", "submitter": "Theodore Vasiloudis", "authors": "Theodore Vasiloudis, Hossein Vahabi, Ross Kravitz, Valery Rashkov", "title": "Predicting Session Length in Media Streaming", "comments": "4 pages, 3 figures", "journal-ref": "Proceedings of the 40th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2017). ACM, New\n  York, NY, USA, 977-980", "doi": "10.1145/3077136.3080695", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session length is a very important aspect in determining a user's\nsatisfaction with a media streaming service. Being able to predict how long a\nsession will last can be of great use for various downstream tasks, such as\nrecommendations and ad scheduling. Most of the related literature on user\ninteraction duration has focused on dwell time for websites, usually in the\ncontext of approximating post-click satisfaction either in search results, or\ndisplay ads. In this work we present the first analysis of session length in a\nmobile-focused online service, using a real world data-set from a major music\nstreaming service. We use survival analysis techniques to show that the\ncharacteristics of the length distributions can differ significantly between\nusers, and use gradient boosted trees with appropriate objectives to predict\nthe length of a session using only information available at its beginning. Our\nevaluation on real world data illustrates that our proposed technique\noutperforms the considered baseline.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 02:15:52 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Vasiloudis", "Theodore", ""], ["Vahabi", "Hossein", ""], ["Kravitz", "Ross", ""], ["Rashkov", "Valery", ""]]}, {"id": "1708.00133", "submitter": "Karthik Narasimhan", "authors": "Karthik Narasimhan, Regina Barzilay and Tommi Jaakkola", "title": "Grounding Language for Transfer in Deep Reinforcement Learning", "comments": "JAIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the utilization of natural language to drive\ntransfer for reinforcement learning (RL). Despite the wide-spread application\nof deep RL techniques, learning generalized policy representations that work\nacross domains remains a challenging problem. We demonstrate that textual\ndescriptions of environments provide a compact intermediate channel to\nfacilitate effective policy transfer. Specifically, by learning to ground the\nmeaning of text to the dynamics of the environment such as transitions and\nrewards, an autonomous agent can effectively bootstrap policy learning on a new\ndomain given its description. We employ a model-based RL approach consisting of\na differentiable planning module, a model-free component and a factorized state\nrepresentation to effectively use entity descriptions. Our model outperforms\nprior work on both transfer and multi-task scenarios in a variety of different\nenvironments. For instance, we achieve up to 14% and 11.5% absolute improvement\nover previously existing models in terms of average and initial rewards,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 02:20:00 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 22:14:04 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Narasimhan", "Karthik", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1708.00146", "submitter": "Quanming Yao", "authors": "Quanming Yao, James T.Kwok, Taifeng Wang and Tie-Yan Liu", "title": "Large-Scale Low-Rank Matrix Learning with Nonconvex Regularizers", "comments": "Accepted by TPAMI in 2018 (extension of ICDM-2015 conference paper\n  arXiv:1512.00984)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank modeling has many important applications in computer vision and\nmachine learning. While the matrix rank is often approximated by the convex\nnuclear norm, the use of nonconvex low-rank regularizers has demonstrated\nbetter empirical performance. However, the resulting optimization problem is\nmuch more challenging. Recent state-of-the-art requires an expensive full SVD\nin each iteration. In this paper, we show that for many commonly-used nonconvex\nlow-rank regularizers, a cutoff can be derived to automatically threshold the\nsingular values obtained from the proximal operator. This allows such operator\nbeing efficiently approximated by power method. Based on it, we develop a\nproximal gradient algorithm (and its accelerated variant) with inexact proximal\nsplitting and prove that a convergence rate of O(1/T) where T is the number of\niterations is guaranteed. Furthermore, we show the proposed algorithm can be\nwell parallelized, which achieves nearly linear speedup w.r.t the number of\nthreads. Extensive experiments are performed on matrix completion and robust\nprincipal component analysis, which shows a significant speedup over the\nstate-of-the-art. Moreover, the matrix solution obtained is more accurate and\nhas a lower rank than that of the nuclear norm regularizer.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 03:21:55 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 03:33:27 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 17:10:20 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Yao", "Quanming", ""], ["Kwok", "James T.", ""], ["Wang", "Taifeng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1708.00185", "submitter": "Boyan Zhang", "authors": "Mingyuan Bai, Boyan Zhang, and Junbin Gao", "title": "Tensorial Recurrent Neural Networks for Longitudinal Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Recurrent Neural Networks assume vectorized data as inputs.\nHowever many data from modern science and technology come in certain structures\nsuch as tensorial time series data. To apply the recurrent neural networks for\nthis type of data, a vectorisation process is necessary, while such a\nvectorisation leads to the loss of the precise information of the spatial or\nlongitudinal dimensions. In addition, such a vectorized data is not an optimum\nsolution for learning the representation of the longitudinal data. In this\npaper, we propose a new variant of tensorial neural networks which directly\ntake tensorial time series data as inputs. We call this new variant as\nTensorial Recurrent Neural Network (TRNN). The proposed TRNN is based on tensor\nTucker decomposition.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 07:14:36 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Bai", "Mingyuan", ""], ["Zhang", "Boyan", ""], ["Gao", "Junbin", ""]]}, {"id": "1708.00197", "submitter": "Ziwei Liu", "authors": "Xiaoxiao Li, Yuankai Qi, Zhe Wang, Kai Chen, Ziwei Liu, Jianping Shi,\n  Ping Luo, Xiaoou Tang, Chen Change Loy", "title": "Video Object Segmentation with Re-identification", "comments": "Published in CVPR 2017 Workshop, DAVIS Challenge on Video Object\n  Segmentation 2017 (Winning Entry)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional video segmentation methods often rely on temporal continuity to\npropagate masks. Such an assumption suffers from issues like drifting and\ninability to handle large displacement. To overcome these issues, we formulate\nan effective mechanism to prevent the target from being lost via adaptive\nobject re-identification. Specifically, our Video Object Segmentation with\nRe-identification (VS-ReID) model includes a mask propagation module and a ReID\nmodule. The former module produces an initial probability map by flow warping\nwhile the latter module retrieves missing instances by adaptive matching. With\nthese two modules iteratively applied, our VS-ReID records a global mean\n(Region Jaccard and Boundary F measure) of 0.699, the best performance in 2017\nDAVIS Challenge.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 08:17:37 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Qi", "Yuankai", ""], ["Wang", "Zhe", ""], ["Chen", "Kai", ""], ["Liu", "Ziwei", ""], ["Shi", "Jianping", ""], ["Luo", "Ping", ""], ["Tang", "Xiaoou", ""], ["Loy", "Chen Change", ""]]}, {"id": "1708.00260", "submitter": "Hae Beom Lee", "authors": "Hae Beom Lee, Eunho Yang, Sung Ju Hwang", "title": "Deep Asymmetric Multi-task Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can\nlearn deep representations shared across multiple tasks while effectively\npreventing negative transfer that may happen in the feature sharing process.\nSpecifically, we introduce an asymmetric autoencoder term that allows reliable\npredictors for the easy tasks to have high contribution to the feature learning\nwhile suppressing the influences of unreliable predictors for more difficult\ntasks. This allows the learning of less noisy representations, and enables\nunreliable predictors to exploit knowledge from the reliable predictors via the\nshared latent features. Such asymmetric knowledge transfer through shared\nfeatures is also more scalable and efficient than inter-task asymmetric\ntransfer. We validate our Deep-AMTFL model on multiple benchmark datasets for\nmultitask learning and image classification, on which it significantly\noutperforms existing symmetric and asymmetric multitask learning models, by\neffectively preventing negative transfer in deep feature learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 11:44:33 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 19:05:45 GMT"}, {"version": "v3", "created": "Sat, 30 Jun 2018 21:19:59 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Lee", "Hae Beom", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1708.00308", "submitter": "Igor Melnyk", "authors": "Ramesh Nallapati, Igor Melnyk, Abhishek Kumar and Bowen Zhou", "title": "SenGen: Sentence Generating Neural Variational Topic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new topic model that generates documents by sampling a topic for\none whole sentence at a time, and generating the words in the sentence using an\nRNN decoder that is conditioned on the topic of the sentence. We argue that\nthis novel formalism will help us not only visualize and model the topical\ndiscourse structure in a document better, but also potentially lead to more\ninterpretable topics since we can now illustrate topics by sampling\nrepresentative sentences instead of bag of words or phrases. We present a\nvariational auto-encoder approach for learning in which we use a factorized\nvariational encoder that independently models the posterior over topical\nmixture vectors of documents using a feed-forward network, and the posterior\nover topic assignments to sentences using an RNN. Our preliminary experiments\non two different datasets indicate early promise, but also expose many\nchallenges that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 13:31:24 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Nallapati", "Ramesh", ""], ["Melnyk", "Igor", ""], ["Kumar", "Abhishek", ""], ["Zhou", "Bowen", ""]]}, {"id": "1708.00339", "submitter": "Yanjun  Qi Dr.", "authors": "Ritambhara Singh, Jack Lanchantin, Arshdeep Sekhon, Yanjun Qi", "title": "Attend and Predict: Understanding Gene Regulation by Selective Attention\n  on Chromatin", "comments": "12 pages; At NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen a revolution in genomic technologies that enable a\nflood of genome-wide profiling of chromatin marks. Recent literature tried to\nunderstand gene regulation by predicting gene expression from large-scale\nchromatin measurements. Two fundamental challenges exist for such learning\ntasks: (1) genome-wide chromatin signals are spatially structured,\nhigh-dimensional and highly modular; and (2) the core aim is to understand what\nare the relevant factors and how they work together? Previous studies either\nfailed to model complex dependencies among input signals or relied on separate\nfeature analysis to explain the decisions. This paper presents an\nattention-based deep learning approach; we call AttentiveChrome, that uses a\nunified architecture to model and to interpret dependencies among chromatin\nfactors for controlling gene regulation. AttentiveChrome uses a hierarchy of\nmultiple Long short-term memory (LSTM) modules to encode the input signals and\nto model how various chromatin marks cooperate automatically. AttentiveChrome\ntrains two levels of attention jointly with the target prediction, enabling it\nto attend differentially to relevant marks and to locate important positions\nper mark. We evaluate the model across 56 different cell types (tasks) in\nhuman. Not only is the proposed architecture more accurate, but its attention\nscores also provide a better interpretation than state-of-the-art feature\nvisualization methods such as saliency map.\n  Code and data are shared at www.deepchrome.org\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 14:06:12 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 17:20:13 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 16:40:55 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Singh", "Ritambhara", ""], ["Lanchantin", "Jack", ""], ["Sekhon", "Arshdeep", ""], ["Qi", "Yanjun", ""]]}, {"id": "1708.00365", "submitter": "Xiao-Lei Zhang", "authors": "Xiao-Lei Zhang", "title": "Learning the kernel matrix by resampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this abstract paper, we introduce a new kernel learning method by a\nnonparametric density estimator. The estimator consists of a group of\nk-centroids clusterings. Each clustering randomly selects data points with\nrandomly selected features as its centroids, and learns a one-hot encoder by\none-nearest-neighbor optimization. The estimator generates a sparse\nrepresentation for each data point. Then, we construct a nonlinear kernel\nmatrix from the sparse representation of data. One major advantage of the\nproposed kernel method is that it is relatively insensitive to its free\nparameters, and therefore, it can produce reasonable results without parameter\ntuning. Another advantage is that it is simple. We conjecture that the proposed\nmethod can find its applications in many learning tasks or methods where sparse\nrepresentation or kernel matrix is explored. In this preliminary study, we have\napplied the kernel matrix to spectral clustering. Our experimental results\ndemonstrate that the kernel generated by the proposed method outperforms the\nwell-tuned Gaussian RBF kernel. This abstract paper is used to protect the\nidea, full versions will be updated later.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 14:39:13 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Zhang", "Xiao-Lei", ""]]}, {"id": "1708.00489", "submitter": "Ozan Sener", "authors": "Ozan Sener, Silvio Savarese", "title": "Active Learning for Convolutional Neural Networks: A Core-Set Approach", "comments": "ICLR 2018 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been successfully applied to many\nrecognition and learning tasks using a universal recipe; training a deep model\non a very large dataset of supervised examples. However, this approach is\nrather restrictive in practice since collecting a large set of labeled images\nis very expensive. One way to ease this problem is coming up with smart ways\nfor choosing images to be labelled from a very large collection (ie. active\nlearning).\n  Our empirical study suggests that many of the active learning heuristics in\nthe literature are not effective when applied to CNNs in batch setting.\nInspired by these limitations, we define the problem of active learning as\ncore-set selection, ie. choosing set of points such that a model learned over\nthe selected subset is competitive for the remaining data points. We further\npresent a theoretical result characterizing the performance of any selected\nsubset using the geometry of the datapoints. As an active learning algorithm,\nwe choose the subset which is expected to yield best result according to our\ncharacterization. Our experiments show that the proposed method significantly\noutperforms existing approaches in image classification experiments by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 19:50:53 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 20:30:22 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 10:55:00 GMT"}, {"version": "v4", "created": "Fri, 1 Jun 2018 10:17:23 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Sener", "Ozan", ""], ["Savarese", "Silvio", ""]]}, {"id": "1708.00497", "submitter": "Chiara Boldrini", "authors": "Chiara Boldrini, Raffaele Bruno and Haitam Laarabi", "title": "Car sharing through the data analysis lens", "comments": "Accepted for KNOWMe: 1st International Workshop on Knowledge\n  Discovery from Mobility and Transportation Systems (colocated with PKDD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car sharing is one the pillars of a smart transportation infrastructure, as\nit is expected to reduce traffic congestion, parking demands and pollution in\nour cities. From the point of view of demand modelling, car sharing is a weak\nsignal in the city landscape: only a small percentage of the population uses\nit, and thus it is difficult to study reliably with traditional techniques such\nas households travel diaries. In this work, we depart from these traditional\napproaches and we rely on web-based, digital records about vehicle availability\nin 10 European cities for one of the major active car sharing operators. We\ndiscuss how vehicles are used, what are the main characteristics of car sharing\ntrips, whether events happening in certain areas are predictable or not, and\nhow the spatio-temporal information about vehicle availability can be used to\ninfer how different zones in a city are used by customers. We conclude the\npaper by presenting a direct application of the analysis of the dataset, aimed\nat identifying where to locate maintenance facilities within the car sharing\noperational area.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 13:07:47 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Boldrini", "Chiara", ""], ["Bruno", "Raffaele", ""], ["Laarabi", "Haitam", ""]]}, {"id": "1708.00523", "submitter": "Thomas Flynn", "authors": "Thomas Flynn", "title": "The duality structure gradient descent algorithm: analysis and\n  applications to neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of deep neural networks is typically carried out using some form\nof gradient descent, often with great success. However, existing non-asymptotic\nanalyses of first-order optimization algorithms typically employ a gradient\nsmoothness assumption that is too strong to be applicable in the case of deep\nneural networks. To address this, we propose an algorithm named duality\nstructure gradient descent (DSGD) that is amenable to non-asymptotic\nperformance analysis, under mild assumptions on the training set and network\narchitecture. The algorithm can be viewed as a form of layer-wise coordinate\ndescent, where at each iteration the algorithm chooses one layer of the network\nto update. The decision of what layer to update is done in a greedy fashion,\nbased on a rigorous lower bound on the improvement of the objective function\nfor each choice of layer. In the analysis, we bound the time required to reach\napproximate stationary points, in both the deterministic and stochastic\nsettings. The convergence is measured in terms of a parameter-dependent family\nof norms that is derived from the network architecture and designed to confirm\na smoothness-like property on the gradient of the training loss function. We\nempirically demonstrate the effectiveness of DSGD in several neural network\ntraining scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 21:24:38 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 17:30:56 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 03:48:30 GMT"}, {"version": "v4", "created": "Thu, 31 Aug 2017 17:45:19 GMT"}, {"version": "v5", "created": "Tue, 25 Dec 2018 08:47:05 GMT"}, {"version": "v6", "created": "Wed, 25 Nov 2020 16:46:48 GMT"}, {"version": "v7", "created": "Wed, 2 Dec 2020 17:55:04 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Flynn", "Thomas", ""]]}, {"id": "1708.00524", "submitter": "Bjarke Felbo", "authors": "Bjarke Felbo, Alan Mislove, Anders S{\\o}gaard, Iyad Rahwan and Sune\n  Lehmann", "title": "Using millions of emoji occurrences to learn any-domain representations\n  for detecting sentiment, emotion and sarcasm", "comments": "Accepted at EMNLP 2017. Please include EMNLP in any citations. Minor\n  changes from the EMNLP camera-ready version. 9 pages + references and\n  supplementary material", "journal-ref": "Proceedings of the 2017 Conference on Empirical Methods in Natural\n  Language Processing", "doi": "10.18653/v1/D17-1169", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLP tasks are often limited by scarcity of manually annotated data. In social\nmedia sentiment analysis and related tasks, researchers have therefore used\nbinarized emoticons and specific hashtags as forms of distant supervision. Our\npaper shows that by extending the distant supervision to a more diverse set of\nnoisy labels, the models can learn richer representations. Through emoji\nprediction on a dataset of 1246 million tweets containing one of 64 common\nemojis we obtain state-of-the-art performance on 8 benchmark datasets within\nsentiment, emotion and sarcasm detection using a single pretrained model. Our\nanalyses confirm that the diversity of our emotional labels yield a performance\nimprovement over previous distant supervision approaches.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 21:28:42 GMT"}, {"version": "v2", "created": "Sat, 7 Oct 2017 19:21:48 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Felbo", "Bjarke", ""], ["Mislove", "Alan", ""], ["S\u00f8gaard", "Anders", ""], ["Rahwan", "Iyad", ""], ["Lehmann", "Sune", ""]]}, {"id": "1708.00531", "submitter": "Hao Tang", "authors": "Hao Tang, Liang Lu, Lingpeng Kong, Kevin Gimpel, Karen Livescu, Chris\n  Dyer, Noah A. Smith, Steve Renals", "title": "End-to-End Neural Segmental Models for Speech Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2017.2752462", "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmental models are an alternative to frame-based models for sequence\nprediction, where hypothesized path weights are based on entire segment scores\nrather than a single frame at a time. Neural segmental models are segmental\nmodels that use neural network-based weight functions. Neural segmental models\nhave achieved competitive results for speech recognition, and their end-to-end\ntraining has been explored in several studies. In this work, we review neural\nsegmental models, which can be viewed as consisting of a neural network-based\nacoustic encoder and a finite-state transducer decoder. We study end-to-end\nsegmental models with different weight functions, including ones based on\nframe-level neural classifiers and on segmental recurrent neural networks. We\nstudy how reducing the search space size impacts performance under different\nweight functions. We also compare several loss functions for end-to-end\ntraining. Finally, we explore training approaches, including multi-stage vs.\nend-to-end training and multitask training that combines segmental and\nframe-level losses.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 21:53:56 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 16:29:05 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Tang", "Hao", ""], ["Lu", "Liang", ""], ["Kong", "Lingpeng", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""], ["Renals", "Steve", ""]]}, {"id": "1708.00568", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Richard Nock", "title": "On $w$-mixtures: Finite convex combinations of prescribed component\n  distributions", "comments": "34 pages, extend a preliminary paper (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the space of $w$-mixtures which is defined as the set of finite\nstatistical mixtures sharing the same prescribed component distributions closed\nunder convex combinations. The information geometry induced by the Bregman\ngenerator set to the Shannon negentropy on this space yields a dually flat\nspace called the mixture family manifold. We show how the Kullback-Leibler (KL)\ndivergence can be recovered from the corresponding Bregman divergence for the\nnegentropy generator: That is, the KL divergence between two $w$-mixtures\namounts to a Bregman Divergence (BD) induced by the Shannon negentropy\ngenerator. Thus the KL divergence between two Gaussian Mixture Models (GMMs)\nsharing the same Gaussian components is equivalent to a Bregman divergence.\nThis KL-BD equivalence on a mixture family manifold implies that we can perform\noptimal KL-averaging aggregation of $w$-mixtures without information loss. More\ngenerally, we prove that the statistical skew Jensen-Shannon divergence between\n$w$-mixtures is equivalent to a skew Jensen divergence between their\ncorresponding parameters. Finally, we state several properties, divergence\nidentities, and inequalities relating to $w$-mixtures.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 01:05:19 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 02:27:10 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 07:15:29 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nielsen", "Frank", ""], ["Nock", "Richard", ""]]}, {"id": "1708.00587", "submitter": "Sibaek Seong", "authors": "Si-Baek Seong, Chongwon Pae, and Hae-Jeong Park", "title": "Geometric Convolutional Neural Network for Analyzing Surface-Based\n  Neuroimaging Data", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional CNN, widely used for two-dimensional images, however, is not\ndirectly applicable to non-regular geometric surface, such as a cortical\nthickness. We propose Geometric CNN (gCNN) that deals with data representation\nover a spherical surface and renders pattern recognition in a multi-shell mesh\nstructure. The classification accuracy for sex was significantly higher than\nthat of SVM and image based CNN. It only uses MRI thickness data to classify\ngender but this method can expand to classify disease from other MRI or fMRI\ndata\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 03:23:17 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Seong", "Si-Baek", ""], ["Pae", "Chongwon", ""], ["Park", "Hae-Jeong", ""]]}, {"id": "1708.00588", "submitter": "Maziar Raissi", "authors": "Maziar Raissi and George Em Karniadakis", "title": "Hidden Physics Models: Machine Learning of Nonlinear Partial\n  Differential Equations", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2017.11.039", "report-no": null, "categories": "cs.AI cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there is currently a lot of enthusiasm about \"big data\", useful data is\nusually \"small\" and expensive to acquire. In this paper, we present a new\nparadigm of learning partial differential equations from {\\em small} data. In\nparticular, we introduce \\emph{hidden physics models}, which are essentially\ndata-efficient learning machines capable of leveraging the underlying laws of\nphysics, expressed by time dependent and nonlinear partial differential\nequations, to extract patterns from high-dimensional data generated from\nexperiments. The proposed methodology may be applied to the problem of\nlearning, system identification, or data-driven discovery of partial\ndifferential equations. Our framework relies on Gaussian processes, a powerful\ntool for probabilistic inference over functions, that enables us to strike a\nbalance between model complexity and data fitting. The effectiveness of the\nproposed approach is demonstrated through a variety of canonical problems,\nspanning a number of scientific domains, including the Navier-Stokes,\nSchr\\\"odinger, Kuramoto-Sivashinsky, and time dependent linear fractional\nequations. The methodology provides a promising new direction for harnessing\nthe long-standing developments of classical methods in applied mathematics and\nmathematical physics to design learning machines with the ability to operate in\ncomplex domains without requiring large quantities of data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 03:28:54 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 22:39:46 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Raissi", "Maziar", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1708.00598", "submitter": "Minhyeok Lee", "authors": "Minhyeok Lee and Junhee Seok", "title": "Controllable Generative Adversarial Network", "comments": "A fully revised version of this paper is published in IEEE Access.\n  Please refer to https://doi.org/10.1109/ACCESS.2019.2899108", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently introduced generative adversarial network (GAN) has been shown\nnumerous promising results to generate realistic samples. The essential task of\nGAN is to control the features of samples generated from a random distribution.\nWhile the current GAN structures, such as conditional GAN, successfully\ngenerate samples with desired major features, they often fail to produce\ndetailed features that bring specific differences among samples. To overcome\nthis limitation, here we propose a controllable GAN (ControlGAN) structure. By\nseparating a feature classifier from a discriminator, the generator of\nControlGAN is designed to learn generating synthetic samples with the specific\ndetailed features. Evaluated with multiple image datasets, ControlGAN shows a\npower to generate improved samples with well-controlled features. Furthermore,\nwe demonstrate that ControlGAN can generate intermediate features and opposite\nfeatures for interpolated and extrapolated input labels that are not used in\nthe training process. It implies that ControlGAN can significantly contribute\nto the variety of generated samples.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 04:17:59 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 10:37:48 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2018 06:21:20 GMT"}, {"version": "v4", "created": "Tue, 1 May 2018 22:39:24 GMT"}, {"version": "v5", "created": "Sat, 30 Mar 2019 08:00:54 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Lee", "Minhyeok", ""], ["Seok", "Junhee", ""]]}, {"id": "1708.00601", "submitter": "Jonathan Jiang", "authors": "Jonathan Q. Jiang, Michael K. Ng", "title": "Exact Tensor Completion from Sparsely Corrupted Observations via Convex\n  Optimization", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper conducts a rigorous analysis for provable estimation of\nmultidimensional arrays, in particular third-order tensors, from a random\nsubset of its corrupted entries. Our study rests heavily on a recently proposed\ntensor algebraic framework in which we can obtain tensor singular value\ndecomposition (t-SVD) that is similar to the SVD for matrices, and define a new\nnotion of tensor rank referred to as the tubal rank. We prove that by simply\nsolving a convex program, which minimizes a weighted combination of tubal\nnuclear norm, a convex surrogate for the tubal rank, and the $\\ell_1$-norm, one\ncan recover an incoherent tensor exactly with overwhelming probability,\nprovided that its tubal rank is not too large and that the corruptions are\nreasonably sparse. Interestingly, our result includes the recovery guarantees\nfor the problems of tensor completion (TC) and tensor principal component\nanalysis (TRPCA) under the same algebraic setup as special cases. An\nalternating direction method of multipliers (ADMM) algorithm is presented to\nsolve this optimization problem. Numerical experiments verify our theory and\nreal-world applications demonstrate the effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 04:45:42 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Jiang", "Jonathan Q.", ""], ["Ng", "Michael K.", ""]]}, {"id": "1708.00630", "submitter": "Sujith Ravi", "authors": "Sujith Ravi", "title": "ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural\n  Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become ubiquitous for applications related to\nvisual recognition and language understanding tasks. However, it is often\nprohibitive to use typical neural networks on devices like mobile phones or\nsmart watches since the model sizes are huge and cannot fit in the limited\nmemory available on such devices. While these devices could make use of machine\nlearning models running on high-performance data centers with CPUs or GPUs,\nthis is not feasible for many applications because data can be privacy\nsensitive and inference needs to be performed directly \"on\" device.\n  We introduce a new architecture for training compact neural networks using a\njoint optimization framework. At its core lies a novel objective that jointly\ntrains using two different types of networks--a full trainer neural network\n(using existing architectures like Feed-forward NNs or LSTM RNNs) combined with\na simpler \"projection\" network that leverages random projections to transform\ninputs or intermediate representations into bits. The simpler network encodes\nlightweight and efficient-to-compute operations in bit space with a low memory\nfootprint. The two networks are trained jointly using backpropagation, where\nthe projection network learns from the full network similar to apprenticeship\nlearning. Once trained, the smaller network can be used directly for inference\nat low memory and computation cost. We demonstrate the effectiveness of the new\napproach at significantly shrinking the memory requirements of different types\nof neural networks while preserving good accuracy on visual recognition and\ntext classification tasks. We also study the question \"how many neural bits are\nrequired to solve a given task?\" using the new framework and show empirical\nresults contrasting model predictive capacity (in bits) versus accuracy on\nseveral datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 07:58:45 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 10:05:09 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Ravi", "Sujith", ""]]}, {"id": "1708.00631", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Yezhou Yang, Cornelia Fermuller, Yiannis Aloimonos", "title": "On the Importance of Consistency in Training Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain that the difficulties of training deep neural networks come from a\nsyndrome of three consistency issues. This paper describes our efforts in their\nanalysis and treatment. The first issue is the training speed inconsistency in\ndifferent layers. We propose to address it with an intuitive,\nsimple-to-implement, low footprint second-order method. The second issue is the\nscale inconsistency between the layer inputs and the layer residuals. We\nexplain how second-order information provides favorable convenience in removing\nthis roadblock. The third and most challenging issue is the inconsistency in\nresidual propagation. Based on the fundamental theorem of linear algebra, we\nprovide a mathematical characterization of the famous vanishing gradient\nproblem. Thus, an important design principle for future optimization and neural\nnetwork design is derived. We conclude this paper with the construction of a\nnovel contractive neural network.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 08:05:09 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Ye", "Chengxi", ""], ["Yang", "Yezhou", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1708.00651", "submitter": "Phong Nguyen", "authors": "Phong Nguyen, John Dines and Jan Krasnodebski", "title": "A Multi-Objective Learning to re-Rank Approach to Optimize Online\n  Marketplaces for Multiple Stakeholders", "comments": "Presented at the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective recommender systems address the difficult task of\nrecommending items that are relevant to multiple, possibly conflicting,\ncriteria. However these systems are most often designed to address the\nobjective of one single stakeholder, typically, in online commerce, the\nconsumers whose input and purchasing decisions ultimately determine the success\nof the recommendation systems. In this work, we address the multi-objective,\nmulti-stakeholder, recommendation problem involving one or more objective(s)\nper stakeholder. In addition to the consumer stakeholder, we also consider two\nother stakeholders; the suppliers who provide the goods and services for sale\nand the intermediary who is responsible for helping connect consumers to\nsuppliers via its recommendation algorithms. We analyze the multi-objective,\nmulti-stakeholder, problem from the point of view of the online marketplace\nintermediary whose objective is to maximize its commission through its\nrecommender system. We define a multi-objective problem relating all our three\nstakeholders which we solve with a novel learning-to-re-rank approach that\nmakes use of a novel regularization function based on the Kendall tau\ncorrelation metric and its kernel version; given an initial ranking of item\nrecommendations built for the consumer, we aim to re-rank it such that the new\nranking is also optimized for the secondary objectives while staying close to\nthe initial ranking. We evaluate our approach on a real-world dataset of hotel\nrecommendations provided by Expedia where we show the effectiveness of our\napproach against a business-rules oriented baseline model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 08:54:07 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 02:35:09 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Nguyen", "Phong", ""], ["Dines", "John", ""], ["Krasnodebski", "Jan", ""]]}, {"id": "1708.00754", "submitter": "Indre Zliobaite", "authors": "Indre Zliobaite", "title": "Fairness-aware machine learning: a perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms learned from data are increasingly used for deciding many aspects\nin our life: from movies we see, to prices we pay, or medicine we get. Yet\nthere is growing evidence that decision making by inappropriately trained\nalgorithms may unintentionally discriminate people. For example, in automated\nmatching of candidate CVs with job descriptions, algorithms may capture and\npropagate ethnicity related biases. Several repairs for selected algorithms\nhave already been proposed, but the underlying mechanisms how such\ndiscrimination happens from the computational perspective are not yet\nscientifically understood. We need to develop theoretical understanding how\nalgorithms may become discriminatory, and establish fundamental machine\nlearning principles for prevention. We need to analyze machine learning process\nas a whole to systematically explain the roots of discrimination occurrence,\nwhich will allow to devise global machine learning optimization criteria for\nguaranteed prevention, as opposed to pushing empirical constraints into\nexisting algorithms case-by-case. As a result, the state-of-the-art will\nadvance from heuristic repairing, to proactive and theoretically supported\nprevention. This is needed not only because law requires to protect vulnerable\npeople. Penetration of big data initiatives will only increase, and computer\nscience needs to provide solid explanations and accountability to the public,\nbefore public concerns lead to unnecessarily restrictive regulations against\nmachine learning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 14:14:49 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Zliobaite", "Indre", ""]]}, {"id": "1708.00768", "submitter": "Odalric-Ambrym Maillard", "authors": "Audrey Durand, Odalric-Ambrym Maillard, Joelle Pineau", "title": "Streaming kernel regression with provably adaptive mean, variance, and\n  regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of streaming kernel regression, when the observations\narrive sequentially and the goal is to recover the underlying mean function,\nassumed to belong to an RKHS. The variance of the noise is not assumed to be\nknown. In this context, we tackle the problem of tuning the regularization\nparameter adaptively at each time step, while maintaining tight confidence\nbounds estimates on the value of the mean function at each point. To this end,\nwe first generalize existing results for finite-dimensional linear regression\nwith fixed regularization and known variance to the kernel setup with a\nregularization parameter allowed to be a measurable function of past\nobservations. Then, using appropriate self-normalized inequalities we build\nupper and lower bound estimates for the variance, leading to Bersntein-like\nconcentration bounds. The later is used in order to define the adaptive\nregularization. The bounds resulting from our technique are valid uniformly\nover all observation points and all time steps, and are compared against the\nliterature with numerical experiments. Finally, the potential of these tools is\nillustrated by an application to kernelized bandits, where we revisit the\nKernel UCB and Kernel Thompson Sampling procedures, and show the benefits of\nthe novel adaptive kernel tuning strategy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 14:38:48 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Durand", "Audrey", ""], ["Maillard", "Odalric-Ambrym", ""], ["Pineau", "Joelle", ""]]}, {"id": "1708.00781", "submitter": "Yangfeng Ji", "authors": "Yangfeng Ji, Chenhao Tan, Sebastian Martschat, Yejin Choi, Noah A.\n  Smith", "title": "Dynamic Entity Representations in Neural Language Models", "comments": "EMNLP 2017 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a long document requires tracking how entities are introduced\nand evolve over time. We present a new type of language model, EntityNLM, that\ncan explicitly model entities, dynamically update their representations, and\ncontextually generate their mentions. Our model is generative and flexible; it\ncan model an arbitrary number of entities in context while generating each\nentity mention at an arbitrary length. In addition, it can be used for several\ndifferent tasks such as language modeling, coreference resolution, and entity\nprediction. Experimental results with all these tasks demonstrate that our\nmodel consistently outperforms strong baselines and prior work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 14:49:03 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Ji", "Yangfeng", ""], ["Tan", "Chenhao", ""], ["Martschat", "Sebastian", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""]]}, {"id": "1708.00805", "submitter": "Philip Bachman", "authors": "Philip Bachman and Doina Precup", "title": "Variational Generative Stochastic Networks with Collaborative Shaping", "comments": "Old paper, from ICML 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an approach to training generative models based on unrolling a\nvariational auto-encoder into a Markov chain, and shaping the chain's\ntrajectories using a technique inspired by recent work in Approximate Bayesian\ncomputation. We show that the global minimizer of the resulting objective is\nachieved when the generative model reproduces the target distribution. To allow\nfiner control over the behavior of the models, we add a regularization term\ninspired by techniques used for regularizing certain types of policy search in\nreinforcement learning. We present empirical results on the MNIST and TFD\ndatasets which show that our approach offers state-of-the-art performance, both\nquantitatively and from a qualitative point of view.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 15:55:40 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Bachman", "Philip", ""], ["Precup", "Doina", ""]]}, {"id": "1708.00807", "submitter": "Yanjun  Qi Dr.", "authors": "Andrew P. Norton, Yanjun Qi", "title": "Adversarial-Playground: A Visualization Suite Showing How Adversarial\n  Examples Fool Deep Learning", "comments": "5 pages. {I.2.6}{Artificial Intelligence} ; {K.6.5}{Management of\n  Computing and Information Systems}{Security and Protection}. arXiv admin\n  note: substantial text overlap with arXiv:1706.01763", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that attackers can force deep learning models to\nmisclassify so-called \"adversarial examples\": maliciously generated images\nformed by making imperceptible modifications to pixel values. With growing\ninterest in deep learning for security applications, it is important for\nsecurity experts and users of machine learning to recognize how learning\nsystems may be attacked. Due to the complex nature of deep learning, it is\nchallenging to understand how deep models can be fooled by adversarial\nexamples. Thus, we present a web-based visualization tool,\nAdversarial-Playground, to demonstrate the efficacy of common adversarial\nmethods against a convolutional neural network (CNN) system.\nAdversarial-Playground is educational, modular and interactive. (1) It enables\nnon-experts to compare examples visually and to understand why an adversarial\nexample can fool a CNN-based image classifier. (2) It can help security experts\nexplore more vulnerability of deep learning as a software module. (3) Building\nan interactive visualization is challenging in this domain due to the large\nfeature space of image classification (generating adversarial examples is slow\nin general and visualizing images are costly). Through multiple novel design\nchoices, our tool can provide fast and accurate responses to user requests.\nEmpirically, we find that our client-server division strategy reduced the\nresponse time by an average of 1.5 seconds per sample. Our other innovation, a\nfaster variant of JSMA evasion algorithm, empirically performed twice as fast\nas JSMA and yet maintains a comparable evasion rate.\n  Project source code and data from our experiments available at:\nhttps://github.com/QData/AdversarialDNN-Playground\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 14:34:35 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Norton", "Andrew P.", ""], ["Qi", "Yanjun", ""]]}, {"id": "1708.00853", "submitter": "Volodymyr Kuleshov", "authors": "Volodymyr Kuleshov, S. Zayd Enam, Stefano Ermon", "title": "Audio Super Resolution using Neural Networks", "comments": "Presented at the 5th International Conference on Learning\n  Representations (ICLR) 2017, Workshop Track, Toulon, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new audio processing technique that increases the sampling\nrate of signals such as speech or music using deep convolutional neural\nnetworks. Our model is trained on pairs of low and high-quality audio examples;\nat test-time, it predicts missing samples within a low-resolution signal in an\ninterpolation process similar to image super-resolution. Our method is simple\nand does not involve specialized audio processing techniques; in our\nexperiments, it outperforms baselines on standard speech and music benchmarks\nat upscaling ratios of 2x, 4x, and 6x. The method has practical applications in\ntelephony, compression, and text-to-speech generation; it demonstrates the\neffectiveness of feed-forward convolutional architectures on an audio\ngeneration task.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 20:07:39 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Kuleshov", "Volodymyr", ""], ["Enam", "S. Zayd", ""], ["Ermon", "Stefano", ""]]}, {"id": "1708.00909", "submitter": "Joshua Glaser", "authors": "Joshua I. Glaser, Ari S. Benjamin, Raeed H. Chowdhury, Matthew G.\n  Perich, Lee E. Miller, Konrad P. Kording", "title": "Machine learning for neural decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite rapid advances in machine learning tools, the majority of neural\ndecoding approaches still use traditional methods. Modern machine learning\ntools, which are versatile and easy to use, have the potential to significantly\nimprove decoding performance. This tutorial describes how to effectively apply\nthese algorithms for typical decoding problems. We provide descriptions, best\npractices, and code for applying common machine learning methods, including\nneural networks and gradient boosting. We also provide detailed comparisons of\nthe performance of various methods at the task of decoding spiking activity in\nmotor cortex, somatosensory cortex, and hippocampus. Modern methods,\nparticularly neural networks and ensembles, significantly outperform\ntraditional approaches, such as Wiener and Kalman filters. Improving the\nperformance of neural decoding algorithms allows neuroscientists to better\nunderstand the information contained in a neural population and can help\nadvance engineering applications such as brain machine interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 19:53:22 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 16:58:31 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 02:46:47 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 15:25:31 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Glaser", "Joshua I.", ""], ["Benjamin", "Ari S.", ""], ["Chowdhury", "Raeed H.", ""], ["Perich", "Matthew G.", ""], ["Miller", "Lee E.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1708.01012", "submitter": "Fan Zhou", "authors": "Fan Zhou and Guojing Cong", "title": "On the convergence properties of a $K$-step averaging stochastic\n  gradient descent algorithm for nonconvex optimization", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2018/447", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their popularity, the practical performance of asynchronous\nstochastic gradient descent methods (ASGD) for solving large scale machine\nlearning problems are not as good as theoretical results indicate. We adopt and\nanalyze a synchronous K-step averaging stochastic gradient descent algorithm\nwhich we call K-AVG. We establish the convergence results of K-AVG for\nnonconvex objectives and explain why the K-step delay is necessary and leads to\nbetter performance than traditional parallel stochastic gradient descent which\nis a special case of K-AVG with $K=1$. We also show that K-AVG scales better\nthan ASGD. Another advantage of K-AVG over ASGD is that it allows larger\nstepsizes. On a cluster of $128$ GPUs, K-AVG is faster than ASGD\nimplementations and achieves better accuracies and faster convergence for\n\\cifar dataset.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 06:18:36 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 20:28:04 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 22:38:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhou", "Fan", ""], ["Cong", "Guojing", ""]]}, {"id": "1708.01015", "submitter": "Stefan Braun", "authors": "Stefan Braun, Daniel Neil, Enea Ceolini, Jithendar Anumula, Shih-Chii\n  Liu", "title": "Sensor Transformation Attention Networks", "comments": "8 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on encoder-decoder models for sequence-to-sequence mapping has\nshown that integrating both temporal and spatial attention mechanisms into\nneural networks increases the performance of the system substantially. In this\nwork, we report on the application of an attentional signal not on temporal and\nspatial regions of the input, but instead as a method of switching among inputs\nthemselves. We evaluate the particular role of attentional switching in the\npresence of dynamic noise in the sensors, and demonstrate how the attentional\nsignal responds dynamically to changing noise levels in the environment to\nachieve increased performance on both audio and visual tasks in three\ncommonly-used datasets: TIDIGITS, Wall Street Journal, and GRID. Moreover, the\nproposed sensor transformation network architecture naturally introduces a\nnumber of advantages that merit exploration, including ease of adding new\nsensors to existing architectures, attentional interpretability, and increased\nrobustness in a variety of noisy environments not seen during training.\nFinally, we demonstrate that the sensor selection attention mechanism of a\nmodel trained only on the small TIDIGITS dataset can be transferred directly to\na pre-existing larger network trained on the Wall Street Journal dataset,\nmaintaining functionality of switching between sensors to yield a dramatic\nreduction of error in the presence of noise.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 06:35:36 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Braun", "Stefan", ""], ["Neil", "Daniel", ""], ["Ceolini", "Enea", ""], ["Anumula", "Jithendar", ""], ["Liu", "Shih-Chii", ""]]}, {"id": "1708.01167", "submitter": "Iaroslav Omelianenko", "authors": "Iaroslav Omelianenko", "title": "Applying advanced machine learning models to classify\n  electro-physiological activity of human brain for use in biometric\n  identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present the results of our research related to the study\nof correlations between specific visual stimulation and the elicited brain's\nelectro-physiological response collected by EEG sensors from a group of\nparticipants. We will look at how the various characteristics of visual\nstimulation affect the measured electro-physiological response of the brain and\ndescribe the optimal parameters found that elicit a steady-state visually\nevoked potential (SSVEP) in certain parts of the cerebral cortex where it can\nbe reliably perceived by the electrode of the EEG device. After that, we\ncontinue with a description of the advanced machine learning pipeline model\nthat can perform confident classification of the collected EEG data in order to\n(a) reliably distinguish signal from noise (about 85% validation score) and (b)\nreliably distinguish between EEG records collected from different human\nparticipants (about 80% validation score). Finally, we demonstrate that the\nproposed method works reliably even with an inexpensive (less than $100)\nconsumer-grade EEG sensing device and with participants who do not have\nprevious experience with EEG technology (EEG illiterate). All this in\ncombination opens up broad prospects for the development of new types of\nconsumer devices, [e.g.] based on virtual reality helmets or augmented reality\nglasses where EEG sensor can be easily integrated. The proposed method can be\nused to improve an online user experience by providing [e.g.] password-less\nuser identification for VR / AR applications. It can also find a more advanced\napplication in intensive care units where collected EEG data can be used to\nclassify the level of conscious awareness of patients during anesthesia or to\nautomatically detect hardware failures by classifying the input signal as\nnoise.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 14:50:02 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Omelianenko", "Iaroslav", ""]]}, {"id": "1708.01241", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Zhuang Liu and Jianguo Li and Yu-Gang Jiang and\n  Yurong Chen and Xiangyang Xue", "title": "DSOD: Learning Deeply Supervised Object Detectors from Scratch", "comments": "ICCV 2017. Code and models are available at:\n  https://github.com/szq0214/DSOD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deeply Supervised Object Detector (DSOD), a framework that can\nlearn object detectors from scratch. State-of-the-art object objectors rely\nheavily on the off-the-shelf networks pre-trained on large-scale classification\ndatasets like ImageNet, which incurs learning bias due to the difference on\nboth the loss functions and the category distributions between classification\nand detection tasks. Model fine-tuning for the detection task could alleviate\nthis bias to some extent but not fundamentally. Besides, transferring\npre-trained models from classification to detection between discrepant domains\nis even more difficult (e.g. RGB to depth images). A better solution to tackle\nthese two critical problems is to train object detectors from scratch, which\nmotivates our proposed DSOD. Previous efforts in this direction mostly failed\ndue to much more complicated loss functions and limited training data in object\ndetection. In DSOD, we contribute a set of design principles for training\nobject detectors from scratch. One of the key findings is that deep\nsupervision, enabled by dense layer-wise connections, plays a critical role in\nlearning a good detector. Combining with several other principles, we develop\nDSOD following the single-shot detection (SSD) framework. Experiments on PASCAL\nVOC 2007, 2012 and MS COCO datasets demonstrate that DSOD can achieve better\nresults than the state-of-the-art solutions with much more compact models. For\ninstance, DSOD outperforms SSD on all three benchmarks with real-time detection\nspeed, while requires only 1/2 parameters to SSD and 1/10 parameters to Faster\nRCNN. Our code and models are available at: https://github.com/szq0214/DSOD .\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 17:33:05 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 02:17:30 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Liu", "Zhuang", ""], ["Li", "Jianguo", ""], ["Jiang", "Yu-Gang", ""], ["Chen", "Yurong", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1708.01289", "submitter": "Jules Pondard", "authors": "Valentin Thomas, Jules Pondard, Emmanuel Bengio, Marc Sarfati,\n  Philippe Beaudoin, Marie-Jean Meurs, Joelle Pineau, Doina Precup, Yoshua\n  Bengio", "title": "Independently Controllable Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been postulated that a good representation is one that disentangles\nthe underlying explanatory factors of variation. However, it remains an open\nquestion what kind of training framework could potentially achieve that.\nWhereas most previous work focuses on the static setting (e.g., with images),\nwe postulate that some of the causal factors could be discovered if the learner\nis allowed to interact with its environment. The agent can experiment with\ndifferent actions and observe their effects. More specifically, we hypothesize\nthat some of these factors correspond to aspects of the environment which are\nindependently controllable, i.e., that there exists a policy and a learnable\nfeature for each such aspect of the environment, such that this policy can\nyield changes in that feature with minimal changes to other features that\nexplain the statistical variations in the observed data. We propose a specific\nobjective function to find such factors and verify experimentally that it can\nindeed disentangle independently controllable aspects of the environment\nwithout any extrinsic reward signal.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 19:32:33 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 22:18:11 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Thomas", "Valentin", ""], ["Pondard", "Jules", ""], ["Bengio", "Emmanuel", ""], ["Sarfati", "Marc", ""], ["Beaudoin", "Philippe", ""], ["Meurs", "Marie-Jean", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1708.01298", "submitter": "Erfan Sadeqi Azer", "authors": "Yangchen Pan, Erfan Sadeqi Azer and Martha White", "title": "Effective sketching methods for value function approximation", "comments": "Conference on Uncertainty in Artificial Intelligence (UAI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional representations, such as radial basis function networks or\ntile coding, are common choices for policy evaluation in reinforcement\nlearning. Learning with such high-dimensional representations, however, can be\nexpensive, particularly for matrix methods, such as least-squares temporal\ndifference learning or quasi-Newton methods that approximate matrix step-sizes.\nIn this work, we explore the utility of sketching for these two classes of\nalgorithms. We highlight issues with sketching the high-dimensional features\ndirectly, which can incur significant bias. As a remedy, we demonstrate how to\nuse sketching more sparingly, with only a left-sided sketch, that can still\nenable significant computational gains and the use of these matrix-based\nlearning algorithms that are less sensitive to parameters. We empirically\ninvestigate these algorithms, in four domains with a variety of\nrepresentations. Our aim is to provide insights into effective use of sketching\nin practice.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 20:27:45 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Pan", "Yangchen", ""], ["Azer", "Erfan Sadeqi", ""], ["White", "Martha", ""]]}, {"id": "1708.01354", "submitter": "Adithya Murali", "authors": "Adithyavairavan Murali, Lerrel Pinto, Dhiraj Gandhi, Abhinav Gupta", "title": "CASSL: Curriculum Accelerated Self-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent self-supervised learning approaches focus on using a few thousand data\npoints to learn policies for high-level, low-dimensional action spaces.\nHowever, scaling this framework for high-dimensional control require either\nscaling up the data collection efforts or using a clever sampling strategy for\ntraining. We present a novel approach - Curriculum Accelerated Self-Supervised\nLearning (CASSL) - to train policies that map visual information to high-level,\nhigher- dimensional action spaces. CASSL orders the sampling of training data\nbased on control dimensions: the learning and sampling are focused on few\ncontrol parameters before other parameters. The right curriculum for learning\nis suggested by variance-based global sensitivity analysis of the control\nspace. We apply our CASSL framework to learning how to grasp using an adaptive,\nunderactuated multi-fingered gripper, a challenging system to control. Our\nexperimental results indicate that CASSL provides significant improvement and\ngeneralization compared to baseline methods such as staged curriculum learning\n(8% increase) and complete end-to-end learning with random exploration (14%\nimprovement) tested on a set of novel objects.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 02:13:50 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 23:24:52 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Murali", "Adithyavairavan", ""], ["Pinto", "Lerrel", ""], ["Gandhi", "Dhiraj", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1708.01383", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Kun Yuan and Ali H. Sayed", "title": "Variance-Reduced Stochastic Learning under Random Reshuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several useful variance-reduced stochastic gradient algorithms, such as SVRG,\nSAGA, Finito, and SAG, have been proposed to minimize empirical risks with\nlinear convergence properties to the exact minimizer. The existing convergence\nresults assume uniform data sampling with replacement. However, it has been\nobserved in related works that random reshuffling can deliver superior\nperformance over uniform sampling and, yet, no formal proofs or guarantees of\nexact convergence exist for variance-reduced algorithms under random\nreshuffling. This paper makes two contributions. First, it resolves this open\nissue and provides the first theoretical guarantee of linear convergence under\nrandom reshuffling for SAGA; the argument is also adaptable to other\nvariance-reduced algorithms. Second, under random reshuffling, the paper\nproposes a new amortized variance-reduced gradient (AVRG) algorithm with\nconstant storage requirements compared to SAGA and with balanced gradient\ncomputations compared to SVRG. AVRG is also shown analytically to converge\nlinearly.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 05:43:33 GMT"}, {"version": "v2", "created": "Sun, 20 Aug 2017 04:40:53 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 15:35:32 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Ying", "Bicheng", ""], ["Yuan", "Kun", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1708.01384", "submitter": "Kun Yuan", "authors": "Kun Yuan, Bicheng Ying, Jiageng Liu, and Ali H. Sayed", "title": "Variance-Reduced Stochastic Learning by Networked Agents under Random\n  Reshuffling", "comments": "23 pages, 12 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new amortized variance-reduced gradient (AVRG) algorithm was developed in\n\\cite{ying2017convergence}, which has constant storage requirement in\ncomparison to SAGA and balanced gradient computations in comparison to SVRG.\nOne key advantage of the AVRG strategy is its amenability to decentralized\nimplementations. In this work, we show how AVRG can be extended to the network\ncase where multiple learning agents are assumed to be connected by a graph\ntopology. In this scenario, each agent observes data that is spatially\ndistributed and all agents are only allowed to communicate with direct\nneighbors. Moreover, the amount of data observed by the individual agents may\ndiffer drastically. For such situations, the balanced gradient computation\nproperty of AVRG becomes a real advantage in reducing idle time caused by\nunbalanced local data storage requirements, which is characteristic of other\nreduced-variance gradient algorithms. The resulting diffusion-AVRG algorithm is\nshown to have linear convergence to the exact solution, and is much more memory\nefficient than other alternative algorithms. In addition, we propose a\nmini-batch strategy to balance the communication and computation efficiency for\ndiffusion-AVRG. When a proper batch size is employed, it is observed in\nsimulations that diffusion-AVRG is more computationally efficient than exact\ndiffusion or EXTRA while maintaining almost the same communication efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 05:43:38 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 03:50:42 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 15:19:44 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Yuan", "Kun", ""], ["Ying", "Bicheng", ""], ["Liu", "Jiageng", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1708.01410", "submitter": "Pierre-Louis Giscard", "authors": "P.-L. Giscard and R. C. Wilson", "title": "The All-Paths and Cycles Graph Kernel", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent rise in the amount of structured data available, there has\nbeen considerable interest in methods for machine learning with graphs. Many of\nthese approaches have been kernel methods, which focus on measuring the\nsimilarity between graphs. These generally involving measuring the similarity\nof structural elements such as walks or paths. Borgwardt and Kriegel proposed\nthe all-paths kernel but emphasized that it is NP-hard to compute and\ninfeasible in practice, favouring instead the shortest-path kernel. In this\npaper, we introduce a new algorithm for computing the all-paths kernel which is\nvery efficient and enrich it further by including the simple cycles as well. We\ndemonstrate how it is feasible even on large datasets to compute all the paths\nand simple cycles up to a moderate length. We show how to count labelled\npaths/simple cycles between vertices of a graph and evaluate a labelled path\nand simple cycles kernel. Extensive evaluations on a variety of graph datasets\ndemonstrate that the all-paths and cycles kernel has superior performance to\nthe shortest-path kernel and state-of-the-art performance overall.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:06:07 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Giscard", "P. -L.", ""], ["Wilson", "R. C.", ""]]}, {"id": "1708.01413", "submitter": "Navid Azizan Ruhi", "authors": "Navid Azizan-Ruhi, Farshad Lahouti, Salman Avestimehr, Babak Hassibi", "title": "Distributed Solution of Large-Scale Linear Systems via Accelerated\n  Projection-Based Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving a large-scale system of linear equations is a key step at the heart\nof many algorithms in machine learning, scientific computing, and beyond. When\nthe problem dimension is large, computational and/or memory constraints make it\ndesirable, or even necessary, to perform the task in a distributed fashion. In\nthis paper, we consider a common scenario in which a taskmaster intends to\nsolve a large-scale system of linear equations by distributing subsets of the\nequations among a number of computing machines/cores. We propose an accelerated\ndistributed consensus algorithm, in which at each iteration every machine\nupdates its solution by adding a scaled version of the projection of an error\nsignal onto the nullspace of its system of equations, and where the taskmaster\nconducts an averaging over the solutions with momentum. The convergence\nbehavior of the proposed algorithm is analyzed in detail and analytically shown\nto compare favorably with the convergence rate of alternative distributed\nmethods, namely distributed gradient descent, distributed versions of\nNesterov's accelerated gradient descent and heavy-ball method, the block\nCimmino method, and ADMM. On randomly chosen linear systems, as well as on\nreal-world data sets, the proposed method offers significant speed-up relative\nto all the aforementioned methods. Finally, our analysis suggests a novel\nvariation of the distributed heavy-ball method, which employs a particular\ndistributed preconditioning, and which achieves the same theoretical\nconvergence rate as the proposed consensus-based method.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:18:26 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 03:00:36 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Azizan-Ruhi", "Navid", ""], ["Lahouti", "Farshad", ""], ["Avestimehr", "Salman", ""], ["Hassibi", "Babak", ""]]}, {"id": "1708.01422", "submitter": "Bo Li", "authors": "Bo Li and David Saad", "title": "Exploring the Function Space of Deep-Learning Machines", "comments": "New examples of networks with ReLU activation and convolutional\n  networks are included", "journal-ref": "Phys. Rev. Lett. 120, 248301 (2018)", "doi": "10.1103/PhysRevLett.120.248301", "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The function space of deep-learning machines is investigated by studying\ngrowth in the entropy of functions of a given error with respect to a reference\nfunction, realized by a deep-learning machine. Using physics-inspired methods\nwe study both sparsely and densely-connected architectures to discover a\nlayer-wise convergence of candidate functions, marked by a corresponding\nreduction in entropy when approaching the reference function, gain insight into\nthe importance of having a large number of layers, and observe phase\ntransitions as the error increases.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:38:20 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 11:29:15 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2018 08:09:52 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Li", "Bo", ""], ["Saad", "David", ""]]}, {"id": "1708.01465", "submitter": "Joos Behncke", "authors": "Dominik Welke, Joos Behncke, Marina Hader, Robin Tibor Schirrmeister,\n  Andreas Sch\\\"onau, Boris E{\\ss}mann, Oliver M\\\"uller, Wolfram Burgard, Tonio\n  Ball", "title": "Brain Responses During Robot-Error Observation", "comments": null, "journal-ref": null, "doi": "10.17185/duepublico/44533", "report-no": null, "categories": "cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-controlled robots are a promising new type of assistive device for\nseverely impaired persons. Little is however known about how to optimize the\ninteraction of humans and brain-controlled robots. Information about the\nhuman's perceived correctness of robot performance might provide a useful\nteaching signal for adaptive control algorithms and thus help enhancing robot\ncontrol. Here, we studied whether watching robots perform erroneous vs. correct\naction elicits differential brain responses that can be decoded from single\ntrials of electroencephalographic (EEG) recordings, and whether brain activity\nduring human-robot interaction is modulated by the robot's visual similarity to\na human. To address these topics, we designed two experiments. In experiment I,\nparticipants watched a robot arm pour liquid into a cup. The robot performed\nthe action either erroneously or correctly, i.e. it either spilled some liquid\nor not. In experiment II, participants observed two different types of robots,\nhumanoid and non-humanoid, grabbing a ball. The robots either managed to grab\nthe ball or not. We recorded high-resolution EEG during the observation tasks\nin both experiments to train a Filter Bank Common Spatial Pattern (FBCSP)\npipeline on the multivariate EEG signal and decode for the correctness of the\nobserved action, and for the type of the observed robot. Our findings show that\nit was possible to decode both correctness and robot type for the majority of\nparticipants significantly, although often just slightly, above chance level.\nOur findings suggest that non-invasive recordings of brain responses elicited\nwhen observing robots indeed contain decodable information about the\ncorrectness of the robot's action and the type of observed robot.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 11:58:52 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 08:21:25 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Welke", "Dominik", ""], ["Behncke", "Joos", ""], ["Hader", "Marina", ""], ["Schirrmeister", "Robin Tibor", ""], ["Sch\u00f6nau", "Andreas", ""], ["E\u00dfmann", "Boris", ""], ["M\u00fcller", "Oliver", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1708.01519", "submitter": "Mehran Safayani", "authors": "Mehran Safayani and Saeid Momenzadeh", "title": "A Latent Variable Model for Two-Dimensional Canonical Correlation\n  Analysis and its Variational Inference", "comments": null, "journal-ref": null, "doi": "10.1007/s00500-020-04906-8", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing the dimension reduction (DR) techniques by means of probabilistic\nmodels has recently been given special attention. Probabilistic models, in\naddition to a better interpretability of the DR methods, provide a framework\nfor further extensions of such algorithms. One of the new approaches to the\nprobabilistic DR methods is to preserving the internal structure of data. It is\nmeant that it is not necessary that the data first be converted from the matrix\nor tensor format to the vector format in the process of dimensionality\nreduction. In this paper, a latent variable model for matrix-variate data for\ncanonical correlation analysis (CCA) is proposed. Since in general there is not\nany analytical maximum likelihood solution for this model, we present two\napproaches for learning the parameters. The proposed methods are evaluated\nusing the synthetic data in terms of convergence and quality of mappings. Also,\nreal data set is employed for assessing the proposed methods with several\nprobabilistic and none-probabilistic CCA based approaches. The results confirm\nthe superiority of the proposed methods with respect to the competing\nalgorithms. Moreover, this model can be considered as a framework for further\nextensions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 14:16:25 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Safayani", "Mehran", ""], ["Momenzadeh", "Saeid", ""]]}, {"id": "1708.01547", "submitter": "Jaehong Yoon", "authors": "Jaehong Yoon, Eunho Yang, Jeongtae Lee, Sung Ju Hwang", "title": "Lifelong Learning with Dynamically Expandable Networks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep network architecture for lifelong learning which we\nrefer to as Dynamically Expandable Network (DEN), that can dynamically decide\nits network capacity as it trains on a sequence of tasks, to learn a compact\noverlapping knowledge sharing structure among tasks. DEN is efficiently trained\nin an online manner by performing selective retraining, dynamically expands\nnetwork capacity upon arrival of each task with only the necessary number of\nunits, and effectively prevents semantic drift by splitting/duplicating units\nand timestamping them. We validate DEN on multiple public datasets under\nlifelong learning scenarios, on which it not only significantly outperforms\nexisting lifelong learning methods for deep networks, but also achieves the\nsame level of performance as the batch counterparts with substantially fewer\nnumber of parameters. Further, the obtained network fine-tuned on all tasks\nobtained significantly better performance over the batch models, which shows\nthat it can be used to estimate the optimal network structure even when all\ntasks are available in the first place.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 15:14:31 GMT"}, {"version": "v10", "created": "Fri, 2 Mar 2018 09:29:55 GMT"}, {"version": "v11", "created": "Mon, 11 Jun 2018 09:03:44 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 08:38:55 GMT"}, {"version": "v3", "created": "Thu, 24 Aug 2017 14:25:56 GMT"}, {"version": "v4", "created": "Wed, 13 Sep 2017 06:41:28 GMT"}, {"version": "v5", "created": "Thu, 14 Sep 2017 13:20:45 GMT"}, {"version": "v6", "created": "Mon, 2 Oct 2017 10:18:29 GMT"}, {"version": "v7", "created": "Mon, 30 Oct 2017 07:06:52 GMT"}, {"version": "v8", "created": "Tue, 31 Oct 2017 11:39:02 GMT"}, {"version": "v9", "created": "Thu, 1 Feb 2018 14:32:33 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Yoon", "Jaehong", ""], ["Yang", "Eunho", ""], ["Lee", "Jeongtae", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1708.01611", "submitter": "Paul Vitanyi", "authors": "Paul M.B. Vitanyi (CWI and University of Amsterdam) and Nick Chater\n  (Behavioural Science Group, Warwick Business School, University of Warwick,\n  Coventry, UK)", "title": "Identification of Probabilities", "comments": "31 pages LaTeX. arXiv admin note: substantial text overlap with\n  arXiv:1311.7385", "journal-ref": "Journal of Mathematical Psychology 51, 135-163 (2007)", "doi": "10.1016/j.jmp.2006.10.002", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within psychology, neuroscience and artificial intelligence, there has been\nincreasing interest in the proposal that the brain builds probabilistic models\nof sensory and linguistic input: that is, to infer a probabilistic model from a\nsample. The practical problems of such inference are substantial: the brain has\nlimited data and restricted computational resources. But there is a more\nfundamental question: is the problem of inferring a probabilistic model from a\nsample possible even in principle? We explore this question and find some\nsurprisingly positive and general results. First, for a broad class of\nprobability distributions characterised by computability restrictions, we\nspecify a learning algorithm that will almost surely identify a probability\ndistribution in the limit given a finite i.i.d. sample of sufficient but\nunknown length. This is similarly shown to hold for sequences generated by a\nbroad class of Markov chains, subject to computability assumptions. The\ntechnical tool is the strong law of large numbers. Second, for a large class of\ndependent sequences, we specify an algorithm which identifies in the limit a\ncomputable measure for which the sequence is typical, in the sense of\nMartin-Lof (there may be more than one such measure). The technical tool is the\ntheory of Kolmogorov complexity. We analyse the associated predictions in both\ncases. We also briefly consider special cases, including language learning, and\nwider theoretical implications for psychology.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 16:36:12 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Vitanyi", "Paul M. B.", "", "CWI and University of Amsterdam"], ["Chater", "Nick", "", "Behavioural Science Group, Warwick Business School, University of Warwick,\n  Coventry, UK"]]}, {"id": "1708.01648", "submitter": "Chuhang Zou", "authors": "Chuhang Zou, Ersin Yumer, Jimei Yang, Duygu Ceylan, Derek Hoiem", "title": "3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks", "comments": "ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of various applications including robotics, digital content\ncreation, and visualization demand a structured and abstract representation of\nthe 3D world from limited sensor data. Inspired by the nature of human\nperception of 3D shapes as a collection of simple parts, we explore such an\nabstract shape representation based on primitives. Given a single depth image\nof an object, we present 3D-PRNN, a generative recurrent neural network that\nsynthesizes multiple plausible shapes composed of a set of primitives. Our\ngenerative model encodes symmetry characteristics of common man-made objects,\npreserves long-range structural coherence, and describes objects of varying\ncomplexity with a compact representation. We also propose a method based on\nGaussian Fields to generate a large scale dataset of primitive-based shape\nrepresentations to train our network. We evaluate our approach on a wide range\nof examples and show that it outperforms nearest-neighbor based shape retrieval\nmethods and is on-par with voxel-based generative models while using a\nsignificantly reduced parameter space.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 19:30:13 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Zou", "Chuhang", ""], ["Yumer", "Ersin", ""], ["Yang", "Jimei", ""], ["Ceylan", "Duygu", ""], ["Hoiem", "Derek", ""]]}, {"id": "1708.01659", "submitter": "Emmanuel Osegi", "authors": "V.I. Anireh and EN Osegi", "title": "HTM-MAT: An online prediction software toolbox based on cortical machine\n  learning algorithm", "comments": "This research is currently under review in a Journal. Contents might\n  vary from final published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  HTM-MAT is a MATLAB based toolbox for implementing cortical learning\nalgorithms (CLA) including related cortical-like algorithms that possesses\nspatiotemporal properties. CLA is a suite of predictive machine learning\nalgorithms developed by Numenta Inc. and is based on the hierarchical temporal\nmemory (HTM). This paper presents an implementation of HTM-MAT with several\nillustrative examples including several toy datasets and compared with two\nsequence learning applications employing state-of-the-art algorithms - the\nrecurrentjs based on the Long Short-Term Memory (LSTM) algorithm and OS-ELM\nwhich is based on an online sequential version of the Extreme Learning Machine.\nThe performance of HTM-MAT using two historical benchmark datasets and one real\nworld dataset is also compared with one of the existing sequence learning\napplications, the OS-ELM. The results indicate that HTM-MAT predictions are\nindeed competitive and can outperform OS-ELM in sequential prediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 01:45:25 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Anireh", "V. I.", ""], ["Osegi", "EN", ""]]}, {"id": "1708.01666", "submitter": "Jie Cao", "authors": "Yang Jiang, Zeyang Dou, Qun Hao, Jie Cao, Kun Gao, Xi Chen", "title": "An Effective Training Method For Deep Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the nonlinearity generation method to speed up and\nstabilize the training of deep convolutional neural networks. The proposed\nmethod modifies a family of activation functions as nonlinearity generators\n(NGs). NGs make the activation functions linear symmetric for their inputs to\nlower model capacity, and automatically introduce nonlinearity to enhance the\ncapacity of the model during training. The proposed method can be considered an\nunusual form of regularization: the model parameters are obtained by training a\nrelatively low-capacity model, that is relatively easy to optimize at the\nbeginning, with only a few iterations, and these parameters are reused for the\ninitialization of a higher-capacity model. We derive the upper and lower bounds\nof variance of the weight variation, and show that the initial symmetric\nstructure of NGs helps stabilize training. We evaluate the proposed method on\ndifferent frameworks of convolutional neural networks over two object\nrecognition benchmark tasks (CIFAR-10 and CIFAR-100). Experimental results\nshowed that the proposed method allows us to (1) speed up the convergence of\ntraining, (2) allow for less careful weight initialization, (3) improve or at\nleast maintain the performance of the model at negligible extra computational\ncost, and (4) easily train a very deep model.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 23:19:03 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 14:41:04 GMT"}, {"version": "v3", "created": "Mon, 21 Aug 2017 15:45:11 GMT"}, {"version": "v4", "created": "Tue, 10 Oct 2017 08:58:03 GMT"}, {"version": "v5", "created": "Tue, 17 Oct 2017 15:53:20 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Jiang", "Yang", ""], ["Dou", "Zeyang", ""], ["Hao", "Qun", ""], ["Cao", "Jie", ""], ["Gao", "Kun", ""], ["Chen", "Xi", ""]]}, {"id": "1708.01715", "submitter": "Oleksii Kuchaiev", "authors": "Oleksii Kuchaiev, Boris Ginsburg", "title": "Training Deep AutoEncoders for Collaborative Filtering", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel model for the rating prediction task in\nrecommender systems which significantly outperforms previous state-of-the art\nmodels on a time-split Netflix data set. Our model is based on deep autoencoder\nwith 6 layers and is trained end-to-end without any layer-wise pre-training. We\nempirically demonstrate that: a) deep autoencoder models generalize much better\nthan the shallow ones, b) non-linear activation functions with negative parts\nare crucial for training deep models, and c) heavy use of regularization\ntechniques such as dropout is necessary to prevent over-fiting. We also propose\na new training algorithm based on iterative output re-feeding to overcome\nnatural sparseness of collaborate filtering. The new algorithm significantly\nspeeds up training and improves model performance. Our code is available at\nhttps://github.com/NVIDIA/DeepRecommender\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 06:31:50 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 23:45:27 GMT"}, {"version": "v3", "created": "Tue, 10 Oct 2017 22:31:59 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Kuchaiev", "Oleksii", ""], ["Ginsburg", "Boris", ""]]}, {"id": "1708.01729", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Weinan Zhang, Jun Wang", "title": "Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x))\n  Alternative", "comments": "An advanced version is included in arXiv:1703.02000 \"Activation\n  Maximization Generative Adversarial Nets\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we mathematically study several GAN related topics,\nincluding Inception score, label smoothing, gradient vanishing and the\n-log(D(x)) alternative.\n  ---\n  An advanced version is included in arXiv:1703.02000 \"Activation Maximization\nGenerative Adversarial Nets\".\n  Please refer Section 6 in 1703.02000 for detailed analysis on Inception\nScore, and refer its appendix for the discussions on Label Smoothing, Gradient\nVanishing and -log(D(x)) Alternative.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 08:15:07 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 02:30:32 GMT"}, {"version": "v3", "created": "Sat, 30 Jun 2018 07:02:11 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Zhou", "Zhiming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "1708.01733", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Rajiv Khanna, Joydeep Ghosh, Gunnar R\\\"atsch", "title": "Boosting Variational Inference: an Optimization Perspective", "comments": null, "journal-ref": "AISTATS 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is a popular technique to approximate a possibly\nintractable Bayesian posterior with a more tractable one. Recently, boosting\nvariational inference has been proposed as a new paradigm to approximate the\nposterior by a mixture of densities by greedily adding components to the\nmixture. However, as is the case with many other variational inference\nalgorithms, its theoretical properties have not been studied. In the present\nwork, we study the convergence properties of this approach from a modern\noptimization viewpoint by establishing connections to the classic Frank-Wolfe\nalgorithm. Our analyses yields novel theoretical insights regarding the\nsufficient conditions for convergence, explicit rates, and algorithmic\nsimplifications. Since a lot of focus in previous works for variational\ninference has been on tractability, our work is especially important as a much\nneeded attempt to bridge the gap between probabilistic models and their\ncorresponding theoretical properties.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 08:42:11 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 13:04:35 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Locatello", "Francesco", ""], ["Khanna", "Rajiv", ""], ["Ghosh", "Joydeep", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1708.01744", "submitter": "Vishnu Raj", "authors": "Vishnu Raj and Sheetal Kalyani", "title": "An aggregating strategy for shifting experts in discrete sequence\n  prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how we can adapt a predictor to a non-stationary environment with\nadvises from multiple experts. We study the problem under complete feedback\nwhen the best expert changes over time from a decision theoretic point of view.\nProposed algorithm is based on popular exponential weighing method with\nexponential discounting. We provide theoretical results bounding regret under\nthe exponential discounting setting. Upper bound on regret is derived for\nfinite time horizon problem. Numerical verification of different real life\ndatasets are provided to show the utility of proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 10:20:10 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Raj", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1708.01776", "submitter": "Clemens Rosenbaum", "authors": "Clemens Rosenbaum, Tian Gao, Tim Klinger", "title": "e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations", "comments": "7 pages, 3 figures, presented at 2017 ICML Workshop on Human\n  Interpretability in Machine Learning (WHI 2017), Sydney, NSW, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new dataset and user simulator e-QRAQ (explainable\nQuery, Reason, and Answer Question) which tests an Agent's ability to read an\nambiguous text; ask questions until it can answer a challenge question; and\nexplain the reasoning behind its questions and answer. The User simulator\nprovides the Agent with a short, ambiguous story and a challenge question about\nthe story. The story is ambiguous because some of the entities have been\nreplaced by variables. At each turn the Agent may ask for the value of a\nvariable or try to answer the challenge question. In response the User\nsimulator provides a natural language explanation of why the Agent's query or\nanswer was useful in narrowing down the set of possible answers, or not. To\ndemonstrate one potential application of the e-QRAQ dataset, we train a new\nneural architecture based on End-to-End Memory Networks to successfully\ngenerate both predictions and partial explanations of its current understanding\nof the problem. We observe a strong correlation between the quality of the\nprediction and explanation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 15:06:56 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Rosenbaum", "Clemens", ""], ["Gao", "Tian", ""], ["Klinger", "Tim", ""]]}, {"id": "1708.01799", "submitter": "Chen-Yu Wei", "authors": "Haipeng Luo and Chen-Yu Wei and Alekh Agarwal and John Langford", "title": "Efficient Contextual Bandits in Non-stationary Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most contextual bandit algorithms minimize regret against the best fixed\npolicy, a questionable benchmark for non-stationary environments that are\nubiquitous in applications. In this work, we develop several efficient\ncontextual bandit algorithms for non-stationary environments by equipping\nexisting methods for i.i.d. problems with sophisticated statistical tests so as\nto dynamically adapt to a change in distribution.\n  We analyze various standard notions of regret suited to non-stationary\nenvironments for these algorithms, including interval regret, switching regret,\nand dynamic regret. When competing with the best policy at each time, one of\nour algorithms achieves regret $\\mathcal{O}(\\sqrt{ST})$ if there are $T$ rounds\nwith $S$ stationary periods, or more generally\n$\\mathcal{O}(\\Delta^{1/3}T^{2/3})$ where $\\Delta$ is some non-stationarity\nmeasure. These results almost match the optimal guarantees achieved by an\ninefficient baseline that is a variant of the classic Exp4 algorithm. The\ndynamic regret result is also the first one for efficient and fully adversarial\ncontextual bandit.\n  Furthermore, while the results above require tuning a parameter based on the\nunknown quantity $S$ or $\\Delta$, we also develop a parameter free algorithm\nachieving regret $\\min\\{S^{1/4}T^{3/4}, \\Delta^{1/5}T^{4/5}\\}$. This improves\nand generalizes the best existing result $\\Delta^{0.18}T^{0.82}$ by Karnin and\nAnava (2016) which only holds for the two-armed bandit problem.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 18:21:31 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 06:58:43 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 17:26:07 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 18:51:43 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""], ["Agarwal", "Alekh", ""], ["Langford", "John", ""]]}, {"id": "1708.01867", "submitter": "Felix Leibfried", "authors": "Felix Leibfried, Jordi Grau-Moya and Haitham Bou-Ammar", "title": "An Information-Theoretic Optimality Principle for Deep Reinforcement\n  Learning", "comments": "Presented at the NIPS Deep Reinforcement Learning Workshop, Montreal,\n  Canada, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We methodologically address the problem of Q-value overestimation in deep\nreinforcement learning to handle high-dimensional state spaces efficiently. By\nadapting concepts from information theory, we introduce an intrinsic penalty\nsignal encouraging reduced Q-value estimates. The resultant algorithm\nencompasses a wide range of learning outcomes containing deep Q-networks as a\nspecial case. Different learning outcomes can be demonstrated by tuning a\nLagrange multiplier accordingly. We furthermore propose a novel scheduling\nscheme for this Lagrange multiplier to ensure efficient and robust learning. In\nexperiments on Atari, our algorithm outperforms other algorithms (e.g. deep and\ndouble deep Q-networks) in terms of both game-play performance and sample\ncomplexity. These results remain valid under the recently proposed dueling\narchitecture.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 09:23:22 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 16:27:50 GMT"}, {"version": "v3", "created": "Thu, 8 Feb 2018 14:07:53 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 09:27:21 GMT"}, {"version": "v5", "created": "Tue, 20 Nov 2018 11:55:21 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Leibfried", "Felix", ""], ["Grau-Moya", "Jordi", ""], ["Bou-Ammar", "Haitham", ""]]}, {"id": "1708.01886", "submitter": "Hamid Eghbal-zadeh", "authors": "Hamid Eghbal-zadeh, Gerhard Widmer", "title": "Probabilistic Generative Adversarial Networks", "comments": "Submitted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Probabilistic Generative Adversarial Network (PGAN), a new\nGAN variant based on a new kind of objective function. The central idea is to\nintegrate a probabilistic model (a Gaussian Mixture Model, in our case) into\nthe GAN framework which supports a new kind of loss function (based on\nlikelihood rather than classification loss), and at the same time gives a\nmeaningful measure of the quality of the outputs generated by the network.\nExperiments with MNIST show that the model learns to generate realistic images,\nand at the same time computes likelihoods that are correlated with the quality\nof the generated images. We show that PGAN is better able to cope with\ninstability problems that are usually observed in the GAN training procedure.\nWe investigate this from three aspects: the probability landscape of the\ndiscriminator, gradients of the generator, and the perfect discriminator\nproblem.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 13:09:59 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Eghbal-zadeh", "Hamid", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1708.01902", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Universally consistent predictive distributions", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes simple universally consistent procedures of probability\nforecasting that satisfy a natural property of small-sample validity, under the\nassumption that the observations are produced independently in the IID fashion.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 15:28:37 GMT"}, {"version": "v2", "created": "Wed, 30 Aug 2017 12:06:15 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "1708.01910", "submitter": "Hamidou Tembine", "authors": "Brian Powers and Michalis Smyrnakis and Hamidou Tembine", "title": "Empathy in Bimatrix Games", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the definition of what empathetic preferences exactly are is still\nevolving, there is a general consensus in the psychology, science and\nengineering communities that the evolution toward players' behaviors in\ninteractive decision-making problems will be accompanied by the exploitation of\ntheir empathy, sympathy, compassion, antipathy, spitefulness, selfishness,\naltruism, and self-abnegating states in the payoffs. In this article, we study\none-shot bimatrix games from a psychological game theory viewpoint. A new\nempathetic payoff model is calculated to fit empirical observations and both\npure and mixed equilibria are investigated. For a realized empathy structure,\nthe bimatrix game is categorized among four generic class of games. Number of\ninteresting results are derived. A notable level of involvement can be observed\nin the empathetic one-shot game compared the non-empathetic one and this holds\neven for games with dominated strategies. Partial altruism can help in breaking\nsymmetry, in reducing payoff-inequality and in selecting social welfare and\nmore efficient outcomes. By contrast, partial spite and self-abnegating may\nworsen payoff equity. Empathetic evolutionary game dynamics are introduced to\ncapture the resulting empathetic evolutionarily stable strategies under wide\nrange of revision protocols including Brown-von Neumann-Nash, Smith, imitation,\nreplicator, and hybrid dynamics. Finally, mutual support and Berge solution are\ninvestigated and their connection with empathetic preferences are established.\nWe show that pure altruism is logically inconsistent, only by balancing it with\nsome partial selfishness does it create a consistent psychology.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 17:01:41 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Powers", "Brian", ""], ["Smyrnakis", "Michalis", ""], ["Tembine", "Hamidou", ""]]}, {"id": "1708.01911", "submitter": "Thomas Kurbiel", "authors": "Thomas Kurbiel and Shahrzad Khaleghian", "title": "Training of Deep Neural Networks based on Distance Measures using\n  RMSProp", "comments": "6 pages, 14 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vanishing gradient problem was a major obstacle for the success of deep\nlearning. In recent years it was gradually alleviated through multiple\ndifferent techniques. However the problem was not really overcome in a\nfundamental way, since it is inherent to neural networks with activation\nfunctions based on dot products. In a series of papers, we are going to analyze\nalternative neural network structures which are not based on dot products. In\nthis first paper, we revisit neural networks built up of layers based on\ndistance measures and Gaussian activation functions. These kinds of networks\nwere only sparsely used in the past since they are hard to train when using\nplain stochastic gradient descent methods. We show that by using Root Mean\nSquare Propagation (RMSProp) it is possible to efficiently learn multi-layer\nneural networks. Furthermore we show that when appropriately initialized these\nkinds of neural networks suffer much less from the vanishing and exploding\ngradient problem than traditional neural networks even for deep networks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 17:10:38 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Kurbiel", "Thomas", ""], ["Khaleghian", "Shahrzad", ""]]}, {"id": "1708.01945", "submitter": "Shusen Wang", "authors": "Miles E. Lopes and Shusen Wang and Michael W. Mahoney", "title": "A Bootstrap Method for Error Estimation in Randomized Matrix\n  Multiplication", "comments": null, "journal-ref": "Journal of Machine Learning Research, 20(39): 1-40, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, randomized methods for numerical linear algebra have\nreceived growing interest as a general approach to large-scale problems.\nTypically, the essential ingredient of these methods is some form of randomized\ndimension reduction, which accelerates computations, but also creates random\napproximation error. In this way, the dimension reduction step encodes a\ntradeoff between cost and accuracy. However, the exact numerical relationship\nbetween cost and accuracy is typically unknown, and consequently, it may be\ndifficult for the user to precisely know (1) how accurate a given solution is,\nor (2) how much computation is needed to achieve a given level of accuracy. In\nthe current paper, we study randomized matrix multiplication (sketching) as a\nprototype setting for addressing these general problems. As a solution, we\ndevelop a bootstrap method for \\emph{directly estimating} the accuracy as a\nfunction of the reduced dimension (as opposed to deriving worst-case bounds on\nthe accuracy in terms of the reduced dimension). From a computational\nstandpoint, the proposed method does not substantially increase the cost of\nstandard sketching methods, and this is made possible by an \"extrapolation\"\ntechnique. In addition, we provide both theoretical and empirical results to\ndemonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 22:20:13 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 01:20:24 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Lopes", "Miles E.", ""], ["Wang", "Shusen", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1708.01960", "submitter": "Qiang Wu", "authors": "Zhengchu Guo, Lei Shi and Qiang Wu", "title": "Learning Theory of Distributed Regression with Bias Corrected\n  Regularization Kernel Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning is an effective way to analyze big data. In distributed\nregression, a typical approach is to divide the big data into multiple blocks,\napply a base regression algorithm on each of them, and then simply average the\noutput functions learnt from these blocks. Since the average process will\ndecrease the variance, not the bias, bias correction is expected to improve the\nlearning performance if the base regression algorithm is a biased one.\nRegularization kernel network is an effective and widely used method for\nnonlinear regression analysis. In this paper we will investigate a bias\ncorrected version of regularization kernel network. We derive the error bounds\nwhen it is applied to a single data set and when it is applied as a base\nalgorithm in distributed regression. We show that, under certain appropriate\nconditions, the optimal learning rates can be reached in both situations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 01:54:56 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Guo", "Zhengchu", ""], ["Shi", "Lei", ""], ["Wu", "Qiang", ""]]}, {"id": "1708.01977", "submitter": "Xinkun Nie", "authors": "Xinkun Nie, Xiaoying Tian, Jonathan Taylor, James Zou", "title": "Why Adaptively Collected Data Have Negative Bias and How to Correct for\n  It", "comments": "Accepted to the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From scientific experiments to online A/B testing, the previously observed\ndata often affects how future experiments are performed, which in turn affects\nwhich data will be collected. Such adaptivity introduces complex correlations\nbetween the data and the collection procedure. In this paper, we prove that\nwhen the data collection procedure satisfies natural conditions, then sample\nmeans of the data have systematic \\emph{negative} biases. As an example,\nconsider an adaptive clinical trial where additional data points are more\nlikely to be tested for treatments that show initial promise. Our surprising\nresult implies that the average observed treatment effects would underestimate\nthe true effects of each treatment. We quantitatively analyze the magnitude and\nbehavior of this negative bias in a variety of settings. We also propose a\nnovel debiasing algorithm based on selective inference techniques. In\nexperiments, our method can effectively reduce bias and estimation error.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 03:30:05 GMT"}, {"version": "v2", "created": "Sat, 30 Dec 2017 20:45:47 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Nie", "Xinkun", ""], ["Tian", "Xiaoying", ""], ["Taylor", "Jonathan", ""], ["Zou", "James", ""]]}, {"id": "1708.02044", "submitter": "Ziwei Liu", "authors": "Sijie Yan, Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, Xiaoou Tang", "title": "Unconstrained Fashion Landmark Detection via Hierarchical Recurrent\n  Transformer Networks", "comments": "To appear in ACM Multimedia (ACM MM) 2017 as a full research paper.\n  More details at the project page:\n  http://personal.ie.cuhk.edu.hk/~lz013/projects/UnconstrainedLandmarks.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fashion landmarks are functional key points defined on clothes, such as\ncorners of neckline, hemline, and cuff. They have been recently introduced as\nan effective visual representation for fashion image understanding. However,\ndetecting fashion landmarks are challenging due to background clutters, human\nposes, and scales. To remove the above variations, previous works usually\nassumed bounding boxes of clothes are provided in training and test as\nadditional annotations, which are expensive to obtain and inapplicable in\npractice. This work addresses unconstrained fashion landmark detection, where\nclothing bounding boxes are not provided in both training and test. To this\nend, we present a novel Deep LAndmark Network (DLAN), where bounding boxes and\nlandmarks are jointly estimated and trained iteratively in an end-to-end\nmanner. DLAN contains two dedicated modules, including a Selective Dilated\nConvolution for handling scale discrepancies, and a Hierarchical Recurrent\nSpatial Transformer for handling background clutters. To evaluate DLAN, we\npresent a large-scale fashion landmark dataset, namely Unconstrained Landmark\nDatabase (ULD), consisting of 30K images. Statistics show that ULD is more\nchallenging than existing datasets in terms of image scales, background\nclutters, and human poses. Extensive experiments demonstrate the effectiveness\nof DLAN over the state-of-the-art methods. DLAN also exhibits excellent\ngeneralization across different clothing categories and modalities, making it\nextremely suitable for real-world fashion analysis.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 09:02:52 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Yan", "Sijie", ""], ["Liu", "Ziwei", ""], ["Luo", "Ping", ""], ["Qiu", "Shi", ""], ["Wang", "Xiaogang", ""], ["Tang", "Xiaoou", ""]]}, {"id": "1708.02059", "submitter": "Xinyue Shen", "authors": "Xinyue Shen, Yuantao Gu", "title": "Nonconvex Sparse Logistic Regression with Weakly Convex Regularization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2824289", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose to fit a sparse logistic regression model by a weakly\nconvex regularized nonconvex optimization problem. The idea is based on the\nfinding that a weakly convex function as an approximation of the $\\ell_0$\npseudo norm is able to better induce sparsity than the commonly used $\\ell_1$\nnorm. For a class of weakly convex sparsity inducing functions, we prove the\nnonconvexity of the corresponding sparse logistic regression problem, and study\nits local optimality conditions and the choice of the regularization parameter\nto exclude trivial solutions. Despite the nonconvexity, a method based on\nproximal gradient descent is used to solve the general weakly convex sparse\nlogistic regression, and its convergence behavior is studied theoretically.\nThen the general framework is applied to a specific weakly convex function, and\na necessary and sufficient local optimality condition is provided. The solution\nmethod is instantiated in this case as an iterative firm-shrinkage algorithm,\nand its effectiveness is demonstrated in numerical experiments by both randomly\ngenerated and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 10:19:16 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Shen", "Xinyue", ""], ["Gu", "Yuantao", ""]]}, {"id": "1708.02072", "submitter": "Ronald Kemker", "authors": "Ronald Kemker, Marc McClure, Angelina Abitino, Tyler Hayes, and\n  Christopher Kanan", "title": "Measuring Catastrophic Forgetting in Neural Networks", "comments": "To appear in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are used in many state-of-the-art systems for machine\nperception. Once a network is trained to do a specific task, e.g., bird\nclassification, it cannot easily be trained to do new tasks, e.g.,\nincrementally learning to recognize additional bird species or learning an\nentirely different task such as flower recognition. When new tasks are added,\ntypical deep neural networks are prone to catastrophically forgetting previous\ntasks. Networks that are capable of assimilating new information incrementally,\nmuch like how humans form new memories over time, will be more efficient than\nre-training the model from scratch each time a new task needs to be learned.\nThere have been multiple attempts to develop schemes that mitigate catastrophic\nforgetting, but these methods have not been directly compared, the tests used\nto evaluate them vary considerably, and these methods have only been evaluated\non small-scale problems (e.g., MNIST). In this paper, we introduce new metrics\nand benchmarks for directly comparing five different mechanisms designed to\nmitigate catastrophic forgetting in neural networks: regularization,\nensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on\nreal-world images and sounds show that the mechanism(s) that are critical for\noptimal performance vary based on the incremental training paradigm and type of\ndata being used, but they all demonstrate that the catastrophic forgetting\nproblem has yet to be solved.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 11:18:43 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 09:33:24 GMT"}, {"version": "v3", "created": "Mon, 11 Sep 2017 16:50:39 GMT"}, {"version": "v4", "created": "Thu, 9 Nov 2017 14:53:07 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kemker", "Ronald", ""], ["McClure", "Marc", ""], ["Abitino", "Angelina", ""], ["Hayes", "Tyler", ""], ["Kanan", "Christopher", ""]]}, {"id": "1708.02105", "submitter": "Wei Hu", "authors": "Zeyuan Allen-Zhu, Elad Hazan, Wei Hu, Yuanzhi Li", "title": "Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls", "comments": "In NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a rank-$k$ variant of the classical Frank-Wolfe algorithm to solve\nconvex optimization over a trace-norm ball. Our algorithm replaces the top\nsingular-vector computation ($1$-SVD) in Frank-Wolfe with a top-$k$\nsingular-vector computation ($k$-SVD), which can be done by repeatedly applying\n$1$-SVD $k$ times. Alternatively, our algorithm can be viewed as a rank-$k$\nrestricted version of projected gradient descent. We show that our algorithm\nhas a linear convergence rate when the objective function is smooth and\nstrongly convex, and the optimal solution has rank at most $k$. This improves\nthe convergence rate and the total time complexity of the Frank-Wolfe method\nand its variants.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 13:07:20 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 23:33:37 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 02:16:15 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Hazan", "Elad", ""], ["Hu", "Wei", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1708.02182", "submitter": "Stephen Merity", "authors": "Stephen Merity, Nitish Shirish Keskar, Richard Socher", "title": "Regularizing and Optimizing LSTM Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs), such as long short-term memory networks\n(LSTMs), serve as a fundamental building block for many sequence learning\ntasks, including machine translation, language modeling, and question\nanswering. In this paper, we consider the specific problem of word-level\nlanguage modeling and investigate strategies for regularizing and optimizing\nLSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on\nhidden-to-hidden weights as a form of recurrent regularization. Further, we\nintroduce NT-ASGD, a variant of the averaged stochastic gradient method,\nwherein the averaging trigger is determined using a non-monotonic condition as\nopposed to being tuned by the user. Using these and other regularization\nstrategies, we achieve state-of-the-art word level perplexities on two data\nsets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the\neffectiveness of a neural cache in conjunction with our proposed model, we\nachieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and\n52.0 on WikiText-2.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 16:03:44 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Merity", "Stephen", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1708.02188", "submitter": "Ulrich Finkler", "authors": "Minsik Cho, Ulrich Finkler, Sameer Kumar, David Kung, Vaibhav Saxena,\n  Dheeraj Sreedhar", "title": "PowerAI DDL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks become more complex and input datasets grow larger,\nit can take days or even weeks to train a deep neural network to the desired\naccuracy. Therefore, distributed Deep Learning at a massive scale is a critical\ncapability, since it offers the potential to reduce the training time from\nweeks to hours. In this paper, we present a software-hardware co-optimized\ndistributed Deep Learning system that can achieve near-linear scaling up to\nhundreds of GPUs. The core algorithm is a multi-ring communication pattern that\nprovides a good tradeoff between latency and bandwidth and adapts to a variety\nof system configurations. The communication algorithm is implemented as a\nlibrary for easy use. This library has been integrated into Tensorflow, Caffe,\nand Torch. We train Resnet-101 on Imagenet 22K with 64 IBM Power8 S822LC\nservers (256 GPUs) in about 7 hours to an accuracy of 33.8 % validation\naccuracy. Microsoft's ADAM and Google's DistBelief results did not reach 30 %\nvalidation accuracy for Imagenet 22K. Compared to Facebook AI Research's recent\npaper on 256 GPU training, we use a different communication algorithm, and our\ncombined software and hardware system offers better communication overhead for\nResnet-50. A PowerAI DDL enabled version of Torch completed 90 epochs of\ntraining on Resnet 50 for 1K classes in 50 minutes using 64 IBM Power8 S822LC\nservers (256 GPUs).\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 16:24:00 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Cho", "Minsik", ""], ["Finkler", "Ulrich", ""], ["Kumar", "Sameer", ""], ["Kung", "David", ""], ["Saxena", "Vaibhav", ""], ["Sreedhar", "Dheeraj", ""]]}, {"id": "1708.02190", "submitter": "S\\'ebastien Forestier", "authors": "S\\'ebastien Forestier, R\\'emy Portelas, Yoan Mollard, Pierre-Yves\n  Oudeyer", "title": "Intrinsically Motivated Goal Exploration Processes with Automatic\n  Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsically motivated spontaneous exploration is a key enabler of\nautonomous lifelong learning in human children. It enables the discovery and\nacquisition of large repertoires of skills through self-generation,\nself-selection, self-ordering and self-experimentation of learning goals. We\npresent an algorithmic approach called Intrinsically Motivated Goal Exploration\nProcesses (IMGEP) to enable similar properties of autonomous or self-supervised\nlearning in machines. The IMGEP algorithmic architecture relies on several\nprinciples: 1) self-generation of goals, generalized as fitness functions; 2)\nselection of goals based on intrinsic rewards; 3) exploration with incremental\ngoal-parameterized policy search and exploitation of the gathered data with a\nbatch learning algorithm; 4) systematic reuse of information acquired when\ntargeting a goal for improving towards other goals. We present a particularly\nefficient form of IMGEP, called Modular Population-Based IMGEP, that uses a\npopulation-based policy and an object-centered modularity in goals and\nmutations. We provide several implementations of this architecture and\ndemonstrate their ability to automatically generate a learning curriculum\nwithin several experimental setups including a real humanoid robot that can\nexplore multiple spaces of goals with several hundred continuous dimensions.\nWhile no particular target goal is provided to the system, this curriculum\nallows the discovery of skills that act as stepping stone for learning more\ncomplex skills, e.g. nested tool use. We show that learning diverse spaces of\ngoals with intrinsic motivations is more efficient for learning complex skills\nthan only trying to directly learn these complex skills.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 16:32:39 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 10:12:16 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Forestier", "S\u00e9bastien", ""], ["Portelas", "R\u00e9my", ""], ["Mollard", "Yoan", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1708.02237", "submitter": "Michael Vertolli", "authors": "Michael O. Vertolli and Jim Davies", "title": "Image Quality Assessment Techniques Show Improved Training and\n  Evaluation of Autoencoder Generative Adversarial Networks", "comments": "10 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a training and evaluation approach for autoencoder Generative\nAdversarial Networks (GANs), specifically the Boundary Equilibrium Generative\nAdversarial Network (BEGAN), based on methods from the image quality assessment\nliterature. Our approach explores a multidimensional evaluation criterion that\nutilizes three distance functions: an $l_1$ score, the Gradient Magnitude\nSimilarity Mean (GMSM) score, and a chrominance score. We show that each of the\ndifferent distance functions captures a slightly different set of properties in\nimage space and, consequently, requires its own evaluation criterion to\nproperly assess whether the relevant property has been adequately learned. We\nshow that models using the new distance functions are able to produce better\nimages than the original BEGAN model in predicted ways.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 16:31:07 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Vertolli", "Michael O.", ""], ["Davies", "Jim", ""]]}, {"id": "1708.02276", "submitter": "Jacob Schroder", "authors": "Jacob B. Schroder", "title": "Parallelizing Over Artificial Neural Network Training Runs with\n  Multigrid", "comments": "Version 2: - Added more complete references to basic neural network\n  literature - Corrected typos - Condensed results in Section 3 to be more\n  concise - 22 pages", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-736173", "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks are a popular and effective machine learning\ntechnique. Great progress has been made parallelizing the expensive training\nphase of an individual network, leading to highly specialized pieces of\nhardware, many based on GPU-type architectures, and more concurrent algorithms\nsuch as synthetic gradients. However, the training phase continues to be a\nbottleneck, where the training data must be processed serially over thousands\nof individual training runs. This work considers a multigrid reduction in time\n(MGRIT) algorithm that is able to parallelize over the thousands of training\nruns and converge to the exact same solution as traditional training would\nprovide. MGRIT was originally developed to provide parallelism for time\nevolution problems that serially step through a finite number of time-steps.\nThis work recasts the training of a neural network similarly, treating neural\nnetwork training as an evolution equation that evolves the network weights from\none step to the next. Thus, this work concerns distributed computing approaches\nfor neural networks, but is distinct from other approaches which seek to\nparallelize only over individual training runs. The work concludes with\nsupporting numerical results for two model problems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 19:42:24 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 18:14:19 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Schroder", "Jacob B.", ""]]}, {"id": "1708.02286", "submitter": "Yu Cheng", "authors": "Shuangjie Xu, Yu Cheng, Kang Gu, Yang Yang, Shiyu Chang, Pan Zhou", "title": "Jointly Attentive Spatial-Temporal Pooling Networks for Video-based\n  Person Re-Identification", "comments": "To appear in ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person Re-Identification (person re-id) is a crucial task as its applications\nin visual surveillance and human-computer interaction. In this work, we present\na novel joint Spatial and Temporal Attention Pooling Network (ASTPN) for\nvideo-based person re-identification, which enables the feature extractor to be\naware of the current input video sequences, in a way that interdependency from\nthe matching items can directly influence the computation of each other's\nrepresentation. Specifically, the spatial pooling layer is able to select\nregions from each frame, while the attention temporal pooling performed can\nselect informative frames over the sequence, both pooling guided by the\ninformation from distance matching. Experiments are conduced on the iLIDS-VID,\nPRID-2011 and MARS datasets and the results demonstrate that this approach\noutperforms existing state-of-art methods. We also analyze how the joint\npooling in both dimensions can boost the person re-id performance more\neffectively than using either of them separately.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 02:35:17 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 14:41:58 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Xu", "Shuangjie", ""], ["Cheng", "Yu", ""], ["Gu", "Kang", ""], ["Yang", "Yang", ""], ["Chang", "Shiyu", ""], ["Zhou", "Pan", ""]]}, {"id": "1708.02300", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Reinforced Video Captioning with Entailment Rewards", "comments": "EMNLP 2017 (9 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models have shown promising improvements on the temporal\ntask of video captioning, but they optimize word-level cross-entropy loss\nduring training. First, using policy gradient and mixed-loss methods for\nreinforcement learning, we directly optimize sentence-level task-based metrics\n(as rewards), achieving significant improvements over the baseline, based on\nboth automatic metrics and human evaluation on multiple datasets. Next, we\npropose a novel entailment-enhanced reward (CIDEnt) that corrects\nphrase-matching based metrics (such as CIDEr) to only allow for\nlogically-implied partial matches and avoid contradictions, achieving further\nsignificant improvements over the CIDEr-reward model. Overall, our\nCIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 20:50:24 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1708.02312", "submitter": "Yixin Nie", "authors": "Yixin Nie, Mohit Bansal", "title": "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference", "comments": "EMNLP 2017 RepEval Multi-NLI Shared Task (6 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple sequential sentence encoder for multi-domain natural\nlanguage inference. Our encoder is based on stacked bidirectional LSTM-RNNs\nwith shortcut connections and fine-tuning of word embeddings. The overall\nsupervised model uses the above encoder to encode two input sentences into two\nvectors, and then uses a classifier over the vector combination to label the\nrelationship between these two sentences as that of entailment, contradiction,\nor neural. Our Shortcut-Stacked sentence encoders achieve strong improvements\nover existing encoders on matched and mismatched multi-domain natural language\ninference (top non-ensemble single-model result in the EMNLP RepEval 2017\nShared Task (Nangia et al., 2017)). Moreover, they achieve the new\nstate-of-the-art encoding result on the original SNLI dataset (Bowman et al.,\n2015).\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 21:33:11 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 18:15:47 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Nie", "Yixin", ""], ["Bansal", "Mohit", ""]]}, {"id": "1708.02313", "submitter": "Avi Singh", "authors": "Avi Singh, Larry Yang, Sergey Levine", "title": "GPLAC: Generalizing Vision-Based Robotic Skills using Weakly Labeled\n  Images", "comments": "ICCV 2017. Also accepted at ICML 2017 Workshop on Lifelong Learning:\n  A Reinforcement Learning Approach. Webpage:\n  https://people.eecs.berkeley.edu/~avisingh/iccv17/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of learning robotic sensorimotor control policies that\ncan generalize to visually diverse and unseen environments. Achieving broad\ngeneralization typically requires large datasets, which are difficult to obtain\nfor task-specific interactive processes such as reinforcement learning or\nlearning from demonstration. However, much of the visual diversity in the world\ncan be captured through passively collected datasets of images or videos. In\nour method, which we refer to as GPLAC (Generalized Policy Learning with\nAttentional Classifier), we use both interaction data and weakly labeled image\ndata to augment the generalization capacity of sensorimotor policies. Our\nmethod combines multitask learning on action selection and an auxiliary binary\nclassification objective, together with a convolutional neural network\narchitecture that uses an attentional mechanism to avoid distractors. We show\nthat pairing interaction data from just a single environment with a diverse\ndataset of weakly labeled data results in greatly improved generalization to\nunseen environments, and show that this generalization depends on both the\nauxiliary objective and the attentional architecture that we propose. We\ndemonstrate our results in both simulation and on a real robotic manipulator,\nand demonstrate substantial improvement over standard convolutional\narchitectures and domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 21:34:59 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Singh", "Avi", ""], ["Yang", "Larry", ""], ["Levine", "Sergey", ""]]}, {"id": "1708.02340", "submitter": "Xiao Lin", "authors": "Xiao Lin, Gabriel Terejanu", "title": "EnLLVM: Ensemble Based Nonlinear Bayesian Filtering Using Linear Latent\n  Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time nonlinear Bayesian filtering algorithms are overwhelmed by data\nvolume, velocity and increasing complexity of computational models. In this\npaper, we propose a novel ensemble based nonlinear Bayesian filtering approach\nwhich only requires a small number of simulations and can be applied to\nhigh-dimensional systems in the presence of intractable likelihood functions.\nThe proposed approach uses linear latent projections to estimate the joint\nprobability distribution between states, parameters, and observables using a\nmixture of Gaussian components generated by the reconstruction error for each\nensemble member. Since it leverages the computational machinery behind linear\nlatent variable models, it can achieve fast implementations without the need to\ncompute high-dimensional sample covariance matrices. The performance of the\nproposed approach is compared with the performance of ensemble Kalman filter on\na high-dimensional Lorenz nonlinear dynamical system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 00:45:18 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 03:25:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Lin", "Xiao", ""], ["Terejanu", "Gabriel", ""]]}, {"id": "1708.02383", "submitter": "Meng Fang", "authors": "Meng Fang, Yuan Li and Trevor Cohn", "title": "Learning how to Active Learn: A Deep Reinforcement Learning Approach", "comments": "To appear in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to select a small subset of data for annotation such\nthat a classifier learned on the data is highly accurate. This is usually done\nusing heuristic selection methods, however the effectiveness of such methods is\nlimited and moreover, the performance of heuristics varies between datasets. To\naddress these shortcomings, we introduce a novel formulation by reframing the\nactive learning as a reinforcement learning problem and explicitly learning a\ndata selection policy, where the policy takes the role of the active learning\nheuristic. Importantly, our method allows the selection policy learned using\nsimulation on one language to be transferred to other languages. We demonstrate\nour method using cross-lingual named entity recognition, observing uniform\nimprovements over traditional active learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 07:06:48 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Fang", "Meng", ""], ["Li", "Yuan", ""], ["Cohn", "Trevor", ""]]}, {"id": "1708.02406", "submitter": "Yoav Wald", "authors": "Yoav Wald, Amir Globerson", "title": "Robust Conditional Probabilities", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional probabilities are a core concept in machine learning. For\nexample, optimal prediction of a label $Y$ given an input $X$ corresponds to\nmaximizing the conditional probability of $Y$ given $X$. A common approach to\ninference tasks is learning a model of conditional probabilities. However,\nthese models are often based on strong assumptions (e.g., log-linear models),\nand hence their estimate of conditional probabilities is not robust and is\nhighly dependent on the validity of their assumptions.\n  Here we propose a framework for reasoning about conditional probabilities\nwithout assuming anything about the underlying distributions, except knowledge\nof their second order marginals, which can be estimated from data. We show how\nthis setting leads to guaranteed bounds on conditional probabilities, which can\nbe calculated efficiently in a variety of settings, including\nstructured-prediction. Finally, we apply them to semi-supervised deep learning,\nobtaining results competitive with variational autoencoders.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 08:42:09 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Wald", "Yoav", ""], ["Globerson", "Amir", ""]]}, {"id": "1708.02455", "submitter": "Linxiao Yang", "authors": "Linxiao Yang, Jun Fang, Huiping Duan, Hongbin Li and Bing Zeng", "title": "Fast Low-Rank Bayesian Matrix Completion with Hierarchical Gaussian\n  Prior Models", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2816575", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of low rank matrix completion is considered in this paper. To\nexploit the underlying low-rank structure of the data matrix, we propose a\nhierarchical Gaussian prior model, where columns of the low-rank matrix are\nassumed to follow a Gaussian distribution with zero mean and a common precision\nmatrix, and a Wishart distribution is specified as a hyperprior over the\nprecision matrix. We show that such a hierarchical Gaussian prior has the\npotential to encourage a low-rank solution. Based on the proposed hierarchical\nprior model, a variational Bayesian method is developed for matrix completion,\nwhere the generalized approximate massage passing (GAMP) technique is embedded\ninto the variational Bayesian inference in order to circumvent cumbersome\nmatrix inverse operations. Simulation results show that our proposed method\ndemonstrates superiority over existing state-of-the-art matrix completion\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 11:59:10 GMT"}, {"version": "v2", "created": "Sat, 26 Aug 2017 14:19:54 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Yang", "Linxiao", ""], ["Fang", "Jun", ""], ["Duan", "Huiping", ""], ["Li", "Hongbin", ""], ["Zeng", "Bing", ""]]}, {"id": "1708.02469", "submitter": "Samuel Gerber", "authors": "Samuel Gerber and Mauro Maggioni", "title": "Multiscale Strategies for Computing Optimal Transport", "comments": "Accepted to JMLR", "journal-ref": "Journal of Machine Learning Research 18 (2017): 1-32", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multiscale approach to efficiently compute approximate\noptimal transport plans between point sets. It is particularly well-suited for\npoint sets that are in high-dimensions, but are close to being intrinsically\nlow-dimensional. The approach is based on an adaptive multiscale decomposition\nof the point sets. The multiscale decomposition yields a sequence of optimal\ntransport problems, that are solved in a top-to-bottom fashion from the\ncoarsest to the finest scale. We provide numerical evidence that this\nmultiscale approach scales approximately linearly, in time and memory, in the\nnumber of nodes, instead of quadratically or worse for a direct solution.\nEmpirically, the multiscale approach results in less than one percent relative\nerror in the objective function. Furthermore, the multiscale plans constructed\nare of interest by themselves as they may be used to introduce novel features\nand notions of distances between point sets. An analysis of sets of brain MRI\nbased on optimal transport distances illustrates the effectiveness of the\nproposed method on a real world data set. The application demonstrates that\nmultiscale optimal transport distances have the potential to improve on\nstate-of-the-art metrics currently used in computational anatomy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 12:54:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gerber", "Samuel", ""], ["Maggioni", "Mauro", ""]]}, {"id": "1708.02497", "submitter": "Janne Lepp\\\"a-aho", "authors": "Janne Lepp\\\"a-aho, Santeri R\\\"ais\\\"anen, Xiao Yang, Teemu Roos", "title": "Learning non-parametric Markov networks with mutual information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for learning Markov network structures for continuous\ndata without invoking any assumptions about the distribution of the variables.\nThe method makes use of previous work on a non-parametric estimator for mutual\ninformation which is used to create a non-parametric test for multivariate\nconditional independence. This independence test is then combined with an\nefficient constraint-based algorithm for learning the graph structure. The\nperformance of the method is evaluated on several synthetic data sets and it is\nshown to learn considerably more accurate structures than competing methods\nwhen the dependencies between the variables involve non-linearities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 14:10:55 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Lepp\u00e4-aho", "Janne", ""], ["R\u00e4is\u00e4nen", "Santeri", ""], ["Yang", "Xiao", ""], ["Roos", "Teemu", ""]]}, {"id": "1708.02511", "submitter": "Gabriel Huang", "authors": "Gabriel Huang, Hugo Berard, Ahmed Touati, Gauthier Gidel, Pascal\n  Vincent, Simon Lacoste-Julien", "title": "Parametric Adversarial Divergences are Good Task Losses for Generative\n  Modeling", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modeling of high dimensional data like images is a notoriously\ndifficult and ill-defined problem. In particular, how to evaluate a learned\ngenerative model is unclear. In this position paper, we argue that adversarial\nlearning, pioneered with generative adversarial networks (GANs), provides an\ninteresting framework to implicitly define more meaningful task losses for\ngenerative modeling tasks, such as for generating \"visually realistic\" images.\nWe refer to those task losses as parametric adversarial divergences and we give\ntwo main reasons why we think parametric divergences are good learning\nobjectives for generative modeling. Additionally, we unify the processes of\nchoosing a good structured loss (in structured prediction) and choosing a\ndiscriminator architecture (in generative modeling) using statistical decision\ntheory; we are then able to formalize and quantify the intuition that \"weaker\"\nlosses are easier to learn from, in a specific setting. Finally, we propose two\nnew challenging tasks to evaluate parametric and nonparametric divergences: a\nqualitative task of generating very high-resolution digits, and a quantitative\ntask of learning data that satisfies high-level algebraic constraints. We use\ntwo common divergences to train a generator and show that the parametric\ndivergence outperforms the nonparametric divergence on both the qualitative and\nthe quantitative task.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 15:01:55 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 00:13:56 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 19:58:51 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Huang", "Gabriel", ""], ["Berard", "Hugo", ""], ["Touati", "Ahmed", ""], ["Gidel", "Gauthier", ""], ["Vincent", "Pascal", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1708.02544", "submitter": "Farnood Salehi", "authors": "Farnood Salehi, L. Elisa Celis and Patrick Thiran", "title": "Stochastic Optimization with Bandit Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many stochastic optimization algorithms work by estimating the gradient of\nthe cost function on the fly by sampling datapoints uniformly at random from a\ntraining set. However, the estimator might have a large variance, which\ninadvertently slows down the convergence rate of the algorithms. One way to\nreduce this variance is to sample the datapoints from a carefully selected\nnon-uniform distribution. In this work, we propose a novel non-uniform sampling\napproach that uses the multi-armed bandit framework. Theoretically, we show\nthat our algorithm asymptotically approximates the optimal variance within a\nfactor of 3. Empirically, we show that using this datapoint-selection technique\nresults in a significant reduction in the convergence time and variance of\nseveral stochastic optimization algorithms such as SGD, SVRG and SAGA. This\napproach for sampling datapoints is general, and can be used in conjunction\nwith any algorithm that uses an unbiased gradient estimation -- we expect it to\nhave broad applicability beyond the specific examples explored in this work.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 16:15:26 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 13:20:18 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Salehi", "Farnood", ""], ["Celis", "L. Elisa", ""], ["Thiran", "Patrick", ""]]}, {"id": "1708.02556", "submitter": "Tu Dinh Nguyen", "authors": "Quan Hoang, Tu Dinh Nguyen, Trung Le and Dinh Phung", "title": "Multi-Generator Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to train the Generative Adversarial Nets (GANs)\nwith a mixture of generators to overcome the mode collapsing problem. The main\nintuition is to employ multiple generators, instead of using a single one as in\nthe original GAN. The idea is simple, yet proven to be extremely effective at\ncovering diverse data modes, easily overcoming the mode collapse and delivering\nstate-of-the-art results. A minimax formulation is able to establish among a\nclassifier, a discriminator, and a set of generators in a similar spirit with\nGAN. Generators create samples that are intended to come from the same\ndistribution as the training data, whilst the discriminator determines whether\nsamples are true data or generated by generators, and the classifier specifies\nwhich generator a sample comes from. The distinguishing feature is that\ninternal samples are created from multiple generators, and then one of them\nwill be randomly selected as final output similar to the mechanism of a\nprobabilistic mixture model. We term our method Mixture GAN (MGAN). We develop\ntheoretical analysis to prove that, at the equilibrium, the Jensen-Shannon\ndivergence (JSD) between the mixture of generators' distributions and the\nempirical data distribution is minimal, whilst the JSD among generators'\ndistributions is maximal, hence effectively avoiding the mode collapse. By\nutilizing parameter sharing, our proposed model adds minimal computational cost\nto the standard GAN, and thus can also efficiently scale to large-scale\ndatasets. We conduct extensive experiments on synthetic 2D data and natural\nimage databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior\nperformance of our MGAN in achieving state-of-the-art Inception scores over\nlatest baselines, generating diverse and appealing recognizable objects at\ndifferent resolutions, and specializing in capturing different types of objects\nby generators.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 16:48:35 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 01:00:49 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 03:24:03 GMT"}, {"version": "v4", "created": "Fri, 27 Oct 2017 23:54:26 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Hoang", "Quan", ""], ["Nguyen", "Tu Dinh", ""], ["Le", "Trung", ""], ["Phung", "Dinh", ""]]}, {"id": "1708.02581", "submitter": "Damian Straszak", "authors": "Damian Straszak and Nisheeth K. Vishnoi", "title": "Belief Propagation, Bethe Approximation and Polynomials", "comments": "Invited to Allerton 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor graphs are important models for succinctly representing probability\ndistributions in machine learning, coding theory, and statistical physics.\nSeveral computational problems, such as computing marginals and partition\nfunctions, arise naturally when working with factor graphs. Belief propagation\nis a widely deployed iterative method for solving these problems. However,\ndespite its significant empirical success, not much is known about the\ncorrectness and efficiency of belief propagation.\n  Bethe approximation is an optimization-based framework for approximating\npartition functions. While it is known that the stationary points of the Bethe\napproximation coincide with the fixed points of belief propagation, in general,\nthe relation between the Bethe approximation and the partition function is not\nwell understood. It has been observed that for a few classes of factor graphs,\nthe Bethe approximation always gives a lower bound to the partition function,\nwhich distinguishes them from the general case, where neither a lower bound,\nnor an upper bound holds universally. This has been rigorously proved for\npermanents and for attractive graphical models.\n  Here we consider bipartite normal factor graphs and show that if the local\nconstraints satisfy a certain analytic property, the Bethe approximation is a\nlower bound to the partition function. We arrive at this result by viewing\nfactor graphs through the lens of polynomials. In this process, we reformulate\nthe Bethe approximation as a polynomial optimization problem. Our sufficient\ncondition for the lower bound property to hold is inspired by recent\ndevelopments in the theory of real stable polynomials. We believe that this way\nof viewing factor graphs and its connection to real stability might lead to a\nbetter understanding of belief propagation and factor graphs in general.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 17:56:15 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Straszak", "Damian", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1708.02582", "submitter": "Taesik Na", "authors": "Taesik Na, Jong Hwan Ko, and Saibal Mukhopadhyay", "title": "Cascade Adversarial Machine Learning Regularized with a Unified\n  Embedding", "comments": "16 pages, 9 figures, International Conference on Learning\n  Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Injecting adversarial examples during training, known as adversarial\ntraining, can improve robustness against one-step attacks, but not for unknown\niterative attacks. To address this challenge, we first show iteratively\ngenerated adversarial images easily transfer between networks trained with the\nsame strategy. Inspired by this observation, we propose cascade adversarial\ntraining, which transfers the knowledge of the end results of adversarial\ntraining. We train a network from scratch by injecting iteratively generated\nadversarial images crafted from already defended networks in addition to\none-step adversarial images from the network being trained. We also propose to\nutilize embedding space for both classification and low-level (pixel-level)\nsimilarity learning to ignore unknown pixel level perturbation. During\ntraining, we inject adversarial images without replacing their corresponding\nclean images and penalize the distance between the two embeddings (clean and\nadversarial). Experimental results show that cascade adversarial training\ntogether with our proposed low-level similarity learning efficiently enhances\nthe robustness against iterative attacks, but at the expense of decreased\nrobustness against one-step attacks. We show that combining those two\ntechniques can also improve robustness under the worst case black box attack\nscenario.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 17:58:40 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 08:37:28 GMT"}, {"version": "v3", "created": "Sat, 17 Mar 2018 06:09:58 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Na", "Taesik", ""], ["Ko", "Jong Hwan", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "1708.02596", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Gregory Kahn, Ronald S. Fearing, Sergey Levine", "title": "Neural Network Dynamics for Model-Based Deep Reinforcement Learning with\n  Model-Free Fine-Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning algorithms have been shown to be\ncapable of learning a wide range of robotic skills, but typically require a\nvery large number of samples to achieve good performance. Model-based\nalgorithms, in principle, can provide for much more efficient learning, but\nhave proven difficult to extend to expressive, high-capacity models such as\ndeep neural networks. In this work, we demonstrate that medium-sized neural\nnetwork models can in fact be combined with model predictive control (MPC) to\nachieve excellent sample complexity in a model-based reinforcement learning\nalgorithm, producing stable and plausible gaits to accomplish various complex\nlocomotion tasks. We also propose using deep neural network dynamics models to\ninitialize a model-free learner, in order to combine the sample efficiency of\nmodel-based approaches with the high task-specific performance of model-free\nmethods. We empirically demonstrate on MuJoCo locomotion tasks that our pure\nmodel-based approach trained on just random action data can follow arbitrary\ntrajectories with excellent sample efficiency, and that our hybrid algorithm\ncan accelerate model-free learning on high-speed benchmark tasks, achieving\nsample efficiency gains of 3-5x on swimmer, cheetah, hopper, and ant agents.\nVideos can be found at https://sites.google.com/view/mbmf\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 18:13:03 GMT"}, {"version": "v2", "created": "Sat, 2 Dec 2017 02:04:21 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Kahn", "Gregory", ""], ["Fearing", "Ronald S.", ""], ["Levine", "Sergey", ""]]}, {"id": "1708.02621", "submitter": "Arun  Kejariwal", "authors": "Arun Kejariwal, Sanjeev Kulkarni and Karthik Ramasamy", "title": "Real Time Analytics: Algorithms and Systems", "comments": "Extended version of VLDB'15 tutorial proposal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Velocity is one of the 4 Vs commonly used to characterize Big Data. In this\nregard, Forrester remarked the following in Q3 2014: \"The high velocity,\nwhite-water flow of data from innumerable real-time data sources such as market\ndata, Internet of Things, mobile, sensors, click-stream, and even transactions\nremain largely unnavigated by most firms. The opportunity to leverage streaming\nanalytics has never been greater.\" Example use cases of streaming analytics\ninclude, but not limited to: (a) visualization of business metrics in real-time\n(b) facilitating highly personalized experiences (c) expediting response during\nemergencies. Streaming analytics is extensively used in a wide variety of\ndomains such as healthcare, e-commerce, financial services, telecommunications,\nenergy and utilities, manufacturing, government and transportation.\n  In this tutorial, we shall present an in-depth overview of streaming\nanalytics - applications, algorithms and platforms - landscape. We shall walk\nthrough how the field has evolved over the last decade and then discuss the\ncurrent challenges - the impact of the other three Vs, viz., Volume, Variety\nand Veracity, on Big Data streaming analytics. The tutorial is intended for\nboth researchers and practitioners in the industry. We shall also present\nstate-of-the-affairs of streaming analytics at Twitter.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 15:59:34 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Kejariwal", "Arun", ""], ["Kulkarni", "Sanjeev", ""], ["Ramasamy", "Karthik", ""]]}, {"id": "1708.02629", "submitter": "Shibiao Wan", "authors": "Shibiao Wan, Man-Wai Mak and Sun-Yuan Kung", "title": "Protecting Genomic Privacy by a Sequence-Similarity Based Obfuscation\n  Method", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the post-genomic era, large-scale personal DNA sequences are produced and\ncollected for genetic medical diagnoses and new drug discovery, which, however,\nsimultaneously poses serious challenges to the protection of personal genomic\nprivacy. Existing genomic privacy-protection methods are either time-consuming\nor with low accuracy. To tackle these problems, this paper proposes a sequence\nsimilarity-based obfuscation method, namely IterMegaBLAST, for fast and\nreliable protection of personal genomic privacy. Specifically, given a randomly\nselected sequence from a dataset of DNA sequences, we first use MegaBLAST to\nfind its most similar sequence from the dataset. These two aligned sequences\nform a cluster, for which an obfuscated sequence was generated via a DNA\ngeneralization lattice scheme. These procedures are iteratively performed until\nall of the sequences in the dataset are clustered and their obfuscated\nsequences are generated. Experimental results on two benchmark datasets\ndemonstrate that under the same degree of anonymity, IterMegaBLAST\nsignificantly outperforms existing state-of-the-art approaches in terms of both\nutility accuracy and time complexity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 19:54:33 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Wan", "Shibiao", ""], ["Mak", "Man-Wai", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "1708.02635", "submitter": "Doyup Lee", "authors": "Doyup Lee", "title": "Anomaly Detection in Multivariate Non-stationary Time Series for\n  Automatic DBMS Diagnosis", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/ICMLA.2017.0-126", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in database management systems (DBMSs) is difficult because\nof increasing number of statistics (stat) and event metrics in big data system.\nIn this paper, I propose an automatic DBMS diagnosis system that detects\nanomaly periods with abnormal DB stat metrics and finds causal events in the\nperiods. Reconstruction error from deep autoencoder and statistical process\ncontrol approach are applied to detect time period with anomalies. Related\nevents are found using time series similarity measures between events and\nabnormal stat metrics. After training deep autoencoder with DBMS metric data,\nefficacy of anomaly detection is investigated from other DBMSs containing\nanomalies. Experiment results show effectiveness of proposed model, especially,\nbatch temporal normalization layer. Proposed model is used for publishing\nautomatic DBMS diagnosis reports in order to determine DBMS configuration and\nSQL tuning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 20:04:19 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 23:54:22 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Lee", "Doyup", ""]]}, {"id": "1708.02637", "submitter": "Illia Polosukhin", "authors": "Heng-Tze Cheng, Zakaria Haque, Lichan Hong, Mustafa Ispir, Clemens\n  Mewald, Illia Polosukhin, Georgios Roumpos, D Sculley, Jamie Smith, David\n  Soergel, Yuan Tang, Philipp Tucker, Martin Wicke, Cassandra Xia, Jianwei Xie", "title": "TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level\n  Machine Learning Frameworks", "comments": "8 pages, Appeared at KDD 2017, August 13--17, 2017, Halifax, NS,\n  Canada", "journal-ref": null, "doi": "10.1145/3097983.3098171", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for specifying, training, evaluating, and deploying\nmachine learning models. Our focus is on simplifying cutting edge machine\nlearning for practitioners in order to bring such technologies into production.\nRecognizing the fast evolution of the field of deep learning, we make no\nattempt to capture the design space of all possible model architectures in a\ndomain- specific language (DSL) or similar configuration language. We allow\nusers to write code to define their models, but provide abstractions that guide\ndevelop- ers to write models in ways conducive to productionization. We also\nprovide a unifying Estimator interface, making it possible to write downstream\ninfrastructure (e.g. distributed training, hyperparameter tuning) independent\nof the model implementation. We balance the competing demands for flexibility\nand simplicity by offering APIs at different levels of abstraction, making\ncommon model architectures available out of the box, while providing a library\nof utilities designed to speed up experimentation with model architectures. To\nmake out of the box models flexible and usable across a wide range of problems,\nthese canned Estimators are parameterized not only over traditional\nhyperparameters, but also using feature columns, a declarative specification\ndescribing how to interpret input data. We discuss our experience in using this\nframework in re- search and production environments, and show the impact on\ncode health, maintainability, and development speed.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 20:06:28 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Cheng", "Heng-Tze", ""], ["Haque", "Zakaria", ""], ["Hong", "Lichan", ""], ["Ispir", "Mustafa", ""], ["Mewald", "Clemens", ""], ["Polosukhin", "Illia", ""], ["Roumpos", "Georgios", ""], ["Sculley", "D", ""], ["Smith", "Jamie", ""], ["Soergel", "David", ""], ["Tang", "Yuan", ""], ["Tucker", "Philipp", ""], ["Wicke", "Martin", ""], ["Xia", "Cassandra", ""], ["Xie", "Jianwei", ""]]}, {"id": "1708.02639", "submitter": "Ran Raz", "authors": "Sumegha Garg, Ran Raz, Avishay Tal", "title": "Extractor-Based Time-Space Lower Bounds for Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matrix $M: A \\times X \\rightarrow \\{-1,1\\}$ corresponds to the following\nlearning problem: An unknown element $x \\in X$ is chosen uniformly at random. A\nlearner tries to learn $x$ from a stream of samples, $(a_1, b_1), (a_2, b_2)\n\\ldots$, where for every $i$, $a_i \\in A$ is chosen uniformly at random and\n$b_i = M(a_i,x)$.\n  Assume that $k,\\ell, r$ are such that any submatrix of $M$ of at least\n$2^{-k} \\cdot |A|$ rows and at least $2^{-\\ell} \\cdot |X|$ columns, has a bias\nof at most $2^{-r}$. We show that any learning algorithm for the learning\nproblem corresponding to $M$ requires either a memory of size at least\n$\\Omega\\left(k \\cdot \\ell \\right)$, or at least $2^{\\Omega(r)}$ samples. The\nresult holds even if the learner has an exponentially small success probability\n(of $2^{-\\Omega(r)}$).\n  In particular, this shows that for a large class of learning problems, any\nlearning algorithm requires either a memory of size at least $\\Omega\\left((\\log\n|X|) \\cdot (\\log |A|)\\right)$ or an exponential number of samples, achieving a\ntight $\\Omega\\left((\\log |X|) \\cdot (\\log |A|)\\right)$ lower bound on the size\nof the memory, rather than a bound of $\\Omega\\left(\\min\\left\\{(\\log\n|X|)^2,(\\log |A|)^2\\right\\}\\right)$ obtained in previous works [R17,MM17b].\n  Moreover, our result implies all previous memory-samples lower bounds, as\nwell as a number of new applications.\n  Our proof builds on [R17] that gave a general technique for proving\nmemory-samples lower bounds.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 20:13:39 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Garg", "Sumegha", ""], ["Raz", "Ran", ""], ["Tal", "Avishay", ""]]}, {"id": "1708.02640", "submitter": "Paul Beame", "authors": "Paul Beame, Shayan Oveis Gharan and Xin Yang", "title": "Time-Space Tradeoffs for Learning from Small Test Spaces: Learning Low\n  Degree Polynomial Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an extension of recently developed methods for obtaining\ntime-space tradeoff lower bounds for problems of learning from random test\nsamples to handle the situation where the space of tests is signficantly\nsmaller than the space of inputs, a class of learning problems that is not\nhandled by prior work. This extension is based on a measure of how matrices\namplify the 2-norms of probability distributions that is more refined than the\n2-norms of these matrices.\n  As applications that follow from our new technique, we show that any\nalgorithm that learns $m$-variate homogeneous polynomial functions of degree at\nmost $d$ over $\\mathbb{F}_2$ from evaluations on randomly chosen inputs either\nrequires space $\\Omega(mn)$ or $2^{\\Omega(m)}$ time where $n=m^{\\Theta(d)}$ is\nthe dimension of the space of such functions. These bounds are asymptotically\noptimal since they match the tradeoffs achieved by natural learning algorithms\nfor the problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 20:13:44 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Beame", "Paul", ""], ["Gharan", "Shayan Oveis", ""], ["Yang", "Xin", ""]]}, {"id": "1708.02657", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Yann LeCun", "title": "Which Encoding is the Best for Text Classification in Chinese, English,\n  Japanese and Korean?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article offers an empirical study on the different ways of encoding\nChinese, Japanese, Korean (CJK) and English languages for text classification.\nDifferent encoding levels are studied, including UTF-8 bytes, characters,\nwords, romanized characters and romanized words. For all encoding levels,\nwhenever applicable, we provide comparisons with linear models, fastText and\nconvolutional networks. For convolutional networks, we compare between encoding\nmechanisms using character glyph images, one-hot (or one-of-n) encoding, and\nembedding. In total there are 473 models, using 14 large-scale text\nclassification datasets in 4 languages including Chinese, English, Japanese and\nKorean. Some conclusions from these results include that byte-level one-hot\nencoding based on UTF-8 consistently produces competitive results for\nconvolutional networks, that word-level n-grams linear models are competitive\neven without perfect word segmentation, and that fastText provides the best\nresult using character-level n-gram encoding but can overfit when the features\nare overly rich.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 21:24:44 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 00:34:08 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Zhang", "Xiang", ""], ["LeCun", "Yann", ""]]}, {"id": "1708.02663", "submitter": "Mohamed Amine Bouhlel Dr", "authors": "Mohamed Amine Bouhlel and Joaquim R. R. A. Martins", "title": "Gradient-enhanced kriging for high-dimensional problems", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate models provide a low computational cost alternative to evaluating\nexpensive functions. The construction of accurate surrogate models with large\nnumbers of independent variables is currently prohibitive because it requires a\nlarge number of function evaluations. Gradient-enhanced kriging has the\npotential to reduce the number of function evaluations for the desired accuracy\nwhen efficient gradient computation, such as an adjoint method, is available.\nHowever, current gradient-enhanced kriging methods do not scale well with the\nnumber of sampling points due to the rapid growth in the size of the\ncorrelation matrix where new information is added for each sampling point in\neach direction of the design space. They do not scale well with the number of\nindependent variables either due to the increase in the number of\nhyperparameters that needs to be estimated. To address this issue, we develop a\nnew gradient-enhanced surrogate model approach that drastically reduced the\nnumber of hyperparameters through the use of the partial-least squares method\nthat maintains accuracy. In addition, this method is able to control the size\nof the correlation matrix by adding only relevant points defined through the\ninformation provided by the partial-least squares method. To validate our\nmethod, we compare the global accuracy of the proposed method with conventional\nkriging surrogate models on two analytic functions with up to 100 dimensions,\nas well as engineering problems of varied complexity with up to 15 dimensions.\nWe show that the proposed method requires fewer sampling points than\nconventional methods to obtain the desired accuracy, or provides more accuracy\nfor a fixed budget of sampling points. In some cases, we get over 3 times more\naccurate models than a bench of surrogate models from the literature, and also\nover 3200 times faster than standard gradient-enhanced kriging models.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 21:58:49 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Bouhlel", "Mohamed Amine", ""], ["Martins", "Joaquim R. R. A.", ""]]}, {"id": "1708.02666", "submitter": "Kush Varshney", "authors": "Been Kim, Dmitry M. Malioutov, Kush R. Varshney, Adrian Weller", "title": "Proceedings of the 2017 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2017)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the 2017 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2017), which was held in Sydney, Australia, August 10,\n2017. Invited speakers were Tony Jebara, Pang Wei Koh, and David Sontag.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 22:21:11 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Kim", "Been", ""], ["Malioutov", "Dmitry M.", ""], ["Varshney", "Kush R.", ""], ["Weller", "Adrian", ""]]}, {"id": "1708.02691", "submitter": "Boris Hanin", "authors": "Boris Hanin", "title": "Universal Function Approximation by Deep Neural Nets with Bounded Width\n  and ReLU Activations", "comments": "v3. Theorem 3 removed. Comments Welcome. 9p", "journal-ref": "Mathematics 2019, 7(10), 992", "doi": "10.3390/math7100992", "report-no": null, "categories": "stat.ML cs.CG cs.LG math.FA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the expressive power of depth in neural nets with ReLU\nactivations and bounded width. We are particularly interested in the following\nquestions: what is the minimal width $w_{\\text{min}}(d)$ so that ReLU nets of\nwidth $w_{\\text{min}}(d)$ (and arbitrary depth) can approximate any continuous\nfunction on the unit cube $[0,1]^d$ aribitrarily well? For ReLU nets near this\nminimal width, what can one say about the depth necessary to approximate a\ngiven function? Our approach to this paper is based on the observation that,\ndue to the convexity of the ReLU activation, ReLU nets are particularly\nwell-suited for representing convex functions. In particular, we prove that\nReLU nets with width $d+1$ can approximate any continuous convex function of\n$d$ variables arbitrarily well. These results then give quantitative depth\nestimates for the rate of approximation of any continuous scalar function on\nthe $d$-dimensional cube $[0,1]^d$ by ReLU nets with width $d+3.$\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 01:37:21 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 22:40:55 GMT"}, {"version": "v3", "created": "Wed, 20 Dec 2017 17:38:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hanin", "Boris", ""]]}, {"id": "1708.02728", "submitter": "John Peebles", "authors": "Ilias Diakonikolas, Themis Gouleakis, John Peebles, Eric Price", "title": "Optimal Identity Testing with High Probability", "comments": null, "journal-ref": "ICALP 2018", "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing identity against a given distribution with a\nfocus on the high confidence regime. More precisely, given samples from an\nunknown distribution $p$ over $n$ elements, an explicitly given distribution\n$q$, and parameters $0< \\epsilon, \\delta < 1$, we wish to distinguish, {\\em\nwith probability at least $1-\\delta$}, whether the distributions are identical\nversus $\\varepsilon$-far in total variation distance. Most prior work focused\non the case that $\\delta = \\Omega(1)$, for which the sample complexity of\nidentity testing is known to be $\\Theta(\\sqrt{n}/\\epsilon^2)$. Given such an\nalgorithm, one can achieve arbitrarily small values of $\\delta$ via black-box\namplification, which multiplies the required number of samples by\n$\\Theta(\\log(1/\\delta))$.\n  We show that black-box amplification is suboptimal for any $\\delta = o(1)$,\nand give a new identity tester that achieves the optimal sample complexity. Our\nnew upper and lower bounds show that the optimal sample complexity of identity\ntesting is \\[\n  \\Theta\\left( \\frac{1}{\\epsilon^2}\\left(\\sqrt{n \\log(1/\\delta)} +\n\\log(1/\\delta) \\right)\\right) \\] for any $n, \\varepsilon$, and $\\delta$. For\nthe special case of uniformity testing, where the given distribution is the\nuniform distribution $U_n$ over the domain, our new tester is surprisingly\nsimple: to test whether $p = U_n$ versus $d_{\\mathrm TV}(p, U_n) \\geq\n\\varepsilon$, we simply threshold $d_{\\mathrm TV}(\\widehat{p}, U_n)$, where\n$\\widehat{p}$ is the empirical probability distribution. The fact that this\nsimple \"plug-in\" estimator is sample-optimal is surprising, even in the\nconstant $\\delta$ case. Indeed, it was believed that such a tester would not\nattain sublinear sample complexity even for constant values of $\\varepsilon$\nand $\\delta$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 06:17:30 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 23:23:35 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Peebles", "John", ""], ["Price", "Eric", ""]]}, {"id": "1708.02735", "submitter": "Stanislav Fort", "authors": "Stanislav Fort", "title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel architecture for $k$-shot classification on the Omniglot\ndataset. Building on prototypical networks, we extend their architecture to\nwhat we call Gaussian prototypical networks. Prototypical networks learn a map\nbetween images and embedding vectors, and use their clustering for\nclassification. In our model, a part of the encoder output is interpreted as a\nconfidence region estimate about the embedding point, and expressed as a\nGaussian covariance matrix. Our network then constructs a direction and class\ndependent distance metric on the embedding space, using uncertainties of\nindividual data points as weights. We show that Gaussian prototypical networks\nare a preferred architecture over vanilla prototypical networks with an\nequivalent number of parameters. We report state-of-the-art performance in\n1-shot and 5-shot classification both in 5-way and 20-way regime (for 5-shot\n5-way, we are comparable to previous state-of-the-art) on the Omniglot dataset.\nWe explore artificially down-sampling a fraction of images in the training set,\nwhich improves our performance even further. We therefore hypothesize that\nGaussian prototypical networks might perform better in less homogeneous,\nnoisier datasets, which are commonplace in real world applications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 06:53:31 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Fort", "Stanislav", ""]]}, {"id": "1708.02740", "submitter": "Gregory Valiant", "authors": "Michela Meister and Gregory Valiant", "title": "A Data Prism: Semi-Verified Learning in the Small-Alpha Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model of unreliable or crowdsourced data where there is an\nunderlying set of $n$ binary variables, each evaluator contributes a (possibly\nunreliable or adversarial) estimate of the values of some subset of $r$ of the\nvariables, and the learner is given the true value of a constant number of\nvariables. We show that, provided an $\\alpha$-fraction of the evaluators are\n\"good\" (either correct, or with independent noise rate $p < 1/2$), then the\ntrue values of a $(1-\\epsilon)$ fraction of the $n$ underlying variables can be\ndeduced as long as $\\alpha > 1/(2-2p)^r$. This setting can be viewed as an\ninstance of the semi-verified learning model introduced in [CSV17], which\nexplores the tradeoff between the number of items evaluated by each worker and\nthe fraction of good evaluators. Our results require the number of evaluators\nto be extremely large, $>n^r$, although our algorithm runs in linear time,\n$O_{r,\\epsilon}(n)$, given query access to the large dataset of evaluations.\nThis setting and results can also be viewed as examining a general class of\nsemi-adversarial CSPs with a planted assignment.\n  This parameter regime where the fraction of reliable data is small, is\nrelevant to a number of practical settings. For example, settings where one has\na large dataset of customer preferences, with each customer specifying\npreferences for a small (constant) number of items, and the goal is to\nascertain the preferences of a specific demographic of interest. Our results\nshow that this large dataset (which lacks demographic information) can be\nleveraged together with the preferences of the demographic of interest for a\nconstant number of randomly selected items, to recover an accurate estimate of\nthe entire set of preferences. In this sense, our results can be viewed as a\n\"data prism\" allowing one to extract the behavior of specific cohorts from a\nlarge, mixed, dataset.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 07:32:56 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Meister", "Michela", ""], ["Valiant", "Gregory", ""]]}, {"id": "1708.02787", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty, Nuha Diab, Shada R. Kawar, Robert J. Shahla", "title": "Non-Adaptive Randomized Algorithm for Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of group testing with a non-adaptive randomized\nalgorithm in the random incidence design (RID) model where each entry in the\ntest is chosen randomly independently from $\\{0,1\\}$ with a fixed probability\n$p$.\n  The property that is sufficient and necessary for a unique decoding is the\nseparability of the tests, but unfortunately no linear time algorithm is known\nfor such tests. In order to achieve linear-time decodable tests, the algorithms\nin the literature use the disjunction property that gives almost optimal number\nof tests.\n  We define a new property for the tests which we call semi-disjunction\nproperty. We show that there is a linear time decoding for such test and for\n$d\\to \\infty$ the number of tests converges to the number of tests with the\nseparability property and is therefore optimal (in the RID model). Our analysis\nshows that, in the RID model, the number of tests in our algorithm is better\nthan the one with the disjunction property even for small $d$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 11:24:02 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Bshouty", "Nader H.", ""], ["Diab", "Nuha", ""], ["Kawar", "Shada R.", ""], ["Shahla", "Robert J.", ""]]}, {"id": "1708.02867", "submitter": "Mostafa Shehata", "authors": "Mostafa A. Shehata, Mohammad Nassef and Amr A. Badr", "title": "Simulated Annealing with Levy Distribution for Fast Matrix\n  Factorization-Based Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is one of the best approaches for collaborative\nfiltering, because of its high accuracy in presenting users and items latent\nfactors. The main disadvantages of matrix factorization are its complexity, and\nbeing very hard to be parallelized, specially with very large matrices. In this\npaper, we introduce a new method for collaborative filtering based on Matrix\nFactorization by combining simulated annealing with levy distribution. By using\nthis method, good solutions are achieved in acceptable time with low\ncomputations, compared to other methods like stochastic gradient descent,\nalternating least squares, and weighted non-negative matrix factorization.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 15:14:54 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Shehata", "Mostafa A.", ""], ["Nassef", "Mohammad", ""], ["Badr", "Amr A.", ""]]}, {"id": "1708.02917", "submitter": "Aur\\'elien Decelle", "authors": "Aur\\'elien Decelle, Giancarlo Fissore and Cyril Furtlehner", "title": "Spectral Dynamics of Learning Restricted Boltzmann Machines", "comments": null, "journal-ref": "EPL 119 (2017) 60001", "doi": "10.1209/0295-5075/119/60001", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Restricted Boltzmann Machine (RBM), an important tool used in machine\nlearning in particular for unsupervized learning tasks, is investigated from\nthe perspective of its spectral properties. Starting from empirical\nobservations, we propose a generic statistical ensemble for the weight matrix\nof the RBM and characterize its mean evolution. This let us show how in the\nlinear regime, in which the RBM is found to operate at the beginning of the\ntraining, the statistical properties of the data drive the selection of the\nunstable modes of the weight matrix. A set of equations characterizing the\nnon-linear regime is then derived, unveiling in some way how the selected modes\ninteract in later stages of the learning procedure and defining a deterministic\nlearning curve for the RBM.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 17:16:30 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 14:28:23 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Decelle", "Aur\u00e9lien", ""], ["Fissore", "Giancarlo", ""], ["Furtlehner", "Cyril", ""]]}, {"id": "1708.02918", "submitter": "Volker Tresp", "authors": "Volker Tresp and Yunpu Ma", "title": "The Tensor Memory Hypothesis", "comments": "Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437) Report-no:\n  MLINI/2016/06", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss memory models which are based on tensor decompositions using\nlatent representations of entities and events. We show how episodic memory and\nsemantic memory can be realized and discuss how new memory traces can be\ngenerated from sensory input: Existing memories are the basis for perception\nand new memories are generated via perception. We relate our mathematical\napproach to the hippocampal memory indexing theory. We describe the first\ndetailed mathematical models for the complete processing pipeline from sensory\ninput and its semantic decoding, i.e., perception, to the formation of episodic\nand semantic memories and their declarative semantic decodings. Our main\nhypothesis is that perception includes an active semantic decoding process,\nwhich relies on latent representations of entities and predicates, and that\nepisodic and semantic memories depend on the same decoding process. We\ncontribute to the debate between the leading memory consolidation theories,\ni.e., the standard consolidation theory (SCT) and the multiple trace theory\n(MTT). The latter is closely related to the complementary learning systems\n(CLS) framework. In particular, we show explicitly how episodic memory can\nteach the neocortex to form a semantic memory, which is a core issue in MTT and\nCLS.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 17:22:18 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 14:20:57 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Tresp", "Volker", ""], ["Ma", "Yunpu", ""]]}, {"id": "1708.02937", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Manoj Kumar, Jos\\'e Moreira, Pratap Pattnaik, Mauricio\n  Serrano, Henry Tufo", "title": "Enabling Massive Deep Neural Networks with the GraphBLAS", "comments": "10 pages, 7 figures, to appear in the 2017 IEEE High Performance\n  Extreme Computing (HPEC) conference", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091098", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have emerged as a core tool for machine learning.\nThe computations performed during DNN training and inference are dominated by\noperations on the weight matrices describing the DNN. As DNNs incorporate more\nstages and more nodes per stage, these weight matrices may be required to be\nsparse because of memory limitations. The GraphBLAS.org math library standard\nwas developed to provide high performance manipulation of sparse weight\nmatrices and input/output vectors. For sufficiently sparse matrices, a sparse\nmatrix library requires significantly less memory than the corresponding dense\nmatrix implementation. This paper provides a brief description of the\nmathematics underlying the GraphBLAS. In addition, the equations of a typical\nDNN are rewritten in a form designed to use the GraphBLAS. An implementation of\nthe DNN is given using a preliminary GraphBLAS C library. The performance of\nthe GraphBLAS implementation is measured relative to a standard dense linear\nalgebra library implementation. For various sizes of DNN weight matrices, it is\nshown that the GraphBLAS sparse implementation outperforms a BLAS dense\nimplementation as the weight matrix becomes sparser.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 03:24:40 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Kepner", "Jeremy", ""], ["Kumar", "Manoj", ""], ["Moreira", "Jos\u00e9", ""], ["Pattnaik", "Pratap", ""], ["Serrano", "Mauricio", ""], ["Tufo", "Henry", ""]]}, {"id": "1708.02939", "submitter": "Yunwen Lei", "authors": "Yunwen Lei, Lei Shi and Zheng-Chu Guo", "title": "Convergence of Unregularized Online Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the convergence of online gradient descent algorithms\nin reproducing kernel Hilbert spaces (RKHSs) without regularization. We\nestablish a sufficient condition and a necessary condition for the convergence\nof excess generalization errors in expectation. A sufficient condition for the\nalmost sure convergence is also given. With high probability, we provide\nexplicit convergence rates of the excess generalization errors for both\naveraged iterates and the last iterate, which in turn also imply convergence\nrates with probability one. To our best knowledge, this is the first\nhigh-probability convergence rate for the last iterate of online gradient\ndescent algorithms without strong convexity. Without any boundedness\nassumptions on iterates, our results are derived by a novel use of two measures\nof the algorithm's one-step progress, respectively by generalization errors and\nby distances in RKHSs, where the variances of the involved martingales are\ncancelled out by the descent property of the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 07:58:29 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Lei", "Yunwen", ""], ["Shi", "Lei", ""], ["Guo", "Zheng-Chu", ""]]}, {"id": "1708.02975", "submitter": "Daniel Hsu", "authors": "Daniel Hsu", "title": "Anomaly Detection on Graph Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we use variational recurrent neural network to investigate the\nanomaly detection problem on graph time series. The temporal correlation is\nmodeled by the combination of recurrent neural network (RNN) and variational\ninference (VI), while the spatial information is captured by the graph\nconvolutional network. In order to incorporate external factors, we use feature\nextractor to augment the transition of latent variables, which can learn the\ninfluence of external factors. With the target function as accumulative ELBO,\nit is easy to extend this model to on-line method. The experimental study on\ntraffic flow data shows the detection capability of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:15:56 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 23:50:17 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Hsu", "Daniel", ""]]}, {"id": "1708.02977", "submitter": "Licheng Yu", "authors": "Licheng Yu and Mohit Bansal and Tamara L. Berg", "title": "Hierarchically-Attentive RNN for Album Summarization and Storytelling", "comments": "To appear at EMNLP-2017 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of end-to-end visual storytelling. Given a photo\nalbum, our model first selects the most representative (summary) photos, and\nthen composes a natural language story for the album. For this task, we make\nuse of the Visual Storytelling dataset and a model composed of three\nhierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album\nphotos, select representative (summary) photos, and compose the story.\nAutomatic and human evaluations show our model achieves better performance on\nselection, generation, and retrieval than baselines.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:26:47 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Yu", "Licheng", ""], ["Bansal", "Mohit", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1708.02979", "submitter": "Andrei Turkin", "authors": "Andrei Turkin", "title": "Tikhonov Regularization for Long Short-Term Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a well-known fact that adding noise to the input data often improves\nnetwork performance. While the dropout technique may be a cause of memory loss,\nwhen it is applied to recurrent connections, Tikhonov regularization, which can\nbe regarded as the training with additive noise, avoids this issue naturally,\nthough it implies regularizer derivation for different architectures. In case\nof feedforward neural networks this is straightforward, while for networks with\nrecurrent connections and complicated layers it leads to some difficulties. In\nthis paper, a Tikhonov regularizer is derived for Long-Short Term Memory (LSTM)\nnetworks. Although it is independent of time for simplicity, it considers\ninteraction between weights of the LSTM unit, which in theory makes it possible\nto regularize the unit with complicated dependences by using only one parameter\nthat measures the input data perturbation. The regularizer that is proposed in\nthis paper has three parameters: one to control the regularization process, and\nother two to maintain computation stability while the network is being trained.\nThe theory developed in this paper can be applied to get such regularizers for\ndifferent recurrent neural networks with Hadamard products and Lipschitz\ncontinuous functions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:34:26 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Turkin", "Andrei", ""]]}, {"id": "1708.03020", "submitter": "Yining Wang", "authors": "Xi Chen, Yining Wang, Yu-Xiang Wang", "title": "Non-stationary Stochastic Optimization under $L_{p,q}$-Variation\n  Measures", "comments": "38 pages, 3 figures. Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-stationary sequential stochastic optimization problem, in\nwhich the underlying cost functions change over time under a variation budget\nconstraint. We propose an $L_{p,q}$-variation functional to quantify the\nchange, which yields less variation for dynamic function sequences whose\nchanges are constrained to short time periods or small subsets of input domain.\nUnder the $L_{p,q}$-variation constraint, we derive both upper and matching\nlower regret bounds for smooth and strongly convex function sequences, which\ngeneralize previous results in Besbes et al. (2015). Furthermore, we provide an\nupper bound for general convex function sequences with noisy gradient feedback,\nwhich matches the optimal rate as $p\\to\\infty$. Our results reveal some\nsurprising phenomena under this general variation functional, such as the curse\nof dimensionality of the function domain. The key technical novelties in our\nanalysis include affinity lemmas that characterize the distance of the\nminimizers of two convex functions with bounded Lp difference, and a cubic\nspline based construction that attains matching lower bounds.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 21:36:38 GMT"}, {"version": "v2", "created": "Thu, 31 Aug 2017 18:45:41 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 16:04:56 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Yining", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "1708.03027", "submitter": "Rongrong Zhang", "authors": "Rongrong Zhang, Wei Deng, Michael Yu Zhu", "title": "Using Deep Neural Networks to Automate Large Scale Statistical Analysis\n  for Big Data Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis (SA) is a complex process to deduce population\nproperties from analysis of data. It usually takes a well-trained analyst to\nsuccessfully perform SA, and it becomes extremely challenging to apply SA to\nbig data applications. We propose to use deep neural networks to automate the\nSA process. In particular, we propose to construct convolutional neural\nnetworks (CNNs) to perform automatic model selection and parameter estimation,\ntwo most important SA tasks. We refer to the resulting CNNs as the neural model\nselector and the neural model estimator, respectively, which can be properly\ntrained using labeled data systematically generated from candidate models.\nSimulation study shows that both the selector and estimator demonstrate\nexcellent performances. The idea and proposed framework can be further extended\nto automate the entire SA process and have the potential to revolutionize how\nSA is performed in big data analytics.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 22:34:36 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Zhang", "Rongrong", ""], ["Deng", "Wei", ""], ["Zhu", "Michael Yu", ""]]}, {"id": "1708.03052", "submitter": "Lee Gao", "authors": "Lee Gao, Ronghuo Zheng", "title": "Communication-Free Parallel Supervised Topic Models", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embarrassingly (communication-free) parallel Markov chain Monte Carlo (MCMC)\nmethods are commonly used in learning graphical models. However, MCMC cannot be\ndirectly applied in learning topic models because of the quasi-ergodicity\nproblem caused by multimodal distribution of topics. In this paper, we develop\nan embarrassingly parallel MCMC algorithm for sLDA. Our algorithm works by\nswitching the order of sampled topics combination and labeling variable\nprediction in sLDA, in which it overcomes the quasi-ergodicity problem because\nhigh-dimension topics that follow a multimodal distribution are projected into\none-dimension document labels that follow a unimodal distribution. Our\nempirical experiments confirm that the out-of-sample prediction performance\nusing our embarrassingly parallel algorithm is comparable to non-parallel sLDA\nwhile the computation time is significantly reduced.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 02:03:52 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Gao", "Lee", ""], ["Zheng", "Ronghuo", ""]]}, {"id": "1708.03058", "submitter": "Qing Wang", "authors": "Qing Wang, Chunqiu Zeng, Wubai Zhou, Tao Li, Larisa Shwartz, Genady\n  Ya. Grabarnik", "title": "Online Interactive Collaborative Filtering Using Multi-Armed Bandit with\n  Dependent Arms", "comments": "Recommender systems; Interactive collaborative filtering; Topic\n  modeling; Cold-start problem; Particle learning; 10 pages", "journal-ref": null, "doi": "10.1109/TKDE.2018.2866041", "report-no": "18795315", "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online interactive recommender systems strive to promptly suggest to\nconsumers appropriate items (e.g., movies, news articles) according to the\ncurrent context including both the consumer and item content information.\nHowever, such context information is often unavailable in practice for the\nrecommendation, where only the users' interaction data on items can be\nutilized. Moreover, the lack of interaction records, especially for new users\nand items, worsens the performance of recommendation further. To address these\nissues, collaborative filtering (CF), one of the recommendation techniques\nrelying on the interaction data only, as well as the online multi-armed bandit\nmechanisms, capable of achieving the balance between exploitation and\nexploration, are adopted in the online interactive recommendation settings, by\nassuming independent items (i.e., arms). Nonetheless, the assumption rarely\nholds in reality, since the real-world items tend to be correlated with each\nother (e.g., two articles with similar topics). In this paper, we study online\ninteractive collaborative filtering problems by considering the dependencies\namong items. We explicitly formulate the item dependencies as the clusters on\narms, where the arms within a single cluster share the similar latent topics.\nIn light of the topic modeling techniques, we come up with a generative model\nto generate the items from their underlying topics. Furthermore, an efficient\nonline algorithm based on particle learning is developed for inferring both\nlatent parameters and states of our model. Additionally, our inferred model can\nbe naturally integrated with existing multi-armed selection strategies in the\nonline interactive collaborating setting. Empirical studies on two real-world\napplications, online recommendations of movies and news, demonstrate both the\neffectiveness and efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 02:52:57 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 23:13:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Qing", ""], ["Zeng", "Chunqiu", ""], ["Zhou", "Wubai", ""], ["Li", "Tao", ""], ["Shwartz", "Larisa", ""], ["Grabarnik", "Genady Ya.", ""]]}, {"id": "1708.03074", "submitter": "Asaf Valadarsky", "authors": "Asaf Valadarsky, Michael Schapira, Dafna Shahaf, Aviv Tamar", "title": "A Machine Learning Approach to Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can ideas and techniques from machine learning be leveraged to automatically\ngenerate \"good\" routing configurations? We investigate the power of data-driven\nrouting protocols. Our results suggest that applying ideas and techniques from\ndeep reinforcement learning to this context yields high performance, motivating\nfurther research along these lines.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 04:33:09 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 09:10:04 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Valadarsky", "Asaf", ""], ["Schapira", "Michael", ""], ["Shahaf", "Dafna", ""], ["Tamar", "Aviv", ""]]}, {"id": "1708.03131", "submitter": "Daniil Ryabko", "authors": "Daniil Ryabko", "title": "Hypotheses testing on infinite random graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing on some recent results that provide the formalism necessary to\ndefinite stationarity for infinite random graphs, this paper initiates the\nstudy of statistical and learning questions pertaining to these objects.\nSpecifically, a criterion for the existence of a consistent test for complex\nhypotheses is presented, generalizing the corresponding results on time series.\nAs an application, it is shown how one can test that a tree has the Markov\nproperty, or, more generally, to estimate its memory.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 09:11:31 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Ryabko", "Daniil", ""]]}, {"id": "1708.03211", "submitter": "Huy Phan", "authors": "Huy Phan, Martin Krawczyk-Becker, Timo Gerkmann, Alfred Mertins", "title": "DNN and CNN with Weighted and Multi-task Loss Functions for Audio Event\n  Detection", "comments": "DCASE 2017 technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents our audio event detection system submitted for Task 2,\n\"Detection of rare sound events\", of DCASE 2017 challenge. The proposed system\nis based on convolutional neural networks (CNNs) and deep neural networks\n(DNNs) coupled with novel weighted and multi-task loss functions and\nstate-of-the-art phase-aware signal enhancement. The loss functions are\ntailored for audio event detection in audio streams. The weighted loss is\ndesigned to tackle the common issue of imbalanced data in background/foreground\nclassification while the multi-task loss enables the networks to simultaneously\nmodel the class distribution and the temporal structures of the target events\nfor recognition. Our proposed systems significantly outperform the challenge\nbaseline, improving F-score from 72.7% to 90.0% and reducing detection error\nrate from 0.53 to 0.18 on average on the development data. On the evaluation\ndata, our submission obtains an average F1-score of 88.3% and an error rate of\n0.22 which are significantly better than those obtained by the DCASE baseline\n(i.e. an F1-score of 64.1% and an error rate of 0.64).\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 13:44:31 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 14:38:07 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Phan", "Huy", ""], ["Krawczyk-Becker", "Martin", ""], ["Gerkmann", "Timo", ""], ["Mertins", "Alfred", ""]]}, {"id": "1708.03218", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki, Stephen Becker", "title": "Improved Fixed-Rank Nystr\\\"om Approximation via QR Decomposition:\n  Practical and Theoretical Aspects", "comments": "Accepted in Neurocomputing. arXiv admin note: text overlap with\n  arXiv:1612.06470", "journal-ref": "Neurocomputing, 2019", "doi": "10.1016/j.neucom.2019.06.070", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nystrom method is a popular technique that uses a small number of\nlandmark points to compute a fixed-rank approximation of large kernel matrices\nthat arise in machine learning problems. In practice, to ensure high quality\napproximations, the number of landmark points is chosen to be greater than the\ntarget rank. However, for simplicity the standard Nystrom method uses a\nsub-optimal procedure for rank reduction. In this paper, we examine the\ndrawbacks of the standard Nystrom method in terms of poor performance and lack\nof theoretical guarantees. To address these issues, we present an efficient\nmodification for generating improved fixed-rank Nystrom approximations.\nTheoretical analysis and numerical experiments are provided to demonstrate the\nadvantages of the modified method over the standard Nystrom method. Overall,\nthe aim of this paper is to convince researchers to use the modified method, as\nit has nearly identical computational complexity, is easy to code, has greatly\nimproved accuracy in many cases, and is optimal in a sense that we make\nprecise.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 23:52:53 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 15:11:19 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""], ["Becker", "Stephen", ""]]}, {"id": "1708.03229", "submitter": "Yanshuai Cao", "authors": "Yanshuai Cao, Luyu Wang", "title": "Automatic Selection of t-SNE Perplexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-Distributed Stochastic Neighbor Embedding (t-SNE) is one of the most widely\nused dimensionality reduction methods for data visualization, but it has a\nperplexity hyperparameter that requires manual selection. In practice, proper\ntuning of t-SNE perplexity requires users to understand the inner working of\nthe method as well as to have hands-on experience. We propose a model selection\nobjective for t-SNE perplexity that requires negligible extra computation\nbeyond that of the t-SNE itself. We empirically validate that the perplexity\nsettings found by our approach are consistent with preferences elicited from\nhuman experts across a number of datasets. The similarities of our approach to\nBayesian information criteria (BIC) and minimum description length (MDL) are\nalso analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 14:19:20 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Cao", "Yanshuai", ""], ["Wang", "Luyu", ""]]}, {"id": "1708.03257", "submitter": "Sushrut Karmalkar", "authors": "Daniel Kane, Sushrut Karmalkar, Eric Price", "title": "Robust polynomial regression up to the information theoretic limit", "comments": "19 Pages. To appear in FOCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust polynomial regression, where one receives\nsamples $(x_i, y_i)$ that are usually within $\\sigma$ of a polynomial $y =\np(x)$, but have a $\\rho$ chance of being arbitrary adversarial outliers.\nPreviously, it was known how to efficiently estimate $p$ only when $\\rho <\n\\frac{1}{\\log d}$. We give an algorithm that works for the entire feasible\nrange of $\\rho < 1/2$, while simultaneously improving other parameters of the\nproblem. We complement our algorithm, which gives a factor 2 approximation,\nwith impossibility results that show, for example, that a $1.09$ approximation\nis impossible even with infinitely many samples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 15:31:02 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Kane", "Daniel", ""], ["Karmalkar", "Sushrut", ""], ["Price", "Eric", ""]]}, {"id": "1708.03322", "submitter": "Weiming Xiang", "authors": "Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson", "title": "Output Reachable Set Estimation and Verification for Multi-Layer Neural\n  Networks", "comments": "8 pages, 9 figures, to appear in TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the output reachable estimation and safety verification\nproblems for multi-layer perceptron neural networks are addressed. First, a\nconception called maximum sensitivity in introduced and, for a class of\nmulti-layer perceptrons whose activation functions are monotonic functions, the\nmaximum sensitivity can be computed via solving convex optimization problems.\nThen, using a simulation-based method, the output reachable set estimation\nproblem for neural networks is formulated into a chain of optimization\nproblems. Finally, an automated safety verification is developed based on the\noutput reachable set estimation result. An application to the safety\nverification for a robotic arm model with two joints is presented to show the\neffectiveness of proposed approaches.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:48:11 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 06:51:34 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Xiang", "Weiming", ""], ["Tran", "Hoang-Dung", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1708.03366", "submitter": "Sangdon Park", "authors": "Sangdon Park, James Weimer and Insup Lee", "title": "Resilient Linear Classification: An Approach to Deal with Attacks on\n  Training Data", "comments": "Accepted as a conference paper at ICCPS17", "journal-ref": null, "doi": "10.1145/3055004.3055006", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven techniques are used in cyber-physical systems (CPS) for\ncontrolling autonomous vehicles, handling demand responses for energy\nmanagement, and modeling human physiology for medical devices. These\ndata-driven techniques extract models from training data, where their\nperformance is often analyzed with respect to random errors in the training\ndata. However, if the training data is maliciously altered by attackers, the\neffect of these attacks on the learning algorithms underpinning data-driven CPS\nhave yet to be considered. In this paper, we analyze the resilience of\nclassification algorithms to training data attacks. Specifically, a generic\nmetric is proposed that is tailored to measure resilience of classification\nalgorithms with respect to worst-case tampering of the training data. Using the\nmetric, we show that traditional linear classification algorithms are resilient\nunder restricted conditions. To overcome these limitations, we propose a linear\nclassification algorithm with a majority constraint and prove that it is\nstrictly more resilient than the traditional algorithms. Evaluations on both\nsynthetic data and a real-world retrospective arrhythmia medical case-study\nshow that the traditional algorithms are vulnerable to tampered training data,\nwhereas the proposed algorithm is more resilient (as measured by worst-case\ntampering).\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 19:54:58 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 15:25:16 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Park", "Sangdon", ""], ["Weimer", "James", ""], ["Lee", "Insup", ""]]}, {"id": "1708.03381", "submitter": "Shih-Chieh Su", "authors": "Shih-Chieh Su", "title": "Topical Behavior Prediction from Massive Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the topical behavior in a large scale. We use the\nnetwork logs where each entry contains the entity ID, the timestamp, and the\nmeta data about the activity. Both the temporal and the spatial relationships\nof the behavior are explored with the deep learning architectures combing the\nrecurrent neural network (RNN) and the convolutional neural network (CNN). To\nmake the behavioral data appropriate for the spatial learning in the CNN, we\npropose several reduction steps to form the topical metrics and to place them\nhomogeneously like pixels in the images. The experimental result shows both\ntemporal and spatial gains when compared against a multilayer perceptron (MLP)\nnetwork. A new learning framework called the spatially connected convolutional\nnetworks (SCCN) is introduced to predict the topical metrics more efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 20:47:10 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Su", "Shih-Chieh", ""]]}, {"id": "1708.03392", "submitter": "Marinka Zitnik", "authors": "Marinka Zitnik and Blaz Zupan", "title": "Jumping across biomedical contexts using compressive data fusion", "comments": "In Proceedings of the 24th International Conference on Intelligent\n  Systems for Molecular Biology (ISMB), 2016", "journal-ref": "Bioinformatics, 32 (12): i90-i100 (2016)", "doi": null, "report-no": null, "categories": "cs.LG q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: The rapid growth of diverse biological data allows us to consider\ninteractions between a variety of objects, such as genes, chemicals, molecular\nsignatures, diseases, pathways and environmental exposures. Often, any pair of\nobjects--such as a gene and a disease--can be related in different ways, for\nexample, directly via gene-disease associations or indirectly via functional\nannotations, chemicals and pathways. Different ways of relating these objects\ncarry different semantic meanings. However, traditional methods disregard these\nsemantics and thus cannot fully exploit their value in data modeling.\n  Results: We present Medusa, an approach to detect size-k modules of objects\nthat, taken together, appear most significant to another set of objects. Medusa\noperates on large-scale collections of heterogeneous data sets and explicitly\ndistinguishes between diverse data semantics. It advances research along two\ndimensions: it builds on collective matrix factorization to derive different\nsemantics, and it formulates the growing of the modules as a submodular\noptimization program. Medusa is flexible in choosing or combining semantic\nmeanings and provides theoretical guarantees about detection quality. In a\nsystematic study on 310 complex diseases, we show the effectiveness of Medusa\nin associating genes with diseases and detecting disease modules. We\ndemonstrate that in predicting gene-disease associations Medusa compares\nfavorably to methods that ignore diverse semantic meanings. We find that the\nutility of different semantics depends on disease categories and that, overall,\nMedusa recovers disease modules more accurately when combining different\nsemantics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 21:39:54 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Zitnik", "Marinka", ""], ["Zupan", "Blaz", ""]]}, {"id": "1708.03395", "submitter": "Jean Barbier Dr.", "authors": "Jean Barbier, Florent Krzakala, Nicolas Macris, L\\'eo Miolane, Lenka\n  Zdeborov\\'a", "title": "Optimal Errors and Phase Transitions in High-Dimensional Generalized\n  Linear Models", "comments": "101 pages, 5 figures", "journal-ref": "Proceedings of the National Academy of Sciences 116. 12 (2019):\n  5451-5460", "doi": "10.1073/pnas.1802705116", "report-no": null, "categories": "cs.IT cond-mat.dis-nn cs.AI cs.LG math-ph math.IT math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized linear models (GLMs) arise in high-dimensional machine learning,\nstatistics, communications and signal processing. In this paper we analyze GLMs\nwhen the data matrix is random, as relevant in problems such as compressed\nsensing, error-correcting codes or benchmark models in neural networks. We\nevaluate the mutual information (or \"free entropy\") from which we deduce the\nBayes-optimal estimation and generalization errors. Our analysis applies to the\nhigh-dimensional limit where both the number of samples and the dimension are\nlarge and their ratio is fixed. Non-rigorous predictions for the optimal errors\nexisted for special cases of GLMs, e.g. for the perceptron, in the field of\nstatistical physics based on the so-called replica method. Our present paper\nrigorously establishes those decades old conjectures and brings forward their\nalgorithmic interpretation in terms of performance of the generalized\napproximate message-passing algorithm. Furthermore, we tightly characterize,\nfor many learning problems, regions of parameters for which this algorithm\nachieves the optimal performance, and locate the associated sharp phase\ntransitions separating learnable and non-learnable regions. We believe that\nthis random version of GLMs can serve as a challenging benchmark for\nmulti-purpose algorithms. This paper is divided in two parts that can be read\nindependently: The first part (main part) presents the model and main results,\ndiscusses some applications and sketches the main ideas of the proof. The\nsecond part (supplementary informations) is much more detailed and provides\nmore examples as well as all the proofs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 21:53:40 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 19:17:17 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 12:05:50 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Barbier", "Jean", ""], ["Krzakala", "Florent", ""], ["Macris", "Nicolas", ""], ["Miolane", "L\u00e9o", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1708.03436", "submitter": "Suthee Chaidaroon", "authors": "Suthee Chaidaroon and Yi Fang", "title": "Variational Deep Semantic Hashing for Text Documents", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the amount of textual data has been rapidly increasing over the past\ndecade, efficient similarity search methods have become a crucial component of\nlarge-scale information retrieval systems. A popular strategy is to represent\noriginal data samples by compact binary codes through hashing. A spectrum of\nmachine learning methods have been utilized, but they often lack expressiveness\nand flexibility in modeling to learn effective representations. The recent\nadvances of deep learning in a wide range of applications has demonstrated its\ncapability to learn robust and powerful feature representations for complex\ndata. Especially, deep generative models naturally combine the expressiveness\nof probabilistic generative models with the high capacity of deep neural\nnetworks, which is very suitable for text modeling. However, little work has\nleveraged the recent progress in deep learning for text hashing.\n  In this paper, we propose a series of novel deep document generative models\nfor text hashing. The first proposed model is unsupervised while the second one\nis supervised by utilizing document labels/tags for hashing. The third model\nfurther considers document-specific factors that affect the generation of\nwords. The probabilistic generative formulation of the proposed models provides\na principled framework for model extension, uncertainty estimation, simulation,\nand interpretability. Based on variational inference and reparameterization,\nthe proposed models can be interpreted as encoder-decoder deep neural networks\nand thus they are capable of learning complex nonlinear distributed\nrepresentations of the original documents. We conduct a comprehensive set of\nexperiments on four public testbeds. The experimental results have demonstrated\nthe effectiveness of the proposed supervised learning models for text hashing.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 05:19:04 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Chaidaroon", "Suthee", ""], ["Fang", "Yi", ""]]}, {"id": "1708.03496", "submitter": "Shuliang Xu", "authors": "Junhong Wang, Shuliang Xu, Bingqian Duan, Caifeng Liu, Jiye Liang", "title": "An Ensemble Classification Algorithm Based on Information Entropy for\n  Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data stream mining problem has caused widely concerns in the area of machine\nlearning and data mining. In some recent studies, ensemble classification has\nbeen widely used in concept drift detection, however, most of them regard\nclassification accuracy as a criterion for judging whether concept drift\nhappening or not. Information entropy is an important and effective method for\nmeasuring uncertainty. Based on the information entropy theory, a new algorithm\nusing information entropy to evaluate a classification result is developed. It\nuses ensemble classification techniques, and the weight of each classifier is\ndecided through the entropy of the result produced by an ensemble classifiers\nsystem. When the concept in data streams changing, the classifiers' weight\nbelow a threshold value will be abandoned to adapt to a new concept in one\ntime. In the experimental analysis section, six databases and four proposed\nalgorithms are executed. The results show that the proposed method can not only\nhandle concept drift effectively, but also have a better classification\naccuracy and time performance than the contrastive algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 10:04:47 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Wang", "Junhong", ""], ["Xu", "Shuliang", ""], ["Duan", "Bingqian", ""], ["Liu", "Caifeng", ""], ["Liang", "Jiye", ""]]}, {"id": "1708.03498", "submitter": "Sjoerd van Steenkiste", "authors": "Klaus Greff, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Neural Expectation Maximization", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real world tasks such as reasoning and physical interaction require\nidentification and manipulation of conceptual entities. A first step towards\nsolving these tasks is the automated discovery of distributed symbol-like\nrepresentations. In this paper, we explicitly formalize this problem as\ninference in a spatial mixture model where each component is parametrized by a\nneural network. Based on the Expectation Maximization framework we then derive\na differentiable clustering method that simultaneously learns how to group and\nrepresent individual entities. We evaluate our method on the (sequential)\nperceptual grouping task and find that it is able to accurately recover the\nconstituent objects. We demonstrate that the learned representations are useful\nfor next-step prediction.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 10:17:23 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 15:14:47 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Greff", "Klaus", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1708.03608", "submitter": "Mathukumalli Vidyasagar", "authors": "Mahsa Lotfi and Mathukumalli Vidyasagar", "title": "A Fast Noniterative Algorithm for Compressive Sensing Using Binary\n  Measurement Matrices", "comments": "24 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new algorithm for compressive sensing that makes\nuse of binary measurement matrices and achieves exact recovery of ultra sparse\nvectors, in a single pass and without any iterations. Due to its noniterative\nnature, our algorithm is hundreds of times faster than $\\ell_1$-norm\nminimization, and methods based on expander graphs, both of which require\nmultiple iterations. Our algorithm can accommodate nearly sparse vectors, in\nwhich case it recovers index set of the largest components, and can also\naccommodate burst noise measurements. Compared to compressive sensing methods\nthat are guaranteed to achieve exact recovery of all sparse vectors, our method\nrequires fewer measurements However, methods that achieve statistical recovery,\nthat is, recovery of almost all but not all sparse vectors, can require fewer\nmeasurements than our method.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 16:45:00 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 07:20:27 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Lotfi", "Mahsa", ""], ["Vidyasagar", "Mathukumalli", ""]]}, {"id": "1708.03665", "submitter": "Stephen Edwards", "authors": "Dominique T. Shipmon, Jason M. Gurevitch, Paolo M. Piselli and Stephen\n  T. Edwards", "title": "Time Series Anomaly Detection; Detection of anomalous drops with limited\n  features and sparse examples in noisy highly periodic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Google uses continuous streams of data from industry partners in order to\ndeliver accurate results to users. Unexpected drops in traffic can be an\nindication of an underlying issue and may be an early warning that remedial\naction may be necessary. Detecting such drops is non-trivial because streams\nare variable and noisy, with roughly regular spikes (in many different shapes)\nin traffic data. We investigated the question of whether or not we can predict\nanomalies in these data streams. Our goal is to utilize Machine Learning and\nstatistical approaches to classify anomalous drops in periodic, but noisy,\ntraffic patterns. Since we do not have a large body of labeled examples to\ndirectly apply supervised learning for anomaly classification, we approached\nthe problem in two parts. First we used TensorFlow to train our various models\nincluding DNNs, RNNs, and LSTMs to perform regression and predict the expected\nvalue in the time series. Secondly we created anomaly detection rules that\ncompared the actual values to predicted values. Since the problem requires\nfinding sustained anomalies, rather than just short delays or momentary\ninactivity in the data, our two detection methods focused on continuous\nsections of activity rather than just single points. We tried multiple\ncombinations of our models and rules and found that using the intersection of\nour two anomaly detection methods proved to be an effective method of detecting\nanomalies on almost all of our models. In the process we also found that not\nall data fell within our experimental assumptions, as one data stream had no\nperiodicity, and therefore no time based model could predict it.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 19:04:53 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Shipmon", "Dominique T.", ""], ["Gurevitch", "Jason M.", ""], ["Piselli", "Paolo M.", ""], ["Edwards", "Stephen T.", ""]]}, {"id": "1708.03704", "submitter": "Alan Mosca", "authors": "Alan Mosca, George D Magoulas", "title": "Deep Incremental Boosting", "comments": null, "journal-ref": "Christoph Benzm\\\"uller, Geoff Sutcliffe and Raul Rojas (editors).\n  GCAI 2016. 2nd Global Conference on Artificial Intelligence, vol 41, pages\n  293--302", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Deep Incremental Boosting, a new technique derived from\nAdaBoost, specifically adapted to work with Deep Learning methods, that reduces\nthe required training time and improves generalisation. We draw inspiration\nfrom Transfer of Learning approaches to reduce the start-up time to training\neach incremental Ensemble member. We show a set of experiments that outlines\nsome preliminary results on some common Deep Learning datasets and discuss the\npotential improvements Deep Incremental Boosting brings to traditional Ensemble\nmethods in Deep Learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 21:05:58 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Mosca", "Alan", ""], ["Magoulas", "George D", ""]]}, {"id": "1708.03708", "submitter": "Surbhi Goel", "authors": "Surbhi Goel, Adam Klivans", "title": "Eigenvalue Decay Implies Polynomial-Time Learnability for Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning function classes computed by neural\nnetworks with various activations (e.g. ReLU or Sigmoid), a task believed to be\ncomputationally intractable in the worst-case. A major open problem is to\nunderstand the minimal assumptions under which these classes admit provably\nefficient algorithms. In this work we show that a natural distributional\nassumption corresponding to {\\em eigenvalue decay} of the Gram matrix yields\npolynomial-time algorithms in the non-realizable setting for expressive classes\nof networks (e.g. feed-forward networks of ReLUs). We make no assumptions on\nthe structure of the network or the labels. Given sufficiently-strong\npolynomial eigenvalue decay, we obtain {\\em fully}-polynomial time algorithms\nin {\\em all} the relevant parameters with respect to square-loss. Milder decay\nassumptions also lead to improved algorithms. This is the first purely\ndistributional assumption that leads to polynomial-time algorithms for networks\nof ReLUs, even with one hidden layer. Further, unlike prior distributional\nassumptions (e.g., the marginal distribution is Gaussian), eigenvalue decay has\nbeen observed in practice on common data sets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 21:26:05 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Goel", "Surbhi", ""], ["Klivans", "Adam", ""]]}, {"id": "1708.03731", "submitter": "Jan N. van Rijn PhD", "authors": "Bernd Bischl, Giuseppe Casalicchio, Matthias Feurer, Frank Hutter,\n  Michel Lang, Rafael G. Mantovani, Jan N. van Rijn, Joaquin Vanschoren", "title": "OpenML Benchmarking Suites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning research depends on objectively interpretable, comparable,\nand reproducible algorithm benchmarks. Therefore, we advocate the use of\ncurated, comprehensive suites of machine learning tasks to standardize the\nsetup, execution, and reporting of benchmarks. We enable this through software\ntools that help to create and leverage these benchmarking suites. These are\nseamlessly integrated into the OpenML platform, and accessible through\ninterfaces in Python, Java, and R. OpenML benchmarking suites are (a) easy to\nuse through standardized data formats, APIs, and client libraries; (b)\nmachine-readable, with extensive meta-information on the included datasets; and\n(c) allow benchmarks to be shared and reused in future studies. We also present\na first, carefully curated and practical benchmarking suite for classification:\nthe OpenML Curated Classification benchmarking suite 2018 (OpenML-CC18).\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 23:28:48 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:02:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Bischl", "Bernd", ""], ["Casalicchio", "Giuseppe", ""], ["Feurer", "Matthias", ""], ["Hutter", "Frank", ""], ["Lang", "Michel", ""], ["Mantovani", "Rafael G.", ""], ["van Rijn", "Jan N.", ""], ["Vanschoren", "Joaquin", ""]]}, {"id": "1708.03735", "submitter": "Anirbit Mukherjee", "authors": "Akshay Rangamani, Anirbit Mukherjee, Amitabh Basu, Tejaswini\n  Ganapathy, Ashish Arora, Sang Chin and Trac D. Tran", "title": "Sparse Coding and Autoencoders", "comments": "In this new version of the paper with a small change in the\n  distributional assumptions we are actually able to prove the asymptotic\n  criticality of a neighbourhood of the ground truth dictionary for even just\n  the standard squared loss of the ReLU autoencoder (unlike the regularized\n  loss in the older version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \"Dictionary Learning\" one tries to recover incoherent matrices $A^* \\in\n\\mathbb{R}^{n \\times h}$ (typically overcomplete and whose columns are assumed\nto be normalized) and sparse vectors $x^* \\in \\mathbb{R}^h$ with a small\nsupport of size $h^p$ for some $0 <p < 1$ while having access to observations\n$y \\in \\mathbb{R}^n$ where $y = A^*x^*$. In this work we undertake a rigorous\nanalysis of whether gradient descent on the squared loss of an autoencoder can\nsolve the dictionary learning problem. The \"Autoencoder\" architecture we\nconsider is a $\\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ mapping with a single\nReLU activation layer of size $h$.\n  Under very mild distributional assumptions on $x^*$, we prove that the norm\nof the expected gradient of the standard squared loss function is\nasymptotically (in sparse code dimension) negligible for all points in a small\nneighborhood of $A^*$. This is supported with experimental evidence using\nsynthetic data. We also conduct experiments to suggest that $A^*$ is a local\nminimum. Along the way we prove that a layer of ReLU gates can be set up to\nautomatically recover the support of the sparse codes. This property holds\nindependent of the loss function. We believe that it could be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 01:02:47 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 18:07:53 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Rangamani", "Akshay", ""], ["Mukherjee", "Anirbit", ""], ["Basu", "Amitabh", ""], ["Ganapathy", "Tejaswini", ""], ["Arora", "Ashish", ""], ["Chin", "Sang", ""], ["Tran", "Trac D.", ""]]}, {"id": "1708.03788", "submitter": "Daniel Smilkov", "authors": "Daniel Smilkov, Shan Carter, D. Sculley, Fernanda B. Vi\\'egas, Martin\n  Wattenberg", "title": "Direct-Manipulation Visualization of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent successes of deep learning have led to a wave of interest from\nnon-experts. Gaining an understanding of this technology, however, is\ndifficult. While the theory is important, it is also helpful for novices to\ndevelop an intuitive feel for the effect of different hyperparameters and\nstructural variations. We describe TensorFlow Playground, an interactive, open\nsourced visualization that allows users to experiment via direct manipulation\nrather than coding, enabling them to quickly build an intuition about neural\nnets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 15:36:26 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Smilkov", "Daniel", ""], ["Carter", "Shan", ""], ["Sculley", "D.", ""], ["Vi\u00e9gas", "Fernanda B.", ""], ["Wattenberg", "Martin", ""]]}, {"id": "1708.03835", "submitter": "Cenk Baykal", "authors": "Cenk Baykal, Lucas Liebenwein, Wilko Schwarting", "title": "Training Support Vector Machines using Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel coreset construction algorithm for solving classification\ntasks using Support Vector Machines (SVMs) in a computationally efficient\nmanner. A coreset is a weighted subset of the original data points that\nprovably approximates the original set. We show that coresets of size\npolylogarithmic in $n$ and polynomial in $d$ exist for a set of $n$ input\npoints with $d$ features and present an $(\\epsilon,\\delta)$-FPRAS for\nconstructing coresets for scalable SVM training. Our method leverages the\ninsight that data points are often redundant and uses an importance sampling\nscheme based on the sensitivity of each data point to construct coresets\nefficiently. We evaluate the performance of our algorithm in accelerating SVM\ntraining against real-world data sets and compare our algorithm to\nstate-of-the-art coreset approaches. Our empirical results show that our\napproach outperforms a state-of-the-art coreset approach and uniform sampling\nin enabling computational speedups while achieving low approximation error.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 01:02:07 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 04:01:46 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Baykal", "Cenk", ""], ["Liebenwein", "Lucas", ""], ["Schwarting", "Wilko", ""]]}, {"id": "1708.03854", "submitter": "Xiaofeng Xie", "authors": "Xiaofeng Xie, Di Wu, Siping Liu, Renfa Li", "title": "IoT Data Analytics Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a popular machine learning approach which has achieved a lot\nof progress in all traditional machine learning areas. Internet of thing (IoT)\nand Smart City deployments are generating large amounts of time-series sensor\ndata in need of analysis. Applying deep learning to these domains has been an\nimportant topic of research. The Long-Short Term Memory (LSTM) network has been\nproven to be well suited for dealing with and predicting important events with\nlong intervals and delays in the time series. LTSM networks have the ability to\nmaintain long-term memory. In an LTSM network, a stacked LSTM hidden layer also\nmakes it possible to learn a high level temporal feature without the need of\nany fine tuning and preprocessing which would be required by other techniques.\nIn this paper, we construct a long-short term memory (LSTM) recurrent neural\nnetwork structure, use the normal time series training set to build the\nprediction model. And then we use the predicted error from the prediction model\nto construct a Gaussian naive Bayes model to detect whether the original sample\nis abnormal. This method is called LSTM-Gauss-NBayes for short. We use three\nreal-world data sets, each of which involve long-term time-dependence or\nshort-term time-dependence, even very weak time dependence. The experimental\nresults show that LSTM-Gauss-NBayes is an effective and robust model.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 04:58:49 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:48:16 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Xie", "Xiaofeng", ""], ["Wu", "Di", ""], ["Liu", "Siping", ""], ["Li", "Renfa", ""]]}, {"id": "1708.03880", "submitter": "Zhuo Chen", "authors": "Zhuo Chen, Weisi Lin, Shiqi Wang, Long Xu, Leida Li", "title": "Image Quality Assessment Guided Deep Neural Networks Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many computer vision problems, the deep neural networks are trained and\nvalidated based on the assumption that the input images are pristine (i.e.,\nartifact-free). However, digital images are subject to a wide range of\ndistortions in real application scenarios, while the practical issues regarding\nimage quality in high level visual information understanding have been largely\nignored. In this paper, in view of the fact that most widely deployed deep\nlearning models are susceptible to various image distortions, the distorted\nimages are involved for data augmentation in the deep neural network training\nprocess to learn a reliable model for practical applications. In particular, an\nimage quality assessment based label smoothing method, which aims at\nregularizing the label distribution of training images, is further proposed to\ntune the objective functions in learning the neural network. Experimental\nresults show that the proposed method is effective in dealing with both low and\nhigh quality images in the typical image classification task.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 09:51:07 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Chen", "Zhuo", ""], ["Lin", "Weisi", ""], ["Wang", "Shiqi", ""], ["Xu", "Long", ""], ["Li", "Leida", ""]]}, {"id": "1708.03940", "submitter": "Tao Yu", "authors": "Tao Yu, Christopher Hidey, Owen Rambow and Kathleen McKeown", "title": "Leveraging Sparse and Dense Feature Combinations for Sentiment\n  Classification", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are one of the most popular approaches for many natural\nlanguage processing tasks such as sentiment analysis. They often outperform\ntraditional machine learning models and achieve the state-of-art results on\nmost tasks. However, many existing deep learning models are complex, difficult\nto train and provide a limited improvement over simpler methods. We propose a\nsimple, robust and powerful model for sentiment classification. This model\noutperforms many deep learning models and achieves comparable results to other\ndeep learning models with complex architectures on sentiment analysis datasets.\nWe publish the code online.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 17:38:17 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Yu", "Tao", ""], ["Hidey", "Christopher", ""], ["Rambow", "Owen", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1708.03949", "submitter": "Mahdi Soltanolkotabi", "authors": "Hamed Hassani, Mahdi Soltanolkotabi and Amin Karbasi", "title": "Gradient Methods for Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of maximizing continuous submodular\nfunctions that naturally arise in many learning applications such as those\ninvolving utility functions in active learning and sensing, matrix\napproximations and network inference. Despite the apparent lack of convexity in\nsuch functions, we prove that stochastic projected gradient methods can provide\nstrong approximation guarantees for maximizing continuous submodular functions\nwith convex constraints. More specifically, we prove that for monotone\ncontinuous DR-submodular functions, all fixed points of projected gradient\nascent provide a factor $1/2$ approximation to the global maxima. We also study\nstochastic gradient and mirror methods and show that after\n$\\mathcal{O}(1/\\epsilon^2)$ iterations these methods reach solutions which\nachieve in expectation objective values exceeding\n$(\\frac{\\text{OPT}}{2}-\\epsilon)$. An immediate application of our results is\nto maximize submodular functions that are defined stochastically, i.e. the\nsubmodular function is defined as an expectation over a family of submodular\nfunctions with an unknown distribution. We will show how stochastic gradient\nmethods are naturally well-suited for this setting, leading to a factor $1/2$\napproximation when the function is monotone. In particular, it allows us to\napproximately maximize discrete, monotone submodular optimization problems via\nprojected gradient descent on a continuous relaxation, directly connecting the\ndiscrete and continuous domains. Finally, experiments on real data demonstrate\nthat our projected gradient methods consistently achieve the best utility\ncompared to other continuous baselines while remaining competitive in terms of\ncomputational effort.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 18:20:50 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 02:13:41 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Hassani", "Hamed", ""], ["Soltanolkotabi", "Mahdi", ""], ["Karbasi", "Amin", ""]]}, {"id": "1708.03995", "submitter": "Prathusha Kameswara Sarma", "authors": "Prathusha Kameswara Sarma, Bill Sethares", "title": "Sentiment Analysis by Joint Learning of Word Embeddings and Classifier", "comments": "10 pages. Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are representations of individual words of a text document in\na vector space and they are often use- ful for performing natural language pro-\ncessing tasks. Current state of the art al- gorithms for learning word\nembeddings learn vector representations from large corpora of text documents in\nan unsu- pervised fashion. This paper introduces SWESA (Supervised Word\nEmbeddings for Sentiment Analysis), an algorithm for sentiment analysis via\nword embeddings. SWESA leverages document label infor- mation to learn vector\nrepresentations of words from a modest corpus of text doc- uments by solving an\noptimization prob- lem that minimizes a cost function with respect to both word\nembeddings as well as classification accuracy. Analysis re- veals that SWESA\nprovides an efficient way of estimating the dimension of the word embeddings\nthat are to be learned. Experiments on several real world data sets show that\nSWESA has superior per- formance when compared to previously suggested\napproaches to word embeddings and sentiment analysis tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 02:40:20 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Sarma", "Prathusha Kameswara", ""], ["Sethares", "Bill", ""]]}, {"id": "1708.03999", "submitter": "Huan Zhang", "authors": "Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, Cho-Jui Hsieh", "title": "ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural\n  Networks without Training Substitute Models", "comments": "Accepted by 10th ACM Workshop on Artificial Intelligence and Security\n  (AISEC) with the 24th ACM Conference on Computer and Communications Security\n  (CCS)", "journal-ref": null, "doi": "10.1145/3128572.3140448", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are one of the most prominent technologies of our\ntime, as they achieve state-of-the-art performance in many machine learning\ntasks, including but not limited to image classification, text mining, and\nspeech processing. However, recent research on DNNs has indicated\never-increasing concern on the robustness to adversarial examples, especially\nfor security-critical tasks such as traffic sign identification for autonomous\ndriving. Studies have unveiled the vulnerability of a well-trained DNN by\ndemonstrating the ability of generating barely noticeable (to both human and\nmachines) adversarial images that lead to misclassification. Furthermore,\nresearchers have shown that these adversarial images are highly transferable by\nsimply training and attacking a substitute model built upon the target model,\nknown as a black-box attack to DNNs.\n  Similar to the setting of training substitute models, in this paper we\npropose an effective black-box attack that also only has access to the input\n(images) and the output (confidence scores) of a targeted DNN. However,\ndifferent from leveraging attack transferability from substitute models, we\npropose zeroth order optimization (ZOO) based attacks to directly estimate the\ngradients of the targeted DNN for generating adversarial examples. We use\nzeroth order stochastic coordinate descent along with dimension reduction,\nhierarchical attack and importance sampling techniques to efficiently attack\nblack-box models. By exploiting zeroth order optimization, improved attacks to\nthe targeted DNN can be accomplished, sparing the need for training substitute\nmodels and avoiding the loss in attack transferability. Experimental results on\nMNIST, CIFAR10 and ImageNet show that the proposed ZOO attack is as effective\nas the state-of-the-art white-box attack and significantly outperforms existing\nblack-box attacks via substitute models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 03:48:03 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 04:18:44 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Zhang", "Huan", ""], ["Sharma", "Yash", ""], ["Yi", "Jinfeng", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1708.04001", "submitter": "Feiyun Zhu", "authors": "Feiyun Zhu and Jun Guo and Zheng Xu and Peng Liao and Junzhou Huang", "title": "Group-driven Reinforcement Learning for Personalized mHealth\n  Intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the popularity of smartphones and wearable devices nowadays, mobile\nhealth (mHealth) technologies are promising to bring positive and wide impacts\non people's health. State-of-the-art decision-making methods for mHealth rely\non some ideal assumptions. Those methods either assume that the users are\ncompletely homogenous or completely heterogeneous. However, in reality, a user\nmight be similar with some, but not all, users. In this paper, we propose a\nnovel group-driven reinforcement learning method for the mHealth. We aim to\nunderstand how to share information among similar users to better convert the\nlimited user information into sharper learned RL policies. Specifically, we\nemploy the K-means clustering method to group users based on their trajectory\ninformation similarity and learn a shared RL policy for each group. Extensive\nexperiment results have shown that our method can achieve clear gains over the\nstate-of-the-art RL methods for mHealth.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 03:58:29 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Zhu", "Feiyun", ""], ["Guo", "Jun", ""], ["Xu", "Zheng", ""], ["Liao", "Peng", ""], ["Huang", "Junzhou", ""]]}, {"id": "1708.04106", "submitter": "Guorui Zhou", "authors": "Guorui Zhou, Ying Fan, Runpeng Cui, Weijie Bian, Xiaoqiang Zhu, Kun\n  Gai", "title": "Rocket Launching: A Universal and Efficient Framework for Training\n  Well-performing Light Net", "comments": "10 pages, AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models applied on real time response task, like click-through rate (CTR)\nprediction model, require high accuracy and rigorous response time. Therefore,\ntop-performing deep models of high depth and complexity are not well suited for\nthese applications with the limitations on the inference time. In order to\nfurther improve the neural networks' performance given the time and\ncomputational limitations, we propose an approach that exploits a cumbersome\nnet to help train the lightweight net for prediction. We dub the whole process\nrocket launching, where the cumbersome booster net is used to guide the\nlearning of the target light net throughout the whole training process. We\nanalyze different loss functions aiming at pushing the light net to behave\nsimilarly to the booster net, and adopt the loss with best performance in our\nexperiments. We use one technique called gradient block to improve the\nperformance of the light net and booster net further. Experiments on benchmark\ndatasets and real-life industrial advertisement data present that our light\nmodel can get performance only previously achievable with more complex models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 13:06:15 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 14:22:27 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 03:35:52 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Zhou", "Guorui", ""], ["Fan", "Ying", ""], ["Cui", "Runpeng", ""], ["Bian", "Weijie", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1708.04116", "submitter": "Hyunsin Park", "authors": "Hyunsin Park and Chang D. Yoo", "title": "Early Improving Recurrent Elastic Highway Network", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To model time-varying nonlinear temporal dynamics in sequential data, a\nrecurrent network capable of varying and adjusting the recurrence depth between\ninput intervals is examined. The recurrence depth is extended by several\nintermediate hidden state units, and the weight parameters involved in\ndetermining these units are dynamically calculated. The motivation behind the\npaper lies on overcoming a deficiency in Recurrent Highway Networks and\nimproving their performances which are currently at the forefront of RNNs: 1)\nDetermining the appropriate number of recurrent depth in RHN for different\ntasks is a huge burden and just setting it to a large number is computationally\nwasteful with possible repercussion in terms of performance degradation and\nhigh latency. Expanding on the idea of adaptive computation time (ACT), with\nthe use of an elastic gate in the form of a rectified exponentially decreasing\nfunction taking on as arguments as previous hidden state and input, the\nproposed model is able to evaluate the appropriate recurrent depth for each\ninput. The rectified gating function enables the most significant intermediate\nhidden state updates to come early such that significant performance gain is\nachieved early. 2) Updating the weights from that of previous intermediate\nlayer offers a richer representation than the use of shared weights across all\nintermediate recurrence layers. The weight update procedure is just an\nexpansion of the idea underlying hypernetworks. To substantiate the\neffectiveness of the proposed network, we conducted three experiments:\nregression on synthetic data, human activity recognition, and language modeling\non the Penn Treebank dataset. The proposed networks showed better performance\nthan other state-of-the-art recurrent networks in all three experiments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 13:39:28 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Park", "Hyunsin", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1708.04133", "submitter": "Peter Henderson", "authors": "Riashat Islam, Peter Henderson, Maziar Gomrokchi, Doina Precup", "title": "Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for\n  Continuous Control", "comments": "Accepted to Reproducibility in Machine Learning Workshop, ICML'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods in reinforcement learning have become increasingly\nprevalent for state-of-the-art performance in continuous control tasks. Novel\nmethods typically benchmark against a few key algorithms such as deep\ndeterministic policy gradients and trust region policy optimization. As such,\nit is important to present and use consistent baselines experiments. However,\nthis can be difficult due to general variance in the algorithms,\nhyper-parameter tuning, and environment stochasticity. We investigate and\ndiscuss: the significance of hyper-parameters in policy gradients for\ncontinuous control, general variance in the algorithms, and reproducibility of\nreported results. We provide guidelines on reporting novel results as\ncomparisons against baseline methods such that future researchers can make\ninformed decisions when investigating novel methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 19:20:15 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Islam", "Riashat", ""], ["Henderson", "Peter", ""], ["Gomrokchi", "Maziar", ""], ["Precup", "Doina", ""]]}, {"id": "1708.04202", "submitter": "Marwin Segler", "authors": "Marwin H.S. Segler, Mike Preuss, Mark P. Waller", "title": "Learning to Plan Chemical Syntheses", "comments": null, "journal-ref": "Nature 555 (2018), 604-610", "doi": "10.1038/nature25978", "report-no": null, "categories": "cs.AI cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From medicines to materials, small organic molecules are indispensable for\nhuman well-being. To plan their syntheses, chemists employ a problem solving\ntechnique called retrosynthesis. In retrosynthesis, target molecules are\nrecursively transformed into increasingly simpler precursor compounds until a\nset of readily available starting materials is obtained. Computer-aided\nretrosynthesis would be a highly valuable tool, however, past approaches were\nslow and provided results of unsatisfactory quality. Here, we employ Monte\nCarlo Tree Search (MCTS) to efficiently discover retrosynthetic routes. MCTS\nwas combined with an expansion policy network that guides the search, and an\n\"in-scope\" filter network to pre-select the most promising retrosynthetic\nsteps. These deep neural networks were trained on 12 million reactions, which\nrepresents essentially all reactions ever published in organic chemistry. Our\nsystem solves almost twice as many molecules and is 30 times faster in\ncomparison to the traditional search method based on extracted rules and\nhand-coded heuristics. Finally after a 60 year history of computer-aided\nsynthesis planning, chemists can no longer distinguish between routes generated\nby a computer system and real routes taken from the scientific literature. We\nanticipate that our method will accelerate drug and materials discovery by\nassisting chemists to plan better syntheses faster, and by enabling fully\nautomated robot synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 16:46:08 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Segler", "Marwin H. S.", ""], ["Preuss", "Mike", ""], ["Waller", "Mark P.", ""]]}, {"id": "1708.04278", "submitter": "Hagit Grushka - Cohen", "authors": "Hagit Grushka-Cohen, Oded Sofer, Ofer Biller, Michael Dymshits, Lior\n  Rokach, Bracha Shapira", "title": "Sampling High Throughput Data for Anomaly Detection of Data-Base\n  Activity", "comments": "Proceedings of the 11th Pre-ICIS Workshop on Information Security and\n  Privacy, Dublin, Ireland December 10, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Data leakage and theft from databases is a dangerous threat to organizations.\nData Security and Data Privacy protection systems (DSDP) monitor data access\nand usage to identify leakage or suspicious activities that should be\ninvestigated. Because of the high velocity nature of database systems, such\nsystems audit only a portion of the vast number of transactions that take\nplace. Anomalies are investigated by a Security Officer (SO) in order to choose\nthe proper response. In this paper we investigate the effect of sampling\nmethods based on the risk the transaction poses and propose a new method for\n\"combined sampling\" for capturing a more varied sample.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 19:05:20 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Grushka-Cohen", "Hagit", ""], ["Sofer", "Oded", ""], ["Biller", "Ofer", ""], ["Dymshits", "Michael", ""], ["Rokach", "Lior", ""], ["Shapira", "Bracha", ""]]}, {"id": "1708.04308", "submitter": "Yuxin Peng", "authors": "Xin Huang, Yuxin Peng and Mingkuan Yuan", "title": "MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal\n  Retrieval", "comments": "12 pages, submitted to IEEE Transactions on Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal retrieval has drawn wide interest for retrieval across different\nmodalities of data. However, existing methods based on DNN face the challenge\nof insufficient cross-modal training data, which limits the training\neffectiveness and easily leads to overfitting. Transfer learning is for\nrelieving the problem of insufficient training data, but it mainly focuses on\nknowledge transfer only from large-scale datasets as single-modal source domain\nto single-modal target domain. Such large-scale single-modal datasets also\ncontain rich modal-independent semantic knowledge that can be shared across\ndifferent modalities. Besides, large-scale cross-modal datasets are very\nlabor-consuming to collect and label, so it is significant to fully exploit the\nknowledge in single-modal datasets for boosting cross-modal retrieval. This\npaper proposes modal-adversarial hybrid transfer network (MHTN), which to the\nbest of our knowledge is the first work to realize knowledge transfer from\nsingle-modal source domain to cross-modal target domain, and learn cross-modal\ncommon representation. It is an end-to-end architecture with two subnetworks:\n(1) Modal-sharing knowledge transfer subnetwork is proposed to jointly transfer\nknowledge from a large-scale single-modal dataset in source domain to all\nmodalities in target domain with a star network structure, which distills\nmodal-independent supplementary knowledge for promoting cross-modal common\nrepresentation learning. (2) Modal-adversarial semantic learning subnetwork is\nproposed to construct an adversarial training mechanism between common\nrepresentation generator and modality discriminator, making the common\nrepresentation discriminative for semantics but indiscriminative for modalities\nto enhance cross-modal semantic consistency during transfer process.\nComprehensive experiments on 4 widely-used datasets show its effectiveness and\ngenerality.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 07:50:52 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Huang", "Xin", ""], ["Peng", "Yuxin", ""], ["Yuan", "Mingkuan", ""]]}, {"id": "1708.04312", "submitter": "Andres G. Abad", "authors": "Andres G. Abad and Luis I. Reyes-Castro", "title": "Collaborative Filtering using Denoising Auto-Encoders for Market Basket\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RS) help users navigate large sets of items in the\nsearch for \"interesting\" ones. One approach to RS is Collaborative Filtering\n(CF), which is based on the idea that similar users are interested in similar\nitems. Most model-based approaches to CF seek to train a\nmachine-learning/data-mining model based on sparse data; the model is then used\nto provide recommendations. While most of the proposed approaches are effective\nfor small-size situations, the combinatorial nature of the problem makes it\nimpractical for medium-to-large instances. In this work we present a novel\napproach to CF that works by training a Denoising Auto-Encoder (DAE) on\ncorrupted baskets, i.e., baskets from which one or more items have been\nremoved. The DAE is then forced to learn to reconstruct the original basket\ngiven its corrupted input. Due to recent advancements in optimization and other\ntechnologies for training neural-network models (such as DAE), the proposed\nmethod results in a scalable and practical approach to CF. The contribution of\nthis work is twofold: (1) to identify missing items in observed baskets and,\nthus, directly providing a CF model; and, (2) to construct a generative model\nof baskets which may be used, for instance, in simulation analysis or as part\nof a more complex analytical method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 20:32:35 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Abad", "Andres G.", ""], ["Reyes-Castro", "Luis I.", ""]]}, {"id": "1708.04321", "submitter": "Surya Prasath", "authors": "V. B. Surya Prasath, Haneen Arafat Abu Alfeilat, Ahmad B. A. Hassanat,\n  Omar Lasassmeh, Ahmad S. Tarawneh, Mahmoud Bashir Alhasanat, Hamzeh S. Eyal\n  Salman", "title": "Distance and Similarity Measures Effect on the Performance of K-Nearest\n  Neighbor Classifier -- A Review", "comments": "39 pages, 6 figures, 17 tables, revised text and added extra\n  experiments", "journal-ref": null, "doi": "10.1089/big.2018.0175", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The K-nearest neighbor (KNN) classifier is one of the simplest and most\ncommon classifiers, yet its performance competes with the most complex\nclassifiers in the literature. The core of this classifier depends mainly on\nmeasuring the distance or similarity between the tested examples and the\ntraining examples. This raises a major question about which distance measures\nto be used for the KNN classifier among a large number of distance and\nsimilarity measures available? This review attempts to answer this question\nthrough evaluating the performance (measured by accuracy, precision and recall)\nof the KNN using a large number of distance measures, tested on a number of\nreal-world datasets, with and without adding different levels of noise. The\nexperimental results show that the performance of KNN classifier depends\nsignificantly on the distance used, and the results showed large gaps between\nthe performances of different distances. We found that a recently proposed\nnon-convex distance performed the best when applied on most datasets comparing\nto the other tested distances. In addition, the performance of the KNN with\nthis top performing distance degraded only about $20\\%$ while the noise level\nreaches $90\\%$, this is true for most of the distances used as well. This means\nthat the KNN classifier using any of the top $10$ distances tolerate noise to a\ncertain degree. Moreover, the results show that some distances are less\naffected by the added noise comparing to other distances.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 20:52:35 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 19:58:50 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 16:27:25 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Prasath", "V. B. Surya", ""], ["Alfeilat", "Haneen Arafat Abu", ""], ["Hassanat", "Ahmad B. A.", ""], ["Lasassmeh", "Omar", ""], ["Tarawneh", "Ahmad S.", ""], ["Alhasanat", "Mahmoud Bashir", ""], ["Salman", "Hamzeh S. Eyal", ""]]}, {"id": "1708.04357", "submitter": "Trang Pham", "authors": "Trang Pham, Truyen Tran, Hoa Dam, Svetha Venkatesh", "title": "Graph Classification via Deep Learning with Virtual Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representation for graph classification turns a variable-size graph\ninto a fixed-size vector (or matrix). Such a representation works nicely with\nalgebraic manipulations. Here we introduce a simple method to augment an\nattributed graph with a virtual node that is bidirectionally connected to all\nexisting nodes. The virtual node represents the latent aspects of the graph,\nwhich are not immediately available from the attributes and local connectivity\nstructures. The expanded graph is then put through any node representation\nmethod. The representation of the virtual node is then the representation of\nthe entire graph. In this paper, we use the recently introduced Column Network\nfor the expanded graph, resulting in a new end-to-end graph classification\nmodel dubbed Virtual Column Network (VCN). The model is validated on two tasks:\n(i) predicting bio-activity of chemical compounds, and (ii) finding software\nvulnerability from source code. Results demonstrate that VCN is competitive\nagainst well-established rivals.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 23:47:02 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Pham", "Trang", ""], ["Tran", "Truyen", ""], ["Dam", "Hoa", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1708.04403", "submitter": "Zhi-Hua Zhou", "authors": "Wei Wang and Zhi-Hua Zhou", "title": "Theoretical Foundation of Co-Training and Disagreement-Based Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disagreement-based approaches generate multiple classifiers and exploit the\ndisagreement among them with unlabeled data to improve learning performance.\nCo-training is a representative paradigm of them, which trains two classifiers\nseparately on two sufficient and redundant views; while for the applications\nwhere there is only one view, several successful variants of co-training with\ntwo different classifiers on single-view data instead of two views have been\nproposed. For these disagreement-based approaches, there are several important\nissues which still are unsolved, in this article we present theoretical\nanalyses to address these issues, which provides a theoretical foundation of\nco-training and disagreement-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 06:00:33 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Wang", "Wei", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1708.04439", "submitter": "Sukriti Verma", "authors": "Sukriti Verma and Vagisha Nidhi", "title": "Extractive Summarization using Deep Learning", "comments": "Accepted to 18th International Conference on Computational\n  Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a text summarization approach for factual reports using a\ndeep learning model. This approach consists of three phases: feature\nextraction, feature enhancement, and summary generation, which work together to\nassimilate core information and generate a coherent, understandable summary. We\nare exploring various features to improve the set of sentences selected for the\nsummary, and are using a Restricted Boltzmann Machine to enhance and abstract\nthose features to improve resultant accuracy without losing any important\ninformation. The sentences are scored based on those enhanced features and an\nextractive summary is constructed. Experimentation carried out on several\narticles demonstrates the effectiveness of the proposed approach. Source code\navailable at: https://github.com/vagisha-nidhi/TextSummarizer\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 09:08:50 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 07:30:40 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Verma", "Sukriti", ""], ["Nidhi", "Vagisha", ""]]}, {"id": "1708.04465", "submitter": "Jos van der Westhuizen", "authors": "David Janz, Jos van der Westhuizen, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Actively Learning what makes a Discrete Sequence Valid", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have been hugely successful for traditional\nsupervised and unsupervised machine learning problems. In large part, these\ntechniques solve continuous optimization problems. Recently however, discrete\ngenerative deep learning models have been successfully used to efficiently\nsearch high-dimensional discrete spaces. These methods work by representing\ndiscrete objects as sequences, for which powerful sequence-based deep models\ncan be employed. Unfortunately, these techniques are significantly hindered by\nthe fact that these generative models often produce invalid sequences. As a\nstep towards solving this problem, we propose to learn a deep recurrent\nvalidator model. Given a partial sequence, our model learns the probability of\nthat sequence occurring as the beginning of a full valid sequence. Thus this\nidentifies valid versus invalid sequences and crucially it also provides\ninsight about how individual sequence elements influence the validity of\ndiscrete objects. To learn this model we propose an approach inspired by\nseminal work in Bayesian active learning. On a synthetic dataset, we\ndemonstrate the ability of our model to distinguish valid and invalid\nsequences. We believe this is a key step toward learning generative models that\nfaithfully produce valid discrete objects.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 11:52:35 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Janz", "David", ""], ["van der Westhuizen", "Jos", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1708.04485", "submitter": "Stephen Keckler", "authors": "Angshuman Parashar, Minsoo Rhu, Anurag Mukkara, Antonio Puglielli,\n  Rangharajan Venkatesan, Brucek Khailany, Joel Emer, Stephen W. Keckler, and\n  William J. Dally", "title": "SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have emerged as a fundamental technology\nfor machine learning. High performance and extreme energy efficiency are\ncritical for deployments of CNNs in a wide range of situations, especially\nmobile platforms such as autonomous vehicles, cameras, and electronic personal\nassistants. This paper introduces the Sparse CNN (SCNN) accelerator\narchitecture, which improves performance and energy efficiency by exploiting\nthe zero-valued weights that stem from network pruning during training and\nzero-valued activations that arise from the common ReLU operator applied during\ninference. Specifically, SCNN employs a novel dataflow that enables maintaining\nthe sparse weights and activations in a compressed encoding, which eliminates\nunnecessary data transfers and reduces storage requirements. Furthermore, the\nSCNN dataflow facilitates efficient delivery of those weights and activations\nto the multiplier array, where they are extensively reused. In addition, the\naccumulation of multiplication products are performed in a novel accumulator\narray. Our results show that on contemporary neural networks, SCNN can improve\nboth performance and energy by a factor of 2.7x and 2.3x, respectively, over a\ncomparably provisioned dense CNN accelerator.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 22:11:11 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Parashar", "Angshuman", ""], ["Rhu", "Minsoo", ""], ["Mukkara", "Anurag", ""], ["Puglielli", "Antonio", ""], ["Venkatesan", "Rangharajan", ""], ["Khailany", "Brucek", ""], ["Emer", "Joel", ""], ["Keckler", "Stephen W.", ""], ["Dally", "William J.", ""]]}, {"id": "1708.04498", "submitter": "Victor Rivera", "authors": "Leonard Johard, Victor Rivera, Manuel Mazzara, and JooYoung Lee", "title": "Self-adaptive node-based PCA encodings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm, Simple Hebbian PCA, and prove that it\nis able to calculate the principal component analysis (PCA) in a distributed\nfashion across nodes. It simplifies existing network structures by removing\nintralayer weights, essentially cutting the number of weights that need to be\ntrained in half.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 12:29:41 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Johard", "Leonard", ""], ["Rivera", "Victor", ""], ["Mazzara", "Manuel", ""], ["Lee", "JooYoung", ""]]}, {"id": "1708.04529", "submitter": "Yuya Yoshikawa", "authors": "Yuya Yoshikawa", "title": "Learning from Noisy Label Distributions", "comments": "Accepted in ICANN2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a novel machine learning problem, that is,\nlearning a classifier from noisy label distributions. In this problem, each\ninstance with a feature vector belongs to at least one group. Then, instead of\nthe true label of each instance, we observe the label distribution of the\ninstances associated with a group, where the label distribution is distorted by\nan unknown noise. Our goals are to (1) estimate the true label of each\ninstance, and (2) learn a classifier that predicts the true label of a new\ninstance. We propose a probabilistic model that considers true label\ndistributions of groups and parameters that represent the noise as hidden\nvariables. The model can be learned based on a variational Bayesian method. In\nnumerical experiments, we show that the proposed model outperforms existing\nmethods in terms of the estimation of the true labels of instances.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 03:25:46 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Yoshikawa", "Yuya", ""]]}, {"id": "1708.04613", "submitter": "Christoph Doblander", "authors": "Christoph Doblander and Martin Strohbach and Holger Ziekow and\n  Hans-Arno Jacobsen", "title": "Real-time Load Prediction with High Velocity Smart Home Data Stream", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the use of smart-home sensor streams for continuous\nprediction of energy loads of individual households which participate as an\nagent in local markets. We introduces a new device level energy consumption\ndataset recorded over three years wich includes high resolution energy\nmeasurements from electrical devices collected within a pilot program. Using\ndata from that pilot, we analyze the applicability of various machine learning\nmechanisms for continuous load prediction. Specifically, we address short-term\nload prediction that is required for load balancing in electrical micro-grids.\nWe report on the prediction performance and the computational requirements of a\nbroad range of prediction mechanisms. Furthermore we present an architecture\nand experimental evaluation when this prediction is applied in the stream.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 12:47:31 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Doblander", "Christoph", ""], ["Strohbach", "Martin", ""], ["Ziekow", "Holger", ""], ["Jacobsen", "Hans-Arno", ""]]}, {"id": "1708.04617", "submitter": "Xiangnan He", "authors": "Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, Tat-Seng Chua", "title": "Attentional Factorization Machines: Learning the Weight of Feature\n  Interactions via Attention Networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization Machines (FMs) are a supervised learning approach that enhances\nthe linear regression model by incorporating the second-order feature\ninteractions. Despite effectiveness, FM can be hindered by its modelling of all\nfeature interactions with the same weight, as not all feature interactions are\nequally useful and predictive. For example, the interactions with useless\nfeatures may even introduce noises and adversely degrade the performance. In\nthis work, we improve FM by discriminating the importance of different feature\ninteractions. We propose a novel model named Attentional Factorization Machine\n(AFM), which learns the importance of each feature interaction from data via a\nneural attention network. Extensive experiments on two real-world datasets\ndemonstrate the effectiveness of AFM. Empirically, it is shown on regression\ntask AFM betters FM with a $8.6\\%$ relative improvement, and consistently\noutperforms the state-of-the-art deep learning methods Wide&Deep and DeepCross\nwith a much simpler structure and fewer model parameters. Our implementation of\nAFM is publicly available at:\nhttps://github.com/hexiangnan/attentional_factorization_machine\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 05:17:08 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Xiao", "Jun", ""], ["Ye", "Hao", ""], ["He", "Xiangnan", ""], ["Zhang", "Hanwang", ""], ["Wu", "Fei", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1708.04622", "submitter": "Alan Morningstar", "authors": "Alan Morningstar and Roger G. Melko", "title": "Deep Learning the Ising Model Near Criticality", "comments": "16 pages, 8 figures, 1 table", "journal-ref": "J. Mach. Learn. Res. 18, 5975 (2018)", "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well established that neural networks with deep architectures perform\nbetter than shallow networks for many tasks in machine learning. In statistical\nphysics, while there has been recent interest in representing physical data\nwith generative modelling, the focus has been on shallow neural networks. A\nnatural question to ask is whether deep neural networks hold any advantage over\nshallow networks in representing such data. We investigate this question by\nusing unsupervised, generative graphical models to learn the probability\ndistribution of a two-dimensional Ising system. Deep Boltzmann machines, deep\nbelief networks, and deep restricted Boltzmann networks are trained on thermal\nspin configurations from this system, and compared to the shallow architecture\nof the restricted Boltzmann machine. We benchmark the models, focussing on the\naccuracy of generating energetic observables near the phase transition, where\nthese quantities are most difficult to approximate. Interestingly, after\ntraining the generative networks, we observe that the accuracy essentially\ndepends only on the number of neurons in the first hidden layer of the network,\nand not on other model details such as network depth or model type. This is\nevidence that shallow networks are more efficient than deep networks at\nrepresenting physical probability distributions associated with Ising systems\nnear criticality.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 18:00:01 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Morningstar", "Alan", ""], ["Melko", "Roger G.", ""]]}, {"id": "1708.04649", "submitter": "Ping Wang", "authors": "Ping Wang, Yan Li, Chandan K. Reddy", "title": "Machine Learning for Survival Analysis: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the time of occurrence of an event of interest is a\ncritical problem in longitudinal data analysis. One of the main challenges in\nthis context is the presence of instances whose event outcomes become\nunobservable after a certain time point or when some instances do not\nexperience any event during the monitoring period. Such a phenomenon is called\ncensoring which can be effectively handled using survival analysis techniques.\nTraditionally, statistical approaches have been widely developed in the\nliterature to overcome this censoring issue. In addition, many machine learning\nalgorithms are adapted to effectively handle survival data and tackle other\nchallenging problems that arise in real-world data. In this survey, we provide\na comprehensive and structured review of the representative statistical methods\nalong with the machine learning techniques used in survival analysis and\nprovide a detailed taxonomy of the existing methods. We also discuss several\ntopics that are closely related to survival analysis and illustrate several\nsuccessful applications in various real-world application domains. We hope that\nthis paper will provide a more thorough understanding of the recent advances in\nsurvival analysis and offer some guidelines on applying these approaches to\nsolve new problems that arise in applications with censored data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 19:03:36 GMT"}], "update_date": "2017-12-26", "authors_parsed": [["Wang", "Ping", ""], ["Li", "Yan", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1708.04657", "submitter": "Dimitri Van De Ville", "authors": "Dimitri Van De Ville, Robin Demesmaeker, Maria Giulia Preti", "title": "Guiding Network Analysis using Graph Slepians: An Illustration for the\n  C. Elegans Connectome", "comments": "7 pages, 2 figures, Proceedings of the SPIE Wavelets & Sparsity XVII\n  (August 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral approaches of network analysis heavily rely upon the\neigendecomposition of the graph Laplacian. For instance, in graph signal\nprocessing, the Laplacian eigendecomposition is used to define the graph\nFourier transform and then transpose signal processing operations to graphs by\nimplementing them in the spectral domain. Here, we build on recent work that\ngeneralized Slepian functions to the graph setting. In particular, graph\nSlepians are band-limited graph signals with maximal energy concentration in a\ngiven subgraph. We show how this approach can be used to guide network\nanalysis; i.e., we propose a visualization that reveals network organization of\na subgraph, but while striking a balance with global network structure. These\ndevelopments are illustrated for the structural connectome of the C. Elegans.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 19:26:56 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 11:03:53 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Van De Ville", "Dimitri", ""], ["Demesmaeker", "Robin", ""], ["Preti", "Maria Giulia", ""]]}, {"id": "1708.04670", "submitter": "Dianbo Liu Mr", "authors": "Dianbo Liu, Fengjiao Peng, Andrew Shea, Ognjen (Oggi) Rudovic,\n  Rosalind Picard", "title": "DeepFaceLIFT: Interpretable Personalized Models for Automatic Estimation\n  of Self-Reported Pain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research on automatic pain estimation from facial expressions has\nfocused primarily on \"one-size-fits-all\" metrics (such as PSPI). In this work,\nwe focus on directly estimating each individual's self-reported visual-analog\nscale (VAS) pain metric, as this is considered the gold standard for pain\nmeasurement. The VAS pain score is highly subjective and context-dependent, and\nits range can vary significantly among different persons. To tackle these\nissues, we propose a novel two-stage personalized model, named DeepFaceLIFT,\nfor automatic estimation of VAS. This model is based on (1) Neural Network and\n(2) Gaussian process regression models, and is used to personalize the\nestimation of self-reported pain via a set of hand-crafted personal features\nand multi-task learning. We show on the benchmark dataset for pain analysis\n(The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed\npersonalized model largely outperforms the traditional, unpersonalized models:\nthe intra-class correlation improves from a baseline performance of 19\\% to a\npersonalized performance of 35\\% while also providing confidence in the\nmodel\\textquotesingle s estimates -- in contrast to existing models for the\ntarget task. Additionally, DeepFaceLIFT automatically discovers the\npain-relevant facial regions for each person, allowing for an easy\ninterpretation of the pain-related facial cues.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 12:07:45 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Liu", "Dianbo", "", "Oggi"], ["Peng", "Fengjiao", "", "Oggi"], ["Shea", "Andrew", "", "Oggi"], ["Ognjen", "", "", "Oggi"], ["Rudovic", "", ""], ["Picard", "Rosalind", ""]]}, {"id": "1708.04675", "submitter": "Ruoyu Li", "authors": "Ruoyu Li, Junzhou Huang", "title": "Learning Graph While Training: An Evolving Graph Convolutional Neural\n  Network", "comments": "10 pages, submitted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Networks on Graphs are important generalization and\nextension of classical CNNs. While previous works generally assumed that the\ngraph structures of samples are regular with unified dimensions, in many\napplications, they are highly diverse or even not well defined. Under some\ncircumstances, e.g. chemical molecular data, clustering or coarsening for\nsimplifying the graphs is hard to be justified chemically. In this paper, we\npropose a more general and flexible graph convolution network (EGCN) fed by\nbatch of arbitrarily shaped data together with their evolving graph Laplacians\ntrained in supervised fashion. Extensive experiments have been conducted to\ndemonstrate the superior performance in terms of both the acceleration of\nparameter fitting and the significantly improved prediction accuracy on\nmultiple graph-structured datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 01:55:01 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Li", "Ruoyu", ""], ["Huang", "Junzhou", ""]]}, {"id": "1708.04680", "submitter": "Marcus Bloice", "authors": "Marcus D. Bloice, Christof Stocker, Andreas Holzinger", "title": "Augmentor: An Image Augmentation Library for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of artificial data based on existing observations, known as\ndata augmentation, is a technique used in machine learning to improve model\naccuracy, generalisation, and to control overfitting. Augmentor is a software\npackage, available in both Python and Julia versions, that provides a high\nlevel API for the expansion of image data using a stochastic, pipeline-based\napproach which effectively allows for images to be sampled from a distribution\nof augmented images at runtime. Augmentor provides methods for most standard\naugmentation practices as well as several advanced features such as\nlabel-preserving, randomised elastic distortions, and provides many helper\nfunctions for typical augmentation tasks used in machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 11:19:44 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Bloice", "Marcus D.", ""], ["Stocker", "Christof", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1708.04686", "submitter": "Chuang Gan", "authors": "Chuang Gan, Yandong Li, Haoxiang Li, Chen Sun, Boqing Gong", "title": "VQS: Linking Segmentations to Questions and Answers for Supervised\n  Attention in VQA and Question-Focused Semantic Segmentation", "comments": "To appear on ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rich and dense human labeled datasets are among the main enabling factors for\nthe recent advance on vision-language understanding. Many seemingly distant\nannotations (e.g., semantic segmentation and visual question answering (VQA))\nare inherently connected in that they reveal different levels and perspectives\nof human understandings about the same visual scenes --- and even the same set\nof images (e.g., of COCO). The popularity of COCO correlates those annotations\nand tasks. Explicitly linking them up may significantly benefit both individual\ntasks and the unified vision and language modeling. We present the preliminary\nwork of linking the instance segmentations provided by COCO to the questions\nand answers (QAs) in the VQA dataset, and name the collected links visual\nquestions and segmentation answers (VQS). They transfer human supervision\nbetween the previously separate tasks, offer more effective leverage to\nexisting problems, and also open the door for new research problems and models.\nWe study two applications of the VQS data in this paper: supervised attention\nfor VQA and a novel question-focused semantic segmentation task. For the\nformer, we obtain state-of-the-art results on the VQA real multiple-choice task\nby simply augmenting the multilayer perceptrons with some attention features\nthat are learned using the segmentation-QA links as explicit supervision. To\nput the latter in perspective, we study two plausible methods and compare them\nto an oracle method assuming that the instance segmentations are given at the\ntest stage.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 20:47:02 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Gan", "Chuang", ""], ["Li", "Yandong", ""], ["Li", "Haoxiang", ""], ["Sun", "Chen", ""], ["Gong", "Boqing", ""]]}, {"id": "1708.04692", "submitter": "Anton Osokin", "authors": "Anton Osokin, Anatole Chessel, Rafael E. Carazo Salas and Federico\n  Vaggi", "title": "GANs for Biological Image Synthesis", "comments": "The paper appearing at the International Conference on Computer\n  Vision (ICCV) 2017 + its supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel application of Generative Adversarial\nNetworks (GAN) to the synthesis of cells imaged by fluorescence microscopy.\nCompared to natural images, cells tend to have a simpler and more geometric\nglobal structure that facilitates image generation. However, the correlation\nbetween the spatial pattern of different fluorescent proteins reflects\nimportant biological functions, and synthesized images have to capture these\nrelationships to be relevant for biological applications. We adapt GANs to the\ntask at hand and propose new models with casual dependencies between image\nchannels that can generate multi-channel images, which would be impossible to\nobtain experimentally. We evaluate our approach using two independent\ntechniques and compare it against sensible baselines. Finally, we demonstrate\nthat by interpolating across the latent space we can mimic the known changes in\nprotein localization that occur through time during the cell cycle, allowing us\nto predict temporal evolution from static images.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 21:04:11 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 09:18:24 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Osokin", "Anton", ""], ["Chessel", "Anatole", ""], ["Salas", "Rafael E. Carazo", ""], ["Vaggi", "Federico", ""]]}, {"id": "1708.04714", "submitter": "Michael Lash", "authors": "Michael T. Lash, Yuqi Sun, Xun Zhou, Charles F. Lynch, W. Nick Street", "title": "Learning Rich Geographical Representations: Predicting Colorectal Cancer\n  Survival in the State of Iowa", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are capable of learning rich, nonlinear feature\nrepresentations shown to be beneficial in many predictive tasks. In this work,\nwe use these models to explore the use of geographical features in predicting\ncolorectal cancer survival curves for patients in the state of Iowa, spanning\nthe years 1989 to 2012. Specifically, we compare model performance using a\nnewly defined metric -- area between the curves (ABC) -- to assess (a) whether\nsurvival curves can be reasonably predicted for colorectal cancer patients in\nthe state of Iowa, (b) whether geographical features improve predictive\nperformance, and (c) whether a simple binary representation or richer, spectral\nclustering-based representation perform better. Our findings suggest that\nsurvival curves can be reasonably estimated on average, with predictive\nperformance deviating at the five-year survival mark. We also find that\ngeographical features improve predictive performance, and that the best\nperformance is obtained using richer, spectral analysis-elicited features.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 23:01:47 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Lash", "Michael T.", ""], ["Sun", "Yuqi", ""], ["Zhou", "Xun", ""], ["Lynch", "Charles F.", ""], ["Street", "W. Nick", ""]]}, {"id": "1708.04726", "submitter": "Stephen Suffian", "authors": "Scott Streit, Brian Streit, Stephen Suffian", "title": "Privacy-Enabled Biometric Search", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometrics have a long-held hope of replacing passwords by establishing a\nnon-repudiated identity and providing authentication with convenience.\nConvenience drives consumers toward biometrics-based access management\nsolutions. Unlike passwords, biometrics cannot be script-injected; however,\nbiometric data is considered highly sensitive due to its personal nature and\nunique association with users. Biometrics differ from passwords in that\ncompromised passwords may be reset. Compromised biometrics offer no such\nrelief. A compromised biometric offers unlimited risk in privacy (anyone can\nview the biometric) and authentication (anyone may use the biometric).\nStandards such as the Biometric Open Protocol Standard (BOPS) (IEEE 2410-2016)\nprovide a detailed mechanism to authenticate biometrics based on pre-enrolled\ndevices and a previous identity by storing the biometric in encrypted form.\nThis paper describes a biometric-agnostic approach that addresses the privacy\nconcerns of biometrics through the implementation of BOPS. Specifically, two\nnovel concepts are introduced. First, a biometric is applied to a neural\nnetwork to create a feature vector. This neural network alone can be used for\none-to-one matching (authentication), but would require a search in linear time\nfor the one-to-many case (identity lookup). The classifying algorithm described\nin this paper addresses this concern by producing normalized floating-point\nvalues for each feature vector. This allows authentication lookup to occur in\nup to polynomial time, allowing for search in encrypted biometric databases\nwith speed, accuracy and privacy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 00:25:11 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Streit", "Scott", ""], ["Streit", "Brian", ""], ["Suffian", "Stephen", ""]]}, {"id": "1708.04729", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Dinghan Shen, Guoyin Wang, Zhe Gan, Ricardo Henao,\n  Lawrence Carin", "title": "Deconvolutional Paragraph Representation Learning", "comments": "Accepted by NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent representations from long text sequences is an important\nfirst step in many natural language processing applications. Recurrent Neural\nNetworks (RNNs) have become a cornerstone for this challenging task. However,\nthe quality of sentences during RNN-based decoding (reconstruction) decreases\nwith the length of the text. We propose a sequence-to-sequence, purely\nconvolutional and deconvolutional autoencoding framework that is free of the\nabove issue, while also being computationally efficient. The proposed method is\nsimple, easy to implement and can be leveraged as a building block for many\napplications. We show empirically that compared to RNNs, our framework is\nbetter at reconstructing and correcting long paragraphs. Quantitative\nevaluation on semi-supervised text classification and summarization tasks\ndemonstrate the potential for better utilization of long unlabeled text data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 00:52:32 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 17:13:13 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 15:20:27 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Zhang", "Yizhe", ""], ["Shen", "Dinghan", ""], ["Wang", "Guoyin", ""], ["Gan", "Zhe", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1708.04733", "submitter": "Minh Trung Le", "authors": "Trung Le, Hung Vu, Tu Dinh Nguyen, Dinh Phung", "title": "Geometric Enclosing Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training model to generate data has increasingly attracted research attention\nand become important in modern world applications. We propose in this paper a\nnew geometry-based optimization approach to address this problem. Orthogonal to\ncurrent state-of-the-art density-based approaches, most notably VAE and GAN, we\npresent a fresh new idea that borrows the principle of minimal enclosing ball\nto train a generator G\\left(\\bz\\right) in such a way that both training and\ngenerated data, after being mapped to the feature space, are enclosed in the\nsame sphere. We develop theory to guarantee that the mapping is bijective so\nthat its inverse from feature space to data space results in expressive\nnonlinear contours to describe the data manifold, hence ensuring data generated\nare also lying on the data manifold learned from training data. Our model\nenjoys a nice geometric interpretation, hence termed Geometric Enclosing\nNetworks (GEN), and possesses some key advantages over its rivals, namely\nsimple and easy-to-control optimization formulation, avoidance of mode\ncollapsing and efficiently learn data manifold representation in a completely\nunsupervised manner. We conducted extensive experiments on synthesis and\nreal-world datasets to illustrate the behaviors, strength and weakness of our\nproposed GEN, in particular its ability to handle multi-modal data and quality\nof generated data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 01:10:49 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 04:58:35 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Le", "Trung", ""], ["Vu", "Hung", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "1708.04757", "submitter": "Hossein Soleimani", "authors": "Hossein Soleimani, James Hensman, Suchi Saria", "title": "Scalable Joint Models for Reliable Uncertainty-Aware Event Prediction", "comments": "To appear in IEEE Transaction on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data and noisy observations pose significant challenges for reliably\npredicting events from irregularly sampled multivariate time series\n(longitudinal) data. Imputation methods, which are typically used for\ncompleting the data prior to event prediction, lack a principled mechanism to\naccount for the uncertainty due to missingness. Alternatively, state-of-the-art\njoint modeling techniques can be used for jointly modeling the longitudinal and\nevent data and compute event probabilities conditioned on the longitudinal\nobservations. These approaches, however, make strong parametric assumptions and\ndo not easily scale to multivariate signals with many observations. Our\nproposed approach consists of several key innovations. First, we develop a\nflexible and scalable joint model based upon sparse multiple-output Gaussian\nprocesses. Unlike state-of-the-art joint models, the proposed model can explain\nhighly challenging structure including non-Gaussian noise while scaling to\nlarge data. Second, we derive an optimal policy for predicting events using the\ndistribution of the event occurrence estimated by the joint model. The derived\npolicy trades-off the cost of a delayed detection versus incorrect assessments\nand abstains from making decisions when the estimated event probability does\nnot satisfy the derived confidence criteria. Experiments on a large dataset\nshow that the proposed framework significantly outperforms state-of-the-art\ntechniques in event prediction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 03:27:25 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Soleimani", "Hossein", ""], ["Hensman", "James", ""], ["Saria", "Suchi", ""]]}, {"id": "1708.04764", "submitter": "Yuantao Gu", "authors": "Yanxi Chen, Gen Li and Yuantao Gu", "title": "Active Orthogonal Matching Pursuit for Sparse Subspace Clustering", "comments": "14 pages, 5 figures, 1 table", "journal-ref": null, "doi": "10.1109/LSP.2017.2741509", "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Subspace Clustering (SSC) is a state-of-the-art method for clustering\nhigh-dimensional data points lying in a union of low-dimensional subspaces.\nHowever, while $\\ell_1$ optimization-based SSC algorithms suffer from high\ncomputational complexity, other variants of SSC, such as Orthogonal Matching\nPursuit-based SSC (OMP-SSC), lose clustering accuracy in pursuit of improving\ntime efficiency. In this letter, we propose a novel Active OMP-SSC, which\nimproves clustering accuracy of OMP-SSC by adaptively updating data points and\nrandomly dropping data points in the OMP process, while still enjoying the low\ncomputational complexity of greedy pursuit algorithms. We provide heuristic\nanalysis of our approach, and explain how these two active steps achieve a\nbetter tradeoff between connectivity and separation. Numerical results on both\nsynthetic data and real-world data validate our analyses and show the\nadvantages of the proposed active algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 04:15:37 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Chen", "Yanxi", ""], ["Li", "Gen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1708.04781", "submitter": "Yichi Zhou", "authors": "Yichi Zhou, Jun Zhu, Jingwei Zhuo", "title": "Racing Thompson: an Efficient Algorithm for Thompson Sampling with\n  Non-conjugate Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling has impressive empirical performance for many multi-armed\nbandit problems. But current algorithms for Thompson sampling only work for the\ncase of conjugate priors since these algorithms require to infer the posterior,\nwhich is often computationally intractable when the prior is not conjugate. In\nthis paper, we propose a novel algorithm for Thompson sampling which only\nrequires to draw samples from a tractable distribution, so our algorithm is\nefficient even when the prior is non-conjugate. To do this, we reformulate\nThompson sampling as an optimization problem via the Gumbel-Max trick. After\nthat we construct a set of random variables and our goal is to identify the one\nwith highest mean. Finally, we solve it with techniques in best arm\nidentification.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 06:20:40 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Zhou", "Yichi", ""], ["Zhu", "Jun", ""], ["Zhuo", "Jingwei", ""]]}, {"id": "1708.04782", "submitter": "Timothy Lillicrap", "authors": "Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander\n  Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich K\\\"uttler, John\n  Agapiou, Julian Schrittwieser, John Quan, Stephen Gaffney, Stig Petersen,\n  Karen Simonyan, Tom Schaul, Hado van Hasselt, David Silver, Timothy\n  Lillicrap, Kevin Calderone, Paul Keet, Anthony Brunasso, David Lawrence,\n  Anders Ekermo, Jacob Repp, Rodney Tsing", "title": "StarCraft II: A New Challenge for Reinforcement Learning", "comments": "Collaboration between DeepMind & Blizzard. 20 pages, 9 figures, 2\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces SC2LE (StarCraft II Learning Environment), a\nreinforcement learning environment based on the StarCraft II game. This domain\nposes a new grand challenge for reinforcement learning, representing a more\ndifficult class of problems than considered in most prior work. It is a\nmulti-agent problem with multiple players interacting; there is imperfect\ninformation due to a partially observed map; it has a large action space\ninvolving the selection and control of hundreds of units; it has a large state\nspace that must be observed solely from raw input feature planes; and it has\ndelayed credit assignment requiring long-term strategies over thousands of\nsteps. We describe the observation, action, and reward specification for the\nStarCraft II domain and provide an open source Python-based interface for\ncommunicating with the game engine. In addition to the main game maps, we\nprovide a suite of mini-games focusing on different elements of StarCraft II\ngameplay. For the main game maps, we also provide an accompanying dataset of\ngame replay data from human expert players. We give initial baseline results\nfor neural networks trained from this data to predict game outcomes and player\nactions. Finally, we present initial baseline results for canonical deep\nreinforcement learning agents applied to the StarCraft II domain. On the\nmini-games, these agents learn to achieve a level of play that is comparable to\na novice player. However, when trained on the main game, these agents are\nunable to make significant progress. Thus, SC2LE offers a new and challenging\nenvironment for exploring deep reinforcement learning algorithms and\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 06:20:52 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Vinyals", "Oriol", ""], ["Ewalds", "Timo", ""], ["Bartunov", "Sergey", ""], ["Georgiev", "Petko", ""], ["Vezhnevets", "Alexander Sasha", ""], ["Yeo", "Michelle", ""], ["Makhzani", "Alireza", ""], ["K\u00fcttler", "Heinrich", ""], ["Agapiou", "John", ""], ["Schrittwieser", "Julian", ""], ["Quan", "John", ""], ["Gaffney", "Stephen", ""], ["Petersen", "Stig", ""], ["Simonyan", "Karen", ""], ["Schaul", "Tom", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Lillicrap", "Timothy", ""], ["Calderone", "Kevin", ""], ["Keet", "Paul", ""], ["Brunasso", "Anthony", ""], ["Lawrence", "David", ""], ["Ekermo", "Anders", ""], ["Repp", "Jacob", ""], ["Tsing", "Rodney", ""]]}, {"id": "1708.04788", "submitter": "Aswin Raghavan", "authors": "Aswin Raghavan, Mohamed Amer, Sek Chai, Graham Taylor", "title": "BitNet: Bit-Regularized Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel optimization strategy for training neural networks which\nwe call \"BitNet\". The parameters of neural networks are usually unconstrained\nand have a dynamic range dispersed over all real values. Our key idea is to\nlimit the expressive power of the network by dynamically controlling the range\nand set of values that the parameters can take. We formulate this idea using a\nnovel end-to-end approach that circumvents the discrete parameter space by\noptimizing a relaxed continuous and differentiable upper bound of the typical\nclassification loss function. The approach can be interpreted as a\nregularization inspired by the Minimum Description Length (MDL) principle. For\neach layer of the network, our approach optimizes real-valued translation and\nscaling factors and arbitrary precision integer-valued parameters (weights). We\nempirically compare BitNet to an equivalent unregularized model on the MNIST\nand CIFAR-10 datasets. We show that BitNet converges faster to a superior\nquality solution. Additionally, the resulting model has significant savings in\nmemory due to the use of integer-valued parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 06:51:23 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 07:52:53 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 20:20:25 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Raghavan", "Aswin", ""], ["Amer", "Mohamed", ""], ["Chai", "Sek", ""], ["Taylor", "Graham", ""]]}, {"id": "1708.04799", "submitter": "Rameshwar Pratap", "authors": "Rameshwar Pratap, Ishan Sohony, Raghav Kulkarni", "title": "Efficient Compression Technique for Sparse Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advancements have led to the generation of huge amounts\nof data over the web, such as text, image, audio and video. Most of this data\nis high dimensional and sparse, for e.g., the bag-of-words representation used\nfor representing text. Often, an efficient search for similar data points needs\nto be performed in many applications like clustering, nearest neighbour search,\nranking and indexing. Even though there have been significant increases in\ncomputational power, a simple brute-force similarity-search on such datasets is\ninefficient and at times impossible. Thus, it is desirable to get a compressed\nrepresentation which preserves the similarity between data points. In this\nwork, we consider the data points as sets and use Jaccard similarity as the\nsimilarity measure. Compression techniques are generally evaluated on the\nfollowing parameters --1) Randomness required for compression, 2) Time required\nfor compression, 3) Dimension of the data after compression, and 4) Space\nrequired to store the compressed data. Ideally, the compressed representation\nof the data should be such, that the similarity between each pair of data\npoints is preserved, while keeping the time and the randomness required for\ncompression as low as possible.\n  We show that the compression technique suggested by Pratap and Kulkarni also\nworks well for Jaccard similarity. We present a theoretical proof of the same\nand complement it with rigorous experimentations on synthetic as well as\nreal-world datasets. We also compare our results with the state-of-the-art\n\"min-wise independent permutation\", and show that our compression algorithm\nachieves almost equal accuracy while significantly reducing the compression\ntime and the randomness.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 08:19:13 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Pratap", "Rameshwar", ""], ["Sohony", "Ishan", ""], ["Kulkarni", "Raghav", ""]]}, {"id": "1708.04801", "submitter": "Daning Cheng", "authors": "Cheng Daning, Li Shigang and Zhang Yunquan", "title": "Weighted parallel SGD for distributed unbalanced-workload training\n  system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is a popular stochastic optimization method\nin machine learning. Traditional parallel SGD algorithms, e.g., SimuParallel\nSGD, often require all nodes to have the same performance or to consume equal\nquantities of data. However, these requirements are difficult to satisfy when\nthe parallel SGD algorithms run in a heterogeneous computing environment;\nlow-performance nodes will exert a negative influence on the final result. In\nthis paper, we propose an algorithm called weighted parallel SGD (WP-SGD).\nWP-SGD combines weighted model parameters from different nodes in the system to\nproduce the final output. WP-SGD makes use of the reduction in standard\ndeviation to compensate for the loss from the inconsistency in performance of\nnodes in the cluster, which means that WP-SGD does not require that all nodes\nconsume equal quantities of data. We also analyze the theoretical feasibility\nof running two other parallel SGD algorithms combined with WP-SGD in a\nheterogeneous environment. The experimental results show that WP-SGD\nsignificantly outperforms the traditional parallel SGD algorithms on\ndistributed training systems with an unbalanced workload.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 08:29:23 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Daning", "Cheng", ""], ["Shigang", "Li", ""], ["Yunquan", "Zhang", ""]]}, {"id": "1708.04887", "submitter": "Jelena Bradic", "authors": "Jelena Bradic, Gerda Claeskens, Thomas Gueuning", "title": "Fixed effects testing in high-dimensional linear mixed models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific and engineering challenges -- ranging from pharmacokinetic\ndrug dosage allocation and personalized medicine to marketing mix (4Ps)\nrecommendations -- require an understanding of the unobserved heterogeneity in\norder to develop the best decision making-processes. In this paper, we develop\na hypothesis test and the corresponding p-value for testing for the\nsignificance of the homogeneous structure in linear mixed models. A robust\nmatching moment construction is used for creating a test that adapts to the\nsize of the model sparsity. When unobserved heterogeneity at a cluster level is\nconstant, we show that our test is both consistent and unbiased even when the\ndimension of the model is extremely high. Our theoretical results rely on a new\nfamily of adaptive sparse estimators of the fixed effects that do not require\nconsistent estimation of the random effects. Moreover, our inference results do\nnot require consistent model selection. We showcase that moment matching can be\nextended to nonlinear mixed effects models and to generalized linear mixed\neffects models. In numerical and real data experiments, we find that the\ndeveloped method is extremely accurate, that it adapts to the size of the\nunderlying model and is decidedly powerful in the presence of irrelevant\ncovariates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 21:48:46 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Bradic", "Jelena", ""], ["Claeskens", "Gerda", ""], ["Gueuning", "Thomas", ""]]}, {"id": "1708.04923", "submitter": "Rahul Aralikatte", "authors": "Naveen Panwar, Shreya Khare, Neelamadhav Gantayat, Rahul Aralikatte,\n  Senthil Mani, Anush Sankaran", "title": "mAnI: Movie Amalgamation using Neural Imitation", "comments": "Accepted in ML4Creativity workshop in KDD 2017. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal data retrieval has been the basis of various creative tasks\nperformed by Artificial Intelligence (AI). One such highly challenging task for\nAI is to convert a book into its corresponding movie, which most of the\ncreative film makers do as of today. In this research, we take the first step\ntowards it by visualizing the content of a book using its corresponding movie\nvisuals. Given a set of sentences from a book or even a fan-fiction written in\nthe same universe, we employ deep learning models to visualize the input by\nstitching together relevant frames from the movie. We studied and compared\nthree different types of setting to match the book with the movie content: (i)\nDialog model: using only the dialog from the movie, (ii) Visual model: using\nonly the visual content from the movie, and (iii) Hybrid model: using the\ndialog and the visual content from the movie. Experiments on the publicly\navailable MovieBook dataset shows the effectiveness of the proposed models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 15:12:20 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Panwar", "Naveen", ""], ["Khare", "Shreya", ""], ["Gantayat", "Neelamadhav", ""], ["Aralikatte", "Rahul", ""], ["Mani", "Senthil", ""], ["Sankaran", "Anush", ""]]}, {"id": "1708.04968", "submitter": "Rahul Aralikatte", "authors": "Rahul Aralikatte, Giriprasad Sridhara, Neelamadhav Gantayat, Senthil\n  Mani", "title": "Fault in your stars: An Analysis of Android App Reviews", "comments": "Accepted in CoDS-COMAD 2018. Preprint", "journal-ref": null, "doi": "10.1145/3152494.3152500", "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile app distribution platforms such as Google Play Store allow users to\nshare their feedback about downloaded apps in the form of a review comment and\na corresponding star rating. Typically, the star rating ranges from one to five\nstars, with one star denoting a high sense of dissatisfaction with the app and\nfive stars denoting a high sense of satisfaction.\n  Unfortunately, due to a variety of reasons, often the star rating provided by\na user is inconsistent with the opinion expressed in the review. For example,\nconsider the following review for the Facebook App on Android; \"Awesome App\".\nOne would reasonably expect the rating for this review to be five stars, but\nthe actual rating is one star!\n  Such inconsistent ratings can lead to a deflated (or inflated) overall\naverage rating of an app which can affect user downloads, as typically users\nlook at the average star ratings while making a decision on downloading an app.\nAlso, the app developers receive a biased feedback about the application that\ndoes not represent ground reality. This is especially significant for small\napps with a few thousand downloads as even a small number of mismatched reviews\ncan bring down the average rating drastically.\n  In this paper, we conducted a study on this review-rating mismatch problem.\nWe manually examined 8600 reviews from 10 popular Android apps and found that\n20% of the ratings in our dataset were inconsistent with the review. Further,\nwe developed three systems; two of which were based on traditional machine\nlearning and one on deep learning to automatically identify reviews whose\nrating did not match with the opinion expressed in the review. Our deep\nlearning system performed the best and had an accuracy of 92% in identifying\nthe correct star rating to be associated with a given review.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 16:37:52 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 06:56:39 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Aralikatte", "Rahul", ""], ["Sridhara", "Giriprasad", ""], ["Gantayat", "Neelamadhav", ""], ["Mani", "Senthil", ""]]}, {"id": "1708.04970", "submitter": "Daniel Ting", "authors": "Daniel Ting", "title": "Adaptive Threshold Sampling and Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is a fundamental problem in both computer science and statistics. A\nnumber of issues arise when designing a method based on sampling. These include\nstatistical considerations such as constructing a good sampling design and\nensuring there are good, tractable estimators for the quantities of interest as\nwell as computational considerations such as designing fast algorithms for\nstreaming data and ensuring the sample fits within memory constraints.\nUnfortunately, existing sampling methods are only able to address all of these\nissues in limited scenarios.\n  We develop a framework that can be used to address these issues in a broad\nrange of scenarios. In particular, it addresses the problem of drawing and\nusing samples under some memory budget constraint. This problem can be\nchallenging since the memory budget forces samples to be drawn\nnon-independently and consequently, makes computation of resulting estimators\ndifficult.\n  At the core of the framework is the notion of a data adaptive thresholding\nscheme where the threshold effectively allows one to treat the non-independent\nsample as if it were drawn independently. We provide sufficient conditions for\na thresholding scheme to allow this and provide ways to build and compose such\nschemes.\n  Furthermore, we provide fast algorithms to efficiently sample under these\nthresholding schemes.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 16:45:47 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Ting", "Daniel", ""]]}, {"id": "1708.04987", "submitter": "Adrian Roitberg", "authors": "Justin S. Smith, Olexandr Isayev, and Adrian E. Roitberg", "title": "ANI-1: A data set of 20M off-equilibrium DFT calculations for organic\n  molecules", "comments": null, "journal-ref": "Scientific Data 4, Article number: 170193 (2017)", "doi": "10.1038/sdata.2017.193", "report-no": null, "categories": "physics.chem-ph cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the grand challenges in modern theoretical chemistry is designing and\nimplementing approximations that expedite ab initio methods without loss of\naccuracy. Machine learning (ML), in particular neural networks, are emerging as\na powerful approach to constructing various forms of transferable atomistic\npotentials. They have been successfully applied in a variety of applications in\nchemistry, biology, catalysis, and solid-state physics. However, these models\nare heavily dependent on the quality and quantity of data used in their\nfitting. Fitting highly flexible ML potentials comes at a cost: a vast amount\nof reference data is required to properly train these models. We address this\nneed by providing access to a large computational DFT database, which consists\nof 20M conformations for 57,454 small organic molecules. We believe it will\nbecome a new standard benchmark for comparison of current and future methods in\nthe ML potential community.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 17:26:49 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 17:00:55 GMT"}, {"version": "v3", "created": "Fri, 8 Dec 2017 21:06:23 GMT"}, {"version": "v4", "created": "Tue, 12 Dec 2017 20:25:20 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Smith", "Justin S.", ""], ["Isayev", "Olexandr", ""], ["Roitberg", "Adrian E.", ""]]}, {"id": "1708.05027", "submitter": "Xiangnan He", "authors": "Xiangnan He, Tat-Seng Chua", "title": "Neural Factorization Machines for Sparse Predictive Analytics", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many predictive tasks of web applications need to model categorical\nvariables, such as user IDs and demographics like genders and occupations. To\napply standard machine learning techniques, these categorical predictors are\nalways converted to a set of binary features via one-hot encoding, making the\nresultant feature vector highly sparse. To learn from such sparse data\neffectively, it is crucial to account for the interactions between features.\n  Factorization Machines (FMs) are a popular solution for efficiently using the\nsecond-order feature interactions. However, FM models feature interactions in a\nlinear way, which can be insufficient for capturing the non-linear and complex\ninherent structure of real-world data. While deep neural networks have recently\nbeen applied to learn non-linear feature interactions in industry, such as the\nWide&Deep by Google and DeepCross by Microsoft, the deep structure meanwhile\nmakes them difficult to train.\n  In this paper, we propose a novel model Neural Factorization Machine (NFM)\nfor prediction under sparse settings. NFM seamlessly combines the linearity of\nFM in modelling second-order feature interactions and the non-linearity of\nneural network in modelling higher-order feature interactions. Conceptually,\nNFM is more expressive than FM since FM can be seen as a special case of NFM\nwithout hidden layers. Empirical results on two regression tasks show that with\none hidden layer only, NFM significantly outperforms FM with a 7.3% relative\nimprovement. Compared to the recent deep learning methods Wide&Deep and\nDeepCross, our NFM uses a shallower structure but offers better performance,\nbeing much easier to train and tune in practice.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 18:24:16 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["He", "Xiangnan", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1708.05033", "submitter": "Pratik Gajane", "authors": "Pratik Gajane, Tanguy Urvoy, Emilie Kaufmann", "title": "Corrupt Bandits for Preserving Local Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the stochastic multi-armed bandit (MAB) problem in\nwhich the rewards are corrupted. In this framework, motivated by privacy\npreservation in online recommender systems, the goal is to maximize the sum of\nthe (unobserved) rewards, based on the observation of transformation of these\nrewards through a stochastic corruption process with known parameters. We\nprovide a lower bound on the expected regret of any bandit algorithm in this\ncorrupted setting. We devise a frequentist algorithm, KLUCB-CF, and a Bayesian\nalgorithm, TS-CF and give upper bounds on their regret. We also provide the\nappropriate corruption parameters to guarantee a desired level of local privacy\nand analyze how this impacts the regret. Finally, we present some experimental\nresults that confirm our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 18:32:24 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 23:13:14 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Gajane", "Pratik", ""], ["Urvoy", "Tanguy", ""], ["Kaufmann", "Emilie", ""]]}, {"id": "1708.05070", "submitter": "Randal Olson", "authors": "Randal S. Olson, William La Cava, Zairah Mustahsan, Akshay Varik,\n  Jason H. Moore", "title": "Data-driven Advice for Applying Machine Learning to Bioinformatics\n  Problems", "comments": "12 pages, 5 figures, 4 tables. To be published in the proceedings of\n  PSB 2018. Randal S. Olson and William La Cava contributed equally as co-first\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the bioinformatics field grows, it must keep pace not only with new data\nbut with new algorithms. Here we contribute a thorough analysis of 13\nstate-of-the-art, commonly used machine learning algorithms on a set of 165\npublicly available classification problems in order to provide data-driven\nalgorithm recommendations to current researchers. We present a number of\nstatistical and visual comparisons of algorithm performance and quantify the\neffect of model selection and algorithm tuning for each algorithm and dataset.\nThe analysis culminates in the recommendation of five algorithms with\nhyperparameters that maximize classifier performance across the tested\nproblems, as well as general guidelines for applying machine learning to\nsupervised classification problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 21:41:48 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 19:08:53 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Olson", "Randal S.", ""], ["La Cava", "William", ""], ["Mustahsan", "Zairah", ""], ["Varik", "Akshay", ""], ["Moore", "Jason H.", ""]]}, {"id": "1708.05106", "submitter": "Arin Chaudhuri", "authors": "Arin Chaudhuri, Deovrat Kakde, Carol Sadek, Laura Gonzalez, Seunghyun\n  Kong", "title": "The Mean and Median Criterion for Automatic Kernel Bandwidth Selection\n  for Support Vector Data Description", "comments": null, "journal-ref": null, "doi": "10.1109/ICDMW.2017.116", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector data description (SVDD) is a popular technique for detecting\nanomalies. The SVDD classifier partitions the whole space into an inlier\nregion, which consists of the region near the training data, and an outlier\nregion, which consists of points away from the training data. The computation\nof the SVDD classifier requires a kernel function, and the Gaussian kernel is a\ncommon choice for the kernel function. The Gaussian kernel has a bandwidth\nparameter, whose value is important for good results. A small bandwidth leads\nto overfitting, and the resulting SVDD classifier overestimates the number of\nanomalies. A large bandwidth leads to underfitting, and the classifier fails to\ndetect many anomalies. In this paper we present a new automatic, unsupervised\nmethod for selecting the Gaussian kernel bandwidth. The selected value can be\ncomputed quickly, and it is competitive with existing bandwidth selection\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 23:38:35 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 23:12:34 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Chaudhuri", "Arin", ""], ["Kakde", "Deovrat", ""], ["Sadek", "Carol", ""], ["Gonzalez", "Laura", ""], ["Kong", "Seunghyun", ""]]}, {"id": "1708.05118", "submitter": "Antonio Blanca", "authors": "Antonio Blanca, Zongchen Chen, Daniel \\v{S}tefankovi\\v{c}, Eric Vigoda", "title": "Structure Learning of $H$-colorings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the structure learning problem for $H$-colorings, an important class\nof Markov random fields that capture key combinatorial structures on graphs,\nincluding proper colorings and independent sets, as well as spin systems from\nstatistical physics. The learning problem is as follows: for a fixed (and\nknown) constraint graph $H$ with $q$ colors and an unknown graph $G=(V,E)$ with\n$n$ vertices, given uniformly random $H$-colorings of $G$, how many samples are\nrequired to learn the edges of the unknown graph $G$? We give a\ncharacterization of $H$ for which the problem is identifiable for every $G$,\ni.e., we can learn $G$ with an infinite number of samples. We also show that\nthere are identifiable constraint graphs for which one cannot hope to learn\nevery graph $G$ efficiently.\n  We focus particular attention on the case of proper vertex $q$-colorings of\ngraphs of maximum degree $d$ where intriguing connections to statistical\nphysics phase transitions appear. We prove that in the tree uniqueness region\n(when $q>d$) the problem is identifiable and we can learn $G$ in ${\\rm\npoly}(d,q) \\times O(n^2\\log{n})$ time. In contrast for soft-constraint systems,\nsuch as the Ising model, the best possible running time is exponential in $d$.\nIn the tree non-uniqueness region (when $q\\leq d$) we prove that the problem is\nnot identifiable and thus $G$ cannot be learned. Moreover, when $q<d-\\sqrt{d} +\n\\Theta(1)$ we prove that even learning an equivalent graph (any graph with the\nsame set of $H$-colorings) is computationally hard---sample complexity is\nexponential in $n$ in the worst case. We further explore the connection between\nthe efficiency/hardness of the structure learning problem and the\nuniqueness/non-uniqueness phase transition for general $H$-colorings and prove\nthat under the well-known Dobrushin uniqueness condition, we can learn $G$ in\n${\\rm poly}(d,q)\\times O(n^2\\log{n})$ time.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 02:29:10 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 15:52:35 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Blanca", "Antonio", ""], ["Chen", "Zongchen", ""], ["\u0160tefankovi\u010d", "Daniel", ""], ["Vigoda", "Eric", ""]]}, {"id": "1708.05123", "submitter": "Ruoxi Wang", "authors": "Ruoxi Wang, Bin Fu, Gang Fu, Mingliang Wang", "title": "Deep & Cross Network for Ad Click Predictions", "comments": "In Proceedings of AdKDD and TargetAd, Halifax, NS, Canada, August,\n  14, 2017, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering has been the key to the success of many prediction\nmodels. However, the process is non-trivial and often requires manual feature\nengineering or exhaustive searching. DNNs are able to automatically learn\nfeature interactions; however, they generate all the interactions implicitly,\nand are not necessarily efficient in learning all types of cross features. In\nthis paper, we propose the Deep & Cross Network (DCN) which keeps the benefits\nof a DNN model, and beyond that, it introduces a novel cross network that is\nmore efficient in learning certain bounded-degree feature interactions. In\nparticular, DCN explicitly applies feature crossing at each layer, requires no\nmanual feature engineering, and adds negligible extra complexity to the DNN\nmodel. Our experimental results have demonstrated its superiority over the\nstate-of-art algorithms on the CTR prediction dataset and dense classification\ndataset, in terms of both model accuracy and memory usage.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 03:28:04 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Wang", "Ruoxi", ""], ["Fu", "Bin", ""], ["Fu", "Gang", ""], ["Wang", "Mingliang", ""]]}, {"id": "1708.05144", "submitter": "Yuhuai(Tony) Wu", "authors": "Yuhuai Wu, Elman Mansimov, Shun Liao, Roger Grosse, Jimmy Ba", "title": "Scalable trust-region method for deep reinforcement learning using\n  Kronecker-factored approximation", "comments": "14 pages, 9 figures; update github repo link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to apply trust region optimization to deep\nreinforcement learning using a recently proposed Kronecker-factored\napproximation to the curvature. We extend the framework of natural policy\ngradient and propose to optimize both the actor and the critic using\nKronecker-factored approximate curvature (K-FAC) with trust region; hence we\ncall our method Actor Critic using Kronecker-Factored Trust Region (ACKTR). To\nthe best of our knowledge, this is the first scalable trust region natural\ngradient method for actor-critic methods. It is also a method that learns\nnon-trivial tasks in continuous control as well as discrete control policies\ndirectly from raw pixel inputs. We tested our approach across discrete domains\nin Atari games as well as continuous domains in the MuJoCo environment. With\nthe proposed methods, we are able to achieve higher rewards and a 2- to 3-fold\nimprovement in sample efficiency on average, compared to previous\nstate-of-the-art on-policy actor-critic methods. Code is available at\nhttps://github.com/openai/baselines\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 06:14:48 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 11:16:36 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Wu", "Yuhuai", ""], ["Mansimov", "Elman", ""], ["Liao", "Shun", ""], ["Grosse", "Roger", ""], ["Ba", "Jimmy", ""]]}, {"id": "1708.05165", "submitter": "Dawei Chen", "authors": "Aditya Krishna Menon, Dawei Chen, Lexing Xie, Cheng Soon Ong", "title": "Revisiting revisits in trajectory recommendation", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory recommendation is the problem of recommending a sequence of places\nin a city for a tourist to visit. It is strongly desirable for the recommended\nsequence to avoid loops, as tourists typically would not wish to revisit the\nsame location. Given some learned model that scores sequences, how can we then\nfind the highest-scoring sequence that is loop-free? This paper studies this\nproblem, with three contributions. First, we detail three distinct approaches\nto the problem -- graph-based heuristics, integer linear programming, and list\nextensions of the Viterbi algorithm -- and qualitatively summarise their\nstrengths and weaknesses. Second, we explicate how two ostensibly different\napproaches to the list Viterbi algorithm are in fact fundamentally identical.\nThird, we conduct experiments on real-world trajectory recommendation datasets\nto identify the tradeoffs imposed by each of the three approaches. Overall, our\nresults indicate that a greedy graph-based heuristic offer excellent\nperformance and runtime, leading us to recommend its use for removing loops at\nprediction time.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 08:05:53 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["Chen", "Dawei", ""], ["Xie", "Lexing", ""], ["Ong", "Cheng Soon", ""]]}, {"id": "1708.05207", "submitter": "Jamie Hayes", "authors": "Jamie Hayes and George Danezis", "title": "Learning Universal Adversarial Perturbations with Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to adversarial examples, inputs\nthat have been intentionally perturbed to remain visually similar to the source\ninput, but cause a misclassification. It was recently shown that given a\ndataset and classifier, there exists so called universal adversarial\nperturbations, a single perturbation that causes a misclassification when\napplied to any input. In this work, we introduce universal adversarial\nnetworks, a generative network that is capable of fooling a target classifier\nwhen it's generated output is added to a clean sample from a dataset. We show\nthat this technique improves on known universal adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 11:25:39 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 17:26:10 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 14:12:48 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Hayes", "Jamie", ""], ["Danezis", "George", ""]]}, {"id": "1708.05256", "submitter": "Thorsten Kurth", "authors": "Thorsten Kurth, Jian Zhang, Nadathur Satish, Ioannis Mitliagkas, Evan\n  Racah, Mostofa Ali Patwary, Tareq Malas, Narayanan Sundaram, Wahid Bhimji,\n  Mikhail Smorkalov, Jack Deslippe, Mikhail Shiryaev, Srinivas Sridharan,\n  Prabhat, Pradeep Dubey", "title": "Deep Learning at 15PF: Supervised and Semi-Supervised Classification for\n  Scientific Data", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first, 15-PetaFLOP Deep Learning system for solving\nscientific pattern classification problems on contemporary HPC architectures.\nWe develop supervised convolutional architectures for discriminating signals in\nhigh-energy physics data as well as semi-supervised architectures for\nlocalizing and classifying extreme weather in climate data. Our\nIntelcaffe-based implementation obtains $\\sim$2TFLOP/s on a single Cori\nPhase-II Xeon-Phi node. We use a hybrid strategy employing synchronous\nnode-groups, while using asynchronous communication across groups. We use this\nstrategy to scale training of a single model to $\\sim$9600 Xeon-Phi nodes;\nobtaining peak performance of 11.73-15.07 PFLOP/s and sustained performance of\n11.41-13.27 PFLOP/s. At scale, our HEP architecture produces state-of-the-art\nclassification accuracy on a dataset with 10M images, exceeding that achieved\nby selections on high-level physics-motivated features. Our semi-supervised\narchitecture successfully extracts weather patterns in a 15TB climate dataset.\nOur results demonstrate that Deep Learning can be optimized and scaled\neffectively on many-core, HPC systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 13:21:36 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Kurth", "Thorsten", ""], ["Zhang", "Jian", ""], ["Satish", "Nadathur", ""], ["Mitliagkas", "Ioannis", ""], ["Racah", "Evan", ""], ["Patwary", "Mostofa Ali", ""], ["Malas", "Tareq", ""], ["Sundaram", "Narayanan", ""], ["Bhimji", "Wahid", ""], ["Smorkalov", "Mikhail", ""], ["Deslippe", "Jack", ""], ["Shiryaev", "Mikhail", ""], ["Sridharan", "Srinivas", ""], ["Prabhat", "", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1708.05279", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, Marcus Edel", "title": "Designing and building the mlpack open-source machine learning library", "comments": "submitted to ICOPUST 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  mlpack is an open-source C++ machine learning library with an emphasis on\nspeed and flexibility. Since its original inception in 2007, it has grown to be\na large project implementing a wide variety of machine learning algorithms,\nfrom standard techniques such as decision trees and logistic regression to\nmodern techniques such as deep neural networks as well as other\nrecently-published cutting-edge techniques not found in any other library.\nmlpack is quite fast, with benchmarks showing mlpack outperforming other\nlibraries' implementations of the same methods. mlpack has an active community,\nwith contributors from around the world---including some from PUST. This short\npaper describes the goals and design of mlpack, discusses how the open-source\ncommunity functions, and shows an example usage of mlpack for a simple data\nscience problem.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 13:59:48 GMT"}, {"version": "v2", "created": "Wed, 30 Aug 2017 15:41:17 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Edel", "Marcus", ""]]}, {"id": "1708.05325", "submitter": "Stefan Lattner", "authors": "Stefan Lattner, Maarten Grachten, Gerhard Widmer", "title": "Learning Musical Relations using Gated Autoencoders", "comments": "In Proceedings of the 2nd Conference on Computer Simulation of\n  Musical Creativity (CSMC 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music is usually highly structured and it is still an open question how to\ndesign models which can successfully learn to recognize and represent musical\nstructure. A fundamental problem is that structurally related patterns can have\nvery distinct appearances, because the structural relationships are often based\non transformations of musical material, like chromatic or diatonic\ntransposition, inversion, retrograde, or rhythm change. In this preliminary\nwork, we study the potential of two unsupervised learning techniques -\nRestricted Boltzmann Machines (RBMs) and Gated Autoencoders (GAEs) - to capture\npre-defined transformations from constructed data pairs. We evaluate the models\nby using the learned representations as inputs in a discriminative task where\nfor a given type of transformation (e.g. diatonic transposition), the specific\nrelation between two musical patterns must be recognized (e.g. an upward\ntransposition of diatonic steps). Furthermore, we measure the reconstruction\nerror of models when reconstructing musical transformed patterns. Lastly, we\ntest the models in an analogy-making task. We find that it is difficult to\nlearn musical transformations with the RBM and that the GAE is much more\nadequate for this task, since it is able to learn representations of specific\ntransformations that are largely content-invariant. We believe these results\nshow that models such as GAEs may provide the basis for more encompassing music\nanalysis systems, by endowing them with a better understanding of the\nstructures underlying music.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 15:04:37 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Lattner", "Stefan", ""], ["Grachten", "Maarten", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1708.05344", "submitter": "Andrew Brock", "authors": "Andrew Brock, Theodore Lim, J.M. Ritchie, Nick Weston", "title": "SMASH: One-Shot Model Architecture Search through HyperNetworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing architectures for deep neural networks requires expert knowledge\nand substantial computation time. We propose a technique to accelerate\narchitecture selection by learning an auxiliary HyperNet that generates the\nweights of a main model conditioned on that model's architecture. By comparing\nthe relative validation performance of networks with HyperNet-generated\nweights, we can effectively search over a wide range of architectures at the\ncost of a single training run. To facilitate this search, we develop a flexible\nmechanism based on memory read-writes that allows us to define a wide range of\nnetwork connectivity patterns, with ResNet, DenseNet, and FractalNet blocks as\nspecial cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100,\nSTL-10, ModelNet10, and Imagenet32x32, achieving competitive performance with\nsimilarly-sized hand-designed networks. Our code is available at\nhttps://github.com/ajbrock/SMASH\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 16:03:33 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Brock", "Andrew", ""], ["Lim", "Theodore", ""], ["Ritchie", "J. M.", ""], ["Weston", "Nick", ""]]}, {"id": "1708.05349", "submitter": "Aayush Bansal", "authors": "Aayush Bansal and Yaser Sheikh and Deva Ramanan", "title": "PixelNN: Example-based Image Synthesis", "comments": "Project Page: http://www.cs.cmu.edu/~aayushb/pixelNN/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple nearest-neighbor (NN) approach that synthesizes\nhigh-frequency photorealistic images from an \"incomplete\" signal such as a\nlow-resolution image, a surface normal map, or edges. Current state-of-the-art\ndeep generative models designed for such conditional image synthesis lack two\nimportant things: (1) they are unable to generate a large set of diverse\noutputs, due to the mode collapse problem. (2) they are not interpretable,\nmaking it difficult to control the synthesized output. We demonstrate that NN\napproaches potentially address such limitations, but suffer in accuracy on\nsmall datasets. We design a simple pipeline that combines the best of both\nworlds: the first stage uses a convolutional neural network (CNN) to maps the\ninput to a (overly-smoothed) image, and the second stage uses a pixel-wise\nnearest neighbor method to map the smoothed output to multiple high-quality,\nhigh-frequency outputs in a controllable manner. We demonstrate our approach\nfor various input modalities, and for various domains ranging from human faces\nto cats-and-dogs to shoes and handbags.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 16:13:42 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Bansal", "Aayush", ""], ["Sheikh", "Yaser", ""], ["Ramanan", "Deva", ""]]}, {"id": "1708.05356", "submitter": "Anup Das", "authors": "Anup Das, Paruthi Pradhapan, Willemijn Groenendaal, Prathyusha\n  Adiraju, Raj Thilak Rajan, Francky Catthoor, Siebren Schaafsma, Jeffrey L.\n  Krichmar, Nikil Dutt and Chris Van Hoof", "title": "Unsupervised Heart-rate Estimation in Wearables With Liquid States and A\n  Probabilistic Readout", "comments": "51 pages, 12 figures, 6 tables, 95 references. Under submission at\n  Elsevier Neural Networks", "journal-ref": null, "doi": "10.1016/j.neunet.2017.12.015", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart-rate estimation is a fundamental feature of modern wearable devices. In\nthis paper we propose a machine intelligent approach for heart-rate estimation\nfrom electrocardiogram (ECG) data collected using wearable devices. The novelty\nof our approach lies in (1) encoding spatio-temporal properties of ECG signals\ndirectly into spike train and using this to excite recurrently connected\nspiking neurons in a Liquid State Machine computation model; (2) a novel\nlearning algorithm; and (3) an intelligently designed unsupervised readout\nbased on Fuzzy c-Means clustering of spike responses from a subset of neurons\n(Liquid states), selected using particle swarm optimization. Our approach\ndiffers from existing works by learning directly from ECG signals (allowing\npersonalization), without requiring costly data annotations. Additionally, our\napproach can be easily implemented on state-of-the-art spiking-based\nneuromorphic systems, offering high accuracy, yet significantly low energy\nfootprint, leading to an extended battery life of wearable devices. We\nvalidated our approach with CARLsim, a GPU accelerated spiking neural network\nsimulator modeling Izhikevich spiking neurons with Spike Timing Dependent\nPlasticity (STDP) and homeostatic scaling. A range of subjects are considered\nfrom in-house clinical trials and public ECG databases. Results show high\naccuracy and low energy footprint in heart-rate estimation across subjects with\nand without cardiac irregularities, signifying the strong potential of this\napproach to be integrated in future wearable devices.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 13:53:55 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Das", "Anup", ""], ["Pradhapan", "Paruthi", ""], ["Groenendaal", "Willemijn", ""], ["Adiraju", "Prathyusha", ""], ["Rajan", "Raj Thilak", ""], ["Catthoor", "Francky", ""], ["Schaafsma", "Siebren", ""], ["Krichmar", "Jeffrey L.", ""], ["Dutt", "Nikil", ""], ["Van Hoof", "Chris", ""]]}, {"id": "1708.05357", "submitter": "Celestine D\\\"unner", "authors": "Celestine D\\\"unner, Thomas Parnell, Martin Jaggi", "title": "Efficient Use of Limited-Memory Accelerators for Linear Learning on\n  Heterogeneous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a generic algorithmic building block to accelerate training of\nmachine learning models on heterogeneous compute systems. Our scheme allows to\nefficiently employ compute accelerators such as GPUs and FPGAs for the training\nof large-scale machine learning models, when the training data exceeds their\nmemory capacity. Also, it provides adaptivity to any system's memory hierarchy\nin terms of size and processing speed. Our technique is built upon novel\ntheoretical insights regarding primal-dual coordinate methods, and uses duality\ngap information to dynamically decide which part of the data should be made\navailable for fast processing. To illustrate the power of our approach we\ndemonstrate its performance for training of generalized linear models on a\nlarge-scale dataset exceeding the memory size of a modern GPU, showing an\norder-of-magnitude speedup over existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 16:33:20 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 10:47:36 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["D\u00fcnner", "Celestine", ""], ["Parnell", "Thomas", ""], ["Jaggi", "Martin", ""]]}, {"id": "1708.05446", "submitter": "Feiyun Zhu", "authors": "Feiyun Zhu, Xinliang Zhu, Sheng Wang, Jiawen Yao, Junzhou Huang", "title": "Robust Contextual Bandit via the Capped-$\\ell_{2}$ norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the actor-critic contextual bandit for the mobile health\n(mHealth) intervention. The state-of-the-art decision-making methods in mHealth\ngenerally assume that the noise in the dynamic system follows the Gaussian\ndistribution. Those methods use the least-square-based algorithm to estimate\nthe expected reward, which is prone to the existence of outliers. To deal with\nthe issue of outliers, we propose a novel robust actor-critic contextual bandit\nmethod for the mHealth intervention. In the critic updating, the\ncapped-$\\ell_{2}$ norm is used to measure the approximation error, which\nprevents outliers from dominating our objective. A set of weights could be\nachieved from the critic updating. Considering them gives a weighted objective\nfor the actor updating. It provides the badly noised sample in the critic\nupdating with zero weights for the actor updating. As a result, the robustness\nof both actor-critic updating is enhanced. There is a key parameter in the\ncapped-$\\ell_{2}$ norm. We provide a reliable method to properly set it by\nmaking use of one of the most fundamental definitions of outliers in\nstatistics. Extensive experiment results demonstrate that our method can\nachieve almost identical results compared with the state-of-the-art methods on\nthe dataset without outliers and dramatically outperform them on the datasets\nnoised by outliers.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 21:44:36 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Zhu", "Feiyun", ""], ["Zhu", "Xinliang", ""], ["Wang", "Sheng", ""], ["Yao", "Jiawen", ""], ["Huang", "Junzhou", ""]]}, {"id": "1708.05512", "submitter": "Sanping Zhou", "authors": "Sanping Zhou, Jinjun Wang, Rui Shi, Qiqi Hou, Yihong Gong, Nanning\n  Zheng", "title": "Large Margin Learning in Set to Set Similarity Comparison for Person\n  Re-identification", "comments": "Accepted by IEEE Transactions on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (Re-ID) aims at matching images of the same person\nacross disjoint camera views, which is a challenging problem in multimedia\nanalysis, multimedia editing and content-based media retrieval communities. The\nmajor challenge lies in how to preserve similarity of the same person across\nvideo footages with large appearance variations, while discriminating different\nindividuals. To address this problem, conventional methods usually consider the\npairwise similarity between persons by only measuring the point to point (P2P)\ndistance. In this paper, we propose to use deep learning technique to model a\nnovel set to set (S2S) distance, in which the underline objective focuses on\npreserving the compactness of intra-class samples for each camera view, while\nmaximizing the margin between the intra-class set and inter-class set. The S2S\ndistance metric is consisted of three terms, namely the class-identity term,\nthe relative distance term and the regularization term. The class-identity term\nkeeps the intra-class samples within each camera view gathering together, the\nrelative distance term maximizes the distance between the intra-class class set\nand inter-class set across different camera views, and the regularization term\nsmoothness the parameters of deep convolutional neural network (CNN). As a\nresult, the final learned deep model can effectively find out the matched\ntarget to the probe object among various candidates in the video gallery by\nlearning discriminative and stable feature representations. Using the CUHK01,\nCUHK03, PRID2011 and Market1501 benchmark datasets, we extensively conducted\ncomparative evaluations to demonstrate the advantages of our method over the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 05:19:01 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Zhou", "Sanping", ""], ["Wang", "Jinjun", ""], ["Shi", "Rui", ""], ["Hou", "Qiqi", ""], ["Gong", "Yihong", ""], ["Zheng", "Nanning", ""]]}, {"id": "1708.05552", "submitter": "Zhao Zhong", "authors": "Zhao Zhong, Junjie Yan, Wei Wu, Jing Shao, Cheng-Lin Liu", "title": "Practical Block-wise Neural Network Architecture Generation", "comments": "Accepted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have gained a remarkable success in computer\nvision. However, most usable network architectures are hand-crafted and usually\nrequire expertise and elaborate design. In this paper, we provide a block-wise\nnetwork generation pipeline called BlockQNN which automatically builds\nhigh-performance networks using the Q-Learning paradigm with epsilon-greedy\nexploration strategy. The optimal network block is constructed by the learning\nagent which is trained sequentially to choose component layers. We stack the\nblock to construct the whole auto-generated network. To accelerate the\ngeneration process, we also propose a distributed asynchronous framework and an\nearly stop strategy. The block-wise generation brings unique advantages: (1) it\nperforms competitive results in comparison to the hand-crafted state-of-the-art\nnetworks on image classification, additionally, the best network generated by\nBlockQNN achieves 3.54% top-1 error rate on CIFAR-10 which beats all existing\nauto-generate networks. (2) in the meanwhile, it offers tremendous reduction of\nthe search space in designing networks which only spends 3 days with 32 GPUs,\nand (3) moreover, it has strong generalizability that the network built on\nCIFAR also performs well on a larger-scale ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 10:12:43 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 04:28:33 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 15:18:35 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhong", "Zhao", ""], ["Yan", "Junjie", ""], ["Wu", "Wei", ""], ["Shao", "Jing", ""], ["Liu", "Cheng-Lin", ""]]}, {"id": "1708.05563", "submitter": "Pedro Almagro-Blanco", "authors": "Pedro Almagro-Blanco, Fernando Sancho-Caparrini", "title": "Induction of Decision Trees based on Generalized Graph Queries", "comments": "Multi-lingual Paper. Main language: English. Additional Language:\n  Spanish. 7 Figures. Engish: 16 pages. Spanish: 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually, decision tree induction algorithms are limited to work with non\nrelational data. Given a record, they do not take into account other objects\nattributes even though they can provide valuable information for the learning\ntask. In this paper we present GGQ-ID3, a multi-relational decision tree\nlearning algorithm that uses Generalized Graph Queries (GGQ) as predicates in\nthe decision nodes. GGQs allow to express complex patterns (including cycles)\nand they can be refined step-by-step. Also, they can evaluate structures (not\nonly single records) and perform Regular Pattern Matching. GGQ are built\ndynamically (pattern mining) during the GGQ-ID3 tree construction process. We\nwill show how to use GGQ-ID3 to perform multi-relational machine learning\nkeeping complexity under control. Finally, some real examples of automatically\nobtained classification trees and semantic patterns are shown.\n  -----\n  Normalmente, los algoritmos de inducci\\'on de \\'arboles de decisi\\'on\ntrabajan con datos no relacionales. Dado un registro, no tienen en cuenta los\natributos de otros objetos a pesar de que \\'estos pueden proporcionar\ninformaci\\'on \\'util para la tarea de aprendizaje. En este art\\'iculo\npresentamos GGQ-ID3, un algoritmo de aprendizaje de \\'arboles de decisiones\nmulti-relacional que utiliza Generalized Graph Queries (GGQ) como predicados en\nlos nodos de decisi\\'on. Los GGQs permiten expresar patrones complejos\n(incluyendo ciclos) y pueden ser refinados paso a paso. Adem\\'as, pueden\nevaluar estructuras (no solo registros) y llevar a cabo Regular Pattern\nMatching. En GGQ-ID3, los GGQ son construidos din\\'amicamente (pattern mining)\ndurante el proceso de construcci\\'on del \\'arbol. Adem\\'as, se muestran algunos\nejemplos reales de \\'arboles de clasificaci\\'on multi-relacionales y patrones\nsem\\'anticos obtenidos autom\\'aticamente.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 11:19:01 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Almagro-Blanco", "Pedro", ""], ["Sancho-Caparrini", "Fernando", ""]]}, {"id": "1708.05565", "submitter": "Yu Wang", "authors": "Yu Wang, Jiayi Liu, Yuxiang Liu, Jun Hao, Yang He, Jinghe Hu, Weipeng\n  P. Yan, Mantian Li", "title": "LADDER: A Human-Level Bidding Agent for Large-Scale Real-Time Online\n  Auctions", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LADDER, the first deep reinforcement learning agent that can\nsuccessfully learn control policies for large-scale real-world problems\ndirectly from raw inputs composed of high-level semantic information. The agent\nis based on an asynchronous stochastic variant of DQN (Deep Q Network) named\nDASQN. The inputs of the agent are plain-text descriptions of states of a game\nof incomplete information, i.e. real-time large scale online auctions, and the\nrewards are auction profits of very large scale. We apply the agent to an\nessential portion of JD's online RTB (real-time bidding) advertising business\nand find that it easily beats the former state-of-the-art bidding policy that\nhad been carefully engineered and calibrated by human experts: during JD.com's\nJune 18th anniversary sale, the agent increased the company's ads revenue from\nthe portion by more than 50%, while the advertisers' ROI (return on investment)\nalso improved significantly.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 11:25:30 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 14:05:09 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Wang", "Yu", ""], ["Liu", "Jiayi", ""], ["Liu", "Yuxiang", ""], ["Hao", "Jun", ""], ["He", "Yang", ""], ["Hu", "Jinghe", ""], ["Yan", "Weipeng P.", ""], ["Li", "Mantian", ""]]}, {"id": "1708.05594", "submitter": "Tu Dinh Nguyen", "authors": "Tu Dinh Nguyen, Truyen Tran, Dinh Phung, Svetha Venkatesh", "title": "Statistical Latent Space Approach for Mixed Data Modelling and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of mixed data has been raising challenges in statistics and\nmachine learning. One of two most prominent challenges is to develop new\nstatistical techniques and methodologies to effectively handle mixed data by\nmaking the data less heterogeneous with minimum loss of information. The other\nchallenge is that such methods must be able to apply in large-scale tasks when\ndealing with huge amount of mixed data. To tackle these challenges, we\nintroduce parameter sharing and balancing extensions to our recent model, the\nmixed-variate restricted Boltzmann machine (MV.RBM) which can transform\nheterogeneous data into homogeneous representation. We also integrate\nstructured sparsity and distance metric learning into RBM-based models. Our\nproposed methods are applied in various applications including latent patient\nprofile modelling in medical data analysis and representation learning for\nimage retrieval. The experimental results demonstrate the models perform better\nthan baseline methods in medical data and outperform state-of-the-art rivals in\nimage dataset.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 13:17:57 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Nguyen", "Tu Dinh", ""], ["Tran", "Truyen", ""], ["Phung", "Dinh", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1708.05603", "submitter": "Tu Dinh Nguyen", "authors": "Tu Dinh Nguyen, Truyen Tran, Dinh Phung, Svetha Venkatesh", "title": "Nonnegative Restricted Boltzmann Machines for Parts-based\n  Representations Discovery and Predictive Model Stabilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of any machine learning system depends critically on effective\nrepresentations of data. In many cases, it is desirable that a representation\nscheme uncovers the parts-based, additive nature of the data. Of current\nrepresentation learning schemes, restricted Boltzmann machines (RBMs) have\nproved to be highly effective in unsupervised settings. However, when it comes\nto parts-based discovery, RBMs do not usually produce satisfactory results. We\nenhance such capacity of RBMs by introducing nonnegativity into the model\nweights, resulting in a variant called nonnegative restricted Boltzmann machine\n(NRBM). The NRBM produces not only controllable decomposition of data into\ninterpretable parts but also offers a way to estimate the intrinsic nonlinear\ndimensionality of data, and helps to stabilize linear predictive models. We\ndemonstrate the capacity of our model on applications such as handwritten digit\nrecognition, face recognition, document classification and patient readmission\nprognosis. The decomposition quality on images is comparable with or better\nthan what produced by the nonnegative matrix factorization (NMF), and the\nthematic features uncovered from text are qualitatively interpretable in a\nsimilar manner to that of the latent Dirichlet allocation (LDA). The stability\nperformance of feature selection on medical data is better than RBM and\ncompetitive with NMF. The learned features, when used for classification, are\nmore discriminative than those discovered by both NMF and LDA and comparable\nwith those by RBM.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 13:34:18 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Nguyen", "Tu Dinh", ""], ["Tran", "Truyen", ""], ["Phung", "Dinh", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1708.05604", "submitter": "Viacheslav Khomenko", "authors": "Viacheslav Khomenko (1), Oleg Shyshkov (1), Olga Radyvonenko (1),\n  Kostiantyn Bokhan (1) ((1) Samsung R&D Institute Ukraine SRK)", "title": "Accelerating recurrent neural network training using sequence bucketing\n  and multi-GPU data parallelization", "comments": "4 pages, 5 figures, Comments, 2016 IEEE First International\n  Conference on Data Stream Mining & Processing (DSMP), Lviv, 2016", "journal-ref": "IEEE DSMP Lviv (2016) 100-103", "doi": "10.1109/DSMP.2016.7583516", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient algorithm for recurrent neural network training is presented.\nThe approach increases the training speed for tasks where a length of the input\nsequence may vary significantly. The proposed approach is based on the optimal\nbatch bucketing by input sequence length and data parallelization on multiple\ngraphical processing units. The baseline training performance without sequence\nbucketing is compared with the proposed solution for a different number of\nbuckets. An example is given for the online handwriting recognition task using\nan LSTM recurrent neural network. The evaluation is performed in terms of the\nwall clock time, number of epochs, and validation loss value.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 13:36:30 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Khomenko", "Viacheslav", "", "Samsung R&D Institute Ukraine SRK"], ["Shyshkov", "Oleg", "", "Samsung R&D Institute Ukraine SRK"], ["Radyvonenko", "Olga", "", "Samsung R&D Institute Ukraine SRK"], ["Bokhan", "Kostiantyn", "", "Samsung R&D Institute Ukraine SRK"]]}, {"id": "1708.05629", "submitter": "Ying Wei", "authors": "Ying Wei, Yu Zhang, Qiang Yang", "title": "Learning to Transfer", "comments": "12 pages, 8 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning borrows knowledge from a source domain to facilitate\nlearning in a target domain. Two primary issues to be addressed in transfer\nlearning are what and how to transfer. For a pair of domains, adopting\ndifferent transfer learning algorithms results in different knowledge\ntransferred between them. To discover the optimal transfer learning algorithm\nthat maximally improves the learning performance in the target domain,\nresearchers have to exhaustively explore all existing transfer learning\nalgorithms, which is computationally intractable. As a trade-off, a sub-optimal\nalgorithm is selected, which requires considerable expertise in an ad-hoc way.\nMeanwhile, it is widely accepted in educational psychology that human beings\nimprove transfer learning skills of deciding what to transfer through\nmeta-cognitive reflection on inductive transfer learning practices. Motivated\nby this, we propose a novel transfer learning framework known as Learning to\nTransfer (L2T) to automatically determine what and how to transfer are the best\nby leveraging previous transfer learning experiences. We establish the L2T\nframework in two stages: 1) we first learn a reflection function encrypting\ntransfer learning skills from experiences; and 2) we infer what and how to\ntransfer for a newly arrived pair of domains by optimizing the reflection\nfunction. Extensive experiments demonstrate the L2T's superiority over several\nstate-of-the-art transfer learning algorithms and its effectiveness on\ndiscovering more transferable knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 14:36:29 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Wei", "Ying", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1708.05655", "submitter": "Cem Tekin", "authors": "Cem Tekin and Eralp Turgay", "title": "Multi-objective Contextual Multi-armed Bandit with a Dominant Objective", "comments": "To appear in IEEE Transactions on Signal Processing, link:\n  https://ieeexplore.ieee.org/document/8368272/", "journal-ref": null, "doi": "10.1109/TSP.2018.2841822", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new multi-objective contextual multi-armed bandit\n(MAB) problem with two objectives, where one of the objectives dominates the\nother objective. Unlike single-objective MAB problems in which the learner\nobtains a random scalar reward for each arm it selects, in the proposed\nproblem, the learner obtains a random reward vector, where each component of\nthe reward vector corresponds to one of the objectives and the distribution of\nthe reward depends on the context that is provided to the learner at the\nbeginning of each round. We call this problem contextual multi-armed bandit\nwith a dominant objective (CMAB-DO). In CMAB-DO, the goal of the learner is to\nmaximize its total reward in the non-dominant objective while ensuring that it\nmaximizes its total reward in the dominant objective. In this case, the optimal\narm given a context is the one that maximizes the expected reward in the\nnon-dominant objective among all arms that maximize the expected reward in the\ndominant objective. First, we show that the optimal arm lies in the Pareto\nfront. Then, we propose the multi-objective contextual multi-armed bandit\nalgorithm (MOC-MAB), and define two performance measures: the 2-dimensional\n(2D) regret and the Pareto regret. We show that both the 2D regret and the\nPareto regret of MOC-MAB are sublinear in the number of rounds. We also compare\nthe performance of the proposed algorithm with other state-of-the-art methods\nin synthetic and real-world datasets. The proposed model and the algorithm have\na wide range of real-world applications that involve multiple and possibly\nconflicting objectives ranging from wireless communication to medical diagnosis\nand recommender systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 15:41:58 GMT"}, {"version": "v2", "created": "Sun, 11 Mar 2018 18:29:43 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 17:29:37 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Tekin", "Cem", ""], ["Turgay", "Eralp", ""]]}, {"id": "1708.05768", "submitter": "Gal Mishne", "authors": "Gal Mishne, Ronen Talmon, Israel Cohen, Ronald R. Coifman and Yuval\n  Kluger", "title": "Data-Driven Tree Transforms and Metrics", "comments": "16 pages, 5 figures. Accepted to IEEE Transactions on Signal and\n  Information Processing over Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the analysis of high dimensional data given in the form of a\nmatrix with columns consisting of observations and rows consisting of features.\nOften the data is such that the observations do not reside on a regular grid,\nand the given order of the features is arbitrary and does not convey a notion\nof locality. Therefore, traditional transforms and metrics cannot be used for\ndata organization and analysis. In this paper, our goal is to organize the data\nby defining an appropriate representation and metric such that they respect the\nsmoothness and structure underlying the data. We also aim to generalize the\njoint clustering of observations and features in the case the data does not\nfall into clear disjoint groups. For this purpose, we propose multiscale\ndata-driven transforms and metrics based on trees. Their construction is\nimplemented in an iterative refinement procedure that exploits the\nco-dependencies between features and observations. Beyond the organization of a\nsingle dataset, our approach enables us to transfer the organization learned\nfrom one dataset to another and to integrate several datasets together. We\npresent an application to breast cancer gene expression analysis: learning\nmetrics on the genes to cluster the tumor samples into cancer sub-types and\nvalidating the joint organization of both the genes and the samples. We\ndemonstrate that using our approach to combine information from multiple gene\nexpression cohorts, acquired by different profiling technologies, improves the\nclustering of tumor samples.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 21:32:34 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Mishne", "Gal", ""], ["Talmon", "Ronen", ""], ["Cohen", "Israel", ""], ["Coifman", "Ronald R.", ""], ["Kluger", "Yuval", ""]]}, {"id": "1708.05789", "submitter": "Kumar Sricharan", "authors": "Kumar Sricharan, Raja Bala, Matthew Shreve, Hui Ding, Kumar Saketh,\n  Jin Sun", "title": "Semi-supervised Conditional GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model for building conditional generative models in a\nsemi-supervised setting to conditionally generate data given attributes by\nadapting the GAN framework. The proposed semi-supervised GAN (SS-GAN) model\nuses a pair of stacked discriminators to learn the marginal distribution of the\ndata, and the conditional distribution of the attributes given the data\nrespectively. In the semi-supervised setting, the marginal distribution (which\nis often harder to learn) is learned from the labeled + unlabeled data, and the\nconditional distribution is learned purely from the labeled data. Our\nexperimental results demonstrate that this model performs significantly better\ncompared to existing semi-supervised conditional GAN models.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 01:05:02 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Sricharan", "Kumar", ""], ["Bala", "Raja", ""], ["Shreve", "Matthew", ""], ["Ding", "Hui", ""], ["Saketh", "Kumar", ""], ["Sun", "Jin", ""]]}, {"id": "1708.05821", "submitter": "Oliver Obst", "authors": "Olivia Michael and Oliver Obst and Falk Schmidsberger and Frieder\n  Stolzenburg", "title": "Analysing Soccer Games with Clustering and Conceptors", "comments": "To appear in RoboCup 2017: Robot World Cup XXI; Springer, 2018", "journal-ref": "In Hidehisa Akyama, Oliver Obst, Claude Sammut, and Flavio\n  Tonidandel, editors, RoboCup 2017: Robot Soccer World Cup XXI. RoboCup\n  International Symposium, LNAI 11175, pp. 120-131, Nagoya, Japan, 2018.\n  Springer Nature Switzerland", "doi": "10.1007/978-3-030-00308-1_10", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for identifying situations and behaviours, which we\ncall \"moves\", from soccer games in the 2D simulation league. Being able to\nidentify key situations and behaviours are useful capabilities for analysing\nsoccer matches, anticipating opponent behaviours to aid selection of\nappropriate tactics, and also as a prerequisite for automatic learning of\nbehaviours and policies. To support a wide set of strategies, our goal is to\nidentify situations from data, in an unsupervised way without making use of\npre-defined soccer specific concepts such as \"pass\" or \"dribble\". The recurrent\nneural networks we use in our approach act as a high-dimensional projection of\nthe recent history of a situation on the field. Similar situations, i.e., with\nsimilar histories, are found by clustering of network states. The same networks\nare also used to learn so-called conceptors, that are lower-dimensional\nmanifolds that describe trajectories through a high-dimensional state space\nthat enable situation-specific predictions from the same neural network. With\nthe proposed approach, we can segment games into sequences of situations that\nare learnt in an unsupervised way, and learn conceptors that are useful for the\nprediction of the near future of the respective situation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 07:58:06 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Michael", "Olivia", ""], ["Obst", "Oliver", ""], ["Schmidsberger", "Falk", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "1708.05840", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Santanu Chaudhury and Dr. Jayadeva", "title": "A Data and Model-Parallel, Distributed and Scalable Framework for\n  Training of Deep Networks in Apache Spark", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep networks is expensive and time-consuming with the training\nperiod increasing with data size and growth in model parameters. In this paper,\nwe provide a framework for distributed training of deep networks over a cluster\nof CPUs in Apache Spark. The framework implements both Data Parallelism and\nModel Parallelism making it suitable to use for deep networks which require\nhuge training data and model parameters which are too big to fit into the\nmemory of a single machine. It can be scaled easily over a cluster of cheap\ncommodity hardware to attain significant speedup and obtain better results\nmaking it quite economical as compared to farm of GPUs and supercomputers. We\nhave proposed a new algorithm for training of deep networks for the case when\nthe network is partitioned across the machines (Model Parallelism) along with\ndetailed cost analysis and proof of convergence of the same. We have developed\nimplementations for Fully-Connected Feedforward Networks, Convolutional Neural\nNetworks, Recurrent Neural Networks and Long Short-Term Memory architectures.\nWe present the results of extensive simulations demonstrating the speedup and\naccuracy obtained by our framework for different sizes of the data and model\nparameters with variation in the number of worker cores/partitions; thereby\nshowing that our proposed framework can achieve significant speedup (upto 11X\nfor CNN) and is also quite scalable.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 13:17:58 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Shrivastava", "Disha", ""], ["Chaudhury", "Santanu", ""], ["Jayadeva", "Dr.", ""]]}, {"id": "1708.05866", "submitter": "Kai Arulkumaran", "authors": "Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, Anil Anthony\n  Bharath", "title": "A Brief Survey of Deep Reinforcement Learning", "comments": "IEEE Signal Processing Magazine, Special Issue on Deep Learning for\n  Image Understanding (arXiv extended version)", "journal-ref": null, "doi": "10.1109/MSP.2017.2743240", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is poised to revolutionise the field of AI and\nrepresents a step towards building autonomous systems with a higher level\nunderstanding of the visual world. Currently, deep learning is enabling\nreinforcement learning to scale to problems that were previously intractable,\nsuch as learning to play video games directly from pixels. Deep reinforcement\nlearning algorithms are also applied to robotics, allowing control policies for\nrobots to be learned directly from camera inputs in the real world. In this\nsurvey, we begin with an introduction to the general field of reinforcement\nlearning, then progress to the main streams of value-based and policy-based\nmethods. Our survey will cover central algorithms in deep reinforcement\nlearning, including the deep $Q$-network, trust region policy optimisation, and\nasynchronous advantage actor-critic. In parallel, we highlight the unique\nadvantages of deep neural networks, focusing on visual understanding via\nreinforcement learning. To conclude, we describe several current areas of\nresearch within the field.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 15:55:31 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 21:51:43 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Arulkumaran", "Kai", ""], ["Deisenroth", "Marc Peter", ""], ["Brundage", "Miles", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1708.05907", "submitter": "Niklas Dahringer", "authors": "Niklas Dahringer", "title": "Electricity Theft Detection using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-technical losses (NTL) in electric power grids arise through electricity\ntheft, broken electric meters or billing errors. They can harm the power\nsupplier as well as the whole economy of a country through losses of up to 40%\nof the total power distribution. For NTL detection, researchers use artificial\nintelligence to analyse data. This work is about improving the extraction of\nmore meaningful features from a data set. With these features, the prediction\nquality will increase.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 22:39:24 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Dahringer", "Niklas", ""]]}, {"id": "1708.05917", "submitter": "Peter Mills", "authors": "Peter Mills", "title": "Accelerating Kernel Classifiers Through Borders Mapping", "comments": "37 pages; 8 figures; 7 tables. List of symbols included. Corrections:\n  parameters table was from the previous revision; volume and page numbers\n  added", "journal-ref": "Journal of Real-Time Image Processing 17, 313-327(2020)", "doi": "10.1007/s11554-018-0769-9", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machines (SVM) and other kernel techniques represent a family\nof powerful statistical classification methods with high accuracy and broad\napplicability. Because they use all or a significant portion of the training\ndata, however, they can be slow, especially for large problems. Piecewise\nlinear classifiers are similarly versatile, yet have the additional advantages\nof simplicity, ease of interpretation and, if the number of component linear\nclassifiers is not too large, speed. Here we show how a simple, piecewise\nlinear classifier can be trained from a kernel-based classifier in order to\nimprove the classification speed. The method works by finding the root of the\ndifference in conditional probabilities between pairs of opposite classes to\nbuild up a representation of the decision boundary. When tested on 17 different\ndatasets, it succeeded in improving the classification speed of a SVM for 12 of\nthem by up to two orders-of-magnitude. Of these, two were less accurate than a\nsimple, linear classifier. The method is best suited to problems with continuum\nfeatures data and smooth probability functions. Because the component linear\nclassifiers are built up individually from an existing classifier, rather than\nthrough a simultaneous optimization procedure, the classifier is also fast to\ntrain.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 00:24:17 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 15:42:49 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 18:12:59 GMT"}, {"version": "v4", "created": "Thu, 31 Oct 2019 02:22:16 GMT"}, {"version": "v5", "created": "Mon, 5 Apr 2021 02:24:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Mills", "Peter", ""]]}, {"id": "1708.05924", "submitter": "Afshin Oroojlooy", "authors": "Afshin Oroojlooyjadid, MohammadReza Nazari, Lawrence Snyder, Martin\n  Tak\\'a\\v{c}", "title": "A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning\n  algorithm to Solve Inventory Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beer game is a widely used in-class game that is played in supply chain\nmanagement classes to demonstrate the bullwhip effect. The game is a\ndecentralized, multi-agent, cooperative problem that can be modeled as a serial\nsupply chain network in which agents cooperatively attempt to minimize the\ntotal cost of the network even though each agent can only observe its own local\ninformation. Each agent chooses order quantities to replenish its stock. Under\nsome conditions, a base-stock replenishment policy is known to be optimal.\nHowever, in a decentralized supply chain in which some agents (stages) may act\nirrationally (as they do in the beer game), there is no known optimal policy\nfor an agent wishing to act optimally.\n  We propose a machine learning algorithm, based on deep Q-networks, to\noptimize the replenishment decisions at a given stage. When playing alongside\nagents who follow a base-stock policy, our algorithm obtains near-optimal order\nquantities. It performs much better than a base-stock policy when the other\nagents use a more realistic model of human ordering behavior. Unlike most other\nalgorithms in the literature, our algorithm does not have any limits on the\nbeer game parameter values. Like any deep learning algorithm, training the\nalgorithm can be computationally intensive, but this can be performed ahead of\ntime; the algorithm executes in real time when the game is played. Moreover, we\npropose a transfer learning approach so that the training performed for one\nagent and one set of cost coefficients can be adapted quickly for other agents\nand costs. Our algorithm can be extended to other decentralized multi-agent\ncooperative games with partially observed information, which is a common type\nof situation in real-world supply chain problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 03:06:23 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 15:09:56 GMT"}, {"version": "v3", "created": "Thu, 7 Feb 2019 01:50:12 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 02:44:29 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Oroojlooyjadid", "Afshin", ""], ["Nazari", "MohammadReza", ""], ["Snyder", "Lawrence", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1708.05929", "submitter": "Leman Akoglu", "authors": "Meghanath Macha and Leman Akoglu", "title": "Explaining Anomalies in Groups with Characterizing Subspace Rules", "comments": "31 pages, 6 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection has numerous applications and has been studied vastly. We\nconsider a complementary problem that has a much sparser literature: anomaly\ndescription. Interpretation of anomalies is crucial for practitioners for\nsense-making, troubleshooting, and planning actions. To this end, we present a\nnew approach called x-PACS (for eXplaining Patterns of Anomalies with\nCharacterizing Subspaces), which \"reverse-engineers\" the known anomalies by\nidentifying (1) the groups (or patterns) that they form, and (2) the\ncharacterizing subspace and feature rules that separate each anomalous pattern\nfrom normal instances. Explaining anomalies in groups not only saves analyst\ntime and gives insight into various types of anomalies, but also draws\nattention to potentially critical, repeating anomalies.\n  In developing x-PACS, we first construct a desiderata for the anomaly\ndescription problem. From a descriptive data mining perspective, our method\nexhibits five desired properties in our desiderata. Namely, it can unearth\nanomalous patterns (i) of multiple different types, (ii) hidden in arbitrary\nsubspaces of a high dimensional space, (iii) interpretable by the analysts,\n(iv) different from normal patterns of the data, and finally (v) succinct,\nproviding the shortest data description. Furthermore, x-PACS is highly\nparallelizable and scales linearly in terms of data size.\n  No existing work on anomaly description satisfies all of these properties\nsimultaneously. While not our primary goal, the anomalous patterns we find\nserve as interpretable \"signatures\" and can be used for detection. We show the\neffectiveness of x-PACS in explanation as well as detection on real-world\ndatasets as compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 03:41:32 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 16:24:40 GMT"}, {"version": "v3", "created": "Thu, 16 Nov 2017 15:27:28 GMT"}, {"version": "v4", "created": "Wed, 2 May 2018 21:36:12 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Macha", "Meghanath", ""], ["Akoglu", "Leman", ""]]}, {"id": "1708.05963", "submitter": "Dmitry Ignatov", "authors": "Artem M. Grachev, Dmitry I. Ignatov, Andrey V. Savchenko", "title": "Neural Networks Compression for Language Modeling", "comments": "Keywords: LSTM, RNN, language modeling, low-rank factorization,\n  pruning, quantization. Published by Springer in the LNCS series, 7th\n  International Conference on Pattern Recognition and Machine Intelligence,\n  2017", "journal-ref": null, "doi": "10.1007/978-3-319-69900-4_44", "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider several compression techniques for the language\nmodeling problem based on recurrent neural networks (RNNs). It is known that\nconventional RNNs, e.g, LSTM-based networks in language modeling, are\ncharacterized with either high space complexity or substantial inference time.\nThis problem is especially crucial for mobile applications, in which the\nconstant interaction with the remote server is inappropriate. By using the Penn\nTreebank (PTB) dataset we compare pruning, quantization, low-rank\nfactorization, tensor train decomposition for LSTM networks in terms of model\nsize and suitability for fast inference.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 13:37:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Grachev", "Artem M.", ""], ["Ignatov", "Dmitry I.", ""], ["Savchenko", "Andrey V.", ""]]}, {"id": "1708.05978", "submitter": "Linbo Qiao", "authors": "Tianyi Lin and Linbo Qiao and Teng Zhang and Jiashi Feng and Bofeng\n  Zhang", "title": "Stochastic Primal-Dual Proximal ExtraGradient Descent for Compositely\n  Regularized Optimization", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2017.07.066", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wide range of regularized stochastic minimization problems with\ntwo regularization terms, one of which is composed with a linear function. This\noptimization model abstracts a number of important applications in artificial\nintelligence and machine learning, such as fused Lasso, fused logistic\nregression, and a class of graph-guided regularized minimization. The\ncomputational challenges of this model are in two folds. On one hand, the\nclosed-form solution of the proximal mapping associated with the composed\nregularization term or the expected objective function is not available. On the\nother hand, the calculation of the full gradient of the expectation in the\nobjective is very expensive when the number of input data samples is\nconsiderably large. To address these issues, we propose a stochastic variant of\nextra-gradient type methods, namely \\textsf{Stochastic Primal-Dual Proximal\nExtraGradient descent (SPDPEG)}, and analyze its convergence property for both\nconvex and strongly convex objectives. For general convex objectives, the\nuniformly average iterates generated by \\textsf{SPDPEG} converge in expectation\nwith $O(1/\\sqrt{t})$ rate. While for strongly convex objectives, the uniformly\nand non-uniformly average iterates generated by \\textsf{SPDPEG} converge with\n$O(\\log(t)/t)$ and $O(1/t)$ rates, respectively. The order of the rate of the\nproposed algorithm is known to match the best convergence rate for first-order\nstochastic algorithms. Experiments on fused logistic regression and\ngraph-guided regularized logistic regression problems show that the proposed\nalgorithm performs very efficiently and consistently outperforms other\ncompeting algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 14:53:12 GMT"}, {"version": "v2", "created": "Sun, 27 Aug 2017 17:37:03 GMT"}, {"version": "v3", "created": "Tue, 12 Dec 2017 13:48:30 GMT"}, {"version": "v4", "created": "Thu, 1 Feb 2018 08:00:24 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Lin", "Tianyi", ""], ["Qiao", "Linbo", ""], ["Zhang", "Teng", ""], ["Feng", "Jiashi", ""], ["Zhang", "Bofeng", ""]]}, {"id": "1708.05987", "submitter": "Dan Elbaz", "authors": "Dan Elbaz, Michael Zibulevsky", "title": "Perceptual audio loss function for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PESQ and POLQA , are standards are standards for automated assessment of\nvoice quality of speech as experienced by human beings. The predictions of\nthose objective measures should come as close as possible to subjective quality\nscores as obtained in subjective listening tests. Wavenet is a deep neural\nnetwork originally developed as a deep generative model of raw audio\nwave-forms. Wavenet architecture is based on dilated causal convolutions, which\nexhibit very large receptive fields. In this short paper we suggest using the\nWavenet architecture, in particular its large receptive filed in order to learn\nPESQ algorithm. By doing so we can use it as a differentiable loss function for\nspeech enhancement.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 16:18:20 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Elbaz", "Dan", ""], ["Zibulevsky", "Michael", ""]]}, {"id": "1708.06019", "submitter": "Gerald Friedland", "authors": "Gerald Friedland and Mario Krell", "title": "A Capacity Scaling Law for Artificial Neural Networks", "comments": "13 pages, 4 figures, 2 listings of source code", "journal-ref": null, "doi": null, "report-no": "LLNL-TR-736950", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the calculation of two critical numbers predicting the behavior of\nperceptron networks. First, we derive the calculation of what we call the\nlossless memory (LM) dimension. The LM dimension is a generalization of the\nVapnik--Chervonenkis (VC) dimension that avoids structured data and therefore\nprovides an upper bound for perfectly fitting almost any training data. Second,\nwe derive what we call the MacKay (MK) dimension. This limit indicates a 50%\nchance of not being able to train a given function. Our derivations are\nperformed by embedding a neural network into Shannon's communication model\nwhich allows to interpret the two points as capacities measured in bits. We\npresent a proof and practical experiments that validate our upper bounds with\nrepeatable experiments using different network configurations, diverse\nimplementations, varying activation functions, and several learning algorithms.\nThe bottom line is that the two capacity points scale strictly linear with the\nnumber of weights. Among other practical applications, our result allows to\ncompare and benchmark different neural network implementations independent of a\nconcrete learning task. Our results provide insight into the capabilities and\nlimits of neural networks and generate valuable know how for experimental\ndesign decisions.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 21:10:42 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 05:02:07 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 01:30:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Friedland", "Gerald", ""], ["Krell", "Mario", ""]]}, {"id": "1708.06020", "submitter": "Luke Taylor", "authors": "Luke Taylor, Geoff Nitschke", "title": "Improving Deep Learning using Generic Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep artificial neural networks require a large corpus of training data in\norder to effectively learn, where collection of such training data is often\nexpensive and laborious. Data augmentation overcomes this issue by artificially\ninflating the training set with label preserving transformations. Recently\nthere has been extensive use of generic data augmentation to improve\nConvolutional Neural Network (CNN) task performance. This study benchmarks\nvarious popular data augmentation schemes to allow researchers to make informed\ndecisions as to which training methods are most appropriate for their data\nsets. Various geometric and photometric schemes are evaluated on a\ncoarse-grained data set using a relatively simple CNN. Experimental results,\nrun using 4-fold cross-validation and reported in terms of Top-1 and Top-5\naccuracy, indicate that cropping in geometric augmentation significantly\nincreases CNN task performance.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 21:16:59 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Taylor", "Luke", ""], ["Nitschke", "Geoff", ""]]}, {"id": "1708.06040", "submitter": "Tongzhou Wang", "authors": "Tongzhou Wang, Yi Wu, David A. Moore, Stuart J. Russell", "title": "Meta-Learning MCMC Proposals", "comments": "32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective implementations of sampling-based probabilistic inference often\nrequire manually constructed, model-specific proposals. Inspired by recent\nprogresses in meta-learning for training learning agents that can generalize to\nunseen environments, we propose a meta-learning approach to building effective\nand generalizable MCMC proposals. We parametrize the proposal as a neural\nnetwork to provide fast approximations to block Gibbs conditionals. The learned\nneural proposals generalize to occurrences of common structural motifs across\ndifferent models, allowing for the construction of a library of learned\ninference primitives that can accelerate inference on unseen models with no\nmodel-specific training required. We explore several applications including\nopen-universe Gaussian mixture models, in which our learned proposals\noutperform a hand-tuned sampler, and a real-world named entity recognition\ntask, in which our sampler yields higher final F1 scores than classical\nsingle-site Gibbs sampling.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 00:44:32 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 18:47:50 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 04:32:39 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 12:09:11 GMT"}, {"version": "v5", "created": "Tue, 1 Jan 2019 06:47:06 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Wang", "Tongzhou", ""], ["Wu", "Yi", ""], ["Moore", "David A.", ""], ["Russell", "Stuart J.", ""]]}, {"id": "1708.06046", "submitter": "Stefan Maetschke", "authors": "S. Maetschke, R. Tennakoon, C. Vecchiola and R. Garnavi", "title": "nuts-flow/ml: data pre-processing for deep learning", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data preprocessing is a fundamental part of any machine learning application\nand frequently the most time-consuming aspect when developing a machine\nlearning solution. Preprocessing for deep learning is characterized by\npipelines that lazily load data and perform data transformation, augmentation,\nbatching and logging. Many of these functions are common across applications\nbut require different arrangements for training, testing or inference. Here we\nintroduce a novel software framework named nuts-flow/ml that encapsulates\ncommon preprocessing operations as components, which can be flexibly arranged\nto rapidly construct efficient preprocessing pipelines for deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 01:28:37 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 00:46:13 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Maetschke", "S.", ""], ["Tennakoon", "R.", ""], ["Vecchiola", "C.", ""], ["Garnavi", "R.", ""]]}, {"id": "1708.06131", "submitter": "Battista Biggio", "authors": "Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim\n  Srndic, Pavel Laskov, Giorgio Giacinto, Fabio Roli", "title": "Evasion Attacks against Machine Learning at Test Time", "comments": "In this paper, in 2013, we were the first to introduce the notion of\n  evasion attacks (adversarial examples) created with high confidence (instead\n  of minimum-distance misclassifications), and the notion of surrogate learners\n  (substitute models). These two concepts are now widely re-used in developing\n  attacks against deep networks (even if not always referring to the ideas\n  reported in this work). arXiv admin note: text overlap with arXiv:1401.7727", "journal-ref": "ECML PKDD, Part III, vol. 8190, LNCS, pp. 387--402. Springer, 2013", "doi": "10.1007/978-3-642-40994-3_25", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In security-sensitive applications, the success of machine learning depends\non a thorough vetting of their resistance to adversarial data. In one\npertinent, well-motivated attack scenario, an adversary may attempt to evade a\ndeployed system at test time by carefully manipulating attack samples. In this\nwork, we present a simple but effective gradient-based approach that can be\nexploited to systematically assess the security of several, widely-used\nclassification algorithms against evasion attacks. Following a recently\nproposed framework for security evaluation, we simulate attack scenarios that\nexhibit different risk levels for the classifier by increasing the attacker's\nknowledge of the system and her ability to manipulate attack samples. This\ngives the classifier designer a better picture of the classifier performance\nunder evasion attacks, and allows him to perform a more informed model\nselection (or parameter setting). We evaluate our approach on the relevant\nsecurity task of malware detection in PDF files, and show that such systems can\nbe easily evaded. We also sketch some countermeasures suggested by our\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 09:55:37 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Biggio", "Battista", ""], ["Corona", "Igino", ""], ["Maiorca", "Davide", ""], ["Nelson", "Blaine", ""], ["Srndic", "Nedim", ""], ["Laskov", "Pavel", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1708.06243", "submitter": "Ge Wang", "authors": "Fenglei Fan, Wenxiang Cong, Ge Wang", "title": "General Backpropagation Algorithm for Training Second-order Neural\n  Networks", "comments": "5 pages, 7 figures, 19 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial neural network is a popular framework in machine learning. To\nempower individual neurons, we recently suggested that the current type of\nneurons could be upgraded to 2nd order counterparts, in which the linear\noperation between inputs to a neuron and the associated weights is replaced\nwith a nonlinear quadratic operation. A single 2nd order neurons already has a\nstrong nonlinear modeling ability, such as implementing basic fuzzy logic\noperations. In this paper, we develop a general backpropagation (BP) algorithm\nto train the network consisting of 2nd-order neurons. The numerical studies are\nperformed to verify of the generalized BP algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 21:42:22 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Fan", "Fenglei", ""], ["Cong", "Wenxiang", ""], ["Wang", "Ge", ""]]}, {"id": "1708.06257", "submitter": "Zhen Li", "authors": "Zhen Li, Zuoqiang Shi", "title": "A Flow Model of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a natural connection between ResNet and transport equation or its\ncharacteristic equation, we propose a continuous flow model for both ResNet and\nplain net. Through this continuous model, a ResNet can be explicitly\nconstructed as a refinement of a plain net. The flow model provides an\nalternative perspective to understand phenomena in deep neural networks, such\nas why it is necessary and sufficient to use 2-layer blocks in ResNets, why\ndeeper is better, and why ResNets are even deeper, and so on. It also opens a\ngate to bring in more tools from the huge area of differential equations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 14:30:49 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 11:26:00 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Li", "Zhen", ""], ["Shi", "Zuoqiang", ""]]}, {"id": "1708.06347", "submitter": "Colleen Farrelly", "authors": "Colleen M. Farrelly", "title": "Deep vs. Diverse Architectures for Classification Problems", "comments": "Paper done as part of R&D project at Kaplan University, submitted to\n  GCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares various superlearner and deep learning architectures\n(machine-learning-based and neural-network-based) for classification problems\nacross several simulated and industrial datasets to assess performance and\ncomputational efficiency, as both methods have nice theoretical convergence\nproperties. Superlearner formulations outperform other methods at small to\nmoderate sample sizes (500-2500) on nonlinear and mixed linear/nonlinear\npredictor relationship datasets, while deep neural networks perform well on\nlinear predictor relationship datasets of all sizes. This suggests faster\nconvergence of the superlearner compared to deep neural network architectures\non many messy classification problems for real-world data.\n  Superlearners also yield interpretable models, allowing users to examine\nimportant signals in the data; in addition, they offer flexible formulation,\nwhere users can retain good performance with low-computational-cost base\nalgorithms.\n  K-nearest-neighbor (KNN) regression demonstrates improvements using the\nsuperlearner framework, as well; KNN superlearners consistently outperform deep\narchitectures and KNN regression, suggesting that superlearners may be better\nable to capture local and global geometric features through utilizing a variety\nof algorithms to probe the data space.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 15:31:44 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Farrelly", "Colleen M.", ""]]}, {"id": "1708.06376", "submitter": "Vera Rimmer Ms.", "authors": "Vera Rimmer, Davy Preuveneers, Marc Juarez, Tom Van Goethem, Wouter\n  Joosen", "title": "Automated Website Fingerprinting through Deep Learning", "comments": "To appear in the 25th Symposium on Network and Distributed System\n  Security (NDSS 2018)", "journal-ref": null, "doi": "10.14722/ndss.2018.23105", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several studies have shown that the network traffic that is generated by a\nvisit to a website over Tor reveals information specific to the website through\nthe timing and sizes of network packets. By capturing traffic traces between\nusers and their Tor entry guard, a network eavesdropper can leverage this\nmeta-data to reveal which website Tor users are visiting. The success of such\nattacks heavily depends on the particular set of traffic features that are used\nto construct the fingerprint. Typically, these features are manually engineered\nand, as such, any change introduced to the Tor network can render these\ncarefully constructed features ineffective. In this paper, we show that an\nadversary can automate the feature engineering process, and thus automatically\ndeanonymize Tor traffic by applying our novel method based on deep learning. We\ncollect a dataset comprised of more than three million network traces, which is\nthe largest dataset of web traffic ever used for website fingerprinting, and\nfind that the performance achieved by our deep learning approaches is\ncomparable to known methods which include various research efforts spanning\nover multiple years. The obtained success rate exceeds 96% for a closed world\nof 100 websites and 94% for our biggest closed world of 900 classes. In our\nopen world evaluation, the most performant deep learning model is 2% more\naccurate than the state-of-the-art attack. Furthermore, we show that the\nimplicit features automatically learned by our approach are far more resilient\nto dynamic changes of web content over time. We conclude that the ability to\nautomatically construct the most relevant traffic features and perform accurate\ntraffic recognition makes our deep learning based approach an efficient,\nflexible and robust technique for website fingerprinting.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 18:32:08 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 17:35:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Rimmer", "Vera", ""], ["Preuveneers", "Davy", ""], ["Juarez", "Marc", ""], ["Van Goethem", "Tom", ""], ["Joosen", "Wouter", ""]]}, {"id": "1708.06425", "submitter": "Mustafa Kocak", "authors": "Mustafa A. Kocak, David Ramirez, Elza Erkip, and Dennis E. Shasha", "title": "SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to\n  Guarantee Correctness", "comments": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SafePredict is a novel meta-algorithm that works with any base prediction\nalgorithm for online data to guarantee an arbitrarily chosen correctness rate,\n$1-\\epsilon$, by allowing refusals. Allowing refusals means that the\nmeta-algorithm may refuse to emit a prediction produced by the base algorithm\non occasion so that the error rate on non-refused predictions does not exceed\n$\\epsilon$. The SafePredict error bound does not rely on any assumptions on the\ndata distribution or the base predictor. When the base predictor happens not to\nexceed the target error rate $\\epsilon$, SafePredict refuses only a finite\nnumber of times. When the error rate of the base predictor changes through time\nSafePredict makes use of a weight-shifting heuristic that adapts to these\nchanges without knowing when the changes occur yet still maintains the\ncorrectness guarantee. Empirical results show that (i) SafePredict compares\nfavorably with state-of-the art confidence based refusal mechanisms which fail\nto offer robust error guarantees; and (ii) combining SafePredict with such\nrefusal mechanisms can in many cases further reduce the number of refusals. Our\nsoftware (currently in Python) is included in the supplementary material.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 21:23:42 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 03:35:00 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kocak", "Mustafa A.", ""], ["Ramirez", "David", ""], ["Erkip", "Elza", ""], ["Shasha", "Dennis E.", ""]]}, {"id": "1708.06438", "submitter": "Mattia Desana", "authors": "Mattia Desana and Christoph Schn\\\"orr", "title": "Sum-Product Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new probabilistic architecture called Sum-Product\nGraphical Model (SPGM). SPGMs combine traits from Sum-Product Networks (SPNs)\nand Graphical Models (GMs): Like SPNs, SPGMs always enable tractable inference\nusing a class of models that incorporate context specific independence. Like\nGMs, SPGMs provide a high-level model interpretation in terms of conditional\nindependence assumptions and corresponding factorizations. Thus, the new\narchitecture represents a class of probability distributions that combines, for\nthe first time, the semantics of graphical models with the evaluation\nefficiency of SPNs. We also propose a novel algorithm for learning both the\nstructure and the parameters of SPGMs. A comparative empirical evaluation\ndemonstrates competitive performances of our approach in density estimation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 22:23:20 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Desana", "Mattia", ""], ["Schn\u00f6rr", "Christoph", ""]]}, {"id": "1708.06519", "submitter": "Zhuang Liu", "authors": "Zhuang Liu and Jianguo Li and Zhiqiang Shen and Gao Huang and Shoumeng\n  Yan and Changshui Zhang", "title": "Learning Efficient Convolutional Networks through Network Slimming", "comments": "Accepted by ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of deep convolutional neural networks (CNNs) in many real\nworld applications is largely hindered by their high computational cost. In\nthis paper, we propose a novel learning scheme for CNNs to simultaneously 1)\nreduce the model size; 2) decrease the run-time memory footprint; and 3) lower\nthe number of computing operations, without compromising accuracy. This is\nachieved by enforcing channel-level sparsity in the network in a simple but\neffective way. Different from many existing approaches, the proposed method\ndirectly applies to modern CNN architectures, introduces minimum overhead to\nthe training process, and requires no special software/hardware accelerators\nfor the resulting models. We call our approach network slimming, which takes\nwide and large networks as input models, but during training insignificant\nchannels are automatically identified and pruned afterwards, yielding thin and\ncompact models with comparable accuracy. We empirically demonstrate the\neffectiveness of our approach with several state-of-the-art CNN models,\nincluding VGGNet, ResNet and DenseNet, on various image classification\ndatasets. For VGGNet, a multi-pass version of network slimming gives a 20x\nreduction in model size and a 5x reduction in computing operations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 07:35:26 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Liu", "Zhuang", ""], ["Li", "Jianguo", ""], ["Shen", "Zhiqiang", ""], ["Huang", "Gao", ""], ["Yan", "Shoumeng", ""], ["Zhang", "Changshui", ""]]}, {"id": "1708.06539", "submitter": "Ratneel Deo Vikash", "authors": "Ratneel Vikash Deo, Rohitash Chandra and Anuraganand Sharma", "title": "Stacked transfer learning for tropical cyclone intensity prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tropical cyclone wind-intensity prediction is a challenging task considering\ndrastic changes climate patterns over the last few decades. In order to develop\nrobust prediction models, one needs to consider different characteristics of\ncyclones in terms of spatial and temporal characteristics. Transfer learning\nincorporates knowledge from a related source dataset to compliment a target\ndatasets especially in cases where there is lack or data. Stacking is a form of\nensemble learning focused for improving generalization that has been recently\nused for transfer learning problems which is referred to as transfer stacking.\nIn this paper, we employ transfer stacking as a means of studying the effects\nof cyclones whereby we evaluate if cyclones in different geographic locations\ncan be helpful for improving generalization performs. Moreover, we use\nconventional neural networks for evaluating the effects of duration on cyclones\nin prediction performance. Therefore, we develop an effective strategy that\nevaluates the relationships between different types of cyclones through\ntransfer learning and conventional learning methods via neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 08:49:36 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Deo", "Ratneel Vikash", ""], ["Chandra", "Rohitash", ""], ["Sharma", "Anuraganand", ""]]}, {"id": "1708.06551", "submitter": "Denis Steckelmacher", "authors": "Denis Steckelmacher, Diederik M. Roijers, Anna Harutyunyan, Peter\n  Vrancx, H\\'el\\`ene Plisnier, Ann Now\\'e", "title": "Reinforcement Learning in POMDPs with Memoryless Options and\n  Option-Observation Initiation Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world reinforcement learning problems have a hierarchical nature,\nand often exhibit some degree of partial observability. While hierarchy and\npartial observability are usually tackled separately (for instance by combining\nrecurrent neural networks and options), we show that addressing both problems\nsimultaneously is simpler and more efficient in many cases. More specifically,\nwe make the initiation set of options conditional on the previously-executed\noption, and show that options with such Option-Observation Initiation Sets\n(OOIs) are at least as expressive as Finite State Controllers (FSCs), a\nstate-of-the-art approach for learning in POMDPs. OOIs are easy to design based\non an intuitive description of the task, lead to explainable policies and keep\nthe top-level and option policies memoryless. Our experiments show that OOIs\nallow agents to learn optimal policies in challenging POMDPs, while being much\nmore sample-efficient than a recurrent neural network over options.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 09:51:18 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 08:34:04 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Steckelmacher", "Denis", ""], ["Roijers", "Diederik M.", ""], ["Harutyunyan", "Anna", ""], ["Vrancx", "Peter", ""], ["Plisnier", "H\u00e9l\u00e8ne", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1708.06555", "submitter": "Youssef Oualil", "authors": "Youssef Oualil, Mittul Singh, Clayton Greenberg, Dietrich Klakow", "title": "Long-Short Range Context Neural Networks for Language Modeling", "comments": "Published at EMNLP'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of language modeling techniques is to capture the statistical and\nstructural properties of natural languages from training corpora. This task\ntypically involves the learning of short range dependencies, which generally\nmodel the syntactic properties of a language and/or long range dependencies,\nwhich are semantic in nature. We propose in this paper a new multi-span\narchitecture, which separately models the short and long context information\nwhile it dynamically merges them to perform the language modeling task. This is\ndone through a novel recurrent Long-Short Range Context (LSRC) network, which\nexplicitly models the local (short) and global (long) context using two\nseparate hidden states that evolve in time. This new architecture is an\nadaptation of the Long-Short Term Memory network (LSTM) to take into account\nthe linguistic properties. Extensive experiments conducted on the Penn Treebank\n(PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a\nsignificant reduction of the perplexity when compared to state-of-the-art\nlanguage modeling techniques.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 10:26:41 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Oualil", "Youssef", ""], ["Singh", "Mittul", ""], ["Greenberg", "Clayton", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1708.06633", "submitter": "Johannes Schmidt-Hieber", "authors": "Johannes Schmidt-Hieber", "title": "Nonparametric regression using deep neural networks with ReLU activation\n  function", "comments": "article, rejoinder and supplementary material", "journal-ref": "Article: Annals of Statistics, Volume 48, Number 4, 1875-1897,\n  2020, Rejoinder: Annals of Statistics, Volume 48, Number 4, 1916-1921, 2020", "doi": "10.1214/19-AOS1875", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the multivariate nonparametric regression model. It is shown that\nestimators based on sparsely connected deep neural networks with ReLU\nactivation function and properly chosen network architecture achieve the\nminimax rates of convergence (up to $\\log n$-factors) under a general\ncomposition assumption on the regression function. The framework includes many\nwell-studied structural constraints such as (generalized) additive models.\nWhile there is a lot of flexibility in the network architecture, the tuning\nparameter is the sparsity of the network. Specifically, we consider large\nnetworks with number of potential network parameters exceeding the sample size.\nThe analysis gives some insights into why multilayer feedforward neural\nnetworks perform well in practice. Interestingly, for ReLU activation function\nthe depth (number of layers) of the neural network architectures plays an\nimportant role and our theory suggests that for nonparametric regression,\nscaling the network depth with the sample size is natural. It is also shown\nthat under the composition assumption wavelet estimators can only achieve\nsuboptimal rates.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 14:25:55 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 08:08:07 GMT"}, {"version": "v3", "created": "Sun, 13 May 2018 14:57:26 GMT"}, {"version": "v4", "created": "Sat, 16 Mar 2019 01:45:13 GMT"}, {"version": "v5", "created": "Sun, 13 Sep 2020 10:18:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1708.06678", "submitter": "Stratis Ioannidis", "authors": "Stratis Ioannidis and Andrea Montanari", "title": "Learning Combinations of Sigmoids Through Gradient Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new approach to learn the parameters of regression models with\nhidden variables. In a nutshell, we estimate the gradient of the regression\nfunction at a set of random points, and cluster the estimated gradients. The\ncenters of the clusters are used as estimates for the parameters of hidden\nunits. We justify this approach by studying a toy model, whereby the regression\nfunction is a linear combination of sigmoids. We prove that indeed the\nestimated gradients concentrate around the parameter vectors of the hidden\nunits, and provide non-asymptotic bounds on the number of required samples. To\nthe best of our knowledge, no comparable guarantees have been proven for linear\ncombinations of sigmoids.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 15:39:18 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 15:54:27 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Ioannidis", "Stratis", ""], ["Montanari", "Andrea", ""]]}, {"id": "1708.06733", "submitter": "Brendan Dolan-Gavitt", "authors": "Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg", "title": "BadNets: Identifying Vulnerabilities in the Machine Learning Model\n  Supply Chain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based techniques have achieved state-of-the-art performance on\na wide variety of recognition and classification tasks. However, these networks\nare typically computationally expensive to train, requiring weeks of\ncomputation on many GPUs; as a result, many users outsource the training\nprocedure to the cloud or rely on pre-trained models that are then fine-tuned\nfor a specific task. In this paper we show that outsourced training introduces\nnew security risks: an adversary can create a maliciously trained network (a\nbackdoored neural network, or a \\emph{BadNet}) that has state-of-the-art\nperformance on the user's training and validation samples, but behaves badly on\nspecific attacker-chosen inputs. We first explore the properties of BadNets in\na toy example, by creating a backdoored handwritten digit classifier. Next, we\ndemonstrate backdoors in a more realistic scenario by creating a U.S. street\nsign classifier that identifies stop signs as speed limits when a special\nsticker is added to the stop sign; we then show in addition that the backdoor\nin our US street sign detector can persist even if the network is later\nretrained for another task and cause a drop in accuracy of {25}\\% on average\nwhen the backdoor trigger is present. These results demonstrate that backdoors\nin neural networks are both powerful and---because the behavior of neural\nnetworks is difficult to explicate---stealthy. This work provides motivation\nfor further research into techniques for verifying and inspecting neural\nnetworks, just as we have developed tools for verifying and debugging software.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 17:31:54 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 20:45:33 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Gu", "Tianyu", ""], ["Dolan-Gavitt", "Brendan", ""], ["Garg", "Siddharth", ""]]}, {"id": "1708.06742", "submitter": "Dmitriy Serdyuk", "authors": "Dmitriy Serdyuk, Nan Rosemary Ke, Alessandro Sordoni, Adam Trischler,\n  Chris Pal, Yoshua Bengio", "title": "Twin Networks: Matching the Future for Sequence Generation", "comments": "12 pages, 3 figures, published at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple technique for encouraging generative RNNs to plan ahead.\nWe train a \"backward\" recurrent network to generate a given sequence in reverse\norder, and we encourage states of the forward model to predict cotemporal\nstates of the backward model. The backward network is used only during\ntraining, and plays no role during sampling or inference. We hypothesize that\nour approach eases modeling of long-term dependencies by implicitly forcing the\nforward states to hold information about the longer-term future (as contained\nin the backward states). We show empirically that our approach achieves 9%\nrelative improvement for a speech recognition task, and achieves significant\nimprovement on a COCO caption generation task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 17:44:56 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 22:09:36 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 19:54:36 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Serdyuk", "Dmitriy", ""], ["Ke", "Nan Rosemary", ""], ["Sordoni", "Alessandro", ""], ["Trischler", "Adam", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1708.06819", "submitter": "Nathan Hilliard", "authors": "Nathan Hilliard, Nathan O. Hodas, Courtney D. Corley", "title": "Dynamic Input Structure and Network Assembly for Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn from a small number of examples has been a difficult\nproblem in machine learning since its inception. While methods have succeeded\nwith large amounts of training data, research has been underway in how to\naccomplish similar performance with fewer examples, known as one-shot or more\ngenerally few-shot learning. This technique has been shown to have promising\nperformance, but in practice requires fixed-size inputs making it impractical\nfor production systems where class sizes can vary. This impedes training and\nthe final utility of few-shot learning systems. This paper describes an\napproach to constructing and training a network that can handle arbitrary\nexample sizes dynamically as the system is used.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 21:00:50 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Hilliard", "Nathan", ""], ["Hodas", "Nathan O.", ""], ["Corley", "Courtney D.", ""]]}, {"id": "1708.06832", "submitter": "Hanzhang Hu", "authors": "Hanzhang Hu, Debadeepta Dey, Martial Hebert, J. Andrew Bagnell", "title": "Learning Anytime Predictions in Neural Networks via Adaptive Loss\n  Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers the trade-off between accuracy and test-time\ncomputational cost of deep neural networks (DNNs) via \\emph{anytime}\npredictions from auxiliary predictions. Specifically, we optimize auxiliary\nlosses jointly in an \\emph{adaptive} weighted sum, where the weights are\ninversely proportional to average of each loss. Intuitively, this balances the\nlosses to have the same scale. We demonstrate theoretical considerations that\nmotivate this approach from multiple viewpoints, including connecting it to\noptimizing the geometric mean of the expectation of each loss, an objective\nthat ignores the scale of losses. Experimentally, the adaptive weights induce\nmore competitive anytime predictions on multiple recognition data-sets and\nmodels than non-adaptive approaches including weighing all losses equally. In\nparticular, anytime neural networks (ANNs) can achieve the same accuracy faster\nusing adaptive weights on a small network than using static constant weights on\na large one. For problems with high performance saturation, we also show a\nsequence of exponentially deepening ANNscan achieve near-optimal anytime\nresults at any budget, at the cost of a const fraction of extra computation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 21:42:15 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 21:25:38 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 05:18:33 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Hu", "Hanzhang", ""], ["Dey", "Debadeepta", ""], ["Hebert", "Martial", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1708.06846", "submitter": "Arthur Choi", "authors": "Arthur Choi and Adnan Darwiche", "title": "On Relaxing Determinism in Arithmetic Circuits", "comments": "In Proceedings of the Thirty-fourth International Conference on\n  Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has seen a significant interest in learning tractable\nprobabilistic representations. Arithmetic circuits (ACs) were among the first\nproposed tractable representations, with some subsequent representations being\ninstances of ACs with weaker or stronger properties. In this paper, we provide\na formal basis under which variants on ACs can be compared, and where the\nprecise roles and semantics of their various properties can be made more\ntransparent. This allows us to place some recent developments on ACs in a\nclearer perspective and to also derive new results for ACs. This includes an\nexponential separation between ACs with and without determinism; completeness\nand incompleteness results; and tractability results (or lack thereof) when\ncomputing most probable explanations (MPEs).\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 23:02:11 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1708.06850", "submitter": "Enoch Yeung Ph.D.", "authors": "Enoch Yeung, Soumya Kundu, Nathan Hodas", "title": "Learning Deep Neural Network Representations for Koopman Operators of\n  Nonlinear Dynamical Systems", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Koopman operator has recently garnered much attention for its value in\ndynamical systems analysis and data-driven model discovery. However, its\napplication has been hindered by the computational complexity of extended\ndynamic mode decomposition; this requires a combinatorially large basis set to\nadequately describe many nonlinear systems of interest, e.g. cyber-physical\ninfrastructure systems, biological networks, social systems, and fluid\ndynamics. Often the dictionaries generated for these problems are manually\ncurated, requiring domain-specific knowledge and painstaking tuning. In this\npaper we introduce a deep learning framework for learning Koopman operators of\nnonlinear dynamical systems. We show that this novel method automatically\nselects efficient deep dictionaries, outperforming state-of-the-art methods. We\nbenchmark this method on partially observed nonlinear systems, including the\nglycolytic oscillator and show it is able to predict quantitatively 100 steps\ninto the future, using only a single timepoint, and qualitative oscillatory\nbehavior 400 steps into the future.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 23:32:19 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 19:36:19 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Yeung", "Enoch", ""], ["Kundu", "Soumya", ""], ["Hodas", "Nathan", ""]]}, {"id": "1708.06899", "submitter": "Johanna \\\"Arje", "authors": "Johanna \\\"Arje, Jenni Raitoharju, Alexandros Iosifidis, Ville\n  Tirronen, Kristian Meissner, Moncef Gabbouj, Serkan Kiranyaz, Salme\n  K\\\"arkk\\\"ainen", "title": "Human experts vs. machines in taxa recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The step of expert taxa recognition currently slows down the response time of\nmany bioassessments. Shifting to quicker and cheaper state-of-the-art machine\nlearning approaches is still met with expert scepticism towards the ability and\nlogic of machines. In our study, we investigate both the differences in\naccuracy and in the identification logic of taxonomic experts and machines. We\npropose a systematic approach utilizing deep Convolutional Neural Nets with the\ntransfer learning paradigm and extensively evaluate it over a multi-pose\ntaxonomic dataset with hierarchical labels specifically created for this\ncomparison. We also study the prediction accuracy on different ranks of\ntaxonomic hierarchy in detail. Our results revealed that human experts using\nactual specimens yield the lowest classification error ($\\overline{CE}=6.1\\%$).\nHowever, a much faster, automated approach using deep Convolutional Neural Nets\ncomes close to human accuracy ($\\overline{CE}=11.4\\%$). Contrary to previous\nfindings in the literature, we find that for machines following a typical flat\nclassification approach commonly used in machine learning performs better than\nforcing machines to adopt a hierarchical, local per parent node approach used\nby human taxonomic experts. Finally, we publicly share our unique dataset to\nserve as a public benchmark dataset in this field.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 06:52:33 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 10:22:16 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2019 11:42:52 GMT"}, {"version": "v4", "created": "Fri, 17 May 2019 08:26:17 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["\u00c4rje", "Johanna", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Tirronen", "Ville", ""], ["Meissner", "Kristian", ""], ["Gabbouj", "Moncef", ""], ["Kiranyaz", "Serkan", ""], ["K\u00e4rkk\u00e4inen", "Salme", ""]]}, {"id": "1708.06939", "submitter": "Battista Biggio", "authors": "Marco Melis, Ambra Demontis, Battista Biggio, Gavin Brown, Giorgio\n  Fumera and Fabio Roli", "title": "Is Deep Learning Safe for Robot Vision? Adversarial Examples against the\n  iCub Humanoid", "comments": "Accepted for publication at the ICCV 2017 Workshop on Vision in\n  Practice on Autonomous Robots (ViPAR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been widely adopted in recent years, exhibiting\nimpressive performances in several application domains. It has however been\nshown that they can be fooled by adversarial examples, i.e., images altered by\na barely-perceivable adversarial noise, carefully crafted to mislead\nclassification. In this work, we aim to evaluate the extent to which\nrobot-vision systems embodying deep-learning algorithms are vulnerable to\nadversarial examples, and propose a computationally efficient countermeasure to\nmitigate this threat, based on rejecting classification of anomalous inputs. We\nthen provide a clearer understanding of the safety properties of deep networks\nthrough an intuitive empirical analysis, showing that the mapping learned by\nsuch networks essentially violates the smoothness assumption of learning\nalgorithms. We finally discuss the main limitations of this work, including the\ncreation of real-world adversarial examples, and sketch promising research\ndirections.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 10:01:35 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Melis", "Marco", ""], ["Demontis", "Ambra", ""], ["Biggio", "Battista", ""], ["Brown", "Gavin", ""], ["Fumera", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1708.06975", "submitter": "Maxime Bucher", "authors": "Maxime Bucher (1), St\\'ephane Herbin (1), Fr\\'ed\\'eric Jurie ((1)\n  Palaiseau)", "title": "Generating Visual Representations for Zero-Shot Classification", "comments": null, "journal-ref": "International Conference on Computer Vision (ICCV) Workshops :\n  TASK-CV: Transferring and Adapting Source Knowledge in Computer Vision, Oct\n  2017, venise, Italy. International Conference on Computer Vision (ICCV)\n  Workshops, 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the task of learning an image clas-sifier when some\ncategories are defined by semantic descriptions only (e.g. visual attributes)\nwhile the others are defined by exemplar images as well. This task is often\nreferred to as the Zero-Shot classification task (ZSC). Most of the previous\nmethods rely on learning a common embedding space allowing to compare visual\nfeatures of unknown categories with semantic descriptions. This paper argues\nthat these approaches are limited as i) efficient discrimi-native classifiers\ncan't be used ii) classification tasks with seen and unseen categories\n(Generalized Zero-Shot Classification or GZSC) can't be addressed efficiently.\nIn contrast , this paper suggests to address ZSC and GZSC by i) learning a\nconditional generator using seen classes ii) generate artificial training\nexamples for the categories without exemplars. ZSC is then turned into a\nstandard supervised learning problem. Experiments with 4 generative models and\n5 datasets experimentally validate the approach, giving state-of-the-art\nresults on both ZSC and GZSC.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 12:23:51 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 12:56:18 GMT"}, {"version": "v3", "created": "Mon, 11 Dec 2017 16:16:01 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Bucher", "Maxime", ""], ["Herbin", "St\u00e9phane", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1708.07012", "submitter": "Paolo Inglese", "authors": "Paolo Inglese, James L. Alexander, Anna Mroz, Zoltan Takats, Robert\n  Glen", "title": "Variational autoencoders for tissue heterogeneity exploration from\n  (almost) no preprocessed mass spectrometry imaging data", "comments": "mass spectrometry imaging, variational autoencoder, desorption\n  electrospray ionization, desi", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The paper presents the application of Variational Autoencoders (VAE) for data\ndimensionality reduction and explorative analysis of mass spectrometry imaging\ndata (MSI). The results confirm that VAEs are capable of detecting the patterns\nassociated with the different tissue sub-types with performance than standard\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 14:12:53 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 13:59:31 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Inglese", "Paolo", ""], ["Alexander", "James L.", ""], ["Mroz", "Anna", ""], ["Takats", "Zoltan", ""], ["Glen", "Robert", ""]]}, {"id": "1708.07025", "submitter": "Philip Graff", "authors": "Cetin Savkli, J. Ryan Carr, Philip Graff, Lauren Kennell", "title": "Bayesian Learning of Clique Tree Structure", "comments": "7 pages, 11 figures; see\n  http://worldcomp-proceedings.com/proc/p2016/DMIN16_Contents.html", "journal-ref": "Proceedings of the International Conference on Data Mining (DMIN).\n  The Steering Committee of The World Congress in Computer Science, Computer\n  Engineering and Applied Computing (WorldComp). p 201, 2016", "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of categorical data analysis in high dimensions is considered. A\ndiscussion of the fundamental difficulties of probability modeling is provided,\nand a solution to the derivation of high dimensional probability distributions\nbased on Bayesian learning of clique tree decomposition is presented. The main\ncontributions of this paper are an automated determination of the optimal\nclique tree structure for probability modeling, the resulting derived\nprobability distribution, and a corresponding unified approach to clustering\nand anomaly detection based on the probability distribution.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 14:40:19 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Savkli", "Cetin", ""], ["Carr", "J. Ryan", ""], ["Graff", "Philip", ""], ["Kennell", "Lauren", ""]]}, {"id": "1708.07042", "submitter": "Wojciech Kot{\\l}owski", "authors": "Wojciech Kot{\\l}owski", "title": "Scale-invariant unconstrained online learning", "comments": "To appear in Proc. of the 28th International Conference on\n  Algorithmic Learning Theory (ALT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of online convex optimization in which both the\ninstances (input vectors) and the comparator (weight vector) are unconstrained.\nWe exploit a natural scale invariance symmetry in our unconstrained setting:\nthe predictions of the optimal comparator are invariant under any linear\ntransformation of the instances. Our goal is to design online algorithms which\nalso enjoy this property, i.e. are scale-invariant. We start with the case of\ncoordinate-wise invariance, in which the individual coordinates (features) can\nbe arbitrarily rescaled. We give an algorithm, which achieves essentially\noptimal regret bound in this setup, expressed by means of a coordinate-wise\nscale-invariant norm of the comparator. We then study general invariance with\nrespect to arbitrary linear transformations. We first give a negative result,\nshowing that no algorithm can achieve a meaningful bound in terms of\nscale-invariant norm of the comparator in the worst case. Next, we compliment\nthis result with a positive one, providing an algorithm which \"almost\" achieves\nthe desired bound, incurring only a logarithmic overhead in terms of the norm\nof the instances.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 15:15:23 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Kot\u0142owski", "Wojciech", ""]]}, {"id": "1708.07058", "submitter": "Moumita Bhattacharya", "authors": "Moumita Bhattacharya, Deborah Ehrenthal, Hagit Shatkay", "title": "Identifying Growth-Patterns in Children by Applying Cluster analysis to\n  Electronic Medical Records", "comments": "4 pages, 5 figure Published in Proc. of the IEEE Int. Conference on\n  Bioinformatics and Biomedicine (BIBM), Belfast, Ireland, November, 2014", "journal-ref": null, "doi": "10.1109/BIBM.2014.6999183", "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is one of the leading health concerns in the United States.\nResearchers and health care providers are interested in understanding factors\naffecting obesity and detecting the likelihood of obesity as early as possible.\nIn this paper, we set out to recognize children who have higher risk of obesity\nby identifying distinct growth patterns in them. This is done by using\nclustering methods, which group together children who share similar body\nmeasurements over a period of time. The measurements characterizing children\nwithin the same cluster are plotted as a function of age. We refer to these\nplots as growthpattern curves. We show that distinct growth-pattern curves are\nassociated with different clusters and thus can be used to separate children\ninto the topmost (heaviest), middle, or bottom-most cluster based on early\ngrowth measurements.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 18:21:21 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Bhattacharya", "Moumita", ""], ["Ehrenthal", "Deborah", ""], ["Shatkay", "Hagit", ""]]}, {"id": "1708.07061", "submitter": "Jesus Lago", "authors": "Jesus Lago, Fjo De Ridder, Peter Vrancx, Bart De Schutter", "title": "Forecasting day-ahead electricity prices in Europe: the importance of\n  considering market integration", "comments": null, "journal-ref": "Applied Energy, Volume 211, 1 February 2018, Pages 890-903", "doi": "10.1016/j.apenergy.2017.11.098", "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.NE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the increasing integration among electricity markets, in this\npaper we propose two different methods to incorporate market integration in\nelectricity price forecasting and to improve the predictive performance. First,\nwe propose a deep neural network that considers features from connected markets\nto improve the predictive accuracy in a local market. To measure the importance\nof these features, we propose a novel feature selection algorithm that, by\nusing Bayesian optimization and functional analysis of variance, evaluates the\neffect of the features on the algorithm performance. In addition, using market\nintegration, we propose a second model that, by simultaneously predicting\nprices from two markets, improves the forecasting accuracy even further. As a\ncase study, we consider the electricity market in Belgium and the improvements\nin forecasting accuracy when using various French electricity features. We show\nthat the two proposed models lead to improvements that are statistically\nsignificant. Particularly, due to market integration, the predictive accuracy\nis improved from 15.7% to 12.5% sMAPE (symmetric mean absolute percentage\nerror). In addition, we show that the proposed feature selection algorithm is\nable to perform a correct assessment, i.e. to discard the irrelevant features.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 15:34:48 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 17:12:16 GMT"}, {"version": "v3", "created": "Thu, 7 Dec 2017 15:34:43 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Lago", "Jesus", ""], ["De Ridder", "Fjo", ""], ["Vrancx", "Peter", ""], ["De Schutter", "Bart", ""]]}, {"id": "1708.07074", "submitter": "Sabeur Aridhi", "authors": "Sabeur Aridhi (1), Seyed Ziaeddin Alborzi (1), Malika Sma\\\"il-Tabbone\n  (2), Marie-Dominique Devignes (1), David Ritchie (1) ((1) CAPSID, (2)\n  ORPAILLEUR)", "title": "Neighborhood-Based Label Propagation in Large Protein Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding protein function is one of the keys to understanding life at\nthe molecular level. It is also important in several scenarios including human\ndisease and drug discovery. In this age of rapid and affordable biological\nsequencing, the number of sequences accumulating in databases is rising with an\nincreasing rate. This presents many challenges for biologists and computer\nscientists alike. In order to make sense of this huge quantity of data, these\nsequences should be annotated with functional properties. UniProtKB consists of\ntwo components: i) the UniProtKB/Swiss-Prot database containing protein\nsequences with reliable information manually reviewed by expert bio-curators\nand ii) the UniProtKB/TrEMBL database that is used for storing and processing\nthe unknown sequences. Hence, for all proteins we have available the sequence\nalong with few more information such as the taxon and some structural domains.\nPairwise similarity can be defined and computed on proteins based on such\nattributes. Other important attributes, while present for proteins in\nSwiss-Prot, are often missing for proteins in TrEMBL, such as their function\nand cellular localization. The enormous number of protein sequences now in\nTrEMBL calls for rapid procedures to annotate them automatically. In this work,\nwe present DistNBLP, a novel Distributed Neighborhood-Based Label Propagation\napproach for large-scale annotation of proteins. To do this, the functional\nannotations of reviewed proteins are used to predict those of non-reviewed\nproteins using label propagation on a graph representation of the protein\ndatabase. DistNBLP is built on top of the \"akka\" toolkit for building resilient\ndistributed message-driven applications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 12:06:15 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Aridhi", "Sabeur", ""], ["Alborzi", "Seyed Ziaeddin", ""], ["Sma\u00efl-Tabbone", "Malika", ""], ["Devignes", "Marie-Dominique", ""], ["Ritchie", "David", ""]]}, {"id": "1708.07120", "submitter": "Leslie Smith", "authors": "Leslie N. Smith and Nicholay Topin", "title": "Super-Convergence: Very Fast Training of Neural Networks Using Large\n  Learning Rates", "comments": "This paper was significantly revised to show super-convergence as a\n  general fast training methodology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a phenomenon, which we named \"super-convergence\",\nwhere neural networks can be trained an order of magnitude faster than with\nstandard training methods. The existence of super-convergence is relevant to\nunderstanding why deep networks generalize well. One of the key elements of\nsuper-convergence is training with one learning rate cycle and a large maximum\nlearning rate. A primary insight that allows super-convergence training is that\nlarge learning rates regularize the training, hence requiring a reduction of\nall other forms of regularization in order to preserve an optimal\nregularization balance. We also derive a simplification of the Hessian Free\noptimization method to compute an estimate of the optimal learning rate.\nExperiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet\ndatasets, and resnet, wide-resnet, densenet, and inception architectures. In\naddition, we show that super-convergence provides a greater boost in\nperformance relative to standard training when the amount of labeled training\ndata is limited. The architectures and code to replicate the figures in this\npaper are available at github.com/lnsmith54/super-convergence. See\nhttp://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of\nsuper-convergence to win the DAWNBench challenge (see\nhttps://dawn.cs.stanford.edu/benchmark/).\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 17:51:57 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 18:24:34 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 17:40:34 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Smith", "Leslie N.", ""], ["Topin", "Nicholay", ""]]}, {"id": "1708.07147", "submitter": "Ashley Prater", "authors": "Ashley Prater", "title": "Classification via Tensor Decompositions of Echo State Networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a tensor-based method to perform supervised\nclassification on spatiotemporal data processed in an echo state network.\nTypically when performing supervised classification tasks on data processed in\nan echo state network, the entire collection of hidden layer node states from\nthe training dataset is shaped into a matrix, allowing one to use standard\nlinear algebra techniques to train the output layer. However, the collection of\nhidden layer states is multidimensional in nature, and representing it as a\nmatrix may lead to undesirable numerical conditions or loss of spatial and\ntemporal correlations in the data.\n  This work proposes a tensor-based supervised classification method on echo\nstate network data that preserves and exploits the multidimensional nature of\nthe hidden layer states. The method, which is based on orthogonal Tucker\ndecompositions of tensors, is compared with the standard linear output weight\napproach in several numerical experiments on both synthetic and natural data.\nThe results show that the tensor-based approach tends to outperform the\nstandard approach in terms of classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 18:51:08 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Prater", "Ashley", ""]]}, {"id": "1708.07149", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe, Michael Noseworthy, Iulian V. Serban, Nicolas\n  Angelard-Gontier, Yoshua Bengio, Joelle Pineau", "title": "Towards an Automatic Turing Test: Learning to Evaluate Dialogue\n  Responses", "comments": "ACL 2017", "journal-ref": "Proceedings of the 55th annual meeting on Association for\n  Computational Linguistics (2017), pp. 1116-1126", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically evaluating the quality of dialogue responses for unstructured\ndomains is a challenging problem. Unfortunately, existing automatic evaluation\nmetrics are biased and correlate very poorly with human judgements of response\nquality. Yet having an accurate automatic evaluation procedure is crucial for\ndialogue research, as it allows rapid prototyping and testing of new models\nwith fewer expensive human evaluations. In response to this challenge, we\nformulate automatic dialogue evaluation as a learning problem. We present an\nevaluation model (ADEM) that learns to predict human-like scores to input\nresponses, using a new dataset of human response scores. We show that the ADEM\nmodel's predictions correlate significantly, and at a level much higher than\nword-overlap metrics such as BLEU, with human judgements at both the utterance\nand system-level. We also show that ADEM can generalize to evaluating dialogue\nmodels unseen during training, an important step for automatic dialogue\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 18:56:00 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 23:29:14 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Lowe", "Ryan", ""], ["Noseworthy", "Michael", ""], ["Serban", "Iulian V.", ""], ["Angelard-Gontier", "Nicolas", ""], ["Bengio", "Yoshua", ""], ["Pineau", "Joelle", ""]]}, {"id": "1708.07164", "submitter": "Peng Xu", "authors": "Peng Xu, Fred Roosta, Michael W. Mahoney", "title": "Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian\n  Information", "comments": "32 pages", "journal-ref": "Mathematical Programming 2019", "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider variants of trust-region and cubic regularization methods for\nnon-convex optimization, in which the Hessian matrix is approximated. Under\nmild conditions on the inexact Hessian, and using approximate solution of the\ncorresponding sub-problems, we provide iteration complexity to achieve $\n\\epsilon $-approximate second-order optimality which have shown to be tight.\nOur Hessian approximation conditions constitute a major relaxation over the\nexisting ones in the literature. Consequently, we are able to show that such\nmild conditions allow for the construction of the approximate Hessian through\nvarious random sampling methods. In this light, we consider the canonical\nproblem of finite-sum minimization, provide appropriate uniform and non-uniform\nsub-sampling strategies to construct such Hessian approximations, and obtain\noptimal iteration complexity for the corresponding sub-sampled trust-region and\ncubic regularization methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 19:40:55 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 01:57:45 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 23:57:07 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 09:13:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Xu", "Peng", ""], ["Roosta", "Fred", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1708.07178", "submitter": "Giorgos Borboudakis", "authors": "Ioannis Tsamardinos and Giorgos Borboudakis and Pavlos Katsogridakis\n  and Polyvios Pratikakis and Vassilis Christophides", "title": "Massively-Parallel Feature Selection for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Parallel, Forward-Backward with Pruning (PFBP) algorithm for\nfeature selection (FS) in Big Data settings (high dimensionality and/or sample\nsize). To tackle the challenges of Big Data FS PFBP partitions the data matrix\nboth in terms of rows (samples, training examples) as well as columns\n(features). By employing the concepts of $p$-values of conditional independence\ntests and meta-analysis techniques PFBP manages to rely only on computations\nlocal to a partition while minimizing communication costs. Then, it employs\npowerful and safe (asymptotically sound) heuristics to make early, approximate\ndecisions, such as Early Dropping of features from consideration in subsequent\niterations, Early Stopping of consideration of features within the same\niteration, or Early Return of the winner in each iteration. PFBP provides\nasymptotic guarantees of optimality for data distributions faithfully\nrepresentable by a causal network (Bayesian network or maximal ancestral\ngraph). Our empirical analysis confirms a super-linear speedup of the algorithm\nwith increasing sample size, linear scalability with respect to the number of\nfeatures and processing cores, while dominating other competitive algorithms in\nits class.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 20:23:36 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Tsamardinos", "Ioannis", ""], ["Borboudakis", "Giorgos", ""], ["Katsogridakis", "Pavlos", ""], ["Pratikakis", "Polyvios", ""], ["Christophides", "Vassilis", ""]]}, {"id": "1708.07180", "submitter": "Giorgos Borboudakis", "authors": "Ioannis Tsamardinos, Elissavet Greasidou, Michalis Tsagris and Giorgos\n  Borboudakis", "title": "Bootstrapping the Out-of-sample Predictions for Efficient and Accurate\n  Cross-Validation", "comments": "Added acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Validation (CV), and out-of-sample performance-estimation protocols in\ngeneral, are often employed both for (a) selecting the optimal combination of\nalgorithms and values of hyper-parameters (called a configuration) for\nproducing the final predictive model, and (b) estimating the predictive\nperformance of the final model. However, the cross-validated performance of the\nbest configuration is optimistically biased. We present an efficient bootstrap\nmethod that corrects for the bias, called Bootstrap Bias Corrected CV (BBC-CV).\nBBC-CV's main idea is to bootstrap the whole process of selecting the\nbest-performing configuration on the out-of-sample predictions of each\nconfiguration, without additional training of models. In comparison to the\nalternatives, namely the nested cross-validation and a method by Tibshirani and\nTibshirani, BBC-CV is computationally more efficient, has smaller variance and\nbias, and is applicable to any metric of performance (accuracy, AUC,\nconcordance index, mean squared error). Subsequently, we employ again the idea\nof bootstrapping the out-of-sample predictions to speed up the CV process.\nSpecifically, using a bootstrap-based hypothesis test we stop training of\nmodels on new folds of statistically-significantly inferior configurations. We\nname the method Bootstrap Corrected with Early Dropping CV (BCED-CV) that is\nboth efficient and provides accurate performance estimates.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 20:30:07 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 14:02:02 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Tsamardinos", "Ioannis", ""], ["Greasidou", "Elissavet", ""], ["Tsagris", "Michalis", ""], ["Borboudakis", "Giorgos", ""]]}, {"id": "1708.07199", "submitter": "Patrik Huber", "authors": "Anil Bas, Patrik Huber, William A. P. Smith, Muhammad Awais, Josef\n  Kittler", "title": "3D Morphable Models as Spatial Transformer Networks", "comments": "Accepted to ICCV 2017 2nd Workshop on Geometry Meets Deep Learning", "journal-ref": null, "doi": "10.1109/ICCVW.2017.110", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how a 3D Morphable Model (i.e. a statistical model of\nthe 3D shape of a class of objects such as faces) can be used to spatially\ntransform input data as a module (a 3DMM-STN) within a convolutional neural\nnetwork. This is an extension of the original spatial transformer network in\nthat we are able to interpret and normalise 3D pose changes and\nself-occlusions. The trained localisation part of the network is independently\nuseful since it learns to fit a 3D morphable model to a single image. We show\nthat the localiser can be trained using only simple geometric loss functions on\na relatively small dataset yet is able to perform robust normalisation on\nhighly uncontrolled images including occlusion, self-occlusion and large pose\nchanges.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 22:01:03 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bas", "Anil", ""], ["Huber", "Patrik", ""], ["Smith", "William A. P.", ""], ["Awais", "Muhammad", ""], ["Kittler", "Josef", ""]]}, {"id": "1708.07227", "submitter": "Sami Abu-El-Haija", "authors": "Sami Abu-El-Haija", "title": "Proportionate gradient updates with PercentDelta", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks are generally trained using iterative gradient updates.\nMagnitudes of gradients are affected by many factors, including choice of\nactivation functions and initialization. More importantly, gradient magnitudes\ncan greatly differ across layers, with some layers receiving much smaller\ngradients than others. causing some layers to train slower than others and\ntherefore slowing down the overall convergence. We analytically explain this\ndisproportionality. Then we propose to explicitly train all layers at the same\nspeed, by scaling the gradient w.r.t. every trainable tensor to be proportional\nto its current value. In particular, at every batch, we want to update all\ntrainable tensors, such that the relative change of the L1-norm of the tensors\nis the same, across all layers of the network, throughout training time.\nExperiments on MNIST show that our method appropriately scales gradients, such\nthat the relative change in trainable tensors is approximately equal across\nlayers. In addition, measuring the test accuracy with training time, shows that\nour method trains faster than other methods, giving higher test accuracy given\nsame budget of training steps.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 00:20:16 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Abu-El-Haija", "Sami", ""]]}, {"id": "1708.07242", "submitter": "Philip Graff", "authors": "Cetin Savkli, Jeffrey Lin, Philip Graff, Matthew Kinsey", "title": "GALILEO: A Generalized Low-Entropy Mixture Model", "comments": "7 pages, 8 figures, 3 tables", "journal-ref": "Proceedings of the International Conference on Data Mining (DMIN\n  17). The Steering Committee of The World Congress in Computer Science,\n  Computer Engineering and Applied Computing (WorldComp). 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method of generating mixture models for data with\ncategorical attributes. The keys to this approach are an entropy-based density\nmetric in categorical space and annealing of high-entropy/low-density\ncomponents from an initial state with many components. Pruning of low-density\ncomponents using the entropy-based density allows GALILEO to consistently find\nhigh-quality clusters and the same optimal number of clusters. GALILEO has\nshown promising results on a range of test datasets commonly used for\ncategorical clustering benchmarks. We demonstrate that the scaling of GALILEO\nis linear in the number of records in the dataset, making this method suitable\nfor very large categorical datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 01:27:34 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Savkli", "Cetin", ""], ["Lin", "Jeffrey", ""], ["Graff", "Philip", ""], ["Kinsey", "Matthew", ""]]}, {"id": "1708.07244", "submitter": "Senjian An Dr.", "authors": "Senjian An, Mohammed Bennamoun and Farid Boussaid", "title": "On the Compressive Power of Deep Rectifier Networks for High Resolution\n  Representation of Class Boundaries", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a theoretical justification of the superior\nclassification performance of deep rectifier networks over shallow rectifier\nnetworks from the geometrical perspective of piecewise linear (PWL) classifier\nboundaries. We show that, for a given threshold on the approximation error, the\nrequired number of boundary facets to approximate a general smooth boundary\ngrows exponentially with the dimension of the data, and thus the number of\nboundary facets, referred to as boundary resolution, of a PWL classifier is an\nimportant quality measure that can be used to estimate a lower bound on the\nclassification errors. However, learning naively an exponentially large number\nof boundary facets requires the determination of an exponentially large number\nof parameters and also requires an exponentially large number of training\npatterns. To overcome this issue of \"curse of dimensionality\", compressive\nrepresentations of high resolution classifier boundaries are required. To show\nthe superior compressive power of deep rectifier networks over shallow\nrectifier networks, we prove that the maximum boundary resolution of a single\nhidden layer rectifier network classifier grows exponentially with the number\nof units when this number is smaller than the dimension of the patterns. When\nthe number of units is larger than the dimension of the patterns, the growth\nrate is reduced to a polynomial order. Consequently, the capacity of generating\na high resolution boundary will increase if the same large number of units are\narranged in multiple layers instead of a single hidden layer. Taking high\ndimensional spherical boundaries as examples, we show how deep rectifier\nnetworks can utilize geometric symmetries to approximate a boundary with the\nsame accuracy but with a significantly fewer number of parameters than single\nhidden layer nets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 01:37:36 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["An", "Senjian", ""], ["Bennamoun", "Mohammed", ""], ["Boussaid", "Farid", ""]]}, {"id": "1708.07303", "submitter": "Xinchen Yan", "authors": "Xinchen Yan, Jasmine Hsu, Mohi Khansari, Yunfei Bai, Arkanath Pathak,\n  Abhinav Gupta, James Davidson, Honglak Lee", "title": "Learning 6-DOF Grasping Interaction via Deep Geometry-aware 3D\n  Representations", "comments": "Published at ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of learning 6-DOF grasping with a parallel\njaw gripper in simulation. We propose the notion of a geometry-aware\nrepresentation in grasping based on the assumption that knowledge of 3D\ngeometry is at the heart of interaction. Our key idea is constraining and\nregularizing grasping interaction learning through 3D geometry prediction.\nSpecifically, we formulate the learning of deep geometry-aware grasping model\nin two steps: First, we learn to build mental geometry-aware representation by\nreconstructing the scene (i.e., 3D occupancy grid) from RGBD input via\ngenerative 3D shape modeling. Second, we learn to predict grasping outcome with\nits internal geometry-aware representation. The learned outcome prediction\nmodel is used to sequentially propose grasping solutions via\nanalysis-by-synthesis optimization. Our contributions are fourfold: (1) To best\nof our knowledge, we are presenting for the first time a method to learn a\n6-DOF grasping net from RGBD input; (2) We build a grasping dataset from\ndemonstrations in virtual reality with rich sensory and interaction\nannotations. This dataset includes 101 everyday objects spread across 7\ncategories, additionally, we propose a data augmentation strategy for effective\nlearning; (3) We demonstrate that the learned geometry-aware representation\nleads to about 10 percent relative performance improvement over the baseline\nCNN on grasping objects from our dataset. (4) We further demonstrate that the\nmodel generalizes to novel viewpoints and object instances.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 08:09:04 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 02:50:28 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 18:57:26 GMT"}, {"version": "v4", "created": "Fri, 15 Jun 2018 03:40:53 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Yan", "Xinchen", ""], ["Hsu", "Jasmine", ""], ["Khansari", "Mohi", ""], ["Bai", "Yunfei", ""], ["Pathak", "Arkanath", ""], ["Gupta", "Abhinav", ""], ["Davidson", "James", ""], ["Lee", "Honglak", ""]]}, {"id": "1708.07308", "submitter": "Ce Zhang", "authors": "Tian Li, Jie Zhong, Ji Liu, Wentao Wu, Ce Zhang", "title": "Ease.ml: Towards Multi-tenant Resource Sharing for Machine Learning\n  Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ease.ml, a declarative machine learning service platform we built\nto support more than ten research groups outside the computer science\ndepartments at ETH Zurich for their machine learning needs. With ease.ml, a\nuser defines the high-level schema of a machine learning application and\nsubmits the task via a Web interface. The system automatically deals with the\nrest, such as model selection and data movement. In this paper, we describe the\nease.ml architecture and focus on a novel technical problem introduced by\nease.ml regarding resource allocation. We ask, as a \"service provider\" that\nmanages a shared cluster of machines among all our users running machine\nlearning workloads, what is the resource allocation strategy that maximizes the\nglobal satisfaction of all our users?\n  Resource allocation is a critical yet subtle issue in this multi-tenant\nscenario, as we have to balance between efficiency and fairness. We first\nformalize the problem that we call multi-tenant model selection, aiming for\nminimizing the total regret of all users running automatic model selection\ntasks. We then develop a novel algorithm that combines multi-armed bandits with\nBayesian optimization and prove a regret bound under the multi-tenant setting.\nFinally, we report our evaluation of ease.ml on synthetic data and on one\nservice we are providing to our users, namely, image classification with deep\nneural networks. Our experimental evaluation results show that our proposed\nsolution can be up to 9.8x faster in achieving the same global quality for all\nusers as the two popular heuristics used by our users before ease.ml.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 08:21:28 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Li", "Tian", ""], ["Zhong", "Jie", ""], ["Liu", "Ji", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "1708.07311", "submitter": "Tobias Sutter", "authors": "Tobias Sutter, David Sutter, Peyman Mohajerin Esfahani, John Lygeros", "title": "Generalized maximum entropy estimation", "comments": "29 pages, 3 figures; v2: approximate dynamic programming section\n  added, v3: published version", "journal-ref": "Journal of Machine Learning Research, vol 20, 2019", "doi": null, "report-no": "http://jmlr.org/papers/v20/17-486.html", "categories": "math.OC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a probability distribution that\nmaximizes the entropy while satisfying a finite number of moment constraints,\npossibly corrupted by noise. Based on duality of convex programming, we present\na novel approximation scheme using a smoothed fast gradient method that is\nequipped with explicit bounds on the approximation error. We further\ndemonstrate how the presented scheme can be used for approximating the chemical\nmaster equation through the zero-information moment closure method, and for an\napproximate dynamic programming approach in the context of constrained Markov\ndecision processes with uncountable state and action spaces.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 08:39:58 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 10:42:37 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 20:11:02 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sutter", "Tobias", ""], ["Sutter", "David", ""], ["Esfahani", "Peyman Mohajerin", ""], ["Lygeros", "John", ""]]}, {"id": "1708.07336", "submitter": "Hsuan-Tien Lin", "authors": "Wei-Yuan Shen and Hsuan-Tien Lin", "title": "Active Sampling of Pairs and Points for Large-scale Linear Bipartite\n  Ranking", "comments": "a shorter version was presented in ACML 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite ranking is a fundamental ranking problem that learns to order\nrelevant instances ahead of irrelevant ones. The pair-wise approach for\nbi-partite ranking construct a quadratic number of pairs to solve the problem,\nwhich is infeasible for large-scale data sets. The point-wise approach, albeit\nmore efficient, often results in inferior performance. That is, it is difficult\nto conduct bipartite ranking accurately and efficiently at the same time. In\nthis paper, we develop a novel active sampling scheme within the pair-wise\napproach to conduct bipartite ranking efficiently. The scheme is inspired from\nactive learning and can reach a competitive ranking performance while focusing\nonly on a small subset of the many pairs during training. Moreover, we propose\na general Combined Ranking and Classification (CRC) framework to accurately\nconduct bipartite ranking. The framework unifies point-wise and pair-wise\napproaches and is simply based on the idea of treating each instance point as a\npseudo-pair. Experiments on 14 real-word large-scale data sets demonstrate that\nthe proposed algorithm of Active Sampling within CRC, when coupled with a\nlinear Support Vector Machine, usually outperforms state-of-the-art point-wise\nand pair-wise ranking approaches in terms of both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 09:43:17 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Shen", "Wei-Yuan", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1708.07347", "submitter": "Sebastian Heinz", "authors": "Sebastian Heinz, Christian Bracher, Roland Vollgraf", "title": "An LSTM-Based Dynamic Customer Model for Fashion Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online fashion sales present a challenging use case for personalized\nrecommendation: Stores offer a huge variety of items in multiple sizes. Small\nstocks, high return rates, seasonality, and changing trends cause continuous\nturnover of articles for sale on all time scales. Customers tend to shop\nrarely, but often buy multiple items at once. We report on backtest experiments\nwith sales data of 100k frequent shoppers at Zalando, Europe's leading online\nfashion platform. To model changing customer and store environments, our\nrecommendation method employs a pair of neural networks: To overcome the cold\nstart problem, a feedforward network generates article embeddings in \"fashion\nspace,\" which serve as input to a recurrent neural network that predicts a\nstyle vector in this space for each client, based on their past purchase\nsequence. We compare our results with a static collaborative filtering\napproach, and a popularity ranking baseline.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 10:35:24 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Heinz", "Sebastian", ""], ["Bracher", "Christian", ""], ["Vollgraf", "Roland", ""]]}, {"id": "1708.07367", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Aryeh Kontorovich, David A. Levin, Yuval Peres, Csaba\n  Szepesv\\'ari", "title": "Mixing time estimation in reversible Markov chains from a single sample\n  path", "comments": "34 pages, merges results of arXiv:1506.02903 and arXiv:1612.05330", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spectral gap $\\gamma$ of a finite, ergodic, and reversible Markov chain\nis an important parameter measuring the asymptotic rate of convergence. In\napplications, the transition matrix $P$ may be unknown, yet one sample of the\nchain up to a fixed time $n$ may be observed. We consider here the problem of\nestimating $\\gamma$ from this data. Let $\\pi$ be the stationary distribution of\n$P$, and $\\pi_\\star = \\min_x \\pi(x)$. We show that if $n =\n\\tilde{O}\\bigl(\\frac{1}{\\gamma \\pi_\\star}\\bigr)$, then $\\gamma$ can be\nestimated to within multiplicative constants with high probability. When $\\pi$\nis uniform on $d$ states, this matches (up to logarithmic correction) a lower\nbound of $\\tilde{\\Omega}\\bigl(\\frac{d}{\\gamma}\\bigr)$ steps required for\nprecise estimation of $\\gamma$. Moreover, we provide the first procedure for\ncomputing a fully data-dependent interval, from a single finite-length\ntrajectory of the chain, that traps the mixing time $t_{\\text{mix}}$ of the\nchain at a prescribed confidence level. The interval does not require the\nknowledge of any parameters of the chain. This stands in contrast to previous\napproaches, which either only provide point estimates, or require a reset\nmechanism, or additional prior knowledge. The interval is constructed around\nthe relaxation time $t_{\\text{relax}} = 1/\\gamma$, which is strongly related to\nthe mixing time, and the width of the interval converges to zero roughly at a\n$1/\\sqrt{n}$ rate, where $n$ is the length of the sample path.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 12:05:11 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Hsu", "Daniel", ""], ["Kontorovich", "Aryeh", ""], ["Levin", "David A.", ""], ["Peres", "Yuval", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1708.07436", "submitter": "Th\\^ong Nguy\\^en", "authors": "Th\\^ong T. Nguy\\^en and Siu Cheung Hui", "title": "Differentially Private Regression for Discrete-Time Survival Analysis", "comments": "19 pages, CIKM17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In survival analysis, regression models are used to understand the effects of\nexplanatory variables (e.g., age, sex, weight, etc.) to the survival\nprobability. However, for sensitive survival data such as medical data, there\nare serious concerns about the privacy of individuals in the data set when\nmedical data is used to fit the regression models. The closest work addressing\nsuch privacy concerns is the work on Cox regression which linearly projects the\noriginal data to a lower dimensional space. However, the weakness of this\napproach is that there is no formal privacy guarantee for such projection. In\nthis work, we aim to propose solutions for the regression problem in survival\nanalysis with the protection of differential privacy which is a golden standard\nof privacy protection in data privacy research. To this end, we extend the\nOutput Perturbation and Objective Perturbation approaches which are originally\nproposed to protect differential privacy for the Empirical Risk Minimization\n(ERM) problems. In addition, we also propose a novel sampling approach based on\nthe Markov Chain Monte Carlo (MCMC) method to practically guarantee\ndifferential privacy with better accuracy. We show that our proposed approaches\nachieve good accuracy as compared to the non-private results while guaranteeing\ndifferential privacy for individuals in the private data set.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 14:25:44 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 01:42:35 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Nguy\u00ean", "Th\u00f4ng T.", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1708.07450", "submitter": "Kaihui Liu", "authors": "Zhou Zhou, Kaihui Liu, and Jun Fang", "title": "Bayesian Compressive Sensing Using Normal Product Priors", "comments": null, "journal-ref": "IEEE SIGNAL PROCESSING LETTERS, VOL. 22, NO. 5, MAY 2015", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new sparsity-promoting prior, namely, the\n\"normal product\" prior, and develop an efficient algorithm for sparse signal\nrecovery under the Bayesian framework. The normal product distribution is the\ndistribution of a product of two normally distributed variables with zero means\nand possibly different variances. Like other sparsity-encouraging distributions\nsuch as the Student's $t$-distribution, the normal product distribution has a\nsharp peak at origin, which makes it a suitable prior to encourage sparse\nsolutions. A two-stage normal product-based hierarchical model is proposed. We\nresort to the variational Bayesian (VB) method to perform the inference.\nSimulations are conducted to illustrate the effectiveness of our proposed\nalgorithm as compared with other state-of-the-art compressed sensing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 15:15:22 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Zhou", "Zhou", ""], ["Liu", "Kaihui", ""], ["Fang", "Jun", ""]]}, {"id": "1708.07524", "submitter": "Jitong Chen", "authors": "DeLiang Wang and Jitong Chen", "title": "Supervised Speech Separation Based on Deep Learning: An Overview", "comments": "27 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech separation is the task of separating target speech from background\ninterference. Traditionally, speech separation is studied as a signal\nprocessing problem. A more recent approach formulates speech separation as a\nsupervised learning problem, where the discriminative patterns of speech,\nspeakers, and background noise are learned from training data. Over the past\ndecade, many supervised separation algorithms have been put forward. In\nparticular, the recent introduction of deep learning to supervised speech\nseparation has dramatically accelerated progress and boosted separation\nperformance. This article provides a comprehensive overview of the research on\ndeep learning based supervised speech separation in the last several years. We\nfirst introduce the background of speech separation and the formulation of\nsupervised separation. Then we discuss three main components of supervised\nseparation: learning machines, training targets, and acoustic features. Much of\nthe overview is on separation algorithms where we review monaural methods,\nincluding speech enhancement (speech-nonspeech separation), speaker separation\n(multi-talker separation), and speech dereverberation, as well as\nmulti-microphone techniques. The important issue of generalization, unique to\nsupervised learning, is discussed. This overview provides a historical\nperspective on how advances are made. In addition, we discuss a number of\nconceptual issues, including what constitutes the target source.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 18:51:50 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 03:28:26 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Wang", "DeLiang", ""], ["Chen", "Jitong", ""]]}, {"id": "1708.07581", "submitter": "Francois Petitjean Ph.D.", "authors": "Francois Petitjean, Wray Buntine, Geoffrey I. Webb and Nayyar Zaidi", "title": "Accurate parameter estimation for Bayesian Network Classifiers using\n  Hierarchical Dirichlet Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel parameter estimation method for the probability\ntables of Bayesian network classifiers (BNCs), using hierarchical Dirichlet\nprocesses (HDPs). The main result of this paper is to show that improved\nparameter estimation allows BNCs to outperform leading learning methods such as\nRandom Forest for both 0-1 loss and RMSE, albeit just on categorical datasets.\n  As data assets become larger, entering the hyped world of \"big\", efficient\naccurate classification requires three main elements: (1) classifiers with\nlow-bias that can capture the fine-detail of large datasets (2) out-of-core\nlearners that can learn from data without having to hold it all in main memory\nand (3) models that can classify new data very efficiently.\n  The latest Bayesian network classifiers (BNCs) satisfy these requirements.\nTheir bias can be controlled easily by increasing the number of parents of the\nnodes in the graph. Their structure can be learned out of core with a limited\nnumber of passes over the data. However, as the bias is made lower to\naccurately model classification tasks, so is the accuracy of their parameters'\nestimates, as each parameter is estimated from ever decreasing quantities of\ndata. In this paper, we introduce the use of Hierarchical Dirichlet Processes\nfor accurate BNC parameter estimation.\n  We conduct an extensive set of experiments on 68 standard datasets and\ndemonstrate that our resulting classifiers perform very competitively with\nRandom Forest in terms of prediction, while keeping the out-of-core capability\nand superior classification time.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 00:20:49 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 22:30:15 GMT"}, {"version": "v3", "created": "Tue, 8 May 2018 12:18:12 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Petitjean", "Francois", ""], ["Buntine", "Wray", ""], ["Webb", "Geoffrey I.", ""], ["Zaidi", "Nayyar", ""]]}, {"id": "1708.07644", "submitter": "Jean-Luc Meunier", "authors": "Jean-Luc Meunier", "title": "Joint Structured Learning and Predictions under Logical Constraints in\n  Conditional Random Fields", "comments": "CAp 2017 (Conf\\'erence sur l'Apprentissage automatique)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with structured machine learning, in a supervised\nmachine learning context. It discusses how to make joint structured learning on\ninterdependent objects of different nature, as well as how to enforce logical\ncon-straints when predicting labels. We explain how this need arose in a\nDocument Understanding task. We then discuss a general extension to Conditional\nRandom Field (CRF) for this purpose and present the contributed open source\nimplementation on top of the open source PyStruct library. We evaluate its\nperformance on a publicly available dataset.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 08:14:22 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Meunier", "Jean-Luc", ""]]}, {"id": "1708.07689", "submitter": "Sebastian Lapuschkin", "authors": "Sebastian Lapuschkin, Alexander Binder, Klaus-Robert M\\\"uller,\n  Wojciech Samek", "title": "Understanding and Comparing Deep Neural Networks for Age and Gender\n  Classification", "comments": "8 pages, 5 figures, 5 tables. Presented at ICCV 2017 Workshop: 7th\n  IEEE International Workshop on Analysis and Modeling of Faces and Gestures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have demonstrated excellent performances in\nrecognizing the age and gender on human face images. However, these models were\napplied in a black-box manner with no information provided about which facial\nfeatures are actually used for prediction and how these features depend on\nimage preprocessing, model initialization and architecture choice. We present a\nstudy investigating these different effects.\n  In detail, our work compares four popular neural network architectures,\nstudies the effect of pretraining, evaluates the robustness of the considered\nalignment preprocessings via cross-method test set swapping and intuitively\nvisualizes the model's prediction strategies in given preprocessing conditions\nusing the recent Layer-wise Relevance Propagation (LRP) algorithm. Our\nevaluations on the challenging Adience benchmark show that suitable parameter\ninitialization leads to a holistic perception of the input, compensating\nartefactual data representations. With a combination of simple preprocessing\nsteps, we reach state of the art performance in gender recognition.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 11:08:38 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Lapuschkin", "Sebastian", ""], ["Binder", "Alexander", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1708.07738", "submitter": "Kun Li", "authors": "Kun Li, Joel W. Burdick", "title": "A Function Approximation Method for Model-based High-Dimensional Inverse\n  Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1707.09394", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works handles the inverse reinforcement learning problem in\nhigh-dimensional state spaces, which relies on an efficient solution of\nmodel-based high-dimensional reinforcement learning problems. To solve the\ncomputationally expensive reinforcement learning problems, we propose a\nfunction approximation method to ensure that the Bellman Optimality Equation\nalways holds, and then estimate a function based on the observed human actions\nfor inverse reinforcement learning problems. The time complexity of the\nproposed method is linearly proportional to the cardinality of the action set,\nthus it can handle high-dimensional even continuous state spaces efficiently.\nWe test the proposed method in a simulated environment to show its accuracy,\nand three clinical tasks to show how it can be used to evaluate a doctor's\nproficiency.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 20:25:01 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Li", "Kun", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1708.07747", "submitter": "Han Xiao", "authors": "Han Xiao, Kashif Rasul, Roland Vollgraf", "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n  Algorithms", "comments": "Dataset is freely available at\n  https://github.com/zalandoresearch/fashion-mnist Benchmark is available at\n  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images\nof 70,000 fashion products from 10 categories, with 7,000 images per category.\nThe training set has 60,000 images and the test set has 10,000 images.\nFashion-MNIST is intended to serve as a direct drop-in replacement for the\noriginal MNIST dataset for benchmarking machine learning algorithms, as it\nshares the same image size, data format and the structure of training and\ntesting splits. The dataset is freely available at\nhttps://github.com/zalandoresearch/fashion-mnist\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 14:01:29 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 21:29:49 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Xiao", "Han", ""], ["Rasul", "Kashif", ""], ["Vollgraf", "Roland", ""]]}, {"id": "1708.07807", "submitter": "Ting Wang", "authors": "Xinyang Zhang, Yujie Ji and Ting Wang", "title": "Modular Learning Component Attacks: Today's Reality, Tomorrow's\n  Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of today's machine learning (ML) systems are not built from scratch, but\nare compositions of an array of {\\em modular learning components} (MLCs). The\nincreasing use of MLCs significantly simplifies the ML system development\ncycles. However, as most MLCs are contributed and maintained by third parties,\ntheir lack of standardization and regulation entails profound security\nimplications.\n  In this paper, for the first time, we demonstrate that potentially harmful\nMLCs pose immense threats to the security of ML systems. We present a broad\nclass of {\\em logic-bomb} attacks in which maliciously crafted MLCs trigger\nhost systems to malfunction in a predictable manner. By empirically studying\ntwo state-of-the-art ML systems in the healthcare domain, we explore the\nfeasibility of such attacks. For example, we show that, without prior knowledge\nabout the host ML system, by modifying only 3.3{\\textperthousand} of the MLC's\nparameters, each with distortion below $10^{-3}$, the adversary is able to\nforce the misdiagnosis of target victims' skin cancers with 100\\% success rate.\nWe provide analytical justification for the success of such attacks, which\npoints to the fundamental characteristics of today's ML models: high\ndimensionality, non-linearity, and non-convexity. The issue thus seems\nfundamental to many ML systems. We further discuss potential countermeasures to\nmitigate MLC-based attacks and their potential technical challenges.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 16:48:54 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Zhang", "Xinyang", ""], ["Ji", "Yujie", ""], ["Wang", "Ting", ""]]}, {"id": "1708.07827", "submitter": "Peng Xu", "authors": "Peng Xu, Farbod Roosta-Khorasani, Michael W. Mahoney", "title": "Second-Order Optimization for Non-Convex Machine Learning: An Empirical\n  Study", "comments": "21 pages, 11 figures. Restructure the paper and add experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While first-order optimization methods such as stochastic gradient descent\n(SGD) are popular in machine learning (ML), they come with well-known\ndeficiencies, including relatively-slow convergence, sensitivity to the\nsettings of hyper-parameters such as learning rate, stagnation at high training\nerrors, and difficulty in escaping flat regions and saddle points. These issues\nare particularly acute in highly non-convex settings such as those arising in\nneural networks. Motivated by this, there has been recent interest in\nsecond-order methods that aim to alleviate these shortcomings by capturing\ncurvature information. In this paper, we report detailed empirical evaluations\nof a class of Newton-type methods, namely sub-sampled variants of trust region\n(TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex\nML problems. In doing so, we demonstrate that these methods not only can be\ncomputationally competitive with hand-tuned SGD with momentum, obtaining\ncomparable or better generalization performance, but also they are highly\nrobust to hyper-parameter settings. Further, in contrast to SGD with momentum,\nwe show that the manner in which these Newton-type methods employ curvature\ninformation allows them to seamlessly escape flat regions and saddle points.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 01:33:15 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 00:57:22 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Xu", "Peng", ""], ["Roosta-Khorasani", "Farbod", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1708.07850", "submitter": "Benjamin Haeffele", "authors": "Benjamin D. Haeffele and Rene Vidal", "title": "Structured Low-Rank Matrix Factorization: Global Optimality, Algorithms,\n  and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, convex formulations of low-rank matrix factorization problems have\nreceived considerable attention in machine learning. However, such formulations\noften require solving for a matrix of the size of the data matrix, making it\nchallenging to apply them to large scale datasets. Moreover, in many\napplications the data can display structures beyond simply being low-rank,\ne.g., images and videos present complex spatio-temporal structures that are\nlargely ignored by standard low-rank methods. In this paper we study a matrix\nfactorization technique that is suitable for large datasets and captures\nadditional structure in the factors by using a particular form of\nregularization that includes well-known regularizers such as total variation\nand the nuclear norm as particular cases. Although the resulting optimization\nproblem is non-convex, we show that if the size of the factors is large enough,\nunder certain conditions, any local minimizer for the factors yields a global\nminimizer. A few practical algorithms are also provided to solve the matrix\nfactorization problem, and bounds on the distance from a given approximate\nsolution of the optimization problem to the global optimum are derived.\nExamples in neural calcium imaging video segmentation and hyperspectral\ncompressed recovery show the advantages of our approach on high-dimensional\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 18:14:44 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Haeffele", "Benjamin D.", ""], ["Vidal", "Rene", ""]]}, {"id": "1708.07888", "submitter": "Wei Chen", "authors": "Wei Chen, Mark Fuge", "title": "Active Expansion Sampling for Learning Feasible Domains in an Unbounded\n  Input Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many engineering problems require identifying feasible domains under implicit\nconstraints. One example is finding acceptable car body styling designs based\non constraints like aesthetics and functionality. Current active-learning based\nmethods learn feasible domains for bounded input spaces. However, we usually\nlack prior knowledge about how to set those input variable bounds. Bounds that\nare too small will fail to cover all feasible domains; while bounds that are\ntoo large will waste query budget. To avoid this problem, we introduce Active\nExpansion Sampling (AES), a method that identifies (possibly disconnected)\nfeasible domains over an unbounded input space. AES progressively expands our\nknowledge of the input space, and uses successive exploitation and exploration\nstages to switch between learning the decision boundary and searching for new\nfeasible domains. We show that AES has a misclassification loss guarantee\nwithin the explored region, independent of the number of iterations or labeled\nsamples. Thus it can be used for real-time prediction of samples' feasibility\nwithin the explored region. We evaluate AES on three test examples and compare\nAES with two adaptive sampling methods -- the Neighborhood-Voronoi algorithm\nand the straddle heuristic -- that operate over fixed input variable bounds.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 21:12:40 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 22:19:23 GMT"}, {"version": "v3", "created": "Sat, 20 Jan 2018 19:29:56 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Chen", "Wei", ""], ["Fuge", "Mark", ""]]}, {"id": "1708.07918", "submitter": "Mo Yu", "authors": "Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Gerald\n  Tesauro, Haoyu Wang, Bowen Zhou", "title": "Robust Task Clustering for Deep Many-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate task clustering for deep-learning based multi-task and\nfew-shot learning in a many-task setting. We propose a new method to measure\ntask similarities with cross-task transfer performance matrix for the deep\nlearning scenario. Although this matrix provides us critical information\nregarding similarity between tasks, its asymmetric property and unreliable\nperformance scores can affect conventional clustering methods adversely.\nAdditionally, the uncertain task-pairs, i.e., the ones with extremely\nasymmetric transfer scores, may collectively mislead clustering algorithms to\noutput an inaccurate task-partition. To overcome these limitations, we propose\na novel task-clustering algorithm by using the matrix completion technique. The\nproposed algorithm constructs a partially-observed similarity matrix based on\nthe certainty of cluster membership of the task-pairs. We then use a matrix\ncompletion algorithm to complete the similarity matrix. Our theoretical\nanalysis shows that under mild constraints, the proposed algorithm will\nperfectly recover the underlying \"true\" similarity matrix with a high\nprobability. Our results show that the new task clustering method can discover\ntask clusters for training flexible and superior neural network models in a\nmulti-task learning setup for sentiment classification and dialog intent\nclassification tasks. Our task clustering approach also extends metric-based\nfew-shot learning methods to adapt multiple metrics, which demonstrates\nempirical advantages when the tasks are diverse.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 02:29:50 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:53:48 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Yi", "Jinfeng", ""], ["Chang", "Shiyu", ""], ["Potdar", "Saloni", ""], ["Tesauro", "Gerald", ""], ["Wang", "Haoyu", ""], ["Zhou", "Bowen", ""]]}, {"id": "1708.07942", "submitter": "Minh Nguyen", "authors": "Minh Nguyen, Sanjay Purushotham, Hien To, Cyrus Shahabi", "title": "m-TSNE: A Framework for Visualizing High-Dimensional Multivariate Time\n  Series", "comments": "VAHC2016 Workshop on Visual Analytics in Healthcare in conjunction\n  with AMIA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) have become increasingly common in healthcare\ndomains where human vital signs and laboratory results are collected for\npredictive diagnosis. Recently, there have been increasing efforts to visualize\nhealthcare MTS data based on star charts or parallel coordinates. However, such\ntechniques might not be ideal for visualizing a large MTS dataset, since it is\ndifficult to obtain insights or interpretations due to the inherent high\ndimensionality of MTS. In this paper, we propose 'm-TSNE': a simple and novel\nframework to visualize high-dimensional MTS data by projecting them into a\nlow-dimensional (2-D or 3-D) space while capturing the underlying data\nproperties. Our framework is easy to use and provides interpretable insights\nfor healthcare professionals to understand MTS data. We evaluate our\nvisualization framework on two real-world datasets and demonstrate that the\nresults of our m-TSNE show patterns that are easy to understand while the other\nmethods' visualization may have limitations in interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 07:21:58 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Nguyen", "Minh", ""], ["Purushotham", "Sanjay", ""], ["To", "Hien", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1708.07946", "submitter": "Kui Zhao", "authors": "Kui Zhao, Can Wang", "title": "Sales Forecast in E-commerce using Convolutional Neural Network", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sales forecast is an essential task in E-commerce and has a crucial impact on\nmaking informed business decisions. It can help us to manage the workforce,\ncash flow and resources such as optimizing the supply chain of manufacturers\netc. Sales forecast is a challenging problem in that sales is affected by many\nfactors including promotion activities, price changes, and user preferences\netc. Traditional sales forecast techniques mainly rely on historical sales data\nto predict future sales and their accuracies are limited. Some more recent\nlearning-based methods capture more information in the model to improve the\nforecast accuracy. However, these methods require case-by-case manual feature\nengineering for specific commercial scenarios, which is usually a difficult,\ntime-consuming task and requires expert knowledge. To overcome the limitations\nof existing methods, we propose a novel approach in this paper to learn\neffective features automatically from the structured data using the\nConvolutional Neural Network (CNN). When fed with raw log data, our approach\ncan automatically extract effective features from that and then forecast sales\nusing those extracted features. We test our method on a large real-world\ndataset from CaiNiao.com and the experimental results validate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 07:47:15 GMT"}], "update_date": "2017-09-02", "authors_parsed": [["Zhao", "Kui", ""], ["Wang", "Can", ""]]}, {"id": "1708.07967", "submitter": "Shuchin Aeron", "authors": "Brian Rappaport, Anuththari Gamage, Shuchin Aeron", "title": "Faster Clustering via Non-Backtracking Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents VEC-NBT, a variation on the unsupervised graph clustering\ntechnique VEC, which improves upon the performance of the original algorithm\nsignificantly for sparse graphs. VEC employs a novel application of the\nstate-of-the-art word2vec model to embed a graph in Euclidean space via random\nwalks on the nodes of the graph. In VEC-NBT, we modify the original algorithm\nto use a non-backtracking random walk instead of the normal backtracking random\nwalk used in VEC. We introduce a modification to a non-backtracking random\nwalk, which we call a begrudgingly-backtracking random walk, and show\nempirically that using this model of random walks for VEC-NBT requires shorter\nwalks on the graph to obtain results with comparable or greater accuracy than\nVEC, especially for sparser graphs.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 13:40:22 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Rappaport", "Brian", ""], ["Gamage", "Anuththari", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1708.07969", "submitter": "Bo Yang", "authors": "Bo Yang, Hongkai Wen, Sen Wang, Ronald Clark, Andrew Markham, Niki\n  Trigoni", "title": "3D Object Reconstruction from a Single Depth View with Adversarial\n  Learning", "comments": "ICCV Workshops 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel 3D-RecGAN approach, which reconstructs the\ncomplete 3D structure of a given object from a single arbitrary depth view\nusing generative adversarial networks. Unlike the existing work which typically\nrequires multiple views of the same object or class labels to recover the full\n3D geometry, the proposed 3D-RecGAN only takes the voxel grid representation of\na depth view of the object as input, and is able to generate the complete 3D\noccupancy grid by filling in the occluded/missing regions. The key idea is to\ncombine the generative capabilities of autoencoders and the conditional\nGenerative Adversarial Networks (GAN) framework, to infer accurate and\nfine-grained 3D structures of objects in high-dimensional voxel space.\nExtensive experiments on large synthetic datasets show that the proposed\n3D-RecGAN significantly outperforms the state of the art in single view 3D\nobject reconstruction, and is able to reconstruct unseen types of objects. Our\ncode and data are available at: https://github.com/Yang7879/3D-RecGAN.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 13:46:21 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Yang", "Bo", ""], ["Wen", "Hongkai", ""], ["Wang", "Sen", ""], ["Clark", "Ronald", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1708.07975", "submitter": "Vincent Bindschaedler", "authors": "Vincent Bindschaedler, Reza Shokri, Carl A. Gunter", "title": "Plausible Deniability for Privacy-Preserving Data Synthesis", "comments": "In PVLDB 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Releasing full data records is one of the most challenging problems in data\nprivacy. On the one hand, many of the popular techniques such as data\nde-identification are problematic because of their dependence on the background\nknowledge of adversaries. On the other hand, rigorous methods such as the\nexponential mechanism for differential privacy are often computationally\nimpractical to use for releasing high dimensional data or cannot preserve high\nutility of original data due to their extensive data perturbation.\n  This paper presents a criterion called plausible deniability that provides a\nformal privacy guarantee, notably for releasing sensitive datasets: an output\nrecord can be released only if a certain amount of input records are\nindistinguishable, up to a privacy parameter. This notion does not depend on\nthe background knowledge of an adversary. Also, it can efficiently be checked\nby privacy tests. We present mechanisms to generate synthetic datasets with\nsimilar statistical properties to the input data and the same format. We study\nthis technique both theoretically and experimentally. A key theoretical result\nshows that, with proper randomization, the plausible deniability mechanism\ngenerates differentially private synthetic data. We demonstrate the efficiency\nof this generative technique on a large dataset; it is shown to preserve the\nutility of original data with respect to various statistical analysis and\nmachine learning measures.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 14:13:28 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Bindschaedler", "Vincent", ""], ["Shokri", "Reza", ""], ["Gunter", "Carl A.", ""]]}, {"id": "1708.08012", "submitter": "Robin Tibor Schirrmeister", "authors": "Robin Tibor Schirrmeister, Lukas Gemein, Katharina Eggensperger, Frank\n  Hutter, Tonio Ball", "title": "Deep learning with convolutional neural networks for decoding and\n  visualization of EEG pathology", "comments": "Published at IEEE SPMB 2017 https://www.ieeespmb.org/2017/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply convolutional neural networks (ConvNets) to the task of\ndistinguishing pathological from normal EEG recordings in the Temple University\nHospital EEG Abnormal Corpus. We use two basic, shallow and deep ConvNet\narchitectures recently shown to decode task-related information from EEG at\nleast as well as established algorithms designed for this purpose. In decoding\nEEG pathology, both ConvNets reached substantially better accuracies (about 6%\nbetter, ~85% vs. ~79%) than the only published result for this dataset, and\nwere still better when using only 1 minute of each recording for training and\nonly six seconds of each recording for testing. We used automated methods to\noptimize architectural hyperparameters and found intriguingly different ConvNet\narchitectures, e.g., with max pooling as the only nonlinearity. Visualizations\nof the ConvNet decoding behavior showed that they used spectral power changes\nin the delta (0-4 Hz) and theta (4-8 Hz) frequency range, possibly alongside\nother features, consistent with expectations derived from spectral analysis of\nthe EEG data and from the textual medical reports. Analysis of the textual\nmedical reports also highlighted the potential for accuracy increases by\nintegrating contextual information, such as the age of subjects. In summary,\nthe ConvNets and visualization techniques used in this study constitute a next\nstep towards clinically useful automated EEG diagnosis and establish a new\nbaseline for future work on this topic.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 19:14:47 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 14:56:40 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 20:11:04 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Schirrmeister", "Robin Tibor", ""], ["Gemein", "Lukas", ""], ["Eggensperger", "Katharina", ""], ["Hutter", "Frank", ""], ["Ball", "Tonio", ""]]}, {"id": "1708.08022", "submitter": "Ilya Mironov", "authors": "Mart\\'in Abadi, \\'Ulfar Erlingsson, Ian Goodfellow, H. Brendan\n  McMahan, Ilya Mironov, Nicolas Papernot, Kunal Talwar, Li Zhang", "title": "On the Protection of Private Information in Machine Learning Systems:\n  Two Recent Approaches", "comments": null, "journal-ref": "IEEE 30th Computer Security Foundations Symposium (CSF), pages\n  1--6, 2017", "doi": "10.1109/CSF.2017.10", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent, remarkable growth of machine learning has led to intense interest\nin the privacy of the data on which machine learning relies, and to new\ntechniques for preserving privacy. However, older ideas about privacy may well\nremain valid and useful. This note reviews two recent works on privacy in the\nlight of the wisdom of some of the early literature, in particular the\nprinciples distilled by Saltzer and Schroeder in the 1970s.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 23:23:39 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Abadi", "Mart\u00edn", ""], ["Erlingsson", "\u00dalfar", ""], ["Goodfellow", "Ian", ""], ["McMahan", "H. Brendan", ""], ["Mironov", "Ilya", ""], ["Papernot", "Nicolas", ""], ["Talwar", "Kunal", ""], ["Zhang", "Li", ""]]}, {"id": "1708.08042", "submitter": "Songqing Yue", "authors": "Songqing Yue", "title": "Imbalanced Malware Images Classification: a CNN based Approach", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) can be applied to malware binary\ndetection through images classification. The performance, however, is degraded\ndue to the imbalance of malware families (classes). To mitigate this issue, we\npropose a simple yet effective weighted softmax loss which can be employed as\nthe final layer of deep CNNs. The original softmax loss is weighted, and the\nweight value can be determined according to class size. A scaling parameter is\nalso included in computing the weight. Proper selection of this parameter has\nbeen studied and an empirical option is given. The weighted loss aims at\nalleviating the impact of data imbalance in an end-to-end learning fashion. To\nvalidate the efficacy, we deploy the proposed weighted loss in a pre-trained\ndeep CNN model and fine-tune it to achieve promising results on malware images\nclassification. Extensive experiments also indicate that the new loss function\ncan fit other typical CNNs with an improved classification performance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 02:27:59 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Yue", "Songqing", ""]]}, {"id": "1708.08053", "submitter": "Pelumi Oluwasanya", "authors": "Pelumi Oluwasanya", "title": "Anomaly Detection in Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wireless sensor networks usually comprise a large number of sensors\nmonitoring changes in variables. These changes in variables represent changes\nin physical quantities. The changes can occur for various reasons; these\nreasons are highlighted in this work. Outliers are unusual measurements.\nOutliers are important; they are information-bearing occurrences. This work\nseeks to identify them based on an approach presented in [1]. A critical review\nof most previous works in this area has been presented in [2], and few more are\nconsidered here just to set the stage. The main work can be described as this;\ngiven a set of measurements from sensors that represent a normal situation, [1]\nproceeds by first estimating the probability density function (pdf) of the set\nusing a data-split approach, then estimate the entropy of the set using the\narithmetic mean as an approximation for the expectation. The increase in\nentropy that occurs when strange data is recorded is used to detect unusual\nmeasurements in the test set depending on the desired confidence interval or\nfalse alarm rate. The results presented in [1] have been confirmed for\ndifferent test signals such as the Gaussian, Beta, in one dimension and beta in\ntwo dimensions, and a beta and uniform mixture distribution in two dimensions.\nFinally, the method was confirmed on real data and the results are presented.\nThe major drawbacks of [1] were identified, and a method that seeks to mitigate\nthis using the Bhattacharyya distance is presented. This method detects more\nsubtle anomalies, especially the type that would pass as normal in [1].\nFinally, recommendations for future research are presented: the subject of\ninterpretability, especially for subtle measurements, being the most elusive as\nof today.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 05:39:17 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Oluwasanya", "Pelumi", ""]]}, {"id": "1708.08079", "submitter": "Richard Oentaryo", "authors": "Truc Viet Le, Richard J. Oentaryo, Siyuan Liu, Hoong Chuin Lau", "title": "Local Gaussian Processes for Efficient Fine-Grained Traffic Speed\n  Prediction", "comments": null, "journal-ref": "IEEE Transactions on Big Data, vol. 3, no. 2, pp. 194-207, 2017", "doi": "10.1109/TBDATA.2016.2620488", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic speed is a key indicator for the efficiency of an urban\ntransportation system. Accurate modeling of the spatiotemporally varying\ntraffic speed thus plays a crucial role in urban planning and development. This\npaper addresses the problem of efficient fine-grained traffic speed prediction\nusing big traffic data obtained from static sensors. Gaussian processes (GPs)\nhave been previously used to model various traffic phenomena, including flow\nand speed. However, GPs do not scale with big traffic data due to their cubic\ntime complexity. In this work, we address their efficiency issues by proposing\nlocal GPs to learn from and make predictions for correlated subsets of data.\nThe main idea is to quickly group speed variables in both spatial and temporal\ndimensions into a finite number of clusters, so that future and unobserved\ntraffic speed queries can be heuristically mapped to one of such clusters. A\nlocal GP corresponding to that cluster can then be trained on the fly to make\npredictions in real-time. We call this method localization. We use non-negative\nmatrix factorization for localization and propose simple heuristics for cluster\nmapping. We additionally leverage on the expressiveness of GP kernel functions\nto model road network topology and incorporate side information. Extensive\nexperiments using real-world traffic data collected in the two U.S. cities of\nPittsburgh and Washington, D.C., show that our proposed local GPs significantly\nimprove both runtime performances and prediction accuracies compared to the\nbaseline global and local GPs.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 11:41:16 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Le", "Truc Viet", ""], ["Oentaryo", "Richard J.", ""], ["Liu", "Siyuan", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1708.08081", "submitter": "Martin Grohe", "authors": "Martin Grohe and Christof L\\\"oding and Martin Ritzert", "title": "Learning MSO-definable hypotheses on string", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classification problems over string data for hypotheses\nspecified by formulas of monadic second-order logic MSO. The goal is to design\nlearning algorithms that run in time polynomial in the size of the training\nset, independently of or at least sublinear in the size of the whole data set.\nWe prove negative as well as positive results. If the data set is an\nunprocessed string to which our algorithms have local access, then learning in\nsublinear time is impossible even for hypotheses definable in a small fragment\nof first-order logic. If we allow for a linear time pre-processing of the\nstring data to build an index data structure, then learning of MSO-definable\nhypotheses is possible in time polynomial in the size of the training set,\nindependently of the size of the whole data set.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 11:47:57 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Grohe", "Martin", ""], ["L\u00f6ding", "Christof", ""], ["Ritzert", "Martin", ""]]}, {"id": "1708.08136", "submitter": "Timothy La Fond", "authors": "Timothy La Fond, Geoffrey Sanders, Christine Klymko, Van Emden Henson", "title": "An Ensemble Framework for Detecting Community Changes in Dynamic\n  Networks", "comments": "6 pages, under submission to HPEC Graph Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic networks, especially those representing social networks, undergo\nconstant evolution of their community structure over time. Nodes can migrate\nbetween different communities, communities can split into multiple new\ncommunities, communities can merge together, etc. In order to represent dynamic\nnetworks with evolving communities it is essential to use a dynamic model\nrather than a static one. Here we use a dynamic stochastic block model where\nthe underlying block model is different at different times. In order to\nrepresent the structural changes expressed by this dynamic model the network\nwill be split into discrete time segments and a clustering algorithm will\nassign block memberships for each segment. In this paper we show that using an\nensemble of clustering assignments accommodates for the variance in scalable\nclustering algorithms and produces superior results in terms of\npairwise-precision and pairwise-recall. We also demonstrate that the dynamic\nclustering produced by the ensemble can be visualized as a flowchart which\nencapsulates the community evolution succinctly.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 23:59:17 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["La Fond", "Timothy", ""], ["Sanders", "Geoffrey", ""], ["Klymko", "Christine", ""], ["Henson", "Van Emden", ""]]}, {"id": "1708.08142", "submitter": "Rodrigo de Lamare", "authors": "R. C. de Lamare and Andr\\'e Flores", "title": "Study of Set-Membership Kernel Adaptive Algorithms and Applications", "comments": "4 figures, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive algorithms based on kernel structures have been a topic of\nsignificant research over the past few years. The main advantage is that they\nform a family of universal approximators, offering an elegant solution to\nproblems with nonlinearities. Nevertheless these methods deal with kernel\nexpansions, creating a growing structure also known as dictionary, whose size\ndepends on the number of new inputs. In this paper we derive the set-membership\nkernel-based normalized least-mean square (SM-NKLMS) algorithm, which is\ncapable of limiting the size of the dictionary created in stationary\nenvironments. We also derive as an extension the set-membership kernelized\naffine projection (SM-KAP) algorithm. Finally several experiments are presented\nto compare the proposed SM-NKLMS and SM-KAP algorithms to the existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 21:41:48 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["de Lamare", "R. C.", ""], ["Flores", "Andr\u00e9", ""]]}, {"id": "1708.08155", "submitter": "Waheed Bajwa", "authors": "Zhixiong Yang and Waheed U. Bajwa", "title": "ByRDiE: Byzantine-resilient distributed coordinate descent for\n  decentralized learning", "comments": "Preprint of a paper accepted into IEEE Transactions on Signal and\n  Information Processing Over Networks; 16 pages, 5 figures, and 1 table", "journal-ref": "IEEE Trans. Signal Inform. Proc. over Netw., vol. 5, no. 4, pp.\n  611-627, Dec. 2019", "doi": "10.1109/TSIPN.2019.2928176", "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning algorithms enable learning of models from\ndatasets that are distributed over a network without gathering the data at a\ncentralized location. While efficient distributed algorithms have been\ndeveloped under the assumption of faultless networks, failures that can render\nthese algorithms nonfunctional occur frequently in the real world. This paper\nfocuses on the problem of Byzantine failures, which are the hardest to\nsafeguard against in distributed algorithms. While Byzantine fault tolerance\nhas a rich history, existing work does not translate into efficient and\npractical algorithms for high-dimensional learning in fully distributed (also\nknown as decentralized) settings. In this paper, an algorithm termed\nByzantine-resilient distributed coordinate descent (ByRDiE) is developed and\nanalyzed that enables distributed learning in the presence of Byzantine\nfailures. Theoretical analysis (convex settings) and numerical experiments\n(convex and nonconvex settings) highlight its usefulness for high-dimensional\ndistributed learning in the presence of Byzantine failures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 00:22:18 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 20:29:11 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 15:08:58 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 17:00:42 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Yang", "Zhixiong", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1708.08177", "submitter": "Jun Lu", "authors": "Jun Lu", "title": "Hyperprior on symmetric Dirichlet distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we introduce how to put vague hyperprior on Dirichlet\ndistribution, and we update the parameter of it by adaptive rejection sampling\n(ARS). Finally we analyze this hyperprior in an over-fitted mixture model by\nsome synthetic experiments.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 03:52:40 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Lu", "Jun", ""]]}, {"id": "1708.08227", "submitter": "Mostapha Benhenda", "authors": "Mostapha Benhenda (LAGA)", "title": "ChemGAN challenge for drug discovery: can AI reproduce natural chemical\n  diversity?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating molecules with desired chemical properties is important for drug\ndiscovery. The use of generative neural networks is promising for this task.\nHowever, from visual inspection, it often appears that generated samples lack\ndiversity. In this paper, we quantify this internal chemical diversity, and we\nraise the following challenge: can a nontrivial AI model reproduce natural\nchemical diversity for desired molecules? To illustrate this question, we\nconsider two generative models: a Reinforcement Learning model and the recently\nintroduced ORGAN. Both fail at this challenge. We hope this challenge will\nstimulate research in this direction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 08:02:55 GMT"}, {"version": "v2", "created": "Wed, 30 Aug 2017 09:03:57 GMT"}, {"version": "v3", "created": "Thu, 31 Aug 2017 14:14:29 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Benhenda", "Mostapha", "", "LAGA"]]}, {"id": "1708.08231", "submitter": "Pittipol Kantavat", "authors": "Pittipol Kantavat, Boonserm Kijsirikul, Patoomsiri Songsiri, Ken-ichi\n  Fukui, Masayuki Numao", "title": "Efficient Decision Trees for Multi-class Support Vector Machines Using\n  Entropy and Generalization Error Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new methods for Support Vector Machines (SVMs) using tree\narchitecture for multi-class classi- fication. In each node of the tree, we\nselect an appropriate binary classifier using entropy and generalization error\nestimation, then group the examples into positive and negative classes based on\nthe selected classi- fier and train a new classifier for use in the\nclassification phase. The proposed methods can work in time complexity between\nO(log2N) to O(N) where N is the number of classes. We compared the performance\nof our proposed methods to the traditional techniques on the UCI machine\nlearning repository using 10-fold cross-validation. The experimental results\nshow that our proposed methods are very useful for the problems that need fast\nclassification time or problems with a large number of classes as the proposed\nmethods run much faster than the traditional techniques but still provide\ncomparable accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 08:16:28 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Kantavat", "Pittipol", ""], ["Kijsirikul", "Boonserm", ""], ["Songsiri", "Patoomsiri", ""], ["Fukui", "Ken-ichi", ""], ["Numao", "Masayuki", ""]]}, {"id": "1708.08282", "submitter": "Peng-Bo Zhang", "authors": "Peng-Bo Zhang and Zhi-Xin Yang", "title": "A New Learning Paradigm for Random Vector Functional-Link Network: RVFL+", "comments": "We have updated the previous work", "journal-ref": "Neural Networks 122(2019) 94-105", "doi": "10.1016/j.neunet.2019.09.039", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In school, a teacher plays an important role in various classroom teaching\npatterns. Likewise to this human learning activity, the learning using\nprivileged information (LUPI) paradigm provides additional information\ngenerated by the teacher to 'teach' learning models during the training stage.\nTherefore, this novel learning paradigm is a typical Teacher-Student\nInteraction mechanism. This paper is the first to present a random vector\nfunctional link network based on the LUPI paradigm, called RVFL+. Rather than\nsimply combining two existing approaches, the newly-derived RVFL+ fills the gap\nbetween classical randomized neural networks and the newfashioned LUPI\nparadigm, which offers an alternative way to train RVFL networks. Moreover, the\nproposed RVFL+ can perform in conjunction with the kernel trick for highly\ncomplicated nonlinear feature learning, which is termed KRVFL+. Furthermore,\nthe statistical property of the proposed RVFL+ is investigated, and we present\na sharp and high-quality generalization error bound based on the Rademacher\ncomplexity. Competitive experimental results on 14 real-world datasets\nillustrate the great effectiveness and efficiency of the novel RVFL+ and\nKRVFL+, which can achieve better generalization performance than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 11:55:00 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 10:55:16 GMT"}, {"version": "v3", "created": "Sat, 9 Mar 2019 14:31:36 GMT"}, {"version": "v4", "created": "Sun, 17 Mar 2019 03:40:19 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Peng-Bo", ""], ["Yang", "Zhi-Xin", ""]]}, {"id": "1708.08310", "submitter": "Maria-Irina Nicolae", "authors": "Vincent P.A. Lonij, Ambrish Rawat, Maria-Irina Nicolae", "title": "Open-World Visual Recognition Using Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a real-world setting, visual recognition systems can be brought to make\npredictions for images belonging to previously unknown class labels. In order\nto make semantically meaningful predictions for such inputs, we propose a\ntwo-step approach that utilizes information from knowledge graphs. First, a\nknowledge-graph representation is learned to embed a large set of entities into\na semantic space. Second, an image representation is learned to embed images\ninto the same space. Under this setup, we are able to predict structured\nproperties in the form of relationship triples for any open-world image. This\nis true even when a set of labels has been omitted from the training protocols\nof both the knowledge graph and image embeddings. Furthermore, we append this\nlearning framework with appropriate smoothness constraints and show how prior\nknowledge can be incorporated into the model. Both these improvements combined\nincrease performance for visual recognition by a factor of six compared to our\nbaseline. Finally, we propose a new, extended dataset which we use for\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 13:45:07 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Lonij", "Vincent P. A.", ""], ["Rawat", "Ambrish", ""], ["Nicolae", "Maria-Irina", ""]]}, {"id": "1708.08311", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen and Evaggelia Tsiligianni and Nikos Deligiannis", "title": "Deep Learning Sparse Ternary Projections for Compressed Sensing of\n  Images", "comments": "To appear in GlobalSIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) is a sampling theory that allows reconstruction of\nsparse (or compressible) signals from an incomplete number of measurements,\nusing of a sensing mechanism implemented by an appropriate projection matrix.\nThe CS theory is based on random Gaussian projection matrices, which satisfy\nrecovery guarantees with high probability; however, sparse ternary {0, -1, +1}\nprojections are more suitable for hardware implementation. In this paper, we\npresent a deep learning approach to obtain very sparse ternary projections for\ncompressed sensing. Our deep learning architecture jointly learns a pair of a\nprojection matrix and a reconstruction operator in an end-to-end fashion. The\nexperimental results on real images demonstrate the effectiveness of the\nproposed approach compared to state-of-the-art methods, with significant\nadvantage in terms of complexity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 13:51:09 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1708.08327", "submitter": "Liang Tong", "authors": "Liang Tong, Bo Li, Chen Hajaj, Chaowei Xiao, Ning Zhang, Yevgeniy\n  Vorobeychik", "title": "Improving Robustness of ML Classifiers against Realizable Evasion\n  Attacks Using Conserved Features", "comments": "1. v5.0; 2. To appear at the 28th USENIX Security Symposium, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) techniques are increasingly common in security\napplications, such as malware and intrusion detection. However, ML models are\noften susceptible to evasion attacks, in which an adversary makes changes to\nthe input (such as malware) in order to avoid being detected. A conventional\napproach to evaluate ML robustness to such attacks, as well as to design robust\nML, is by considering simplified feature-space models of attacks, where the\nattacker changes ML features directly to effect evasion, while minimizing or\nconstraining the magnitude of this change. We investigate the effectiveness of\nthis approach to designing robust ML in the face of attacks that can be\nrealized in actual malware (realizable attacks). We demonstrate that in the\ncontext of structure-based PDF malware detection, such techniques appear to\nhave limited effectiveness, but they are effective with content-based\ndetectors. In either case, we show that augmenting the feature space models\nwith conserved features (those that cannot be unilaterally modified without\ncompromising malicious functionality) significantly improves performance.\nFinally, we show that feature space models enable generalized robustness when\nfaced with a variety of realizable attacks, as compared to classifiers which\nare tuned to be robust to a specific realizable attack.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 14:18:35 GMT"}, {"version": "v2", "created": "Sat, 4 Nov 2017 11:33:08 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 21:17:15 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 23:16:01 GMT"}, {"version": "v5", "created": "Fri, 10 May 2019 20:26:47 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Tong", "Liang", ""], ["Li", "Bo", ""], ["Hajaj", "Chen", ""], ["Xiao", "Chaowei", ""], ["Zhang", "Ning", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1708.08333", "submitter": "Jong Chul Ye", "authors": "Yoseob Han and Jong Chul Ye", "title": "Framing U-Net via Deep Convolutional Framelets: Application to\n  Sparse-view CT", "comments": "This will appear in IEEE Transaction on Medical Imaging, a special\n  issue of Machine Learning for Image Reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray computed tomography (CT) using sparse projection views is a recent\napproach to reduce the radiation dose. However, due to the insufficient\nprojection views, an analytic reconstruction approach using the filtered back\nprojection (FBP) produces severe streaking artifacts. Recently, deep learning\napproaches using large receptive field neural networks such as U-Net have\ndemonstrated impressive performance for sparse- view CT reconstruction.\nHowever, theoretical justification is still lacking. Inspired by the recent\ntheory of deep convolutional framelets, the main goal of this paper is,\ntherefore, to reveal the limitation of U-Net and propose new multi-resolution\ndeep learning schemes. In particular, we show that the alternative U- Net\nvariants such as dual frame and the tight frame U-Nets satisfy the so-called\nframe condition which make them better for effective recovery of high frequency\nedges in sparse view- CT. Using extensive experiments with real patient data\nset, we demonstrate that the new network architectures provide better\nreconstruction performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 14:31:50 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 10:04:46 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 07:20:28 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Han", "Yoseob", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1708.08407", "submitter": "Jinbo Xu", "authors": "Sheng Wang, Zhen Li, Yizhou Yu and Jinbo Xu", "title": "Folding membrane proteins by deep transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational elucidation of membrane protein (MP) structures is challenging\npartially due to lack of sufficient solved structures for homology modeling.\nHere we describe a high-throughput deep transfer learning method that first\npredicts MP contacts by learning from non-membrane proteins (non-MPs) and then\npredicting three-dimensional structure models using the predicted contacts as\ndistance restraints. Tested on 510 non-redundant MPs, our method has contact\nprediction accuracy at least 0.18 better than existing methods, predicts\ncorrect folds for 218 MPs (TMscore at least 0.6), and generates\nthree-dimensional models with RMSD less than 4 Angstrom and 5 Angstrom for 57\nand 108 MPs, respectively. A rigorous blind test in the continuous automated\nmodel evaluation (CAMEO) project shows that our method predicted\nhigh-resolution three-dimensional models for two recent test MPs of 210\nresidues with RMSD close to 2 Angstrom. We estimated that our method could\npredict correct folds for between 1,345 and 1,871 reviewed human multi-pass MPs\nincluding a few hundred new folds, which shall facilitate the discovery of\ndrugs targeting at membrane proteins.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 16:38:52 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Wang", "Sheng", ""], ["Li", "Zhen", ""], ["Yu", "Yizhou", ""], ["Xu", "Jinbo", ""]]}, {"id": "1708.08487", "submitter": "Antonia Creswell", "authors": "Antonia Creswell, Kai Arulkumaran, Anil A. Bharath", "title": "On denoising autoencoders trained to minimise binary cross-entropy", "comments": "Submitted to Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising autoencoders (DAEs) are powerful deep learning models used for\nfeature extraction, data generation and network pre-training. DAEs consist of\nan encoder and decoder which may be trained simultaneously to minimise a loss\n(function) between an input and the reconstruction of a corrupted version of\nthe input. There are two common loss functions used for training autoencoders,\nthese include the mean-squared error (MSE) and the binary cross-entropy (BCE).\nWhen training autoencoders on image data a natural choice of loss function is\nBCE, since pixel values may be normalised to take values in [0,1] and the\ndecoder model may be designed to generate samples that take values in (0,1). We\nshow theoretically that DAEs trained to minimise BCE may be used to take\ngradient steps in the data space towards regions of high probability under the\ndata-generating distribution. Previously this had only been shown for DAEs\ntrained using MSE. As a consequence of the theory, iterative application of a\ntrained DAE moves a data sample from regions of low probability to regions of\nhigher probability under the data-generating distribution. Firstly, we validate\nthe theory by showing that novel data samples, consistent with the training\ndata, may be synthesised when the initial data samples are random noise.\nSecondly, we motivate the theory by showing that initial data samples\nsynthesised via other methods may be improved via iterative application of a\ntrained DAE to those initial samples.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 19:07:33 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 08:40:39 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Creswell", "Antonia", ""], ["Arulkumaran", "Kai", ""], ["Bharath", "Anil A.", ""]]}, {"id": "1708.08508", "submitter": "Azin Asgarian", "authors": "Azin Asgarian, Ahmed Bilal Ashraf, David Fleet, and Babak Taati", "title": "Subspace Selection to Suppress Confounding Source Domain Information in\n  AAM Transfer Learning", "comments": "Copyright IEEE. To be published in the proceedings of International\n  Joint Conference on Biometrics (IJCB) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active appearance models (AAMs) are a class of generative models that have\nseen tremendous success in face analysis. However, model learning depends on\nthe availability of detailed annotation of canonical landmark points. As a\nresult, when accurate AAM fitting is required on a different set of variations\n(expression, pose, identity), a new dataset is collected and annotated. To\novercome the need for time consuming data collection and annotation, transfer\nlearning approaches have received recent attention. The goal is to transfer\nknowledge from previously available datasets (source) to a new dataset\n(target). We propose a subspace transfer learning method, in which we select a\nsubspace from the source that best describes the target space. We propose a\nmetric to compute the directional similarity between the source eigenvectors\nand the target subspace. We show an equivalence between this metric and the\nvariance of target data when projected onto source eigenvectors. Using this\nequivalence, we select a subset of source principal directions that capture the\nvariance in target data. To define our model, we augment the selected source\nsubspace with the target subspace learned from a handful of target examples. In\nexperiments done on six publicly available datasets, we show that our approach\noutperforms the state of the art in terms of the RMS fitting error as well as\nthe percentage of test examples for which AAM fitting converges to the ground\ntruth.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 20:21:21 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 18:26:16 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Asgarian", "Azin", ""], ["Ashraf", "Ahmed Bilal", ""], ["Fleet", "David", ""], ["Taati", "Babak", ""]]}, {"id": "1708.08552", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Cho-Jui Hsieh, Jason D. Lee and Yuekai Sun", "title": "An inexact subsampled proximal Newton-type method for large-scale\n  machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast proximal Newton-type algorithm for minimizing regularized\nfinite sums that returns an $\\epsilon$-suboptimal point in\n$\\tilde{\\mathcal{O}}(d(n + \\sqrt{\\kappa d})\\log(\\frac{1}{\\epsilon}))$ FLOPS,\nwhere $n$ is number of samples, $d$ is feature dimension, and $\\kappa$ is the\ncondition number. As long as $n > d$, the proposed method is more efficient\nthan state-of-the-art accelerated stochastic first-order methods for non-smooth\nregularizers which requires $\\tilde{\\mathcal{O}}(d(n + \\sqrt{\\kappa\nn})\\log(\\frac{1}{\\epsilon}))$ FLOPS. The key idea is to form the subsampled\nNewton subproblem in a way that preserves the finite sum structure of the\nobjective, thereby allowing us to leverage recent developments in stochastic\nfirst-order methods to solve the subproblem. Experimental results verify that\nthe proposed algorithm outperforms previous algorithms for $\\ell_1$-regularized\nlogistic regression on real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 22:47:48 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""], ["Lee", "Jason D.", ""], ["Sun", "Yuekai", ""]]}, {"id": "1708.08559", "submitter": "Baishakhi Ray", "authors": "Yuchi Tian, Kexin Pei, Suman Jana, Baishakhi Ray", "title": "DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous\n  Cars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Neural Networks (DNNs) have led to the development of\nDNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can\ndrive without any human intervention. Most major manufacturers including Tesla,\nGM, Ford, BMW, and Waymo/Google are working on building and testing different\ntypes of autonomous vehicles. The lawmakers of several US states including\nCalifornia, Texas, and New York have passed new legislation to fast-track the\nprocess of testing and deployment of autonomous vehicles on their roads.\n  However, despite their spectacular progress, DNNs, just like traditional\nsoftware, often demonstrate incorrect or unexpected corner case behaviors that\ncan lead to potentially fatal collisions. Several such real-world accidents\ninvolving autonomous cars have already happened including one which resulted in\na fatality. Most existing testing techniques for DNN-driven vehicles are\nheavily dependent on the manual collection of test data under different driving\nconditions which become prohibitively expensive as the number of test\nconditions increases.\n  In this paper, we design, implement and evaluate DeepTest, a systematic\ntesting tool for automatically detecting erroneous behaviors of DNN-driven\nvehicles that can potentially lead to fatal crashes. First, our tool is\ndesigned to automatically generated test cases leveraging real-world changes in\ndriving conditions like rain, fog, lighting conditions, etc. DeepTest\nsystematically explores different parts of the DNN logic by generating test\ninputs that maximize the numbers of activated neurons. DeepTest found thousands\nof erroneous behaviors under different realistic driving conditions (e.g.,\nblurring, rain, fog, etc.) many of which lead to potentially fatal crashes in\nthree top performing DNNs in the Udacity self-driving car challenge.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 23:26:14 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 06:10:24 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Tian", "Yuchi", ""], ["Pei", "Kexin", ""], ["Jana", "Suman", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1708.08587", "submitter": "Shashank Singh", "authors": "Shashank Singh, Barnab\\'as P\\'oczos, and Jian Ma", "title": "On the Reconstruction Risk of Convolutional Sparse Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse dictionary learning (SDL) has become a popular method for adaptively\nidentifying parsimonious representations of a dataset, a fundamental problem in\nmachine learning and signal processing. While most work on SDL assumes a\ntraining dataset of independent and identically distributed samples, a variant\nknown as convolutional sparse dictionary learning (CSDL) relaxes this\nassumption, allowing more general sequential data sources, such as time series\nor other dependent data. Although recent work has explored the statistical\nproperties of classical SDL, the statistical properties of CSDL remain\nunstudied. This paper begins to study this by identifying the minimax\nconvergence rate of CSDL in terms of reconstruction risk, by both upper\nbounding the risk of an established CSDL estimator and proving a matching\ninformation-theoretic lower bound. Our results indicate that consistency in\nreconstruction risk is possible precisely in the `ultra-sparse' setting, in\nwhich the sparsity (i.e., the number of feature occurrences) is in $o(N)$ in\nterms of the length N of the training sequence. Notably, our results make very\nweak assumptions, allowing arbitrary dictionaries and dependent measurement\nnoise. Finally, we verify our theoretical results with numerical experiments on\nsynthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 04:15:39 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 23:49:15 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Singh", "Shashank", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Ma", "Jian", ""]]}, {"id": "1708.08591", "submitter": "Tanmoy Chakraborty", "authors": "Tanmoy Chakraborty", "title": "EC3: Combining Clustering and Classification for Ensemble Learning", "comments": "14 pages, 7 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification and clustering algorithms have been proved to be successful\nindividually in different contexts. Both of them have their own advantages and\nlimitations. For instance, although classification algorithms are more powerful\nthan clustering methods in predicting class labels of objects, they do not\nperform well when there is a lack of sufficient manually labeled reliable data.\nOn the other hand, although clustering algorithms do not produce label\ninformation for objects, they provide supplementary constraints (e.g., if two\nobjects are clustered together, it is more likely that the same label is\nassigned to both of them) that one can leverage for label prediction of a set\nof unknown objects. Therefore, systematic utilization of both these types of\nalgorithms together can lead to better prediction performance. In this paper,\nWe propose a novel algorithm, called EC3 that merges classification and\nclustering together in order to support both binary and multi-class\nclassification. EC3 is based on a principled combination of multiple\nclassification and multiple clustering methods using an optimization function.\nWe theoretically show the convexity and optimality of the problem and solve it\nby block coordinate descent method. We additionally propose iEC3, a variant of\nEC3 that handles imbalanced training data. We perform an extensive experimental\nanalysis by comparing EC3 and iEC3 with 14 baseline methods (7 well-known\nstandalone classifiers, 5 ensemble classifiers, and 2 existing methods that\nmerge classification and clustering) on 13 standard benchmark datasets. We show\nthat our methods outperform other baselines for every single dataset, achieving\nat most 10% higher AUC. Moreover our methods are faster (1.21 times faster than\nthe best baseline), more resilient to noise and class imbalance than the best\nbaseline method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 05:12:10 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Chakraborty", "Tanmoy", ""]]}, {"id": "1708.08611", "submitter": "Mohammed Alshiekh", "authors": "Mohammed Alshiekh, Roderick Bloem, Ruediger Ehlers, Bettina\n  K\\\"onighofer, Scott Niekum, Ufuk Topcu", "title": "Safe Reinforcement Learning via Shielding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms discover policies that maximize reward, but\ndo not necessarily guarantee safety during learning or execution phases. We\nintroduce a new approach to learn optimal policies while enforcing properties\nexpressed in temporal logic. To this end, given the temporal logic\nspecification that is to be obeyed by the learning system, we propose to\nsynthesize a reactive system called a shield. The shield is introduced in the\ntraditional learning process in two alternative ways, depending on the location\nat which the shield is implemented. In the first one, the shield acts each time\nthe learning agent is about to make a decision and provides a list of safe\nactions. In the second way, the shield is introduced after the learning agent.\nThe shield monitors the actions from the learner and corrects them only if the\nchosen action causes a violation of the specification. We discuss which\nrequirements a shield must meet to preserve the convergence guarantees of the\nlearner. Finally, we demonstrate the versatility of our approach on several\nchallenging reinforcement learning scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 07:16:54 GMT"}, {"version": "v2", "created": "Sun, 3 Sep 2017 20:35:33 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Alshiekh", "Mohammed", ""], ["Bloem", "Roderick", ""], ["Ehlers", "Ruediger", ""], ["K\u00f6nighofer", "Bettina", ""], ["Niekum", "Scott", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1708.08670", "submitter": "Yuri G. Gordienko", "authors": "Yuriy Kochura, Sergii Stirenko, Oleg Alienin, Michail Novotarskiy, and\n  Yuri Gordienko", "title": "Performance Analysis of Open Source Machine Learning Frameworks for\n  Various Parameters in Single-Threaded and Multi-Threaded Modes", "comments": "15 pages, 11 figures, 4 tables; this paper summarizes the activities\n  which were started recently and described shortly in the previous conference\n  presentations arXiv:1706.02248 and arXiv:1707.04940; it is accepted for\n  Springer book series \"Advances in Intelligent Systems and Computing\"", "journal-ref": "Advances in Intelligent Systems and Computing II. CSIT 2017.\n  Advances in Intelligent Systems and Computing, vol 689, pp 243-256. Springer,\n  Cham", "doi": "10.1007/978-3-319-70581-1_17", "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic features of some of the most versatile and popular open source\nframeworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are\nconsidered and compared. Their comparative analysis was performed and\nconclusions were made as to the advantages and disadvantages of these\nplatforms. The performance tests for the de facto standard MNIST data set were\ncarried out on H2O framework for deep learning algorithms designed for CPU and\nGPU platforms for single-threaded and multithreaded modes of operation Also, we\npresent the results of testing neural networks architectures on H2O platform\nfor various activation functions, stopping metrics, and other parameters of\nmachine learning algorithm. It was demonstrated for the use case of MNIST\ndatabase of handwritten digits in single-threaded mode that blind selection of\nthese parameters can hugely increase (by 2-3 orders) the runtime without the\nsignificant increase of precision. This result can have crucial influence for\noptimization of available and new machine learning methods, especially for\nimage recognition problems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 09:54:28 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Kochura", "Yuriy", ""], ["Stirenko", "Sergii", ""], ["Alienin", "Oleg", ""], ["Novotarskiy", "Michail", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1708.08689", "submitter": "Battista Biggio", "authors": "Luis Mu\\~noz-Gonz\\'alez, Battista Biggio, Ambra Demontis, Andrea\n  Paudice, Vasin Wongrassamee, Emil C. Lupu, Fabio Roli", "title": "Towards Poisoning of Deep Learning Algorithms with Back-gradient\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of online services nowadays rely upon machine learning to extract\nvaluable information from data collected in the wild. This exposes learning\nalgorithms to the threat of data poisoning, i.e., a coordinate attack in which\na fraction of the training data is controlled by the attacker and manipulated\nto subvert the learning process. To date, these attacks have been devised only\nagainst a limited class of binary learning algorithms, due to the inherent\ncomplexity of the gradient-based procedure used to optimize the poisoning\npoints (a.k.a. adversarial training examples). In this work, we rst extend the\nde nition of poisoning attacks to multiclass problems. We then propose a novel\npoisoning algorithm based on the idea of back-gradient optimization, i.e., to\ncompute the gradient of interest through automatic di erentiation, while also\nreversing the learning procedure to drastically reduce the attack complexity.\nCompared to current poisoning strategies, our approach is able to target a\nwider class of learning algorithms, trained with gradient- based procedures,\nincluding neural networks and deep learning architectures. We empirically\nevaluate its e ectiveness on several application examples, including spam\nltering, malware detection, and handwritten digit recognition. We nally show\nthat, similarly to adversarial test examples, adversarial training examples can\nalso be transferred across di erent learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 10:47:38 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Biggio", "Battista", ""], ["Demontis", "Ambra", ""], ["Paudice", "Andrea", ""], ["Wongrassamee", "Vasin", ""], ["Lupu", "Emil C.", ""], ["Roli", "Fabio", ""]]}, {"id": "1708.08694", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu", "title": "Natasha 2: Faster Non-Convex Optimization Than SGD", "comments": "V2 and V3 polished writing; V4 was a deep revision and simplified\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a stochastic algorithm to train any smooth neural network to\n$\\varepsilon$-approximate local minima, using $O(\\varepsilon^{-3.25})$\nbackpropagations. The best result was essentially $O(\\varepsilon^{-4})$ by SGD.\n  More broadly, it finds $\\varepsilon$-approximate local minima of any smooth\nnonconvex function in rate $O(\\varepsilon^{-3.25})$, with only oracle access to\nstochastic gradients.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 10:56:28 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 11:23:34 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 09:40:29 GMT"}, {"version": "v4", "created": "Mon, 11 Jun 2018 10:25:50 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""]]}, {"id": "1708.08705", "submitter": "Jeremias Sulam", "authors": "Jeremias Sulam, Vardan Papyan, Yaniv Romano, Michael Elad", "title": "Multi-Layer Convolutional Sparse Modeling: Pursuit and Dictionary\n  Learning", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, vol. 66, no. 15, pp.\n  4090-4104, Aug.1, 1 2018", "doi": "10.1109/TSP.2018.2846226", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Multi-Layer Convolutional Sparse Coding (ML-CSC) model,\nconsisting of a cascade of convolutional sparse layers, provides a new\ninterpretation of Convolutional Neural Networks (CNNs). Under this framework,\nthe computation of the forward pass in a CNN is equivalent to a pursuit\nalgorithm aiming to estimate the nested sparse representation vectors -- or\nfeature maps -- from a given input signal. Despite having served as a pivotal\nconnection between CNNs and sparse modeling, a deeper understanding of the\nML-CSC is still lacking: there are no pursuit algorithms that can serve this\nmodel exactly, nor are there conditions to guarantee a non-empty model. While\none can easily obtain signals that approximately satisfy the ML-CSC\nconstraints, it remains unclear how to simply sample from the model and, more\nimportantly, how one can train the convolutional filters from real data.\n  In this work, we propose a sound pursuit algorithm for the ML-CSC model by\nadopting a projection approach. We provide new and improved bounds on the\nstability of the solution of such pursuit and we analyze different practical\nalternatives to implement this in practice. We show that the training of the\nfilters is essential to allow for non-trivial signals in the model, and we\nderive an online algorithm to learn the dictionaries from real data,\neffectively resulting in cascaded sparse convolutional layers. Last, but not\nleast, we demonstrate the applicability of the ML-CSC model for several\napplications in an unsupervised setting, providing competitive results. Our\nwork represents a bridge between matrix factorization, sparse dictionary\nlearning and sparse auto-encoders, and we analyze these connections in detail.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 11:43:40 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2018 19:46:15 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Sulam", "Jeremias", ""], ["Papyan", "Vardan", ""], ["Romano", "Yaniv", ""], ["Elad", "Michael", ""]]}, {"id": "1708.08725", "submitter": "Xavier Bellekens", "authors": "Elike Hodo and Xavier Bellekens and Ephraim Iorkyase and Andrew\n  Hamilton and Christos Tachtatzis and Robert Atkinson", "title": "Machine Learning Approach for Detection of nonTor Traffic", "comments": "6 pages, 4 figures, Accepted and Presented in ARES '17 Proceedings of\n  the 12th International Conference on Availability, Reliability and Security", "journal-ref": "Information 2018, 9(9), 231", "doi": "10.3390/info9090231", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection has attracted a considerable interest from researchers\nand industries. After many years of research the community still faces the\nproblem of building reliable and efficient intrusion detection systems (IDS)\ncapable of handling large quantities of data with changing patterns in real\ntime situations. The Tor network is popular in providing privacy and security\nto end user by anonymising the identity of internet users connecting through a\nseries of tunnels and nodes. This work focuses on the classification of Tor\ntraffic and nonTor traffic to expose the activities within Tor traffic that\nminimizes the protection of users. A study to compare the reliability and\nefficiency of Artificial Neural Network and Support vector machine in detecting\nnonTor traffic in UNB-CIC Tor Network Traffic dataset is presented in this\npaper. The results are analysed based on the overall accuracy, detection rate\nand false positive rate of the two algorithms. Experimental results show that\nboth algorithms could detect nonTor traffic in the dataset. A hybrid Artificial\nneural network proved a better classifier than SVM in detecting nonTor traffic\nin UNB-CIC Tor Network Traffic dataset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 12:35:51 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Hodo", "Elike", ""], ["Bellekens", "Xavier", ""], ["Iorkyase", "Ephraim", ""], ["Hamilton", "Andrew", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""]]}, {"id": "1708.08732", "submitter": "Maria Brbic", "authors": "Maria Brbic and Ivica Kopriva", "title": "Multi-view Low-rank Sparse Subspace Clustering", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2017.08.024", "report-no": null, "categories": "cs.CV cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing approaches address multi-view subspace clustering problem by\nconstructing the affinity matrix on each view separately and afterwards propose\nhow to extend spectral clustering algorithm to handle multi-view data. This\npaper presents an approach to multi-view subspace clustering that learns a\njoint subspace representation by constructing affinity matrix shared among all\nviews. Relying on the importance of both low-rank and sparsity constraints in\nthe construction of the affinity matrix, we introduce the objective that\nbalances between the agreement across different views, while at the same time\nencourages sparsity and low-rankness of the solution. Related low-rank and\nsparsity constrained optimization problem is for each view solved using the\nalternating direction method of multipliers. Furthermore, we extend our\napproach to cluster data drawn from nonlinear subspaces by solving the\ncorresponding problem in a reproducing kernel Hilbert space. The proposed\nalgorithm outperforms state-of-the-art multi-view subspace clustering\nalgorithms on one synthetic and four real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 13:07:56 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Brbic", "Maria", ""], ["Kopriva", "Ivica", ""]]}, {"id": "1708.08750", "submitter": "Allan Melvin Andrew", "authors": "Allan Melvin Andrew, Ammar Zakaria, Shaharil Mad Saad and Ali Yeon Md\n  Shakaff", "title": "Multi-Stage Feature Selection Based Intelligent Classifier for\n  Classification of Incipient Stage Fire in Building", "comments": "electronic nose; gas sensors; fire detection; feature selection;\n  feature fusion; Artificial intelligence, machine learning, neural networks,\n  remote sensing, decision support", "journal-ref": "Sensors 2016, 16, 31", "doi": "10.3390/s16010031", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, an early fire detection algorithm has been proposed based on\nlow cost array sensing system, utilizing gas sensors, dust particles and\nambient sensors such as temperature and humidity sensor. The odor or\nsmell-print emanated from various fire sources and building construction\nmaterials at early stage are measured. For this purpose, odor profile data from\nfive common fire sources and three common building construction materials were\nused to develop the classification model. Normalized feature extractions of the\nsmell print data were performed before subjected to prediction classifier.\nThese features represent the odor signals in the time domain. The obtained\nfeatures undergo the proposed multi-stage feature selection technique and\nlastly, further reduced by Principal Component Analysis (PCA), a dimension\nreduction technique. The hybrid PCA-PNN based approach has been applied on\ndifferent datasets from in-house developed system and the portable electronic\nnose unit. Experimental classification results show that the dimension\nreduction process performed by PCA has improved the classification accuracy and\nprovided high reliability, regardless of ambient temperature and humidity\nvariation, baseline sensor drift, the different gas concentration level and\nexposure towards different heating temperature range.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 09:54:45 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Andrew", "Allan Melvin", ""], ["Zakaria", "Ammar", ""], ["Saad", "Shaharil Mad", ""], ["Shakaff", "Ali Yeon Md", ""]]}, {"id": "1708.08755", "submitter": "Daniel Lopez Martinez", "authors": "Daniel Lopez-Martinez, Rosalind Picard", "title": "Multi-task Neural Networks for Personalized Pain Recognition from\n  Physiological Signals", "comments": "2017 Seventh International Conference on Affective Computing and\n  Intelligent Interaction Workshops and Demos (ACIIW), 1st Workshop on Tools\n  and Algorithms for Mental Health and Wellbeing, Pain, and Distress (MHWPD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain is a complex and subjective experience that poses a number of\nmeasurement challenges. While self-report by the patient is viewed as the gold\nstandard of pain assessment, this approach fails when patients cannot verbally\ncommunicate pain intensity or lack normal mental abilities. Here, we present a\npain intensity measurement method based on physiological signals. Specifically,\nwe implement a multi-task learning approach based on neural networks that\naccounts for individual differences in pain responses while still leveraging\ndata from across the population. We test our method in a dataset containing\nmulti-modal physiological responses to nociceptive pain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 05:38:56 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 19:23:11 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["Picard", "Rosalind", ""]]}, {"id": "1708.08813", "submitter": "Pelumi Oluwasanya", "authors": "Pelumi Oluwasanya", "title": "Anomaly Detection: Review and preliminary Entropy method tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anomalies are strange data points; they usually represent an unusual\noccurrence. Anomaly detection is presented from the perspective of Wireless\nsensor networks. Different approaches have been taken in the past, as we will\nsee, not only to identify outliers, but also to establish the statistical\nproperties of the different methods. The usual goal is to show that the\napproach is asymptotically efficient and that the metric used is unbiased or\nmaybe biased.\n  This project is based on a work done by [1]. The approach is based on the\nprinciple that the entropy of the data is increased when an anomalous data\npoint is measured. The entropy of the data set is thus to be estimated. In this\nreport however, preliminary efforts at confirming the results of [1] is\npresented. To estimate the entropy of the dataset, since no parametric form is\nassumed, the probability density function of the data set is first estimated\nusing data split method. This estimated pdf value is then plugged-in to the\nentropy estimation formula to estimate the entropy of the dataset. The data\n(test signal) used in this report is Gaussian distributed with zero mean and\nvariance 4. Results of pdf estimation using the k-nearest neighbour method\nusing the entire dataset, and a data-split method are presented and compared\nbased on how well they approximate the probability density function of a\nGaussian with similar mean and variance. The number of nearest neighbours\nchosen for the purpose of this report is 8. This is arbitrary, but is\nreasonable since the number of anomalies introduced is expected to be less than\nthis upon data-split. The data-split method is preferred and rightly so.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 15:08:05 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Oluwasanya", "Pelumi", ""]]}, {"id": "1708.08819", "submitter": "Thomas Unterthiner", "authors": "Thomas Unterthiner, Bernhard Nessler, Calvin Seward, G\\\"unter\n  Klambauer, Martin Heusel, Hubert Ramsauer, Sepp Hochreiter", "title": "Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields", "comments": "Published as a conference paper at ICLR (International Conference on\n  Learning Representations) 2018. Implementation available at\n  https://github.com/bioinf-jku/coulomb_gan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) evolved into one of the most\nsuccessful unsupervised techniques for generating realistic images. Even though\nit has recently been shown that GAN training converges, GAN models often end up\nin local Nash equilibria that are associated with mode collapse or otherwise\nfail to model the target distribution. We introduce Coulomb GANs, which pose\nthe GAN learning problem as a potential field of charged particles, where\ngenerated samples are attracted to training set samples but repel each other.\nThe discriminator learns a potential field while the generator decreases the\nenergy by moving its samples along the vector (force) field determined by the\ngradient of the potential field. Through decreasing the energy, the GAN model\nlearns to generate samples according to the whole target distribution and does\nnot only cover some of its modes. We prove that Coulomb GANs possess only one\nNash equilibrium which is optimal in the sense that the model distribution\nequals the target distribution. We show the efficacy of Coulomb GANs on a\nvariety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of\nthe art and produce a previously unseen variety of different samples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 15:22:03 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 09:43:53 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 11:54:35 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Unterthiner", "Thomas", ""], ["Nessler", "Bernhard", ""], ["Seward", "Calvin", ""], ["Klambauer", "G\u00fcnter", ""], ["Heusel", "Martin", ""], ["Ramsauer", "Hubert", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1708.08863", "submitter": "Ziv Aharoni", "authors": "Ziv Aharoni, Gal Rattner, Haim Permuter", "title": "Gradual Learning of Recurrent Neural Networks", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) achieve state-of-the-art results in many\nsequence-to-sequence modeling tasks. However, RNNs are difficult to train and\ntend to suffer from overfitting. Motivated by the Data Processing Inequality\n(DPI), we formulate the multi-layered network as a Markov chain, introducing a\ntraining method that comprises training the network gradually and using\nlayer-wise gradient clipping. We found that applying our methods, combined with\npreviously introduced regularization and optimization methods, resulted in\nimprovements in state-of-the-art architectures operating in language modeling\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 16:18:44 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 10:22:10 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Aharoni", "Ziv", ""], ["Rattner", "Gal", ""], ["Permuter", "Haim", ""]]}, {"id": "1708.08917", "submitter": "Caiwen Ding Kevin Ding", "authors": "Caiwen Ding, Siyu Liao, Yanzhi Wang, Zhe Li, Ning Liu, Youwei Zhuo,\n  Chao Wang, Xuehai Qian, Yu Bai, Geng Yuan, Xiaolong Ma, Yipeng Zhang, Jian\n  Tang, Qinru Qiu, Xue Lin, Bo Yuan", "title": "CirCNN: Accelerating and Compressing Deep Neural Networks Using\n  Block-CirculantWeight Matrices", "comments": "14 pages, 15 Figures, conference", "journal-ref": null, "doi": "10.1145/3123939.3124552", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale deep neural networks (DNNs) are both compute and memory\nintensive. As the size of DNNs continues to grow, it is critical to improve the\nenergy efficiency and performance while maintaining accuracy. For DNNs, the\nmodel size is an important factor affecting performance, scalability and energy\nefficiency. Weight pruning achieves good compression ratios but suffers from\nthree drawbacks: 1) the irregular network structure after pruning; 2) the\nincreased training complexity; and 3) the lack of rigorous guarantee of\ncompression ratio and inference accuracy. To overcome these limitations, this\npaper proposes CirCNN, a principled approach to represent weights and process\nneural networks using block-circulant matrices. CirCNN utilizes the Fast\nFourier Transform (FFT)-based fast multiplication, simultaneously reducing the\ncomputational complexity (both in inference and training) from O(n2) to\nO(nlogn) and the storage complexity from O(n2) to O(n), with negligible\naccuracy loss. Compared to other approaches, CirCNN is distinct due to its\nmathematical rigor: it can converge to the same effectiveness as DNNs without\ncompression. The CirCNN architecture, a universal DNN inference engine that can\nbe implemented on various hardware/software platforms with configurable network\narchitecture. To demonstrate the performance and energy efficiency, we test\nCirCNN in FPGA, ASIC and embedded processors. Our results show that CirCNN\narchitecture achieves very high energy efficiency and performance with a small\nhardware footprint. Based on the FPGA implementation and ASIC synthesis\nresults, CirCNN achieves 6-102X energy efficiency improvements compared with\nthe best state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 04:18:57 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Ding", "Caiwen", ""], ["Liao", "Siyu", ""], ["Wang", "Yanzhi", ""], ["Li", "Zhe", ""], ["Liu", "Ning", ""], ["Zhuo", "Youwei", ""], ["Wang", "Chao", ""], ["Qian", "Xuehai", ""], ["Bai", "Yu", ""], ["Yuan", "Geng", ""], ["Ma", "Xiaolong", ""], ["Zhang", "Yipeng", ""], ["Tang", "Jian", ""], ["Qiu", "Qinru", ""], ["Lin", "Xue", ""], ["Yuan", "Bo", ""]]}, {"id": "1708.08985", "submitter": "Giovanni De Magistris", "authors": "Asim Munawar, Phongtharin Vinayavekhin and Giovanni De Magistris", "title": "Limiting the Reconstruction Capability of Generative Neural Network\n  using Negative Learning", "comments": "Conference: IEEE International Workshop on Machine Learning for\n  Signal Processing (MLSP), Roppongi, Tokyo, Japan, September 25-28, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models are widely used for unsupervised learning with various\napplications, including data compression and signal restoration. Training\nmethods for such systems focus on the generality of the network given limited\namount of training data. A less researched type of techniques concerns\ngeneration of only a single type of input. This is useful for applications such\nas constraint handling, noise reduction and anomaly detection. In this paper we\npresent a technique to limit the generative capability of the network using\nnegative learning. The proposed method searches the solution in the gradient\ndirection for the desired input and in the opposite direction for the undesired\ninput. One of the application can be anomaly detection where the undesired\ninputs are the anomalous data. In the results section we demonstrate the\nfeatures of the algorithm using MNIST handwritten digit dataset and latter\napply the technique to a real-world obstacle detection problem. The results\nclearly show that the proposed learning technique can significantly improve the\nperformance for anomaly detection.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 01:16:14 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Munawar", "Asim", ""], ["Vinayavekhin", "Phongtharin", ""], ["De Magistris", "Giovanni", ""]]}, {"id": "1708.08989", "submitter": "Yu Zhao", "authors": "Yu Zhao, Rennong Yang, Guillaume Chevalier, Maoguo Gong", "title": "Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable\n  Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) has become a popular topic in research\nbecause of its wide application. With the development of deep learning, new\nideas have appeared to address HAR problems. Here, a deep network architecture\nusing residual bidirectional long short-term memory (LSTM) cells is proposed.\nThe advantages of the new network include that a bidirectional connection can\nconcatenate the positive time direction (forward state) and the negative time\ndirection (backward state). Second, residual connections between stacked cells\nact as highways for gradients, which can pass underlying information directly\nto the upper layer, effectively avoiding the gradient vanishing problem.\nGenerally, the proposed network shows improvements on both the temporal (using\nbidirectional cells) and the spatial (residual connections stacked deeply)\ndimensions, aiming to enhance the recognition rate. When tested with the\nOpportunity data set and the public domain UCI data set, the accuracy was\nincreased by 4.78% and 3.68%, respectively, compared with previously reported\nresults. Finally, the confusion matrix of the public domain UCI data set was\nanalyzed.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 11:02:13 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 07:36:31 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Zhao", "Yu", ""], ["Yang", "Rennong", ""], ["Chevalier", "Guillaume", ""], ["Gong", "Maoguo", ""]]}, {"id": "1708.08994", "submitter": "Matteo Ruffini MR", "authors": "Matteo Ruffini, Ricard Gavald\\`a, Esther Lim\\'on", "title": "Clustering Patients with Tensor Decomposition", "comments": "Presented at 2017 Machine Learning for Healthcare Conference (MLHC\n  2017). Boston, MA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method for the unsupervised clustering of\nhigh-dimensional binary data, with a special focus on electronic healthcare\nrecords. We present a robust and efficient heuristic to face this problem using\ntensor decomposition. We present the reasons why this approach is preferable\nfor tasks such as clustering patient records, to more commonly used\ndistance-based methods. We run the algorithm on two datasets of healthcare\nrecords, obtaining clinically meaningful results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 19:53:08 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Ruffini", "Matteo", ""], ["Gavald\u00e0", "Ricard", ""], ["Lim\u00f3n", "Esther", ""]]}, {"id": "1708.09022", "submitter": "Margarita Osadchy", "authors": "Jinchao Liu, Margarita Osadchy, Lorna Ashton, Michael Foster,\n  Christopher J. Solomon, Stuart J. Gibson", "title": "Deep Convolutional Neural Networks for Raman Spectrum Recognition: A\n  Unified Solution", "comments": null, "journal-ref": null, "doi": "10.1039/C7AN01371J", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have found many applications in Raman spectroscopy,\nespecially for the identification of chemical species. However, almost all of\nthese methods require non-trivial preprocessing such as baseline correction\nand/or PCA as an essential step. Here we describe our unified solution for the\nidentification of chemical species in which a convolutional neural network is\ntrained to automatically identify substances according to their Raman spectrum\nwithout the need of ad-hoc preprocessing steps. We evaluated our approach using\nthe RRUFF spectral database, comprising mineral sample data. Superior\nclassification performance is demonstrated compared with other frequently used\nmachine learning algorithms including the popular support vector machine.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 14:06:10 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Liu", "Jinchao", ""], ["Osadchy", "Margarita", ""], ["Ashton", "Lorna", ""], ["Foster", "Michael", ""], ["Solomon", "Christopher J.", ""], ["Gibson", "Stuart J.", ""]]}, {"id": "1708.09025", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Diego Klabjan, Patrick Bless", "title": "Unsupervised Terminological Ontology Learning based on Hierarchical\n  Topic Modeling", "comments": null, "journal-ref": "IRI 2017", "doi": "10.1109/IRI.2017.18", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present hierarchical relationbased latent Dirichlet\nallocation (hrLDA), a data-driven hierarchical topic model for extracting\nterminological ontologies from a large number of heterogeneous documents. In\ncontrast to traditional topic models, hrLDA relies on noun phrases instead of\nunigrams, considers syntax and document structures, and enriches topic\nhierarchies with topic relations. Through a series of experiments, we\ndemonstrate the superiority of hrLDA over existing topic models, especially for\nbuilding hierarchies. Furthermore, we illustrate the robustness of hrLDA in the\nsettings of noisy data sets, which are likely to occur in many practical\nscenarios. Our ontology evaluation results show that ontologies extracted from\nhrLDA are very competitive with the ontologies created by domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 21:04:11 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Klabjan", "Diego", ""], ["Bless", "Patrick", ""]]}, {"id": "1708.09056", "submitter": "Yizheng Chen", "authors": "Yizheng Chen, Yacin Nadji, Athanasios Kountouras, Fabian Monrose,\n  Roberto Perdisci, Manos Antonakakis, Nikolaos Vasiloglou", "title": "Practical Attacks Against Graph-based Clustering", "comments": "ACM CCS 2017", "journal-ref": null, "doi": "10.1145/3133956.3134083", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph modeling allows numerous security problems to be tackled in a general\nway, however, little work has been done to understand their ability to\nwithstand adversarial attacks. We design and evaluate two novel graph attacks\nagainst a state-of-the-art network-level, graph-based detection system. Our\nwork highlights areas in adversarial machine learning that have not yet been\naddressed, specifically: graph-based clustering techniques, and a global\nfeature space where realistic attackers without perfect knowledge must be\naccounted for (by the defenders) in order to be practical. Even though less\ninformed attackers can evade graph clustering with low cost, we show that some\npractical defenses are possible.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 23:22:31 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Chen", "Yizheng", ""], ["Nadji", "Yacin", ""], ["Kountouras", "Athanasios", ""], ["Monrose", "Fabian", ""], ["Perdisci", "Roberto", ""], ["Antonakakis", "Manos", ""], ["Vasiloglou", "Nikolaos", ""]]}, {"id": "1708.09066", "submitter": "Fred Moolekamp", "authors": "Fred Moolekamp and Peter Melchior", "title": "Block-Simultaneous Direction Method of Multipliers: A proximal\n  primal-dual splitting algorithm for nonconvex problems with multiple\n  constraints", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": "10.1007/s11081-018-9380-y", "report-no": null, "categories": "math.OC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalization of the linearized Alternating Direction Method\nof Multipliers to optimize a real-valued function $f$ of multiple arguments\nwith potentially multiple constraints $g_\\circ$ on each of them. The function\n$f$ may be nonconvex as long as it is convex in every argument, while the\nconstraints $g_\\circ$ need to be convex but not smooth. If $f$ is smooth, the\nproposed Block-Simultaneous Direction Method of Multipliers (bSDMM) can be\ninterpreted as a proximal analog to inexact coordinate descent methods under\nconstraints. Unlike alternative approaches for joint solvers of\nmultiple-constraint problems, we do not require linear operators $L$ of a\nconstraint function $g(L\\ \\cdot)$ to be invertible or linked between each\nother. bSDMM is well-suited for a range of optimization problems, in particular\nfor data analysis, where $f$ is the likelihood function of a model and $L$\ncould be a transformation matrix describing e.g. finite differences or basis\ntransforms. We apply bSDMM to the Non-negative Matrix Factorization task of a\nhyperspectral unmixing problem and demonstrate convergence and effectiveness of\nmultiple constraints on both matrix factors. The algorithms are implemented in\npython and released as an open-source package.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 00:15:50 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Moolekamp", "Fred", ""], ["Melchior", "Peter", ""]]}, {"id": "1708.09121", "submitter": "Ritchie Lee", "authors": "Ritchie Lee, Mykel J. Kochenderfer, Ole J. Mengshoel and Joshua\n  Silbermann", "title": "Interpretable Categorization of Heterogeneous Time Series Data", "comments": "9 pages, 5 figures, 2 tables, SIAM International Conference on Data\n  Mining (SDM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding heterogeneous multivariate time series data is important in\nmany applications ranging from smart homes to aviation. Learning models of\nheterogeneous multivariate time series that are also human-interpretable is\nchallenging and not adequately addressed by the existing literature. We propose\ngrammar-based decision trees (GBDTs) and an algorithm for learning them. GBDTs\nextend decision trees with a grammar framework. Logical expressions derived\nfrom a context-free grammar are used for branching in place of simple\nthresholds on attributes. The added expressivity enables support for a wide\nrange of data types while retaining the interpretability of decision trees. In\nparticular, when a grammar based on temporal logic is used, we show that GBDTs\ncan be used for the interpretable classi cation of high-dimensional and\nheterogeneous time series data. Furthermore, we show how GBDTs can also be used\nfor categorization, which is a combination of clustering and generating\ninterpretable explanations for each cluster. We apply GBDTs to analyze the\nclassic Australian Sign Language dataset as well as data on near mid-air\ncollisions (NMACs). The NMAC data comes from aircraft simulations used in the\ndevelopment of the next-generation Airborne Collision Avoidance System (ACAS\nX).\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 05:21:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 20:41:23 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""], ["Mengshoel", "Ole J.", ""], ["Silbermann", "Joshua", ""]]}, {"id": "1708.09165", "submitter": "Andrzej Cichocki", "authors": "A. Cichocki, A-H. Phan, Q. Zhao, N. Lee, I.V. Oseledets, M. Sugiyama,\n  D. Mandic", "title": "Tensor Networks for Dimensionality Reduction and Large-Scale\n  Optimizations. Part 2 Applications and Future Perspectives", "comments": "232 pages", "journal-ref": "Foundations and Trends in Machine Learning: Vol. 9: No. 6, pp\n  431-673, 2017", "doi": "10.1561/2200000067", "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Part 2 of this monograph builds on the introduction to tensor networks and\ntheir operations presented in Part 1. It focuses on tensor network models for\nsuper-compressed higher-order representation of data/parameters and related\ncost functions, while providing an outline of their applications in machine\nlearning and data analytics. A particular emphasis is on the tensor train (TT)\nand Hierarchical Tucker (HT) decompositions, and their physically meaningful\ninterpretations which reflect the scalability of the tensor network approach.\nThrough a graphical approach, we also elucidate how, by virtue of the\nunderlying low-rank tensor approximations and sophisticated contractions of\ncore tensors, tensor networks have the ability to perform distributed\ncomputations on otherwise prohibitively large volumes of data/parameters,\nthereby alleviating or even eliminating the curse of dimensionality. The\nusefulness of this concept is illustrated over a number of applied areas,\nincluding generalized regression and classification (support tensor machines,\ncanonical correlation analysis, higher order partial least squares),\ngeneralized eigenvalue decomposition, Riemannian optimization, and in the\noptimization of deep neural networks. Part 1 and Part 2 of this work can be\nused either as stand-alone separate texts, or indeed as a conjoint\ncomprehensive review of the exciting field of low-rank tensor networks and\ntensor decompositions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 08:37:36 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Cichocki", "A.", ""], ["Phan", "A-H.", ""], ["Zhao", "Q.", ""], ["Lee", "N.", ""], ["Oseledets", "I. V.", ""], ["Sugiyama", "M.", ""], ["Mandic", "D.", ""]]}, {"id": "1708.09252", "submitter": "Hongteng Xu", "authors": "Hongteng Xu and Hongyuan Zha", "title": "THAP: A Matlab Toolkit for Learning with Hawkes Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a powerful tool of asynchronous event sequence analysis, point processes\nhave been studied for a long time and achieved numerous successes in different\nfields. Among various point process models, Hawkes process and its variants\nattract many researchers in statistics and computer science these years because\nthey capture the self- and mutually-triggering patterns between different\nevents in complicated sequences explicitly and quantitatively and are broadly\napplicable to many practical problems. In this paper, we describe an\nopen-source toolkit implementing many learning algorithms and analysis tools\nfor Hawkes process model and its variants. Our toolkit systematically\nsummarizes recent state-of-the-art algorithms as well as most classic\nalgorithms of Hawkes processes, which is beneficial for both academical\neducation and research. Source code can be downloaded from\nhttps://github.com/HongtengXu/Hawkes-Process-Toolkit.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 21:07:20 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Xu", "Hongteng", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1708.09259", "submitter": "Amarjot Singh", "authors": "Amarjot Singh and Nick Kingsbury", "title": "Efficient Convolutional Network Learning using Parametric Log based\n  Dual-Tree Wavelet ScatterNet", "comments": "To Appear in the IEEE International Conference on Computer Vision\n  Workshops (ICCVW) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a DTCWT ScatterNet Convolutional Neural Network (DTSCNN) formed by\nreplacing the first few layers of a CNN network with a parametric log based\nDTCWT ScatterNet. The ScatterNet extracts edge based invariant representations\nthat are used by the later layers of the CNN to learn high-level features. This\nimproves the training of the network as the later layers can learn more complex\npatterns from the start of learning because the edge representations are\nalready present. The efficient learning of the DTSCNN network is demonstrated\non CIFAR-10 and Caltech-101 datasets. The generic nature of the ScatterNet\nfront-end is shown by an equivalent performance to pre-trained CNN front-ends.\nA comparison with the state-of-the-art on CIFAR-10 and Caltech-101 datasets is\nalso presented.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 13:33:19 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Singh", "Amarjot", ""], ["Kingsbury", "Nick", ""]]}, {"id": "1708.09342", "submitter": "Jonas Buchli", "authors": "Jonas Buchli, Farbod Farshidian, Alexander Winkler, Timothy Sandy,\n  Markus Giftthaler", "title": "Optimal and Learning Control for Autonomous Robots", "comments": "Lecture Notes, 101 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal and Learning Control for Autonomous Robots has been taught in the\nRobotics, Systems and Controls Masters at ETH Zurich with the aim to teach\noptimal control and reinforcement learning for closed loop control problems\nfrom a unified point of view. The starting point is the formulation of of an\noptimal control problem and deriving the different types of solutions and\nalgorithms from there. These lecture notes aim at supporting this unified view\nwith a unified notation wherever possible, and a bit of a translation help to\ncompare the terminology and notation in the different fields. The course\nassumes basic knowledge of Control Theory, Linear Algebra and Stochastic\nCalculus.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 16:17:00 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Buchli", "Jonas", ""], ["Farshidian", "Farbod", ""], ["Winkler", "Alexander", ""], ["Sandy", "Timothy", ""], ["Giftthaler", "Markus", ""]]}, {"id": "1708.09401", "submitter": "Huitao Shen", "authors": "Pengfei Zhang, Huitao Shen, Hui Zhai", "title": "Machine Learning Topological Invariants with Neural Networks", "comments": "6 pages, 4 figures and 1 table + 2 pages of supplemental material", "journal-ref": "Phys. Rev. Lett. 120, 066401 (2018)", "doi": "10.1103/PhysRevLett.120.066401", "report-no": null, "categories": "cond-mat.mes-hall cond-mat.dis-nn cond-mat.str-el cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Letter we supervisedly train neural networks to distinguish different\ntopological phases in the context of topological band insulators. After\ntraining with Hamiltonians of one-dimensional insulators with chiral symmetry,\nthe neural network can predict their topological winding numbers with nearly\n100% accuracy, even for Hamiltonians with larger winding numbers that are not\nincluded in the training data. These results show a remarkable success that the\nneural network can capture the global and nonlinear topological features of\nquantum phases from local inputs. By opening up the neural network, we confirm\nthat the network does learn the discrete version of the winding number formula.\nWe also make a couple of remarks regarding the role of the symmetry and the\nopposite effect of regularization techniques when applying machine learning to\nphysical systems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 18:00:51 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 01:07:25 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 23:13:36 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Zhang", "Pengfei", ""], ["Shen", "Huitao", ""], ["Zhai", "Hui", ""]]}, {"id": "1708.09441", "submitter": "Shubhomoy Das", "authors": "Shubhomoy Das, Weng-Keen Wong, Alan Fern, Thomas G. Dietterich, Md\n  Amran Siddiqui", "title": "Incorporating Feedback into Tree-based Anomaly Detection", "comments": "8 Pages, KDD 2017 Workshop on Interactive Data Exploration and\n  Analytics (IDEA'17), August 14th, 2017, Halifax, Nova Scotia, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detectors are often used to produce a ranked list of statistical\nanomalies, which are examined by human analysts in order to extract the actual\nanomalies of interest. Unfortunately, in realworld applications, this process\ncan be exceedingly difficult for the analyst since a large fraction of\nhigh-ranking anomalies are false positives and not interesting from the\napplication perspective. In this paper, we aim to make the analyst's job easier\nby allowing for analyst feedback during the investigation process. Ideally, the\nfeedback influences the ranking of the anomaly detector in a way that reduces\nthe number of false positives that must be examined before discovering the\nanomalies of interest. In particular, we introduce a novel technique for\nincorporating simple binary feedback into tree-based anomaly detectors. We\nfocus on the Isolation Forest algorithm as a representative tree-based anomaly\ndetector, and show that we can significantly improve its performance by\nincorporating feedback, when compared with the baseline algorithm that does not\nincorporate feedback. Our technique is simple and scales well as the size of\nthe data increases, which makes it suitable for interactive discovery of\nanomalies in large datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 19:36:21 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Das", "Shubhomoy", ""], ["Wong", "Weng-Keen", ""], ["Fern", "Alan", ""], ["Dietterich", "Thomas G.", ""], ["Siddiqui", "Md Amran", ""]]}, {"id": "1708.09477", "submitter": "Daniel Mckenzie", "authors": "Ming-Jun Lai and Daniel Mckenzie", "title": "A Compressive Sensing Approach to Community Detection with Applications", "comments": "39 pages, 10 figures Version 2, disabled 'showkeys' package. Note\n  that there is an error in the proof of Lemma 5.1. A correct version of this\n  lemma, as well as a greatly improved version of the central algorithm of this\n  paper, is available at: arXiv:1808.05780", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The community detection problem for graphs asks one to partition the n\nvertices V of a graph G into k communities, or clusters, such that there are\nmany intracluster edges and few intercluster edges. Of course this is\nequivalent to finding a permutation matrix P such that, if A denotes the\nadjacency matrix of G, then PAP^T is approximately block diagonal. As there are\nk^n possible partitions of n vertices into k subsets, directly determining the\noptimal clustering is clearly infeasible. Instead one seeks to solve a more\ntractable approximation to the clustering problem. In this paper we reformulate\nthe community detection problem via sparse solution of a linear system\nassociated with the Laplacian of a graph G and then develop a two-stage\napproach based on a thresholding technique and a compressive sensing algorithm\nto find a sparse solution which corresponds to the community containing a\nvertex of interest in G. Crucially, our approach results in an algorithm which\nis able to find a single cluster of size n_0 in O(nlog(n)n_0) operations and\nall k clusters in fewer than O(n^2ln(n)) operations. This is a marked\nimprovement over the classic spectral clustering algorithm, which is unable to\nfind a single cluster at a time and takes approximately O(n^3) operations to\nfind all k clusters. Moreover, we are able to provide robust guarantees of\nsuccess for the case where G is drawn at random from the Stochastic Block\nModel, a popular model for graphs with clusters. Extensive numerical results\nare also provided, showing the efficacy of our algorithm on both synthetic and\nreal-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 21:19:30 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 14:22:28 GMT"}, {"version": "v3", "created": "Mon, 20 Aug 2018 13:50:41 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Lai", "Ming-Jun", ""], ["Mckenzie", "Daniel", ""]]}, {"id": "1708.09516", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra and Horacio Franco", "title": "Leveraging Deep Neural Network Activation Entropy to cope with Unseen\n  Data in Speech Recognition", "comments": "7 pages, Index Terms: automatic speech recognition, robust speech\n  recognition, unsupervised adaptation, neural network activations, confidence\n  measures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen data conditions can inflict serious performance degradation on systems\nrelying on supervised machine learning algorithms. Because data can often be\nunseen, and because traditional machine learning algorithms are trained in a\nsupervised manner, unsupervised adaptation techniques must be used to adapt the\nmodel to the unseen data conditions. However, unsupervised adaptation is often\nchallenging, as one must generate some hypothesis given a model and then use\nthat hypothesis to bootstrap the model to the unseen data conditions.\nUnfortunately, reliability of such hypotheses is often poor, given the mismatch\nbetween the training and testing datasets. In such cases, a model hypothesis\nconfidence measure enables performing data selection for the model adaptation.\nUnderlying this approach is the fact that for unseen data conditions, data\nvariability is introduced to the model, which the model propagates to its\noutput decision, impacting decision reliability. In a fully connected network,\nthis data variability is propagated as distortions from one layer to the next.\nThis work aims to estimate the propagation of such distortion in the form of\nnetwork activation entropy, which is measured over a short- time running window\non the activation from each neuron of a given hidden layer, and these\nmeasurements are then used to compute summary entropy. This work demonstrates\nthat such an entropy measure can help to select data for unsupervised model\nadaptation, resulting in performance gains in speech recognition tasks. Results\nfrom standard benchmark speech recognition tasks show that the proposed\napproach can alleviate the performance degradation experienced under unseen\ndata conditions by iteratively adapting the model to the unseen datas acoustic\ncondition.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 01:00:19 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Franco", "Horacio", ""]]}, {"id": "1708.09630", "submitter": "Rohollah Moghadam", "authors": "Rohollah Moghadam and Hamidreza Modares", "title": "Resilient Autonomous Control of Distributed Multi-agent Systems in\n  Contested Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autonomous and resilient controller is proposed for leader-follower\nmulti-agent systems under uncertainties and cyber-physical attacks. The leader\nis assumed non-autonomous with a nonzero control input, which allows changing\nthe team behavior or mission in response to environmental changes. A resilient\nlearning-based control protocol is presented to find optimal solutions to the\nsynchronization problem in the presence of attacks and system dynamic\nuncertainties. An observer-based distributed H_infinity controller is first\ndesigned to prevent propagating the effects of attacks on sensors and actuators\nthroughout the network, as well as to attenuate the effect of these attacks on\nthe compromised agent itself. Non-homogeneous game algebraic Riccati equations\nare derived to solve the H_infinity optimal synchronization problem and\noff-policy reinforcement learning is utilized to learn their solution without\nrequiring any knowledge of the agent's dynamics. A trust-confidence based\ndistributed control protocol is then proposed to mitigate attacks that hijack\nthe entire node and attacks on communication links. A confidence value is\ndefined for each agent based solely on its local evidence. The proposed\nresilient reinforcement learning algorithm employs the confidence value of each\nagent to indicate the trustworthiness of its own information and broadcast it\nto its neighbors to put weights on the data they receive from it during and\nafter learning. If the confidence value of an agent is low, it employs a trust\nmechanism to identify compromised agents and remove the data it receives from\nthem from the learning process. Simulation results are provided to show the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 09:21:08 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 13:52:23 GMT"}, {"version": "v3", "created": "Sun, 31 Dec 2017 05:51:31 GMT"}, {"version": "v4", "created": "Mon, 9 Apr 2018 02:25:13 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Moghadam", "Rohollah", ""], ["Modares", "Hamidreza", ""]]}, {"id": "1708.09794", "submitter": "Nihar Shah", "authors": "Nihar B. Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon,\n  Ulrike von Luxburg", "title": "Design and Analysis of the NIPS 2016 Review Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Information Processing Systems (NIPS) is a top-tier annual conference\nin machine learning. The 2016 edition of the conference comprised more than\n2,400 paper submissions, 3,000 reviewers, and 8,000 attendees. This represents\na growth of nearly 40% in terms of submissions, 96% in terms of reviewers, and\nover 100% in terms of attendees as compared to the previous year. The massive\nscale as well as rapid growth of the conference calls for a thorough quality\nassessment of the peer-review process and novel means of improvement. In this\npaper, we analyze several aspects of the data collected during the review\nprocess, including an experiment investigating the efficacy of collecting\nordinal rankings from reviewers. Our goal is to check the soundness of the\nreview process, and provide insights that may be useful in the design of the\nreview process of subsequent conferences.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 16:09:33 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 18:22:09 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Shah", "Nihar B.", ""], ["Tabibian", "Behzad", ""], ["Muandet", "Krikamol", ""], ["Guyon", "Isabelle", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1708.09811", "submitter": "Jaouad Mourtada", "authors": "Jaouad Mourtada and Odalric-Ambrym Maillard", "title": "Efficient tracking of a growing number of experts", "comments": "To appear in Proceedings of the 28th International Conference on\n  Algorithmic Learning Theory (ALT 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variation on the problem of prediction with expert advice,\nwhere new forecasters that were unknown until then may appear at each round. As\noften in prediction with expert advice, designing an algorithm that achieves\nnear-optimal regret guarantees is straightforward, using aggregation of\nexperts. However, when the comparison class is sufficiently rich, for instance\nwhen the best expert and the set of experts itself changes over time, such\nstrategies naively require to maintain a prohibitive number of weights\n(typically exponential with the time horizon). By contrast, designing\nstrategies that both achieve a near-optimal regret and maintain a reasonable\nnumber of weights is highly non-trivial. We consider three increasingly\nchallenging objectives (simple regret, shifting regret and sparse shifting\nregret) that extend existing notions defined for a fixed expert ensemble; in\neach case, we design strategies that achieve tight regret bounds, adaptive to\nthe parameters of the comparison class, while being computationally\ninexpensive. Moreover, our algorithms are anytime, agnostic to the number of\nincoming experts and completely parameter-free. Such remarkable results are\nmade possible thanks to two simple but highly effective recipes: first the\n\"abstention trick\" that comes from the specialist framework and enables to\nhandle the least challenging notions of regret, but is limited when addressing\nmore sophisticated objectives. Second, the \"muting trick\" that we introduce to\ngive more flexibility. We show how to combine these two tricks in order to\nhandle the most challenging class of comparison strategies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 16:45:14 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Mourtada", "Jaouad", ""], ["Maillard", "Odalric-Ambrym", ""]]}]