[{"id": "1807.00002", "submitter": "Jonathan Mei", "authors": "Jonathan Mei and Jos\\'e M.F. Moura", "title": "Single Index Latent Variable Models for Network Topology Inference", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.03536", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-parametric, non-linear regression model in the presence of latent\nvariables is applied towards learning network graph structure. These latent\nvariables can correspond to unmodeled phenomena or unmeasured agents in a\ncomplex system of interacting entities. This formulation jointly estimates\nnon-linearities in the underlying data generation, the direct interactions\nbetween measured entities, and the indirect effects of unmeasured processes on\nthe observed data. The learning is posed as regularized empirical risk\nminimization. Details of the algorithm for learning the model are outlined.\nExperiments demonstrate the performance of the learned model on real data.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 19:36:52 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Mei", "Jonathan", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1807.00028", "submitter": "Andrew Cotter", "authors": "Andrew Cotter, Maya Gupta, Heinrich Jiang, Nathan Srebro, Karthik\n  Sridharan, Serena Wang, Blake Woodworth, Seungil You", "title": "Training Well-Generalizing Classifiers for Fairness Metrics and Other\n  Data-Dependent Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers can be trained with data-dependent constraints to satisfy\nfairness goals, reduce churn, achieve a targeted false positive rate, or other\npolicy goals. We study the generalization performance for such constrained\noptimization problems, in terms of how well the constraints are satisfied at\nevaluation time, given that they are satisfied at training time. To improve\ngeneralization performance, we frame the problem as a two-player game where one\nplayer optimizes the model parameters on a training dataset, and the other\nplayer enforces the constraints on an independent validation dataset. We build\non recent work in two-player constrained optimization to show that if one uses\nthis two-dataset approach, then constraint generalization can be significantly\nimproved. As we illustrate experimentally, this approach works not only in\ntheory, but also in practice.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 18:27:29 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 20:55:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Cotter", "Andrew", ""], ["Gupta", "Maya", ""], ["Jiang", "Heinrich", ""], ["Srebro", "Nathan", ""], ["Sridharan", "Karthik", ""], ["Wang", "Serena", ""], ["Woodworth", "Blake", ""], ["You", "Seungil", ""]]}, {"id": "1807.00042", "submitter": "Hendrick de Haan", "authors": "Martin Magill, Faisal Qureshi, Hendrick W. de Haan", "title": "Neural Networks Trained to Solve Differential Equations Learn General\n  Representations", "comments": "14 pages, 9 figures. Submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a technique based on the singular vector canonical correlation\nanalysis (SVCCA) for measuring the generality of neural network layers across a\ncontinuously-parametrized set of tasks. We illustrate this method by studying\ngenerality in neural networks trained to solve parametrized boundary value\nproblems based on the Poisson partial differential equation. We find that the\nfirst hidden layer is general, and that deeper layers are successively more\nspecific. Next, we validate our method against an existing technique that\nmeasures layer generality using transfer learning experiments. We find\nexcellent agreement between the two methods, and note that our method is much\nfaster, particularly for continuously-parametrized problems. Finally, we\nvisualize the general representations of the first layers, and interpret them\nas generalized coordinates over the input domain.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 19:23:45 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Magill", "Martin", ""], ["Qureshi", "Faisal", ""], ["de Haan", "Hendrick W.", ""]]}, {"id": "1807.00046", "submitter": "Jelena Milosevic", "authors": "Jelena Milosevic, Dexmont Pena, Andrew Forembsky, David Moloney,\n  Miroslaw Malek", "title": "It All Matters: Reporting Accuracy, Inference Time and Power Consumption\n  for Face Emotion Recognition on Embedded Systems", "comments": "13 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While several approaches to face emotion recognition task are proposed in\nliterature, none of them reports on power consumption nor inference time\nrequired to run the system in an embedded environment. Without adequate\nknowledge about these factors it is not clear whether we are actually able to\nprovide accurate face emotion recognition in the embedded environment or not,\nand if not, how far we are from making it feasible and what are the biggest\nbottlenecks we face.\n  The main goal of this paper is to answer these questions and to convey the\nmessage that instead of reporting only detection accuracy also power\nconsumption and inference time should be reported as real usability of the\nproposed systems and their adoption in human computer interaction strongly\ndepends on it. In this paper, we identify the state-of-the art face emotion\nrecognition methods that are potentially suitable for embedded environment and\nthe most frequently used datasets for this task. Our study shows that most of\nthe performed experiments use datasets with posed expressions or in a\nparticular experimental setup with special conditions for image collection.\nSince our goal is to evaluate the performance of the identified promising\nmethods in the realistic scenario, we collect a new dataset with\nnon-exaggerated emotions and we use it, in addition to the publicly available\ndatasets, for the evaluation of detection accuracy, power consumption and\ninference time on three frequently used embedded devices with different\ncomputational capabilities. Our results show that gray images are still more\nsuitable for embedded environment than color ones and that for most of the\nanalyzed systems either inference time or energy consumption or both are\nlimiting factor for their adoption in real-life embedded applications.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 19:47:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Milosevic", "Jelena", ""], ["Pena", "Dexmont", ""], ["Forembsky", "Andrew", ""], ["Moloney", "David", ""], ["Malek", "Miroslaw", ""]]}, {"id": "1807.00051", "submitter": "Wenqi Wei", "authors": "Wenqi Wei, Ling Liu, Margaret Loper, Stacey Truex, Lei Yu, Mehmet Emre\n  Gursoy, Yanzhao Wu", "title": "Adversarial Examples in Deep Learning: Characterization and Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The burgeoning success of deep learning has raised the security and privacy\nconcerns as more and more tasks are accompanied with sensitive data.\nAdversarial attacks in deep learning have emerged as one of the dominating\nsecurity threat to a range of mission-critical deep learning systems and\napplications. This paper takes a holistic and principled approach to perform\nstatistical characterization of adversarial examples in deep learning. We\nprovide a general formulation of adversarial examples and elaborate on the\nbasic principle for adversarial attack algorithm design. We introduce easy and\nhard categorization of adversarial attacks to analyze the effectiveness of\nadversarial examples in terms of attack success rate, degree of change in\nadversarial perturbation, average entropy of prediction qualities, and fraction\nof adversarial examples that lead to successful attacks. We conduct extensive\nexperimental study on adversarial behavior in easy and hard attacks under deep\nlearning models with different hyperparameters and different deep learning\nframeworks. We show that the same adversarial attack behaves differently under\ndifferent hyperparameters and across different frameworks due to the different\nfeatures learned under different deep learning model training process. Our\nstatistical characterization with strong empirical evidence provides a\ntransformative enlightenment on mitigation strategies towards effective\ncountermeasures against present and future adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 19:50:25 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 02:43:04 GMT"}, {"version": "v3", "created": "Sun, 30 Dec 2018 21:07:54 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""], ["Loper", "Margaret", ""], ["Truex", "Stacey", ""], ["Yu", "Lei", ""], ["Gursoy", "Mehmet Emre", ""], ["Wu", "Yanzhao", ""]]}, {"id": "1807.00053", "submitter": "Aran Nayebi", "authors": "Aran Nayebi, Daniel Bear, Jonas Kubilius, Kohitij Kar, Surya Ganguli,\n  David Sussillo, James J. DiCarlo, Daniel L. K. Yamins", "title": "Task-Driven Convolutional Recurrent Models of the Visual System", "comments": "NIPS 2018 Camera Ready Version, 16 pages including supplementary\n  information, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward convolutional neural networks (CNNs) are currently\nstate-of-the-art for object classification tasks such as ImageNet. Further,\nthey are quantitatively accurate models of temporally-averaged responses of\nneurons in the primate brain's visual system. However, biological visual\nsystems have two ubiquitous architectural features not shared with typical\nCNNs: local recurrence within cortical areas, and long-range feedback from\ndownstream areas to upstream areas. Here we explored the role of recurrence in\nimproving classification performance. We found that standard forms of\nrecurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the\nImageNet task. In contrast, novel cells that incorporated two structural\nfeatures, bypassing and gating, were able to boost task accuracy substantially.\nWe extended these design principles in an automated search over thousands of\nmodel architectures, which identified novel local recurrent cells and\nlong-range feedback connections useful for object recognition. Moreover, these\ntask-optimized ConvRNNs matched the dynamics of neural activity in the primate\nvisual system better than feedforward networks, suggesting a role for the\nbrain's recurrent connections in performing difficult visual behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 20:27:23 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 03:49:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Nayebi", "Aran", ""], ["Bear", "Daniel", ""], ["Kubilius", "Jonas", ""], ["Kar", "Kohitij", ""], ["Ganguli", "Surya", ""], ["Sussillo", "David", ""], ["DiCarlo", "James J.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1807.00068", "submitter": "Robert McCulloch", "authors": "Edward George and Prakash Laud and Brent Logan and Robert McCulloch\n  and Rodney Sparapani", "title": "Fully Nonparametric Bayesian Additive Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Additive Regression Trees (BART) is a fully Bayesian approach to\nmodeling with ensembles of trees. BART can uncover complex regression functions\nwith high dimensional regressors in a fairly automatic way and provide Bayesian\nquantification of the uncertainty through the posterior. However, BART assumes\nIID normal errors. This strong parametric assumption can lead to misleading\ninference and uncertainty quantification. In this paper, we use the classic\nDirichlet process mixture (DPM) mechanism to nonparametrically model the error\ndistribution. A key strength of BART is that default prior settings work\nreasonably well in a variety of problems. The challenge in extending BART is to\nchoose the parameters of the DPM so that the strengths of the standard BART\napproach is not lost when the errors are close to normal, but the DPM has the\nability to adapt to non-normal errors.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 21:01:06 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 18:47:45 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["George", "Edward", ""], ["Laud", "Prakash", ""], ["Logan", "Brent", ""], ["McCulloch", "Robert", ""], ["Sparapani", "Rodney", ""]]}, {"id": "1807.00083", "submitter": "Thong Q. Nguyen", "authors": "Thong Q. Nguyen, Daniel Weitekamp III, Dustin Anderson, Roberto\n  Castello, Olmo Cerri, Maurizio Pierini, Maria Spiropulu, and Jean-Roch\n  Vlimant", "title": "Topology classification with deep learning to improve real-time event\n  selection at the LHC", "comments": "This is a pre-print of an article published in Computing and Software\n  for Big Science. The final authenticated version is available online at:\n  https://doi.org/10.1007/s41781-019-0028-1", "journal-ref": "Comput Softw Big Sci (2019) 3: 12", "doi": "10.1007/s41781-019-0028-1", "report-no": null, "categories": "hep-ex cs.LG hep-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how event topology classification based on deep learning could be\nused to improve the purity of data samples selected in real time at at the\nLarge Hadron Collider. We consider different data representations, on which\ndifferent kinds of multi-class classifiers are trained. Both raw data and\nhigh-level features are utilized. In the considered examples, a filter based on\nthe classifier's score can be trained to retain ~99% of the interesting events\nand reduce the false-positive rate by as much as one order of magnitude for\ncertain background processes. By operating such a filter as part of the online\nevent selection infrastructure of the LHC experiments, one could benefit from a\nmore flexible and inclusive selection strategy while reducing the amount of\ndownstream resources wasted in processing false positives. The saved resources\ncould be translated into a reduction of the detector operation cost or into an\neffective increase of storage and processing capabilities, which could be\nreinvested to extend the physics reach of the LHC experiments.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 23:07:49 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 23:44:59 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 20:49:03 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Nguyen", "Thong Q.", ""], ["Weitekamp", "Daniel", "III"], ["Anderson", "Dustin", ""], ["Castello", "Roberto", ""], ["Cerri", "Olmo", ""], ["Pierini", "Maurizio", ""], ["Spiropulu", "Maria", ""], ["Vlimant", "Jean-Roch", ""]]}, {"id": "1807.00084", "submitter": "Se Un Park", "authors": "Se Un Park", "title": "A Learning Theory in Linear Systems under Compositional Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning theory for the training of a linear system operator\nhaving an input compositional variable and propose a Bayesian inversion method\nfor inferring the unknown variable from an output of a noisy linear system. We\nassume that we have partial or even no knowledge of the operator but have\ntraining data of input and ouput. A compositional variable satisfies the\nconstraints that the elements of the variable are all non-negative and sum to\nunity. We quantified the uncertainty in the trained operator and present the\nconvergence rates of training in explicit forms for several interesting cases\nunder stochastic compositional models. The trained linear operator with the\ncovariance matrix, estimated from the training set of pairs of ground-truth\ninput and noisy output data, is further used in evaluation of posterior\nuncertainty of the solution. This posterior uncertainty clearly demonstrates\nuncertainty propagation from noisy training data and addresses possible\nmismatch between the true operator and the estimated one in the final solution.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 23:14:30 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Park", "Se Un", ""]]}, {"id": "1807.00095", "submitter": "Mike Ludkovski", "authors": "Sergio Rodriguez and Mike Ludkovski", "title": "Probabilistic Bisection with Spatial Metamodels", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Bisection Algorithm performs root finding based on knowledge\nacquired from noisy oracle responses. We consider the generalized PBA setting\n(G-PBA) where the statistical distribution of the oracle is unknown and\nlocation-dependent, so that model inference and Bayesian knowledge updating\nmust be performed simultaneously. To this end, we propose to leverage the\nspatial structure of a typical oracle by constructing a statistical surrogate\nfor the underlying logistic regression step. We investigate several\nnon-parametric surrogates, including Binomial Gaussian Processes (B-GP),\nPolynomial, Kernel, and Spline Logistic Regression. In parallel, we develop\nsampling policies that adaptively balance learning the oracle distribution and\nlearning the root. One of our proposals mimics active learning with B-GPs and\nprovides a novel look-ahead predictive variance formula. The resulting gains of\nour Spatial PBA algorithm relative to earlier G-PBA models are illustrated with\nsynthetic examples and a challenging stochastic root finding problem from\nBermudan option pricing.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 00:33:41 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Rodriguez", "Sergio", ""], ["Ludkovski", "Mike", ""]]}, {"id": "1807.00099", "submitter": "Braden Hancock", "authors": "Braden Hancock, Hongrae Lee, Cong Yu", "title": "Generating Titles for Web Tables", "comments": "WWW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descriptive titles provide crucial context for interpreting tables that are\nextracted from web pages and are a key component of table-based web\napplications. Prior approaches have attempted to produce titles by selecting\nexisting text snippets associated with the table. These approaches, however,\nare limited by their dependence on suitable titles existing a priori. In our\nuser study, we observe that the relevant information for the title tends to be\nscattered across the page, and often--more than 80% of the time--does not\nappear verbatim anywhere in the page. We propose instead the application of a\nsequence-to-sequence neural network model as a more generalizable means of\ngenerating high-quality titles. This is accomplished by extracting many text\nsnippets that have potentially relevant information to the table, encoding them\ninto an input sequence, and using both copy and generation mechanisms in the\ndecoder to balance relevance and readability of the generated title. We\nvalidate this approach with human evaluation on sample web tables and report\nthat while sequence models with only a copy mechanism or only a generation\nmechanism are easily outperformed by simple selection-based baselines, the\nmodel with both capabilities outperforms them all, approaching the quality of\ncrowdsourced titles while training on fewer than ten thousand examples. To the\nbest of our knowledge, the proposed technique is the first to consider text\ngeneration methods for table titles and establishes a new state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 00:57:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 03:29:05 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hancock", "Braden", ""], ["Lee", "Hongrae", ""], ["Yu", "Cong", ""]]}, {"id": "1807.00122", "submitter": "Sanaz Bahargam", "authors": "Sanaz Bahargam, Evangelos E. Papalexakis", "title": "A Constrained Coupled Matrix-Tensor Factorization for Learning\n  Time-evolving and Emerging Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic discovery has witnessed a significant growth as a field of data mining\nat large. In particular, time-evolving topic discovery, where the evolution of\na topic is taken into account has been instrumental in understanding the\nhistorical context of an emerging topic in a dynamic corpus. Traditionally,\ntime-evolving topic discovery has focused on this notion of time. However,\nespecially in settings where content is contributed by a community or a crowd,\nan orthogonal notion of time is the one that pertains to the level of expertise\nof the content creator: the more experienced the creator, the more advanced the\ntopic. In this paper, we propose a novel time-evolving topic discovery method\nwhich, in addition to the extracted topics, is able to identify the evolution\nof that topic over time, as well as the level of difficulty of that topic, as\nit is inferred by the level of expertise of its main contributors. Our method\nis based on a novel formulation of Constrained Coupled Matrix-Tensor\nFactorization, which adopts constraints well-motivated for, and, as we\ndemonstrate, are essential for high-quality topic discovery. We qualitatively\nevaluate our approach using real data from the Physics and also Programming\nStack Exchange forum, and we were able to identify topics of varying levels of\ndifficulty which can be linked to external events, such as the announcement of\ngravitational waves by the LIGO lab in Physics forum. We provide a quantitative\nevaluation of our method by conducting a user study where experts were asked to\njudge the coherence and quality of the extracted topics. Finally, our proposed\nmethod has implications for automatic curriculum design using the extracted\ntopics, where the notion of the level of difficulty is necessary for the proper\nmodeling of prerequisites and advanced concepts.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 04:07:00 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Bahargam", "Sanaz", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1807.00123", "submitter": "Marinka Zitnik", "authors": "Marinka Zitnik, Francis Nguyen, Bo Wang, Jure Leskovec, Anna\n  Goldenberg, Michael M. Hoffman", "title": "Machine Learning for Integrating Data in Biology and Medicine:\n  Principles, Practice, and Opportunities", "comments": null, "journal-ref": "Information Fusion 50 (2019) 71-91", "doi": "10.1016/j.inffus.2018.09.012", "report-no": null, "categories": "q-bio.QM cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New technologies have enabled the investigation of biology and human health\nat an unprecedented scale and in multiple dimensions. These dimensions include\na myriad of properties describing genome, epigenome, transcriptome, microbiome,\nphenotype, and lifestyle. No single data type, however, can capture the\ncomplexity of all the factors relevant to understanding a phenomenon such as a\ndisease. Integrative methods that combine data from multiple technologies have\nthus emerged as critical statistical and computational approaches. The key\nchallenge in developing such approaches is the identification of effective\nmodels to provide a comprehensive and relevant systems view. An ideal method\ncan answer a biological or medical question, identifying important features and\npredicting outcomes, by harnessing heterogeneous data across several dimensions\nof biological variation. In this Review, we describe the principles of data\nintegration and discuss current methods and available implementations. We\nprovide examples of successful data integration in biology and medicine.\nFinally, we discuss current challenges in biomedical integrative methods and\nour perspective on the future development of the field.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 04:31:59 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 18:35:23 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Zitnik", "Marinka", ""], ["Nguyen", "Francis", ""], ["Wang", "Bo", ""], ["Leskovec", "Jure", ""], ["Goldenberg", "Anna", ""], ["Hoffman", "Michael M.", ""]]}, {"id": "1807.00126", "submitter": "Jason Ramapuram", "authors": "Jason Ramapuram, Russ Webb", "title": "A New Benchmark and Progress Toward Improved Weakly Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Matters: Importance of Prior Information for Optimization [7], by\nGulcehre et. al., sought to establish the limits of current black-box, deep\nlearning techniques by posing problems which are difficult to learn without\nengineering knowledge into the model or training procedure. In our work, we\ncompletely solve the previous Knowledge Matters problem using a generic model,\npose a more difficult and scalable problem, All-Pairs, and advance this new\nproblem by introducing a new learned, spatially-varying histogram model called\nTypeNet which outperforms conventional models on the problem. We present\nresults on All-Pairs where our model achieves 100% test accuracy while the best\nResNet models achieve 79% accuracy. In addition, our model is more than an\norder of magnitude smaller than Resnet-34. The challenge of solving\nlarger-scale All-Pairs problems with high accuracy is presented to the\ncommunity for investigation.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 05:21:33 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 15:05:33 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Ramapuram", "Jason", ""], ["Webb", "Russ", ""]]}, {"id": "1807.00130", "submitter": "Guang-He Lee", "authors": "Guang-He Lee, David Alvarez-Melis, Tommi S. Jaakkola", "title": "Game-Theoretic Interpretability for Temporal Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has arisen as a key desideratum of machine learning models\nalongside performance. Approaches so far have been primarily concerned with\nfixed dimensional inputs emphasizing feature relevance or selection. In\ncontrast, we focus on temporal modeling and the problem of tailoring the\npredictor, functionally, towards an interpretable family. To this end, we\npropose a co-operative game between the predictor and an explainer without any\na priori restrictions on the functional class of the predictor. The goal of the\nexplainer is to highlight, locally, how well the predictor conforms to the\nchosen interpretable family of temporal models. Our co-operative game is setup\nasymmetrically in terms of information sets for efficiency reasons. We develop\nand illustrate the framework in the context of temporal sequence models with\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 06:13:31 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Lee", "Guang-He", ""], ["Alvarez-Melis", "David", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1807.00172", "submitter": "Vyacheslav Kungurtsev", "authors": "Vyacheslav Kungurtsev and Tomas Pevny", "title": "Algorithms for solving optimization problems arising from deep neural\n  net models: smooth problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "Cisco Prague WP5 Project Report 2016-01", "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning models incorporating multiple layered learning networks have\nbeen seen to provide effective models for various classification problems. The\nresulting optimization problem to solve for the optimal vector minimizing the\nempirical risk is, however, highly nonlinear. This presents a challenge to\napplication and development of appropriate optimization algorithms for solving\nthe problem. In this paper, we summarize the primary challenges involved and\npresent the case for a Newton-based method incorporating directions of negative\ncurvature, including promising numerical results on data arising from security\nanomally deetection.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 13:00:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kungurtsev", "Vyacheslav", ""], ["Pevny", "Tomas", ""]]}, {"id": "1807.00173", "submitter": "Vyacheslav Kungurtsev", "authors": "Vyacheslav Kungurtsev and Tomas Pevny", "title": "Algorithms for solving optimization problems arising from deep neural\n  net models: nonsmooth problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "Cisco Prague WP5 Report 2016-02", "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning models incorporating multiple layered learning networks have\nbeen seen to provide effective models for various classification problems. The\nresulting optimization problem to solve for the optimal vector minimizing the\nempirical risk is, however, highly nonconvex. This alone presents a challenge\nto application and development of appropriate optimization algorithms for\nsolving the problem. However, in addition, there are a number of interesting\nproblems for which the objective function is non- smooth and nonseparable. In\nthis paper, we summarize the primary challenges involved, the state of the art,\nand present some numerical results on an interesting and representative class\nof problems.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 13:03:48 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kungurtsev", "Vyacheslav", ""], ["Pevny", "Tomas", ""]]}, {"id": "1807.00199", "submitter": "Christina Wadsworth", "authors": "Christina Wadsworth, Francesca Vera, Chris Piech", "title": "Achieving Fairness through Adversarial Learning: an Application to\n  Recidivism Prediction", "comments": "To be published in FAT/ML, 2018, Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recidivism prediction scores are used across the USA to determine sentencing\nand supervision for hundreds of thousands of inmates. One such generator of\nrecidivism prediction scores is Northpointe's Correctional Offender Management\nProfiling for Alternative Sanctions (COMPAS) score, used in states like\nCalifornia and Florida, which past research has shown to be biased against\nblack inmates according to certain measures of fairness. To counteract this\nracial bias, we present an adversarially-trained neural network that predicts\nrecidivism and is trained to remove racial bias. When comparing the results of\nour model to COMPAS, we gain predictive accuracy and get closer to achieving\ntwo out of three measures of fairness: parity and equality of odds. Our model\ncan be generalized to any prediction and demographic. This piece of research\ncontributes an example of scientific replication and simplification in a\nhigh-stakes real-world application like recidivism prediction.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 16:43:23 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wadsworth", "Christina", ""], ["Vera", "Francesca", ""], ["Piech", "Chris", ""]]}, {"id": "1807.00202", "submitter": "Yu Liu", "authors": "Yu Liu, Guanlong Zhao, Boyuan Gong, Yang Li, Ritu Raj, Niraj Goel,\n  Satya Kesav, Sandeep Gottimukkala, Zhangyang Wang, Wenqi Ren, Dacheng Tao", "title": "Improved Techniques for Learning to Dehaze and Beyond: A Collective\n  Study", "comments": "updated: typo fixed and some other improvements on writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we explore two related but important tasks based on the recently\nreleased REalistic Single Image DEhazing (RESIDE) benchmark dataset: (i) single\nimage dehazing as a low-level image restoration problem; and (ii) high-level\nvisual understanding (e.g., object detection) of hazy images. For the first\ntask, we investigated a variety of loss functions and show that\nperception-driven loss significantly improves dehazing performance. In the\nsecond task, we provide multiple solutions including using advanced modules in\nthe dehazing-detection cascade and domain-adaptive object detectors. In both\ntasks, our proposed solutions significantly improve performance. GitHub\nrepository URL is: https://github.com/guanlongzhao/dehaze\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 16:52:33 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 03:58:30 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Yu", ""], ["Zhao", "Guanlong", ""], ["Gong", "Boyuan", ""], ["Li", "Yang", ""], ["Raj", "Ritu", ""], ["Goel", "Niraj", ""], ["Kesav", "Satya", ""], ["Gottimukkala", "Sandeep", ""], ["Wang", "Zhangyang", ""], ["Ren", "Wenqi", ""], ["Tao", "Dacheng", ""]]}, {"id": "1807.00211", "submitter": "Evgeny Lavrik", "authors": "E. Lavrik and I. Panasenko and H.R. Schmidt", "title": "Advanced Methods for the Optical Quality Assurance of Silicon Sensors", "comments": null, "journal-ref": null, "doi": "10.1016/j.nima.2018.10.210", "report-no": null, "categories": "physics.ins-det cs.LG hep-ex nucl-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a setup for optical quality assurance of silicon microstrip\nsensors. Pattern recognition algorithms were developed to analyze microscopic\nscans of the sensors for defects. It is shown that the software has a\nrecognition and classification rate of $>$~90\\% for defects like scratches,\nshorts, broken metal lines etc. We have demonstrated that advanced image\nprocessing based on neural network techniques is able to further improve the\nrecognition and defect classification rate.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 17:56:51 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:16:47 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Lavrik", "E.", ""], ["Panasenko", "I.", ""], ["Schmidt", "H. R.", ""]]}, {"id": "1807.00228", "submitter": "Yunpu Ma", "authors": "Yunpu Ma, Volker Tresp, Erik Daxberger", "title": "Embedding Models for Episodic Knowledge Graphs", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years a number of large-scale triple-oriented knowledge graphs have\nbeen generated and various models have been proposed to perform learning in\nthose graphs. Most knowledge graphs are static and reflect the world in its\ncurrent state. In reality, of course, the state of the world is changing: a\nhealthy person becomes diagnosed with a disease and a new president is\ninaugurated. In this paper, we extend models for static knowledge graphs to\ntemporal knowledge graphs. This enables us to store episodic data and to\ngeneralize to new facts (inductive learning). We generalize leading learning\nmodels for static knowledge graphs (i.e., Tucker, RESCAL, HolE, ComplEx,\nDistMult) to temporal knowledge graphs. In particular, we introduce a new\ntensor model, ConT, with superior generalization performance. The performances\nof all proposed models are analyzed on two different datasets: the Global\nDatabase of Events, Language, and Tone (GDELT) and the database for Integrated\nConflict Early Warning System (ICEWS). We argue that temporal knowledge graph\nembeddings might be models also for cognitive episodic memory (facts we\nremember and can recollect) and that a semantic memory (current facts we know)\ncan be generated from episodic memory by a marginalization operation. We\nvalidate this episodic-to-semantic projection hypothesis with the ICEWS\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 21:25:04 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 19:20:25 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""], ["Daxberger", "Erik", ""]]}, {"id": "1807.00243", "submitter": "Jeremy Ash", "authors": "Jeremy R. Ash Jacqueline M. Hughes-Oliver", "title": "chemmodlab: A Cheminformatics Modeling Laboratory for Fitting and\n  Assessing Machine Learning Models", "comments": "21 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of chemmodlab is to streamline the fitting and assessment pipeline\nfor many machine learning models in R, making it easy for researchers to\ncompare the utility of new models. While focused on implementing methods for\nmodel fitting and assessment that have been accepted by experts in the\ncheminformatics field, all of the methods in chemmodlab have broad utility for\nthe machine learning community. chemmodlab contains several assessment\nutilities including a plotting function that constructs accumulation curves and\na function that computes many performance measures. The most novel feature of\nchemmodlab is the ease with which statistically significant performance\ndifferences for many machine learning models is presented by means of the\nmultiple comparisons similarity plot. Differences are assessed using repeated\nk-fold cross validation where blocking increases precision and multiplicity\nadjustments are applied.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 23:17:41 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 17:11:05 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2018 03:02:31 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Hughes-Oliver", "Jeremy R. Ash Jacqueline M.", ""]]}, {"id": "1807.00244", "submitter": "Andrey Gritsenko", "authors": "Andrey Gritsenko, Martin A. Lindquist, Gregory R. Kirk, Moo K. Chung", "title": "Automatic Identification of Twin Zygosity in Resting-State Functional\n  MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key strength of twin studies arises from the fact that there are two types\nof twins, monozygotic and dizygotic, that share differing amounts of genetic\ninformation. Accurate differentiation of twin types allows efficient inference\non genetic influences in a population. However, identification of zygosity is\noften prone to errors without genotying. In this study, we propose a novel\npairwise feature representation to classify the zygosity of twin pairs of\nresting state functional magnetic resonance images (rs-fMRI). For this, we\nproject an fMRI signal to a set of basis functions and use the projection\ncoefficients as the compact and discriminative feature representation of noisy\nfMRI. We encode the relationship between twins as the correlation between the\nnew feature representations across brain regions. We employ hill climbing\nvariable selection to identify brain regions that are the most genetically\naffected. The proposed framework was applied to 208 twin pairs and achieved\n94.19% classification accuracy in automatically identifying the zygosity of\npaired images.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 23:31:00 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 01:39:19 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 20:48:03 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 18:06:03 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Gritsenko", "Andrey", ""], ["Lindquist", "Martin A.", ""], ["Kirk", "Gregory R.", ""], ["Chung", "Moo K.", ""]]}, {"id": "1807.00251", "submitter": "Jennifer Erway", "authors": "Jennifer B. Erway, Joshua Griffin, Roummel F. Marcia, and Riadh Omheni", "title": "Trust-Region Algorithms for Training Responses: Machine Learning Methods\n  Using Indefinite Hessian Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) problems are often posed as highly nonlinear and\nnonconvex unconstrained optimization problems. Methods for solving ML problems\nbased on stochastic gradient descent are easily scaled for very large problems\nbut may involve fine-tuning many hyper-parameters. Quasi-Newton approaches\nbased on the limited-memory Broyden-Fletcher-Goldfarb-Shanno (BFGS) update\ntypically do not require manually tuning hyper-parameters but suffer from\napproximating a potentially indefinite Hessian with a positive-definite matrix.\nHessian-free methods leverage the ability to perform Hessian-vector\nmultiplication without needing the entire Hessian matrix, but each iteration's\ncomplexity is significantly greater than quasi-Newton methods. In this paper we\npropose an alternative approach for solving ML problems based on a quasi-Newton\ntrust-region framework for solving large-scale optimization problems that allow\nfor indefinite Hessian approximations. Numerical experiments on a standard\ntesting data set show that with a fixed computational time budget, the proposed\nmethods achieve better results than the traditional limited-memory BFGS and the\nHessian-free methods.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 01:08:40 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 02:24:05 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 00:47:06 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Erway", "Jennifer B.", ""], ["Griffin", "Joshua", ""], ["Marcia", "Roummel F.", ""], ["Omheni", "Riadh", ""]]}, {"id": "1807.00255", "submitter": "Damek Davis", "authors": "Damek Davis, Dmitriy Drusvyatskiy, Kellie J. MacPhee", "title": "Stochastic model-based minimization under high-order growth", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a nonsmooth, nonconvex minimization problem, we consider algorithms\nthat iteratively sample and minimize stochastic convex models of the objective\nfunction. Assuming that the one-sided approximation quality and the variation\nof the models is controlled by a Bregman divergence, we show that the scheme\ndrives a natural stationarity measure to zero at the rate $O(k^{-1/4})$. Under\nadditional convexity and relative strong convexity assumptions, the function\nvalues converge to the minimum at the rate of $O(k^{-1/2})$ and\n$\\widetilde{O}(k^{-1})$, respectively. We discuss consequences for stochastic\nproximal point, mirror descent, regularized Gauss-Newton, and saddle point\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 01:49:22 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""], ["MacPhee", "Kellie J.", ""]]}, {"id": "1807.00263", "submitter": "Volodymyr Kuleshov", "authors": "Volodymyr Kuleshov, Nathan Fenner, Stefano Ermon", "title": "Accurate Uncertainties for Deep Learning Using Calibrated Regression", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for reasoning under uncertainty are a key building block of accurate\nand reliable machine learning systems. Bayesian methods provide a general\nframework to quantify uncertainty. However, because of model misspecification\nand the use of approximate inference, Bayesian uncertainty estimates are often\ninaccurate -- for example, a 90% credible interval may not contain the true\noutcome 90% of the time. Here, we propose a simple procedure for calibrating\nany regression algorithm; when applied to Bayesian and probabilistic models, it\nis guaranteed to produce calibrated uncertainty estimates given enough data.\nOur procedure is inspired by Platt scaling and extends previous work on\nclassification. We evaluate this approach on Bayesian linear regression,\nfeedforward, and recurrent neural networks, and find that it consistently\noutputs well-calibrated credible intervals while improving performance on time\nseries forecasting and model-based reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 03:31:32 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kuleshov", "Volodymyr", ""], ["Fenner", "Nathan", ""], ["Ermon", "Stefano", ""]]}, {"id": "1807.00275", "submitter": "Fangchang Ma", "authors": "Fangchang Ma, Guilherme Venturelli Cavalheiro, Sertac Karaman", "title": "Self-supervised Sparse-to-Dense: Self-supervised Depth Completion from\n  LiDAR and Monocular Camera", "comments": "Software:\n  https://github.com/fangchangma/self-supervised-depth-completion . Video:\n  https://youtu.be/bGXfvF261pc . 12 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth completion, the technique of estimating a dense depth image from sparse\ndepth measurements, has a variety of applications in robotics and autonomous\ndriving. However, depth completion faces 3 main challenges: the irregularly\nspaced pattern in the sparse depth input, the difficulty in handling multiple\nsensor modalities (when color images are available), as well as the lack of\ndense, pixel-level ground truth depth labels. In this work, we address all\nthese challenges. Specifically, we develop a deep regression model to learn a\ndirect mapping from sparse depth (and color images) to dense depth. We also\npropose a self-supervised training framework that requires only sequences of\ncolor and sparse depth images, without the need for dense depth labels. Our\nexperiments demonstrate that our network, when trained with semi-dense\nannotations, attains state-of-the- art accuracy and is the winning approach on\nthe KITTI depth completion benchmark at the time of submission. Furthermore,\nthe self-supervised framework outperforms a number of existing solutions\ntrained with semi- dense annotations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 06:02:48 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 00:47:09 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Ma", "Fangchang", ""], ["Cavalheiro", "Guilherme Venturelli", ""], ["Karaman", "Sertac", ""]]}, {"id": "1807.00284", "submitter": "Yong Xia", "authors": "Benteng Ma, Yong Xia", "title": "Autonomous Deep Learning: A Genetic DCNN Designer for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the breakthrough success of deep convolutional\nneural networks (DCNNs) in image classification and other vision applications.\nAlthough freeing users from the troublesome handcrafted feature extraction by\nproviding a uniform feature extraction-classification framework, DCNNs still\nrequire a handcrafted design of their architectures. In this paper, we propose\nthe genetic DCNN designer, an autonomous learning algorithm can generate a DCNN\narchitecture automatically based on the data available for a specific image\nclassification problem. We first partition a DCNN into multiple stacked meta\nconvolutional blocks and fully connected blocks, each containing the operations\nof convolution, pooling, fully connection, batch normalization, activation and\ndrop out, and thus convert the architecture into an integer vector. Then, we\nuse refined evolutionary operations, including selection, mutation and\ncrossover to evolve a population of DCNN architectures. Our results on the\nMNIST, Fashion-MNIST, EMNISTDigit, EMNIST-Letter, CIFAR10 and CIFAR100 datasets\nsuggest that the proposed genetic DCNN designer is able to produce\nautomatically DCNN architectures, whose performance is comparable to, if not\nbetter than, that of stateof- the-art DCNN models\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 07:11:54 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Ma", "Benteng", ""], ["Xia", "Yong", ""]]}, {"id": "1807.00297", "submitter": "Qingcan Wang", "authors": "Weinan E and Qingcan Wang", "title": "Exponential Convergence of the Deep Neural Network Approximation for\n  Analytic Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for analytic functions in low dimension, the convergence rate\nof the deep neural network approximation is exponential.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 09:01:52 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["E", "Weinan", ""], ["Wang", "Qingcan", ""]]}, {"id": "1807.00298", "submitter": "JunPing Wang", "authors": "JunPing Wang, WenSheng Zhang, Ian Thomas, ShiHui Duan, YouKang Shi", "title": "Multi-Task Generative Adversarial Nets with Shared Memory for\n  Cross-Domain Coordination Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generating sequential decision process from huge amounts of measured process\ndata is a future research direction for collaborative factory automation,\nmaking full use of those online or offline process data to directly design\nflexible make decisions policy, and evaluate performance. The key challenges\nfor the sequential decision process is to online generate sequential\ndecision-making policy directly, and transferring knowledge across tasks\ndomain. Most multi-task policy generating algorithms often suffer from\ninsufficient generating cross-task sharing structure at discrete-time nonlinear\nsystems with applications. This paper proposes the multi-task generative\nadversarial nets with shared memory for cross-domain coordination control,\nwhich can generate sequential decision policy directly from raw sensory input\nof all of tasks, and online evaluate performance of system actions in\ndiscrete-time nonlinear systems. Experiments have been undertaken using a\nprofessional flexible manufacturing testbed deployed within a smart factory of\nWeichai Power in China. Results on three groups of discrete-time nonlinear\ncontrol tasks show that our proposed model can availably improve the\nperformance of task with the help of other related tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 09:07:04 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "JunPing", ""], ["Zhang", "WenSheng", ""], ["Thomas", "Ian", ""], ["Duan", "ShiHui", ""], ["Shi", "YouKang", ""]]}, {"id": "1807.00311", "submitter": "Yanru Qu", "authors": "Yanru Qu, Bohui Fang, Weinan Zhang, Ruiming Tang, Minzhe Niu, Huifeng\n  Guo, Yong Yu, Xiuqiang He", "title": "Product-based Neural Networks for User Response Prediction over\n  Multi-field Categorical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User response prediction is a crucial component for personalized information\nretrieval and filtering scenarios, such as recommender system and web search.\nThe data in user response prediction is mostly in a multi-field categorical\nformat and transformed into sparse representations via one-hot encoding. Due to\nthe sparsity problems in representation and optimization, most research focuses\non feature engineering and shallow modeling. Recently, deep neural networks\nhave attracted research attention on such a problem for their high capacity and\nend-to-end training scheme. In this paper, we study user response prediction in\nthe scenario of click prediction. We first analyze a coupled gradient issue in\nlatent vector-based models and propose kernel product to learn field-aware\nfeature interactions. Then we discuss an insensitive gradient issue in\nDNN-based models and propose Product-based Neural Network (PNN) which adopts a\nfeature extractor to explore feature interactions. Generalizing the kernel\nproduct to a net-in-net architecture, we further propose Product-network In\nNetwork (PIN) which can generalize previous models. Extensive experiments on 4\nindustrial datasets and 1 contest dataset demonstrate that our models\nconsistently outperform 8 baselines on both AUC and log loss. Besides, PIN\nmakes great CTR improvement (relatively 34.67%) in online A/B test.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 11:02:50 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Qu", "Yanru", ""], ["Fang", "Bohui", ""], ["Zhang", "Weinan", ""], ["Tang", "Ruiming", ""], ["Niu", "Minzhe", ""], ["Guo", "Huifeng", ""], ["Yu", "Yong", ""], ["He", "Xiuqiang", ""]]}, {"id": "1807.00340", "submitter": "Pengqian Yu", "authors": "Xinhan Di, Pengqian Yu, Meng Tian", "title": "Towards Adversarial Training with Moderate Performance Improvement for\n  Neural Network Classification", "comments": "Accepted for publication in Uncertainty in Deep Learning Workshop at\n  Uncertainty in Artificial Intelligence (UAI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated that deep neural networks are prone to noisy\nexamples particular adversarial samples during inference process. The gap\nbetween robust deep learning systems in real world applications and vulnerable\nneural networks is still large. Current adversarial training strategies improve\nthe robustness against adversarial samples. However, these methods lead to\naccuracy reduction when the input examples are clean thus hinders the\npracticability. In this paper, we investigate an approach that protects the\nneural network classification from the adversarial samples and improves its\naccuracy when the input examples are clean. We demonstrate the versatility and\neffectiveness of our proposed approach on a variety of different networks and\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 15:08:52 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Di", "Xinhan", ""], ["Yu", "Pengqian", ""], ["Tian", "Meng", ""]]}, {"id": "1807.00349", "submitter": "Melanie Weber", "authors": "F. Patricia Medina, Linda Ness and Melanie Weber, Karamatou Yacoubou\n  Djima", "title": "Heuristic Framework for Multi-Scale Testing of the Multi-Manifold\n  Hypothesis", "comments": "Workshop paper (Women in Data Science and Mathematics Research\n  Collaboration Workshop (WiSDM); ICERM, July 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When analyzing empirical data, we often find that global linear models\noverestimate the number of parameters required. In such cases, we may ask\nwhether the data lies on or near a manifold or a set of manifolds (a so-called\nmulti-manifold) of lower dimension than the ambient space. This question can be\nphrased as a (multi-) manifold hypothesis. The identification of such intrinsic\nmultiscale features is a cornerstone of data analysis and representation and\nhas given rise to a large body of work on manifold learning. In this work, we\nreview key results on multi-scale data analysis and intrinsic dimension\nfollowed by the introduction of a heuristic, multiscale framework for testing\nthe multi-manifold hypothesis. Our method implements a hypothesis test on a set\nof spline-interpolated manifolds constructed from variance-based intrinsic\ndimensions. The workflow is suitable for empirical data analysis as we\ndemonstrate on two use cases.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 16:08:41 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Medina", "F. Patricia", ""], ["Ness", "Linda", ""], ["Weber", "Melanie", ""], ["Djima", "Karamatou Yacoubou", ""]]}, {"id": "1807.00366", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang, Tongfang Sun, Xianjun Sam Zheng", "title": "Beyond Winning and Losing: Modeling Human Motivations and Behaviors\n  Using Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, reinforcement learning (RL) methods have been applied to\nmodel gameplay with great success, achieving super-human performance in various\nenvironments, such as Atari, Go, and Poker. However, those studies mostly focus\non winning the game and have largely ignored the rich and complex human\nmotivations, which are essential for understanding different players' diverse\nbehaviors. In this paper, we present a novel method called Multi-Motivation\nBehavior Modeling (MMBM) that takes the multifaceted human motivations into\nconsideration and models the underlying value structure of the players using\ninverse RL. Our approach does not require the access to the dynamic of the\nsystem, making it feasible to model complex interactive environments such as\nmassively multiplayer online games. MMBM is tested on the World of Warcraft\nAvatar History dataset, which recorded over 70,000 users' gameplay spanning\nthree years period. Our model reveals the significant difference of value\nstructures among different player groups. Using the results of motivation\nmodeling, we also predict and explain their diverse gameplay behaviors and\nprovide a quantitative assessment of how the redesign of the game environment\nimpacts players' behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 18:20:23 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 09:14:00 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Wang", "Baoxiang", ""], ["Sun", "Tongfang", ""], ["Zheng", "Xianjun Sam", ""]]}, {"id": "1807.00373", "submitter": "Ran Rubin", "authors": "Ran Rubin", "title": "New Heuristics for Parallel and Scalable Bayesian Optimization", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has emerged as a strong candidate tool for global\noptimization of functions with expensive evaluation costs. However, due to the\ndynamic nature of research in Bayesian approaches, and the evolution of\ncomputing technology, using Bayesian optimization in a parallel computing\nenvironment remains a challenge for the non-expert. In this report, I review\nthe state-of-the-art in parallel and scalable Bayesian optimization methods. In\naddition, I propose practical ways to avoid a few of the pitfalls of Bayesian\noptimization, such as oversampling of edge parameters and over-exploitation of\nhigh performance parameters. Finally, I provide relatively simple, heuristic\nalgorithms, along with their open source software implementations, that can be\nimmediately and easily deployed in any computing environment.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 19:09:15 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 01:39:44 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Rubin", "Ran", ""]]}, {"id": "1807.00374", "submitter": "Ehsan Hosseini-Asl", "authors": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher", "title": "Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation", "comments": "14 pages, 5 figures, 8 tables; Accepted as a conference paper at ICLR\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a model to perform a task typically requires a large amount of data\nfrom the domains in which the task will be applied. However, it is often the\ncase that data are abundant in some domains but scarce in others. Domain\nadaptation deals with the challenge of adapting a model trained from a\ndata-rich source domain to perform well in a data-poor target domain. In\ngeneral, this requires learning plausible mappings between domains. CycleGAN is\na powerful framework that efficiently learns to map inputs from one domain to\nanother using adversarial training and a cycle-consistency constraint. However,\nthe conventional approach of enforcing cycle-consistency via reconstruction may\nbe overly restrictive in cases where one or more domains have limited training\ndata. In this paper, we propose an augmented cyclic adversarial learning model\nthat enforces the cycle-consistency constraint via an external task specific\nmodel, which encourages the preservation of task-relevant content as opposed to\nexact reconstruction. We explore digit classification in a low-resource setting\nin supervised, semi and unsupervised situation, as well as high resource\nunsupervised. In low-resource supervised setting, the results show that our\napproach improves absolute performance by 14% and 4% when adapting SVHN to\nMNIST and vice versa, respectively, which outperforms unsupervised domain\nadaptation methods that require high-resource unlabeled target domain.\nMoreover, using only few unsupervised target data, our approach can still\noutperforms many high-resource unsupervised models. In speech domains, we\nsimilarly adopt a speech recognition model from each domain as the task\nspecific model. Our approach improves absolute performance of speech\nrecognition by 2% for female speakers in the TIMIT dataset, where the majority\nof training samples are from male voices.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 19:16:11 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 23:36:19 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 23:18:45 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 19:35:27 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Hosseini-Asl", "Ehsan", ""], ["Zhou", "Yingbo", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1807.00381", "submitter": "Oliver Schulte", "authors": "Fatemeh Riahi and Oliver Schulte", "title": "Model-based Exception Mining for Object-Relational Data", "comments": "StarAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is based on a previous publication [29]. Our work extends\nexception mining and outlier detection to the case of object-relational data.\nObject-relational data represent a complex heterogeneous network [12], which\ncomprises objects of different types, links among these objects, also of\ndifferent types, and attributes of these links. This special structure\nprohibits a direct vectorial data representation. We follow the\nwell-established Exceptional Model Mining framework, which leverages machine\nlearning models for exception mining: A object is exceptional to the extent\nthat a model learned for the object data differs from a model learned for the\ngeneral population. Exceptional objects can be viewed as outliers. We apply\nstate of-the-art probabilistic modelling techniques for object-relational data\nthat construct a graphical model (Bayesian network), which compactly represents\nprobabilistic associations in the data. A new metric, derived from the learned\nobject-relational model, quantifies the extent to which the individual\nassociation pattern of a potential outlier deviates from that of the whole\npopulation. The metric is based on the likelihood ratio of two parameter\nvectors: One that represents the population associations, and another that\nrepresents the individual associations. Our method is validated on synthetic\ndatasets and on real-world data sets about soccer matches and movies. Compared\nto baseline methods, our novel transformed likelihood ratio achieved the best\ndetection accuracy on all datasets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 19:42:02 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Riahi", "Fatemeh", ""], ["Schulte", "Oliver", ""]]}, {"id": "1807.00392", "submitter": "Edward Raff", "authors": "Edward Raff and Jared Sylvester", "title": "Gradient Reversal Against Discrimination", "comments": "Proceedings of the 5'th Workshop on Fairness, Accountability and\n  Transparency in Machine Learning, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No methods currently exist for making arbitrary neural networks fair. In this\nwork we introduce GRAD, a new and simplified method to producing fair neural\nnetworks that can be used for auto-encoding fair representations or directly\nwith predictive networks. It is easy to implement and add to existing\narchitectures, has only one (insensitive) hyper-parameter, and provides\nimproved individual and group fairness. We use the flexibility of GRAD to\ndemonstrate multi-attribute protection.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 20:46:20 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Raff", "Edward", ""], ["Sylvester", "Jared", ""]]}, {"id": "1807.00400", "submitter": "Maria Lomeli Dr", "authors": "Maria Lomeli, Mark Rowland, Arthur Gretton, Zoubin Ghahramani", "title": "Antithetic and Monte Carlo kernel estimators for partial rankings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern age, rankings data is ubiquitous and it is useful for a variety\nof applications such as recommender systems, multi-object tracking and\npreference learning. However, most rankings data encountered in the real world\nis incomplete, which prevents the direct application of existing modelling\ntools for complete rankings. Our contribution is a novel way to extend kernel\nmethods for complete rankings to partial rankings, via consistent Monte Carlo\nestimators for Gram matrices: matrices of kernel values between pairs of\nobservations. We also present a novel variance reduction scheme based on an\nantithetic variate construction between permutations to obtain an improved\nestimator for the Mallows kernel. The corresponding antithetic kernel estimator\nhas lower variance and we demonstrate empirically that it has a better\nperformance in a variety of Machine Learning tasks. Both kernel estimators are\nbased on extending kernel mean embeddings to the embedding of a set of full\nrankings consistent with an observed partial ranking. They form a\ncomputationally tractable alternative to previous approaches for partial\nrankings data. An overview of the existing kernels and metrics for permutations\nis also provided.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:49:40 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 20:49:21 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lomeli", "Maria", ""], ["Rowland", "Mark", ""], ["Gretton", "Arthur", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1807.00403", "submitter": "Kumar Krishna Agrawal", "authors": "Surya Bhupatiraju, Kumar Krishna Agrawal, Rishabh Singh", "title": "Towards Mixed Optimization for Reinforcement Learning with Program\n  Synthesis", "comments": "Updated publication details, format. Accepted at NAMPI workshop, ICML\n  '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has led to several recent breakthroughs, though\nthe learned policies are often based on black-box neural networks. This makes\nthem difficult to interpret and to impose desired specification constraints\nduring learning. We present an iterative framework, MORL, for improving the\nlearned policies using program synthesis. Concretely, we propose to use\nsynthesis techniques to obtain a symbolic representation of the learned policy,\nwhich can then be debugged manually or automatically using program repair.\nAfter the repair step, we use behavior cloning to obtain the policy\ncorresponding to the repaired program, which is then further improved using\ngradient descent. This process continues until the learned policy satisfies\ndesired constraints. We instantiate MORL for the simple CartPole problem and\nshow that the programmatic representation allows for high-level modifications\nthat in turn lead to improved learning of the policies.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:52:07 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 22:08:06 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Bhupatiraju", "Surya", ""], ["Agrawal", "Kumar Krishna", ""], ["Singh", "Rishabh", ""]]}, {"id": "1807.00412", "submitter": "Alex Kendall", "authors": "Alex Kendall, Jeffrey Hawke, David Janz, Przemyslaw Mazur, Daniele\n  Reda, John-Mark Allen, Vinh-Dieu Lam, Alex Bewley and Amar Shah", "title": "Learning to Drive in a Day", "comments": "Further results and demo videos can be viewed at:\n  https://wayve.ai/blog/l2diad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first application of deep reinforcement learning to\nautonomous driving. From randomly initialised parameters, our model is able to\nlearn a policy for lane following in a handful of training episodes using a\nsingle monocular image as input. We provide a general and easy to obtain\nreward: the distance travelled by the vehicle without the safety driver taking\ncontrol. We use a continuous, model-free deep reinforcement learning algorithm,\nwith all exploration and optimisation performed on-vehicle. This demonstrates a\nnew framework for autonomous driving which moves away from reliance on defined\nlogical rules, mapping, and direct supervision. We discuss the challenges and\nopportunities to scale this approach to a broader range of autonomous driving\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 22:47:08 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 13:56:13 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Kendall", "Alex", ""], ["Hawke", "Jeffrey", ""], ["Janz", "David", ""], ["Mazur", "Przemyslaw", ""], ["Reda", "Daniele", ""], ["Allen", "John-Mark", ""], ["Lam", "Vinh-Dieu", ""], ["Bewley", "Alex", ""], ["Shah", "Amar", ""]]}, {"id": "1807.00414", "submitter": "Masayuki Ohzeki", "authors": "Masayuki Ohzeki, Shuntaro Okada, Masayoshi Terabe, and Shinichiro\n  Taguchi", "title": "Optimization of neural networks via finite-value quantum fluctuations", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We numerically test an optimization method for deep neural networks (DNNs)\nusing quantum fluctuations inspired by quantum annealing. For efficient\noptimization, our method utilizes the quantum tunneling effect beyond the\npotential barriers. The path integral formulation of the DNN optimization\ngenerates an attracting force to simulate the quantum tunneling effect. In the\nstandard quantum annealing method, the quantum fluctuations will vanish at the\nlast stage of optimization. In this study, we propose a learning protocol that\nutilizes a finite value for quantum fluctuations strength to obtain higher\ngeneralization performance, which is a type of robustness. We demonstrate the\nperformance of our method using two well-known open datasets: the MNIST dataset\nand the Olivetti face dataset. Although computational costs prevent us from\ntesting our method on large datasets with high-dimensional data, results show\nthat our method can enhance generalization performance by induction of the\nfinite value for quantum fluctuations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 23:18:49 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Ohzeki", "Masayuki", ""], ["Okada", "Shuntaro", ""], ["Terabe", "Masayoshi", ""], ["Taguchi", "Shinichiro", ""]]}, {"id": "1807.00425", "submitter": "Mark Harmon", "authors": "Mark Harmon, Diego Klabjan", "title": "Dynamic Prediction Length for Time Series with Sequence to Sequence\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks and sequence to sequence models require a\npredetermined length for prediction output length. Our model addresses this by\nallowing the network to predict a variable length output in inference. A new\nloss function with a tailored gradient computation is developed that trades off\nprediction accuracy and output length. The model utilizes a function to\ndetermine whether a particular output at a time should be evaluated or not\ngiven a predetermined threshold. We evaluate the model on the problem of\npredicting the prices of securities. We find that the model makes longer\npredictions for more stable securities and it naturally balances prediction\naccuracy and length.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 01:00:23 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 16:31:28 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Harmon", "Mark", ""], ["Klabjan", "Diego", ""]]}, {"id": "1807.00431", "submitter": "John Zech", "authors": "John R. Zech, Marcus A. Badgeley, Manway Liu, Anthony B. Costa, Joseph\n  J. Titano, Eric K. Oermann", "title": "Confounding variables can degrade generalization performance of\n  radiological deep learning models", "comments": null, "journal-ref": "PLoS Med 15(11):e1002683 (2019)", "doi": "10.1371/journal.pmed.1002683", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early results in using convolutional neural networks (CNNs) on x-rays to\ndiagnose disease have been promising, but it has not yet been shown that models\ntrained on x-rays from one hospital or one group of hospitals will work equally\nwell at different hospitals. Before these tools are used for computer-aided\ndiagnosis in real-world clinical settings, we must verify their ability to\ngeneralize across a variety of hospital systems. A cross-sectional design was\nused to train and evaluate pneumonia screening CNNs on 158,323 chest x-rays\nfrom NIH (n=112,120 from 30,805 patients), Mount Sinai (42,396 from 12,904\npatients), and Indiana (n=3,807 from 3,683 patients). In 3 / 5 natural\ncomparisons, performance on chest x-rays from outside hospitals was\nsignificantly lower than on held-out x-rays from the original hospital systems.\nCNNs were able to detect where an x-ray was acquired (hospital system, hospital\ndepartment) with extremely high accuracy and calibrate predictions accordingly.\nThe performance of CNNs in diagnosing diseases on x-rays may reflect not only\ntheir ability to identify disease-specific imaging findings on x-rays, but also\ntheir ability to exploit confounding information. Estimates of CNN performance\nbased on test data from hospital systems used for model training may overstate\ntheir likely real-world performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 01:57:38 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 01:07:41 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Zech", "John R.", ""], ["Badgeley", "Marcus A.", ""], ["Liu", "Manway", ""], ["Costa", "Anthony B.", ""], ["Titano", "Joseph J.", ""], ["Oermann", "Eric K.", ""]]}, {"id": "1807.00442", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu", "title": "Policy Optimization With Penalized Point Probability Distance: An\n  Alternative To Proximal Policy Optimization", "comments": "open source", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the most successful variant and improvement for Trust Region Policy\nOptimization (TRPO), proximal policy optimization (PPO) has been widely applied\nacross various domains with several advantages: efficient data utilization,\neasy implementation, and good parallelism. In this paper, a first-order\ngradient reinforcement learning algorithm called Policy Optimization with\nPenalized Point Probability Distance (POP3D), which is a lower bound to the\nsquare of total variance divergence is proposed as another powerful variant.\nFirstly, we talk about the shortcomings of several commonly used algorithms, by\nwhich our method is partly motivated. Secondly, we address to overcome these\nshortcomings by applying POP3D. Thirdly, we dive into its mechanism from the\nperspective of solution manifold. Finally, we make quantitative comparisons\namong several state-of-the-art algorithms based on common benchmarks.\nSimulation results show that POP3D is highly competitive compared with PPO.\nBesides, our code is released in https://github.com/paperwithcode/pop3d.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 02:49:36 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 06:47:30 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 07:20:32 GMT"}, {"version": "v4", "created": "Thu, 14 Feb 2019 08:51:28 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Chu", "Xiangxiang", ""]]}, {"id": "1807.00448", "submitter": "Da Qing", "authors": "Hua-Lin He, Chun-Xiang Pan, Qing Da, An-Xiang Zeng", "title": "Speeding up the Metabolism in E-commerce by Reinforcement Mechanism\n  Design", "comments": "Sigir ecom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a large E-commerce platform, all the participants compete for impressions\nunder the allocation mechanism of the platform. Existing methods mainly focus\non the short-term return based on the current observations instead of the\nlong-term return. In this paper, we formally establish the lifecycle model for\nproducts, by defining the introduction, growth, maturity and decline stages and\ntheir transitions throughout the whole life period. Based on such model, we\nfurther propose a reinforcement learning based mechanism design framework for\nimpression allocation, which incorporates the first principal component based\npermutation and the novel experiences generation method, to maximize short-term\nas well as long-term return of the platform. With the power of trial-and-error,\nit is possible to optimize impression allocation strategies globally which is\ncontribute to the healthy development of participants and the platform itself.\nWe evaluate our algorithm on a simulated environment built based on one of the\nlargest E-commerce platforms, and a significant improvement has been achieved\nin comparison with the baseline solutions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 03:14:09 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["He", "Hua-Lin", ""], ["Pan", "Chun-Xiang", ""], ["Da", "Qing", ""], ["Zeng", "An-Xiang", ""]]}, {"id": "1807.00451", "submitter": "Yunfei Ye", "authors": "Yunfei Ye and Dong Han", "title": "Multi-distance Support Matrix Machines", "comments": "The paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data such as digital images, MRI scans and electroencephalography\nsignals are naturally represented as matrices with structural information. Most\nexisting classifiers aim to capture these structures by regularizing the\nregression matrix to be low-rank or sparse. Some other methodologies introduce\nfactorization technique to explore nonlinear relationships of matrix data in\nkernel space. In this paper, we propose a multi-distance support matrix machine\n(MDSMM), which provides a principled way of solving matrix classification\nproblems. The multi-distance is introduced to capture the correlation within\nmatrix data, by means of intrinsic information in rows and columns of input\ndata. A complex hyperplane is established upon these values to separate\ndistinct classes. We further study the generalization bounds for i.i.d.\nprocesses and non i.i.d. process based on both SVM and SMM classifiers. For\ntypical hypothesis classes where matrix norms are constrained, MDSMM achieves a\nfaster learning rate than traditional classifiers. We also provide a more\ngeneral approach for samples without prior knowledge. We demonstrate the merits\nof the proposed method by conducting exhaustive experiments on both simulation\nstudy and a number of real-word datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 03:40:01 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 04:07:45 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Ye", "Yunfei", ""], ["Han", "Dong", ""]]}, {"id": "1807.00456", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Chinmaya Devaraj, Michael Maynord, Cornelia Ferm\\\"uller,\n  Yiannis Aloimonos", "title": "Evenly Cascaded Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Evenly Cascaded convolutional Network (ECN), a neural network\ntaking inspiration from the cascade algorithm of wavelet analysis. ECN employs\ntwo feature streams - a low-level and high-level steam. At each layer these\nstreams interact, such that low-level features are modulated using advanced\nperspectives from the high-level stream. ECN is evenly structured through\nresizing feature map dimensions by a consistent ratio, which removes the burden\nof ad-hoc specification of feature map dimensions. ECN produces easily\ninterpretable features maps, a result whose intuition can be understood in the\ncontext of scale-space theory. We demonstrate that ECN's design facilitates the\ntraining process through providing easily trainable shortcuts. We report new\nstate-of-the-art results for small networks, without the need for additional\ntreatment such as pruning or compression - a consequence of ECN's simple\nstructure and direct training. A 6-layered ECN design with under 500k\nparameters achieves 95.24% and 78.99% accuracy on CIFAR-10 and CIFAR-100\ndatasets, respectively, outperforming the current state-of-the-art on small\nparameter networks, and a 3 million parameter ECN produces results competitive\nto the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 04:12:16 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 07:49:01 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ye", "Chengxi", ""], ["Devaraj", "Chinmaya", ""], ["Maynord", "Michael", ""], ["Ferm\u00fcller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1807.00458", "submitter": "Shasha Li", "authors": "Shasha Li, Ajaya Neupane, Sujoy Paul, Chengyu Song, Srikanth V.\n  Krishnamurthy, Amit K. Roy Chowdhury, Ananthram Swami", "title": "Adversarial Perturbations Against Real-Time Video Classification Systems", "comments": null, "journal-ref": "Network and Distributed Systems Security (NDSS) Symposium 2019\n  24-27 February 2019, San Diego, CA, USA", "doi": "10.14722/ndss.2019.23202", "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has demonstrated the brittleness of machine learning systems\nto adversarial perturbations. However, the studies have been mostly limited to\nperturbations on images and more generally, classification that does not deal\nwith temporally varying inputs. In this paper we ask \"Are adversarial\nperturbations possible in real-time video classification systems and if so,\nwhat properties must they satisfy?\" Such systems find application in\nsurveillance applications, smart vehicles, and smart elderly care and thus,\nmisclassification could be particularly harmful (e.g., a mishap at an elderly\ncare facility may be missed). We show that accounting for temporal structure is\nkey to generating adversarial examples in such systems. We exploit recent\nadvances in generative adversarial network (GAN) architectures to account for\ntemporal correlations and generate adversarial samples that can cause\nmisclassification rates of over 80% for targeted activities. More importantly,\nthe samples also leave other activities largely unaffected making them\nextremely stealthy. Finally, we also surprisingly find that in many scenarios,\nthe same perturbation can be applied to every frame in a video clip that makes\nthe adversary's ability to achieve misclassification relatively easy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 04:25:46 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Li", "Shasha", ""], ["Neupane", "Ajaya", ""], ["Paul", "Sujoy", ""], ["Song", "Chengyu", ""], ["Krishnamurthy", "Srikanth V.", ""], ["Chowdhury", "Amit K. Roy", ""], ["Swami", "Ananthram", ""]]}, {"id": "1807.00459", "submitter": "Eugene Bagdasaryan", "authors": "Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, Vitaly\n  Shmatikov", "title": "How To Backdoor Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables thousands of participants to construct a deep\nlearning model without sharing their private training data with each other. For\nexample, multiple smartphones can jointly train a next-word predictor for\nkeyboards without revealing what individual users type. We demonstrate that any\nparticipant in federated learning can introduce hidden backdoor functionality\ninto the joint global model, e.g., to ensure that an image classifier assigns\nan attacker-chosen label to images with certain features, or that a word\npredictor completes certain sentences with an attacker-chosen word.\n  We design and evaluate a new model-poisoning methodology based on model\nreplacement. An attacker selected in a single round of federated learning can\ncause the global model to immediately reach 100% accuracy on the backdoor task.\nWe evaluate the attack under different assumptions for the standard\nfederated-learning tasks and show that it greatly outperforms data poisoning.\nOur generic constrain-and-scale technique also evades anomaly detection-based\ndefenses by incorporating the evasion into the attacker's loss function during\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 04:37:43 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 23:01:52 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 04:36:45 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Bagdasaryan", "Eugene", ""], ["Veit", "Andreas", ""], ["Hua", "Yiqing", ""], ["Estrin", "Deborah", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1807.00462", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, Abhinav Vishnu, Aniket Chakrabarti, Charles Siegel, and\n  Srinivasan Parthasarathy", "title": "ColdRoute: Effective Routing of Cold Questions in Stack Exchange Sites", "comments": "Accepted to the Journal Track of The European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECML PKDD 2018); Published by Springer:\n  https://link.springer.com/article/10.1007%2Fs10618-018-0577-7", "journal-ref": "@Article{Sun2018, author=\"Sun, Jiankai and Vishnu, A. and\n  Chakrabarti, A. and Siegel, C. and Parthasarathy, S.\", title=\"ColdRoute:\n  effective routing of cold questions in stack exchange sites\", journal=\"ECML\n  PKDD\", year=\"2018\"}", "doi": "10.1007/s10618-018-0577-7", "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing questions in Community Question Answer services (CQAs) such as Stack\nExchange sites is a well-studied problem. Yet, cold-start -- a phenomena\nobserved when a new question is posted is not well addressed by existing\napproaches. Additionally, cold questions posted by new askers present\nsignificant challenges to state-of-the-art approaches. We propose ColdRoute to\naddress these challenges. ColdRoute is able to handle the task of routing cold\nquestions posted by new or existing askers to matching experts. Specifically,\nwe use Factorization Machines on the one-hot encoding of critical features such\nas question tags and compare our approach to well-studied techniques such as\nCQARank and semantic matching (LDA, BoW, and Doc2Vec). Using data from eight\nstack exchange sites, we are able to improve upon the routing metrics\n(Precision$@1$, Accuracy, MRR) over the state-of-the-art models such as\nsemantic matching by $159.5\\%$,$31.84\\%$, and $40.36\\%$ for cold questions\nposted by existing askers, and $123.1\\%$, $27.03\\%$, and $34.81\\%$ for cold\nquestions posted by new askers respectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 05:08:05 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Sun", "Jiankai", ""], ["Vishnu", "Abhinav", ""], ["Chakrabarti", "Aniket", ""], ["Siegel", "Charles", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1807.00468", "submitter": "Sakshi Udeshi", "authors": "Sakshi Udeshi, Pryanshu Arora, Sudipta Chattopadhyay", "title": "Automated Directed Fairness Testing", "comments": "In Proceedings of the 2018 33rd ACM/IEEE International Conference on\n  Automated Software Engineering (ASE 18), September 3-7, 2018, Montpellier,\n  France", "journal-ref": "Automated Directed Fairness Testing. In Proceedings of the 2018\n  33rd ACM/IEEE International Conference on Automated Software Engineering (ASE\n  18), September 3-7, 2018, Montpellier, France", "doi": "10.1145/3238147.3238165", "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fairness is a critical trait in decision making. As machine-learning models\nare increasingly being used in sensitive application domains (e.g. education\nand employment) for decision making, it is crucial that the decisions computed\nby such models are free of unintended bias. But how can we automatically\nvalidate the fairness of arbitrary machine-learning models? For a given\nmachine-learning model and a set of sensitive input parameters, our AEQUITAS\napproach automatically discovers discriminatory inputs that highlight fairness\nviolation. At the core of AEQUITAS are three novel strategies to employ\nprobabilistic search over the input space with the objective of uncovering\nfairness violation. Our AEQUITAS approach leverages inherent robustness\nproperty in common machine-learning models to design and implement scalable\ntest generation methodologies. An appealing feature of our generated test\ninputs is that they can be systematically added to the training set of the\nunderlying model and improve its fairness. To this end, we design a fully\nautomated module that guarantees to improve the fairness of the underlying\nmodel.\n  We implemented AEQUITAS and we have evaluated it on six state-of-the-art\nclassifiers, including a classifier that was designed with fairness\nconstraints. We show that AEQUITAS effectively generates inputs to uncover\nfairness violation in all the subject classifiers and systematically improves\nthe fairness of the respective models using the generated test inputs. In our\nevaluation, AEQUITAS generates up to 70% discriminatory inputs (w.r.t. the\ntotal number of inputs generated) and leverages these inputs to improve the\nfairness up to 94%.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 05:29:57 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 12:08:59 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Udeshi", "Sakshi", ""], ["Arora", "Pryanshu", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1807.00480", "submitter": "Jeff  (Jun) Zhang", "authors": "Jeff Zhang, Siddharth Garg", "title": "FATE: Fast and Accurate Timing Error Prediction Framework for Low Power\n  DNN Accelerator Design", "comments": "To appear at IEEE/ACM International Conference On Computer Aided\n  Design 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are increasingly being accelerated on\napplication-specific hardware such as the Google TPU designed especially for\ndeep learning. Timing speculation is a promising approach to further increase\nthe energy efficiency of DNN accelerators. Architectural exploration for timing\nspeculation requires detailed gate-level timing simulations that can be\ntime-consuming for large DNNs that execute millions of multiply-and-accumulate\n(MAC) operations. In this paper we propose FATE, a new methodology for fast and\naccurate timing simulations of DNN accelerators like the Google TPU. FATE\nproposes two novel ideas: (i) DelayNet, a DNN based timing model for MAC units;\nand (ii) a statistical sampling methodology that reduces the number of MAC\noperations for which timing simulations are performed. We show that FATE\nresults in between 8 times-58 times speed-up in timing simulations, while\nintroducing less than 2% error in classification accuracy estimates. We\ndemonstrate the use of FATE by comparing to conventional DNN accelerator that\nuses 2's complement (2C) arithmetic with an alternative implementation that\nuses signed magnitude representations (SMR). We show that that the SMR\nimplementation provides 18% more energy savings for the same classification\naccuracy than 2C, a result that might be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:21:23 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Zhang", "Jeff", ""], ["Garg", "Siddharth", ""]]}, {"id": "1807.00482", "submitter": "Toan Nguyen", "authors": "Toan Nguyen and Nasir Memon", "title": "Tap-based User Authentication for Smartwatches", "comments": "11 pages, 8 figures", "journal-ref": "Computer & Security, Volume 78, September 2018, Pages 174-186", "doi": "10.1016/j.cose.2018.07.001", "report-no": null, "categories": "cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents TapMeIn, an eyes-free, two-factor authentication method\nfor smartwatches. It allows users to tap a memorable melody (tap-password) of\ntheir choice anywhere on the touchscreen to unlock their watch. A user is\nverified based on the tap-password as well as her physiological and behavioral\ncharacteristics when tapping. Results from preliminary experiments with 41\nparticipants show that TapMeIn could achieve an accuracy of 98.7% with a False\nPositive Rate of only 0.98%. In addition, TapMeIn retains its performance in\ndifferent conditions such as sitting and walking. In terms of speed, TapMeIn\nhas an average authentication time of 2 seconds. A user study with the System\nUsability Scale (SUS) tool suggests that TapMeIn has a high usability score.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:27:42 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 19:02:05 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Nguyen", "Toan", ""], ["Memon", "Nasir", ""]]}, {"id": "1807.00511", "submitter": "Ilker Bozcan", "authors": "Ilker Bozcan and Sinan Kalkan", "title": "COSMO: Contextualized Scene Modeling with Boltzmann Machines", "comments": "40 pages, 15 figures, 9 tables, accepted to the Robotics and\n  Autonomous Systems (RAS) special issue on Semantic Policy and Action\n  Representations for Autonomous Robots (SPAR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene modeling is very crucial for robots that need to perceive, reason about\nand manipulate the objects in their environments. In this paper, we adapt and\nextend Boltzmann Machines (BMs) for contextualized scene modeling. Although\nthere are many models on the subject, ours is the first to bring together\nobjects, relations, and affordances in a highly-capable generative model. For\nthis end, we introduce a hybrid version of BMs where relations and affordances\nare introduced with shared, tri-way connections into the model. Moreover, we\ncontribute a dataset for relation estimation and modeling studies. We evaluate\nour method in comparison with several baselines on object estimation,\nout-of-context object detection, relation estimation, and affordance estimation\ntasks. Moreover, to illustrate the generative capability of the model, we show\nseveral example scenes that the model is able to generate.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 08:07:36 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 15:20:39 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Bozcan", "Ilker", ""], ["Kalkan", "Sinan", ""]]}, {"id": "1807.00516", "submitter": "Jindong Wang", "authors": "Jindong Wang, Yiqiang Chen, Shuji Hao, Wenjie Feng, Zhiqi Shen", "title": "Balanced Distribution Adaptation for Transfer Learning", "comments": "ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has achieved promising results by leveraging knowledge from\nthe source domain to annotate the target domain which has few or none labels.\nExisting methods often seek to minimize the distribution divergence between\ndomains, such as the marginal distribution, the conditional distribution or\nboth. However, these two distances are often treated equally in existing\nalgorithms, which will result in poor performance in real applications.\nMoreover, existing methods usually assume that the dataset is balanced, which\nalso limits their performances on imbalanced tasks that are quite common in\nreal problems. To tackle the distribution adaptation problem, in this paper, we\npropose a novel transfer learning approach, named as Balanced Distribution\n\\underline{A}daptation~(BDA), which can adaptively leverage the importance of\nthe marginal and conditional distribution discrepancies, and several existing\nmethods can be treated as special cases of BDA. Based on BDA, we also propose a\nnovel Weighted Balanced Distribution Adaptation~(W-BDA) algorithm to tackle the\nclass imbalance issue in transfer learning. W-BDA not only considers the\ndistribution adaptation between domains but also adaptively changes the weight\nof each class. To evaluate the proposed methods, we conduct extensive\nexperiments on several transfer learning tasks, which demonstrate the\neffectiveness of our proposed algorithms over several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 08:14:04 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Hao", "Shuji", ""], ["Feng", "Wenjie", ""], ["Shen", "Zhiqi", ""]]}, {"id": "1807.00546", "submitter": "Yunlong Wang", "authors": "Yunlong Wang, Bjoern Sommer, Falk Schreiber, Harald Reiterer", "title": "Clustering with Temporal Constraints on Spatio-Temporal Data of Human\n  Mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting significant places or places of interest (POIs) using individuals'\nspatio-temporal data is of fundamental importance for human mobility analysis.\nClassical clustering methods have been used in prior work for detecting POIs,\nbut without considering temporal constraints. Usually, the involved parameters\nfor clustering are difficult to determine, e.g., the optimal cluster number in\nhierarchical clustering. Currently, researchers either choose heuristic values\nor use spatial distance-based optimization to determine an appropriate\nparameter set. We argue that existing research does not optimally address\ntemporal information and thus leaves much room for improvement. Considering\ntemporal constraints in human mobility, we introduce an effective clustering\napproach - namely POI clustering with temporal constraints (PC-TC) - to extract\nPOIs from spatio-temporal data of human mobility. Following human mobility\nnature in modern society, our approach aims to extract both global POIs (e.g.,\nworkplace or university) and local POIs (e.g., library, lab, and canteen).\nBased on two publicly available datasets including 193 individuals, our\nevaluation results show that PC-TC has much potential for next place prediction\nin terms of granularity (i.e., the number of extracted POIs) and\npredictability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:07:17 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "Yunlong", ""], ["Sommer", "Bjoern", ""], ["Schreiber", "Falk", ""], ["Reiterer", "Harald", ""]]}, {"id": "1807.00553", "submitter": "Roel Dobbe", "authors": "Roel Dobbe, Sarah Dean, Thomas Gilbert, Nitin Kohli", "title": "A Broader View on Bias in Automated Decision-Making: Reflecting on\n  Epistemology and Dynamics", "comments": "Presented at the 2018 Workshop on Fairness, Accountability and\n  Transparency in Machine Learning during ICML 2018, Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is increasingly deployed in real world contexts,\nsupplying actionable insights and forming the basis of automated\ndecision-making systems. While issues resulting from biases pre-existing in\ntraining data have been at the center of the fairness debate, these systems are\nalso affected by technical and emergent biases, which often arise as\ncontext-specific artifacts of implementation. This position paper interprets\ntechnical bias as an epistemological problem and emergent bias as a dynamical\nfeedback phenomenon. In order to stimulate debate on how to change machine\nlearning practice to effectively address these issues, we explore this broader\nview on bias, stress the need to reflect on epistemology, and point to\nvalue-sensitive design methodologies to revisit the design and implementation\nprocess of automated decision-making systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:23:38 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 07:51:10 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Dobbe", "Roel", ""], ["Dean", "Sarah", ""], ["Gilbert", "Thomas", ""], ["Kohli", "Nitin", ""]]}, {"id": "1807.00558", "submitter": "Jiajun Pan", "authors": "Jiajun Pan, Hoel Le Capitaine, Philippe Leray", "title": "Relational Constraints for Metric Learning on Relational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of metric learning approaches are dedicated to be applied on data\ndescribed by feature vectors, with some notable exceptions such as times\nseries, trees or graphs. The objective of this paper is to propose a metric\nlearning algorithm that specifically considers relational data. The proposed\napproach can take benefit from both the topological structure of the data and\nsupervised labels. For selecting relative constraints representing the\nrelational information, we introduce a link-strength function that measures the\nstrength of relationship links between entities by the side-information of\ntheir common parents. We show the performance of the proposed method with two\ndifferent classical metric learning algorithms, which are ITML (Information\nTheoretic Metric Learning) and LSML (Least Squares Metric Learning), and test\non several real-world datasets. Experimental results show that using relational\ninformation improves the quality of the learned metric.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:29:06 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Pan", "Jiajun", ""], ["Capitaine", "Hoel Le", ""], ["Leray", "Philippe", ""]]}, {"id": "1807.00560", "submitter": "Sihao Xue", "authors": "Sihao Xue, Zhenyi Ying, Fan Mo, Min Wang, Jue Sun", "title": "Weight-importance sparse training in keyword spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large size models are implemented in recently ASR system to deal with complex\nspeech recognition problems. The num- ber of parameters in these models makes\nthem hard to deploy, especially on some resource-short devices such as car\ntablet. Besides this, at most of time, ASR system is used to deal with\nreal-time problem such as keyword spotting (KWS). It is contradictory to the\nfact that large model requires long com- putation time. To deal with this\nproblem, we apply some sparse algo- rithms to reduces number of parameters in\nsome widely used models, Deep Neural Network (DNN) KWS, which requires real\nshort computation time. We can prune more than 90 % even 95% of parameters in\nthe model with tiny effect decline. And the sparse model performs better than\nbaseline models which has same order number of parameters. Besides this, sparse\nalgorithm can lead us to find rational model size au- tomatically for certain\nproblem without concerning choosing an original model size.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:34:34 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 11:33:33 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 01:35:50 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Xue", "Sihao", ""], ["Ying", "Zhenyi", ""], ["Mo", "Fan", ""], ["Wang", "Min", ""], ["Sun", "Jue", ""]]}, {"id": "1807.00583", "submitter": "Jasper Linmans", "authors": "Jasper Linmans, Jim Winkens, Bastiaan S. Veeling, Taco S. Cohen, Max\n  Welling", "title": "Sample Efficient Semantic Segmentation using Rotation Equivariant\n  Convolutional Networks", "comments": "Presented at the ICML workshop: Towards learning with limited labels:\n  Equivariance, Invariance, and Beyond, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semantic segmentation model that exploits rotation and\nreflection symmetries. We demonstrate significant gains in sample efficiency\ndue to increased weight sharing, as well as improvements in robustness to\nsymmetry transformations. The group equivariant CNN framework is extended for\nsegmentation by introducing a new equivariant (G->Z2)-convolution that\ntransforms feature maps on a group to planar feature maps. Also, equivariant\ntransposed convolution is formulated for up-sampling in an encoder-decoder\nnetwork. To demonstrate improvements in sample efficiency we evaluate on\nmultiple data regimes of a rotation-equivariant segmentation task: cancer\nmetastases detection in histopathology images. We further show the\neffectiveness of exploiting more symmetries by varying the size of the group.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 10:31:05 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Linmans", "Jasper", ""], ["Winkens", "Jim", ""], ["Veeling", "Bastiaan S.", ""], ["Cohen", "Taco S.", ""], ["Welling", "Max", ""]]}, {"id": "1807.00595", "submitter": "Ashwin Srinivasan", "authors": "Ashwin Srinivasan, Lovekesh Vig and Michael Bain", "title": "Logical Explanations for Deep Relational Machines Using Relevance\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our interest in this paper is in the construction of symbolic explanations\nfor predictions made by a deep neural network. We will focus attention on deep\nrelational machines (DRMs, first proposed by H. Lodhi). A DRM is a deep network\nin which the input layer consists of Boolean-valued functions (features) that\nare defined in terms of relations provided as domain, or background, knowledge.\nOur DRMs differ from those proposed by Lodhi, which use an Inductive Logic\nProgramming (ILP) engine to first select features (we use random selections\nfrom a space of features that satisfies some approximate constraints on logical\nrelevance and non-redundancy). But why do the DRMs predict what they do? One\nway of answering this is the LIME setting, in which readable proxies for a\nblack-box predictor. The proxies are intended only to model the predictions of\nthe black-box in local regions of the instance-space. But readability alone may\nnot enough: to be understandable, the local models must use relevant concepts\nin an meaningful manner. We investigate the use of a Bayes-like approach to\nidentify logical proxies for local predictions of a DRM. We show: (a) DRM's\nwith our randomised propositionalization method achieve state-of-the-art\npredictive performance; (b) Models in first-order logic can approximate the\nDRM's prediction closely in a small local region; and (c) Expert-provided\nrelevance information can play the role of a prior to distinguish between\nlogical explanations that perform equivalently on prediction alone.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 10:56:18 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Srinivasan", "Ashwin", ""], ["Vig", "Lovekesh", ""], ["Bain", "Michael", ""]]}, {"id": "1807.00636", "submitter": "Tobias Sommer Thune", "authors": "Tobias Sommer Thune and Yevgeny Seldin", "title": "Adaptation to Easy Data in Prediction with Limited Advice", "comments": "Fixed a mistake in the proof and statement of Theorem 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an online learning algorithm with improved regret guarantees for\n`easy' loss sequences. We consider two types of `easiness': (a) stochastic loss\nsequences and (b) adversarial loss sequences with small effective range of the\nlosses. While a number of algorithms have been proposed for exploiting small\neffective range in the full information setting, Gerchinovitz and Lattimore\n[2016] have shown the impossibility of regret scaling with the effective range\nof the losses in the bandit setting. We show that just one additional\nobservation per round is sufficient to circumvent the impossibility result. The\nproposed Second Order Difference Adjustments (SODA) algorithm requires no prior\nknowledge of the effective range of the losses, $\\varepsilon$, and achieves an\n$O(\\varepsilon \\sqrt{KT \\ln K}) + \\tilde{O}(\\varepsilon K \\sqrt[4]{T})$\nexpected regret guarantee, where $T$ is the time horizon and $K$ is the number\nof actions. The scaling with the effective loss range is achieved under\nsignificantly weaker assumptions than those made by Cesa-Bianchi and Shamir\n[2018] in an earlier attempt to circumvent the impossibility result. We also\nprovide a regret lower bound of $\\Omega(\\varepsilon\\sqrt{T K})$, which almost\nmatches the upper bound. In addition, we show that in the stochastic setting\nSODA achieves an $O\\left(\\sum_{a:\\Delta_a>0} \\frac{K^3\n\\varepsilon^2}{\\Delta_a}\\right)$ pseudo-regret bound that holds simultaneously\nwith the adversarial regret guarantee. In other words, SODA is safe against an\nunrestricted oblivious adversary and provides improved regret guarantees for at\nleast two different types of `easiness' simultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 12:47:21 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 10:54:31 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 11:02:11 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Thune", "Tobias Sommer", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1807.00692", "submitter": "Richard Diehl Martinez", "authors": "Richard Diehl Martinez, Geoffrey Angus, Rooz Mahdavian", "title": "Grapevine: A Wine Prediction Algorithm Using Multi-dimensional\n  Clustering Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for a wine recommendation system that employs\nmultidimensional clustering and unsupervised learning methods. Our algorithm\nfirst performs clustering on a large corpus of wine reviews. It then uses the\nresulting wine clusters as an approximation of the most common flavor palates,\nrecommending a user a wine by optimizing over a price-quality ratio within\nclusters that they demonstrated a preference for.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 13:55:44 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Martinez", "Richard Diehl", ""], ["Angus", "Geoffrey", ""], ["Mahdavian", "Rooz", ""]]}, {"id": "1807.00703", "submitter": "Fabio Ferreira", "authors": "Fabio Ferreira, Jonas Rothfuss, Eren Erdal Aksoy, You Zhou, Tamim\n  Asfour", "title": "Introducing the Simulated Flying Shapes and Simulated Planar Manipulator\n  Datasets", "comments": "technical documentation, 2 figures, links to repositories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We release two artificial datasets, Simulated Flying Shapes and Simulated\nPlanar Manipulator that allow to test the learning ability of video processing\nsystems. In particular, the dataset is meant as a tool which allows to easily\nassess the sanity of deep neural network models that aim to encode, reconstruct\nor predict video frame sequences. The datasets each consist of 90000 videos.\nThe Simulated Flying Shapes dataset comprises scenes showing two objects of\nequal shape (rectangle, triangle and circle) and size in which one object\napproaches its counterpart. The Simulated Planar Manipulator shows a 3-DOF\nplanar manipulator that executes a pick-and-place task in which it has to place\na size-varying circle on a squared platform. Different from other widely used\ndatasets such as moving MNIST [1], [2], the two presented datasets involve\ngoal-oriented tasks (e.g. the manipulator grasping an object and placing it on\na platform), rather than showing random movements. This makes our datasets more\nsuitable for testing prediction capabilities and the learning of sophisticated\nmotions by a machine learning model. This technical document aims at providing\nan introduction into the usage of both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 14:20:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Ferreira", "Fabio", ""], ["Rothfuss", "Jonas", ""], ["Aksoy", "Eren Erdal", ""], ["Zhou", "You", ""], ["Asfour", "Tamim", ""]]}, {"id": "1807.00734", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau", "title": "The relativistic discriminator: a key element missing from standard GAN", "comments": "https://github.com/AlexiaJM/RelativisticGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard generative adversarial network (SGAN), the discriminator\nestimates the probability that the input data is real. The generator is trained\nto increase the probability that fake data is real. We argue that it should\nalso simultaneously decrease the probability that real data is real because 1)\nthis would account for a priori knowledge that half of the data in the\nmini-batch is fake, 2) this would be observed with divergence minimization, and\n3) in optimal settings, SGAN would be equivalent to integral probability metric\n(IPM) GANs.\n  We show that this property can be induced by using a relativistic\ndiscriminator which estimate the probability that the given real data is more\nrealistic than a randomly sampled fake data. We also present a variant in which\nthe discriminator estimate the probability that the given real data is more\nrealistic than fake data, on average. We generalize both approaches to\nnon-standard GAN loss functions and we refer to them respectively as\nRelativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that\nIPM-based GANs are a subset of RGANs which use the identity function.\n  Empirically, we observe that 1) RGANs and RaGANs are significantly more\nstable and generate higher quality data samples than their non-relativistic\ncounterparts, 2) Standard RaGAN with gradient penalty generate data of better\nquality than WGAN-GP while only requiring a single discriminator update per\ngenerator update (reducing the time taken for reaching the state-of-the-art by\n400%), and 3) RaGANs are able to generate plausible high resolutions images\n(256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these\nimages are of significantly better quality than the ones generated by WGAN-GP\nand SGAN with spectral normalization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:11:23 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 15:07:07 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 17:11:59 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""]]}, {"id": "1807.00737", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Learning Goal-Oriented Visual Dialog via Tempered Policy Gradient", "comments": "Published in IEEE Spoken Language Technology (SLT 2018), Athens,\n  Greece", "journal-ref": null, "doi": "10.1109/SLT.2018.8639546", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning goal-oriented dialogues by means of deep reinforcement learning has\nrecently become a popular research topic. However, commonly used policy-based\ndialogue agents often end up focusing on simple utterances and suboptimal\npolicies. To mitigate this problem, we propose a class of novel\ntemperature-based extensions for policy gradient methods, which are referred to\nas Tempered Policy Gradients (TPGs). On a recent AI-testbed, i.e., the\nGuessWhat?! game, we achieve significant improvements with two innovations. The\nfirst one is an extension of the state-of-the-art solutions with Seq2Seq and\nMemory Network structures that leads to an improvement of 7%. The second one is\nthe application of our newly developed TPG methods, which improves the\nperformance additionally by around 5% and, even more importantly, helps produce\nmore convincing utterances.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:14:43 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 05:35:32 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2018 08:24:41 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 10:22:01 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 08:03:58 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1807.00745", "submitter": "Michael A. Hedderich", "authors": "Michael A. Hedderich and Dietrich Klakow", "title": "Training a Neural Network in a Low-Resource Setting on Automatically\n  Annotated Noisy Data", "comments": "In Proceedings of the Workshop on Deep Learning Approaches for\n  Low-Resource NLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually labeled corpora are expensive to create and often not available for\nlow-resource languages or domains. Automatic labeling approaches are an\nalternative way to obtain labeled data in a quicker and cheaper way. However,\nthese labels often contain more errors which can deteriorate a classifier's\nperformance when trained on this data. We propose a noise layer that is added\nto a neural network architecture. This allows modeling the noise and train on a\ncombination of clean and noisy data. We show that in a low-resource NER task we\ncan improve performance by up to 35% by using additional, noisy data and\nhandling the noise.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:35:02 GMT"}, {"version": "v2", "created": "Sun, 22 Jul 2018 06:01:14 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1807.00751", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Yuxuan Song, Lantao Yu, Hongwei Wang, Jiadong Liang,\n  Weinan Zhang, Zhihua Zhang, Yong Yu", "title": "Understanding the Effectiveness of Lipschitz-Continuity in Generative\n  Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the underlying factor that leads to failure and\nsuccess in the training of GANs. We study the property of the optimal\ndiscriminative function and show that in many GANs, the gradient from the\noptimal discriminative function is not reliable, which turns out to be the\nfundamental cause of failure in training of GANs. We further demonstrate that a\nwell-defined distance metric does not necessarily guarantee the convergence of\nGANs. Finally, we prove in this paper that Lipschitz-continuity condition is a\ngeneral solution to make the gradient of the optimal discriminative function\nreliable, and characterized the necessary condition where Lipschitz-continuity\nensures the convergence, which leads to a broad family of valid GAN objectives\nunder Lipschitz-continuity condition, where Wasserstein distance is one special\ncase. We experiment with several new objectives, which are sound according to\nour theorems, and we found that, compared with Wasserstein distance, the\noutputs of the discriminator with new objectives are more stable and the final\nqualities of generated samples are also consistently higher than those produced\nby Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:41:34 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 03:52:20 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 09:27:16 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2018 07:04:43 GMT"}, {"version": "v5", "created": "Mon, 19 Nov 2018 16:55:18 GMT"}, {"version": "v6", "created": "Sun, 23 Dec 2018 15:09:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhou", "Zhiming", ""], ["Song", "Yuxuan", ""], ["Yu", "Lantao", ""], ["Wang", "Hongwei", ""], ["Liang", "Jiadong", ""], ["Zhang", "Weinan", ""], ["Zhang", "Zhihua", ""], ["Yu", "Yong", ""]]}, {"id": "1807.00755", "submitter": "Csaba Szepesvari", "authors": "Gell\\'ert Weisz and Andr\\'as Gy\\\"orgy and Csaba Szepesv\\'ari", "title": "LeapsAndBounds: A Method for Approximately Optimal Algorithm\n  Configuration", "comments": "to appear at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of configuring general-purpose solvers to run\nefficiently on problem instances drawn from an unknown distribution. The goal\nof the configurator is to find a configuration that runs fast on average on\nmost instances, and do so with the least amount of total work. It can run a\nchosen solver on a random instance until the solver finishes or a timeout is\nreached. We propose LeapsAndBounds, an algorithm that tests configurations on\nrandomly selected problem instances for longer and longer time. We prove that\nthe capped expected runtime of the configuration returned by LeapsAndBounds is\nclose to the optimal expected runtime, while our algorithm's running time is\nnear-optimal. Our results show that LeapsAndBounds is more efficient than the\nrecent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the\nonly other algorithm configuration method with non-trivial theoretical\nguarantees. Experimental results on configuring a public SAT solver on a new\nbenchmark dataset also stand witness to the superiority of our method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:44:36 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1807.00780", "submitter": "Pengqian Yu", "authors": "Xinhan Di, Pengqian Yu, Meng Tian", "title": "Ambient Hidden Space of Generative Adversarial Networks", "comments": "Accepted for publication in Uncertainty in Deep Learning Workshop at\n  Uncertainty in Artificial Intelligence (UAI) 2018", "journal-ref": "Uncertainty in Deep Learning Workshop at Uncertainty in Artificial\n  Intelligence (UAI) 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial models are powerful tools to model structure in\ncomplex distributions for a variety of tasks. Current techniques for learning\ngenerative models require an access to samples which have high quality, and\nadvanced generative models are applied to generate samples from noisy training\ndata through ambient modules. However, the modules are only practical for the\noutput space of the generator, and their application in the hidden space is not\nwell studied. In this paper, we extend the ambient module to the hidden space\nof the generator, and provide the uniqueness condition and the corresponding\nstrategy for the ambient hidden generator in the adversarial training process.\nWe report the practicality of the proposed method on the benchmark dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 16:51:27 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Di", "Xinhan", ""], ["Yu", "Pengqian", ""], ["Tian", "Meng", ""]]}, {"id": "1807.00787", "submitter": "Till Speicher", "authors": "Till Speicher (1), Hoda Heidari (2), Nina Grgic-Hlaca (1), Krishna P.\n  Gummadi (1), Adish Singla (1), Adrian Weller (3 and 4), Muhammad Bilal Zafar\n  (1) ((1) MPI-SWS, (2) ETH Zurich, (3) University of Cambridge, (4) The Alan\n  Turing Institute)", "title": "A Unified Approach to Quantifying Algorithmic Unfairness: Measuring\n  Individual & Group Unfairness via Inequality Indices", "comments": "12 pages 7 figures To be published in: KDD '18: The 24th ACM SIGKDD\n  International Conference on Knowledge Discovery and Data Mining Proceedings", "journal-ref": null, "doi": "10.1145/3219819.3220046", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discrimination via algorithmic decision making has received considerable\nattention. Prior work largely focuses on defining conditions for fairness, but\ndoes not define satisfactory measures of algorithmic unfairness. In this paper,\nwe focus on the following question: Given two unfair algorithms, how should we\ndetermine which of the two is more unfair? Our core idea is to use existing\ninequality indices from economics to measure how unequally the outcomes of an\nalgorithm benefit different individuals or groups in a population. Our work\noffers a justified and general framework to compare and contrast the\n(un)fairness of algorithmic predictors. This unifying approach enables us to\nquantify unfairness both at the individual and the group level. Further, our\nwork reveals overlooked tradeoffs between different fairness notions: using our\nproposed measures, the overall individual-level unfairness of an algorithm can\nbe decomposed into a between-group and a within-group component. Earlier\nmethods are typically designed to tackle only between-group unfairness, which\nmay be justified for legal or other reasons. However, we demonstrate that\nminimizing exclusively the between-group component may, in fact, increase the\nwithin-group, and hence the overall unfairness. We characterize and illustrate\nthe tradeoffs between our measures of (un)fairness and the prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 17:05:26 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Speicher", "Till", "", "3 and 4"], ["Heidari", "Hoda", "", "3 and 4"], ["Grgic-Hlaca", "Nina", "", "3 and 4"], ["Gummadi", "Krishna P.", "", "3 and 4"], ["Singla", "Adish", "", "3 and 4"], ["Weller", "Adrian", "", "3 and 4"], ["Zafar", "Muhammad Bilal", ""]]}, {"id": "1807.00801", "submitter": "Hyeji Kim", "authors": "Hyeji Kim, Yihan Jiang, Sreeram Kannan, Sewoong Oh, Pramod Viswanath", "title": "Deepcode: Feedback Codes via Deep Learning", "comments": "24 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of codes for communicating reliably over a statistically well\ndefined channel is an important endeavor involving deep mathematical research\nand wide-ranging practical applications. In this work, we present the first\nfamily of codes obtained via deep learning, which significantly beats\nstate-of-the-art codes designed over several decades of research. The\ncommunication channel under consideration is the Gaussian noise channel with\nfeedback, whose study was initiated by Shannon; feedback is known theoretically\nto improve reliability of communication, but no practical codes that do so have\never been successfully constructed.\n  We break this logjam by integrating information theoretic insights\nharmoniously with recurrent-neural-network based encoders and decoders to\ncreate novel codes that outperform known codes by 3 orders of magnitude in\nreliability. We also demonstrate several desirable properties of the codes: (a)\ngeneralization to larger block lengths, (b) composability with known codes, (c)\nadaptation to practical constraints. This result also has broader ramifications\nfor coding theory: even when the channel has a clear mathematical model, deep\nlearning methodologies, when combined with channel-specific\ninformation-theoretic insights, can potentially beat state-of-the-art codes\nconstructed over decades of mathematical research.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 17:50:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kim", "Hyeji", ""], ["Jiang", "Yihan", ""], ["Kannan", "Sreeram", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1807.00804", "submitter": "Johannes Bausch", "authors": "Johannes Bausch", "title": "Classifying Data with Local Hamiltonians", "comments": "21 pages, 8 figures, 4 tables", "journal-ref": "Int. J. Quantum Inf. 1840001 (2018)", "doi": "10.1142/S0219749918400014", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to define a notion of a quantum neural network to\nclassify data, which exploits the low energy spectrum of a local Hamiltonian.\nAs a concrete application, we build a binary classifier, train it on some\nactual data and then test its performance on a simple classification task. More\nspecifically, we use Microsoft's quantum simulator, Liquid, to construct local\nHamiltonians that can encode trained classifier functions in their ground\nspace, and which can be probed by measuring the overlap with test states\ncorresponding to the data to be classified. To obtain such a classifier\nHamiltonian, we further propose a training scheme based on quantum annealing\nwhich is completely closed-off to the environment and which does not depend on\nexternal measurements until the very end, avoiding unnecessary decoherence\nduring the annealing procedure. For a network of size n, the trained network\ncan be stored as a list of O(n) coupling strengths. We address the question of\nwhich interactions are most suitable for a given classification task, and\ndevelop a qubit-saving optimization for the training procedure on a simulated\nannealing device. Furthermore, a small neural network to classify colors into\nred vs. blue is trained and tested, and benchmarked against the annealing\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 17:58:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Bausch", "Johannes", ""]]}, {"id": "1807.00818", "submitter": "Ilya Gusev", "authors": "Daniil Anastasyev, Ilya Gusev, Eugene Indenbom", "title": "Improving part-of-speech tagging via multi-task learning and\n  character-level word representations", "comments": null, "journal-ref": "Computational Linguistics and Intellectual Technologies, Papers\n  from the Annual International Conference \"Dialogue\" (2018) Issue 17, 14-27", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the ways to improve POS-tagging using various types\nof auxiliary losses and different word representations. As a baseline, we\nutilized a BiLSTM tagger, which is able to achieve state-of-the-art results on\nthe sequence labelling tasks. We developed a new method for character-level\nword representation using feedforward neural network. Such representation gave\nus better results in terms of speed and performance of the model. We also\napplied a novel technique of pretraining such word representations with\nexisting word vectors. Finally, we designed a new variant of auxiliary loss for\nsequence labelling tasks: an additional prediction of the neighbour labels.\nSuch loss forces a model to learn the dependencies in-side a sequence of labels\nand accelerates the process of training. We test these methods on English and\nRussian languages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:04:52 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Anastasyev", "Daniil", ""], ["Gusev", "Ilya", ""], ["Indenbom", "Eugene", ""]]}, {"id": "1807.00847", "submitter": "Jiayi Liu", "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah", "title": "Make (Nearly) Every Neural Network Better: Generating Neural Network\n  Ensembles by Weight Parameter Resampling", "comments": "Accepted at UAI Workshop on Uncertainty in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become increasingly popular in computer\nvision, natural language processing, and other areas. However, training and\nfine-tuning a deep learning model is computationally intensive and\ntime-consuming. We propose a new method to improve the performance of nearly\nevery model including pre-trained models. The proposed method uses an ensemble\napproach where the networks in the ensemble are constructed by reassigning\nmodel parameter values based on the probabilistic distribution of these\nparameters, calculated towards the end of the training process. For pre-trained\nmodels, this approach results in an additional training step (usually less than\none epoch). We perform a variety of analysis using the MNIST dataset and\nvalidate the approach with a number of DNN models using pre-trained models on\nthe ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 18:12:32 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1807.00867", "submitter": "Meghana Bande", "authors": "Meghana Bande and Venugopal V. Veeravalli", "title": "Multi-User Multi-Armed Bandits for Uncoordinated Spectrum Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-user multi-armed bandit (MAB) framework is used to develop algorithms\nfor uncoordinated spectrum access. The number of users is assumed to be unknown\nto each user. A stochastic setting is first considered, where the rewards on a\nchannel are the same for each user. In contrast to prior work, it is assumed\nthat the number of users can possibly exceed the number of channels, and that\nrewards can be non-zero even under collisions. The proposed algorithm consists\nof an estimation phase and an allocation phase. It is shown that if every user\nadopts the algorithm, the system wide regret is constant with time with high\nprobability. The regret guarantees hold for any number of users and channels,\nin particular, even when the number of users is less than the number of\nchannels. Next, an adversarial multi-user MAB framework is considered, where\nthe rewards on the channels are user-dependent. It is assumed that the number\nof users is less than the number of channels, and that the users receive zero\nreward on collision. The proposed algorithm combines the Exp3.P algorithm\ndeveloped in prior work for single user adversarial bandits with a collision\nresolution mechanism to achieve sub-linear regret. It is shown that if every\nuser employs the proposed algorithm, the system wide regret is of the order\n$O(T^\\frac{3}{4})$ over a horizon of time $T$. The algorithms in both\nstochastic and adversarial scenarios are extended to the dynamic case where the\nnumber of users in the system evolves over time and are shown to lead to\nsub-linear regret.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 19:41:18 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 19:45:00 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 17:21:29 GMT"}, {"version": "v4", "created": "Fri, 4 Jan 2019 18:38:27 GMT"}, {"version": "v5", "created": "Tue, 29 Jan 2019 20:52:36 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Bande", "Meghana", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "1807.00882", "submitter": "Shaoxing Mo", "authors": "Shaoxing Mo, Yinhao Zhu, Nicholas Zabaras, Xiaoqing Shi, and Jichun Wu", "title": "Deep convolutional encoder-decoder networks for uncertainty\n  quantification of dynamic multiphase flow in heterogeneous media", "comments": "30 pages, 21 figures, submitted to Water Resources Research", "journal-ref": "Water Resour. Res. 55 (2019) 703-728", "doi": "10.1029/2018WR023528", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate strategies are used widely for uncertainty quantification of\ngroundwater models in order to improve computational efficiency. However, their\napplication to dynamic multiphase flow problems is hindered by the curse of\ndimensionality, the saturation discontinuity due to capillarity effects, and\nthe time-dependence of the multi-output responses. In this paper, we propose a\ndeep convolutional encoder-decoder neural network methodology to tackle these\nissues. The surrogate modeling task is transformed to an image-to-image\nregression strategy. This approach extracts high-level coarse features from the\nhigh-dimensional input permeability images using an encoder, and then refines\nthe coarse features to provide the output pressure/saturation images through a\ndecoder. A training strategy combining a regression loss and a segmentation\nloss is proposed in order to better approximate the discontinuous saturation\nfield. To characterize the high-dimensional time-dependent outputs of the\ndynamic system, time is treated as an additional input to the network that is\ntrained using pairs of input realizations and of the corresponding system\noutputs at a limited number of time instances. The proposed method is evaluated\nusing a geological carbon storage process-based multiphase flow model with a\n2500-dimensional stochastic permeability field. With a relatively small number\nof training data, the surrogate model is capable of accurately characterizing\nthe spatio-temporal evolution of the pressure and discontinuous CO2 saturation\nfields and can be used efficiently to compute the statistics of the system\nresponses.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 20:41:03 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Mo", "Shaoxing", ""], ["Zhu", "Yinhao", ""], ["Zabaras", "Nicholas", ""], ["Shi", "Xiaoqing", ""], ["Wu", "Jichun", ""]]}, {"id": "1807.00905", "submitter": "Maria De-Arteaga", "authors": "Maria De-Arteaga, Artur Dubrawski, Alexandra Chouldechova", "title": "Learning under selective labels in the presence of expert consistency", "comments": "Presented at the 2018 Workshop on Fairness, Accountability, and\n  Transparency in Machine Learning (FAT/ML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the problem of learning under selective labels in the context of\nalgorithm-assisted decision making. Selective labels is a pervasive selection\nbias problem that arises when historical decision making blinds us to the true\noutcome for certain instances. Examples of this are common in many\napplications, ranging from predicting recidivism using pre-trial release data\nto diagnosing patients. In this paper we discuss why selective labels often\ncannot be effectively tackled by standard methods for adjusting for sample\nselection bias, even if there are no unobservables. We propose a data\naugmentation approach that can be used to either leverage expert consistency to\nmitigate the partial blindness that results from selective labels, or to\nempirically validate whether learning under such framework may lead to\nunreliable models prone to systemic discrimination.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 21:48:59 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 22:55:26 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Dubrawski", "Artur", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "1807.00906", "submitter": "Alexander Alemi", "authors": "Alexander A. Alemi and Ian Fischer and Joshua V. Dillon", "title": "Uncertainty in the Variational Information Bottleneck", "comments": "10 pages, 7 figures. Accepted to UAI 2018 - Uncertainty in Deep\n  Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple case study, demonstrating that Variational Information\nBottleneck (VIB) can improve a network's classification calibration as well as\nits ability to detect out-of-distribution data. Without explicitly being\ndesigned to do so, VIB gives two natural metrics for handling and quantifying\nuncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 21:49:32 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Alemi", "Alexander A.", ""], ["Fischer", "Ian", ""], ["Dillon", "Joshua V.", ""]]}, {"id": "1807.00911", "submitter": "Isay Katsman", "authors": "Isay Katsman, Rohun Tripathi, Andreas Veit, Serge Belongie", "title": "Semantic Segmentation with Scarce Data", "comments": "ICML 2018 Workshop, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is a challenging vision problem that usually\nnecessitates the collection of large amounts of finely annotated data, which is\noften quite expensive to obtain. Coarsely annotated data provides an\ninteresting alternative as it is usually substantially more cheap. In this\nwork, we present a method to leverage coarsely annotated data along with fine\nsupervision to produce better segmentation results than would be obtained when\ntraining using only the fine data. We validate our approach by simulating a\nscarce data setting with less than 200 low resolution images from the\nCityscapes dataset and show that our method substantially outperforms solely\ntraining on the fine annotation data by an average of 15.52% mIoU and\noutperforms the coarse mask by an average of 5.28% mIoU.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 22:06:11 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 03:23:04 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Katsman", "Isay", ""], ["Tripathi", "Rohun", ""], ["Veit", "Andreas", ""], ["Belongie", "Serge", ""]]}, {"id": "1807.00939", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, Sheikh Khaled Ghafoor, William Eberle", "title": "Mining Illegal Insider Trading of Stocks: A Proactive Approach", "comments": "Accepted in IEEE BigData 2018", "journal-ref": "2018 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData.2018.8622303", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illegal insider trading of stocks is based on releasing non-public\ninformation (e.g., new product launch, quarterly financial report, acquisition\nor merger plan) before the information is made public. Detecting illegal\ninsider trading is difficult due to the complex, nonlinear, and non-stationary\nnature of the stock market. In this work, we present an approach that detects\nand predicts illegal insider trading proactively from large heterogeneous\nsources of structured and unstructured data using a deep-learning based\napproach combined with discrete signal processing on the time series data. In\naddition, we use a tree-based approach that visualizes events and actions to\naid analysts in their understanding of large amounts of unstructured data.\nUsing existing data, we have discovered that our approach has a good success\nrate in detecting illegal insider trading patterns.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 04:21:10 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 16:00:02 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 20:04:31 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Ghafoor", "Sheikh Khaled", ""], ["Eberle", "William", ""]]}, {"id": "1807.00942", "submitter": "Griffin Lacey", "authors": "Griffin Lacey, Graham W. Taylor, Shawki Areibi", "title": "Stochastic Layer-Wise Precision in Deep Neural Networks", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low precision weights, activations, and gradients have been proposed as a way\nto improve the computational efficiency and memory footprint of deep neural\nnetworks. Recently, low precision networks have even shown to be more robust to\nadversarial attacks. However, typical implementations of low precision DNNs use\nuniform precision across all layers of the network. In this work, we explore\nwhether a heterogeneous allocation of precision across a network leads to\nimproved performance, and introduce a learning scheme where a DNN\nstochastically explores multiple precision configurations through learning.\nThis permits a network to learn an optimal precision configuration. We show on\nconvolutional neural networks trained on MNIST and ILSVRC12 that even though\nthese nets learn a uniform or near-uniform allocation strategy respectively,\nstochastic precision leads to a favourable regularization effect improving\ngeneralization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 01:11:14 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Lacey", "Griffin", ""], ["Taylor", "Graham W.", ""], ["Areibi", "Shawki", ""]]}, {"id": "1807.00944", "submitter": "Yuya Takashina", "authors": "Yuya Takashina, Shuyo Nakatani, Masato Inoue", "title": "Structure Learning of Markov Random Fields through Grow-Shrink Maximum\n  Pseudolikelihood Estimation", "comments": "Submission to Eighth International Workshop on Statistical Relational\n  AI at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of Markov random fields (MRFs) plays an important role\nin multivariate analysis. The importance has been increasing with the recent\nrise of statistical relational models since the MRF serves as a building block\nof these models such as Markov logic networks. There are two fundamental ways\nto learn structures of MRFs: methods based on parameter learning and those\nbased on independence test. The former methods more or less assume certain\nforms of distribution, so they potentially perform poorly when the assumption\nis not satisfied. The latter can learn an MRF structure without a strong\ndistributional assumption, but sometimes it is unclear what objective function\nis maximized/minimized in these methods. In this paper, we follow the latter,\nbut we explicitly define the optimization problem of MRF structure learning as\nmaximum pseudolikelihood estimation (MPLE) with respect to the edge set. As a\nresult, the proposed solution successfully deals with the {\\em symmetricity} in\nMRFs, whereas such symmetricity is not taken into account in most existing\nindependence test techniques. The proposed method achieved higher accuracy than\nprevious methods when there were asymmetric dependencies in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 01:22:52 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Takashina", "Yuya", ""], ["Nakatani", "Shuyo", ""], ["Inoue", "Masato", ""]]}, {"id": "1807.00973", "submitter": "Varun Embar", "authors": "Varun Embar and Dhanya Sridhar and Golnoosh Farnadi and Lise Getoor", "title": "Scalable Structure Learning for Probabilistic Soft Logic", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical relational frameworks such as Markov logic networks and\nprobabilistic soft logic (PSL) encode model structure with weighted first-order\nlogical clauses. Learning these clauses from data is referred to as structure\nlearning. Structure learning alleviates the manual cost of specifying models.\nHowever, this benefit comes with high computational costs; structure learning\ntypically requires an expensive search over the space of clauses which involves\nrepeated optimization of clause weights. In this paper, we propose the first\ntwo approaches to structure learning for PSL. We introduce a greedy\nsearch-based algorithm and a novel optimization method that trade-off\nscalability and approximations to the structure learning problem in varying\nways. The highly scalable optimization method combines data-driven generation\nof clauses with a piecewise pseudolikelihood (PPLL) objective that learns model\nstructure by optimizing clause weights only once. We compare both methods\nacross five real-world tasks, showing that PPLL achieves an order of magnitude\nruntime speedup and AUC gains up to 15% over greedy search.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 04:25:23 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Embar", "Varun", ""], ["Sridhar", "Dhanya", ""], ["Farnadi", "Golnoosh", ""], ["Getoor", "Lise", ""]]}, {"id": "1807.01001", "submitter": "Patrick Wenzel", "authors": "Patrick Wenzel, Qadeer Khan, Daniel Cremers, Laura Leal-Taix\\'e", "title": "Modular Vehicle Control for Transferring Semantic Information Between\n  Weather Conditions Using GANs", "comments": "2nd Conference on Robot Learning (CoRL 2018), Z\\\"urich, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though end-to-end supervised learning has shown promising results for\nsensorimotor control of self-driving cars, its performance is greatly affected\nby the weather conditions under which it was trained, showing poor\ngeneralization to unseen conditions. In this paper, we show how knowledge can\nbe transferred using semantic maps to new weather conditions without the need\nto obtain new ground truth data. To this end, we propose to divide the task of\nvehicle control into two independent modules: a control module which is only\ntrained on one weather condition for which labeled steering data is available,\nand a perception module which is used as an interface between new weather\nconditions and the fixed control module. To generate the semantic data needed\nto train the perception module, we propose to use a generative adversarial\nnetwork (GAN)-based model to retrieve the semantic information for the new\nconditions in an unsupervised manner. We introduce a master-servant\narchitecture, where the master model (semantic labels available) trains the\nservant model (semantic labels not available). We show that our proposed method\ntrained with ground truth data for a single weather condition is capable of\nachieving similar results on the task of steering angle prediction as an\nend-to-end model trained with ground truth data of 15 different weather\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 07:29:19 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 14:01:46 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Wenzel", "Patrick", ""], ["Khan", "Qadeer", ""], ["Cremers", "Daniel", ""], ["Leal-Taix\u00e9", "Laura", ""]]}, {"id": "1807.01020", "submitter": "Maarten Bieshaar", "authors": "Stephan Deist, Maarten Bieshaar, Jens Schreiber, Andre Gensler,\n  Bernhard Sick", "title": "Coopetitive Soft Gating Ensemble", "comments": "8 pages, 10 figures, 4 tables, submitted (accepted for publication) -\n  SISSY 2018 - Workshop on Self-Improving System Integration at IEEE ICAC/ SASO\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose the Coopetititve Soft Gating Ensemble or CSGE for\ngeneral machine learning tasks and interwoven systems. The goal of machine\nlearning is to create models that generalize well for unknown datasets. Often,\nhowever, the problems are too complex to be solved with a single model, so\nseveral models are combined. Similar, Autonomic Computing requires the\nintegration of different systems. Here, especially, the local, temporal online\nevaluation and the resulting (re-)weighting scheme of the CSGE makes the\napproach highly applicable for self-improving system integrations. To achieve\nthe best potential performance the CSGE can be optimized according to arbitrary\nloss functions making it accessible for a broader range of problems. We\nintroduce a novel training procedure including a hyper-parameter initialisation\nat its heart. We show that the CSGE approach reaches state-of-the-art\nperformance for both classification and regression tasks. Further on, the CSGE\nprovides a human-readable quantification on the influence of all base\nestimators employing the three weighting aspects. Moreover, we provide a\nscikit-learn compatible implementation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 08:33:01 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 10:50:05 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Deist", "Stephan", ""], ["Bieshaar", "Maarten", ""], ["Schreiber", "Jens", ""], ["Gensler", "Andre", ""], ["Sick", "Bernhard", ""]]}, {"id": "1807.01065", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Xiaobo Shen, Jianfei Cai", "title": "When Gaussian Process Meets Big Data: A Review of Scalable GPs", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast quantity of information brought by big data as well as the evolving\ncomputer hardware encourages success stories in the machine learning community.\nIn the meanwhile, it poses challenges for the Gaussian process (GP) regression,\na well-known non-parametric and interpretable Bayesian model, which suffers\nfrom cubic complexity to data size. To improve the scalability while retaining\ndesirable prediction quality, a variety of scalable GPs have been presented.\nBut they have not yet been comprehensively reviewed and analyzed in order to be\nwell understood by both academia and industry. The review of scalable GPs in\nthe GP community is timely and important due to the explosion of data size. To\nthis end, this paper is devoted to the review on state-of-the-art scalable GPs\ninvolving two main categories: global approximations which distillate the\nentire data and local approximations which divide the data for subspace\nlearning. Particularly, for global approximations, we mainly focus on sparse\napproximations comprising prior approximations which modify the prior but\nperform exact inference, posterior approximations which retain exact prior but\nperform approximate inference, and structured sparse approximations which\nexploit specific structures in kernel matrix; for local approximations, we\nhighlight the mixture/product of experts that conducts model averaging from\nmultiple local experts to boost predictions. To present a complete review,\nrecent advances for improving the scalability and capability of scalable GPs\nare reviewed. Finally, the extensions and open issues regarding the\nimplementation of scalable GPs in various scenarios are reviewed and discussed\nto inspire novel ideas for future research avenues.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:19:25 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 12:58:08 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Shen", "Xiaobo", ""], ["Cai", "Jianfei", ""]]}, {"id": "1807.01066", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Omer Gottesman, Yao Liu, Matthieu Komorowski, Aldo\n  Faisal, Finale Doshi-Velez, Emma Brunskill", "title": "Behaviour Policy Estimation in Off-Policy Policy Evaluation: Calibration\n  Matters", "comments": "Accepted to workshop on Machine Learning for Causal Inference,\n  Counterfactual Prediction, and Autonomous Action at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of estimating a behaviour policy for\nuse in Off-Policy Policy Evaluation (OPE) when the true behaviour policy is\nunknown. Via a series of empirical studies, we demonstrate how accurate OPE is\nstrongly dependent on the calibration of estimated behaviour policy models: how\nprecisely the behaviour policy is estimated from data. We show how powerful\nparametric models such as neural networks can result in highly uncalibrated\nbehaviour policy models on a real-world medical dataset, and illustrate how a\nsimple, non-parametric, k-nearest neighbours model produces better calibrated\nbehaviour policy estimates and can be used to obtain superior importance\nsampling-based OPE estimates.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:20:22 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 09:21:17 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Gottesman", "Omer", ""], ["Liu", "Yao", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo", ""], ["Doshi-Velez", "Finale", ""], ["Brunskill", "Emma", ""]]}, {"id": "1807.01069", "submitter": "Mathieu Sinn", "authors": "Maria-Irina Nicolae and Mathieu Sinn and Minh Ngoc Tran and Beat\n  Buesser and Ambrish Rawat and Martin Wistuba and Valentina Zantedeschi and\n  Nathalie Baracaldo and Bryant Chen and Heiko Ludwig and Ian M. Molloy and Ben\n  Edwards", "title": "Adversarial Robustness Toolbox v1.0.0", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Robustness Toolbox (ART) is a Python library supporting\ndevelopers and researchers in defending Machine Learning models (Deep Neural\nNetworks, Gradient Boosted Decision Trees, Support Vector Machines, Random\nForests, Logistic Regression, Gaussian Processes, Decision Trees, Scikit-learn\nPipelines, etc.) against adversarial threats and helps making AI systems more\nsecure and trustworthy. Machine Learning models are vulnerable to adversarial\nexamples, which are inputs (images, texts, tabular data, etc.) deliberately\nmodified to produce a desired response by the Machine Learning model. ART\nprovides the tools to build and deploy defences and test them with adversarial\nattacks. Defending Machine Learning models involves certifying and verifying\nmodel robustness and model hardening with approaches such as pre-processing\ninputs, augmenting training data with adversarial samples, and leveraging\nruntime detection methods to flag any inputs that might have been modified by\nan adversary. The attacks implemented in ART allow creating adversarial attacks\nagainst Machine Learning models which is required to test defenses with\nstate-of-the-art threat models. Supported Machine Learning Libraries include\nTensorFlow (v1 and v2), Keras, PyTorch, MXNet, Scikit-learn, XGBoost, LightGBM,\nCatBoost, and GPy. The source code of ART is released with MIT license at\nhttps://github.com/IBM/adversarial-robustness-toolbox. The release includes\ncode examples, notebooks with tutorials and documentation\n(http://adversarial-robustness-toolbox.readthedocs.io).\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:25:26 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 22:17:25 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2019 14:01:33 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 15:05:57 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Nicolae", "Maria-Irina", ""], ["Sinn", "Mathieu", ""], ["Tran", "Minh Ngoc", ""], ["Buesser", "Beat", ""], ["Rawat", "Ambrish", ""], ["Wistuba", "Martin", ""], ["Zantedeschi", "Valentina", ""], ["Baracaldo", "Nathalie", ""], ["Chen", "Bryant", ""], ["Ludwig", "Heiko", ""], ["Molloy", "Ian M.", ""], ["Edwards", "Ben", ""]]}, {"id": "1807.01082", "submitter": "Happy Mittal", "authors": "Happy Mittal, Ayush Bhardwaj, Vibhav Gogate, Parag Singla", "title": "Domain Aware Markov Logic Networks", "comments": "2 pages Position Paper accepted in StarAI workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining logic and probability has been a long stand- ing goal of AI\nresearch. Markov Logic Networks (MLNs) achieve this by attaching weights to\nformulas in first-order logic, and can be seen as templates for constructing\nfeatures for ground Markov networks. Most techniques for learning weights of\nMLNs are domain-size agnostic, i.e., the size of the domain is not explicitly\ntaken into account while learn- ing the parameters of the model. This often\nresults in ex- treme probabilities when testing on domain sizes different from\nthose seen during training. In this paper, we propose Domain Aware Markov logic\nNetworks (DA-MLNs) which present a principled solution to this problem. While\ndefin- ing the ground network distribution, DA-MLNs divide the ground feature\nweight by a scaling factor which is a function of the number of connections the\nground atoms appearing in the feature are involved in. We show that standard\nMLNs fall out as a special case of our formalism when this func- tion evaluates\nto a constant equal to 1. Experiments on the benchmark Friends & Smokers domain\nshow that our ap- proach results in significantly higher accuracies compared to\nexisting methods when testing on domains whose sizes different from those seen\nduring training.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 11:00:24 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 08:33:42 GMT"}, {"version": "v3", "created": "Sat, 7 Jul 2018 08:53:26 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Mittal", "Happy", ""], ["Bhardwaj", "Ayush", ""], ["Gogate", "Vibhav", ""], ["Singla", "Parag", ""]]}, {"id": "1807.01083", "submitter": "Jiequn Han", "authors": "Weinan E, Jiequn Han, Qianxiao Li", "title": "A Mean-Field Optimal Control Formulation of Deep Learning", "comments": "44 pages", "journal-ref": "Research in the Mathematical Sciences, 6:10 (2019)", "doi": "10.1007/s40687-018-0172-y", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work linking deep neural networks and dynamical systems opened up new\navenues to analyze deep learning. In particular, it is observed that new\ninsights can be obtained by recasting deep learning as an optimal control\nproblem on difference or differential equations. However, the mathematical\naspects of such a formulation have not been systematically explored. This paper\nintroduces the mathematical formulation of the population risk minimization\nproblem in deep learning as a mean-field optimal control problem. Mirroring the\ndevelopment of classical optimal control, we state and prove optimality\nconditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type.\nThese mean-field results reflect the probabilistic nature of the learning\nproblem. In addition, by appealing to the mean-field Pontryagin's maximum\nprinciple, we establish some quantitative relationships between population and\nempirical learning problems. This serves to establish a mathematical foundation\nfor investigating the algorithmic and theoretical connections between optimal\ncontrol and deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 11:05:13 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["E", "Weinan", ""], ["Han", "Jiequn", ""], ["Li", "Qianxiao", ""]]}, {"id": "1807.01085", "submitter": "Shervin Rahimzadeh Arashloo", "authors": "Shervin Rahimzadeh Arashloo and Josef Kittler", "title": "One-Class Kernel Spectral Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a new efficient nonlinear one-class classifier\nformulated as the Rayleigh quotient criterion optimisation. The method,\noperating in a reproducing kernel Hilbert space, minimises the scatter of\ntarget distribution along an optimal projection direction while at the same\ntime keeping projections of positive observations distant from the mean of the\nnegative class. We provide a graph embedding view of the problem which can then\nbe solved efficiently using the spectral regression approach. In this sense,\nunlike previous similar methods which often require costly eigen-computations\nof dense matrices, the proposed approach casts the problem under consideration\ninto a regression framework which is computationally more efficient. In\nparticular, it is shown that the dominant complexity of the proposed method is\nthe complexity of computing the kernel matrix. Additional appealing\ncharacteristics of the proposed one-class classifier are: 1-the ability to be\ntrained in an incremental fashion (allowing for application in streaming data\nscenarios while also reducing the computational complexity in a non-streaming\noperation mode); 2-being unsupervised, but providing the option for refining\nthe solution using negative training examples, when available; And last but not\nthe least, 3-the use of the kernel trick which facilitates a nonlinear mapping\nof the data into a high-dimensional feature space to seek better solutions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 11:19:17 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 06:57:12 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 16:31:08 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 13:45:54 GMT"}, {"version": "v5", "created": "Mon, 20 Aug 2018 13:05:59 GMT"}, {"version": "v6", "created": "Sun, 10 Feb 2019 11:45:13 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Arashloo", "Shervin Rahimzadeh", ""], ["Kittler", "Josef", ""]]}, {"id": "1807.01126", "submitter": "Nelson Yalta", "authors": "Nelson Yalta, Shinji Watanabe, Kazuhiro Nakadai, Tetsuya Ogata", "title": "Weakly Supervised Deep Recurrent Neural Networks for Basic Dance Step\n  Generation", "comments": "8 pages, 7 figures. Proc. IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synthesizing human's movements such as dancing is a flourishing research\nfield which has several applications in computer graphics. Recent studies have\ndemonstrated the advantages of deep neural networks (DNNs) for achieving\nremarkable performance in motion and music tasks with little effort for feature\npre-processing. However, applying DNNs for generating dance to a piece of music\nis nevertheless challenging, because of 1) DNNs need to generate large\nsequences while mapping the music input, 2) the DNN needs to constraint the\nmotion beat to the music, and 3) DNNs require a considerable amount of\nhand-crafted data. In this study, we propose a weakly supervised deep recurrent\nmethod for real-time basic dance generation with audio power spectrum as input.\nThe proposed model employs convolutional layers and a multilayered Long\nShort-Term memory (LSTM) to process the audio input. Then, another deep LSTM\nlayer decodes the target dance sequence. Notably, this end-to-end approach has\n1) an auto-conditioned decode configuration that reduces accumulation of\nfeedback error of large dance sequence, 2) uses a contrastive cost function to\nregulate the mapping between the music and motion beat, and 3) trains with weak\nlabels generated from the motion beat, reducing the amount of hand-crafted\ndata. We evaluate the proposed network based on i) the similarities between\ngenerated and the baseline dancer motion with a cross entropy measure for large\ndance sequences, and ii) accurate timing between the music and motion beat with\nan F-measure. Experimental results revealed that, after training using a small\ndataset, the model generates basic dance steps with low cross entropy and\nmaintains an F-measure score similar to that of a baseline dancer.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 12:47:15 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 12:46:20 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 00:48:28 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Yalta", "Nelson", ""], ["Watanabe", "Shinji", ""], ["Nakadai", "Kazuhiro", ""], ["Ogata", "Tetsuya", ""]]}, {"id": "1807.01134", "submitter": "Lily Hu", "authors": "Lily Hu and Yiling Chen", "title": "Welfare and Distributional Impacts of Fair Classification", "comments": "5 pages, FATML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methodologies in machine learning analyze the effects of various\nstatistical parity notions of fairness primarily in light of their impacts on\npredictive accuracy and vendor utility loss. In this paper, we propose a new\nframework for interpreting the effects of fairness criteria by converting the\nconstrained loss minimization problem into a social welfare maximization\nproblem. This translation moves a classifier and its output into utility space\nwhere individuals, groups, and society at-large experience different welfare\nchanges due to classification assignments. Under this characterization,\npredictions and fairness constraints are seen as shaping societal welfare and\ndistribution and revealing individuals' implied welfare weights in\nsociety--weights that may then be interpreted through a fairness lens. The\nsocial welfare formulation of the fairness problem brings to the fore concerns\nof distributive justice that have always had a central albeit more implicit\nrole in standard algorithmic fairness approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 12:57:59 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Hu", "Lily", ""], ["Chen", "Yiling", ""]]}, {"id": "1807.01176", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh Khaled Ghafoor", "title": "Credit Default Mining Using Combined Machine Learning and Heuristic\n  Approach", "comments": "Accepted for ICDATA, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting potential credit default accounts in advance is challenging.\nTraditional statistical techniques typically cannot handle large amounts of\ndata and the dynamic nature of fraud and humans. To tackle this problem, recent\nresearch has focused on artificial and computational intelligence based\napproaches. In this work, we present and validate a heuristic approach to mine\npotential default accounts in advance where a risk probability is precomputed\nfrom all previous data and the risk probability for recent transactions are\ncomputed as soon they happen. Beside our heuristic approach, we also apply a\nrecently proposed machine learning approach that has not been applied\npreviously on our targeted dataset [15]. As a result, we find that these\napplied approaches outperform existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:51:35 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh Khaled", ""]]}, {"id": "1807.01182", "submitter": "Ayushi Dalmia", "authors": "Ayushi Dalmia, Sachindra Joshi, Raghavendra Singh, Vikas Raykar", "title": "Styling with Attention to Details", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fashion as characterized by its nature, is driven by style. In this paper, we\npropose a method that takes into account the style information to complete a\ngiven set of selected fashion items with a complementary fashion item.\nComplementary items are those items that can be worn along with the selected\nitems according to the style. Addressing this problem facilitates in\nautomatically generating stylish fashion ensembles leading to a richer shopping\nexperience for users.\n  Recently, there has been a surge of online social websites where fashion\nenthusiasts post the outfit of the day and other users can like and comment on\nthem. These posts contain a gold-mine of information about style. In this\npaper, we exploit these posts to train a deep neural network which captures\nstyle in an automated manner. We pose the problem of predicting complementary\nfashion items as a sequence to sequence problem where the input is the selected\nset of fashion items and the output is a complementary fashion item based on\nthe style information learned by the model. We use the encoder decoder\narchitecture to solve this problem of completing the set of fashion items. We\nevaluate the goodness of the proposed model through a variety of experiments.\nWe empirically observe that our proposed model outperforms competitive baseline\nlike apriori algorithm by ~28 in terms of accuracy for top-1 recommendation to\ncomplete the fashion ensemble. We also perform retrieval based experiments to\nunderstand the ability of the model to learn style and rank the complementary\nfashion items and find that using attention in our encoder decoder model helps\nin improving the mean reciprocal rank by ~24. Qualitatively we find the\ncomplementary fashion items generated by our proposed model are richer than the\napriori algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 13:38:20 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Dalmia", "Ayushi", ""], ["Joshi", "Sachindra", ""], ["Singh", "Raghavendra", ""], ["Raykar", "Vikas", ""]]}, {"id": "1807.01183", "submitter": "V\\'ictor Guti\\'errez-Basulto", "authors": "V\\'ictor Guti\\'errez-Basulto, Jean Christoph Jung, Ondrej Kuzelka", "title": "Quantified Markov Logic Networks", "comments": "Paper accepted at the 16th International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2018). This work was also\n  presented in the Eighth International Workshop on Statistical Relational AI\n  (StarAI 2018) under the title \"Markov Logic Networks with Statistical\n  Quantifiers\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Logic Networks (MLNs) are well-suited for expressing statistics such\nas \"with high probability a smoker knows another smoker\" but not for expressing\nstatements such as \"there is a smoker who knows most other smokers\", which is\nnecessary for modeling, e.g. influencers in social networks. To overcome this\nshortcoming, we study quantified MLNs which generalize MLNs by introducing\nstatistical universal quantifiers, allowing to express also the latter type of\nstatistics in a principled way. Our main technical contribution is to show that\nthe standard reasoning tasks in quantified MLNs, maximum a posteriori and\nmarginal inference, can be reduced to their respective MLN counterparts in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 13:39:19 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 16:47:24 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 14:18:47 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Jung", "Jean Christoph", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "1807.01194", "submitter": "Steve Dias Da Cruz", "authors": "Hans-Peter Beise, Steve Dias Da Cruz, Udo Schr\\\"oder", "title": "On decision regions of narrow deep neural networks", "comments": "This paper is accepted for publication in Neural Networks (Elsevier\n  Journal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for neural network functions that have width less or equal to\nthe input dimension all connected components of decision regions are unbounded.\nThe result holds for continuous and strictly monotonic activation functions as\nwell as for the ReLU activation function. This complements recent results on\napproximation capabilities by [Hanin 2017 Approximating] and connectivity of\ndecision regions by [Nguyen 2018 Neural] for such narrow neural networks. Our\nresults are illustrated by means of numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 14:03:42 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 10:26:45 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 09:44:00 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 08:35:12 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Beise", "Hans-Peter", ""], ["Da Cruz", "Steve Dias", ""], ["Schr\u00f6der", "Udo", ""]]}, {"id": "1807.01202", "submitter": "Ramiro Camino", "authors": "Ramiro Camino, Christian Hammerschmidt, Radu State", "title": "Generating Multi-Categorical Samples with Generative Adversarial\n  Networks", "comments": null, "journal-ref": "Presented at the ICML 2018 workshop on Theoretical Foundations and\n  Applications of Deep Generative Models, Stockholm, Sweden", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to train generative adversarial networks on mutivariate\nfeature vectors representing multiple categorical values. In contrast to the\ncontinuous domain, where GAN-based methods have delivered considerable results,\nGANs struggle to perform equally well on discrete data. We propose and compare\nseveral architectures based on multiple (Gumbel) softmax output layers taking\ninto account the structure of the data. We evaluate the performance of our\narchitecture on datasets with different sparsity, number of features, ranges of\ncategorical values, and dependencies among the features. Our proposed\narchitecture and method outperforms existing models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 14:26:57 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 15:10:32 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Camino", "Ramiro", ""], ["Hammerschmidt", "Christian", ""], ["State", "Radu", ""]]}, {"id": "1807.01251", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu, Yaoyu Zhang, Yanyang Xiao", "title": "Training behavior of deep neural network in frequency domain", "comments": "To appear in 2019 26th-International conference of neural information\n  processing (ICONIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:50:41 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 17:53:43 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 05:54:32 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 21:46:34 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 07:26:27 GMT"}, {"version": "v6", "created": "Fri, 1 Nov 2019 02:21:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhang", "Yaoyu", ""], ["Xiao", "Yanyang", ""]]}, {"id": "1807.01279", "submitter": "Edward Pyzer-Knapp", "authors": "Dipti Jasrasaria and Edward O. Pyzer-Knapp", "title": "Dynamic Control of Explore/Exploit Trade-Off In Bayesian Optimization", "comments": "Accepted for publication in the proceedings of 2018 Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization offers the possibility of optimizing black-box\noperations not accessible through traditional techniques. The success of\nBayesian optimization methods such as Expected Improvement (EI) are\nsignificantly affected by the degree of trade-off between exploration and\nexploitation. Too much exploration can lead to inefficient optimization\nprotocols, whilst too much exploitation leaves the protocol open to strong\ninitial biases, and a high chance of getting stuck in a local minimum.\nTypically, a constant margin is used to control this trade-off, which results\nin yet another hyper-parameter to be optimized. We propose contextual\nimprovement as a simple, yet effective heuristic to counter this - achieving a\none-shot optimization strategy. Our proposed heuristic can be swiftly\ncalculated and improves both the speed and robustness of discovery of optimal\nsolutions. We demonstrate its effectiveness on both synthetic and real world\nproblems and explore the unaccounted for uncertainty in the pre-determination\nof search hyperparameters controlling explore-exploit trade-off.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:56:05 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Jasrasaria", "Dipti", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "1807.01280", "submitter": "Vaggos Chatziafratis", "authors": "Vaggos Chatziafratis, Tim Roughgarden, Joshua R. Wang", "title": "On the Computational Power of Online Gradient Descent", "comments": "Added results, linear regression, neural nets. Fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the evolution of weight vectors in online gradient descent can\nencode arbitrary polynomial-space computations, even in very simple learning\nsettings. Our results imply that, under weak complexity-theoretic assumptions,\nit is impossible to reason efficiently about the fine-grained behavior of\nonline gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:56:14 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 09:33:18 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Chatziafratis", "Vaggos", ""], ["Roughgarden", "Tim", ""], ["Wang", "Joshua R.", ""]]}, {"id": "1807.01281", "submitter": "Wojciech Czarnecki", "authors": "Max Jaderberg, Wojciech M. Czarnecki, Iain Dunning, Luke Marris, Guy\n  Lever, Antonio Garcia Castaneda, Charles Beattie, Neil C. Rabinowitz, Ari S.\n  Morcos, Avraham Ruderman, Nicolas Sonnerat, Tim Green, Louise Deason, Joel Z.\n  Leibo, David Silver, Demis Hassabis, Koray Kavukcuoglu, Thore Graepel", "title": "Human-level performance in first-person multiplayer games with\n  population-based deep reinforcement learning", "comments": null, "journal-ref": null, "doi": "10.1126/science.aau6249", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence through reinforcement learning\n(RL) has shown great success on increasingly complex single-agent environments\nand two-player turn-based games. However, the real-world contains multiple\nagents, each learning and acting independently to cooperate and compete with\nother agents, and environments reflecting this degree of complexity remain an\nopen challenge. In this work, we demonstrate for the first time that an agent\ncan achieve human-level in a popular 3D multiplayer first-person video game,\nQuake III Arena Capture the Flag, using only pixels and game points as input.\nThese results were achieved by a novel two-tier optimisation process in which a\npopulation of independent RL agents are trained concurrently from thousands of\nparallel matches with agents playing in teams together and against each other\non randomly generated environments. Each agent in the population learns its own\ninternal reward signal to complement the sparse delayed reward from winning,\nand selects actions using a novel temporally hierarchical representation that\nenables the agent to reason at multiple timescales. During game-play, these\nagents display human-like behaviours such as navigating, following, and\ndefending based on a rich learned representation that is shown to encode\nhigh-level game knowledge. In an extensive tournament-style evaluation the\ntrained agents exceeded the win-rate of strong human players both as teammates\nand opponents, and proved far stronger than existing state-of-the-art agents.\nThese results demonstrate a significant jump in the capabilities of artificial\nagents, bringing us closer to the goal of human-level intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:57:18 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Jaderberg", "Max", ""], ["Czarnecki", "Wojciech M.", ""], ["Dunning", "Iain", ""], ["Marris", "Luke", ""], ["Lever", "Guy", ""], ["Castaneda", "Antonio Garcia", ""], ["Beattie", "Charles", ""], ["Rabinowitz", "Neil C.", ""], ["Morcos", "Ari S.", ""], ["Ruderman", "Avraham", ""], ["Sonnerat", "Nicolas", ""], ["Green", "Tim", ""], ["Deason", "Louise", ""], ["Leibo", "Joel Z.", ""], ["Silver", "David", ""], ["Hassabis", "Demis", ""], ["Kavukcuoglu", "Koray", ""], ["Graepel", "Thore", ""]]}, {"id": "1807.01290", "submitter": "Victor Berger", "authors": "Victor Berger and Mich\\`ele Sebag", "title": "New Losses for Generative Adversarial Learning", "comments": "The central result of the paper was based on a wrong assumption: the\n  term in the loss capturing the variation of the optimal discriminator with\n  relation to the generator can be proved to be always zero using the Envelope\n  Theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (Goodfellow et al., 2014), a major\nbreakthrough in the field of generative modeling, learn a discriminator to\nestimate some distance between the target and the candidate distributions.\n  This paper examines mathematical issues regarding the way the gradients for\nthe generative model are computed in this context, and notably how to take into\naccount how the discriminator itself depends on the generator parameters.\n  A unifying methodology is presented to define mathematically sound training\nobjectives for generative models taking this dependency into account in a\nrobust way, covering both GAN, VAE and some GAN variants as particular cases.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 17:07:55 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 14:38:33 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Berger", "Victor", ""], ["Sebag", "Mich\u00e8le", ""]]}, {"id": "1807.01297", "submitter": "Raphael Townshend", "authors": "Raphael J. L. Townshend, Rishi Bedi, Patricia A. Suriana, Ron O. Dror", "title": "End-to-End Learning on 3D Protein Structure for Interface Prediction", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite an explosion in the number of experimentally determined, atomically\ndetailed structures of biomolecules, many critical tasks in structural biology\nremain data-limited. Whether performance in such tasks can be improved by using\nlarge repositories of tangentially related structural data remains an open\nquestion. To address this question, we focused on a central problem in biology:\npredicting how proteins interact with one another---that is, which surfaces of\none protein bind to those of another protein. We built a training dataset, the\nDatabase of Interacting Protein Structures (DIPS), that contains biases but is\ntwo orders of magnitude larger than those used previously. We found that these\nbiases significantly degrade the performance of existing methods on\ngold-standard data. Hypothesizing that assumptions baked into the hand-crafted\nfeatures on which these methods depend were the source of the problem, we\ndeveloped the first end-to-end learning model for protein interface prediction,\nthe Siamese Atomic Surfacelet Network (SASNet). Using only spatial coordinates\nand identities of atoms, SASNet outperforms state-of-the-art methods trained on\ngold-standard structural data, even when trained on only 3% of our new dataset.\nCode and data available at https://github.com/drorlab/DIPS.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 17:31:32 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 21:45:23 GMT"}, {"version": "v3", "created": "Sun, 18 Nov 2018 08:12:56 GMT"}, {"version": "v4", "created": "Sun, 27 Oct 2019 00:39:54 GMT"}, {"version": "v5", "created": "Thu, 26 Dec 2019 22:09:57 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Townshend", "Raphael J. L.", ""], ["Bedi", "Rishi", ""], ["Suriana", "Patricia A.", ""], ["Dror", "Ron O.", ""]]}, {"id": "1807.01298", "submitter": "Sobhan Soleymani", "authors": "Sobhan Soleymani, Amirsina Torfi, Jeremy Dawson, Nasser M. Nasrabadi", "title": "Generalized Bilinear Deep Convolutional Neural Networks for Multimodal\n  Biometric Identification", "comments": "Accepted in 2018 IEEE International Conference on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to employ a bank of modality-dedicated\nConvolutional Neural Networks (CNNs), fuse, train, and optimize them together\nfor person classification tasks. A modality-dedicated CNN is used for each\nmodality to extract modality-specific features. We demonstrate that, rather\nthan spatial fusion at the convolutional layers, the fusion can be performed on\nthe outputs of the fully-connected layers of the modality-specific CNNs without\nany loss of performance and with significant reduction in the number of\nparameters. We show that, using multiple CNNs with multimodal fusion at the\nfeature-level, we significantly outperform systems that use unimodal\nrepresentation. We study weighted feature, bilinear, and compact bilinear\nfeature-level fusion algorithms for multimodal biometric person identification.\nFinally, We propose generalized compact bilinear fusion algorithm to deploy\nboth the weighted feature fusion and compact bilinear schemes. We provide the\nresults for the proposed algorithms on three challenging databases: CMU\nMulti-PIE, BioCop, and BIOMDATA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 17:31:42 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Soleymani", "Sobhan", ""], ["Torfi", "Amirsina", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1807.01308", "submitter": "Kush Varshney", "authors": "Been Kim, Kush R. Varshney, Adrian Weller", "title": "Proceedings of the 2018 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2018)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of the 2018 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2018), which was held in Stockholm, Sweden, July 14,\n2018. Invited speakers were Barbara Engelhardt, Cynthia Rudin, Fernanda\nVi\\'egas, and Martin Wattenberg.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 17:49:14 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Kim", "Been", ""], ["Varshney", "Kush R.", ""], ["Weller", "Adrian", ""]]}, {"id": "1807.01332", "submitter": "Sobhan Soleymani", "authors": "Sobhan Soleymani, Ali Dabouei, Hadi Kazemi, Jeremy Dawson and Nasser\n  M. Nasrabadi", "title": "Multi-Level Feature Abstraction from Convolutional Neural Networks for\n  Multimodal Biometric Identification", "comments": "Accepted in \"2018 International Conference on Pattern Recognition\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep multimodal fusion network to fuse multiple\nmodalities (face, iris, and fingerprint) for person identification. The\nproposed deep multimodal fusion algorithm consists of multiple streams of\nmodality-specific Convolutional Neural Networks (CNNs), which are jointly\noptimized at multiple feature abstraction levels. Multiple features are\nextracted at several different convolutional layers from each modality-specific\nCNN for joint feature fusion, optimization, and classification. Features\nextracted at different convolutional layers of a modality-specific CNN\nrepresent the input at several different levels of abstract representations. We\ndemonstrate that an efficient multimodal classification can be accomplished\nwith a significant reduction in the number of network parameters by exploiting\nthese multi-level abstract representations extracted from all the\nmodality-specific CNNs. We demonstrate an increase in multimodal person\nidentification performance by utilizing the proposed multi-level feature\nabstract representations in our multimodal fusion, rather than using only the\nfeatures from the last layer of each modality-specific CNNs. We show that our\ndeep multi-modal CNNs with multimodal fusion at several different feature level\nabstraction can significantly outperform the unimodal representation accuracy.\nWe also demonstrate that the joint optimization of all the modality-specific\nCNNs excels the score and decision level fusions of independently optimized\nCNNs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 18:10:30 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Soleymani", "Sobhan", ""], ["Dabouei", "Ali", ""], ["Kazemi", "Hadi", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1807.01334", "submitter": "Reihaneh Entezari", "authors": "Reihaneh Entezari", "title": "Breast Cancer Diagnosis via Classification Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the Wisconsin Diagnostic Breast Cancer Data using\nMachine Learning classification techniques, such as the SVM, Bayesian Logistic\nRegression (Variational Approximation), and K-Nearest-Neighbors. We describe\neach model, and compare their performance through different measures. We\nconclude that SVM has the best performance among all other classifiers, while\nit competes closely with the Bayesian Logistic Regression that is ranked second\nbest method for this dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 18:13:55 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Entezari", "Reihaneh", ""]]}, {"id": "1807.01337", "submitter": "Piero Molino", "authors": "Piero Molino, Huaixiu Zheng, Yi-Chia Wang", "title": "COTA: Improving the Speed and Accuracy of Customer Support through\n  Ranking and Deep Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3219819.3219851", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a company looking to provide delightful user experiences, it is of\nparamount importance to take care of any customer issues. This paper proposes\nCOTA, a system to improve speed and reliability of customer support for end\nusers through automated ticket classification and answers selection for support\nrepresentatives. Two machine learning and natural language processing\ntechniques are demonstrated: one relying on feature engineering (COTA v1) and\nthe other exploiting raw signals through deep learning architectures (COTA v2).\nCOTA v1 employs a new approach that converts the multi-classification task into\na ranking problem, demonstrating significantly better performance in the case\nof thousands of classes. For COTA v2, we propose an Encoder-Combiner-Decoder, a\nnovel deep learning architecture that allows for heterogeneous input and output\nfeature types and injection of prior knowledge through network architecture\nchoices. This paper compares these models and their variants on the task of\nticket classification and answer selection, showing model COTA v2 outperforms\nCOTA v1, and analyzes their inner workings and shortcomings. Finally, an A/B\ntest is conducted in a production setting validating the real-world impact of\nCOTA in reducing issue resolution time by 10 percent without reducing customer\nsatisfaction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 18:25:44 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Molino", "Piero", ""], ["Zheng", "Huaixiu", ""], ["Wang", "Yi-Chia", ""]]}, {"id": "1807.01349", "submitter": "Peng Xu", "authors": "Yuchen Lu, Peng Xu", "title": "Anomaly Detection for Skin Disease Images Using Variational Autoencoder", "comments": "8 pages, 2 figures, submitted to ISIC Skin Image Analysis Workshop\n  and Challenge at MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the potential of applying Variational\nAutoencoder (VAE) [10] for anomaly detection in skin disease images. VAE is a\nclass of deep generative models which is trained by maximizing the evidence\nlower bound of data distribution [10]. When trained on only normal data, the\nresulting model is able to perform efficient inference and to determine if a\ntest image is normal or not. We perform experiments on ISIC2018 Challenge\nDisease Classification dataset (Task 3) and compare different methods to use\nVAE to detect anomaly. The model is able to detect all diseases with 0.779\nAUCROC. If we focus on specific diseases, the model is able to detect melanoma\nwith 0.864 AUCROC and detect actinic keratosis with 0.872 AUCROC, even if it\nonly sees the images of nevus. To the best of our knowledge, this is the first\napplied work of deep generative models for anomaly detection in dermatology.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 19:27:47 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 18:09:51 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Lu", "Yuchen", ""], ["Xu", "Peng", ""]]}, {"id": "1807.01350", "submitter": "Ekta Gujral", "authors": "Ekta Gujral, Ravdeep Pasricha, Tianxiong Yang, Evangelos E.\n  Papalexakis", "title": "OCTen: Online Compression-based Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decompositions are powerful tools for large data analytics as they\njointly model multiple aspects of data into one framework and enable the\ndiscovery of the latent structures and higher-order correlations within the\ndata. One of the most widely studied and used decompositions, especially in\ndata mining and machine learning, is the Canonical Polyadic or CP\ndecomposition. However, today's datasets are not static and these datasets\noften dynamically growing and changing with time. To operate on such large\ndata, we present OCTen the first ever compression-based online parallel\nimplementation for the CP decomposition. We conduct an extensive empirical\nanalysis of the algorithms in terms of fitness, memory used and CPU time, and\nin order to demonstrate the compression and scalability of the method, we apply\nOCTen to big tensor data. Indicatively, OCTen performs on-par or better than\nstate-of-the-art online and online methods in terms of decomposition accuracy\nand efficiency, while saving up to 40-200 % memory space.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 19:30:41 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Gujral", "Ekta", ""], ["Pasricha", "Ravdeep", ""], ["Yang", "Tianxiong", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1807.01356", "submitter": "Malte J. Rasch", "authors": "Malte J. Rasch and Tayfun Gokmen and Mattia Rigotti and Wilfried\n  Haensch", "title": "Efficient ConvNets for Analog Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog arrays are a promising upcoming hardware technology with the potential\nto drastically speed up deep learning. Their main advantage is that they\ncompute matrix-vector products in constant time, irrespective of the size of\nthe matrix. However, early convolution layers in ConvNets map very unfavorably\nonto analog arrays, because kernel matrices are typically small and the\nconstant time operation needs to be sequentially iterated a large number of\ntimes, reducing the speed up advantage for ConvNets. Here, we propose to\nreplicate the kernel matrix of a convolution layer on distinct analog arrays,\nand randomly divide parts of the compute among them, so that multiple kernel\nmatrices are trained in parallel. With this modification, analog arrays execute\nConvNets with an acceleration factor that is proportional to the number of\nkernel matrices used per layer (here tested 16-128). Despite having more free\nparameters, we show analytically and in numerical experiments that this\nconvolution architecture is self-regularizing and implicitly learns similar\nfilters across arrays. We also report superior performance on a number of\ndatasets and increased robustness to adversarial attacks. Our investigation\nsuggests to revise the notion that mixed analog-digital hardware is not\nsuitable for ConvNets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 19:37:58 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Rasch", "Malte J.", ""], ["Gokmen", "Tayfun", ""], ["Rigotti", "Mattia", ""], ["Haensch", "Wilfried", ""]]}, {"id": "1807.01367", "submitter": "Phuc Nguyen Tri", "authors": "Phuc Nguyen, Khai Nguyen, Ryutaro Ichise, Hideaki Takeda", "title": "EmbNum: Semantic labeling for numerical values with deep metric learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic labeling for numerical values is a task of assigning semantic labels\nto unknown numerical attributes. The semantic labels could be numerical\nproperties in ontologies, instances in knowledge bases, or labeled data that\nare manually annotated by domain experts. In this paper, we refer to semantic\nlabeling as a retrieval setting where the label of an unknown attribute is\nassigned by the label of the most relevant attribute in labeled data. One of\nthe greatest challenges is that an unknown attribute rarely has the same set of\nvalues with the similar one in the labeled data. To overcome the issue,\nstatistical interpretation of value distribution is taken into account.\nHowever, the existing studies assume a specific form of distribution. It is not\nappropriate in particular to apply open data where there is no knowledge of\ndata in advance. To address these problems, we propose a neural numerical\nembedding model (EmbNum) to learn useful representation vectors for numerical\nattributes without prior assumptions on the distribution of data. Then, the\n\"semantic similarities\" between the attributes are measured on these\nrepresentation vectors by the Euclidean distance. Our empirical experiments on\nCity Data and Open Data show that EmbNum significantly outperforms\nstate-of-the-art methods for the task of numerical attribute semantic labeling\nregarding effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 03:51:53 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 06:21:56 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Nguyen", "Phuc", ""], ["Nguyen", "Khai", ""], ["Ichise", "Ryutaro", ""], ["Takeda", "Hideaki", ""]]}, {"id": "1807.01395", "submitter": "Madhumita Sushil", "authors": "Madhumita Sushil and Simon \\v{S}uster and Kim Luyckx and Walter\n  Daelemans", "title": "Patient representation learning and interpretable evaluation using\n  clinical notes", "comments": "Accepted manuscript at Journal of Biomedical Informatics", "journal-ref": "Journal of Biomedical Informatics Volume 84C (2018) pp. 103-113", "doi": "10.1016/j.jbi.2018.06.016", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have three contributions in this work: 1. We explore the utility of a\nstacked denoising autoencoder and a paragraph vector model to learn\ntask-independent dense patient representations directly from clinical notes. To\nanalyze if these representations are transferable across tasks, we evaluate\nthem in multiple supervised setups to predict patient mortality, primary\ndiagnostic and procedural category, and gender. We compare their performance\nwith sparse representations obtained from a bag-of-words model. We observe that\nthe learned generalized representations significantly outperform the sparse\nrepresentations when we have few positive instances to learn from, and there is\nan absence of strong lexical features. 2. We compare the model performance of\nthe feature set constructed from a bag of words to that obtained from medical\nconcepts. In the latter case, concepts represent problems, treatments, and\ntests. We find that concept identification does not improve the classification\nperformance. 3. We propose novel techniques to facilitate model\ninterpretability. To understand and interpret the representations, we explore\nthe best encoded features within the patient representations obtained from the\nautoencoder model. Further, we calculate feature sensitivity across two\nnetworks to identify the most significant input features for different\nclassification tasks when we use these pretrained representations as the\nsupervised input. We successfully extract the most influential features for the\npipeline using this technique.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 23:20:49 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Sushil", "Madhumita", ""], ["\u0160uster", "Simon", ""], ["Luyckx", "Kim", ""], ["Daelemans", "Walter", ""]]}, {"id": "1807.01401", "submitter": "Henry Kvinge", "authors": "Elin Farnell, Henry Kvinge, Michael Kirby, Chris Peterson", "title": "Endmember Extraction on the Grassmannian", "comments": "To appear in Proceedings of the 2018 IEEE Data Science Workshop,\n  Lausanne, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endmember extraction plays a prominent role in a variety of data analysis\nproblems as endmembers often correspond to data representing the purest or best\nrepresentative of some feature. Identifying endmembers then can be useful for\nfurther identification and classification tasks. In settings with\nhigh-dimensional data, such as hyperspectral imagery, it can be useful to\nconsider endmembers that are subspaces as they are capable of capturing a wider\nrange of variations of a signature. The endmember extraction problem in this\nsetting thus translates to finding the vertices of the convex hull of a set of\npoints on a Grassmannian. In the presence of noise, it can be less clear\nwhether a point should be considered a vertex. In this paper, we propose an\nalgorithm to extract endmembers on a Grassmannian, identify subspaces of\ninterest that lie near the boundary of a convex hull, and demonstrate the use\nof the algorithm on a synthetic example and on the 220 spectral band AVIRIS\nIndian Pines hyperspectral image.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 23:35:47 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Farnell", "Elin", ""], ["Kvinge", "Henry", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""]]}, {"id": "1807.01406", "submitter": "Guillaume Rabusseau", "authors": "Guillaume Rabusseau and Tianyu Li and Doina Precup", "title": "Connecting Weighted Automata and Recurrent Neural Networks through\n  Spectral Learning", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we unravel a fundamental connection between weighted finite\nautomata~(WFAs) and second-order recurrent neural networks~(2-RNNs): in the\ncase of sequences of discrete symbols, WFAs and 2-RNNs with linear activation\nfunctions are expressively equivalent. Motivated by this result, we build upon\na recent extension of the spectral learning algorithm to vector-valued WFAs and\npropose the first provable learning algorithm for linear 2-RNNs defined over\nsequences of continuous input vectors. This algorithm relies on estimating low\nrank sub-blocks of the so-called Hankel tensor, from which the parameters of a\nlinear 2-RNN can be provably recovered. The performances of the proposed method\nare assessed in a simulation study.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 00:12:12 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 03:50:03 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Rabusseau", "Guillaume", ""], ["Li", "Tianyu", ""], ["Precup", "Doina", ""]]}, {"id": "1807.01422", "submitter": "Sarah Romanes", "authors": "Sarah Elizabeth Romanes, John Thomas Ormerod, Jean YH Yang", "title": "Diagonal Discriminant Analysis with Feature Selection for High\n  Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method of performing high dimensional discriminant\nanalysis, which we call multiDA. We achieve this by constructing a hybrid model\nthat seamlessly integrates a multiclass diagonal discriminant analysis model\nand feature selection components. Our feature selection component naturally\nsimplifies to weights which are simple functions of likelihood ratio statistics\nallowing natural comparisons with traditional hypothesis testing methods. We\nprovide heuristic arguments suggesting desirable asymptotic properties of our\nalgorithm with regards to feature selection. We compare our method with several\nother approaches, showing marked improvements in regard to prediction accuracy,\ninterpretability of chosen features, and algorithm run time. We demonstrate\nsuch strengths of our model by showing strong classification performance on\npublicly available high dimensional datasets, as well as through multiple\nsimulation studies. We make an R package available implementing our approach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 01:39:03 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Romanes", "Sarah Elizabeth", ""], ["Ormerod", "John Thomas", ""], ["Yang", "Jean YH", ""]]}, {"id": "1807.01430", "submitter": "Zhisheng Wang", "authors": "Zhisheng Wang, Fangxuan Sun, Jun Lin, Zhongfeng Wang and Bo Yuan", "title": "SGAD: Soft-Guided Adaptively-Dropped Neural Network", "comments": "9 pages, 4 figures; the first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been proven to have many redundancies.\nHence, many efforts have been made to compress DNNs. However, the existing\nmodel compression methods treat all the input samples equally while ignoring\nthe fact that the difficulties of various input samples being correctly\nclassified are different. To address this problem, DNNs with adaptive dropping\nmechanism are well explored in this work. To inform the DNNs how difficult the\ninput samples can be classified, a guideline that contains the information of\ninput samples is introduced to improve the performance. Based on the developed\nguideline and adaptive dropping mechanism, an innovative soft-guided\nadaptively-dropped (SGAD) neural network is proposed in this paper. Compared\nwith the 32 layers residual neural networks, the presented SGAD can reduce the\nFLOPs by 77% with less than 1% drop in accuracy on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 02:23:10 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Wang", "Zhisheng", ""], ["Sun", "Fangxuan", ""], ["Lin", "Jun", ""], ["Wang", "Zhongfeng", ""], ["Yuan", "Bo", ""]]}, {"id": "1807.01442", "submitter": "Aditya Grover", "authors": "Manik Dhar, Aditya Grover, Stefano Ermon", "title": "Modeling Sparse Deviations for Compressed Sensing using Generative\n  Models", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing, a small number of linear measurements can be used to\nreconstruct an unknown signal. Existing approaches leverage assumptions on the\nstructure of these signals, such as sparsity or the availability of a\ngenerative model. A domain-specific generative model can provide a stronger\nprior and thus allow for recovery with far fewer measurements. However, unlike\nsparsity-based approaches, existing methods based on generative models\nguarantee exact recovery only over their support, which is typically only a\nsmall subset of the space on which the signals are defined. We propose\nSparse-Gen, a framework that allows for sparse deviations from the support set,\nthereby achieving the best of both worlds by using a domain specific prior and\nallowing reconstruction over the full space of signals. Theoretically, our\nframework provides a new class of signals that can be acquired using compressed\nsensing, reducing classic sparse vector recovery to a special case and avoiding\nthe restrictive support due to a generative model prior. Empirically, we\nobserve consistent improvements in reconstruction accuracy over competing\napproaches, especially in the more practical setting of transfer compressed\nsensing where a generative model for a data-rich, source domain aids sensing on\na data-scarce, target domain.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 03:57:21 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 21:30:28 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Dhar", "Manik", ""], ["Grover", "Aditya", ""], ["Ermon", "Stefano", ""]]}, {"id": "1807.01473", "submitter": "Lu Wang", "authors": "Lu Wang, Wei Zhang, Xiaofeng He, Hongyuan Zha", "title": "Supervised Reinforcement Learning with Recurrent Neural Network for\n  Dynamic Treatment Recommendation", "comments": "10 pages, 11 figures. To appear in 2018 ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining conference. Some typos are revise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic treatment recommendation systems based on large-scale electronic\nhealth records (EHRs) become a key to successfully improve practical clinical\noutcomes. Prior relevant studies recommend treatments either use supervised\nlearning (e.g. matching the indicator signal which denotes doctor\nprescriptions), or reinforcement learning (e.g. maximizing evaluation signal\nwhich indicates cumulative reward from survival rates). However, none of these\nstudies have considered to combine the benefits of supervised learning and\nreinforcement learning. In this paper, we propose Supervised Reinforcement\nLearning with Recurrent Neural Network (SRL-RNN), which fuses them into a\nsynergistic learning framework. Specifically, SRL-RNN applies an off-policy\nactor-critic framework to handle complex relations among multiple medications,\ndiseases and individual characteristics. The \"actor\" in the framework is\nadjusted by both the indicator signal and evaluation signal to ensure effective\nprescription and low mortality. RNN is further utilized to solve the\nPartially-Observed Markov Decision Process (POMDP) problem due to the lack of\nfully observed states in real world applications. Experiments on the publicly\nreal-world dataset, i.e., MIMIC-3, illustrate that our model can reduce the\nestimated mortality, while providing promising accuracy in matching doctors'\nprescriptions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 07:54:32 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 12:58:17 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wang", "Lu", ""], ["Zhang", "Wei", ""], ["He", "Xiaofeng", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1807.01486", "submitter": "Gergo Bohner", "authors": "Gergo Bohner and Maneesh Sahani", "title": "Empirical fixed point bifurcation analysis", "comments": "Submitted to ICML2018 on 9 February 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a common experimental setting, the behaviour of a noisy dynamical system\nis monitored in response to manipulations of one or more control parameters.\nHere, we introduce a structured model to describe parametric changes in\nqualitative system behaviour via stochastic bifurcation analysis. In\nparticular, we describe an extension of Gaussian Process models of transition\nmaps, in which the learned map is directly parametrized by its fixed points and\nassociated local linearisations. We show that the system recovers the behaviour\nof a well-studied one dimensional system from little data, then learn the\nbehaviour of a more realistic two dimensional process of mutually inhibiting\nneural populations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 08:51:12 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Bohner", "Gergo", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1807.01488", "submitter": "Julian Zimmert", "authors": "Julian Zimmert, Yevgeny Seldin", "title": "Factored Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the factored bandits model, which is a framework for learning\nwith limited (bandit) feedback, where actions can be decomposed into a\nCartesian product of atomic actions. Factored bandits incorporate rank-1\nbandits as a special case, but significantly relax the assumptions on the form\nof the reward function. We provide an anytime algorithm for stochastic factored\nbandits and up to constants matching upper and lower regret bounds for the\nproblem. Furthermore, we show that with a slight modification the proposed\nalgorithm can be applied to utility based dueling bandits. We obtain an\nimprovement in the additive terms of the regret bound compared to state of the\nart algorithms (the additive terms are dominating up to time horizons which are\nexponential in the number of arms).\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 09:07:10 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 10:53:49 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zimmert", "Julian", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1807.01514", "submitter": "Matteo Ruffini MR", "authors": "Laura Avi\\~n\\'o, Matteo Ruffini, Ricard Gavald\\`a", "title": "Generating Synthetic but Plausible Healthcare Record Datasets", "comments": "MLMH 2018 : 2018 KDD workshop on Machine Learning for Medicine and\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating datasets that \"look like\" given real ones is an interesting tasks\nfor healthcare applications of ML and many other fields of science and\nengineering. In this paper we propose a new method of general application to\nbinary datasets based on a method for learning the parameters of a latent\nvariable moment that we have previously used for clustering patient datasets.\nWe compare our method with a recent proposal (MedGan) based on generative\nadversarial methods and find that the synthetic datasets we generate are\nglobally more realistic in at least two senses: real and synthetic instances\nare harder to tell apart by Random Forests, and the MMD statistic. The most\nlikely explanation is that our method does not suffer from the \"mode collapse\"\nwhich is an admitted problem of GANs. Additionally, the generative models we\ngenerate are easy to interpret, unlike the rather obscure GANs. Our experiments\nare performed on two patient datasets containing ICD-9 diagnostic codes: the\npublicly available MIMIC-III dataset and a dataset containing admissions for\ncongestive heart failure during 7 years at Hospital de Sant Pau in Barcelona.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 10:55:38 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Avi\u00f1\u00f3", "Laura", ""], ["Ruffini", "Matteo", ""], ["Gavald\u00e0", "Ricard", ""]]}, {"id": "1807.01521", "submitter": "Adrien Laversanne-Finot", "authors": "Adrien Laversanne-Finot, Alexandre P\\'er\\'e and Pierre-Yves Oudeyer", "title": "Curiosity Driven Exploration of Learned Disentangled Goal Spaces", "comments": "The code used in the experiments is available at\n  https://github.com/flowersteam/Curiosity_Driven_Goal_Exploration", "journal-ref": "Proceedings of The 2nd Conference on Robot Learning, PMLR\n  87:487-504, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsically motivated goal exploration processes enable agents to\nautonomously sample goals to explore efficiently complex environments with\nhigh-dimensional continuous actions. They have been applied successfully to\nreal world robots to discover repertoires of policies producing a wide\ndiversity of effects. Often these algorithms relied on engineered goal spaces\nbut it was recently shown that one can use deep representation learning\nalgorithms to learn an adequate goal space in simple environments. However, in\nthe case of more complex environments containing multiple objects or\ndistractors, an efficient exploration requires that the structure of the goal\nspace reflects the one of the environment. In this paper we show that using a\ndisentangled goal space leads to better exploration performances than an\nentangled goal space. We further show that when the representation is\ndisentangled, one can leverage it by sampling goals that maximize learning\nprogress in a modular manner. Finally, we show that the measure of learning\nprogress, used to drive curiosity-driven exploration, can be used\nsimultaneously to discover abstract independently controllable features of the\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 11:23:57 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 16:33:56 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 16:36:39 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Laversanne-Finot", "Adrien", ""], ["P\u00e9r\u00e9", "Alexandre", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1807.01603", "submitter": "Javier Ferrer", "authors": "Javier Ferrer and Enrique Alba", "title": "BIN-CT: Urban Waste Collection based in Predicting the Container Fill\n  Level", "comments": "11 pages, double column, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.biosystems.2019.04.006", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast demographic growth, together with the concentration of the\npopulation in cities and the increasing amount of daily waste, are factors that\npush to the limit the ability of waste assimilation by Nature. Therefore, we\nneed technological means to make an optimal management of the waste collection\nprocess, which represents 70% of the operational cost in waste treatment. In\nthis article, we present a free intelligent software system, based on\ncomputational learning algorithms, which plans the best routes for waste\ncollection supported by past (historical) and future (predictions) data.\n  The objective of the system is the cost reduction of the waste collection\nservice by means of the minimization in distance traveled by any truck to\ncollect a container, hence the fuel consumption. At the same time the quality\nof service to the citizen is increased avoiding the annoying overflows of\ncontainers thanks to the accurate fill level predictions performed by BIN-CT.\nIn this article we show the features of our software system, illustrating it\noperation with a real case study of a Spanish city. We conclude that the use of\nBIN-CT avoids unnecessary visits to containers, reduces the distance traveled\nto collect a container and therefore we obtain a reduction of total costs and\nharmful emissions thrown to the atmosphere.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:50:03 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 08:55:16 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Ferrer", "Javier", ""], ["Alba", "Enrique", ""]]}, {"id": "1807.01604", "submitter": "Florian Wenzel", "authors": "Alexander Buchholz, Florian Wenzel, Stephan Mandt", "title": "Quasi-Monte Carlo Variational Inference", "comments": null, "journal-ref": "Published in the proceedings of the 35th International Conference\n  on Machine Learning (ICML 2018)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems involve Monte Carlo gradient estimators. As a\nprominent example, we focus on Monte Carlo variational inference (MCVI) in this\npaper. The performance of MCVI crucially depends on the variance of its\nstochastic gradients. We propose variance reduction by means of Quasi-Monte\nCarlo (QMC) sampling. QMC replaces N i.i.d. samples from a uniform probability\ndistribution by a deterministic sequence of samples of length N. This sequence\ncovers the underlying random variable space more evenly than i.i.d. draws,\nreducing the variance of the gradient estimator. With our novel approach, both\nthe score function and the reparameterization gradient estimators lead to much\nfaster convergence. We also propose a new algorithm for Monte Carlo objectives,\nwhere we operate with a constant learning rate and increase the number of QMC\nsamples per iteration. We prove that this way, our algorithm can converge\nasymptotically at a faster rate than SGD. We furthermore provide theoretical\nguarantees on QMC for Monte Carlo objectives that go beyond MCVI, and support\nour findings by several experiments on large-scale data sets from various\ndomains.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 14:14:30 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Buchholz", "Alexander", ""], ["Wenzel", "Florian", ""], ["Mandt", "Stephan", ""]]}, {"id": "1807.01613", "submitter": "Marta Garnelo", "authors": "Marta Garnelo, Dan Rosenbaum, Chris J. Maddison, Tiago Ramalho, David\n  Saxton, Murray Shanahan, Yee Whye Teh, Danilo J. Rezende, S. M. Ali Eslami", "title": "Conditional Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks excel at function approximation, yet they are typically\ntrained from scratch for each new function. On the other hand, Bayesian\nmethods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly\ninfer the shape of a new function at test time. Yet GPs are computationally\nexpensive, and it can be hard to design appropriate priors. In this paper we\npropose a family of neural models, Conditional Neural Processes (CNPs), that\ncombine the benefits of both. CNPs are inspired by the flexibility of\nstochastic processes such as GPs, but are structured as neural networks and\ntrained via gradient descent. CNPs make accurate predictions after observing\nonly a handful of training data points, yet scale to complex functions and\nlarge datasets. We demonstrate the performance and versatility of the approach\non a range of canonical machine learning tasks, including regression,\nclassification and image completion.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 14:36:15 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Garnelo", "Marta", ""], ["Rosenbaum", "Dan", ""], ["Maddison", "Chris J.", ""], ["Ramalho", "Tiago", ""], ["Saxton", "David", ""], ["Shanahan", "Murray", ""], ["Teh", "Yee Whye", ""], ["Rezende", "Danilo J.", ""], ["Eslami", "S. M. Ali", ""]]}, {"id": "1807.01619", "submitter": "Telma Pereira", "authors": "Telma Pereira, Sandra Cardoso, Dina Silva, Manuela Guerreiro,\n  Alexandre de Mendon\\c{c}a, Sara C. Madeira", "title": "Ensemble learning with Conformal Predictors: Targeting credible\n  predictions of conversion from Mild Cognitive Impairment to Alzheimer's\n  Disease", "comments": "4 pages, 1 figure, accepted for presentation at the KDD Workshop on\n  Machine Learning for Medicine and Healthcare, London, UK, August 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning classifiers give predictions for new examples\naccurately, yet without indicating how trustworthy predictions are. In the\nmedical domain, this hampers their integration in decision support systems,\nwhich could be useful in the clinical practice. We use a supervised learning\napproach that combines Ensemble learning with Conformal Predictors to predict\nconversion from Mild Cognitive Impairment to Alzheimer's Disease. Our goal is\nto enhance the classification performance (Ensemble learning) and complement\neach prediction with a measure of credibility (Conformal Predictors). Our\nresults showed the superiority of the proposed approach over a similar ensemble\nframework with standard classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 14:43:57 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 14:58:54 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Pereira", "Telma", ""], ["Cardoso", "Sandra", ""], ["Silva", "Dina", ""], ["Guerreiro", "Manuela", ""], ["de Mendon\u00e7a", "Alexandre", ""], ["Madeira", "Sara C.", ""]]}, {"id": "1807.01622", "submitter": "Marta Garnelo", "authors": "Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J.\n  Rezende, S.M. Ali Eslami, Yee Whye Teh", "title": "Neural Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural network (NN) is a parameterised function that can be tuned via\ngradient descent to approximate a labelled collection of data with high\nprecision. A Gaussian process (GP), on the other hand, is a probabilistic model\nthat defines a distribution over possible functions, and is updated in light of\ndata via the rules of probabilistic inference. GPs are probabilistic,\ndata-efficient and flexible, however they are also computationally intensive\nand thus limited in their applicability. We introduce a class of neural latent\nvariable models which we call Neural Processes (NPs), combining the best of\nboth worlds. Like GPs, NPs define distributions over functions, are capable of\nrapid adaptation to new observations, and can estimate the uncertainty in their\npredictions. Like NNs, NPs are computationally efficient during training and\nevaluation but also learn to adapt their priors to data. We demonstrate the\nperformance of NPs on a range of learning tasks, including regression and\noptimisation, and compare and contrast with related models in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 14:49:46 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Garnelo", "Marta", ""], ["Schwarz", "Jonathan", ""], ["Rosenbaum", "Dan", ""], ["Viola", "Fabio", ""], ["Rezende", "Danilo J.", ""], ["Eslami", "S. M. Ali", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1807.01647", "submitter": "Borja Balle", "authors": "Borja Balle and Gilles Barthe and Marco Gaboardi", "title": "Privacy Amplification by Subsampling: Tight Analyses via Couplings and\n  Divergences", "comments": "To appear in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy comes equipped with multiple analytical tools for the\ndesign of private data analyses. One important tool is the so-called \"privacy\namplification by subsampling\" principle, which ensures that a differentially\nprivate mechanism run on a random subsample of a population provides higher\nprivacy guarantees than when run on the entire population. Several instances of\nthis principle have been studied for different random subsampling methods, each\nwith an ad-hoc analysis. In this paper we present a general method that\nrecovers and improves prior analyses, yields lower bounds and derives new\ninstances of privacy amplification by subsampling. Our method leverages a\ncharacterization of differential privacy as a divergence which emerged in the\nprogram verification community. Furthermore, it introduces new tools, including\nadvanced joint convexity and privacy profiles, which might be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 15:49:20 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 10:38:30 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Balle", "Borja", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""]]}, {"id": "1807.01659", "submitter": "Guang-Yuan Hao", "authors": "Guang-Yuan Hao, Hong-Xing Yu, Wei-Shi Zheng", "title": "MIXGAN: Learning Concepts from Different Domains for Mixture Generation", "comments": "Accepted by IJCAI-ECAI 2018, the 27th International Joint Conference\n  on Artificial Intelligence and the 23rd European Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an interesting attempt on mixture generation:\nabsorbing different image concepts (e.g., content and style) from different\ndomains and thus generating a new domain with learned concepts. In particular,\nwe propose a mixture generative adversarial network (MIXGAN). MIXGAN learns\nconcepts of content and style from two domains respectively, and thus can join\nthem for mixture generation in a new domain, i.e., generating images with\ncontent from one domain and style from another. MIXGAN overcomes the limitation\nof current GAN-based models which either generate new images in the same domain\nas they observed in training stage, or require off-the-shelf content templates\nfor transferring or translation. Extensive experimental results demonstrate the\neffectiveness of MIXGAN as compared to related state-of-the-art GAN-based\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:20:47 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Hao", "Guang-Yuan", ""], ["Yu", "Hong-Xing", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1807.01670", "submitter": "Karl Moritz Hermann", "authors": "Tiago Ramalho, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Frederic Besse, S. M. Ali\n  Eslami, G\\'abor Melis, Fabio Viola, Phil Blunsom, Karl Moritz Hermann", "title": "Encoding Spatial Relations from Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing has made significant inroads into learning the\nsemantics of words through distributional approaches, however representations\nlearnt via these methods fail to capture certain kinds of information implicit\nin the real world. In particular, spatial relations are encoded in a way that\nis inconsistent with human spatial reasoning and lacking invariance to\nviewpoint changes. We present a system capable of capturing the semantics of\nspatial relations such as behind, left of, etc from natural language. Our key\ncontributions are a novel multi-modal objective based on generating images of\nscenes from their textual descriptions, and a new dataset on which to train it.\nWe demonstrate that internal representations are robust to meaning preserving\ntransformations of descriptions (paraphrase invariance), while viewpoint\ninvariance is an emergent property of the system.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:38:49 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 10:03:23 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ramalho", "Tiago", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Besse", "Frederic", ""], ["Eslami", "S. M. Ali", ""], ["Melis", "G\u00e1bor", ""], ["Viola", "Fabio", ""], ["Blunsom", "Phil", ""], ["Hermann", "Karl Moritz", ""]]}, {"id": "1807.01672", "submitter": "Torbjorn Dahl", "authors": "Alexandre Laterre and Yunguan Fu and Mohamed Khalil Jabri and\n  Alain-Sam Cohen and David Kas and Karl Hajjar and Torbjorn S. Dahl and Amine\n  Kerkeni and Karim Beguir", "title": "Ranked Reward: Enabling Self-Play Reinforcement Learning for\n  Combinatorial Optimization", "comments": null, "journal-ref": "Presented at the Thirty-second Conference on Neural Information\n  Processing Systems (NeurIPS 2018), Deep Reinforcement Learning Workshop,\n  Montreal, Canada, December 3-8, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial self-play in two-player games has delivered impressive results\nwhen used with reinforcement learning algorithms that combine deep neural\nnetworks and tree search. Algorithms like AlphaZero and Expert Iteration learn\ntabula-rasa, producing highly informative training data on the fly. However,\nthe self-play training strategy is not directly applicable to single-player\ngames. Recently, several practically important combinatorial optimisation\nproblems, such as the travelling salesman problem and the bin packing problem,\nhave been reformulated as reinforcement learning problems, increasing the\nimportance of enabling the benefits of self-play beyond two-player games. We\npresent the Ranked Reward (R2) algorithm which accomplishes this by ranking the\nrewards obtained by a single agent over multiple games to create a relative\nperformance metric. Results from applying the R2 algorithm to instances of a\ntwo-dimensional and three-dimensional bin packing problems show that it\noutperforms generic Monte Carlo tree search, heuristic algorithms and integer\nprogramming solvers. We also present an analysis of the ranked reward\nmechanism, in particular, the effects of problem instances with varying\ndifficulty and different ranking thresholds.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:40:53 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 17:17:07 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 23:32:05 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Laterre", "Alexandre", ""], ["Fu", "Yunguan", ""], ["Jabri", "Mohamed Khalil", ""], ["Cohen", "Alain-Sam", ""], ["Kas", "David", ""], ["Hajjar", "Karl", ""], ["Dahl", "Torbjorn S.", ""], ["Kerkeni", "Amine", ""], ["Beguir", "Karim", ""]]}, {"id": "1807.01675", "submitter": "Jacob Buckman", "authors": "Jacob Buckman, Danijar Hafner, George Tucker, Eugene Brevdo, Honglak\n  Lee", "title": "Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value\n  Expansion", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2019 (pp.\n  8224-8234)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating model-free and model-based approaches in reinforcement learning\nhas the potential to achieve the high performance of model-free algorithms with\nlow sample complexity. However, this is difficult because an imperfect dynamics\nmodel can degrade the performance of the learning algorithm, and in\nsufficiently complex environments, the dynamics model will almost always be\nimperfect. As a result, a key challenge is to combine model-based approaches\nwith model-free learning in such a way that errors in the model do not degrade\nperformance. We propose stochastic ensemble value expansion (STEVE), a novel\nmodel-based technique that addresses this issue. By dynamically interpolating\nbetween model rollouts of various horizon lengths for each individual example,\nSTEVE ensures that the model is only utilized when doing so does not introduce\nsignificant errors. Our approach outperforms model-free baselines on\nchallenging continuous control benchmarks with an order-of-magnitude increase\nin sample efficiency, and in contrast to previous model-based approaches,\nperformance does not degrade in complex environments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:51:56 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 16:39:35 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Buckman", "Jacob", ""], ["Hafner", "Danijar", ""], ["Tucker", "George", ""], ["Brevdo", "Eugene", ""], ["Lee", "Honglak", ""]]}, {"id": "1807.01695", "submitter": "Junchi Li", "authors": "Cong Fang, Chris Junchi Li, Zhouchen Lin, Tong Zhang", "title": "SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path\n  Integrated Differential Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new technique named \\textit{Stochastic\nPath-Integrated Differential EstimatoR} (SPIDER), which can be used to track\nmany deterministic quantities of interest with significantly reduced\ncomputational cost. We apply SPIDER to two tasks, namely the stochastic\nfirst-order and zeroth-order methods. For stochastic first-order method,\ncombining SPIDER with normalized gradient descent, we propose two new\nalgorithms, namely SPIDER-SFO and SPIDER-SFO\\textsuperscript{+}, that solve\nnon-convex stochastic optimization problems using stochastic gradients only. We\nprovide sharp error-bound results on their convergence rates. In special, we\nprove that the SPIDER-SFO and SPIDER-SFO\\textsuperscript{+} algorithms achieve\na record-breaking gradient computation cost of $\\mathcal{O}\\left( \\min( n^{1/2}\n\\epsilon^{-2}, \\epsilon^{-3} ) \\right)$ for finding an $\\epsilon$-approximate\nfirst-order and $\\tilde{\\mathcal{O}}\\left( \\min( n^{1/2}\n\\epsilon^{-2}+\\epsilon^{-2.5}, \\epsilon^{-3} ) \\right)$ for finding an\n$(\\epsilon, \\mathcal{O}(\\epsilon^{0.5}))$-approximate second-order stationary\npoint, respectively. In addition, we prove that SPIDER-SFO nearly matches the\nalgorithmic lower bound for finding approximate first-order stationary points\nunder the gradient Lipschitz assumption in the finite-sum setting. For\nstochastic zeroth-order method, we prove a cost of $\\mathcal{O}( d \\min(\nn^{1/2} \\epsilon^{-2}, \\epsilon^{-3}) )$ which outperforms all existing\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 17:44:39 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 14:31:04 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Fang", "Cong", ""], ["Li", "Chris Junchi", ""], ["Lin", "Zhouchen", ""], ["Zhang", "Tong", ""]]}, {"id": "1807.01697", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Thomas G. Dietterich", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Surface\n  Variations", "comments": "Superseded by _Benchmarking Neural Network Robustness to Common\n  Corruptions and Perturbations_ arXiv:1903.12261", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish rigorous benchmarks for image classifier\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\ncorruption robustness topic, while showing which classifiers are preferable in\nsafety-critical applications. Unlike recent robustness research, this benchmark\nevaluates performance on commonplace corruptions not worst-case adversarial\ncorruptions. We find that there are negligible changes in relative corruption\nrobustness from AlexNet to ResNet classifiers, and we discover ways to enhance\ncorruption robustness. Then we propose a new dataset called Icons-50 which\nopens research on a new kind of robustness, surface variation robustness. With\nthis dataset we evaluate the frailty of classifiers on new styles of known\nobjects and unexpected instances of known classes. We also demonstrate two\nmethods that improve surface variation robustness. Together our benchmarks may\naid future work toward networks that learn fundamental class structure and also\nrobustly generalize.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 17:57:11 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 18:57:31 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 20:30:27 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 21:36:39 GMT"}, {"version": "v5", "created": "Sat, 27 Apr 2019 18:19:39 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Hendrycks", "Dan", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1807.01702", "submitter": "Jung Ho Ahn", "authors": "Wonkyung Jung and Daejin Jung and and Byeongho Kim and Sunjung Lee and\n  Wonjong Rhee and Jung Ho Ahn", "title": "Restructuring Batch Normalization to Accelerate CNN Training", "comments": "13 pages, 8 figures, to appear in SysML 2019, added ResNet-50 results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) has become a core design block of modern\nConvolutional Neural Networks (CNNs). A typical modern CNN has a large number\nof BN layers in its lean and deep architecture. BN requires mean and variance\ncalculations over each mini-batch during training. Therefore, the existing\nmemory access reduction techniques, such as fusing multiple CONV layers, are\nnot effective for accelerating BN due to their inability to optimize mini-batch\nrelated calculations during training. To address this increasingly important\nproblem, we propose to restructure BN layers by first splitting a BN layer into\ntwo sub-layers (fission) and then combining the first sub-layer with its\npreceding CONV layer and the second sub-layer with the following activation and\nCONV layers (fusion). The proposed solution can significantly reduce\nmain-memory accesses while training the latest CNN models, and the experiments\non a chip multiprocessor show that the proposed BN restructuring can improve\nthe performance of DenseNet-121 by 25.7%.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 02:00:19 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 08:27:20 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Jung", "Wonkyung", ""], ["Jung", "Daejin", ""], ["Kim", "and Byeongho", ""], ["Lee", "Sunjung", ""], ["Rhee", "Wonjong", ""], ["Ahn", "Jung Ho", ""]]}, {"id": "1807.01705", "submitter": "Pankaj Malhotra", "authors": "Priyanka Gupta, Pankaj Malhotra, Lovekesh Vig, Gautam Shroff", "title": "Transfer Learning for Clinical Time Series Analysis using Recurrent\n  Neural Networks", "comments": "Accepted at Machine Learning for Medicine and Healthcare Workshop at\n  ACM KDD 2018 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown promising results for various clinical\nprediction tasks such as diagnosis, mortality prediction, predicting duration\nof stay in hospital, etc. However, training deep networks -- such as those\nbased on Recurrent Neural Networks (RNNs) -- requires large labeled data, high\ncomputational resources, and significant hyperparameter tuning effort. In this\nwork, we investigate as to what extent can transfer learning address these\nissues when using deep RNNs to model multivariate clinical time series. We\nconsider transferring the knowledge captured in an RNN trained on several\nsource tasks simultaneously using a large labeled dataset to build the model\nfor a target task with limited labeled data. An RNN pre-trained on several\ntasks provides generic features, which are then used to build simpler linear\nmodels for new target tasks without training task-specific RNNs. For\nevaluation, we train a deep RNN to identify several patient phenotypes on time\nseries from MIMIC-III database, and then use the features extracted using that\nRNN to build classifiers for identifying previously unseen phenotypes, and also\nfor a seemingly unrelated task of in-hospital mortality. We demonstrate that\n(i) models trained on features extracted using pre-trained RNN outperform or,\nin the worst case, perform as well as task-specific RNNs; (ii) the models using\nfeatures from pre-trained models are more robust to the size of labeled data\nthan task-specific RNNs; and (iii) features extracted using pre-trained RNN are\ngeneric enough and perform better than typical statistical hand-crafted\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 12:42:48 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Gupta", "Priyanka", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1807.01736", "submitter": "Lucas Lehnert", "authors": "Lucas Lehnert, Michael L. Littman", "title": "Transfer with Model Features in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in Reinforcement Learning is which representation an agent can\nlearn to efficiently reuse knowledge between different tasks. Recently the\nSuccessor Representation was shown to have empirical benefits for transferring\nknowledge between tasks with shared transition dynamics. This paper presents\nModel Features: a feature representation that clusters behaviourally equivalent\nstates and that is equivalent to a Model-Reduction. Further, we present a\nSuccessor Feature model which shows that learning Successor Features is\nequivalent to learning a Model-Reduction. A novel optimization objective is\ndeveloped and we provide bounds showing that minimizing this objective results\nin an increasingly improved approximation of a Model-Reduction. Further, we\nprovide transfer experiments on randomly generated MDPs which vary in their\ntransition and reward functions but approximately preserve behavioural\nequivalence between states. These results demonstrate that Model Features are\nsuitable for transfer between tasks with varying transition and reward\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 18:41:27 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Lehnert", "Lucas", ""], ["Littman", "Michael L.", ""]]}, {"id": "1807.01739", "submitter": "Mihailo Jovanovic", "authors": "Armin Zare, Hesameddin Mohammadi, Neil K. Dhingra, Tryphon T.\n  Georgiou, Mihailo R. Jovanovi\\'c", "title": "Proximal algorithms for large-scale statistical modeling and\n  sensor/actuator selection", "comments": "To appear in IEEE Trans. Automat. Control", "journal-ref": null, "doi": "10.1109/TAC.2019.2948268", "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several problems in modeling and control of stochastically-driven dynamical\nsystems can be cast as regularized semi-definite programs. We examine two such\nrepresentative problems and show that they can be formulated in a similar\nmanner. The first, in statistical modeling, seeks to reconcile observed\nstatistics by suitably and minimally perturbing prior dynamics. The second\nseeks to optimally select a subset of available sensors and actuators for\ncontrol purposes. To address modeling and control of large-scale systems we\ndevelop a unified algorithmic framework using proximal methods. Our customized\nalgorithms exploit problem structure and allow handling statistical modeling,\nas well as sensor and actuator selection, for substantially larger scales than\nwhat is amenable to current general-purpose solvers. We establish linear\nconvergence of the proximal gradient algorithm, draw contrast between the\nproposed proximal algorithms and alternating direction method of multipliers,\nand provide examples that illustrate the merits and effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 18:47:03 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 17:38:06 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 07:45:19 GMT"}, {"version": "v4", "created": "Thu, 26 Dec 2019 18:04:42 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zare", "Armin", ""], ["Mohammadi", "Hesameddin", ""], ["Dhingra", "Neil K.", ""], ["Georgiou", "Tryphon T.", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1807.01750", "submitter": "Chang Liu", "authors": "Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, Jun Zhu, Lawrence\n  Carin", "title": "Understanding and Accelerating Particle-Based Variational Inference", "comments": "A typo for citation corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle-based variational inference methods (ParVIs) have gained attention\nin the Bayesian inference literature, for their capacity to yield flexible and\naccurate approximations. We explore ParVIs from the perspective of Wasserstein\ngradient flows, and make both theoretical and practical contributions. We unify\nvarious finite-particle approximations that existing ParVIs use, and recognize\nthat the approximation is essentially a compulsory smoothing treatment, in\neither of two equivalent forms. This novel understanding reveals the\nassumptions and relations of existing ParVIs, and also inspires new ParVIs. We\npropose an acceleration framework and a principled bandwidth-selection method\nfor general ParVIs; these are based on the developed theory and leverage the\ngeometry of the Wasserstein space. Experimental results show the improved\nconvergence by the acceleration framework and enhanced sample accuracy by the\nbandwidth-selection method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 19:17:36 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 05:47:18 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 09:50:12 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 16:23:33 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Liu", "Chang", ""], ["Zhuo", "Jingwei", ""], ["Cheng", "Pengyu", ""], ["Zhang", "Ruiyi", ""], ["Zhu", "Jun", ""], ["Carin", "Lawrence", ""]]}, {"id": "1807.01759", "submitter": "Kuang Gong", "authors": "Kuang Gong, Kyungsang Kim, Jianan Cui, Ning Guo, Ciprian Catana, Jinyi\n  Qi, Quanzheng Li", "title": "Learning Personalized Representation for Inverse Problems in Medical\n  Imaging Using Deep Neural Network", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks have been widely and successfully applied in\ncomputer vision tasks and attracted growing interests in medical imaging. One\nbarrier for the application of deep neural networks to medical imaging is the\nneed of large amounts of prior training pairs, which is not always feasible in\nclinical practice. In this work we propose a personalized representation\nlearning framework where no prior training pairs are needed, but only the\npatient's own prior images. The representation is expressed using a deep neural\nnetwork with the patient's prior images as network input. We then applied this\nnovel image representation to inverse problems in medical imaging in which the\noriginal inverse problem was formulated as a constraint optimization problem\nand solved using the alternating direction method of multipliers (ADMM)\nalgorithm. Anatomically guided brain positron emission tomography (PET) image\nreconstruction and image denoising were employed as examples to demonstrate the\neffectiveness of the proposed framework. Quantification results based on\nsimulation and real datasets show that the proposed personalized representation\nframework outperform other widely adopted methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 20:00:00 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Gong", "Kuang", ""], ["Kim", "Kyungsang", ""], ["Cui", "Jianan", ""], ["Guo", "Ning", ""], ["Catana", "Ciprian", ""], ["Qi", "Jinyi", ""], ["Li", "Quanzheng", ""]]}, {"id": "1807.01771", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Katy Blumer, Rory Sayres, Ziad Obermeyer, Robert\n  Kleinberg, Sendhil Mullainathan, Jon Kleinberg", "title": "Direct Uncertainty Prediction for Medical Second Opinions", "comments": "Accepted for publication at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of disagreements amongst human experts is a ubiquitous one in both\nmachine learning and medicine. In medicine, this often corresponds to doctor\ndisagreements on a patient diagnosis. In this work, we show that machine\nlearning models can be trained to give uncertainty scores to data instances\nthat might result in high expert disagreements. In particular, they can\nidentify patient cases that would benefit most from a medical second opinion.\nOur central methodological finding is that Direct Uncertainty Prediction (DUP),\ntraining a model to predict an uncertainty score directly from the raw patient\nfeatures, works better than Uncertainty Via Classification, the two-step\nprocess of training a classifier and postprocessing the output distribution to\ngive an uncertainty score. We show this both with a theoretical result, and on\nextensive evaluations on a large scale medical imaging application.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 20:55:05 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 15:09:28 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 02:00:57 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 02:27:48 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Raghu", "Maithra", ""], ["Blumer", "Katy", ""], ["Sayres", "Rory", ""], ["Obermeyer", "Ziad", ""], ["Kleinberg", "Robert", ""], ["Mullainathan", "Sendhil", ""], ["Kleinberg", "Jon", ""]]}, {"id": "1807.01774", "submitter": "Stefan Falkner", "authors": "Stefan Falkner, Aaron Klein, Frank Hutter", "title": "BOHB: Robust and Efficient Hyperparameter Optimization at Scale", "comments": "published at ICML2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning methods are very sensitive to many hyperparameters, and,\ndue to the long training times of state-of-the-art models, vanilla Bayesian\nhyperparameter optimization is typically computationally infeasible. On the\nother hand, bandit-based configuration evaluation approaches based on random\nsearch lack guidance and do not converge to the best configurations as quickly.\nHere, we propose to combine the benefits of both Bayesian optimization and\nbandit-based methods, in order to achieve the best of both worlds: strong\nanytime performance and fast convergence to optimal configurations. We propose\na new practical state-of-the-art hyperparameter optimization method, which\nconsistently outperforms both Bayesian optimization and Hyperband on a wide\nrange of problem types, including high-dimensional toy functions, support\nvector machines, feed-forward neural networks, Bayesian neural networks, deep\nreinforcement learning, and convolutional neural networks. Our method is robust\nand versatile, while at the same time being conceptually simple and easy to\nimplement.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 20:59:35 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Falkner", "Stefan", ""], ["Klein", "Aaron", ""], ["Hutter", "Frank", ""]]}, {"id": "1807.01779", "submitter": "Daniele Della Latta", "authors": "Gianmarco Santini, Lorena M. Zumbo, Nicola Martini, Gabriele Valvano,\n  Andrea Leo, Andrea Ripoli, Francesco Avogliero, Dante Chiappino and Daniele\n  Della Latta", "title": "Synthetic contrast enhancement in cardiac CT with Deep Learning", "comments": "8 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Europe the 20% of the CT scans cover the thoracic region. The acquired\nimages contain information about the cardiovascular system that often remains\nlatent due to the lack of contrast in the cardiac area. On the other hand, the\ncontrast enhanced computed tomography (CECT) represents an imaging technique\nthat allows to easily assess the cardiac chambers volumes and the contrast\ndynamics. With this work we aim to face the problem of extraction and\npresentation of these latent information, using a deep learning approach with\nconvolutional neural networks. Starting from the extraction of relevant\nfeatures from the image without contrast medium, we try to re-map them on\nfeatures typical of CECT, to synthesize an image characterized by an\nattenuation in the cardiac chambers as if a virtually iodine contrast medium\nwas injected. The purposes are to guarantee an estimation of the left cardiac\nchambers volume and to perform an evaluation of the contrast dynamics. Our\napproach is based on a deconvolutional network trained on a set of 120 patients\nwho underwent both CT acquisitions in the same contrastographic arterial phase\nand the same cardiac phase. To ensure a reliable predicted CECT image, in terms\nof values and morphology, a custom loss function is defined by combining an\nerror function to find a pixel-wise correspondence, which takes into account\nthe similarity in term of Hounsfield units between the input and output images\nand by a cross-entropy computed on the binarized versions of the synthesized\nand of the real CECT image. The proposed method is finally tested on 20\nsubjects.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:26:14 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Santini", "Gianmarco", ""], ["Zumbo", "Lorena M.", ""], ["Martini", "Nicola", ""], ["Valvano", "Gabriele", ""], ["Leo", "Andrea", ""], ["Ripoli", "Andrea", ""], ["Avogliero", "Francesco", ""], ["Chiappino", "Dante", ""], ["Della Latta", "Daniele", ""]]}, {"id": "1807.01784", "submitter": "Mehdi Drissi", "authors": "Mehdi Drissi, Olivia Watkins, Aditya Khant, Vivaswat Ojha, Pedro\n  Sandoval, Rakia Segev, Eric Weiner, Robert Keller", "title": "Program Language Translation Using a Grammar-Driven Tree-to-Tree Model", "comments": "Accepted at the ICML workshop Neural Abstract Machines & Program\n  Induction v2. 4 pages excluding acknowledgements/references (6 pages total)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of translating between programming languages differs from the\nchallenge of translating natural languages in that programming languages are\ndesigned with a far more rigid set of structural and grammatical rules.\nPrevious work has used a tree-to-tree encoder/decoder model to take advantage\nof the inherent tree structure of programs during translation. Neural decoders,\nhowever, by default do not exploit known grammar rules of the target language.\nIn this paper, we describe a tree decoder that leverages knowledge of a\nlanguage's grammar rules to exclusively generate syntactically correct\nprograms. We find that this grammar-based tree-to-tree model outperforms the\nstate of the art tree-to-tree model in translating between two programming\nlanguages on a previously used synthetic task.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 21:19:00 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Drissi", "Mehdi", ""], ["Watkins", "Olivia", ""], ["Khant", "Aditya", ""], ["Ojha", "Vivaswat", ""], ["Sandoval", "Pedro", ""], ["Segev", "Rakia", ""], ["Weiner", "Eric", ""], ["Keller", "Robert", ""]]}, {"id": "1807.01798", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen, Evaggelia Tsiligianni, Robert Calderbank, Nikos\n  Deligiannis", "title": "Regularizing Autoencoder-Based Matrix Completion Models via Manifold\n  Learning", "comments": "5 pages, Eusipco 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are popular among neural-network-based matrix completion models\ndue to their ability to retrieve potential latent factors from the partially\nobserved matrices. Nevertheless, when training data is scarce their performance\nis significantly degraded due to overfitting. In this paper, we mit- igate\noverfitting with a data-dependent regularization technique that relies on the\nprinciples of multi-task learning. Specifically, we propose an\nautoencoder-based matrix completion model that performs prediction of the\nunknown matrix values as a main task, and manifold learning as an auxiliary\ntask. The latter acts as an inductive bias, leading to solutions that\ngeneralize better. The proposed model outperforms the existing\nautoencoder-based models designed for matrix completion, achieving high\nreconstruction accuracy in well-known datasets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 21:54:27 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Calderbank", "Robert", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1807.01808", "submitter": "Alkis Gotovos", "authors": "Alkis Gotovos, Hamed Hassani, Andreas Krause, and Stefanie Jegelka", "title": "Discrete Sampling using Semigradient-based Product Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of inference in discrete probabilistic models, that\nis, distributions over subsets of a finite ground set. These encompass a range\nof well-known models in machine learning, such as determinantal point processes\nand Ising models. Locally-moving Markov chain Monte Carlo algorithms, such as\nthe Gibbs sampler, are commonly used for inference in such models, but their\nconvergence is, at times, prohibitively slow. This is often caused by\nstate-space bottlenecks that greatly hinder the movement of such samplers. We\npropose a novel sampling strategy that uses a specific mixture of product\ndistributions to propose global moves and, thus, accelerate convergence.\nFurthermore, we show how to construct such a mixture using semigradient\ninformation. We illustrate the effectiveness of combining our sampler with\nexisting ones, both theoretically on an example model, as well as practically\non three models learned from real-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 23:12:09 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 10:58:44 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gotovos", "Alkis", ""], ["Hassani", "Hamed", ""], ["Krause", "Andreas", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1807.01827", "submitter": "Lulu Wang", "authors": "Lulu Wang, Huahui Liu, Guanhao Chen, Shaola Ren, Xiaonan Meng, Yi Hu", "title": "Learning Theory and Algorithms for Revenue Management in Sponsored\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online advertisement is the main source of revenue for Internet business.\nAdvertisers are typically ranked according to a score that takes into account\ntheir bids and potential click-through rates(eCTR). Generally, the likelihood\nthat a user clicks on an ad is often modeled by optimizing for the click\nthrough rates rather than the performance of the auction in which the click\nthrough rates will be used. This paper attempts to eliminate this\ndis-connection by proposing loss functions for click modeling that are based on\nfinal auction performance.In this paper, we address two feasible metrics (AUC^R\nand SAUC) to evaluate the on-line RPM (revenue per mille) directly rather than\nthe CTR. And then, we design an explicit ranking function by incorporating the\ncalibration fac-tor and price-squashed factor to maximize the revenue. Given\nthe power of deep networks, we also explore an implicit optimal ranking\nfunction with deep model. Lastly, various experiments with two real world\ndatasets are presented. In particular, our proposed methods perform better than\nthe state-of-the-art methods with regard to the revenue of the platform.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 02:01:41 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Wang", "Lulu", ""], ["Liu", "Huahui", ""], ["Chen", "Guanhao", ""], ["Ren", "Shaola", ""], ["Meng", "Xiaonan", ""], ["Hu", "Yi", ""]]}, {"id": "1807.01830", "submitter": "Kristopher De Asis", "authors": "Kristopher De Asis, Richard S. Sutton", "title": "Per-decision Multi-step Temporal Difference Learning with Control\n  Variates", "comments": null, "journal-ref": "(2018). In Conference on Uncertainty in Artificial Intelligence.\n  http://auai.org/uai2018/proceedings/papers/282.pdf", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step temporal difference (TD) learning is an important approach in\nreinforcement learning, as it unifies one-step TD learning with Monte Carlo\nmethods in a way where intermediate algorithms can outperform either extreme.\nThey address a bias-variance trade off between reliance on current estimates,\nwhich could be poor, and incorporating longer sampled reward sequences into the\nupdates. Especially in the off-policy setting, where the agent aims to learn\nabout a policy different from the one generating its behaviour, the variance in\nthe updates can cause learning to diverge as the number of sampled rewards used\nin the estimates increases. In this paper, we introduce per-decision control\nvariates for multi-step TD algorithms, and compare them to existing methods.\nOur results show that including the control variates can greatly improve\nperformance on both on and off-policy multi-step temporal difference learning\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 02:34:40 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["De Asis", "Kristopher", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1807.01846", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "Logistic Regression, Neural Networks and Dempster-Shafer Theory: a New\n  Perspective", "comments": null, "journal-ref": "Knowledge-Based Systems, Vol. 176, Pages 54-67, 2019", "doi": "10.1016/j.knosys.2019.03.030", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit logistic regression and its nonlinear extensions, including\nmultilayer feedforward neural networks, by showing that these classifiers can\nbe viewed as converting input or higher-level features into Dempster-Shafer\nmass functions and aggregating them by Dempster's rule of combination. The\nprobabilistic outputs of these classifiers are the normalized plausibilities\ncorresponding to the underlying combined mass function. This mass function is\nmore informative than the output probability distribution. In particular, it\nmakes it possible to distinguish between lack of evidence (when none of the\nfeatures provides discriminant information) from conflicting evidence (when\ndifferent features support different classes). This expressivity of mass\nfunctions allows us to gain insight into the role played by each input feature\nin logistic regression, and to interpret hidden unit outputs in multilayer\nneural networks. It also makes it possible to use alternative decision rules,\nsuch as interval dominance, which select a set of classes when the available\nevidence does not unambiguously point to a single class, thus trading reduced\nerror rate for higher imprecision.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 04:50:52 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 09:16:17 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 08:14:02 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "1807.01860", "submitter": "Tianwei Zhang", "authors": "Tianwei Zhang and Zecheng He and Ruby B. Lee", "title": "Privacy-preserving Machine Learning through Data Obfuscation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes a practice and commodity, numerous cloud-based\nservices and frameworks are provided to help customers develop and deploy\nmachine learning applications. While it is prevalent to outsource model\ntraining and serving tasks in the cloud, it is important to protect the privacy\nof sensitive samples in the training dataset and prevent information leakage to\nuntrusted third parties. Past work have shown that a malicious machine learning\nservice provider or end user can easily extract critical information about the\ntraining samples, from the model parameters or even just model outputs.\n  In this paper, we propose a novel and generic methodology to preserve the\nprivacy of training data in machine learning applications. Specifically we\nintroduce an obfuscate function and apply it to the training data before\nfeeding them to the model training task. This function adds random noise to\nexisting samples, or augments the dataset with new samples. By doing so\nsensitive information about the properties of individual samples, or\nstatistical properties of a group of samples, is hidden. Meanwhile the model\ntrained from the obfuscated dataset can still achieve high accuracy. With this\napproach, the customers can safely disclose the data or models to third-party\nproviders or end users without the need to worry about data privacy. Our\nexperiments show that this approach can effective defeat four existing types of\nmachine learning privacy attacks at negligible accuracy cost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 06:21:48 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 02:50:37 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Zhang", "Tianwei", ""], ["He", "Zecheng", ""], ["Lee", "Ruby B.", ""]]}, {"id": "1807.01868", "submitter": "TonTon Huang", "authors": "TonTon Hsien-De Huang", "title": "Hunting the Ethereum Smart Contract: Color-inspired Inspection of\n  Potential Attacks", "comments": "2018/07/04 Draft Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain and Cryptocurrencies are gaining unprecedented popularity and\nunderstanding. Meanwhile, Ethereum is gaining a significant popularity in the\nblockchain community, mainly due to the fact that it is designed in a way that\nenables developers to write smart contract and decentralized applications\n(Dapps). This new paradigm of applications opens the door to many possibilities\nand opportunities. However, the security of Ethereum smart contracts has not\nreceived much attention; several Ethereum smart contracts malfunctioning have\nrecently been reported. Unlike many previous works that have applied static and\ndynamic analyses to find bugs in smart contracts, we do not attempt to define\nand extract any features; instead we focus on reducing the expert's labor\ncosts. We first present a new in-depth analysis of potential attacks\nmethodology and then translate the bytecode of solidity into RGB color code.\nAfter that, we transform them to a fixed-sized encoded image. Finally, the\nencoded image is fed to convolutional neural network (CNN) for automatic\nfeature extraction and learning, detecting compiler bugs of Ethereum smart\ncontract.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 07:06:36 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Huang", "TonTon Hsien-De", ""]]}, {"id": "1807.01889", "submitter": "Septimia Sarbu", "authors": "Septimia S\\^arbu and Riccardo Volpi and Alexandra Pe\\c{s}te and Luigi\n  Malag\\`o", "title": "Learning in Variational Autoencoders with Kullback-Leibler and Renyi\n  Integral Bounds", "comments": "accepted at the ICML 2018 workshop on Theoretical Foundations and\n  Applications of Deep Generative Models, Stockholm, Sweden, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose two novel bounds for the log-likelihood based on\nKullback-Leibler and the R\\'{e}nyi divergences, which can be used for\nvariational inference and in particular for the training of Variational\nAutoEncoders. Our proposal is motivated by the difficulties encountered in\ntraining VAEs on continuous datasets with high contrast images, such as those\nwith handwritten digits and characters, where numerical issues often appear\nunless noise is added, either to the dataset during training or to the\ngenerative model given by the decoder. The new bounds we propose, which are\nobtained from the maximization of the likelihood of an interval for the\nobservations, allow numerically stable training procedures without the\nnecessity of adding any extra source of noise to the data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 08:10:14 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["S\u00e2rbu", "Septimia", ""], ["Volpi", "Riccardo", ""], ["Pe\u015fte", "Alexandra", ""], ["Malag\u00f2", "Luigi", ""]]}, {"id": "1807.01956", "submitter": "Markus M\\\"uller", "authors": "Markus M\\\"uller, Sebastian St\\\"uker, and Alex Waibel", "title": "Neural Language Codes for Multilingual Acoustic Models", "comments": "5 pages, 3 figures, accepted at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Speech Recognition is one of the most costly AI problems,\nbecause each language (7,000+) and even different accents require their own\nacoustic models to obtain best recognition performance. Even though they all\nuse the same phoneme symbols, each language and accent imposes its own coloring\nor \"twang\". Many adaptive approaches have been proposed, but they require\nfurther training, additional data and generally are inferior to monolingually\ntrained models. In this paper, we propose a different approach that uses a\nlarge multilingual model that is \\emph{modulated} by the codes generated by an\nancillary network that learns to code useful differences between the \"twangs\"\nor human language.\n  We use Meta-Pi networks to have one network (the language code net) gate the\nactivity of neurons in another (the acoustic model nets). Our results show that\nduring recognition multilingual Meta-Pi networks quickly adapt to the proper\nlanguage coloring without retraining or new data, and perform better than\nmonolingually trained networks. The model was evaluated by training acoustic\nmodeling nets and modulating language code nets jointly and optimize them for\nbest recognition performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:15:34 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["M\u00fcller", "Markus", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1807.01958", "submitter": "Demba Ba", "authors": "Demba Ba", "title": "Deeply-Sparse Signal rePresentations ($\\text{D}\\text{S}^2\\text{P}$)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work shows that a deep neural network with ReLU\nnonlinearities arises from a finite sequence of cascaded sparse coding models,\nthe outputs of which, except for the last element in the cascade, are sparse\nand unobservable. That is, intermediate outputs deep in the cascade are sparse,\nhence the title of this manuscript. We show here, using techniques from the\ndictionary learning literature that, if the measurement matrices in the\ncascaded sparse coding model (a) satisfy RIP and (b) all have sparse columns\nexcept for the last, they can be recovered with high probability. We propose\ntwo algorithms for this purpose: one that recovers the matrices in a forward\nsequence, and another that recovers them in a backward sequence. The method of\nchoice in deep learning to solve this problem is by training an auto-encoder.\nOur algorithms provide a sound alternative, with theoretical guarantees, as\nwell upper bounds on sample complexity. The theory shows that the learning\ncomplexity of the forward algorithm depends on the number of hidden units at\nthe deepest layer and the number of active neurons at that layer (sparsity). In\naddition, the theory relates the number of hidden units in successive layers,\nthus giving a practical prescription for designing deep ReLU neural networks.\nBecause it puts fewer restrictions on the architecture, the backward algorithm\nrequires more data. We demonstrate the deep dictionary learning algorithm via\nsimulations. Finally, we use a coupon-collection argument to conjecture a lower\nbound on sample complexity that gives some insight as to why deep networks\nrequire more data to train than shallow ones.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:20:02 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 14:47:13 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 16:18:54 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2019 15:06:02 GMT"}, {"version": "v5", "created": "Fri, 24 Apr 2020 17:57:30 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ba", "Demba", ""]]}, {"id": "1807.01960", "submitter": "Kyriakos Chatzidimitriou", "authors": "Georgios Papoudakis, Kyriakos C. Chatzidimitriou, Pericles A. Mitkas", "title": "Deep Reinforcement Learning for Doom using Unsupervised Auxiliary Tasks", "comments": "4 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in deep reinforcement learning have enabled the creation\nof agents for solving a large variety of games given a visual input. These\nmethods have been proven successful for 2D games, like the Atari games, or for\nsimple tasks, like navigating in mazes. It is still an open question, how to\naddress more complex environments, in which the reward is sparse and the state\nspace is huge. In this paper we propose a divide and conquer deep reinforcement\nlearning solution and we test our agent in the first person shooter (FPS) game\nof Doom. Our work is based on previous works in deep reinforcement learning and\nin Doom agents. We also present how our agent is able to perform better in\nunknown environments compared to a state of the art reinforcement learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:30:15 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Chatzidimitriou", "Kyriakos C.", ""], ["Mitkas", "Pericles A.", ""]]}, {"id": "1807.01961", "submitter": "Ondrej Bajgar", "authors": "Ondrej Bajgar, Rudolf Kadlec, Jan Kleindienst", "title": "A Boo(n) for Evaluating Architecture Performance", "comments": "ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML 2018). Volume 80 of the Proceedings of Machine Learning\n  Research (PMLR)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We point out important problems with the common practice of using the best\nsingle model performance for comparing deep learning architectures, and we\npropose a method that corrects these flaws. Each time a model is trained, one\ngets a different result due to random factors in the training process, which\ninclude random parameter initialization and random data shuffling. Reporting\nthe best single model performance does not appropriately address this\nstochasticity. We propose a normalized expected best-out-of-$n$ performance\n($\\text{Boo}_n$) as a way to correct these problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:33:31 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 11:14:20 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bajgar", "Ondrej", ""], ["Kadlec", "Rudolf", ""], ["Kleindienst", "Jan", ""]]}, {"id": "1807.01969", "submitter": "Jiri Hron", "authors": "Jiri Hron, Alexander G. de G. Matthews, Zoubin Ghahramani", "title": "Variational Bayesian dropout: pitfalls and fixes", "comments": "Extended version of the paper accepted to ICML 2018: more details in\n  the proofs, few minor modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout, a stochastic regularisation technique for training of neural\nnetworks, has recently been reinterpreted as a specific type of approximate\ninference algorithm for Bayesian neural networks. The main contribution of the\nreinterpretation is in providing a theoretical framework useful for analysing\nand extending the algorithm. We show that the proposed framework suffers from\nseveral issues; from undefined or pathological behaviour of the true posterior\nrelated to use of improper priors, to an ill-defined variational objective due\nto singularity of the approximating distribution relative to the true\nposterior. Our analysis of the improper log uniform prior used in variational\nGaussian dropout suggests the pathologies are generally irredeemable, and that\nthe algorithm still works only because the variational formulation annuls some\nof the pathologies. To address the singularity issue, we proffer Quasi-KL (QKL)\ndivergence, a new approximate inference objective for approximation of\nhigh-dimensional distributions. We show that motivations for variational\nBernoulli dropout based on discretisation and noise have QKL as a limit.\nProperties of QKL are studied both theoretically and on a simple practical\nexample which shows that the QKL-optimal approximation of a full rank Gaussian\nwith a degenerate one naturally leads to the Principal Component Analysis\nsolution.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:48:53 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Hron", "Jiri", ""], ["Matthews", "Alexander G. de G.", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1807.01970", "submitter": "Alexis Brenon", "authors": "Alexis Brenon and Fran\\c{c}ois Portet and Michel Vacher", "title": "Arcades: A deep model for adaptive decision making in voice controlled\n  smart-home", "comments": "27 pages, 15 figures, 5 tables, 4 algorithms. In Press, Accepted\n  Manuscript", "journal-ref": "Pervasive and Mobile Computing, Volume 49, September 2018, Pages\n  92-110", "doi": "10.1016/j.pmcj.2018.06.011", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a voice-controlled smart-home, a controller must respond not only to\nuser's requests but also according to the interaction context. This paper\ndescribes Arcades, a system which uses deep reinforcement learning to extract\ncontext from a graphical representation of home automation system and to update\ncontinuously its behavior to the user's one. This system is robust to changes\nin the environment (sensor breakdown or addition) through its graphical\nrepresentation (scale well) and the reinforcement mechanism (adapt well). The\nexperiments on realistic data demonstrate that this method promises to reach\nlong life context-aware control of smart-home.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:50:16 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Brenon", "Alexis", ""], ["Portet", "Fran\u00e7ois", ""], ["Vacher", "Michel", ""]]}, {"id": "1807.01972", "submitter": "Alex Ter-Sarkisov", "authors": "Aram Ter-Sarkisov, Robert Ross, John Kelleher, Bernadette Earley,\n  Michael Keane", "title": "Beef Cattle Instance Segmentation Using Fully Convolutional Neural\n  Network", "comments": "accepted at BMVC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an instance segmentation algorithm trained and applied to a CCTV\nrecording of beef cattle during a winter finishing period. A fully\nconvolutional network was transformed into an instance segmentation network\nthat learns to label each instance of an animal separately. We introduce a\nconceptually simple framework that the network uses to output a single\nprediction for every animal. These results are a contribution towards behaviour\nanalysis in winter finishing beef cattle for early detection of animal\nwelfare-related problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:52:07 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 15:18:34 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Ter-Sarkisov", "Aram", ""], ["Ross", "Robert", ""], ["Kelleher", "John", ""], ["Earley", "Bernadette", ""], ["Keane", "Michael", ""]]}, {"id": "1807.01985", "submitter": "Hirotaka Akita", "authors": "Hirotaka Akita, Kosuke Nakago, Tomoki Komatsu, Yohei Sugawara,\n  Shin-ichi Maeda, Yukino Baba, Hisashi Kashima", "title": "BayesGrad: Explaining Predictions of Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in graph convolutional networks have significantly improved\nthe performance of chemical predictions, raising a new research question: \"how\ndo we explain the predictions of graph convolutional networks?\" A possible\napproach to answer this question is to visualize evidence substructures\nresponsible for the predictions. For chemical property prediction tasks, the\nsample size of the training data is often small and/or a label imbalance\nproblem occurs, where a few samples belong to a single class and the majority\nof samples belong to the other classes. This can lead to uncertainty related to\nthe learned parameters of the machine learning model. To address this\nuncertainty, we propose BayesGrad, utilizing the Bayesian predictive\ndistribution, to define the importance of each node in an input graph, which is\ncomputed efficiently using the dropout technique. We demonstrate that BayesGrad\nsuccessfully visualizes the substructures responsible for the label prediction\nin the artificial experiment, even when the sample size is small. Furthermore,\nwe use a real dataset to evaluate the effectiveness of the visualization. The\nbasic idea of BayesGrad is not limited to graph-structured data and can be\napplied to other data types.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 14:03:37 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Akita", "Hirotaka", ""], ["Nakago", "Kosuke", ""], ["Komatsu", "Tomoki", ""], ["Sugawara", "Yohei", ""], ["Maeda", "Shin-ichi", ""], ["Baba", "Yukino", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1807.02011", "submitter": "Paul Bergmann", "authors": "Paul Bergmann, Sindy L\\\"owe, Michael Fauser, David Sattlegger, Carsten\n  Steger", "title": "Improving Unsupervised Defect Segmentation by Applying Structural\n  Similarity to Autoencoders", "comments": null, "journal-ref": null, "doi": "10.5220/0007364503720380", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional autoencoders have emerged as popular methods for unsupervised\ndefect segmentation on image data. Most commonly, this task is performed by\nthresholding a pixel-wise reconstruction error based on an $\\ell^p$ distance.\nThis procedure, however, leads to large residuals whenever the reconstruction\nencompasses slight localization inaccuracies around edges. It also fails to\nreveal defective regions that have been visually altered when intensity values\nstay roughly consistent. We show that these problems prevent these approaches\nfrom being applied to complex real-world scenarios and that it cannot be easily\navoided by employing more elaborate architectures such as variational or\nfeature matching autoencoders. We propose to use a perceptual loss function\nbased on structural similarity which examines inter-dependencies between local\nimage regions, taking into account luminance, contrast and structural\ninformation, instead of simply comparing single pixel values. It achieves\nsignificant performance gains on a challenging real-world dataset of\nnanofibrous materials and a novel dataset of two woven fabrics over the state\nof the art approaches for unsupervised defect segmentation that use pixel-wise\nreconstruction error metrics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:07:23 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 11:58:22 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 16:16:28 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bergmann", "Paul", ""], ["L\u00f6we", "Sindy", ""], ["Fauser", "Michael", ""], ["Sattlegger", "David", ""], ["Steger", "Carsten", ""]]}, {"id": "1807.02033", "submitter": "Ananya Kumar", "authors": "Ananya Kumar, S. M. Ali Eslami, Danilo J. Rezende, Marta Garnelo,\n  Fabio Viola, Edward Lockhart, Murray Shanahan", "title": "Consistent Generative Query Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic video prediction models take in a sequence of image frames, and\ngenerate a sequence of consecutive future image frames. These models typically\ngenerate future frames in an autoregressive fashion, which is slow and requires\nthe input and output frames to be consecutive. We introduce a model that\novercomes these drawbacks by generating a latent representation from an\narbitrary set of frames that can then be used to simultaneously and efficiently\nsample temporally consistent frames at arbitrary time-points. For example, our\nmodel can \"jump\" and directly sample frames at the end of the video, without\nsampling intermediate frames. Synthetic video evaluations confirm substantial\ngains in speed and functionality without loss in fidelity. We also apply our\nframework to a 3D scene reconstruction dataset. Here, our model is conditioned\non camera location and can sample consistent sets of images for what an\noccluded region of a 3D scene might look like, even if there are multiple\npossibilities for what that region might contain. Reconstructions and videos\nare available at https://bit.ly/2O4Pc4R.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:51:51 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 17:59:14 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 00:51:13 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Kumar", "Ananya", ""], ["Eslami", "S. M. Ali", ""], ["Rezende", "Danilo J.", ""], ["Garnelo", "Marta", ""], ["Viola", "Fabio", ""], ["Lockhart", "Edward", ""], ["Shanahan", "Murray", ""]]}, {"id": "1807.02037", "submitter": "Tung D. Le", "authors": "Tung D. Le, Haruki Imai, Yasushi Negishi and Kiyokuni Kawachiya", "title": "TFLMS: Large Model Support in TensorFlow by Graph Rewriting", "comments": "A new version of TFLMS was published at ISMM 2019\n  (https://dl.acm.org/citation.cfm?id=3329984)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While accelerators such as GPUs have limited memory, deep neural networks are\nbecoming larger and will not fit with the memory limitation of accelerators for\ntraining. We propose an approach to tackle this problem by rewriting the\ncomputational graph of a neural network, in which swap-out and swap-in\noperations are inserted to temporarily store intermediate results on CPU\nmemory. In particular, we first revise the concept of a computational graph by\ndefining a concrete semantics for variables in a graph. We then formally show\nhow to derive swap-out and swap-in operations from an existing graph and\npresent rules to optimize the graph. To realize our approach, we developed a\nmodule in TensorFlow, named TFLMS. TFLMS is published as a pull request in the\nTensorFlow repository for contributing to the TensorFlow community. With TFLMS,\nwe were able to train ResNet-50 and 3DUnet with 4.7x and 2x larger batch size,\nrespectively. In particular, we were able to train 3DUNet using images of size\nof $192^3$ for image segmentation, which, without TFLMS, had been done only by\ndividing the images to smaller images, which affects the accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:56:39 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 06:54:46 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Le", "Tung D.", ""], ["Imai", "Haruki", ""], ["Negishi", "Yasushi", ""], ["Kawachiya", "Kiyokuni", ""]]}, {"id": "1807.02078", "submitter": "Fabio Pardo", "authors": "Fabio Pardo, Vitaly Levdik, Petar Kormushev", "title": "Goal-oriented Trajectories for Efficient Exploration", "comments": "ICML 2018 Exploration in RL Workshop, videos:\n  https://sites.google.com/view/got-exploration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a difficult challenge in reinforcement learning and even\nrecent state-of-the art curiosity-based methods rely on the simple\nepsilon-greedy strategy to generate novelty. We argue that pure random walks do\nnot succeed to properly expand the exploration area in most environments and\npropose to replace single random action choices by random goals selection\nfollowed by several steps in their direction. This approach is compatible with\nany curiosity-based exploration and off-policy reinforcement learning agents\nand generates longer and safer trajectories than individual random actions. To\nillustrate this, we present a task-independent agent that learns to reach\ncoordinates in screen frames and demonstrate its ability to explore with the\ngame Super Mario Bros. improving significantly the score of a baseline DQN\nagent.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 16:31:21 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Pardo", "Fabio", ""], ["Levdik", "Vitaly", ""], ["Kormushev", "Petar", ""]]}, {"id": "1807.02089", "submitter": "Claire Vernade", "authors": "Claire Vernade, Alexandra Carpentier, Tor Lattimore, Giovanni\n  Zappella, Beyza Ermis, Michael Brueckner", "title": "Linear Bandits with Stochastic Delayed Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic linear bandits are a natural and well-studied model for structured\nexploration/exploitation problems and are widely used in applications such as\nonline marketing and recommendation. One of the main challenges faced by\npractitioners hoping to apply existing algorithms is that usually the feedback\nis randomly delayed and delays are only partially observable. For example,\nwhile a purchase is usually observable some time after the display, the\ndecision of not buying is never explicitly sent to the system. In other words,\nthe learner only observes delayed positive events. We formalize this problem as\na novel stochastic delayed linear bandit and propose ${\\tt OTFLinUCB}$ and\n${\\tt OTFLinTS}$, two computationally efficient algorithms able to integrate\nnew information as it becomes available and to deal with the permanently\ncensored feedback. We prove optimal $\\tilde O(\\smash{d\\sqrt{T}})$ bounds on the\nregret of the first algorithm and study the dependency on delay-dependent\nparameters. Our model, assumptions and results are validated by experiments on\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 17:09:33 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:09:21 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 14:19:17 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Vernade", "Claire", ""], ["Carpentier", "Alexandra", ""], ["Lattimore", "Tor", ""], ["Zappella", "Giovanni", ""], ["Ermis", "Beyza", ""], ["Brueckner", "Michael", ""]]}, {"id": "1807.02125", "submitter": "Trefor Evans", "authors": "Trefor W. Evans and Prasanth B. Nair", "title": "Scalable Gaussian Processes with Grid-Structured Eigenfunctions\n  (GP-GRIEF)", "comments": "Appears in the proceedings of the International Conference on Machine\n  Learning (ICML), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a kernel approximation strategy that enables computation of the\nGaussian process log marginal likelihood and all hyperparameter derivatives in\n$\\mathcal{O}(p)$ time. Our GRIEF kernel consists of $p$ eigenfunctions found\nusing a Nystrom approximation from a dense Cartesian product grid of inducing\npoints. By exploiting algebraic properties of Kronecker and Khatri-Rao tensor\nproducts, computational complexity of the training procedure can be practically\nindependent of the number of inducing points. This allows us to use arbitrarily\nmany inducing points to achieve a globally accurate kernel approximation, even\nin high-dimensional problems. The fast likelihood evaluation enables type-I or\nII Bayesian inference on large-scale datasets. We benchmark our algorithms on\nreal-world problems with up to two-million training points and $10^{33}$\ninducing points.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 18:00:34 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 16:22:55 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Evans", "Trefor W.", ""], ["Nair", "Prasanth B.", ""]]}, {"id": "1807.02128", "submitter": "Jung-Su Ha", "authors": "Jung-Su Ha, Young-Jin Park, Hyeok-Joo Chae, Soon-Seo Park, Han-Lim\n  Choi", "title": "Adaptive Path-Integral Autoencoder: Representation Learning and Planning\n  for Dynamical Systems", "comments": "Neural Information Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": "10.1088/1742-5468/ab3455", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation learning algorithm that learns a low-dimensional\nlatent dynamical system from high-dimensional \\textit{sequential} raw data,\ne.g., video. The framework builds upon recent advances in amortized inference\nmethods that use both an inference network and a refinement procedure to output\nsamples from a variational distribution given an observation sequence, and\ntakes advantage of the duality between control and inference to approximately\nsolve the intractable inference problem using the path integral control\napproach. The learned dynamical model can be used to predict and plan the\nfuture states; we also present the efficient planning method that exploits the\nlearned low-dimensional latent dynamics. Numerical experiments show that the\nproposed path-integral control based variational inference method leads to\ntighter lower bounds in statistical model learning of sequential data. The\nsupplementary video: https://youtu.be/xCp35crUoLQ\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 18:05:18 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 05:19:25 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 13:18:36 GMT"}, {"version": "v4", "created": "Thu, 3 Jan 2019 12:15:47 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ha", "Jung-Su", ""], ["Park", "Young-Jin", ""], ["Chae", "Hyeok-Joo", ""], ["Park", "Soon-Seo", ""], ["Choi", "Han-Lim", ""]]}, {"id": "1807.02150", "submitter": "Kevin Luk", "authors": "Elias Tragas, Calvin Luo, Maxime Gazeau, Kevin Luk, David Duvenaud", "title": "Scalable Recommender Systems through Recursive Evidence Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems can be formulated as a matrix completion problem,\npredicting ratings from user and item parameter vectors. Optimizing these\nparameters by subsampling data becomes difficult as the number of users and\nitems grows. We develop a novel approach to generate all latent variables on\ndemand from the ratings matrix itself and a fixed pool of parameters. We\nestimate missing ratings using chains of evidence that link them to a small set\nof prototypical users and items. Our model automatically addresses the\ncold-start and online learning problems by combining information across both\nusers and items. We investigate the scaling behavior of this model, and\ndemonstrate competitive results with respect to current matrix factorization\ntechniques in terms of accuracy and convergence speed.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 18:48:56 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Tragas", "Elias", ""], ["Luo", "Calvin", ""], ["Gazeau", "Maxime", ""], ["Luk", "Kevin", ""], ["Duvenaud", "David", ""]]}, {"id": "1807.02164", "submitter": "Mao Yang", "authors": "Mao Yang, Bo Li, Guanxiong Feng, Zhongjiang Yan", "title": "V-CNN: When Convolutional Neural Network encounters Data Visualization", "comments": "2 pages, 2 figures, submitted to ACM Sigcomm 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning poses a deep technical revolution in almost\nevery field and attracts great attentions from industry and academia.\nEspecially, the convolutional neural network (CNN), one representative model of\ndeep learning, achieves great successes in computer vision and natural language\nprocessing. However, simply or blindly applying CNN to the other fields results\nin lower training effects or makes it quite difficult to adjust the model\nparameters. In this poster, we propose a general methodology named V-CNN by\nintroducing data visualizing for CNN. V-CNN introduces a data visualization\nmodel prior to CNN modeling to make sure the data after processing is fit for\nthe features of images as well as CNN modeling. We apply V-CNN to the network\nintrusion detection problem based on a famous practical dataset: AWID.\nSimulation results confirm V-CNN significantly outperforms other studies and\nthe recall rate of each invasion category is more than 99.8%.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 10:57:57 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yang", "Mao", ""], ["Li", "Bo", ""], ["Feng", "Guanxiong", ""], ["Yan", "Zhongjiang", ""]]}, {"id": "1807.02187", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen", "title": "Encoding Motion Primitives for Autonomous Vehicles using Virtual\n  Velocity Constraints and Neural Network Scheduling", "comments": "8 pages, 4 figures, 7 tables, ICMLA 2018", "journal-ref": null, "doi": "10.13140/RG.2.2.28803.81448", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of trajectory planning for autonomous vehicles this paper\nproposes methods for efficient encoding of motion primitives in neural networks\non top of model-based and gradient-free reinforcement learning. It is\ndistinguished between 5 core aspects: system model, network architecture,\ntraining algorithm, training tasks selection and hardware/software\nimplementation. For the system model, a kinematic (3-states-2-controls) and a\ndynamic (16-states-2-controls) vehicle model are compared. For the network\narchitecture, 3 feedforward structures are compared including weighted skip\nconnections. For the training algorithm, virtual velocity constraints and\nnetwork scheduling are proposed. For the training tasks, different feature\nvector selections are discussed. For the implementation, aspects of\ngradient-free learning using 1 GPU and the handling of perturbation noise\ntherefore are discussed. The effects of proposed methods are illustrated in\nexperiments encoding up to 14625 motion primitives. The capabilities of tiny\nneural networks with as few as 10 scalar parameters when scheduled on vehicle\nvelocity are emphasized.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 21:44:39 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 13:50:07 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Plessen", "Mogens Graf", ""]]}, {"id": "1807.02188", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, and Kaushik Roy", "title": "Implicit Generative Modeling of Random Noise during Training for\n  Adversarial Robustness", "comments": "Preliminary version of this work accepted at ICML 2019 (Workshop on\n  Uncertainty and Robustness in Deep Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Noise-based prior Learning (NoL) approach for training neural\nnetworks that are intrinsically robust to adversarial attacks. We find that the\nimplicit generative modeling of random noise with the same loss function used\nduring posterior maximization, improves a model's understanding of the data\nmanifold furthering adversarial robustness. We evaluate our approach's efficacy\nand provide a simplistic visualization tool for understanding adversarial data,\nusing Principal Component Analysis. Our analysis reveals that adversarial\nrobustness, in general, manifests in models with higher variance along the\nhigh-ranked principal components. We show that models learnt with our approach\nperform remarkably well against a wide-range of attacks. Furthermore, combining\nNoL with state-of-the-art adversarial training extends the robustness of a\nmodel, even beyond what it is adversarially trained for, in both white-box and\nblack-box attack scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 21:52:36 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 16:54:50 GMT"}, {"version": "v3", "created": "Sat, 11 May 2019 12:19:08 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 19:09:09 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1807.02233", "submitter": "Yan Zhang", "authors": "Yan Zhang, Xiang Huang, Nicola Ferrier, Emine B. Gulsoy, Charudatta\n  Phatak", "title": "U-SLADS: Unsupervised Learning Approach for Dynamic Dendrite Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel data acquisition schemes have been an emerging need for scanning\nmicroscopy based imaging techniques to reduce the time in data acquisition and\nto minimize probing radiation in sample exposure. Varies sparse sampling\nschemes have been studied and are ideally suited for such applications where\nthe images can be reconstructed from a sparse set of measurements. Dynamic\nsparse sampling methods, particularly supervised learning based iterative\nsampling algorithms, have shown promising results for sampling pixel locations\non the edges or boundaries during imaging. However, dynamic sampling for\nimaging skeleton-like objects such as metal dendrites remains difficult. Here,\nwe address a new unsupervised learning approach using Hierarchical Gaussian\nMixture Mod- els (HGMM) to dynamically sample metal dendrites. This technique\nis very useful if the users are interested in fast imaging the primary and\nsecondary arms of metal dendrites in solidification process in materials\nscience.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 03:14:29 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Zhang", "Yan", ""], ["Huang", "Xiang", ""], ["Ferrier", "Nicola", ""], ["Gulsoy", "Emine B.", ""], ["Phatak", "Charudatta", ""]]}, {"id": "1807.02234", "submitter": "Xuchao Zhang", "authors": "Xuchao Zhang, Liang Zhao, Zhiqian Chen, Chang-Tien Lu", "title": "Distributed Self-Paced Learning in Alternating Direction Method of\n  Multipliers", "comments": "8 pages, 4 figures, accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-paced learning (SPL) mimics the cognitive process of humans, who\ngenerally learn from easy samples to hard ones. One key issue in SPL is the\ntraining process required for each instance weight depends on the other samples\nand thus cannot easily be run in a distributed manner in a large-scale dataset.\nIn this paper, we reformulate the self-paced learning problem into a\ndistributed setting and propose a novel Distributed Self-Paced Learning method\n(DSPL) to handle large-scale datasets. Specifically, both the model and\ninstance weights can be optimized in parallel for each batch based on a\nconsensus alternating direction method of multipliers. We also prove the\nconvergence of our algorithm under mild conditions. Extensive experiments on\nboth synthetic and real datasets demonstrate that our approach is superior to\nthose of existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 03:18:33 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Zhang", "Xuchao", ""], ["Zhao", "Liang", ""], ["Chen", "Zhiqian", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1807.02235", "submitter": "Zirui Wang", "authors": "Zirui Wang and Jaime Carbonell", "title": "Towards more Reliable Transfer Learning", "comments": "ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-source transfer learning has been proven effective when within-target\nlabeled data is scarce. Previous work focuses primarily on exploiting domain\nsimilarities and assumes that source domains are richly or at least comparably\nlabeled. While this strong assumption is never true in practice, this paper\nrelaxes it and addresses challenges related to sources with diverse labeling\nvolume and diverse reliability. The first challenge is combining domain\nsimilarity and source reliability by proposing a new transfer learning method\nthat utilizes both source-target similarities and inter-source relationships.\nThe second challenge involves pool-based active learning where the oracle is\nonly available in source domains, resulting in an integrated active transfer\nlearning framework that incorporates distribution matching and uncertainty\nsampling. Extensive experiments on synthetic and two real-world datasets\nclearly demonstrate the superiority of our proposed methods over several\nbaselines including state-of-the-art transfer learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 03:22:29 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Wang", "Zirui", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1807.02264", "submitter": "Hongzi Mao", "authors": "Hongzi Mao, Shaileshh Bojja Venkatakrishnan, Malte Schwarzkopf,\n  Mohammad Alizadeh", "title": "Variance Reduction for Reinforcement Learning in Input-Driven\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reinforcement learning in input-driven environments, where an\nexogenous, stochastic input process affects the dynamics of the system. Input\nprocesses arise in many applications, including queuing systems, robotics\ncontrol with disturbances, and object tracking. Since the state dynamics and\nrewards depend on the input process, the state alone provides limited\ninformation for the expected future returns. Therefore, policy gradient methods\nwith standard state-dependent baselines suffer high variance during training.\nWe derive a bias-free, input-dependent baseline to reduce this variance, and\nanalytically show its benefits over state-dependent baselines. We then propose\na meta-learning approach to overcome the complexity of learning a baseline that\ndepends on a long sequence of inputs. Our experimental results show that across\nenvironments from queuing systems, computer networks, and MuJoCo robotic\nlocomotion, input-dependent baselines consistently improve training stability\nand result in better eventual policies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 06:03:06 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 20:11:34 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 05:38:15 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Mao", "Hongzi", ""], ["Venkatakrishnan", "Shaileshh Bojja", ""], ["Schwarzkopf", "Malte", ""], ["Alizadeh", "Mohammad", ""]]}, {"id": "1807.02287", "submitter": "Amichai Painsky", "authors": "Amichai Painsky and Meir Feder", "title": "Outperforming Good-Turing: Preliminary Report", "comments": "This paper has several inaccuracies in the experimental setup which\n  require additional work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating a large alphabet probability distribution from a limited number of\nsamples is a fundamental problem in machine learning and statistics. A variety\nof estimation schemes have been proposed over the years, mostly inspired by the\nearly work of Laplace and the seminal contribution of Good and Turing. One of\nthe basic assumptions shared by most commonly-used estimators is the unique\ncorrespondence between the symbol's sample frequency and its estimated\nprobability. In this work we tackle this paradigmatic assumption; we claim that\nsymbols with \"similar\" frequencies shall be assigned the same estimated\nprobability value. This way we regulate the number of parameters and improve\ngeneralization. In this preliminary report we show that by applying an ensemble\nof such regulated estimators, we introduce a dramatic enhancement in the\nestimation accuracy (typically up to 50%), compared to currently known methods.\nAn implementation of our suggested method is publicly available at the first\nauthor's web-page.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 07:12:56 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 15:27:29 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Painsky", "Amichai", ""], ["Feder", "Meir", ""]]}, {"id": "1807.02290", "submitter": "Rachel Cummings", "authors": "Adrian Rivera Cardoso and Rachel Cummings", "title": "Differentially Private Online Submodular Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop the first algorithms for online submodular\nminimization that preserve differential privacy under full information feedback\nand bandit feedback. A sequence of $T$ submodular functions over a collection\nof $n$ elements arrive online, and at each timestep the algorithm must choose a\nsubset of $[n]$ before seeing the function. The algorithm incurs a cost equal\nto the function evaluated on the chosen set, and seeks to choose a sequence of\nsets that achieves low expected regret.\n  Our first result is in the full information setting, where the algorithm can\nobserve the entire function after making its decision at each timestep. We give\nan algorithm in this setting that is $\\epsilon$-differentially private and\nachieves expected regret\n$\\tilde{O}\\left(\\frac{n^{3/2}\\sqrt{T}}{\\epsilon}\\right)$. This algorithm works\nby relaxing submodular function to a convex function using the Lovasz\nextension, and then simulating an algorithm for differentially private online\nconvex optimization.\n  Our second result is in the bandit setting, where the algorithm can only see\nthe cost incurred by its chosen set, and does not have access to the entire\nfunction. This setting is significantly more challenging because the algorithm\ndoes not receive enough information to compute the Lovasz extension or its\nsubgradients. Instead, we construct an unbiased estimate using a single-point\nestimation, and then simulate private online convex optimization using this\nestimate. Our algorithm using bandit feedback is $\\epsilon$-differentially\nprivate and achieves expected regret\n$\\tilde{O}\\left(\\frac{n^{3/2}T^{3/4}}{\\epsilon}\\right)$.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 07:30:17 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Cummings", "Rachel", ""]]}, {"id": "1807.02297", "submitter": "Tanner Fiez", "authors": "Tanner Fiez, Shreyas Sekar, Liyuan Zheng, Lillian J. Ratliff", "title": "Combinatorial Bandits for Incentivizing Agents with Dynamic Preferences", "comments": "Published as a conference paper in Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of personalized incentives or recommendations to improve user\nengagement is gaining prominence as digital platform providers continually\nemerge. We propose a multi-armed bandit framework for matching incentives to\nusers, whose preferences are unknown a priori and evolving dynamically in time,\nin a resource constrained environment. We design an algorithm that combines\nideas from three distinct domains: (i) a greedy matching paradigm, (ii) the\nupper confidence bound algorithm (UCB) for bandits, and (iii) mixing times from\nthe theory of Markov chains. For this algorithm, we provide theoretical bounds\non the regret and demonstrate its performance via both synthetic and realistic\n(matching supply and demand in a bike-sharing platform) examples.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:03:39 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Fiez", "Tanner", ""], ["Sekar", "Shreyas", ""], ["Zheng", "Liyuan", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "1807.02303", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis, Vassilis Vassiliades, Freek Stulp,\n  Sylvain Calinon and Jean-Baptiste Mouret", "title": "A survey on policy search algorithms for learning robot controllers in a\n  handful of trials", "comments": "21 pages, 3 figures, 4 algorithms, accepted at IEEE Transactions on\n  Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most policy search algorithms require thousands of training episodes to find\nan effective policy, which is often infeasible with a physical robot. This\nsurvey article focuses on the extreme other end of the spectrum: how can a\nrobot adapt with only a handful of trials (a dozen) and a few minutes? By\nanalogy with the word \"big-data\", we refer to this challenge as \"micro-data\nreinforcement learning\". We show that a first strategy is to leverage prior\nknowledge on the policy structure (e.g., dynamic movement primitives), on the\npolicy parameters (e.g., demonstrations), or on the dynamics (e.g.,\nsimulators). A second strategy is to create data-driven surrogate models of the\nexpected reward (e.g., Bayesian optimization) or the dynamical model (e.g.,\nmodel-based policy search), so that the policy optimizer queries the model\ninstead of the real system. Overall, all successful micro-data algorithms\ncombine these two strategies by varying the kind of model and prior knowledge.\nThe current scientific challenges essentially revolve around scaling up to\ncomplex robots (e.g., humanoids), designing generic priors, and optimizing the\ncomputing time.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:14:27 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 08:17:41 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 13:44:20 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 22:22:44 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 10:24:27 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Vassiliades", "Vassilis", ""], ["Stulp", "Freek", ""], ["Calinon", "Sylvain", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1807.02314", "submitter": "Xianggen Liu", "authors": "Xianggen Liu, Lili Mou, Haotian Cui, Zhengdong Lu, Sen Song", "title": "JUMPER: Learning When to Make Classification Decisions in Reading", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In early years, text classification is typically accomplished by\nfeature-based machine learning models; recently, deep neural networks, as a\npowerful learning machine, make it possible to work with raw input as the text\nstands. However, exiting end-to-end neural networks lack explicit\ninterpretation of the prediction. In this paper, we propose a novel framework,\nJUMPER, inspired by the cognitive process of text reading, that models text\nclassification as a sequential decision process. Basically, JUMPER is a neural\nsystem that scans a piece of text sequentially and makes classification\ndecisions at the time it wishes. Both the classification result and when to\nmake the classification are part of the decision process, which is controlled\nby a policy network and trained with reinforcement learning. Experimental\nresults show that a properly trained JUMPER has the following properties: (1)\nIt can make decisions whenever the evidence is enough, therefore reducing total\ntext reading by 30-40% and often finding the key rationale of prediction. (2)\nIt achieves classification accuracy better than or comparable to\nstate-of-the-art models in several benchmark and industrial datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:49:56 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Liu", "Xianggen", ""], ["Mou", "Lili", ""], ["Cui", "Haotian", ""], ["Lu", "Zhengdong", ""], ["Song", "Sen", ""]]}, {"id": "1807.02322", "submitter": "Chen Liang", "authors": "Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc Le, Ni Lao", "title": "Memory Augmented Policy Optimization for Program Synthesis and Semantic\n  Parsing", "comments": "17 Pages, 4 figures, 7 tables, accepted as a spotlight paper for\n  NeurIPS 2018, camera ready version, fixed a typo in table 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Memory Augmented Policy Optimization (MAPO), a simple and novel\nway to leverage a memory buffer of promising trajectories to reduce the\nvariance of policy gradient estimate. MAPO is applicable to deterministic\nenvironments with discrete actions, such as structured prediction and\ncombinatorial optimization tasks. We express the expected return objective as a\nweighted sum of two terms: an expectation over the high-reward trajectories\ninside the memory buffer, and a separate expectation over trajectories outside\nthe buffer. To make an efficient algorithm of MAPO, we propose: (1) memory\nweight clipping to accelerate and stabilize training; (2) systematic\nexploration to discover high-reward trajectories; (3) distributed sampling from\ninside and outside of the memory buffer to scale up training. MAPO improves the\nsample efficiency and robustness of policy gradient, especially on tasks with\nsparse rewards. We evaluate MAPO on weakly supervised program synthesis from\nnatural language (semantic parsing). On the WikiTableQuestions benchmark, we\nimprove the state-of-the-art by 2.6%, achieving an accuracy of 46.3%. On the\nWikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak\nsupervision, outperforming several strong baselines with full supervision. Our\nsource code is available at\nhttps://github.com/crazydonkey200/neural-symbolic-machines\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 09:15:05 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 00:53:35 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 07:51:12 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 17:58:45 GMT"}, {"version": "v5", "created": "Sun, 13 Jan 2019 02:03:10 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Liang", "Chen", ""], ["Norouzi", "Mohammad", ""], ["Berant", "Jonathan", ""], ["Le", "Quoc", ""], ["Lao", "Ni", ""]]}, {"id": "1807.02324", "submitter": "Sebastian Tschiatschek", "authors": "Martin Ratajczak, Sebastian Tschiatschek, Franz Pernkopf", "title": "Sum-Product Networks for Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider higher-order linear-chain conditional random fields (HO-LC-CRFs)\nfor sequence modelling, and use sum-product networks (SPNs) for representing\nhigher-order input- and output-dependent factors. SPNs are a recently\nintroduced class of deep models for which exact and efficient inference can be\nperformed. By combining HO-LC-CRFs with SPNs, expressive models over both the\noutput labels and the hidden variables are instantiated while still enabling\nefficient exact inference. Furthermore, the use of higher-order factors allows\nus to capture relations of multiple input segments and multiple output labels\nas often present in real-world data. These relations can not be modelled by the\ncommonly used first-order models and higher-order models with local factors\nincluding only a single output label. We demonstrate the effectiveness of our\nproposed models for sequence labeling. In extensive experiments, we outperform\nother state-of-the-art methods in optical character recognition and achieve\ncompetitive results in phone classification.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 09:22:12 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ratajczak", "Martin", ""], ["Tschiatschek", "Sebastian", ""], ["Pernkopf", "Franz", ""]]}, {"id": "1807.02326", "submitter": "Sonali Parbhoo", "authors": "Sonali Parbhoo, Mario Wieser, Aleksander Wieczorek, Volker Roth", "title": "Cause-Effect Deep Information Bottleneck For Systematically Missing\n  Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating the causal effects of an intervention from high-dimensional\nobservational data is difficult due to the presence of confounding. The task is\noften complicated by the fact that we may have a systematic missingness in our\ndata at test time. Our approach uses the information bottleneck to perform a\nlow-dimensional compression of covariates by explicitly considering the\nrelevance of information. Based on the sufficiently reduced covariate, we\ntransfer the relevant information to cases where data is missing at test time,\nallowing us to reliably and accurately estimate the effects of an intervention,\neven where data is incomplete. Our results on causal inference benchmarks and a\nreal application for treating sepsis show that our method achieves state-of-the\nart performance, without sacrificing interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 09:29:57 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 15:08:43 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 15:36:06 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Parbhoo", "Sonali", ""], ["Wieser", "Mario", ""], ["Wieczorek", "Aleksander", ""], ["Roth", "Volker", ""]]}, {"id": "1807.02350", "submitter": "Maxime Chaveroche", "authors": "Maxime Chaveroche, Adrien Malais\\'e, Francis Colas, Fran\\c{c}ois\n  Charpillet, Serena Ivaldi", "title": "A Variational Time Series Feature Extractor for Action Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Variational Time Series Feature Extractor (VTSFE), inspired by\nthe VAE-DMP model of Chen et al., to be used for action recognition and\nprediction. Our method is based on variational autoencoders. It improves\nVAE-DMP in that it has a better noise inference model, a simpler transition\nmodel constraining the acceleration in the trajectories of the latent space,\nand a tighter lower bound for the variational inference. We apply the method\nfor classification and prediction of whole-body movements on a dataset with 7\ntasks and 10 demonstrations per task, recorded with a wearable motion capture\nsuit. The comparison with VAE and VAE-DMP suggests the better performance of\nour method for feature extraction. An open-source software implementation of\neach method with TensorFlow is also provided. In addition, a more detailed\nversion of this work can be found in the indicated code repository. Although it\nwas meant to, the VTSFE hasn't been tested for action prediction, due to a lack\nof time in the context of Maxime Chaveroche's Master thesis at INRIA.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 10:47:20 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 11:52:58 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Chaveroche", "Maxime", ""], ["Malais\u00e9", "Adrien", ""], ["Colas", "Francis", ""], ["Charpillet", "Fran\u00e7ois", ""], ["Ivaldi", "Serena", ""]]}, {"id": "1807.02373", "submitter": "Matteo Pirotta", "authors": "Ronan Fruit, Matteo Pirotta and Alessandro Lazaric", "title": "Near Optimal Exploration-Exploitation in Non-Communicating Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While designing the state space of an MDP, it is common to include states\nthat are transient or not reachable by any policy (e.g., in mountain car, the\nproduct space of speed and position contains configurations that are not\nphysically reachable). This leads to defining weakly-communicating or\nmulti-chain MDPs. In this paper, we introduce \\tucrl, the first algorithm able\nto perform efficient exploration-exploitation in any finite Markov Decision\nProcess (MDP) without requiring any form of prior knowledge. In particular, for\nany MDP with $S^{\\texttt{C}}$ communicating states, $A$ actions and\n$\\Gamma^{\\texttt{C}} \\leq S^{\\texttt{C}}$ possible communicating next states,\nwe derive a $\\widetilde{O}(D^{\\texttt{C}} \\sqrt{\\Gamma^{\\texttt{C}}\nS^{\\texttt{C}} AT})$ regret bound, where $D^{\\texttt{C}}$ is the diameter\n(i.e., the longest shortest path) of the communicating part of the MDP. This is\nin contrast with optimistic algorithms (e.g., UCRL, Optimistic PSRL) that\nsuffer linear regret in weakly-communicating MDPs, as well as posterior\nsampling or regularised algorithms (e.g., REGAL), which require prior knowledge\non the bias span of the optimal policy to bias the exploration to achieve\nsub-linear regret. We also prove that in weakly-communicating MDPs, no\nalgorithm can ever achieve a logarithmic growth of the regret without first\nsuffering a linear regret for a number of steps that is exponential in the\nparameters of the MDP. Finally, we report numerical simulations supporting our\ntheoretical findings and showing how TUCRL overcomes the limitations of the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 12:13:52 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 16:39:07 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Fruit", "Ronan", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1807.02374", "submitter": "Anna Korba", "authors": "Anna Korba, Alexandre Garcia, Florence d'Alch\\'e Buc", "title": "A Structured Prediction Approach for Label Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to solve a label ranking problem as a structured output regression\ntask. We adopt a least square surrogate loss approach that solves a supervised\nlearning problem in two steps: the regression step in a well-chosen feature\nspace and the pre-image step. We use specific feature maps/embeddings for\nranking data, which convert any ranking/permutation into a vector\nrepresentation. These embeddings are all well-tailored for our approach, either\nby resulting in consistent estimators, or by solving trivially the pre-image\nproblem which is often the bottleneck in structured prediction. We also propose\ntheir natural extension to the case of partial rankings and prove their\nefficiency on real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 12:18:14 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Korba", "Anna", ""], ["Garcia", "Alexandre", ""], ["Buc", "Florence d'Alch\u00e9", ""]]}, {"id": "1807.02391", "submitter": "Sudha Subramani", "authors": "Sudha Subramani, Manjula O'Connor", "title": "Extracting Actionable Knowledge from Domestic Violence Discourses on\n  Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic Violence (DV) is considered as big social issue and there exists a\nstrong relationship between DV and health impacts of the public. Existing\nresearch studies have focused on social media to track and analyse real world\nevents like emerging trends, natural disasters, user sentiment analysis,\npolitical opinions, and health care. However there is less attention given on\nsocial welfare issues like DV and its impact on public health. Recently, the\nvictims of DV turned to social media platforms to express their feelings in the\nform of posts and seek the social and emotional support, for sympathetic\nencouragement, to show compassion and empathy among public. But, it is\ndifficult to mine the actionable knowledge from large conversational datasets\nfrom social media due to the characteristics of high dimensions, short, noisy,\nhuge volume, high velocity, and so on. Hence, this paper will propose a novel\nframework to model and discover the various themes related to DV from the\npublic domain. The proposed framework would possibly provide unprecedentedly\nvaluable information to the public health researchers, national family health\norganizations, government and public with data enrichment and consolidation to\nimprove the social welfare of the community. Thus provides actionable knowledge\nby monitoring and analysing continuous and rich user generated content.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 03:34:22 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Subramani", "Sudha", ""], ["O'Connor", "Manjula", ""]]}, {"id": "1807.02401", "submitter": "Kaixin Hu", "authors": "Kaixin Hu, Peter O'Connor", "title": "Learning a Representation Map for Robot Navigation using Deep\n  Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to use Variational Autoencoder (VAE) to learn a\nrepresentation of an indoor environment that can be used for robot navigation.\nWe use images extracted from a video, in which a camera takes a tour around a\nhouse, for training the VAE model with a 4 dimensional latent space. After the\nmodel is trained, each real frame has a corresponding representation point on\nmanifold in the latent space, and each representation point has corresponding\nreconstructed image. For the navigation problem, we map the starting image and\ndestination image to the latent space, then optimize a path on the learned\nmanifold connecting the two points, and finally map the path back through\ndecoder to a sequence of images. The ideal sequence of images should correspond\nto a route that is spatially continuous - i.e. neighbor images in the route\nshould correspond to neighbor locations in physical space. Such a route could\nbe used for navigation with computer vision techniques, i.e. a robot could\nfollow the image sequence from starting location to destination in the\nenvironment step by step. We implement this algorithm, but find in our\nexperimental results that the resulting route is not satisfactory. The route\nconsist of several discontinuous image frames along the ideal routes, so that\nthe route could not be followed by a robot with computer vision techniques in\npractice. In our evaluation, we propose two reasons for our failure to\nautomatically find continuous routes: (1) The VAE tends to capture global\nstructures, but discard the details; (2) the Euclidean similarity metric used\nfor measuring continuity between house images is sub-optimal. For further work,\nwe propose: trying other generative models like VAE-GANs which may be better at\nreconstructing the details to learn the representation map, and adjusting the\nsimilarity metric in the path selecting algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:46:32 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 19:22:04 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Hu", "Kaixin", ""], ["O'Connor", "Peter", ""]]}, {"id": "1807.02442", "submitter": "Xin Hunt", "authors": "Xin J. Hunt, Saba Emrani, Ilknur Kaynar Kabul, and Jorge Silva", "title": "Multi-Task Learning with Incomplete Data for Healthcare", "comments": "4 pages, 3 figures, 1 table, 2018 KDD Workshop on Machine Learning\n  for Medicine and Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is a type of transfer learning that trains multiple tasks\nsimultaneously and leverages the shared information between related tasks to\nimprove the generalization performance. However, missing features in the input\nmatrix is a much more difficult problem which needs to be carefully addressed.\nRemoving records with missing values can significantly reduce the sample size,\nwhich is impractical for datasets with large percentage of missing values.\nPopular imputation methods often distort the covariance structure of the data,\nwhich causes inaccurate inference. In this paper we propose using plug-in\ncovariance matrix estimators to tackle the challenge of missing features.\nSpecifically, we analyze the plug-in estimators under the framework of robust\nmulti-task learning with LASSO and graph regularization, which captures the\nrelatedness between tasks via graph regularization. We use the Alzheimer's\ndisease progression dataset as an example to show how the proposed framework is\neffective for prediction and model estimation when missing data is present.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 15:08:26 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Hunt", "Xin J.", ""], ["Emrani", "Saba", ""], ["Kabul", "Ilknur Kaynar", ""], ["Silva", "Jorge", ""]]}, {"id": "1807.02471", "submitter": "Debadri Dutta", "authors": "Debadri Dutta", "title": "A Review of Different Word Embeddings for Sentiment Classification using\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web is loaded with textual content, and Natural Language Processing is a\nstandout amongst the most vital fields in Machine Learning. But when data is\nhuge simple Machine Learning algorithms are not able to handle it and that is\nwhen Deep Learning comes into play which based on Neural Networks. However\nsince neural networks cannot process raw text, we have to change over them\nthrough some diverse strategies of word embedding. This paper demonstrates\nthose distinctive word embedding strategies implemented on an Amazon Review\nDataset, which has two sentiments to be classified: Happy and Unhappy based on\nnumerous customer reviews. Moreover we demonstrate the distinction in accuracy\nwith a discourse about which word embedding to apply when.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 07:17:21 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Dutta", "Debadri", ""]]}, {"id": "1807.02490", "submitter": "Shabnam Ghaffarzadegan", "authors": "Shabnam Ghaffarzadegan", "title": "Deep Multiple Instance Feature Learning via Variational Autoencoder", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel weakly supervised deep learning framework that combines\nboth the discriminative and generative models to learn meaningful\nrepresentation in the multiple instance learning (MIL) setting. MIL is a weakly\nsupervised learning problem where labels are associated with groups of\ninstances (referred as bags) instead of individual instances. To address the\nessential challenge in MIL problems raised from the uncertainty of positive\ninstances label, we use a discriminative model regularized by variational\nautoencoders (VAEs) to maximize the differences between latent representations\nof all instances and negative instances. As a result, the hidden layer of the\nvariational autoencoder learns meaningful representation. This representation\ncan effectively be used for MIL problems as illustrated by better performance\non the standard benchmark datasets comparing to the state-of-the-art\napproaches. More importantly, unlike most related studies, the proposed\nframework can be easily scaled to large dataset problems, as illustrated by the\naudio event detection and segmentation task. Visualization also confirms the\neffectiveness of the latent representation in discriminating positive and\nnegative classes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 17:05:10 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ghaffarzadegan", "Shabnam", ""]]}, {"id": "1807.02515", "submitter": "Gihan Janith Mendis Imbulgoda Liyangahawatte", "authors": "Gihan J. Mendis, Yifu Wu, Jin Wei, Moein Sabounchi, and Rigoberto\n  Roche'", "title": "Blockchain as a Service: A Decentralized and Secure Computing Paradigm", "comments": "14 pages, 14 figures", "journal-ref": null, "doi": "10.1109/TETC.2020.2983007", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the advances in machine learning, data-driven analysis tools have\nbecome valuable solutions for various applications. However, there still remain\nessential challenges to develop effective data-driven methods because of the\nneed to acquire a large amount of data and to have sufficient computing power\nto handle the data. In many instances these challenges are addressed by relying\non a dominant cloud computing vendor, but, although commercial cloud vendors\nprovide valuable platforms for data analytics, they can suffer from a lack of\ntransparency, security, and privacy-perservation. Furthermore, reliance on\ncloud servers prevents applying big data analytics in environments where the\ncomputing power is scattered. To address these challenges, a decentralize,\nsecure, and privacy-preserving computing paradigm is proposed to enable an\nasynchronized cooperative computing process amongst scattered and untrustworthy\ncomputing nodes that may have limited computing power and computing\nintelligence. This paradigm is designed by exploring blockchain, decentralized\nlearning, homomorphic encryption, and software defined networking(SDN)\ntechniques. The performance of the proposed paradigm is evaluated via different\nscenarios in the simulation section.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 20:03:38 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 02:53:24 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 15:37:43 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Mendis", "Gihan J.", ""], ["Wu", "Yifu", ""], ["Wei", "Jin", ""], ["Sabounchi", "Moein", ""], ["Roche'", "Rigoberto", ""]]}, {"id": "1807.02537", "submitter": "Aristeidis Panos", "authors": "Aristeidis Panos, Petros Dellaportas, Michalis K. Titsias", "title": "Fully Scalable Gaussian Processes using Subspace Inducing Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce fully scalable Gaussian processes, an implementation scheme that\ntackles the problem of treating a high number of training instances together\nwith high dimensional input data. Our key idea is a representation trick over\nthe inducing variables called subspace inducing inputs. This is combined with\ncertain matrix-preconditioning based parametrizations of the variational\ndistributions that lead to simplified and numerically stable variational lower\nbounds. Our illustrative applications are based on challenging extreme\nmulti-label classification problems with the extra burden of the very large\nnumber of class labels. We demonstrate the usefulness of our approach by\npresenting predictive performances together with low computational times in\ndatasets with extremely large number of instances and input dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 18:18:36 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 19:14:56 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Panos", "Aristeidis", ""], ["Dellaportas", "Petros", ""], ["Titsias", "Michalis K.", ""]]}, {"id": "1807.02547", "submitter": "Maurice Weiler", "authors": "Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, Taco Cohen", "title": "3D Steerable CNNs: Learning Rotationally Equivariant Features in\n  Volumetric Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convolutional network that is equivariant to rigid body motions.\nThe model uses scalar-, vector-, and tensor fields over 3D Euclidean space to\nrepresent data, and equivariant convolutions to map between such\nrepresentations. These SE(3)-equivariant convolutions utilize kernels which are\nparameterized as a linear combination of a complete steerable kernel basis,\nwhich is derived analytically in this paper. We prove that equivariant\nconvolutions are the most general equivariant linear maps between fields over\nR^3. Our experimental results confirm the effectiveness of 3D Steerable CNNs\nfor the problem of amino acid propensity prediction and protein structure\nclassification, both of which have inherent SE(3) symmetry.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 19:06:12 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 14:55:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Weiler", "Maurice", ""], ["Geiger", "Mario", ""], ["Welling", "Max", ""], ["Boomsma", "Wouter", ""], ["Cohen", "Taco", ""]]}, {"id": "1807.02552", "submitter": "Issam Hadj Laradji", "authors": "Issam Laradji and Reza Babanezhad", "title": "M-ADDA: Unsupervised Domain Adaptation with Deep Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation techniques have been successful for a wide\nrange of problems where supervised labels are limited. The task is to classify\nan unlabeled `target' dataset by leveraging a labeled `source' dataset that\ncomes from a slightly similar distribution. We propose metric-based adversarial\ndiscriminative domain adaptation (M-ADDA) which performs two main steps. First,\nit uses a metric learning approach to train the source model on the source\ndataset by optimizing the triplet loss function. This results in clusters where\nembeddings of the same label are close to each other and those with different\nlabels are far from one another. Next, it uses the adversarial approach (as\nthat used in ADDA \\cite{2017arXiv170205464T}) to make the extracted features\nfrom the source and target datasets indistinguishable. Simultaneously, we\noptimize a novel loss function that encourages the target dataset's embeddings\nto form clusters. While ADDA and M-ADDA use similar architectures, we show that\nM-ADDA performs significantly better on the digits adaptation datasets of MNIST\nand USPS. This suggests that using metric-learning for domain adaptation can\nlead to large improvements in classification accuracy for the domain adaptation\ntask. The code is available at \\url{https://github.com/IssamLaradji/M-ADDA}.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 19:21:59 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Laradji", "Issam", ""], ["Babanezhad", "Reza", ""]]}, {"id": "1807.02567", "submitter": "Tugba Erpek", "authors": "Tugba Erpek, Yalin E. Sagduyu, Yi Shi", "title": "Deep Learning for Launching and Mitigating Wireless Jamming Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial machine learning approach is introduced to launch jamming\nattacks on wireless communications and a defense strategy is presented. A\ncognitive transmitter uses a pre-trained classifier to predict the current\nchannel status based on recent sensing results and decides whether to transmit\nor not, whereas a jammer collects channel status and ACKs to build a deep\nlearning classifier that reliably predicts the next successful transmissions\nand effectively jams them. This jamming approach is shown to reduce the\ntransmitter's performance much more severely compared with random or\nsensing-based jamming. The deep learning classification scores are used by the\njammer for power control subject to an average power constraint. Next, a\ngenerative adversarial network (GAN) is developed for the jammer to reduce the\ntime to collect the training dataset by augmenting it with synthetic samples.\nAs a defense scheme, the transmitter deliberately takes a small number of wrong\nactions in spectrum access (in form of a causative attack against the jammer)\nand therefore prevents the jammer from building a reliable classifier. The\ntransmitter systematically selects when to take wrong actions and adapts the\nlevel of defense to mislead the jammer into making prediction errors and\nconsequently increase its throughput.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 23:17:50 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 17:37:45 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""]]}, {"id": "1807.02581", "submitter": "Stanislav Fort", "authors": "Stanislav Fort, Adam Scherlis", "title": "The Goldilocks zone: Towards better understanding of neural network loss\n  landscapes", "comments": "8 pages, 15 figures. Accepted for publication at the Thirty-Third\n  AAAI Conference on Artificial Intelligence (AAAI-19). A subset of the paper\n  accepted at Modern Trends in Nonconvex Optimization for Machine Learning\n  workshop at the 35th International Conference on Machine Learning (ICML\n  2018), and BayLearn 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the loss landscape of fully-connected and convolutional neural\nnetworks using random, low-dimensional hyperplanes and hyperspheres. Evaluating\nthe Hessian, $H$, of the loss function on these hypersurfaces, we observe 1) an\nunusual excess of the number of positive eigenvalues of $H$, and 2) a large\nvalue of $\\mathrm{Tr}(H) / ||H||$ at a well defined range of configuration\nspace radii, corresponding to a thick, hollow, spherical shell we refer to as\nthe \\textit{Goldilocks zone}. We observe this effect for fully-connected neural\nnetworks over a range of network widths and depths on MNIST and CIFAR-10\ndatasets with the $\\mathrm{ReLU}$ and $\\tanh$ non-linearities, and a similar\neffect for convolutional networks. Using our observations, we demonstrate a\nclose connection between the Goldilocks zone, measures of local\nconvexity/prevalence of positive curvature, and the suitability of a network\ninitialization. We show that the high and stable accuracy reached when\noptimizing on random, low-dimensional hypersurfaces is directly related to the\noverlap between the hypersurface and the Goldilocks zone, and as a corollary\ndemonstrate that the notion of intrinsic dimension is initialization-dependent.\nWe note that common initialization techniques initialize neural networks in\nthis particular region of unusually high convexity/prevalence of positive\ncurvature, and offer a geometric intuition for their success. Furthermore, we\ndemonstrate that initializing a neural network at a number of points and\nselecting for high measures of local convexity such as $\\mathrm{Tr}(H) /\n||H||$, number of positive eigenvalues of $H$, or low initial loss, leads to\nstatistically significantly faster training on MNIST. Based on our\nobservations, we hypothesize that the Goldilocks zone contains an unusually\nhigh density of suitable initialization configurations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 22:31:53 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 10:29:42 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Fort", "Stanislav", ""], ["Scherlis", "Adam", ""]]}, {"id": "1807.02582", "submitter": "Motonobu Kanagawa", "authors": "Motonobu Kanagawa, Philipp Hennig, Dino Sejdinovic, Bharath K\n  Sriperumbudur", "title": "Gaussian Processes and Kernel Methods: A Review on Connections and\n  Equivalences", "comments": "64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an attempt to bridge the conceptual gaps between researchers\nworking on the two widely used approaches based on positive definite kernels:\nBayesian learning or inference using Gaussian processes on the one side, and\nfrequentist kernel methods based on reproducing kernel Hilbert spaces on the\nother. It is widely known in machine learning that these two formalisms are\nclosely related; for instance, the estimator of kernel ridge regression is\nidentical to the posterior mean of Gaussian process regression. However, they\nhave been studied and developed almost independently by two essentially\nseparate communities, and this makes it difficult to seamlessly transfer\nresults between them. Our aim is to overcome this potential difficulty. To this\nend, we review several old and new results and concepts from either side, and\njuxtapose algorithmic quantities from each framework to highlight close\nsimilarities. We also provide discussions on subtle philosophical and\ntheoretical differences between the two approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 22:44:10 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Kanagawa", "Motonobu", ""], ["Hennig", "Philipp", ""], ["Sejdinovic", "Dino", ""], ["Sriperumbudur", "Bharath K", ""]]}, {"id": "1807.02588", "submitter": "Stanislav Pidhorskyi", "authors": "Stanislav Pidhorskyi, Ranya Almohsen, Donald A Adjeroh, Gianfranco\n  Doretto", "title": "Generative Probabilistic Novelty Detection with Adversarial Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection is the problem of identifying whether a new data point is\nconsidered to be an inlier or an outlier. We assume that training data is\navailable to describe only the inlier distribution. Recent approaches primarily\nleverage deep encoder-decoder network architectures to compute a reconstruction\nerror that is used to either compute a novelty score or to train a one-class\nclassifier. While we too leverage a novel network of that kind, we take a\nprobabilistic approach and effectively compute how likely is that a sample was\ngenerated by the inlier distribution. We achieve this with two main\ncontributions. First, we make the computation of the novelty probability\nfeasible because we linearize the parameterized manifold capturing the\nunderlying structure of the inlier distribution, and show how the probability\nfactorizes and can be computed with respect to local coordinates of the\nmanifold tangent space. Second, we improved the training of the autoencoder\nnetwork. An extensive set of results show that the approach achieves\nstate-of-the-art results on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 23:46:30 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 01:39:29 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Pidhorskyi", "Stanislav", ""], ["Almohsen", "Ranya", ""], ["Adjeroh", "Donald A", ""], ["Doretto", "Gianfranco", ""]]}, {"id": "1807.02599", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Erik Mayer, Sophia N. Yaliraki, Mauricio Barahona", "title": "From Text to Topics in Healthcare Records: An Unsupervised Graph\n  Partitioning Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Healthcare Records contain large volumes of unstructured data,\nincluding extensive free text. Yet this source of detailed information often\nremains under-used because of a lack of methodologies to extract interpretable\ncontent in a timely manner. Here we apply network-theoretical tools to analyse\nfree text in Hospital Patient Incident reports from the National Health\nService, to find clusters of documents with similar content in an unsupervised\nmanner at different levels of resolution. We combine deep neural network\nparagraph vector text-embedding with multiscale Markov Stability community\ndetection applied to a sparsified similarity graph of document vectors, and\nshowcase the approach on incident reports from Imperial College Healthcare NHS\nTrust, London. The multiscale community structure reveals different levels of\nmeaning in the topics of the dataset, as shown by descriptive terms extracted\nfrom the clusters of records. We also compare a posteriori against hand-coded\ncategories assigned by healthcare personnel, and show that our approach\noutperforms LDA-based models. Our content clusters exhibit good correspondence\nwith two levels of hand-coded categories, yet they also provide further medical\ndetail in certain areas and reveal complementary descriptors of incidents\nbeyond the external classification taxonomy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 01:14:10 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1807.02608", "submitter": "Matthew Yung", "authors": "Matthew Yung, Eli T. Brown, Alexander Rasin, Jacob D. Furst, Daniela\n  S. Raicu", "title": "Synthetic Sampling for Multi-Class Malignancy Prediction", "comments": "5 pages, 3 figures, 4 Tables, KDD MLMH'18 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore several oversampling techniques for an imbalanced multi-label\nclassification problem, a setting often encountered when developing models for\nComputer-Aided Diagnosis (CADx) systems. While most CADx systems aim to\noptimize classifiers for overall accuracy without considering the relative\ndistribution of each class, we look into using synthetic sampling to increase\nper-class performance when predicting the degree of malignancy. Using low-level\nimage features and a random forest classifier, we show that using synthetic\noversampling techniques increases the sensitivity of the minority classes by an\naverage of 7.22% points, with as much as a 19.88% point increase in sensitivity\nfor a particular minority class. Furthermore, the analysis of low-level image\nfeature distributions for the synthetic nodules reveals that these nodules can\nprovide insights on how to preprocess image data for better classification\nperformance or how to supplement the original datasets when more data\nacquisition is feasible.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 03:23:08 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Yung", "Matthew", ""], ["Brown", "Eli T.", ""], ["Rasin", "Alexander", ""], ["Furst", "Jacob D.", ""], ["Raicu", "Daniela S.", ""]]}, {"id": "1807.02609", "submitter": "Hankook Lee", "authors": "Hankook Lee, Jinwoo Shin", "title": "Anytime Neural Prediction via Slicing Networks Vertically", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pioneer deep neural networks (DNNs) have emerged to be deeper or wider\nfor improving their accuracy in various applications of artificial\nintelligence. However, DNNs are often too heavy to deploy in practice, and it\nis often required to control their architectures dynamically given computing\nresource budget, i.e., anytime prediction. While most existing approaches have\nfocused on training multiple shallow sub-networks jointly, we study training\nthin sub-networks instead. To this end, we first build many inclusive thin\nsub-networks (of the same depth) under a minor modification of existing\nmulti-branch DNNs, and found that they can significantly outperform the\nstate-of-art dense architecture for anytime prediction. This is remarkable due\nto their simplicity and effectiveness, but training many thin sub-networks\njointly faces a new challenge on training complexity. To address the issue, we\nalso propose a novel DNN architecture by forcing a certain sparsity pattern on\nmulti-branch network parameters, making them train efficiently for the purpose\nof anytime prediction. In our experiments on the ImageNet dataset, its\nsub-networks have up to $43.3\\%$ smaller sizes (FLOPs) compared to those of the\nstate-of-art anytime model with respect to the same accuracy. Finally, we also\npropose an alternative task under the proposed architecture using a\nhierarchical taxonomy, which brings a new angle for anytime prediction.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 03:55:26 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Lee", "Hankook", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1807.02612", "submitter": "Muhammad Yousefnezhad", "authors": "Tonglin Xu, Muhammad Yousefnezhad, Daoqiang Zhang", "title": "Gradient Hyperalignment for multi-subject fMRI data alignment", "comments": "15th Pacific Rim International Conference on Artificial Intelligence\n  (PRICAI 2018), Nanjing, China, August 28-31, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-subject fMRI data analysis is an interesting and challenging problem in\nhuman brain decoding studies. The inherent anatomical and functional\nvariability across subjects make it necessary to do both anatomical and\nfunctional alignment before classification analysis. Besides, when it comes to\nbig data, time complexity becomes a problem that cannot be ignored. This paper\nproposes Gradient Hyperalignment (Gradient-HA) as a gradient-based functional\nalignment method that is suitable for multi-subject fMRI datasets with large\namounts of samples and voxels. The advantage of Gradient-HA is that it can\nsolve independence and high dimension problems by using Independent Component\nAnalysis (ICA) and Stochastic Gradient Ascent (SGA). Validation using\nmulti-classification tasks on big data demonstrates that Gradient-HA method has\nless time complexity and better or comparable performance compared with other\nstate-of-the-art functional alignment methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 05:02:04 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Xu", "Tonglin", ""], ["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1807.02617", "submitter": "Jos\\'e Carlos Pulido Pascual", "authors": "David Goodfellow, Ruoyu Zhi, Rebecca Funke, Jose Carlos Pulido, Maja\n  Mataric and Beth A. Smith", "title": "Predicting Infant Motor Development Status using Day Long Movement Data\n  from Wearable Sensors", "comments": "4 pages, KDD Machine Learning and Healthcare Workshop August 2018.\n  This work was funded in part by the American Physical Therapy Association\n  Academy of Pediatric Physical Therapy Research Grant 1 and 2 Awards (PI:\n  Smith) and in part by NSF award 1706964 (PI: Smith, Co-PI: Matari\\'c)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infants with a variety of complications at or before birth are classified as\nbeing at risk for developmental delays (AR). As they grow older, they are\nfollowed by healthcare providers in an effort to discern whether they are on a\ntypical or impaired developmental trajectory. Often, it is difficult to make an\naccurate determination early in infancy as infants with typical development\n(TD) display high variability in their developmental trajectories both in\ncontent and timing. Studies have shown that spontaneous movements have the\npotential to differentiate typical and atypical trajectories early in life\nusing sensors and kinematic analysis systems. In this study, machine learning\nclassification algorithms are used to take inertial movement from wearable\nsensors placed on an infant for a day and predict if the infant is AR or TD,\nthus further establishing the connection between early spontaneous movement and\ndevelopmental trajectory.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 05:53:17 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 13:11:03 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Goodfellow", "David", ""], ["Zhi", "Ruoyu", ""], ["Funke", "Rebecca", ""], ["Pulido", "Jose Carlos", ""], ["Mataric", "Maja", ""], ["Smith", "Beth A.", ""]]}, {"id": "1807.02629", "submitter": "Panayotis Mertikopoulos", "authors": "Panayotis Mertikopoulos and Bruno Lecouat and Houssam Zenati and\n  Chuan-Sheng Foo and Vijay Chandrasekhar and Georgios Piliouras", "title": "Optimistic mirror descent in saddle-point problems: Going the extra\n  (gradient) mile", "comments": "26 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to their connection with generative adversarial networks (GANs),\nsaddle-point problems have recently attracted considerable interest in machine\nlearning and beyond. By necessity, most theoretical guarantees revolve around\nconvex-concave (or even linear) problems; however, making theoretical inroads\ntowards efficient GAN training depends crucially on moving beyond this classic\nframework. To make piecemeal progress along these lines, we analyze the\nbehavior of mirror descent (MD) in a class of non-monotone problems whose\nsolutions coincide with those of a naturally associated variational inequality\n- a property which we call coherence. We first show that ordinary, \"vanilla\" MD\nconverges under a strict version of this condition, but not otherwise; in\nparticular, it may fail to converge even in bilinear models with a unique\nsolution. We then show that this deficiency is mitigated by optimism: by taking\nan \"extra-gradient\" step, optimistic mirror descent (OMD) converges in all\ncoherent problems. Our analysis generalizes and extends the results of\nDaskalakis et al. (2018) for optimistic gradient descent (OGD) in bilinear\nproblems, and makes concrete headway for establishing convergence beyond\nconvex-concave games. We also provide stochastic analogues of these results,\nand we validate our analysis by numerical experiments in a wide array of GAN\nmodels (including Gaussian mixture models, as well as the CelebA and CIFAR-10\ndatasets).\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 08:08:33 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 23:11:31 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Mertikopoulos", "Panayotis", ""], ["Lecouat", "Bruno", ""], ["Zenati", "Houssam", ""], ["Foo", "Chuan-Sheng", ""], ["Chandrasekhar", "Vijay", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1807.02653", "submitter": "Wenting Zhao", "authors": "Wenting Zhao, Chunyan Xu, Zhen Cui, Tong Zhang, Jiatao Jiang, Zhenyu\n  Zhang, Jian Yang", "title": "When Work Matters: Transforming Classical Network Structures to Graph\n  CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous pattern recognition applications can be formed as learning from\ngraph-structured data, including social network, protein-interaction network,\nthe world wide web data, knowledge graph, etc. While convolutional neural\nnetwork (CNN) facilitates great advances in gridded image/video understanding\ntasks, very limited attention has been devoted to transform these successful\nnetwork structures (including Inception net, Residual net, Dense net, etc.) to\nestablish convolutional networks on graph, due to its irregularity and\ncomplexity geometric topologies (unordered vertices, unfixed number of adjacent\nedges/vertices). In this paper, we aim to give a comprehensive analysis of when\nwork matters by transforming different classical network structures to graph\nCNN, particularly in the basic graph recognition problem. Specifically, we\nfirstly review the general graph CNN methods, especially in its spectral\nfiltering operation on the irregular graph data. We then introduce the basic\nstructures of ResNet, Inception and DenseNet into graph CNN and construct these\nnetwork structures on graph, named as G_ResNet, G_Inception, G_DenseNet. In\nparticular, it seeks to help graph CNNs by shedding light on how these\nclassical network structures work and providing guidelines for choosing\nappropriate graph network frameworks. Finally, we comprehensively evaluate the\nperformance of these different network structures on several public graph\ndatasets (including social networks and bioinformatic datasets), and\ndemonstrate how different network structures work on graph CNN in the graph\nrecognition task.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 12:12:38 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Zhao", "Wenting", ""], ["Xu", "Chunyan", ""], ["Cui", "Zhen", ""], ["Zhang", "Tong", ""], ["Jiang", "Jiatao", ""], ["Zhang", "Zhenyu", ""], ["Yang", "Jian", ""]]}, {"id": "1807.02658", "submitter": "J\\\"org Franke", "authors": "J\\\"org Franke, Jan Niehues, Alex Waibel", "title": "Robust and Scalable Differentiable Neural Computer for Question\n  Answering", "comments": "Accepted at Workshop on Machine Reading for Question Answering\n  (MRQA), ACL 2018. 14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are often not easily adaptable to new tasks and require\ntask-specific adjustments. The differentiable neural computer (DNC), a\nmemory-augmented neural network, is designed as a general problem solver which\ncan be used in a wide range of tasks. But in reality, it is hard to apply this\nmodel to new tasks. We analyze the DNC and identify possible improvements\nwithin the application of question answering. This motivates a more robust and\nscalable DNC (rsDNC). The objective precondition is to keep the general\ncharacter of this model intact while making its application more reliable and\nspeeding up its required training time. The rsDNC is distinguished by a more\nrobust training, a slim memory unit and a bidirectional architecture. We not\nonly achieve new state-of-the-art performance on the bAbI task, but also\nminimize the performance variance between different initializations.\nFurthermore, we demonstrate the simplified applicability of the rsDNC to new\ntasks with passable results on the CNN RC task without adaptions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 12:44:32 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Franke", "J\u00f6rg", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1807.02682", "submitter": "Ramanarayan Mohanty", "authors": "Ramanarayan Mohanty, S L Happy and Aurobinda Routray", "title": "A Supervised Geometry-Aware Mapping Approach for Classification of\n  Hyperspectral Images", "comments": null, "journal-ref": "IEEE Geoscience and Remote Sensing Letters, Volume-15, Issue-4,\n  Pages-582-586, 27 February 2018", "doi": "10.1109/LGRS.2018.2804888", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of proper class discrimination among the Hyperspectral (HS) data\npoints poses a potential challenge in HS classification. To address this issue,\nthis paper proposes an optimal geometry-aware transformation for enhancing the\nclassification accuracy. The underlying idea of this method is to obtain a\nlinear projection matrix by solving a nonlinear objective function based on the\nintrinsic geometrical structure of the data. The objective function is\nconstructed to quantify the discrimination between the points from dissimilar\nclasses on the projected data space. Then the obtained projection matrix is\nused to linearly map the data to more discriminative space. The effectiveness\nof the proposed transformation is illustrated with three benchmark real-world\nHS data sets. The experiments reveal that the classification and dimensionality\nreduction methods on the projected discriminative space outperform their\ncounterpart in the original space.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 15:57:50 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Mohanty", "Ramanarayan", ""], ["Happy", "S L", ""], ["Routray", "Aurobinda", ""]]}, {"id": "1807.02684", "submitter": "Nabil Ibtehaz", "authors": "Nabil Ibtehaz, M. Saifur Rahman, M. Sohel Rahman", "title": "VFPred: A Fusion of Signal Processing and Machine Learning techniques in\n  Detecting Ventricular Fibrillation from ECG Signals", "comments": null, "journal-ref": null, "doi": "10.1016/j.bspc.2018.12.016", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ventricular Fibrillation (VF), one of the most dangerous arrhythmias, is\nresponsible for sudden cardiac arrests. Thus, various algorithms have been\ndeveloped to predict VF from Electrocardiogram (ECG), which is a binary\nclassification problem. In the literature, we find a number of algorithms based\non signal processing, where, after some robust mathematical operations the\ndecision is given based on a predefined threshold over a single value. On the\nother hand, some machine learning based algorithms are also reported in the\nliterature; however, these algorithms merely combine some parameters and make a\nprediction using those as features. Both the approaches have their perks and\npitfalls; thus our motivation was to coalesce them to get the best out of the\nboth worlds. Hence we have developed, VFPred that, in addition to employing a\nsignal processing pipeline, namely, Empirical Mode Decomposition and Discrete\nTime Fourier Transform for useful feature extraction, uses a Support Vector\nMachine for efficient classification. VFPred turns out to be a robust algorithm\nas it is able to successfully segregate the two classes with equal confidence\n(Sensitivity = 99.99%, Specificity = 98.40%) even from a short signal of 5\nseconds long, whereas existing works though requires longer signals, flourishes\nin one but fails in the other.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 16:09:40 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 11:48:41 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 19:04:22 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Ibtehaz", "Nabil", ""], ["Rahman", "M. Saifur", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "1807.02694", "submitter": "Shuaiwen Wang", "authors": "Shuaiwen Wang, Wenda Zhou, Haihao Lu, Arian Maleki, Vahab Mirrokni", "title": "Approximate Leave-One-Out for Fast Parameter Tuning in High Dimensions", "comments": "The paper is published on ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following class of learning schemes: $$\\hat{\\boldsymbol{\\beta}}\n:= \\arg\\min_{\\boldsymbol{\\beta}}\\;\\sum_{j=1}^n\n\\ell(\\boldsymbol{x}_j^\\top\\boldsymbol{\\beta}; y_j) + \\lambda\nR(\\boldsymbol{\\beta}),\\qquad\\qquad (1) $$ where $\\boldsymbol{x}_i \\in\n\\mathbb{R}^p$ and $y_i \\in \\mathbb{R}$ denote the $i^{\\text{th}}$ feature and\nresponse variable respectively. Let $\\ell$ and $R$ be the loss function and\nregularizer, $\\boldsymbol{\\beta}$ denote the unknown weights, and $\\lambda$ be\na regularization parameter. Finding the optimal choice of $\\lambda$ is a\nchallenging problem in high-dimensional regimes where both $n$ and $p$ are\nlarge. We propose two frameworks to obtain a computationally efficient\napproximation ALO of the leave-one-out cross validation (LOOCV) risk for\nnonsmooth losses and regularizers. Our two frameworks are based on the primal\nand dual formulations of (1). We prove the equivalence of the two approaches\nunder smoothness conditions. This equivalence enables us to justify the\naccuracy of both methods under such conditions. We use our approaches to obtain\na risk estimate for several standard problems, including generalized LASSO,\nnuclear norm regularization, and support vector machines. We empirically\ndemonstrate the effectiveness of our results for non-differentiable cases.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 17:00:24 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wang", "Shuaiwen", ""], ["Zhou", "Wenda", ""], ["Lu", "Haihao", ""], ["Maleki", "Arian", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1807.02701", "submitter": "Alireza Vafaei Sadr", "authors": "A. Vafaei Sadr, Etienne. E. Vos, Bruce A. Bassett, Zafiirah Hosenie,\n  N. Oozeer, Michelle Lochner", "title": "DeepSource: Point Source Detection using Deep Learning", "comments": "15 pages, 13 figures, submitted to MNRAS", "journal-ref": "MNRAS, Volume 484, Issue 2, April 2019, Pages 2793-2806", "doi": "10.1093/mnras/stz131", "report-no": null, "categories": "astro-ph.IM cs.CV cs.LG hep-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Point source detection at low signal-to-noise is challenging for astronomical\nsurveys, particularly in radio interferometry images where the noise is\ncorrelated. Machine learning is a promising solution, allowing the development\nof algorithms tailored to specific telescope arrays and science cases. We\npresent DeepSource - a deep learning solution - that uses convolutional neural\nnetworks to achieve these goals. DeepSource enhances the Signal-to-Noise Ratio\n(SNR) of the original map and then uses dynamic blob detection to detect\nsources. Trained and tested on two sets of 500 simulated 1 deg x 1 deg MeerKAT\nimages with a total of 300,000 sources, DeepSource is essentially perfect in\nboth purity and completeness down to SNR = 4 and outperforms PyBDSF in all\nmetrics. For uniformly-weighted images it achieves a Purity x Completeness (PC)\nscore at SNR = 3 of 0.73, compared to 0.31 for the best PyBDSF model. For\nnatural-weighting we find a smaller improvement of ~40% in the PC score at SNR\n= 3. If instead we ask where either of the purity or completeness first drop to\n90%, we find that DeepSource reaches this value at SNR = 3.6 compared to the\n4.3 of PyBDSF (natural-weighting). A key advantage of DeepSource is that it can\nlearn to optimally trade off purity and completeness for any science case under\nconsideration. Our results show that deep learning is a promising approach to\npoint source detection in astronomical images.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 18:00:07 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Sadr", "A. Vafaei", ""], ["Vos", "Etienne. E.", ""], ["Bassett", "Bruce A.", ""], ["Hosenie", "Zafiirah", ""], ["Oozeer", "N.", ""], ["Lochner", "Michelle", ""]]}, {"id": "1807.02710", "submitter": "Stefan Uhlich", "authors": "Joachim Muth, Stefan Uhlich, Nathanael Perraudin, Thomas Kemp, Fabien\n  Cardinaux, Yuki Mitsufuji", "title": "Improving DNN-based Music Source Separation using Phase Features", "comments": "7 pages, 9 figures, Joint Workshop on Machine Learning for Music at\n  ICML, IJCAI/ECAI and AAMAS, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music source separation with deep neural networks typically relies only on\namplitude features. In this paper we show that additional phase features can\nimprove the separation performance. Using the theoretical relationship between\nSTFT phase and amplitude, we conjecture that derivatives of the phase are a\ngood feature representation opposed to the raw phase. We verify this conjecture\nexperimentally and propose a new DNN architecture which combines amplitude and\nphase. This joint approach achieves a better signal-to distortion ratio on the\nDSD100 dataset for all instruments compared to a network that uses only\namplitude features. Especially, the bass instrument benefits from the phase\ninformation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 19:02:36 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 06:57:00 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 06:09:41 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Muth", "Joachim", ""], ["Uhlich", "Stefan", ""], ["Perraudin", "Nathanael", ""], ["Kemp", "Thomas", ""], ["Cardinaux", "Fabien", ""], ["Mitsufuji", "Yuki", ""]]}, {"id": "1807.02716", "submitter": "Yimin Liu", "authors": "Yimin Liu, Wenyue Sun, Louis J. Durlofsky", "title": "A Deep-Learning-Based Geological Parameterization for History Matching\n  Complex Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new low-dimensional parameterization based on principal component analysis\n(PCA) and convolutional neural networks (CNN) is developed to represent complex\ngeological models. The CNN-PCA method is inspired by recent developments in\ncomputer vision using deep learning. CNN-PCA can be viewed as a generalization\nof an existing optimization-based PCA (O-PCA) method. Both CNN-PCA and O-PCA\nentail post-processing a PCA model to better honor complex geological features.\nIn CNN-PCA, rather than use a histogram-based regularization as in O-PCA, a new\nregularization involving a set of metrics for multipoint statistics is\nintroduced. The metrics are based on summary statistics of the nonlinear filter\nresponses of geological models to a pre-trained deep CNN. In addition, in the\nCNN-PCA formulation presented here, a convolutional neural network is trained\nas an explicit transform function that can post-process PCA models quickly.\nCNN-PCA is shown to provide both unconditional and conditional realizations\nthat honor the geological features present in reference SGeMS geostatistical\nrealizations for a binary channelized system. Flow statistics obtained through\nsimulation of random CNN-PCA models closely match results for random SGeMS\nmodels for a demanding case in which O-PCA models lead to significant\ndiscrepancies. Results for history matching are also presented. In this\nassessment CNN-PCA is applied with derivative-free optimization, and a subspace\nrandomized maximum likelihood method is used to provide multiple posterior\nmodels. Data assimilation and significant uncertainty reduction are achieved\nfor existing wells, and physically reasonable predictions are also obtained for\nnew wells. Finally, the CNN-PCA method is extended to a more complex\nnon-stationary bimodal deltaic fan system, and is shown to provide high-quality\nrealizations for this challenging example.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 20:34:04 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Liu", "Yimin", ""], ["Sun", "Wenyue", ""], ["Durlofsky", "Louis J.", ""]]}, {"id": "1807.02740", "submitter": "Wentai Zhang", "authors": "Wentai Zhang, Haoliang Jiang, Zhangsihao Yang, Soji Yamakawa, Kenji\n  Shimada, Levent Burak Kara", "title": "Data-driven Upsampling of Point Clouds", "comments": "Preprint submitted to CAD", "journal-ref": "Computer-Aided Design, Volume 112, Pages 1-13, 2019", "doi": "10.1016/j.cad.2019.02.006.", "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality upsampling of sparse 3D point clouds is critically useful for a\nwide range of geometric operations such as reconstruction, rendering, meshing,\nand analysis. In this paper, we propose a data-driven algorithm that enables an\nupsampling of 3D point clouds without the need for hard-coded rules. Our\napproach uses a deep network with Chamfer distance as the loss function,\ncapable of learning the latent features in point clouds belonging to different\nobject categories. We evaluate our algorithm across different amplification\nfactors, with upsampling learned and performed on objects belonging to the same\ncategory as well as different categories. We also explore the desirable\ncharacteristics of input point clouds as a function of the distribution of the\npoint samples. Finally, we demonstrate the performance of our algorithm in\nsingle-category training versus multi-category training scenarios. The final\nproposed model is compared against a baseline, optimization-based upsampling\nmethod. Results indicate that our algorithm is capable of generating more\nuniform and accurate upsamplings.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 02:19:09 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 03:49:16 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Wentai", ""], ["Jiang", "Haoliang", ""], ["Yang", "Zhangsihao", ""], ["Yamakawa", "Soji", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1807.02787", "submitter": "Chien Yi Huang", "authors": "Chien Yi Huang", "title": "Financial Trading as a Game: A Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automatic program that generates constant profit from the financial market\nis lucrative for every market practitioner. Recent advance in deep\nreinforcement learning provides a framework toward end-to-end training of such\ntrading agent. In this paper, we propose an Markov Decision Process (MDP) model\nsuitable for the financial trading task and solve it with the state-of-the-art\ndeep recurrent Q-network (DRQN) algorithm. We propose several modifications to\nthe existing learning algorithm to make it more suitable under the financial\ntrading setting, namely 1. We employ a substantially small replay memory (only\na few hundreds in size) compared to ones used in modern deep reinforcement\nlearning algorithms (often millions in size.) 2. We develop an action\naugmentation technique to mitigate the need for random exploration by providing\nextra feedback signals for all actions to the agent. This enables us to use\ngreedy policy over the course of learning and shows strong empirical\nperformance compared to more commonly used epsilon-greedy exploration. However,\nthis technique is specific to financial trading under a few market assumptions.\n3. We sample a longer sequence for recurrent neural network training. A side\nproduct of this mechanism is that we can now train the agent for every T steps.\nThis greatly reduces training time since the overall computation is down by a\nfactor of T. We combine all of the above into a complete online learning\nalgorithm and validate our approach on the spot foreign exchange market.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 09:17:09 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Huang", "Chien Yi", ""]]}, {"id": "1807.02795", "submitter": "Jiyang Xie", "authors": "Jiyang Xie, Zhanyu Ma, Guoqiang Zhang, Jing-Hao Xue, Jen-Tzung Chien,\n  Zhiqing Lin, Jun Guo", "title": "BALSON: Bayesian Least Squares Optimization with Nonnegative L1-Norm\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian approach termed BAyesian Least Squares Optimization with\nNonnegative L1-norm constraint (BALSON) is proposed. The error distribution of\ndata fitting is described by Gaussian likelihood. The parameter distribution is\nassumed to be a Dirichlet distribution. With the Bayes rule, searching for the\noptimal parameters is equivalent to finding the mode of the posterior\ndistribution. In order to explicitly characterize the nonnegative L1-norm\nconstraint of the parameters, we further approximate the true posterior\ndistribution by a Dirichlet distribution. We estimate the statistics of the\napproximating Dirichlet posterior distribution by sampling methods. Four\nsampling methods have been introduced. With the estimated posterior\ndistributions, the original parameters can be effectively reconstructed in\npolynomial fitting problems, and the BALSON framework is found to perform\nbetter than conventional methods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 10:11:44 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Xie", "Jiyang", ""], ["Ma", "Zhanyu", ""], ["Zhang", "Guoqiang", ""], ["Xue", "Jing-Hao", ""], ["Chien", "Jen-Tzung", ""], ["Lin", "Zhiqing", ""], ["Guo", "Jun", ""]]}, {"id": "1807.02799", "submitter": "Haseeb Shah", "authors": "Haseeb Shah, Khurram Javed and Faisal Shafait", "title": "Distillation Techniques for Pseudo-rehearsal Based Incremental Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn from incrementally arriving data is essential for any\nlife-long learning system. However, standard deep neural networks forget the\nknowledge about the old tasks, a phenomenon called catastrophic forgetting,\nwhen trained on incrementally arriving data. We discuss the biases in current\nGenerative Adversarial Networks (GAN) based approaches that learn the\nclassifier by knowledge distillation from previously trained classifiers. These\nbiases cause the trained classifier to perform poorly. We propose an approach\nto remove these biases by distilling knowledge from the classifier of AC-GAN.\nExperiments on MNIST and CIFAR10 show that this method is comparable to current\nstate of the art rehearsal based approaches. The code for this paper is\navailable at https://bit.ly/incremental-learning\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 11:01:00 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 09:46:50 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 08:05:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Shah", "Haseeb", ""], ["Javed", "Khurram", ""], ["Shafait", "Faisal", ""]]}, {"id": "1807.02802", "submitter": "Khurram Javed Mr", "authors": "Khurram Javed and Faisal Shafait", "title": "Revisiting Distillation and Incremental Classifier Learning", "comments": "16 pages, 5 figures, open-source, pytorch, ACCV18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key differences between the learning mechanism of humans and\nArtificial Neural Networks (ANNs) is the ability of humans to learn one task at\na time. ANNs, on the other hand, can only learn multiple tasks simultaneously.\nAny attempts at learning new tasks incrementally cause them to completely\nforget about previous tasks. This lack of ability to learn incrementally,\ncalled Catastrophic Forgetting, is considered a major hurdle in building a true\nAI system. In this paper, our goal is to isolate the truly effective existing\nideas for incremental learning from those that only work under certain\nconditions. To this end, we first thoroughly analyze the current state of the\nart (iCaRL) method for incremental learning and demonstrate that the good\nperformance of the system is not because of the reasons presented in the\nexisting literature. We conclude that the success of iCaRL is primarily due to\nknowledge distillation and recognize a key limitation of knowledge\ndistillation, i.e, it often leads to bias in classifiers. Finally, we propose a\ndynamic threshold moving algorithm that is able to successfully remove this\nbias. We demonstrate the effectiveness of our algorithm on CIFAR100 and MNIST\ndatasets showing near-optimal results. Our implementation is available at\nhttps://github.com/Khurramjaved96/incremental-learning.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 11:42:31 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 16:24:50 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Javed", "Khurram", ""], ["Shafait", "Faisal", ""]]}, {"id": "1807.02811", "submitter": "Peter Frazier", "authors": "Peter I. Frazier", "title": "A Tutorial on Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is an approach to optimizing objective functions that\ntake a long time (minutes or hours) to evaluate. It is best-suited for\noptimization over continuous domains of less than 20 dimensions, and tolerates\nstochastic noise in function evaluations. It builds a surrogate for the\nobjective and quantifies the uncertainty in that surrogate using a Bayesian\nmachine learning technique, Gaussian process regression, and then uses an\nacquisition function defined from this surrogate to decide where to sample. In\nthis tutorial, we describe how Bayesian optimization works, including Gaussian\nprocess regression and three common acquisition functions: expected\nimprovement, entropy search, and knowledge gradient. We then discuss more\nadvanced techniques, including running multiple function evaluations in\nparallel, multi-fidelity and multi-information source optimization,\nexpensive-to-evaluate constraints, random environmental conditions, multi-task\nBayesian optimization, and the inclusion of derivative information. We conclude\nwith a discussion of Bayesian optimization software and future research\ndirections in the field. Within our tutorial material we provide a\ngeneralization of expected improvement to noisy evaluations, beyond the\nnoise-free setting where it is more commonly applied. This generalization is\njustified by a formal decision-theoretic argument, standing in contrast to\nprevious ad hoc modifications.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 13:06:26 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Frazier", "Peter I.", ""]]}, {"id": "1807.02816", "submitter": "The-Hien Dang-Ha", "authors": "The-Hien Dang-Ha", "title": "Improving Deep Learning through Automatic Programming", "comments": "Master's thesis (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning and deep architectures are emerging as the best machine\nlearning methods so far in many practical applications such as reducing the\ndimensionality of data, image classification, speech recognition or object\nsegmentation. In fact, many leading technology companies such as Google,\nMicrosoft or IBM are researching and using deep architectures in their systems\nto replace other traditional models. Therefore, improving the performance of\nthese models could make a strong impact in the area of machine learning.\nHowever, deep learning is a very fast-growing research domain with many core\nmethodologies and paradigms just discovered over the last few years. This\nthesis will first serve as a short summary of deep learning, which tries to\ninclude all of the most important ideas in this research area. Based on this\nknowledge, we suggested, and conducted some experiments to investigate the\npossibility of improving the deep learning based on automatic programming\n(ADATE). Although our experiments did produce good results, there are still\nmany more possibilities that we could not try due to limited time as well as\nsome limitations of the current ADATE version. I hope that this thesis can\npromote future work on this topic, especially when the next version of ADATE\ncomes out. This thesis also includes a short analysis of the power of ADATE\nsystem, which could be useful for other researchers who want to know what it is\ncapable of.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 13:38:21 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Dang-Ha", "The-Hien", ""]]}, {"id": "1807.02839", "submitter": "Anjan Dutta", "authors": "Anjan Dutta, Pau Riba, Josep Llad\\'os, Alicia Forn\\'es", "title": "Hierarchical stochastic graphlet embedding for graph-based pattern\n  recognition", "comments": "In Neural Computing and Applications (17 pages, 5 figures, 6 tables)", "journal-ref": null, "doi": "10.1007/s00521-019-04642-7", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being very successful within the pattern recognition and machine\nlearning community, graph-based methods are often unusable because of the lack\nof mathematical operations defined in graph domain. Graph embedding, which maps\ngraphs to a vectorial space, has been proposed as a way to tackle these\ndifficulties enabling the use of standard machine learning techniques. However,\nit is well known that graph embedding functions usually suffer from the loss of\nstructural information. In this paper, we consider the hierarchical structure\nof a graph as a way to mitigate this loss of information. The hierarchical\nstructure is constructed by topologically clustering the graph nodes, and\nconsidering each cluster as a node in the upper hierarchical level. Once this\nhierarchical structure is constructed, we consider several configurations to\ndefine the mapping into a vector space given a classical graph embedding, in\nparticular, we propose to make use of the Stochastic Graphlet Embedding (SGE).\nBroadly speaking, SGE produces a distribution of uniformly sampled low to high\norder graphlets as a way to embed graphs into the vector space. In what\nfollows, the coarse-to-fine structure of a graph hierarchy and the statistics\nfetched by the SGE complements each other and includes important structural\ninformation with varied contexts. Altogether, these two techniques\nsubstantially cope with the usual information loss involved in graph embedding\ntechniques, obtaining a more robust graph representation. This fact has been\ncorroborated through a detailed experimental evaluation on various benchmark\ngraph datasets, where we outperform the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 15:33:22 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 17:37:12 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dutta", "Anjan", ""], ["Riba", "Pau", ""], ["Llad\u00f3s", "Josep", ""], ["Forn\u00e9s", "Alicia", ""]]}, {"id": "1807.02854", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Bernt Andrassy and Hinrich Sch\\\"utze", "title": "Replicated Siamese LSTM in Ticketing System for Similarity Learning and\n  Retrieval in Asymmetric Texts", "comments": "In the 27th International Conference on Computational Linguistics\n  (COLING 2018) workshop on Semantic Deep Learning (SemDeep-3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of our industrial ticketing system is to retrieve a relevant\nsolution for an input query, by matching with historical tickets stored in\nknowledge base. A query is comprised of subject and description, while a\nhistorical ticket consists of subject, description and solution. To retrieve a\nrelevant solution, we use textual similarity paradigm to learn similarity in\nthe query and historical tickets. The task is challenging due to significant\nterm mismatch in the query and ticket pairs of asymmetric lengths, where\nsubject is a short text but description and solution are multi-sentence texts.\nWe present a novel Replicated Siamese LSTM model to learn similarity in\nasymmetric text pairs, that gives 22% and 7% gain (Accuracy@10) for retrieval\ntask, respectively over unsupervised and supervised baselines. We also show\nthat the topic and distributed semantic features for short and long texts\nimproved both similarity learning and retrieval.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 17:33:43 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Andrassy", "Bernt", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1807.02857", "submitter": "Pushparaja Murugan", "authors": "Pushparaja Murugan", "title": "Learning The Sequential Temporal Information with Recurrent Neural\n  Networks", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recurrent Networks are one of the most powerful and promising artificial\nneural network algorithms to processing the sequential data such as natural\nlanguages, sound, time series data. Unlike traditional feed-forward network,\nRecurrent Network has a inherent feed back loop that allows to store the\ntemporal context information and pass the state of information to the entire\nsequences of the events. This helps to achieve the state of art performance in\nmany important tasks such as language modeling, stock market prediction, image\ncaptioning, speech recognition, machine translation and object tracking etc.,\nHowever, training the fully connected RNN and managing the gradient flow are\nthe complicated process. Many studies are carried out to address the mentioned\nlimitation. This article is intent to provide the brief details about recurrent\nneurons, its variances and trips & tricks to train the fully recurrent neural\nnetwork. This review work is carried out as a part of our IPO studio software\nmodule 'Multiple Object Tracking'.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 17:57:27 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Murugan", "Pushparaja", ""]]}, {"id": "1807.02872", "submitter": "Yong Wang", "authors": "Yong Wang, Xiao-Ming Wu, Qimai Li, Jiatao Gu, Wangmeng Xiang, Lei\n  Zhang, Victor O.K. Li", "title": "Large Margin Few-Shot Learning", "comments": "17 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key issue of few-shot learning is learning to generalize. This paper\nproposes a large margin principle to improve the generalization capacity of\nmetric based methods for few-shot learning. To realize it, we develop a unified\nframework to learn a more discriminative metric space by augmenting the\nclassification loss function with a large margin distance loss function for\ntraining. Extensive experiments on two state-of-the-art few-shot learning\nmethods, graph neural networks and prototypical networks, show that our method\ncan improve the performance of existing models substantially with very little\ncomputational overhead, demonstrating the effectiveness of the large margin\nprinciple and the potential of our method.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 19:44:31 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 06:39:48 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Wang", "Yong", ""], ["Wu", "Xiao-Ming", ""], ["Li", "Qimai", ""], ["Gu", "Jiatao", ""], ["Xiang", "Wangmeng", ""], ["Zhang", "Lei", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1807.02873", "submitter": "Wlodzislaw Duch", "authors": "Wlodzislaw Duch", "title": "Separability is not the best goal for machine learning", "comments": "Extension of a conference paper on k-separability idea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks use their hidden layers to transform input data into linearly\nseparable data clusters, with a linear or a perceptron type output layer making\nthe final projection on the line perpendicular to the discriminating\nhyperplane. For complex data with multimodal distributions this transformation\nis difficult to learn. Projection on $k\\geq 2$ line segments is the simplest\nextension of linear separability, defining much easier goal for the learning\nprocess. Simple problems are 2-separable, but problems with inherent complex\nlogic may be solved in a simple way by $k$-separable projections. The\ndifficulty of learning non-linear data distributions is shifted to separation\nof line intervals, simplifying the transformation of data by hidden network\nlayers. For classification of difficult Boolean problems, such as the parity\nproblem, linear projection combined with \\ksep is sufficient and provides a\npowerful new target for learning. More complex targets may also be defined,\nchanging the goal of learning from linear discrimination to creation of data\ndistributions that can easily be handled by specialized models selected to\nanalyze output distributions. This approach can replace many layers of\ntransformation required by deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 19:53:58 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Duch", "Wlodzislaw", ""]]}, {"id": "1807.02876", "submitter": "Sergei Gleyzer", "authors": "Kim Albertsson, Piero Altoe, Dustin Anderson, John Anderson, Michael\n  Andrews, Juan Pedro Araque Espinosa, Adam Aurisano, Laurent Basara, Adrian\n  Bevan, Wahid Bhimji, Daniele Bonacorsi, Bjorn Burkle, Paolo Calafiura, Mario\n  Campanelli, Louis Capps, Federico Carminati, Stefano Carrazza, Yi-fan Chen,\n  Taylor Childers, Yann Coadou, Elias Coniavitis, Kyle Cranmer, Claire David,\n  Douglas Davis, Andrea De Simone, Javier Duarte, Martin Erdmann, Jonas Eschle,\n  Amir Farbin, Matthew Feickert, Nuno Filipe Castro, Conor Fitzpatrick, Michele\n  Floris, Alessandra Forti, Jordi Garra-Tico, Jochen Gemmler, Maria Girone,\n  Paul Glaysher, Sergei Gleyzer, Vladimir Gligorov, Tobias Golling, Jonas Graw,\n  Lindsey Gray, Dick Greenwood, Thomas Hacker, John Harvey, Benedikt Hegner,\n  Lukas Heinrich, Ulrich Heintz, Ben Hooberman, Johannes Junggeburth, Michael\n  Kagan, Meghan Kane, Konstantin Kanishchev, Przemys{\\l}aw Karpi\\'nski, Zahari\n  Kassabov, Gaurav Kaul, Dorian Kcira, Thomas Keck, Alexei Klimentov, Jim\n  Kowalkowski, Luke Kreczko, Alexander Kurepin, Rob Kutschke, Valentin\n  Kuznetsov, Nicolas K\\\"ohler, Igor Lakomov, Kevin Lannon, Mario Lassnig,\n  Antonio Limosani, Gilles Louppe, Aashrita Mangu, Pere Mato, Narain Meenakshi,\n  Helge Meinhard, Dario Menasce, Lorenzo Moneta, Seth Moortgat, Mark Neubauer,\n  Harvey Newman, Sydney Otten, Hans Pabst, Michela Paganini, Manfred Paulini,\n  Gabriel Perdue, Uzziel Perez, Attilio Picazio, Jim Pivarski, Harrison\n  Prosper, Fernanda Psihas, Alexander Radovic, Ryan Reece, Aurelius\n  Rinkevicius, Eduardo Rodrigues, Jamal Rorie, David Rousseau, Aaron Sauers,\n  Steven Schramm, Ariel Schwartzman, Horst Severini, Paul Seyfert, Filip\n  Siroky, Konstantin Skazytkin, Mike Sokoloff, Graeme Stewart, Bob Stienen, Ian\n  Stockdale, Giles Strong, Wei Sun, Savannah Thais, Karen Tomko, Eli Upfal,\n  Emanuele Usai, Andrey Ustyuzhanin, Martin Vala, Justin Vasel, Sofia\n  Vallecorsa, Mauro Verzetti, Xavier Vilas\\'is-Cardona, Jean-Roch Vlimant,\n  Ilija Vukotic, Sean-Jiun Wang, Gordon Watts, Michael Williams, Wenjing Wu,\n  Stefan Wunsch, Kun Yang, Omar Zapata", "title": "Machine Learning in High Energy Physics Community White Paper", "comments": "Editors: Sergei Gleyzer, Paul Seyfert and Steven Schramm", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been applied to several problems in particle physics\nresearch, beginning with applications to high-level physics analysis in the\n1990s and 2000s, followed by an explosion of applications in particle and event\nidentification and reconstruction in the 2010s. In this document we discuss\npromising future research and development areas for machine learning in\nparticle physics. We detail a roadmap for their implementation, software and\nhardware resource requirements, collaborative initiatives with the data science\ncommunity, academia and industry, and training the particle physics community\nin data science. The main objective of the document is to connect and motivate\nthese areas of research and development with the physics drivers of the\nHigh-Luminosity Large Hadron Collider and future neutrino experiments and\nidentify the resource needs for their implementation. Additionally we identify\nareas where collaboration with external communities will be of great benefit.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 20:20:19 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 00:05:59 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 05:13:31 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Albertsson", "Kim", ""], ["Altoe", "Piero", ""], ["Anderson", "Dustin", ""], ["Anderson", "John", ""], ["Andrews", "Michael", ""], ["Espinosa", "Juan Pedro Araque", ""], ["Aurisano", "Adam", ""], ["Basara", "Laurent", ""], ["Bevan", "Adrian", ""], ["Bhimji", "Wahid", ""], ["Bonacorsi", "Daniele", ""], ["Burkle", "Bjorn", ""], ["Calafiura", "Paolo", ""], ["Campanelli", "Mario", ""], ["Capps", "Louis", ""], ["Carminati", "Federico", ""], ["Carrazza", "Stefano", ""], ["Chen", "Yi-fan", ""], ["Childers", "Taylor", ""], ["Coadou", "Yann", ""], ["Coniavitis", "Elias", ""], ["Cranmer", "Kyle", ""], ["David", "Claire", ""], ["Davis", "Douglas", ""], ["De Simone", "Andrea", ""], ["Duarte", "Javier", ""], ["Erdmann", "Martin", ""], ["Eschle", "Jonas", ""], ["Farbin", "Amir", ""], ["Feickert", "Matthew", ""], ["Castro", "Nuno Filipe", ""], ["Fitzpatrick", "Conor", ""], ["Floris", "Michele", ""], ["Forti", "Alessandra", ""], ["Garra-Tico", "Jordi", ""], ["Gemmler", "Jochen", ""], ["Girone", "Maria", ""], ["Glaysher", "Paul", ""], ["Gleyzer", "Sergei", ""], ["Gligorov", "Vladimir", ""], ["Golling", "Tobias", ""], ["Graw", "Jonas", ""], ["Gray", "Lindsey", ""], ["Greenwood", "Dick", ""], ["Hacker", "Thomas", ""], ["Harvey", "John", ""], ["Hegner", "Benedikt", ""], ["Heinrich", "Lukas", ""], ["Heintz", "Ulrich", ""], ["Hooberman", "Ben", ""], ["Junggeburth", "Johannes", ""], ["Kagan", "Michael", ""], ["Kane", "Meghan", ""], ["Kanishchev", "Konstantin", ""], ["Karpi\u0144ski", "Przemys\u0142aw", ""], ["Kassabov", "Zahari", ""], ["Kaul", "Gaurav", ""], ["Kcira", "Dorian", ""], ["Keck", "Thomas", ""], ["Klimentov", "Alexei", ""], ["Kowalkowski", "Jim", ""], ["Kreczko", "Luke", ""], ["Kurepin", "Alexander", ""], ["Kutschke", "Rob", ""], ["Kuznetsov", "Valentin", ""], ["K\u00f6hler", "Nicolas", ""], ["Lakomov", "Igor", ""], ["Lannon", "Kevin", ""], ["Lassnig", "Mario", ""], ["Limosani", "Antonio", ""], ["Louppe", "Gilles", ""], ["Mangu", "Aashrita", ""], ["Mato", "Pere", ""], ["Meenakshi", "Narain", ""], ["Meinhard", "Helge", ""], ["Menasce", "Dario", ""], ["Moneta", "Lorenzo", ""], ["Moortgat", "Seth", ""], ["Neubauer", "Mark", ""], ["Newman", "Harvey", ""], ["Otten", "Sydney", ""], ["Pabst", "Hans", ""], ["Paganini", "Michela", ""], ["Paulini", "Manfred", ""], ["Perdue", "Gabriel", ""], ["Perez", "Uzziel", ""], ["Picazio", "Attilio", ""], ["Pivarski", "Jim", ""], ["Prosper", "Harrison", ""], ["Psihas", "Fernanda", ""], ["Radovic", "Alexander", ""], ["Reece", "Ryan", ""], ["Rinkevicius", "Aurelius", ""], ["Rodrigues", "Eduardo", ""], ["Rorie", "Jamal", ""], ["Rousseau", "David", ""], ["Sauers", "Aaron", ""], ["Schramm", "Steven", ""], ["Schwartzman", "Ariel", ""], ["Severini", "Horst", ""], ["Seyfert", "Paul", ""], ["Siroky", "Filip", ""], ["Skazytkin", "Konstantin", ""], ["Sokoloff", "Mike", ""], ["Stewart", "Graeme", ""], ["Stienen", "Bob", ""], ["Stockdale", "Ian", ""], ["Strong", "Giles", ""], ["Sun", "Wei", ""], ["Thais", "Savannah", ""], ["Tomko", "Karen", ""], ["Upfal", "Eli", ""], ["Usai", "Emanuele", ""], ["Ustyuzhanin", "Andrey", ""], ["Vala", "Martin", ""], ["Vasel", "Justin", ""], ["Vallecorsa", "Sofia", ""], ["Verzetti", "Mauro", ""], ["Vilas\u00eds-Cardona", "Xavier", ""], ["Vlimant", "Jean-Roch", ""], ["Vukotic", "Ilija", ""], ["Wang", "Sean-Jiun", ""], ["Watts", "Gordon", ""], ["Williams", "Michael", ""], ["Wu", "Wenjing", ""], ["Wunsch", "Stefan", ""], ["Yang", "Kun", ""], ["Zapata", "Omar", ""]]}, {"id": "1807.02884", "submitter": "Chiheon Kim", "authors": "Chiheon Kim, Afonso S. Bandeira, Michel X. Goemans", "title": "Stochastic Block Model for Hypergraphs: Statistical limits and a\n  semidefinite programming approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of community detection in a random hypergraph model\nwhich we call the stochastic block model for $k$-uniform hypergraphs ($k$-SBM).\nWe investigate the exact recovery problem in $k$-SBM and show that a sharp\nphase transition occurs around a threshold: below the threshold it is\nimpossible to recover the communities with non-vanishing probability, yet above\nthe threshold there is an estimator which recovers the communities almost\nasymptotically surely. We also consider a simple, efficient algorithm for the\nexact recovery problem which is based on a semidefinite relaxation technique.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 21:06:21 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Kim", "Chiheon", ""], ["Bandeira", "Afonso S.", ""], ["Goemans", "Michel X.", ""]]}, {"id": "1807.02886", "submitter": "Hamed Hakkak", "authors": "Hamed Hakkak", "title": "Auto Deep Compression by Reinforcement Learning Based Actor-Critic\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based compression is an effective, facilitating, and expanded model of\nneural network models with limited computing and low power. However,\nconventional models of compression techniques utilize crafted features [2,3,12]\nand explore specialized areas for exploration and design of large spaces in\nterms of size, speed, and accuracy, which usually have returns Less and time is\nup. This paper will effectively analyze deep auto compression (ADC) and\nreinforcement learning strength in an effective sample and space design, and\nimprove the compression quality of the model. The results of compression of the\nadvanced model are obtained without any human effort and in a completely\nautomated way. With a 4- fold reduction in FLOP, the accuracy of 2.8% is higher\nthan the manual compression model for VGG-16 in ImageNet.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 21:34:30 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Hakkak", "Hamed", ""]]}, {"id": "1807.02892", "submitter": "Deon Nicholas", "authors": "Volodymyr Lyubinets, Taras Boiko, Deon Nicholas", "title": "Automated labeling of bugs and tickets using attention-based mechanisms\n  in recurrent neural networks", "comments": "Accepted to 2018 IEEE Second International Conference on Data Stream\n  Mining and Processing. Index Terms - text classification, recurrent neural\n  network, hierarchical attention, machine learning, natural language\n  processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore solutions for automated labeling of content in bug trackers and\ncustomer support systems. In order to do that, we classify content in terms of\nseveral criteria, such as priority or product area. In the first part of the\npaper, we provide an overview of existing methods used for text classification.\nThese methods fall into two categories - the ones that rely on neural networks\nand the ones that don't. We evaluate results of several solutions of both\nkinds. In the second part of the paper we present our own recurrent neural\nnetwork solution based on hierarchical attention paradigm. It consists of\nseveral Hierarchical Attention network blocks with varying Gated Recurrent Unit\ncell sizes and a complementary shallow network that goes alongside. Lastly, we\nevaluate above-mentioned methods when predicting fields from two datasets -\nArch Linux bug tracker and Chromium bug tracker. Our contributions include a\ncomprehensive benchmark between a variety of methods on relevant datasets; a\nnovel solution that outperforms previous generation methods; and two new\ndatasets that are made public for further research.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 22:33:51 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Lyubinets", "Volodymyr", ""], ["Boiko", "Taras", ""], ["Nicholas", "Deon", ""]]}, {"id": "1807.02908", "submitter": "Walid Abdullah Al", "authors": "Walid Abdullah Al, Il Dong Yun", "title": "Partial Policy-based Reinforcement Learning for Anatomical Landmark\n  Localization in 3D Medical Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying the idea of long-term cumulative return, reinforcement learning has\nshown remarkable performance in various fields. We propose a formulation of the\nlandmark localization in 3D medical images as a reinforcement learning problem.\nWhereas value-based methods have been widely used to solve similar problems, we\nadopt an actor-critic based direct policy search method framed in a temporal\ndifference learning approach. Successful behavior learning is challenging in\nlarge state and/or action spaces, requiring many trials. We introduce a partial\npolicy-based reinforcement learning to enable solving the large problem of\nlocalization by learning the optimal policy on smaller partial domains.\nIndependent actors efficiently learn the corresponding partial policies, each\nutilizing their own independent critic. The proposed policy reconstruction from\nthe partial policies ensures a robust and efficient localization utilizing the\nsub-agents solving simple binary decision problems in their corresponding\npartial action spaces. The proposed reinforcement learning requires a small\nnumber of trials to learn the optimal behavior compared with the original\nbehavior learning scheme.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 01:34:14 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 06:22:17 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Al", "Walid Abdullah", ""], ["Yun", "Il Dong", ""]]}, {"id": "1807.02910", "submitter": "Gregory Plumb", "authors": "Gregory Plumb, Denali Molitor, Ameet Talwalkar", "title": "Model Agnostic Supervised Local Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability is an increasingly important component of practical\nmachine learning. Some of the most common forms of interpretability systems are\nexample-based, local, and global explanations. One of the main challenges in\ninterpretability is designing explanation systems that can capture aspects of\neach of these explanation types, in order to develop a more thorough\nunderstanding of the model. We address this challenge in a novel model called\nMAPLE that uses local linear modeling techniques along with a dual\ninterpretation of random forests (both as a supervised neighborhood approach\nand as a feature selection method). MAPLE has two fundamental advantages over\nexisting interpretability systems. First, while it is effective as a black-box\nexplanation system, MAPLE itself is a highly accurate predictive model that\nprovides faithful self explanations, and thus sidesteps the typical\naccuracy-interpretability trade-off. Specifically, we demonstrate, on several\nUCI datasets, that MAPLE is at least as accurate as random forests and that it\nproduces more faithful local explanations than LIME, a popular interpretability\nsystem. Second, MAPLE provides both example-based and local explanations and\ncan detect global patterns, which allows it to diagnose limitations in its\nlocal explanations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 01:40:04 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 13:52:24 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 21:22:02 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Plumb", "Gregory", ""], ["Molitor", "Denali", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1807.02919", "submitter": "Aniket Anand Deshmukh", "authors": "Aniket Anand Deshmukh, Ankit Bansal, Akash Rastogi", "title": "Domain2Vec: Deep Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of domain generalization where a decision function is\nlearned from the data of several related domains, and the goal is to apply it\non an unseen domain successfully. It is assumed that there is plenty of labeled\ndata available in source domains (also called as training domain), but no\nlabeled data is available for the unseen domain (also called a target domain or\ntest domain). We propose a novel neural network architecture, Domain2Vec (D2V)\nthat learns domain-specific embedding and then uses this embedding to\ngeneralize the learning across related domains. The proposed algorithm, D2V\nextends the idea of distribution regression and kernelized domain\ngeneralization to the neural networks setting. We propose a neural network\narchitecture to learn domain-specific embedding and then use this embedding\nalong with the data point specific features to label it. We show the\neffectiveness of the architecture by accurately estimating domain to domain\nsimilarity. We evaluate our algorithm against standard domain generalization\ndatasets for image classification and outperform other state of the art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 02:34:54 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Deshmukh", "Aniket Anand", ""], ["Bansal", "Ankit", ""], ["Rastogi", "Akash", ""]]}, {"id": "1807.02927", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai, Tomoharu Iwata", "title": "Zero-shot Domain Adaptation without Domain Semantic Descriptors", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to infer domain-specific models such as classifiers for\nunseen domains, from which no data are given in the training phase, without\ndomain semantic descriptors. When training and test distributions are\ndifferent, standard supervised learning methods perform poorly. Zero-shot\ndomain adaptation attempts to alleviate this problem by inferring models that\ngeneralize well to unseen domains by using training data in multiple source\ndomains. Existing methods use observed semantic descriptors characterizing\ndomains such as time information to infer the domain-specific models for the\nunseen domains. However, it cannot always be assumed that such metadata can be\nused in real-world applications. The proposed method can infer appropriate\ndomain-specific models without any semantic descriptors by introducing the\nconcept of latent domain vectors, which are latent representations for the\ndomains and are used for inferring the models. The latent domain vector for the\nunseen domain is inferred from the set of the feature vectors in the\ncorresponding domain, which is given in the testing phase. The domain-specific\nmodels consist of two components: the first is for extracting a representation\nof a feature vector to be predicted, and the second is for inferring model\nparameters given the latent domain vector. The posterior distributions of the\nlatent domain vectors and the domain-specific models are parametrized by neural\nnetworks, and are optimized by maximizing the variational lower bound using\nstochastic gradient descent. The effectiveness of the proposed method was\ndemonstrated through experiments using one regression and two classification\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 03:31:01 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""]]}, {"id": "1807.02963", "submitter": "Ryo Shirakawa", "authors": "Ryo Shirakawa, Yusei Yokoyama, Fumiya Okazaki, Ichigaku Takigawa", "title": "Jointly learning relevant subgraph patterns and nonlinear models of\n  their indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification and regression in which the inputs are graphs of arbitrary\nsize and shape have been paid attention in various fields such as computational\nchemistry and bioinformatics. Subgraph indicators are often used as the most\nfundamental features, but the number of possible subgraph patterns are\nintractably large due to the combinatorial explosion. We propose a novel\nefficient algorithm to jointly learn relevant subgraph patterns and nonlinear\nmodels of their indicators. Previous methods for such joint learning of\nsubgraph features and models are based on search for single best subgraph\nfeatures with specific pruning and boosting procedures of adding their\nindicators one by one, which result in linear models of subgraph indicators. In\ncontrast, the proposed approach is based on directly learning regression trees\nfor graph inputs using a newly derived bound of the total sum of squares for\ndata partitions by a given subgraph feature, and thus can learn nonlinear\nmodels through standard gradient boosting. An illustrative example we call the\nGraph-XOR problem to consider nonlinearity, numerical experiments with real\ndatasets, and scalability comparisons to naive approaches using explicit\npattern enumeration are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 06:56:22 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Shirakawa", "Ryo", ""], ["Yokoyama", "Yusei", ""], ["Okazaki", "Fumiya", ""], ["Takigawa", "Ichigaku", ""]]}, {"id": "1807.02999", "submitter": "Yohei Saito", "authors": "Yohei Saito and Takuya Kato", "title": "Decreasing the size of the Restricted Boltzmann machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to decrease the number of hidden units of the restricted\nBoltzmann machine while avoiding decrease of the performance measured by the\nKullback-Leibler divergence. Then, we demonstrate our algorithm by using\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:19:46 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 06:48:21 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Saito", "Yohei", ""], ["Kato", "Takuya", ""]]}, {"id": "1807.03010", "submitter": "Francesco Conti", "authors": "Francesco Conti, Pasquale Davide Schiavone and Luca Benini", "title": "XNOR Neural Engine: a Hardware Accelerator IP for 21.6 fJ/op Binary\n  Neural Network Inference", "comments": "11 pages, 8 figures, 2 tables, 3 listings. Accepted for presentation\n  at CODES'18 and for publication in IEEE Transactions on Computer-Aided Design\n  of Circuits and Systems (TCAD) as part of the ESWEEK-TCAD special issue", "journal-ref": null, "doi": "10.1109/TCAD.2018.2857019", "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) are promising to deliver accuracy comparable to\nconventional deep neural networks at a fraction of the cost in terms of memory\nand energy. In this paper, we introduce the XNOR Neural Engine (XNE), a fully\ndigital configurable hardware accelerator IP for BNNs, integrated within a\nmicrocontroller unit (MCU) equipped with an autonomous I/O subsystem and hybrid\nSRAM / standard cell memory. The XNE is able to fully compute convolutional and\ndense layers in autonomy or in cooperation with the core in the MCU to realize\nmore complex behaviors. We show post-synthesis results in 65nm and 22nm\ntechnology for the XNE IP and post-layout results in 22nm for the full MCU\nindicating that this system can drop the energy cost per binary operation to\n21.6fJ per operation at 0.4V, and at the same time is flexible and performant\nenough to execute state-of-the-art BNN topologies such as ResNet-34 in less\nthan 2.2mJ per frame at 8.9 fps.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:40:37 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Conti", "Francesco", ""], ["Schiavone", "Pasquale Davide", ""], ["Benini", "Luca", ""]]}, {"id": "1807.03024", "submitter": "Joris Mooij", "authors": "Patrick Forr\\'e and Joris M. Mooij", "title": "Constraint-based Causal Discovery for Non-Linear Structural Causal\n  Models with Cycles and Latent Confounders", "comments": "Accepted for publication in Conference on Uncertainty in Artificial\n  Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of causal discovery from data, making use of the\nrecently proposed causal modeling framework of modular structural causal models\n(mSCM) to handle cycles, latent confounders and non-linearities. We introduce\n{\\sigma}-connection graphs ({\\sigma}-CG), a new class of mixed graphs\n(containing undirected, bidirected and directed edges) with additional\nstructure, and extend the concept of {\\sigma}-separation, the appropriate\ngeneralization of the well-known notion of d-separation in this setting, to\napply to {\\sigma}-CGs. We prove the closedness of {\\sigma}-separation under\nmarginalisation and conditioning and exploit this to implement a test of\n{\\sigma}-separation on a {\\sigma}-CG. This then leads us to the first causal\ndiscovery algorithm that can handle non-linear functional relations, latent\nconfounders, cyclic causal relationships, and data from different (stochastic)\nperfect interventions. As a proof of concept, we show on synthetic data how\nwell the algorithm recovers features of the causal graph of modular structural\ncausal models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 10:17:48 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Forr\u00e9", "Patrick", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1807.03026", "submitter": "Ari Heljakka", "authors": "Ari Heljakka, Arno Solin, Juho Kannala", "title": "Pioneer Networks: Progressively Growing Generative Autoencoder", "comments": "To appear in ACCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel generative autoencoder network model that learns to\nencode and reconstruct images with high quality and resolution, and supports\nsmooth random sampling from the latent space of the encoder. Generative\nadversarial networks (GANs) are known for their ability to simulate random\nhigh-quality images, but they cannot reconstruct existing images. Previous\nworks have attempted to extend GANs to support such inference but, so far, have\nnot delivered satisfactory high-quality results. Instead, we propose the\nProgressively Growing Generative Autoencoder (PIONEER) network which achieves\nhigh-quality reconstruction with $128{\\times}128$ images without requiring a\nGAN discriminator. We merge recent techniques for progressively building up the\nparts of the network with the recently introduced adversarial encoder-generator\nnetwork. The ability to reconstruct input images is crucial in many real-world\napplications, and allows for precise intelligent manipulation of existing\nimages. We show promising results in image synthesis and inference, with\nstate-of-the-art results in CelebA inference tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 10:19:51 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 15:26:41 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Heljakka", "Ari", ""], ["Solin", "Arno", ""], ["Kannala", "Juho", ""]]}, {"id": "1807.03039", "submitter": "Prafulla Dhariwal", "authors": "Diederik P. Kingma, Prafulla Dhariwal", "title": "Glow: Generative Flow with Invertible 1x1 Convolutions", "comments": "15 pages; fixed typo in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models (Dinh et al., 2014) are conceptually attractive\ndue to tractability of the exact log-likelihood, tractability of exact\nlatent-variable inference, and parallelizability of both training and\nsynthesis. In this paper we propose Glow, a simple type of generative flow\nusing an invertible 1x1 convolution. Using our method we demonstrate a\nsignificant improvement in log-likelihood on standard benchmarks. Perhaps most\nstrikingly, we demonstrate that a generative model optimized towards the plain\nlog-likelihood objective is capable of efficient realistic-looking synthesis\nand manipulation of large images. The code for our model is available at\nhttps://github.com/openai/glow\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 10:57:26 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 05:12:03 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kingma", "Diederik P.", ""], ["Dhariwal", "Prafulla", ""]]}, {"id": "1807.03046", "submitter": "Emilia Gomez", "authors": "Emilia G\\'omez and Merlijn Blaauw and Jordi Bonada and Pritish Chandna\n  and Helena Cuesta", "title": "Deep Learning for Singing Processing: Achievements, Challenges and\n  Impact on Singers and Listeners", "comments": "Keynote speech, 2018 Joint Workshop on Machine Learning for Music.\n  The Federated Artificial Intelligence Meeting (FAIM), a joint workshop\n  program of ICML, IJCAI/ECAI, and AAMAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes some recent advances on a set of tasks related to the\nprocessing of singing using state-of-the-art deep learning techniques. We\ndiscuss their achievements in terms of accuracy and sound quality, and the\ncurrent challenges, such as availability of data and computing resources. We\nalso discuss the impact that these advances do and will have on listeners and\nsingers when they are integrated in commercial applications.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 11:19:42 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["G\u00f3mez", "Emilia", ""], ["Blaauw", "Merlijn", ""], ["Bonada", "Jordi", ""], ["Chandna", "Pritish", ""], ["Cuesta", "Helena", ""]]}, {"id": "1807.03052", "submitter": "Benjamin Roth", "authors": "Ivan Bilan and Benjamin Roth", "title": "Position-aware Self-attention with Relative Positional Encodings for\n  Slot Filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how to apply self-attention with relative positional\nencodings to the task of relation extraction. We propose to use the\nself-attention encoder layer together with an additional position-aware\nattention layer that takes into account positions of the query and the object\nin the sentence. The self-attention encoder also uses a custom implementation\nof relative positional encodings which allow each word in the sentence to take\ninto account its left and right context. The evaluation of the model is done on\nthe TACRED dataset. The proposed model relies only on attention (no recurrent\nor convolutional layers are used), while improving performance w.r.t. the\nprevious state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 11:34:13 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Bilan", "Ivan", ""], ["Roth", "Benjamin", ""]]}, {"id": "1807.03064", "submitter": "Hugo Penedones", "authors": "Hugo Penedones, Damien Vincent, Hartmut Maennel, Sylvain Gelly,\n  Timothy Mann, Andre Barreto", "title": "Temporal Difference Learning with Neural Networks - Study of the Leakage\n  Propagation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-Difference learning (TD) [Sutton, 1988] with function approximation\ncan converge to solutions that are worse than those obtained by Monte-Carlo\nregression, even in the simple case of on-policy evaluation. To increase our\nunderstanding of the problem, we investigate the issue of approximation errors\nin areas of sharp discontinuities of the value function being further\npropagated by bootstrap updates. We show empirical evidence of this leakage\npropagation, and show analytically that it must occur, in a simple Markov\nchain, when function approximation errors are present. For reversible policies,\nthe result can be interpreted as the tension between two terms of the loss\nfunction that TD minimises, as recently described by [Ollivier, 2018]. We show\nthat the upper bounds from [Tsitsiklis and Van Roy, 1997] hold, but they do not\nimply that leakage propagation occurs and under what conditions. Finally, we\ntest whether the problem could be mitigated with a better state representation,\nand whether it can be learned in an unsupervised manner, without rewards or\nprivileged information.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 12:11:35 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Penedones", "Hugo", ""], ["Vincent", "Damien", ""], ["Maennel", "Hartmut", ""], ["Gelly", "Sylvain", ""], ["Mann", "Timothy", ""], ["Barreto", "Andre", ""]]}, {"id": "1807.03095", "submitter": "Ulzee An", "authors": "Ulzee An, Khader Shameer, Lakshmi Subramanian", "title": "Mammography Assessment using Multi-Scale Deep Classifiers", "comments": "Prepared for MLMH at KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying deep learning methods to mammography assessment has remained a\nchallenging topic. Dense noise with sparse expressions, mega-pixel raw data\nresolution, lack of diverse examples have all been factors affecting\nperformance. The lack of pixel-level ground truths have especially limited\nsegmentation methods in pushing beyond approximately bounding regions. We\npropose a classification approach grounded in high performance tissue\nassessment as an alternative to all-in-one localization and assessment models\nthat is also capable of pinpointing the causal pixels. First, the objective of\nthe mammography assessment task is formalized in the context of local tissue\nclassifiers. Then, the accuracy of a convolutional neural net is evaluated on\nclassifying patches of tissue with suspicious findings at varying scales, where\nhighest obtained AUC is above $0.9$. The local evaluations of one such expert\ntissue classifier is used to augment the results of a heatmap regression model\nand additionally recover the exact causal regions at high resolution as a\nsaliency image suitable for clinical settings.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 01:26:51 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["An", "Ulzee", ""], ["Shameer", "Khader", ""], ["Subramanian", "Lakshmi", ""]]}, {"id": "1807.03100", "submitter": "Oleksandr Polozov", "authors": "Chenglong Wang, Kedar Tatwawadi, Marc Brockschmidt, Po-Sen Huang, Yi\n  Mao, Oleksandr Polozov, Rishabh Singh", "title": "Robust Text-to-SQL Generation with Execution-Guided Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of neural semantic parsing, which translates natural\nlanguage questions into executable SQL queries. We introduce a new mechanism,\nexecution guidance, to leverage the semantics of SQL. It detects and excludes\nfaulty programs during the decoding procedure by conditioning on the execution\nof partially generated program. The mechanism can be used with any\nautoregressive generative model, which we demonstrate on four state-of-the-art\nrecurrent or template-based semantic parsing models. We demonstrate that\nexecution guidance universally improves model performance on various\ntext-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS,\nand GeoQuery. As a result, we achieve new state-of-the-art execution accuracy\nof 83.8% on WikiSQL.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:20:28 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 21:55:52 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 00:29:17 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Wang", "Chenglong", ""], ["Tatwawadi", "Kedar", ""], ["Brockschmidt", "Marc", ""], ["Huang", "Po-Sen", ""], ["Mao", "Yi", ""], ["Polozov", "Oleksandr", ""], ["Singh", "Rishabh", ""]]}, {"id": "1807.03113", "submitter": "Benjamin Bloem-Reddy", "authors": "Benjamin Bloem-Reddy and Adam Foster and Emile Mathieu and Yee Whye\n  Teh", "title": "Sampling and Inference for Beta Neutral-to-the-Left Models of Sparse\n  Networks", "comments": "Accepted for publication in the proceedings of Conference on\n  Uncertainty in Artificial Intelligence (UAI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evidence suggests that heavy-tailed degree distributions occurring\nin many real networks are well-approximated by power laws with exponents $\\eta$\nthat may take values either less than and greater than two. Models based on\nvarious forms of exchangeability are able to capture power laws with $\\eta <\n2$, and admit tractable inference algorithms; we draw on previous results to\nshow that $\\eta > 2$ cannot be generated by the forms of exchangeability used\nin existing random graph models. Preferential attachment models generate power\nlaw exponents greater than two, but have been of limited use as statistical\nmodels due to the inherent difficulty of performing inference in\nnon-exchangeable models. Motivated by this gap, we design and implement\ninference algorithms for a recently proposed class of models that generates\n$\\eta$ of all possible values. We show that although they are not exchangeable,\nthese models have probabilistic structure amenable to inference. Our methods\nmake a large class of previously intractable models useful for statistical\ninference.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:28:15 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Bloem-Reddy", "Benjamin", ""], ["Foster", "Adam", ""], ["Mathieu", "Emile", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1807.03116", "submitter": "Zhi Chen", "authors": "Zhi Chen, Pin-han Ho", "title": "Deep Global-Connected Net With The Generalized Multi-Piecewise ReLU\n  Activation in Deep Learning", "comments": "9 pages, 3 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Progress has shown that exploitation of hidden layer neurons in\nconvolution neural networks incorporating with a carefully designed activation\nfunction can yield better classification results in the field of computer\nvision. The paper firstly introduces a novel deep learning architecture aiming\nto mitigate the gradient-vanishing problem, in which the earlier hidden layer\nneurons could be directly connected with the last hidden layer and feed into\nthe last layer for classification. We then design a generalized linear\nrectifier function as the activation function that can approximate arbitrary\ncomplex functions via training of the parameters. We will show that our design\ncan achieve similar performance in a number of object recognition and video\naction benchmark tasks, under significantly less number of parameters and\nshallower network infrastructure, which is not only promising in training in\nterms of computation burden and memory usage, but is also applicable to\nlow-computation, low-memory mobile scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 22:53:48 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Chen", "Zhi", ""], ["Ho", "Pin-han", ""]]}, {"id": "1807.03117", "submitter": "Miguel Martin-Abadal", "authors": "Miguel Martin-Abadal, Eric Guerrero-Font, Francisco Bonin-Font and\n  Yolanda Gonzalez-Cid", "title": "Deep Semantic Segmentation in an AUV for Online Posidonia Oceanica\n  Meadows identification", "comments": "11 pages, 16 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2875412", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown evidence of a significant decline of the Posidonia\noceanica (P.O.) meadows on a global scale. The monitoring and mapping of these\nmeadows are fundamental tools for measuring their status. We present an\napproach based on a deep neural network to automatically perform a\nhigh-precision semantic segmentation of P.O. meadows in sea-floor images,\noffering several improvements over the state of the art techniques. Our network\ndemonstrates outstanding performance over diverse test sets, reaching a\nprecision of 96.57% and an accuracy of 96.81%, surpassing the reliability of\nlabelling the images manually. Also, the network is implemented in an\nAutonomous Underwater Vehicle (AUV), performing an online P.O. segmentation,\nwhich will be used to generate real-time semantic coverage maps.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 22:21:51 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 19:46:42 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Martin-Abadal", "Miguel", ""], ["Guerrero-Font", "Eric", ""], ["Bonin-Font", "Francisco", ""], ["Gonzalez-Cid", "Yolanda", ""]]}, {"id": "1807.03120", "submitter": "Mrinal Haloi", "authors": "Mrinal Haloi, K. Raja Rajalakshmi, Pradeep Walia", "title": "Towards Radiologist-Level Accurate Deep Learning System for Pulmonary\n  Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose advanced pneumonia and Tuberculosis grading system\nfor X-ray images. The proposed system is a very deep fully convolutional\nclassification network with online augmentation that outputs confidence values\nfor diseases prevalence. Its a fully automated system capable of disease\nfeature understanding without any offline preprocessing step or manual feature\nextraction. We have achieved state- of-the- art performance on the public\ndatabases such as ChestXray-14, Mendeley, Shenzhen Hospital X-ray and Belarus\nX-ray set.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 07:07:25 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Haloi", "Mrinal", ""], ["Rajalakshmi", "K. Raja", ""], ["Walia", "Pradeep", ""]]}, {"id": "1807.03126", "submitter": "V\\'it R\\r{u}\\v{z}i\\v{c}ka", "authors": "V\\'it R\\r{u}\\v{z}i\\v{c}ka", "title": "Estimating Bicycle Route Attractivity from Image Data", "comments": "86 pages. (Master's thesis, 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This master thesis focuses on practical application of Convolutional Neural\nNetwork models on the task of road labeling with bike attractivity score. We\nstart with an abstraction of real world locations into nodes and scored edges\nin partially annotated dataset. We enhance information available about each\nedge with photographic data from Google Street View service and with additional\nneighborhood information from Open Street Map database. We teach a model on\nthis enhanced dataset and experiment with ImageNet Large Scale Visual\nRecognition Competition. We try different dataset enhancing techniques as well\nas various model architectures to improve road scoring. We also make use of\ntransfer learning to use features from a task with rich dataset of ImageNet\ninto our task with smaller number of images, to prevent model overfitting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 19:29:05 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["R\u016f\u017ei\u010dka", "V\u00edt", ""]]}, {"id": "1807.03132", "submitter": "Zhiyan Cui", "authors": "Zhiyan Cui, Na Lu", "title": "Fast Dynamic Convolutional Neural Networks for Visual Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing tracking methods based on CNN(convolutional neural\nnetworks) are too slow for real-time application despite the excellent tracking\nprecision compared with the traditional ones. In this paper, a fast dynamic\nvisual tracking algorithm combining CNN based MDNet(Multi-Domain Network) and\nRoIAlign was developed. The major problem of MDNet also lies in the time\nefficiency. Considering the computational complexity of MDNet is mainly caused\nby the large amount of convolution operations and fine-tuning of the network\nduring tracking, a RoIPool layer which could conduct the convolution over the\nwhole image instead of each RoI is added to accelerate the convolution and a\nnew strategy of fine-tuning the fully-connected layers is used to accelerate\nthe update. With RoIPool employed, the computation speed has been increased but\nthe tracking precision has dropped simultaneously. RoIPool could lose some\npositioning precision because it can not handle locations represented by\nfloating numbers. So RoIAlign, instead of RoIPool, which can process floating\nnumbers of locations by bilinear interpolation has been added to the network.\nThe results show the target localization precision has been improved and it\nhardly increases the computational cost. These strategies can accelerate the\nprocessing and make it 7x faster than MDNet with very low impact on precision\nand it can run at around 7 fps. The proposed algorithm has been evaluated on\ntwo benchmarks: OTB100 and VOT2016, on which high precision and speed have been\nobtained. The influence of the network structure and training data are also\ndiscussed with experiments.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 06:30:18 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 08:06:56 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Cui", "Zhiyan", ""], ["Lu", "Na", ""]]}, {"id": "1807.03133", "submitter": "Ryosuke Goto", "authors": "Takuma Nakamura and Ryosuke Goto", "title": "Outfit Generation and Style Extraction via Bidirectional LSTM and\n  Autoencoder", "comments": "9 pages, 5 figures, KDD Workshop AI for fashion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating an outfit, style is a criterion in selecting each fashion item.\nThis means that style can be regarded as a feature of the overall outfit.\nHowever, in various previous studies on outfit generation, there have been few\nmethods focusing on global information obtained from an outfit. To address this\ndeficiency, we have incorporated an unsupervised style extraction module into a\nmodel to learn outfits. Using the style information of an outfit as a whole,\nthe proposed model succeeded in generating outfits more flexibly without\nrequiring additional information. Moreover, the style information extracted by\nthe proposed model is easy to interpret. The proposed model was evaluated on\ntwo human-generated outfit datasets. In a fashion item prediction task (missing\nprediction task), the proposed model outperformed a baseline method. In a style\nextraction task, the proposed model extracted some easily distinguishable\nstyles. In an outfit generation task, the proposed model generated an outfit\nwhile controlling its styles. This capability allows us to generate fashionable\noutfits according to various preferences.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 18:00:03 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 04:24:35 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 10:28:23 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Nakamura", "Takuma", ""], ["Goto", "Ryosuke", ""]]}, {"id": "1807.03135", "submitter": "Mohammad Tofighi", "authors": "Mohammad Tofighi, Tiantong Guo, Jairam K.P. Vanamala, and Vishal Monga", "title": "Deep Networks with Shape Priors for Nucleus Detection", "comments": "Accepted paper to 2018 IEEE International Conference on Image\n  Processing (ICIP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of cell nuclei in microscopic images is a challenging research\ntopic, because of limitations in cellular image quality and diversity of\nnuclear morphology, i.e. varying nuclei shapes, sizes, and overlaps between\nmultiple cell nuclei. This has been a topic of enduring interest with promising\nrecent success shown by deep learning methods. These methods train for example\nconvolutional neural networks (CNNs) with a training set of input images and\nknown, labeled nuclei locations. Many of these methods are supplemented by\nspatial or morphological processing. We develop a new approach that we call\nShape Priors with Convolutional Neural Networks (SP-CNN) to perform\nsignificantly enhanced nuclei detection. A set of canonical shapes is prepared\nwith the help of a domain expert. Subsequently, we present a new network\nstructure that can incorporate `expected behavior' of nucleus shapes via two\ncomponents: {\\em learnable} layers that perform the nucleus detection and a\n{\\em fixed} processing part that guides the learning with prior information.\nAnalytically, we formulate a new regularization term that is targeted at\npenalizing false positives while simultaneously encouraging detection inside\ncell nucleus boundary. Experimental results on a challenging dataset reveal\nthat SP-CNN is competitive with or outperforms several state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 17:54:41 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Tofighi", "Mohammad", ""], ["Guo", "Tiantong", ""], ["Vanamala", "Jairam K. P.", ""], ["Monga", "Vishal", ""]]}, {"id": "1807.03142", "submitter": "Bishwo Adhikari Mr.", "authors": "Bishwo Adhikari, Jukka Peltom\\\"aki, Jussi Puura and Heikki Huttunen", "title": "Faster Bounding Box Annotation for Object Detection in Indoor Scenes", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": "7th European Workshop on Visual Information Processing (EUVIP),\n  2018", "doi": "10.1109/EUVIP.2018.8611732", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach for rapid bounding box annotation for object\ndetection datasets. The procedure consists of two stages: The first step is to\nannotate a part of the dataset manually, and the second step proposes\nannotations for the remaining samples using a model trained with the first\nstage annotations. We experimentally study which first/second stage split\nminimizes to total workload. In addition, we introduce a new fully labeled\nobject detection dataset collected from indoor scenes. Compared to other indoor\ndatasets, our collection has more class categories, different backgrounds,\nlighting conditions, occlusion and high intra-class differences. We train deep\nlearning based object detectors with a number of state-of-the-art models and\ncompare them in terms of speed and accuracy. The fully annotated dataset is\nreleased freely available for the research community.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 08:46:57 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Adhikari", "Bishwo", ""], ["Peltom\u00e4ki", "Jukka", ""], ["Puura", "Jussi", ""], ["Huttunen", "Heikki", ""]]}, {"id": "1807.03146", "submitter": "Supasorn Suwajanakorn", "authors": "Supasorn Suwajanakorn, Noah Snavely, Jonathan Tompson, Mohammad\n  Norouzi", "title": "Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents KeypointNet, an end-to-end geometric reasoning framework\nto learn an optimal set of category-specific 3D keypoints, along with their\ndetectors. Given a single image, KeypointNet extracts 3D keypoints that are\noptimized for a downstream task. We demonstrate this framework on 3D pose\nestimation by proposing a differentiable objective that seeks the optimal set\nof keypoints for recovering the relative pose between two views of an object.\nOur model discovers geometrically and semantically consistent keypoints across\nviewing angles and instances of an object category. Importantly, we find that\nour end-to-end framework using no ground-truth keypoint annotations outperforms\na fully supervised baseline using the same neural network architecture on the\ntask of pose estimation. The discovered 3D keypoints on the car, chair, and\nplane categories of ShapeNet are visualized at http://keypointnet.github.io/.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 17:41:49 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 10:21:09 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Suwajanakorn", "Supasorn", ""], ["Snavely", "Noah", ""], ["Tompson", "Jonathan", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1807.03148", "submitter": "Siddhartha Chandra", "authors": "Siddhartha Chandra and Camille Couprie and Iasonas Kokkinos", "title": "Deep Spatio-Temporal Random Fields for Efficient Video Segmentation", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a time- and memory-efficient method for structured\nprediction that couples neuron decisions across both space at time. We show\nthat we are able to perform exact and efficient inference on a densely\nconnected spatio-temporal graph by capitalizing on recent advances on deep\nGaussian Conditional Random Fields (GCRFs). Our method, called VideoGCRF is (a)\nefficient, (b) has a unique global minimum, and (c) can be trained end-to-end\nalongside contemporary deep networks for video understanding. We experiment\nwith multiple connectivity patterns in the temporal domain, and present\nempirical improvements over strong baselines on the tasks of both semantic and\ninstance segmentation of videos.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:46:07 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Chandra", "Siddhartha", ""], ["Couprie", "Camille", ""], ["Kokkinos", "Iasonas", ""]]}, {"id": "1807.03149", "submitter": "Dan Rosenbaum", "authors": "Dan Rosenbaum, Frederic Besse, Fabio Viola, Danilo J. Rezende, S. M.\n  Ali Eslami", "title": "Learning models for visual 3D localization with implicit mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning based methods for visual localization that do not\nrequire the construction of explicit maps in the form of point clouds or\nvoxels. The goal is to learn an implicit representation of the environment at a\nhigher, more abstract level. We propose to use a generative approach based on\nGenerative Query Networks (GQNs, Eslami et al. 2018), asking the following\nquestions: 1) Can GQN capture more complex scenes than those it was originally\ndemonstrated on? 2) Can GQN be used for localization in those scenes? To study\nthis approach we consider procedurally generated Minecraft worlds, for which we\ncan generate images of complex 3D scenes along with camera pose coordinates. We\nfirst show that GQNs, enhanced with a novel attention mechanism can capture the\nstructure of 3D scenes in Minecraft, as evidenced by their samples. We then\napply the models to the localization problem, comparing the results to a\ndiscriminative baseline, and comparing the ways each approach captures the task\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 15:50:58 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 11:26:23 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Rosenbaum", "Dan", ""], ["Besse", "Frederic", ""], ["Viola", "Fabio", ""], ["Rezende", "Danilo J.", ""], ["Eslami", "S. M. Ali", ""]]}, {"id": "1807.03155", "submitter": "Marie-Morgane Paumard", "authors": "Marie-Morgane Paumard, David Picard, Hedi Tabia", "title": "Jigsaw Puzzle Solving Using Local Feature Co-Occurrences in Deep Neural\n  Networks", "comments": "ICIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archaeologists are in dire need of automated object reconstruction methods.\nFragments reassembly is close to puzzle problems, which may be solved by\ncomputer vision algorithms. As they are often beaten on most image related\ntasks by deep learning algorithms, we study a classification method that can\nsolve jigsaw puzzles. In this paper, we focus on classifying the relative\nposition: given a couple of fragments, we compute their local relation (e.g. on\ntop). We propose several enhancements over the state of the art in this domain,\nwhich is outperformed by our method by 25\\%. We propose an original dataset\ncomposed of pictures from the Metropolitan Museum of Art. We propose a greedy\nreconstruction method based on the predicted relative positions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:19:09 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Paumard", "Marie-Morgane", ""], ["Picard", "David", ""], ["Tabia", "Hedi", ""]]}, {"id": "1807.03159", "submitter": "Bryan Lim", "authors": "Bryan Lim and Mihaela van der Schaar", "title": "Forecasting Disease Trajectories in Alzheimer's Disease Using Deep\n  Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.10254", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint models for longitudinal and time-to-event data are commonly used in\nlongitudinal studies to forecast disease trajectories over time. Despite the\nmany advantages of joint modeling, the standard forms suffer from limitations\nthat arise from a fixed model specification and computational difficulties when\napplied to large datasets. We adopt a deep learning approach to address these\nlimitations, enhancing existing methods with the flexibility and scalability of\ndeep neural networks while retaining the benefits of joint modeling. Using data\nfrom the Alzheimer's Disease Neuroimaging Institute, we show improvements in\nperformance and scalability compared to traditional methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 16:28:58 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Lim", "Bryan", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1807.03162", "submitter": "Mostafa Mohammadkarimi", "authors": "Mostafa Mohammadkarimi, Mehrtash Mehrabi, Masoud Ardakani, and Yindi\n  Jing", "title": "Deep Learning Based Sphere Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a deep learning (DL)-based sphere decoding algorithm is\nproposed, where the radius of the decoding hypersphere is learnt by a deep\nneural network (DNN). The performance achieved by the proposed algorithm is\nvery close to the optimal maximum likelihood decoding (MLD) over a wide range\nof signal-to-noise ratios (SNRs), while the computational complexity, compared\nto existing sphere decoding variants, is significantly reduced. This\nimprovement is attributed to DNN's ability of intelligently learning the radius\nof the hypersphere used in decoding. The expected complexity of the proposed\nDL-based algorithm is analytically derived and compared with existing ones. It\nis shown that the number of lattice points inside the decoding hypersphere\ndrastically reduces in the DL- based algorithm in both the average and\nworst-case senses. The effectiveness of the proposed algorithm is shown through\nsimulation for high-dimensional multiple-input multiple-output (MIMO) systems,\nusing high-order modulations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 03:18:35 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Mohammadkarimi", "Mostafa", ""], ["Mehrabi", "Mehrtash", ""], ["Ardakani", "Masoud", ""], ["Jing", "Yindi", ""]]}, {"id": "1807.03165", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Vijay Gadepally, Hayden Jananthan, Lauren Milechin, Sid\n  Samsi", "title": "Sparse Deep Neural Network Exact Solutions", "comments": "8 pages, 10 figures, accepted to IEEE HPEC 2018. arXiv admin note:\n  text overlap with arXiv:1708.02937", "journal-ref": null, "doi": "10.1109/HPEC.2018.8547742", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have emerged as key enablers of machine learning.\nApplying larger DNNs to more diverse applications is an important challenge.\nThe computations performed during DNN training and inference are dominated by\noperations on the weight matrices describing the DNN. As DNNs incorporate more\nlayers and more neurons per layers, these weight matrices may be required to be\nsparse because of memory limitations. Sparse DNNs are one possible approach,\nbut the underlying theory is in the early stages of development and presents a\nnumber of challenges, including determining the accuracy of inference and\nselecting nonzero weights for training. Associative array algebra has been\ndeveloped by the big data community to combine and extend database, matrix, and\ngraph/network concepts for use in large, sparse data problems. Applying this\nmathematics to DNNs simplifies the formulation of DNN mathematics and reveals\nthat DNNs are linear over oscillating semirings. This work uses associative\narray DNNs to construct exact solutions and corresponding perturbation models\nto the rectified linear unit (ReLU) DNN equations that can be used to construct\ntest vectors for sparse DNN implementations over various precisions. These\nsolutions can be used for DNN verification, theoretical explorations of DNN\nproperties, and a starting point for the challenge of sparse training.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 00:47:12 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""], ["Jananthan", "Hayden", ""], ["Milechin", "Lauren", ""], ["Samsi", "Sid", ""]]}, {"id": "1807.03167", "submitter": "Helder Oliveira", "authors": "Arthur C. Costa, Helder C. R. Oliveira, Juliana H. Catani, Nestor de\n  Barros, Carlos F. E. Melo, and Marcelo A. C. Vieira", "title": "Data Augmentation for Detection of Architectural Distortion in Digital\n  Mammography using Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Early detection of breast cancer can increase treatment efficiency.\nArchitectural Distortion (AD) is a very subtle contraction of the breast tissue\nand may represent the earliest sign of cancer. Since it is very likely to be\nunnoticed by radiologists, several approaches have been proposed over the years\nbut none using deep learning techniques. To train a Convolutional Neural\nNetwork (CNN), which is a deep neural architecture, is necessary a huge amount\nof data. To overcome this problem, this paper proposes a data augmentation\napproach applied to clinical image dataset to properly train a CNN. Results\nusing receiver operating characteristic analysis showed that with a very\nlimited dataset we could train a CNN to detect AD in digital mammography with\narea under the curve (AUC = 0.74).\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 02:12:49 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Costa", "Arthur C.", ""], ["Oliveira", "Helder C. R.", ""], ["Catani", "Juliana H.", ""], ["de Barros", "Nestor", ""], ["Melo", "Carlos F. E.", ""], ["Vieira", "Marcelo A. C.", ""]]}, {"id": "1807.03168", "submitter": "Maksym Zavershynskyi", "authors": "Maksym Zavershynskyi, Alex Skidanov, Illia Polosukhin", "title": "NAPS: Natural Program Synthesis Dataset", "comments": "4 pages, 5 tables in 2nd Workshop on Neural Abstract Machines &\n  Program Induction (NAMPI), @ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a program synthesis-oriented dataset consisting of human written\nproblem statements and solutions for these problems. The problem statements\nwere collected via crowdsourcing and the program solutions were extracted from\nhuman-written solutions in programming competitions, accompanied by\ninput/output examples. We propose using this dataset for the program synthesis\ntasks aimed for working with real user-generated data. As a baseline we present\nfew models, with the best model achieving 8.8% accuracy, showcasing both the\ncomplexity of the dataset and large room for future research.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 02:59:34 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Zavershynskyi", "Maksym", ""], ["Skidanov", "Alex", ""], ["Polosukhin", "Illia", ""]]}, {"id": "1807.03173", "submitter": "Kilian Hett", "authors": "Kilian Hett (LaBRI, CNRS), Vinh-Thong Ta (Bordeaux INP), Jose Vicente\n  Manjon, Pierrick Coup\\'e (LaBRI, CNRS)", "title": "Graph of brain structures grading for early detection of Alzheimer's\n  disease", "comments": null, "journal-ref": "Medical Image Computing and Computer-Assisted Intervention, Sep\n  2018, GRANADA, Spain", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease is the most common dementia leading to an irreversible\nneurodegenerative process. To date, subject revealed advanced brain structural\nalterations when the diagnosis is established. Therefore, an earlier diagnosis\nof this dementia is crucial although it is a challenging task. Recently, many\nstudies have proposed biomarkers to perform early detection of Alzheimer's\ndisease. Some of them have proposed methods based on inter-subject similarity\nwhile other approaches have investigated framework using intra-subject\nvariability. In this work, we propose a novel framework combining both\napproaches within an efficient graph of brain structures grading. Subsequently,\nwe demonstrate the competitive performance of the proposed method compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:43:31 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Hett", "Kilian", "", "LaBRI, CNRS"], ["Ta", "Vinh-Thong", "", "Bordeaux INP"], ["Manjon", "Jose Vicente", "", "LaBRI, CNRS"], ["Coup\u00e9", "Pierrick", "", "LaBRI, CNRS"]]}, {"id": "1807.03179", "submitter": "Xiao Liu", "authors": "Xiao Liu, Bin Zhang, Anjana Susarla, Rema Padman", "title": "YouTube for Patient Education: A Deep Learning Approach for\n  Understanding Medical Knowledge from User-Generated Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  YouTube presents an unprecedented opportunity to explore how machine learning\nmethods can improve healthcare information dissemination. We propose an\ninterdisciplinary lens that synthesizes machine learning methods with\nhealthcare informatics themes to address the critical issue of developing a\nscalable algorithmic solution to evaluate videos from a health literacy and\npatient education perspective. We develop a deep learning method to understand\nthe level of medical knowledge encoded in YouTube videos. Preliminary results\nsuggest that we can extract medical knowledge from YouTube videos and classify\nvideos according to the embedded knowledge with satisfying performance. Deep\nlearning methods show great promise in knowledge extraction, natural language\nunderstanding, and image classification, especially in an era of\npatient-centric care and precision medicine.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 17:19:26 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Liu", "Xiao", ""], ["Zhang", "Bin", ""], ["Susarla", "Anjana", ""], ["Padman", "Rema", ""]]}, {"id": "1807.03191", "submitter": "Andreas Selmar Hauptmann", "authors": "Andreas Hauptmann, Ben Cox, Felix Lucka, Nam Huynh, Marta Betcke, Paul\n  Beard, Simon Arridge", "title": "Approximate k-space models and Deep Learning for fast photoacoustic\n  reconstruction", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-00129-2_12", "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for accelerated iterative reconstructions using a fast\nand approximate forward model that is based on k-space methods for\nphotoacoustic tomography. The approximate model introduces aliasing artefacts\nin the gradient information for the iterative reconstruction, but these\nartefacts are highly structured and we can train a CNN that can use the\napproximate information to perform an iterative reconstruction. We show\nfeasibility of the method for human in-vivo measurements in a limited-view\ngeometry. The proposed method is able to produce superior results to total\nvariation reconstructions with a speed-up of 32 times.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 14:32:18 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Hauptmann", "Andreas", ""], ["Cox", "Ben", ""], ["Lucka", "Felix", ""], ["Huynh", "Nam", ""], ["Betcke", "Marta", ""], ["Beard", "Paul", ""], ["Arridge", "Simon", ""]]}, {"id": "1807.03200", "submitter": "Zimin Chen", "authors": "Zimin Chen and Martin Monperrus", "title": "The CodRep Machine Learning on Source Code Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CodRep is a machine learning competition on source code data. It is carefully\ndesigned so that anybody can enter the competition, whether professional\nresearchers, students or independent scholars, without specific knowledge in\nmachine learning or program analysis. In particular, it aims at being a common\nplayground on which the machine learning and the software engineering research\ncommunities can interact. The competition has started on April 14th 2018 and\nhas ended on October 14th 2018. The CodRep data is hosted at\nhttps://github.com/KTH/CodRep-competition/.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 13:40:58 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 10:46:48 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Chen", "Zimin", ""], ["Monperrus", "Martin", ""]]}, {"id": "1807.03205", "submitter": "Bingcong Li", "authors": "Bingcong Li, Tianyi Chen, and Georgios B. Giannakis", "title": "Bandit Online Learning with Unknown Delays", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with bandit online learning problems involving feedback of\nunknown delay that can emerge in multi-armed bandit (MAB) and bandit convex\noptimization (BCO) settings. MAB and BCO require only values of the objective\nfunction involved that become available through feedback, and are used to\nestimate the gradient appearing in the corresponding iterative algorithms.\nSince the challenging case of feedback with \\emph{unknown} delays prevents one\nfrom constructing the sought gradient estimates, existing MAB and BCO\nalgorithms become intractable. For such challenging setups, delayed\nexploration, exploitation, and exponential (DEXP3) iterations, along with\ndelayed bandit gradient descent (DBGD) iterations are developed for MAB and\nBCO, respectively. Leveraging a unified analysis framework, it is established\nthat the regret of DEXP3 and DBGD are ${\\cal O}\\big( \\sqrt{K\\bar{d}(T+D)}\n\\big)$ and ${\\cal O}\\big( \\sqrt{K(T+D)} \\big)$, respectively, where $\\bar{d}$\nis the maximum delay and $D$ denotes the delay accumulated over $T$ slots.\nNumerical tests using both synthetic and real data validate the performance of\nDEXP3 and DBGD.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 14:55:03 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 05:37:55 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 12:53:47 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Li", "Bingcong", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1807.03210", "submitter": "Michael Kamp", "authors": "Michael Kamp and Linara Adilova and Joachim Sicking and Fabian H\\\"uger\n  and Peter Schlicht and Tim Wirtz and Stefan Wrobel", "title": "Efficient Decentralized Deep Learning by Dynamic Model Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient protocol for decentralized training of deep neural\nnetworks from distributed data sources. The proposed protocol allows to handle\ndifferent phases of model training equally well and to quickly adapt to concept\ndrifts. This leads to a reduction of communication by an order of magnitude\ncompared to periodically communicating state-of-the-art approaches. Moreover,\nwe derive a communication bound that scales well with the hardness of the\nserialized learning problem. The reduction in communication comes at almost no\ncost, as the predictive performance remains virtually unchanged. Indeed, the\nproposed protocol retains loss bounds of periodically averaging schemes. An\nextensive empirical evaluation validates major improvement of the trade-off\nbetween model performance and communication which could be beneficial for\nnumerous decentralized learning applications, such as autonomous driving, or\nvoice recognition and image classification on mobile phones.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:01:51 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 18:45:10 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kamp", "Michael", ""], ["Adilova", "Linara", ""], ["Sicking", "Joachim", ""], ["H\u00fcger", "Fabian", ""], ["Schlicht", "Peter", ""], ["Wirtz", "Tim", ""], ["Wrobel", "Stefan", ""]]}, {"id": "1807.03233", "submitter": "Kunhong Liu Dr", "authors": "Mengxin Sun, Kunhong Liu, Qingqi Hong, Beizhan Wang", "title": "A New ECOC Algorithm for Multiclass Microarray Data Classification", "comments": "conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of multi-class microarray datasets is a hard task because\nof the small samples size in each class and the heavy overlaps among classes.\nTo effectively solve these problems, we propose novel Error Correcting Output\nCode (ECOC) algorithm by Enhance Class Separability related Data Complexity\nmeasures during encoding process, named as ECOCECS. In this algorithm, two\nnearest neighbor related DC measures are deployed to extract the intrinsic\noverlapping information from microarray data. Our ECOC algorithm aims to search\nan optimal class split scheme by minimizing these measures. The class splitting\nprocess ends when each class is separated from others, and then the class\nassignment scheme is mapped as a coding matrix. Experiments are carried out on\nfive microarray datasets, and results demonstrate the effectiveness and\nrobustness of our method in comparison with six state-of-art ECOC methods. In\nshort, our work confirm the probability of applying DC to ECOC framework.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 01:29:53 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Sun", "Mengxin", ""], ["Liu", "Kunhong", ""], ["Hong", "Qingqi", ""], ["Wang", "Beizhan", ""]]}, {"id": "1807.03247", "submitter": "Rosanne Liu", "authors": "Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric\n  Frank, Alex Sergeev, Jason Yosinski", "title": "An Intriguing Failing of Convolutional Neural Networks and the CoordConv\n  Solution", "comments": "Published in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few ideas have enjoyed as large an impact on deep learning as convolution.\nFor any problem involving pixels or spatial representations, common intuition\nholds that convolutional neural networks may be appropriate. In this paper we\nshow a striking counterexample to this intuition via the seemingly trivial\ncoordinate transform problem, which simply requires learning a mapping between\ncoordinates in (x,y) Cartesian space and one-hot pixel space. Although\nconvolutional networks would seem appropriate for this task, we show that they\nfail spectacularly. We demonstrate and carefully analyze the failure first on a\ntoy problem, at which point a simple fix becomes obvious. We call this solution\nCoordConv, which works by giving convolution access to its own input\ncoordinates through the use of extra coordinate channels. Without sacrificing\nthe computational and parametric efficiency of ordinary convolution, CoordConv\nallows networks to learn either complete translation invariance or varying\ndegrees of translation dependence, as required by the end task. CoordConv\nsolves the coordinate transform problem with perfect generalization and 150\ntimes faster with 10--100 times fewer parameters than convolution. This stark\ncontrast raises the question: to what extent has this inability of convolution\npersisted insidiously inside other tasks, subtly hampering performance from\nwithin? A complete answer to this question will require further investigation,\nbut we show preliminary evidence that swapping convolution for CoordConv can\nimprove models on a diverse set of tasks. Using CoordConv in a GAN produced\nless mode collapse as the transform between high-level spatial latents and\npixels becomes easier to learn. A Faster R-CNN detection model trained on MNIST\nshowed 24% better IOU when using CoordConv, and in the RL domain agents playing\nAtari games benefit significantly from the use of CoordConv layers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:48:08 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 16:31:58 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Rosanne", ""], ["Lehman", "Joel", ""], ["Molino", "Piero", ""], ["Such", "Felipe Petroski", ""], ["Frank", "Eric", ""], ["Sergeev", "Alex", ""], ["Yosinski", "Jason", ""]]}, {"id": "1807.03257", "submitter": "Yibo Lin", "authors": "Yibo Lin, Meng Li, Yuki Watanabe, Taiki Kimura, Tetsuaki Matsunawa,\n  Shigeki Nojima, David Z. Pan", "title": "Data Efficient Lithography Modeling with Transfer Learning and Active\n  Data Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lithography simulation is one of the key steps in physical verification,\nenabled by the substantial optical and resist models. A resist model bridges\nthe aerial image simulation to printed patterns. While the effectiveness of\nlearning-based solutions for resist modeling has been demonstrated, they are\nconsiderably data-demanding. Meanwhile, a set of manufactured data for a\nspecific lithography configuration is only valid for the training of one single\nmodel, indicating low data efficiency. Due to the complexity of the\nmanufacturing process, obtaining enough data for acceptable accuracy becomes\nvery expensive in terms of both time and cost, especially during the evolution\nof technology generations when the design space is intensively explored. In\nthis work, we propose a new resist modeling framework for contact layers,\nutilizing existing data from old technology nodes and active selection of data\nin a target technology node, to reduce the amount of data required from the\ntarget lithography configuration. Our framework based on transfer learning and\nactive learning techniques is effective within a competitive range of accuracy,\ni.e., 3-10X reduction on the amount of training data with comparable accuracy\nto the state-of-the-art learning approach.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 17:53:24 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Lin", "Yibo", ""], ["Li", "Meng", ""], ["Watanabe", "Yuki", ""], ["Kimura", "Taiki", ""], ["Matsunawa", "Tetsuaki", ""], ["Nojima", "Shigeki", ""], ["Pan", "David Z.", ""]]}, {"id": "1807.03283", "submitter": "Ahmed I. Taloba", "authors": "Ahmed I. Taloba, D. A. Eisa, Safaa S. I. Ismail", "title": "A Comparative Study on using Principle Component Analysis with Different\n  Text Classifiers", "comments": null, "journal-ref": "International Journal of Computer Applications 180(31):1-6, April\n  2018", "doi": "10.5120/ijca2018916800", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text categorization (TC) is the task of automatically organizing a set of\ndocuments into a set of pre-defined categories. Over the last few years,\nincreased attention has been paid to the use of documents in digital form and\nthis makes text categorization becomes a challenging issue. The most\nsignificant problem of text categorization is its huge number of features. Most\nof these features are redundant, noisy and irrelevant that cause over fitting\nwith most of the classifiers. Hence, feature extraction is an important step to\nimprove the overall accuracy and the performance of the text classifiers. In\nthis paper, we will provide an overview of using principle component analysis\n(PCA) as a feature extraction with various classifiers. It was observed that\nthe performance rate of the classifiers after using PCA to reduce the dimension\nof data improved. Experiments are conducted on three UCI data sets, Classic03,\nCNAE-9 and DBWorld e-mails. We compare the classification performance results\nof using PCA with popular and well-known text classifiers. Results show that\nusing PCA encouragingly enhances classification performance on most of the\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 08:50:35 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Taloba", "Ahmed I.", ""], ["Eisa", "D. A.", ""], ["Ismail", "Safaa S. I.", ""]]}, {"id": "1807.03288", "submitter": "Tommaso Renato Cesari", "authors": "Nicol\\`o Cesa-Bianchi, Tommaso Cesari, Vianney Perchet", "title": "Dynamic Pricing with Finitely Many Unknown Valuations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by posted price auctions where buyers are grouped in an unknown\nnumber of latent types characterized by their private values for the good on\nsale, we investigate revenue maximization in stochastic dynamic pricing when\nthe distribution of buyers' private values is supported on an unknown set of\npoints in [0,1] of unknown cardinality $K$. This setting can be viewed as an\ninstance of a stochastic $K$-armed bandit problem where the location of the\narms (the $K$ unknown valuations) must be learned as well. In the\ndistribution-free case, we prove that our setting is just as hard as $K$-armed\nstochastic bandits: no algorithm can achieve a regret significantly better than\n$\\sqrt{KT}$, (where T is the time horizon); we present an efficient algorithm\nmatching this lower bound up to logarithmic factors. In the\ndistribution-dependent case, we show that for all $K>2$ our setting is strictly\nharder than $K$-armed stochastic bandits by proving that it is impossible to\nobtain regret bounds that grow logarithmically in time or slower. On the other\nhand, when a lower bound $\\gamma>0$ on the smallest drop in the demand curve is\nknown, we prove an upper bound on the regret of order $(1/\\Delta+(\\log \\log\nT)/\\gamma^2)(K\\log T)$. This is a significant improvement on previously known\nregret bounds for discontinuous demand curves, that are at best of order\n$(K^{12}/\\gamma^8)\\sqrt{T}$. When $K=2$ in the distribution-dependent case, the\nhardness of our setting reduces to that of a stochastic $2$-armed bandit: we\nprove that an upper bound of order $(\\log T)/\\Delta$ (up to $\\log\\log$ factors)\non the regret can be achieved with no information on the demand curve. Finally,\nwe show a $O(\\sqrt{T})$ upper bound on the regret for the setting in which the\nbuyers' decisions are nonstochastic, and the regret is measured with respect to\nthe best between two fixed valuations one of which is known to the seller.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 17:42:22 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 09:16:36 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", ""], ["Cesari", "Tommaso", ""], ["Perchet", "Vianney", ""]]}, {"id": "1807.03299", "submitter": "Aurelien Garivier", "authors": "Gr\\'egoire Jauvion, Nicolas Grislain, Pascal Sielenou Dkengne (IMT),\n  Aur\\'elien Garivier (IMT), S\\'ebastien Gerchinovitz (IMT)", "title": "Optimization of a SSP's Header Bidding Strategy using Thompson Sampling", "comments": null, "journal-ref": "The 24th ACM SIGKDD International Conference on Knowledge\n  Discovery & Data Mining, Aug 2018, London, United Kingdom", "doi": "10.1145/3219819.3219917", "report-no": null, "categories": "cs.LG cs.GT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, digital media (web or app publishers) generalized the\nuse of real time ad auctions to sell their ad spaces. Multiple auction\nplatforms, also called Supply-Side Platforms (SSP), were created. Because of\nthis multiplicity, publishers started to create competition between SSPs. In\nthis setting, there are two successive auctions: a second price auction in each\nSSP and a secondary, first price auction, called header bidding auction,\nbetween SSPs.In this paper, we consider an SSP competing with other SSPs for ad\nspaces. The SSP acts as an intermediary between an advertiser wanting to buy ad\nspaces and a web publisher wanting to sell its ad spaces, and needs to define a\nbidding strategy to be able to deliver to the advertisers as many ads as\npossible while spending as little as possible. The revenue optimization of this\nSSP can be written as a contextual bandit problem, where the context consists\nof the information available about the ad opportunity, such as properties of\nthe internet user or of the ad placement.Using classical multi-armed bandit\nstrategies (such as the original versions of UCB and EXP3) is inefficient in\nthis setting and yields a low convergence speed, as the arms are very\ncorrelated. In this paper we design and experiment a version of the Thompson\nSampling algorithm that easily takes this correlation into account. We combine\nthis bayesian algorithm with a particle filter, which permits to handle\nnon-stationarity by sequentially estimating the distribution of the highest bid\nto beat in order to win an auction. We apply this methodology on two real\nauction datasets, and show that it significantly outperforms more classical\napproaches.The strategy defined in this paper is being developed to be deployed\non thousands of publishers worldwide.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 08:47:19 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Jauvion", "Gr\u00e9goire", "", "IMT"], ["Grislain", "Nicolas", "", "IMT"], ["Dkengne", "Pascal Sielenou", "", "IMT"], ["Garivier", "Aur\u00e9lien", "", "IMT"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"]]}, {"id": "1807.03326", "submitter": "Xiaoyong Yuan", "authors": "Xiaoyong Yuan, Pan He, Xiaolin Andy Li, Dapeng Oliver Wu", "title": "Adaptive Adversarial Attack on Scene Text Recognition", "comments": "To be appear in INFOCOM 2020, The Eighth International Workshop on\n  Security and Privacy in Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that state-of-the-art deep learning models are\nvulnerable to the inputs with small perturbations (adversarial examples). We\nobserve two critical obstacles in adversarial examples: (i) Strong adversarial\nattacks (e.g., C&W attack) require manually tuning hyper-parameters and take a\nlong time to construct an adversarial example, making it impractical to attack\nreal-time systems; (ii) Most of the studies focus on non-sequential tasks, such\nas image classification, yet only a few consider sequential tasks. In this\nwork, we speed up adversarial attacks, especially on sequential learning tasks.\nBy leveraging the uncertainty of each task, we directly learn the adaptive\nmulti-task weightings, without manually searching hyper-parameters. A unified\narchitecture is developed and evaluated for both non-sequential tasks and\nsequential ones. To validate the effectiveness, we take the scene text\nrecognition task as a case study. To our best knowledge, our proposed method is\nthe first attempt to adversarial attack for scene text recognition. Adaptive\nAttack achieves over 99.9\\% success rate with 3-6X speedup compared to\nstate-of-the-art adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 18:12:27 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 18:57:08 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 15:40:36 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yuan", "Xiaoyong", ""], ["He", "Pan", ""], ["Li", "Xiaolin Andy", ""], ["Wu", "Dapeng Oliver", ""]]}, {"id": "1807.03341", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Jacob Steinhardt", "title": "Troubling Trends in Machine Learning Scholarship", "comments": "Presented at ICML 2018: The Debates", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collectively, machine learning (ML) researchers are engaged in the creation\nand dissemination of knowledge about data-driven algorithms. In a given paper,\nresearchers might aspire to any subset of the following goals, among others: to\ntheoretically characterize what is learnable, to obtain understanding through\nempirically rigorous experiments, or to build a working system that has high\npredictive accuracy. While determining which knowledge warrants inquiry may be\nsubjective, once the topic is fixed, papers are most valuable to the community\nwhen they act in service of the reader, creating foundational knowledge and\ncommunicating as clearly as possible.\n  Recent progress in machine learning comes despite frequent departures from\nthese ideals. In this paper, we focus on the following four patterns that\nappear to us to be trending in ML scholarship: (i) failure to distinguish\nbetween explanation and speculation; (ii) failure to identify the sources of\nempirical gains, e.g., emphasizing unnecessary modifications to neural\narchitectures when gains actually stem from hyper-parameter tuning; (iii)\nmathiness: the use of mathematics that obfuscates or impresses rather than\nclarifies, e.g., by confusing technical and non-technical concepts; and (iv)\nmisuse of language, e.g., by choosing terms of art with colloquial connotations\nor by overloading established technical terms.\n  While the causes behind these patterns are uncertain, possibilities include\nthe rapid expansion of the community, the consequent thinness of the reviewer\npool, and the often-misaligned incentives between scholarship and short-term\nmeasures of success (e.g., bibliometrics, attention, and entrepreneurial\nopportunity). While each pattern offers a corresponding remedy (don't do it),\nwe also discuss some speculative suggestions for how the community might combat\nthese trends.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 18:59:17 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 12:54:30 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1807.03361", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Marc Modat, Eli Gibson, Wenqi Li, Nooshin Ghavami, Ester\n  Bonmati, Guotai Wang, Steven Bandula, Caroline M. Moore, Mark Emberton,\n  S\\'ebastien Ourselin, J. Alison Noble, Dean C. Barratt, Tom Vercauteren", "title": "Weakly-Supervised Convolutional Neural Networks for Multimodal Image\n  Registration", "comments": "Accepted manuscript in Medical Image Analysis", "journal-ref": null, "doi": "10.1016/j.media.2018.07.002", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the fundamental challenges in supervised learning for multimodal image\nregistration is the lack of ground-truth for voxel-level spatial\ncorrespondence. This work describes a method to infer voxel-level\ntransformation from higher-level correspondence information contained in\nanatomical labels. We argue that such labels are more reliable and practical to\nobtain for reference sets of image pairs than voxel-level correspondence.\nTypical anatomical labels of interest may include solid organs, vessels, ducts,\nstructure boundaries and other subject-specific ad hoc landmarks. The proposed\nend-to-end convolutional neural network approach aims to predict displacement\nfields to align multiple labelled corresponding structures for individual image\npairs during the training, while only unlabelled image pairs are used as the\nnetwork input for inference. We highlight the versatility of the proposed\nstrategy, for training, utilising diverse types of anatomical labels, which\nneed not to be identifiable over all training image pairs. At inference, the\nresulting 3D deformable image registration algorithm runs in real-time and is\nfully-automated without requiring any anatomical labels or initialisation.\nSeveral network architecture variants are compared for registering T2-weighted\nmagnetic resonance images and 3D transrectal ultrasound images from prostate\ncancer patients. A median target registration error of 3.6 mm on landmark\ncentroids and a median Dice of 0.87 on prostate glands are achieved from\ncross-validation experiments, in which 108 pairs of multimodal images from 76\npatients were tested with high-quality anatomical labels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 19:53:16 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Hu", "Yipeng", ""], ["Modat", "Marc", ""], ["Gibson", "Eli", ""], ["Li", "Wenqi", ""], ["Ghavami", "Nooshin", ""], ["Bonmati", "Ester", ""], ["Wang", "Guotai", ""], ["Bandula", "Steven", ""], ["Moore", "Caroline M.", ""], ["Emberton", "Mark", ""], ["Ourselin", "S\u00e9bastien", ""], ["Noble", "J. Alison", ""], ["Barratt", "Dean C.", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1807.03367", "submitter": "Harm de Vries", "authors": "Harm de Vries, Kurt Shuster, Dhruv Batra, Devi Parikh, Jason Weston,\n  Douwe Kiela", "title": "Talk the Walk: Navigating New York City through Grounded Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"Talk The Walk\", the first large-scale dialogue dataset grounded\nin action and perception. The task involves two agents (a \"guide\" and a\n\"tourist\") that communicate via natural language in order to achieve a common\ngoal: having the tourist navigate to a given target location. The task and\ndataset, which are described in detail, are challenging and their full solution\nis an open problem that we pose to the community. We (i) focus on the task of\ntourist localization and develop the novel Masked Attention for Spatial\nConvolutions (MASC) mechanism that allows for grounding tourist utterances into\nthe guide's map, (ii) show it yields significant improvements for both emergent\nand natural language communication, and (iii) using this method, we establish\nnon-trivial baselines on the full task.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:05:24 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 16:07:08 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 22:42:59 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["de Vries", "Harm", ""], ["Shuster", "Kurt", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""]]}, {"id": "1807.03368", "submitter": "Jos\\'e Bento", "authors": "Sam Safavi and Jos\\'e Bento", "title": "Tractable $n$-Metrics for Multiple Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG eess.SP math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are used in almost every scientific discipline to express relations\namong a set of objects. Algorithms that compare graphs, and output a closeness\nscore, or a correspondence among their nodes, are thus extremely important.\nDespite the large amount of work done, many of the scalable algorithms to\ncompare graphs do not produce closeness scores that satisfy the intuitive\nproperties of metrics. This is problematic since non-metrics are known to\ndegrade the performance of algorithms such as distance-based clustering of\ngraphs (Stratis and Bento 2018). On the other hand, the use of metrics\nincreases the performance of several machine learning tasks (Indyk et al. 1999,\nClarkson et al. 1999, Angiulli et al. 2002, Ackermann et al. 2010). In this\npaper, we introduce a new family of multi-distances (a distance between more\nthan two elements) that satisfies a generalization of the properties of metrics\nto multiple elements. In the context of comparing graphs, we are the first to\nshow the existence of multi-distances that simultaneously incorporate the\nuseful property of alignment consistency (Nguyen et al. 2011), and a\ngeneralized metric property. Furthermore, we show that these multi-distances\ncan be relaxed to convex optimization problems, without losing the generalized\nmetric property.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:13:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 16:41:43 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 18:35:30 GMT"}, {"version": "v4", "created": "Sat, 14 Nov 2020 21:08:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Safavi", "Sam", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1807.03369", "submitter": "Danil Kuzin", "authors": "Danil Kuzin, Le Yang, Olga Isupova, Lyudmila Mihaylova", "title": "Ensemble Kalman Filtering for Online Gaussian Process Regression and\n  Learning", "comments": "FUSION 2018", "journal-ref": null, "doi": "10.23919/ICIF.2018.8455785", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process regression is a machine learning approach which has been\nshown its power for estimation of unknown functions. However, Gaussian\nprocesses suffer from high computational complexity, as in a basic form they\nscale cubically with the number of observations. Several approaches based on\ninducing points were proposed to handle this problem in a static context. These\nmethods though face challenges with real-time tasks and when the data is\nreceived sequentially over time. In this paper, a novel online algorithm for\ntraining sparse Gaussian process models is presented. It treats the mean and\nhyperparameters of the Gaussian process as the state and parameters of the\nensemble Kalman filter, respectively. The online evaluation of the parameters\nand the state is performed on new upcoming samples of data. This procedure\niteratively improves the accuracy of parameter estimates. The ensemble Kalman\nfilter reduces the computational complexity required to obtain predictions with\nGaussian processes preserving the accuracy level of these predictions. The\nperformance of the proposed method is demonstrated on the synthetic dataset and\nreal large dataset of UK house prices.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:20:20 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Kuzin", "Danil", ""], ["Yang", "Le", ""], ["Isupova", "Olga", ""], ["Mihaylova", "Lyudmila", ""]]}, {"id": "1807.03379", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh and Kannan Ramchandran", "title": "Online Scoring with Delayed Information: A Convex Optimization Viewpoint", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system where agents enter in an online fashion and are\nevaluated based on their attributes or context vectors. There can be practical\nsituations where this context is partially observed, and the unobserved part\ncomes after some delay. We assume that an agent, once left, cannot re-enter the\nsystem. Therefore, the job of the system is to provide an estimated score for\nthe agent based on her instantaneous score and possibly some inference of the\ninstantaneous score over the delayed score. In this paper, we estimate the\ndelayed context via an online convex game between the agent and the system. We\nargue that the error in the score estimate accumulated over $T$ iterations is\nsmall if the regret of the online convex game is small. Further, we leverage\nside information about the delayed context in the form of a correlation\nfunction with the known context. We consider the settings where the delay is\nfixed or arbitrarily chosen by an adversary. Furthermore, we extend the\nformulation to the setting where the contexts are drawn from some Banach space.\nOverall, we show that the average penalty for not knowing the delayed context\nwhile making a decision scales with $\\mathcal{O}(\\frac{1}{\\sqrt{T}})$, where\nthis can be improved to $\\mathcal{O}(\\frac{\\log T}{T})$ under special setting.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:40:17 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Ghosh", "Avishek", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1807.03387", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, Vladimir Zadorozhny", "title": "Process Monitoring Using Maximum Sequence Divergence", "comments": null, "journal-ref": "Knowledge and Information Systems 48.1 (2016): 81-109", "doi": "10.1007/s10115-015-0858-z", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process Monitoring involves tracking a system's behaviors, evaluating the\ncurrent state of the system, and discovering interesting events that require\nimmediate actions. In this paper, we consider monitoring temporal system state\nsequences to help detect the changes of dynamic systems, check the divergence\nof the system development, and evaluate the significance of the deviation. We\nbegin with discussions of data reduction, symbolic data representation, and the\nanomaly detection in temporal discrete sequences. Time-series representation\nmethods are also discussed and used in this paper to discretize raw data into\nsequences of system states. Markov Chains and stationary state distributions\nare continuously generated from temporal sequences to represent snapshots of\nthe system dynamics in different time frames. We use generalized Jensen-Shannon\nDivergence as the measure to monitor changes of the stationary symbol\nprobability distributions and evaluate the significance of system deviations.\nWe prove that the proposed approach is able to detect deviations of the systems\nwe monitor and assess the deviation significance in probabilistic manner.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:07:14 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kang", "Yihuang", ""], ["Zadorozhny", "Vladimir", ""]]}, {"id": "1807.03395", "submitter": "Ao Liu", "authors": "Ao Liu, Qiong Wu, Zhenming Liu and Lirong Xia", "title": "Towards Non-Parametric Learning to Rank", "comments": "10 pages' main document and 10 pages' supplementary documents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a stylized, yet natural, learning-to-rank problem and\npoints out the critical incorrectness of a widely used nearest neighbor\nalgorithm. We consider a model with $n$ agents (users) $\\{x_i\\}_{i \\in [n]}$\nand $m$ alternatives (items) $\\{y_j\\}_{j \\in [m]}$, each of which is associated\nwith a latent feature vector. Agents rank items nondeterministically according\nto the Plackett-Luce model, where the higher the utility of an item to the\nagent, the more likely this item will be ranked high by the agent. Our goal is\nto find neighbors of an arbitrary agent or alternative in the latent space.\n  We first show that the Kendall-tau distance based kNN produces incorrect\nresults in our model. Next, we fix the problem by introducing a new algorithm\nwith features constructed from \"global information\" of the data matrix. Our\napproach is in sharp contrast to most existing feature engineering methods.\nFinally, we design another new algorithm identifying similar alternatives. The\nconstruction of alternative features can be done using \"local information,\"\nhighlighting the algorithmic difference between finding similar agents and\nsimilar alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:27:14 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Liu", "Ao", ""], ["Wu", "Qiong", ""], ["Liu", "Zhenming", ""], ["Xia", "Lirong", ""]]}, {"id": "1807.03396", "submitter": "Hao Tang", "authors": "Hao Tang and James Glass", "title": "On Training Recurrent Networks with Truncated Backpropagation Through\n  Time in Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have been the dominant models for many speech and\nlanguage processing tasks. However, we understand little about the behavior and\nthe class of functions recurrent networks can realize. Moreover, the heuristics\nused during training complicate the analyses. In this paper, we study recurrent\nnetworks' ability to learn long-term dependency in the context of speech\nrecognition. We consider two decoding approaches, online and batch decoding,\nand show the classes of functions to which the decoding approaches correspond.\nWe then draw a connection between batch decoding and a popular training\napproach for recurrent networks, truncated backpropagation through time.\nChanging the decoding approach restricts the amount of past history recurrent\nnetworks can use for prediction, allowing us to analyze their ability to\nremember. Empirically, we utilize long-term dependency in subphonetic states,\nphonemes, and words, and show how the design decisions, such as the decoding\napproach, lookahead, context frames, and consecutive prediction, characterize\nthe behavior of recurrent networks. Finally, we draw a connection between\nMarkov processes and vanishing gradients. These results have implications for\nstudying the long-term dependency in speech data and how these properties are\nlearned by recurrent networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:31:49 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 15:41:08 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 17:17:30 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1807.03402", "submitter": "Vsevolod Sourkov M", "authors": "Vsevolod Sourkov", "title": "IGLOO: Slicing the Features Space to Represent Sequences", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, Recurrent neural networks (RNNs) and its variants such as LSTM\nand GRU and more recently Transformers have been the standard go-to components\nwhen processing sequential data with neural networks. One notable issue is the\nrelative difficulty to deal with long sequences (i.e. more than 20,000 steps).\nWe introduce IGLOO, a new neural network architecture which aims at being\nefficient for short sequences but also at being able to deal with long\nsequences. IGLOOs core idea is to use the relationships between non-local\npatches sliced out of the features maps of successively applied convolutions to\nbuild a representation for the sequence. We show that the model can deal with\ndependencies of more than 20,000 steps in a reasonable time frame. We stress\ntest IGLOO on the copy-memory and addition tasks, as well as permuted MNIST\n(98.4%). For a larger task we apply this new structure to the Wikitext-2\ndataset Merity et al. (2017b) and achieve a perplexity in line with baseline\nTransformers but lower than baseline AWD-LSTM. We also present how IGLOO is\nalready used today in production for bioinformatics tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:57:20 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 20:45:21 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 16:33:01 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Sourkov", "Vsevolod", ""]]}, {"id": "1807.03404", "submitter": "Tian Xie", "authors": "Tian Xie, Jeffrey C. Grossman", "title": "Hierarchical Visualization of Materials Space with Graph Convolutional\n  Neural Networks", "comments": "22 + 7 pages, 6 + 5 figures", "journal-ref": "J. Chem. Phys. 149, 174111 (2018)", "doi": "10.1063/1.5047803", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of high throughput computation and machine learning has led\nto a new paradigm in materials design by allowing for the direct screening of\nvast portions of structural, chemical, and property space. The use of these\npowerful techniques leads to the generation of enormous amounts of data, which\nin turn calls for new techniques to efficiently explore and visualize the\nmaterials space to help identify underlying patterns. In this work, we develop\na unified framework to hierarchically visualize the compositional and\nstructural similarities between materials in an arbitrary material space with\nrepresentations learned from different layers of graph convolutional neural\nnetworks. We demonstrate the potential for such a visualization approach by\nshowing that patterns emerge automatically that reflect similarities at\ndifferent scales in three representative classes of materials: perovskites,\nelemental boron, and general inorganic crystals, covering material spaces of\ndifferent compositions, structures, and both. For perovskites, elemental\nsimilarities are learned that reflects multiple aspects of atom properties. For\nelemental boron, structural motifs emerge automatically showing characteristic\nboron local environments. For inorganic crystals, the similarity and stability\nof local coordination environments are shown combining different center and\nneighbor atoms. The method could help transition to a data-centered exploration\nof materials space in automated materials design.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 22:06:04 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 04:43:35 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Xie", "Tian", ""], ["Grossman", "Jeffrey C.", ""]]}, {"id": "1807.03418", "submitter": "S\\\"oren Becker", "authors": "S\\\"oren Becker, Marcel Ackermann, Sebastian Lapuschkin, Klaus-Robert\n  M\\\"uller, Wojciech Samek", "title": "Interpreting and Explaining Deep Neural Networks for Classification of\n  Audio Signals", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of deep neural networks is a recently emerging area of\nmachine learning research targeting a better understanding of how models\nperform feature selection and derive their classification decisions. This paper\nexplores the interpretability of neural networks in the audio domain by using\nthe previously proposed technique of layer-wise relevance propagation (LRP). We\npresent a novel audio dataset of English spoken digits which we use for\nclassification tasks on spoken digits and speaker's gender. We use LRP to\nidentify relevant features for two neural network architectures that process\neither waveform or spectrogram representations of the data. Based on the\nrelevance scores obtained from LRP, hypotheses about the neural networks'\nfeature selection are derived and subsequently tested through systematic\nmanipulations of the input data. The results confirm that the networks are\nhighly reliant on features marked as relevant by LRP.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 23:11:17 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 11:16:44 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Becker", "S\u00f6ren", ""], ["Ackermann", "Marcel", ""], ["Lapuschkin", "Sebastian", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1807.03425", "submitter": "Elin Farnell", "authors": "Henry Kvinge, Elin Farnell, Michael Kirby, and Chris Peterson", "title": "A GPU-Oriented Algorithm Design for Secant-Based Dimensionality\n  Reduction", "comments": "To appear in the 17th IEEE International Symposium on Parallel and\n  Distributed Computing, Geneva, Switzerland 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality-reduction techniques are a fundamental tool for extracting\nuseful information from high-dimensional data sets. Because secant sets encode\nmanifold geometry, they are a useful tool for designing meaningful\ndata-reduction algorithms. In one such approach, the goal is to construct a\nprojection that maximally avoids secant directions and hence ensures that\ndistinct data points are not mapped too close together in the reduced space.\nThis type of algorithm is based on a mathematical framework inspired by the\nconstructive proof of Whitney's embedding theorem from differential topology.\nComputing all (unit) secants for a set of points is by nature computationally\nexpensive, thus opening the door for exploitation of GPU architecture for\nachieving fast versions of these algorithms. We present a polynomial-time\ndata-reduction algorithm that produces a meaningful low-dimensional\nrepresentation of a data set by iteratively constructing improved projections\nwithin the framework described above. Key to our algorithm design and\nimplementation is the use of GPUs which, among other things, minimizes the\ncomputational time required for the calculation of all secant lines. One goal\nof this report is to share ideas with GPU experts and to discuss a class of\nmathematical algorithms that may be of interest to the broader GPU community.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 00:02:16 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kvinge", "Henry", ""], ["Farnell", "Elin", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""]]}, {"id": "1807.03431", "submitter": "Carlos Brito", "authors": "Carlos David Brito Pacheco, Carlos Francisco Brito Loeza", "title": "A New Variational Model for Binary Classification in the Supervised\n  Learning Context", "comments": "9 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the supervised learning problem in its continuous setting and give\na general optimality condition through techniques of functional analysis and\nthe calculus of variations. This enables us to solve the optimality condition\nfor the desired function u numerically and make several comparisons with other\nwidely utilized supervised learning models. We employ the accuracy and area\nunder the receiver operating characteristic curve as metrics of the\nperformance. Finally, 3 analyses are conducted based on these two mentioned\nmetrics where we compare the models and make conclusions to determine whether\nor not our method is competitive.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 00:57:03 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 02:09:42 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Pacheco", "Carlos David Brito", ""], ["Loeza", "Carlos Francisco Brito", ""]]}, {"id": "1807.03440", "submitter": "Asim Iqbal", "authors": "Asim Iqbal, Romesa Khan, Theofanis Karayannis", "title": "Developing Brain Atlas through Deep Learning", "comments": "31 pages, 17 figures, 1 Table", "journal-ref": null, "doi": "10.1038/s42256-019-0058-8", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists have devoted significant effort into the creation of standard\nbrain reference atlases for high-throughput registration of anatomical regions\nof interest. However, variability in brain size and form across individuals\nposes a significant challenge for such reference atlases. To overcome these\nlimitations, we introduce a fully automated deep neural network-based method\n(SeBRe) for registration through Segmenting Brain Regions of interest with\nminimal human supervision. We demonstrate the validity of our method on brain\nimages from different mouse developmental time points, across a range of\nneuronal markers and imaging modalities. We further assess the performance of\nour method on images from MR-scanned human brains. Our registration method can\naccelerate brain-wide exploration of region-specific changes in brain\ndevelopment and, by simply segmenting brain regions of interest for\nhigh-throughput brain-wide analysis, provides an alternative to existing\ncomplex brain registration techniques.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 01:28:44 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:01:56 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Iqbal", "Asim", ""], ["Khan", "Romesa", ""], ["Karayannis", "Theofanis", ""]]}, {"id": "1807.03456", "submitter": "Jeremy Diaz", "authors": "Jeremy Diaz and Maxwell Joseph", "title": "Predicting property damage from tornadoes with zero-inflated neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tornadoes are the most violent of all atmospheric storms. In a typical year,\nthe United States experiences hundreds of tornadoes with associated damages on\nthe order of one billion dollars. Community preparation and resilience would\nbenefit from accurate predictions of these economic losses, particularly as\npopulations in tornado-prone areas increase in density and extent. Here, we use\na zero-inflated modeling approach and artificial neural networks to predict\ntornado-induced property damage using publicly available data. We developed a\nneural network that predicts whether a tornado will cause property damage\n(out-of-sample accuracy = 0.821 and area under the receiver operating\ncharacteristic curve, AUROC, = 0.872). Conditional on a tornado causing damage,\nanother neural network predicts the amount of damage (out-of-sample mean\nsquared error = 0.0918 and R2 = 0.432). When used together, these two models\nfunction as a zero-inflated log-normal regression with hidden layers. From the\nbest-performing models, we provide static and interactive gridded maps of\nmonthly predicted probabilities of damage and property damages for the year\n2019. Two primary weaknesses include (1) model fitting requires log-scale data\nwhich leads to large natural-scale residuals and (2) beginning tornado\ncoordinates were utilized rather than tornado paths. Ultimately, this is the\nfirst known study to directly model tornado-induced property damages, and all\ndata, code, and tools are publicly available. The predictive capacity of this\nmodel along with an interactive interface may provide an opportunity for\nscience-informed tornado disaster planning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 02:39:33 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 22:32:08 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 17:54:24 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Diaz", "Jeremy", ""], ["Joseph", "Maxwell", ""]]}, {"id": "1807.03464", "submitter": "Ravi Kumar Thakur", "authors": "Ravi Kumar Thakur and Snehasis Mukherjee", "title": "SceneEDNet: A Deep Learning Approach for Scene Flow Estimation", "comments": null, "journal-ref": "ICARCV (2018) 394-399", "doi": "10.1109/ICARCV.2018.8581172", "report-no": null, "categories": "cs.CV cs.CG cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating scene flow in RGB-D videos is attracting much interest of the\ncomputer vision researchers, due to its potential applications in robotics. The\nstate-of-the-art techniques for scene flow estimation, typically rely on the\nknowledge of scene structure of the frame and the correspondence between\nframes. However, with the increasing amount of RGB-D data captured from\nsophisticated sensors like Microsoft Kinect, and the recent advances in the\narea of sophisticated deep learning techniques, introduction of an efficient\ndeep learning technique for scene flow estimation, is becoming important. This\npaper introduces a first effort to apply a deep learning method for direct\nestimation of scene flow by presenting a fully convolutional neural network\nwith an encoder-decoder (ED) architecture. The proposed network SceneEDNet\ninvolves estimation of three dimensional motion vectors of all the scene points\nfrom sequence of stereo images. The training for direct estimation of scene\nflow is done using consecutive pairs of stereo images and corresponding scene\nflow ground truth. The proposed architecture is applied on a huge dataset and\nprovides meaningful results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 03:26:55 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Thakur", "Ravi Kumar", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1807.03478", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura", "title": "An Adaptive Learning Method of Restricted Boltzmann Machine by Neuron\n  Generation and Annihilation Algorithm", "comments": "6 pages, 6 figures", "journal-ref": "Proc. of 2016 IEEE International Conference on Systems, Man, and\n  Cybernetics (IEEE SMC 2016)", "doi": "10.1109/SMC.2016.7844417", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machine (RBM) is a generative stochastic energy-based\nmodel of artificial neural network for unsupervised learning. Recently, RBM is\nwell known to be a pre-training method of Deep Learning. In addition to visible\nand hidden neurons, the structure of RBM has a number of parameters such as the\nweights between neurons and the coefficients for them. Therefore, we may meet\nsome difficulties to determine an optimal network structure to analyze big\ndata. In order to evade the problem, we investigated the variance of parameters\nto find an optimal structure during learning. For the reason, we should check\nthe variance of parameters to cause the fluctuation for energy function in RBM\nmodel. In this paper, we propose the adaptive learning method of RBM that can\ndiscover an optimal number of hidden neurons according to the training\nsituation by applying the neuron generation and annihilation algorithm. In this\nmethod, a new hidden neuron is generated if the energy function is not still\nconverged and the variance of the parameters is large. Moreover, the\ninactivated hidden neuron will be annihilated if the neuron does not affect the\nlearning situation. The experimental results for some benchmark data sets were\ndiscussed in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 04:39:18 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 08:06:52 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""]]}, {"id": "1807.03480", "submitter": "De-An Huang", "authors": "De-An Huang, Suraj Nair, Danfei Xu, Yuke Zhu, Animesh Garg, Li\n  Fei-Fei, Silvio Savarese, Juan Carlos Niebles", "title": "Neural Task Graphs: Generalizing to Unseen Tasks from a Single Video\n  Demonstration", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to generate a policy to complete an unseen task given just a\nsingle video demonstration of the task in a given domain. We hypothesize that\nto successfully generalize to unseen complex tasks from a single video\ndemonstration, it is necessary to explicitly incorporate the compositional\nstructure of the tasks into the model. To this end, we propose Neural Task\nGraph (NTG) Networks, which use conjugate task graph as the intermediate\nrepresentation to modularize both the video demonstration and the derived\npolicy. We empirically show NTG achieves inter-task generalization on two\ncomplex tasks: Block Stacking in BulletPhysics and Object Collection in\nAI2-THOR. NTG improves data efficiency with visual input as well as achieve\nstrong generalization without the need for dense hierarchical supervision. We\nfurther show that similar performance trends hold when applied to real-world\ndata. We show that NTG can effectively predict task structure on the JIGSAWS\nsurgical dataset and generalize to unseen tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 04:55:45 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 21:56:52 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Huang", "De-An", ""], ["Nair", "Suraj", ""], ["Xu", "Danfei", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""], ["Niebles", "Juan Carlos", ""]]}, {"id": "1807.03490", "submitter": "Yu Shi", "authors": "Yu Shi and Qi Zhu and Fang Guo and Chao Zhang and Jiawei Han", "title": "Easing Embedding Learning by Comprehensive Transcription of\n  Heterogeneous Information Networks", "comments": "10 pages. In Proceedings of the 24th ACM SIGKDD International\n  Conference on Knowledge Discovery and Data Mining, London, United Kingdom,\n  ACM, 2018", "journal-ref": null, "doi": "10.1145/3219819.3220006", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information networks (HINs) are ubiquitous in real-world\napplications. In the meantime, network embedding has emerged as a convenient\ntool to mine and learn from networked data. As a result, it is of interest to\ndevelop HIN embedding methods. However, the heterogeneity in HINs introduces\nnot only rich information but also potentially incompatible semantics, which\nposes special challenges to embedding learning in HINs. With the intention to\npreserve the rich yet potentially incompatible information in HIN embedding, we\npropose to study the problem of comprehensive transcription of heterogeneous\ninformation networks. The comprehensive transcription of HINs also provides an\neasy-to-use approach to unleash the power of HINs, since it requires no\nadditional supervision, expertise, or feature engineering. To cope with the\nchallenges in the comprehensive transcription of HINs, we propose the HEER\nalgorithm, which embeds HINs via edge representations that are further coupled\nwith properly-learned heterogeneous metrics. To corroborate the efficacy of\nHEER, we conducted experiments on two large-scale real-words datasets with an\nedge reconstruction task and multiple case studies. Experiment results\ndemonstrate the effectiveness of the proposed HEER model and the utility of\nedge representations and heterogeneous metrics. The code and data are available\nat https://github.com/GentleZhu/HEER.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:21:22 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Shi", "Yu", ""], ["Zhu", "Qi", ""], ["Guo", "Fang", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "1807.03520", "submitter": "Matheus Gadelha", "authors": "Matheus Gadelha, Rui Wang and Subhransu Maji", "title": "Multiresolution Tree Networks for 3D Point Cloud Processing", "comments": "Accepted to ECCV 2018. 23 pages, including supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present multiresolution tree-structured networks to process point clouds\nfor 3D shape understanding and generation tasks. Our network represents a 3D\nshape as a set of locality-preserving 1D ordered list of points at multiple\nresolutions. This allows efficient feed-forward processing through 1D\nconvolutions, coarse-to-fine analysis through a multi-grid architecture, and it\nleads to faster convergence and small memory footprint during training. The\nproposed tree-structured encoders can be used to classify shapes and outperform\nexisting point-based architectures on shape classification benchmarks, while\ntree-structured decoders can be used for generating point clouds directly and\nthey outperform existing approaches for image-to-shape inference tasks learned\nusing the ShapeNet dataset. Our model also allows unsupervised learning of\npoint-cloud based shapes by using a variational autoencoder, leading to\nhigher-quality generated shapes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:28:01 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 20:19:30 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Gadelha", "Matheus", ""], ["Wang", "Rui", ""], ["Maji", "Subhransu", ""]]}, {"id": "1807.03521", "submitter": "Yehezkel Resheff", "authors": "Yehezkel S. Resheff, Yanai Elazar, Moni Shahar, Oren Sar Shalom", "title": "Privacy and Fairness in Recommender Systems via Adversarial Training of\n  User Representations", "comments": "International Conference on Pattern Recognition and Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models for recommender systems represent users and items as low\ndimensional vectors. Privacy risks of such systems have previously been studied\nmostly in the context of recovery of personal information in the form of usage\nrecords from the training data. However, the user representations themselves\nmay be used together with external data to recover private user information\nsuch as gender and age. In this paper we show that user vectors calculated by a\ncommon recommender system can be exploited in this way. We propose the\nprivacy-adversarial framework to eliminate such leakage of private information,\nand study the trade-off between recommender performance and leakage both\ntheoretically and empirically using a benchmark dataset. An advantage of the\nproposed method is that it also helps guarantee fairness of results, since all\nimplicit knowledge of a set of attributes is scrubbed from the representations\nused by the model, and thus can't enter into the decision making. We discuss\nfurther applications of this method towards the generation of deeper and more\ninsightful recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:33:20 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 19:47:46 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 06:21:43 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Resheff", "Yehezkel S.", ""], ["Elazar", "Yanai", ""], ["Shahar", "Moni", ""], ["Shalom", "Oren Sar", ""]]}, {"id": "1807.03523", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Jamal Toutouh and Enrique Alba", "title": "DLOPT: Deep Learning Optimization Library", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning hyper-parameter optimization is a tough task. Finding an\nappropriate network configuration is a key to success, however most of the\ntimes this labor is roughly done. In this work we introduce a novel library to\ntackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly\ndescribe its architecture and present a set of use examples. This is an open\nsource project developed under the GNU GPL v3 license and it is freely\navailable at https://github.com/acamero/dlopt\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:34:25 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Toutouh", "Jamal", ""], ["Alba", "Enrique", ""]]}, {"id": "1807.03527", "submitter": "Joris Mooij", "authors": "Thijs van Ommen, Joris M. Mooij", "title": "Algebraic Equivalence of Linear Structural Equation Models", "comments": "Published in (online) Proceedings of the 33rd Annual Conference on\n  Uncertainty in Artificial Intelligence (UAI-17)", "journal-ref": "Proceedings of the 33rd Annual Conference on Uncertainty in\n  Artificial Intelligence, 2017", "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their popularity, many questions about the algebraic constraints\nimposed by linear structural equation models remain open problems. For causal\ndiscovery, two of these problems are especially important: the enumeration of\nthe constraints imposed by a model, and deciding whether two graphs define the\nsame statistical model. We show how the half-trek criterion can be used to make\nprogress in both of these problems. We apply our theoretical results to a\nsmall-scale model selection problem, and find that taking the additional\nalgebraic constraints into account may lead to significant improvements in\nmodel selection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:38:37 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["van Ommen", "Thijs", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1807.03545", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "Martin Bompaire, Emmanuel Bacry, St\\'ephane Ga\\\"iffas", "title": "Dual optimization for convex constrained objectives without the\n  gradient-Lipschitz assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of convex objectives coming from linear supervised learning\nproblems, such as penalized generalized linear models, can be formulated as\nfinite sums of convex functions. For such problems, a large set of stochastic\nfirst-order solvers based on the idea of variance reduction are available and\ncombine both computational efficiency and sound theoretical guarantees (linear\nconvergence rates). Such rates are obtained under both gradient-Lipschitz and\nstrong convexity assumptions. Motivated by learning problems that do not meet\nthe gradient-Lipschitz assumption, such as linear Poisson regression, we work\nunder another smoothness assumption, and obtain a linear convergence rate for a\nshifted version of Stochastic Dual Coordinate Ascent (SDCA) that improves the\ncurrent state-of-the-art. Our motivation for considering a solver working on\nthe Fenchel-dual problem comes from the fact that such objectives include many\nlinear constraints, that are easier to deal with in the dual. Our approach and\ntheoretical findings are validated on several datasets, for Poisson regression\nand another objective coming from the negative log-likelihood of the Hawkes\nprocess, which is a family of models which proves extremely useful for the\nmodeling of information propagation in social networks and causality inference.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 09:24:06 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 18:18:36 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Bompaire", "Martin", ""], ["Bacry", "Emmanuel", ""], ["Ga\u00efffas", "St\u00e9phane", ""]]}, {"id": "1807.03555", "submitter": "Martin Zaefferer", "authors": "Martin Zaefferer, Thomas Bartz-Beielstein and G\\\"unter Rudolph", "title": "An Empirical Approach For Probing the Definiteness of Kernels", "comments": "preprint submitted to Soft Computing journal, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models like support vector machines or Gaussian process regression often\nrequire positive semi-definite kernels. These kernels may be based on distance\nfunctions. While definiteness is proven for common distances and kernels, a\nproof for a new kernel may require too much time and effort for users who\nsimply aim at practical usage. Furthermore, designing definite distances or\nkernels may be equally intricate. Finally, models can be enabled to use\nindefinite kernels. This may deteriorate the accuracy or computational cost of\nthe model. Hence, an efficient method to determine definiteness is required. We\npropose an empirical approach. We show that sampling as well as optimization\nwith an evolutionary algorithm may be employed to determine definiteness. We\nprovide a proof-of-concept with 16 different distance measures for\npermutations. Our approach allows to disprove definiteness if a respective\ncounter-example is found. It can also provide an estimate of how likely it is\nto obtain indefinite kernel matrices. This provides a simple, efficient tool to\ndecide whether additional effort should be spent on designing/selecting a more\nsuitable kernel or algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 10:04:58 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Zaefferer", "Martin", ""], ["Bartz-Beielstein", "Thomas", ""], ["Rudolph", "G\u00fcnter", ""]]}, {"id": "1807.03558", "submitter": "R\\'emy Degenne", "authors": "R\\'emy Degenne, Evrard Garcelon, Vianney Perchet", "title": "Bandits with Side Observations: Bounded vs. Logarithmic Regret", "comments": "Conference on Uncertainty in Artificial Intelligence (UAI) 2018, 21\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical stochastic multi-armed bandit but where, from time\nto time and roughly with frequency $\\epsilon$, an extra observation is gathered\nby the agent for free. We prove that, no matter how small $\\epsilon$ is the\nagent can ensure a regret uniformly bounded in time.\n  More precisely, we construct an algorithm with a regret smaller than $\\sum_i\n\\frac{\\log(1/\\epsilon)}{\\Delta_i}$, up to multiplicative constant and loglog\nterms. We also prove a matching lower-bound, stating that no reasonable\nalgorithm can outperform this quantity.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 10:15:30 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Degenne", "R\u00e9my", ""], ["Garcelon", "Evrard", ""], ["Perchet", "Vianney", ""]]}, {"id": "1807.03570", "submitter": "Gundeep Arora", "authors": "Gundeep Arora, Anupreet Porwal, Kanupriya Agarwal, Avani Samdariya,\n  Piyush Rai", "title": "Small-Variance Asymptotics for Nonparametric Bayesian Overlapping\n  Stochastic Blockmodels", "comments": "Accepted For IJCAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latent feature relational model (LFRM) is a generative model for\ngraph-structured data to learn a binary vector representation for each node in\nthe graph. The binary vector denotes the node's membership in one or more\ncommunities. At its core, the LFRM miller2009nonparametric is an overlapping\nstochastic blockmodel, which defines the link probability between any pair of\nnodes as a bilinear function of their community membership vectors. Moreover,\nusing a nonparametric Bayesian prior (Indian Buffet Process) enables learning\nthe number of communities automatically from the data. However, despite its\nappealing properties, inference in LFRM remains a challenge and is typically\ndone via MCMC methods. This can be slow and may take a long time to converge.\nIn this work, we develop a small-variance asymptotics based framework for the\nnon-parametric Bayesian LFRM. This leads to an objective function that retains\nthe nonparametric Bayesian flavor of LFRM, while enabling us to design\ndeterministic inference algorithms for this model, that are easy to implement\n(using generic or specialized optimization routines) and are fast in practice.\nOur results on several benchmark datasets demonstrate that our algorithm is\ncompetitive to methods such as MCMC, while being much faster.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 11:20:17 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Arora", "Gundeep", ""], ["Porwal", "Anupreet", ""], ["Agarwal", "Kanupriya", ""], ["Samdariya", "Avani", ""], ["Rai", "Piyush", ""]]}, {"id": "1807.03571", "submitter": "Min Wu", "authors": "Min Wu, Matthew Wicker, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska", "title": "A Game-Based Approximate Verification of Deep Neural Networks with\n  Provable Guarantees", "comments": null, "journal-ref": "Theoretical Computer Science 807 (2020) 298-329", "doi": "10.1016/j.tcs.2019.05.046", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the improved accuracy of deep neural networks, the discovery of\nadversarial examples has raised serious safety concerns. In this paper, we\nstudy two variants of pointwise robustness, the maximum safe radius problem,\nwhich for a given input sample computes the minimum distance to an adversarial\nexample, and the feature robustness problem, which aims to quantify the\nrobustness of individual features to adversarial perturbations. We demonstrate\nthat, under the assumption of Lipschitz continuity, both problems can be\napproximated using finite optimisation by discretising the input space, and the\napproximation has provable guarantees, i.e., the error is bounded. We then show\nthat the resulting optimisation problems can be reduced to the solution of\ntwo-player turn-based games, where the first player selects features and the\nsecond perturbs the image within the feature. While the second player aims to\nminimise the distance to an adversarial example, depending on the optimisation\nobjective the first player can be cooperative or competitive. We employ an\nanytime approach to solve the games, in the sense of approximating the value of\na game by monotonically improving its upper and lower bounds. The Monte Carlo\ntree search algorithm is applied to compute upper bounds for both games, and\nthe Admissible A* and the Alpha-Beta Pruning algorithms are, respectively, used\nto compute lower bounds for the maximum safety radius and feature robustness\ngames. When working on the upper bound of the maximum safe radius problem, our\ntool demonstrates competitive performance against existing adversarial example\ncrafting algorithms. Furthermore, we show how our framework can be deployed to\nevaluate pointwise robustness of neural networks in safety-critical\napplications such as traffic sign recognition in self-driving cars.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 11:28:46 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 22:21:11 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wu", "Min", ""], ["Wicker", "Matthew", ""], ["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1807.03610", "submitter": "Romana Markovic", "authors": "Romana Markovic, Eva Grintal, Daniel W\\\"olki, J\\'er\\^ome Frisch,\n  Christoph van Treeck", "title": "Window Opening Model using Deep Learning Methods", "comments": "Accepted for publication in Building and Environment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Occupant behavior (OB) and in particular window openings need to be\nconsidered in building performance simulation (BPS), in order to realistically\nmodel the indoor climate and energy consumption for heating ventilation and air\nconditioning (HVAC). However, the proposed OB window opening models are often\nbiased towards the over-represented class where windows remained closed. In\naddition, they require tuning for each occupant which can not be efficiently\nscaled to the increased number of occupants. This paper presents a window\nopening model for commercial buildings using deep learning methods. The model\nis trained using data from occupants from an office building in Germany. In\ntotal the model is evaluated using almost 20 mio. data points from 3\nindependent buildings, located in Aachen, Frankfurt and Philadelphia.\nEventually, the results of 3100 core hours of model development are summarized,\nwhich makes this study the largest of its kind in window states modeling.\nAdditionally, the practical potential of the proposed model was tested by\nincorporating it in the Modelica-based thermal building simulation. The\nresulting evaluation accuracy and F1 scores on the office buildings ranged\nbetween 86-89 % and 0.53-0.65 respectively. The performance dropped around 15 %\npoints in case of sparse input data, while the F1 score remained high.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 13:17:08 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 11:12:00 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 08:21:21 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Markovic", "Romana", ""], ["Grintal", "Eva", ""], ["W\u00f6lki", "Daniel", ""], ["Frisch", "J\u00e9r\u00f4me", ""], ["van Treeck", "Christoph", ""]]}, {"id": "1807.03625", "submitter": "Fedor Kitashov", "authors": "Fedor Kitashov, Elizaveta Svitanko, Debojyoti Dutta", "title": "Foreign English Accent Adjustment by Learning Phonetic Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art automatic speech recognition (ASR) systems struggle with the\nlack of data for rare accents. For sufficiently large datasets, neural engines\ntend to outshine statistical models in most natural language processing\nproblems. However, a speech accent remains a challenge for both approaches.\nPhonologists manually create general rules describing a speaker's accent, but\ntheir results remain underutilized. In this paper, we propose a model that\nautomatically retrieves phonological generalizations from a small dataset. This\nmethod leverages the difference in pronunciation between a particular dialect\nand General American English (GAE) and creates new accented samples of words.\nThe proposed model is able to learn all generalizations that previously were\nmanually obtained by phonologists. We use this statistical method to generate a\nmillion phonological variations of words from the CMU Pronouncing Dictionary\nand train a sequence-to-sequence RNN to recognize accented words with 59%\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 17:38:23 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kitashov", "Fedor", ""], ["Svitanko", "Elizaveta", ""], ["Dutta", "Debojyoti", ""]]}, {"id": "1807.03653", "submitter": "Pablo Martinez Olmos", "authors": "Alfredo Nazabal, Pablo M. Olmos, Zoubin Ghahramani, Isabel Valera", "title": "Handling Incomplete Heterogeneous Data using VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs), as well as other generative models, have\nbeen shown to be efficient and accurate for capturing the latent structure of\nvast amounts of complex high-dimensional data. However, existing VAEs can still\nnot directly handle data that are heterogenous (mixed continuous and discrete)\nor incomplete (with missing data at random), which is indeed common in\nreal-world applications. In this paper, we propose a general framework to\ndesign VAEs suitable for fitting incomplete heterogenous data. The proposed\nHI-VAE includes likelihood models for real-valued, positive real valued,\ninterval, categorical, ordinal and count data, and allows accurate estimation\n(and potentially imputation) of missing data. Furthermore, HI-VAE presents\ncompetitive predictive performance in supervised tasks, outperforming\nsupervised models when trained on incomplete data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:00:23 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 12:06:18 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 14:58:48 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 13:56:07 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Nazabal", "Alfredo", ""], ["Olmos", "Pablo M.", ""], ["Ghahramani", "Zoubin", ""], ["Valera", "Isabel", ""]]}, {"id": "1807.03697", "submitter": "Veronica Morfi", "authors": "Veronica Morfi, Dan Stowell", "title": "Deep Learning for Audio Transcription on Low-Resource Datasets", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In training a deep learning system to perform audio transcription, two\npractical problems may arise. Firstly, most datasets are weakly labelled,\nhaving only a list of events present in each recording without any temporal\ninformation for training. Secondly, deep neural networks need a very large\namount of labelled training data to achieve good quality performance, yet in\npractice it is difficult to collect enough samples for most classes of\ninterest. In this paper, we propose factorising the final task of audio\ntranscription into multiple intermediate tasks in order to improve the training\nperformance when dealing with this kind of low-resource datasets. We evaluate\nthree data-efficient approaches of training a stacked convolutional and\nrecurrent neural network for the intermediate tasks. Our results show that\ndifferent methods of training have different advantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:12:23 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 11:59:36 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Morfi", "Veronica", ""], ["Stowell", "Dan", ""]]}, {"id": "1807.03708", "submitter": "Qingpeng Cai", "authors": "Qingpeng Cai, Ling Pan, Pingzhong Tang", "title": "Deterministic Policy Gradients With General State Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a reinforcement learning setting, where the state transition\nfunction is a convex combination of a stochastic continuous function and a\ndeterministic function. Such a setting generalizes the widely-studied\nstochastic state transition setting, namely the setting of deterministic policy\ngradient (DPG).\n  We firstly give a simple example to illustrate that the deterministic policy\ngradient may be infinite under deterministic state transitions, and introduce a\ntheoretical technique to prove the existence of the policy gradient in this\ngeneralized setting. Using this technique, we prove that the deterministic\npolicy gradient indeed exists for a certain set of discount factors, and\nfurther prove two conditions that guarantee the existence for all discount\nfactors. We then derive a closed form of the policy gradient whenever exists.\nFurthermore, to overcome the challenge of high sample complexity of DPG in this\nsetting, we propose the Generalized Deterministic Policy Gradient (GDPG)\nalgorithm. The main innovation of the algorithm is a new method of applying\nmodel-based techniques to the model-free algorithm, the deep deterministic\npolicy gradient algorithm (DDPG). GDPG optimize the long-term rewards of the\nmodel-based augmented MDP subject to a constraint that the long-rewards of the\nMDP is less than the original one.\n  We finally conduct extensive experiments comparing GDPG with state-of-the-art\nmethods and the direct model-based extension method of DDPG on several standard\ncontinuous control benchmarks. Results demonstrate that GDPG substantially\noutperforms DDPG, the model-based extension of DDPG and other baselines in\nterms of both convergence and long-term rewards in most environments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:24:36 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 05:56:19 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 03:10:49 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Cai", "Qingpeng", ""], ["Pan", "Ling", ""], ["Tang", "Pingzhong", ""]]}, {"id": "1807.03710", "submitter": "Timothy Wong", "authors": "Timothy Wong, Zhiyuan Luo", "title": "Recurrent Auto-Encoder Model for Large-Scale Industrial Sensor Signal\n  Analysis", "comments": "Accepted paper at the 19th International Conference on Engineering\n  Applications of Neural Networks (EANN 2018)", "journal-ref": "E. Pimenidis and C. Jayne (Eds.): EANN 2018, CCIS 893", "doi": "10.1007/978-3-319-98204-5_17", "report-no": null, "categories": "cs.LG cs.AI cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent auto-encoder model summarises sequential data through an encoder\nstructure into a fixed-length vector and then reconstructs the original\nsequence through the decoder structure. The summarised vector can be used to\nrepresent time series features. In this paper, we propose relaxing the\ndimensionality of the decoder output so that it performs partial\nreconstruction. The fixed-length vector therefore represents features in the\nselected dimensions only. In addition, we propose using rolling fixed window\napproach to generate training samples from unbounded time series data. The\nchange of time series features over time can be summarised as a smooth\ntrajectory path. The fixed-length vectors are further analysed using additional\nvisualisation and unsupervised clustering techniques. The proposed method can\nbe applied in large-scale industrial processes for sensors signal analysis\npurpose, where clusters of the vector representations can reflect the operating\nstates of the industrial system.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:26:33 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Wong", "Timothy", ""], ["Luo", "Zhiyuan", ""]]}, {"id": "1807.03711", "submitter": "Rajesh Chidambaram", "authors": "Rajesh Chidambaram, Michael Kampffmeyer, Willie Neiswanger, Xiaodan\n  Liang, Thomas Lachmann and Eric Xing", "title": "Geometric Generalization Based Zero-Shot Learning Dataset Infinite\n  World: Simple Yet Powerful", "comments": null, "journal-ref": "ICML 2018, Workshop TADGM", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raven's Progressive Matrices are one of the widely used tests in evaluating\nthe human test taker's fluid intelligence. Analogously, this paper introduces\ngeometric generalization based zero-shot learning tests to measure the rapid\nlearning ability and the internal consistency of deep generative models. Our\nempirical research analysis on state-of-the-art generative models discern their\nability to generalize concepts across classes. In the process, we introduce\nInfinite World, an evaluable, scalable, multi-modal, light-weight dataset and\nZero-Shot Intelligence Metric ZSI. The proposed tests condenses human-level\nspatial and numerical reasoning tasks to its simplistic geometric forms. The\ndataset is scalable to a theoretical limit of infinity, in numerical features\nof the generated geometric figures, image size and in quantity. We\nsystematically analyze state-of-the-art model's internal consistency, identify\ntheir bottlenecks and propose a pro-active optimization method for few-shot and\nzero-shot learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:30:17 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 09:09:10 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Chidambaram", "Rajesh", ""], ["Kampffmeyer", "Michael", ""], ["Neiswanger", "Willie", ""], ["Liang", "Xiaodan", ""], ["Lachmann", "Thomas", ""], ["Xing", "Eric", ""]]}, {"id": "1807.03723", "submitter": "Huangjie Zheng", "authors": "Huangjie Zheng, Jiangchao Yao, Ya Zhang, Ivor W. Tsang, Jia Wang", "title": "Understanding VAEs in Fisher-Shannon Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information theory, Fisher information and Shannon information (entropy)\nare respectively used to quantify the uncertainty associated with the\ndistribution modeling and the uncertainty in specifying the outcome of given\nvariables. These two quantities are complementary and are jointly applied to\ninformation behavior analysis in most cases. The uncertainty property in\ninformation asserts a fundamental trade-off between Fisher information and\nShannon information, which enlightens us the relationship between the encoder\nand the decoder in variational auto-encoders (VAEs). In this paper, we\ninvestigate VAEs in the Fisher-Shannon plane and demonstrate that the\nrepresentation learning and the log-likelihood estimation are intrinsically\nrelated to these two information quantities. Through extensive qualitative and\nquantitative experiments, we provide with a better comprehension of VAEs in\ntasks such as high-resolution reconstruction, and representation learning in\nthe perspective of Fisher information and Shannon information. We further\npropose a variant of VAEs, termed as Fisher auto-encoder (FAE), for practical\nneeds to balance Fisher information and Shannon information. Our experimental\nresults have demonstrated its promise in improving the reconstruction accuracy\nand avoiding the non-informative latent code as occurred in previous works.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:47:59 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 19:46:30 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Zheng", "Huangjie", ""], ["Yao", "Jiangchao", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""], ["Wang", "Jia", ""]]}, {"id": "1807.03733", "submitter": "Jian Li", "authors": "Kun Tu, Jian Li, Don Towsley, Dave Braines and Liam D. Turner", "title": "Network Classification in Temporal Networks Using Motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network classification has a variety of applications, such as detecting\ncommunities within networks and finding similarities between those representing\ndifferent aspects of the real world. However, most existing work in this area\nfocus on examining static undirected networks without considering directed\nedges or temporality. In this paper, we propose a new methodology that utilizes\nfeature representation for network classification based on the temporal motif\ndistribution of the network and a null model for comparing against random\ngraphs. Experimental results show that our method improves accuracy by up\n$10\\%$ compared to the state-of-the-art embedding method in network\nclassification, for tasks such as classifying network type, identifying\ncommunities in email exchange network, and identifying users given their\napp-switching behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 16:09:29 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 14:02:20 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Tu", "Kun", ""], ["Li", "Jian", ""], ["Towsley", "Don", ""], ["Braines", "Dave", ""], ["Turner", "Liam D.", ""]]}, {"id": "1807.03746", "submitter": "Urvashi Oswal", "authors": "Urvashi Oswal and Robert Nowak", "title": "Scalable Sparse Subspace Clustering via Ordered Weighted $\\ell_1$\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of the paper is a new approach to subspace clustering\nthat is significantly more computationally efficient and scalable than existing\nstate-of-the-art methods. The central idea is to modify the regression\ntechnique in sparse subspace clustering (SSC) by replacing the $\\ell_1$\nminimization with a generalization called Ordered Weighted $\\ell_1$ (OWL)\nminimization which performs simultaneous regression and clustering of\ncorrelated variables. Using random geometric graph theory, we prove that OWL\nregression selects more points within each subspace, resulting in better\nclustering results. This allows for accurate subspace clustering based on\nregression solutions for only a small subset of the total dataset,\nsignificantly reducing the computational complexity compared to SSC. In\nexperiments, we find that our OWL approach can achieve a speedup of 20$\\times$\nto 30$\\times$ for synthetic problems and 4$\\times$ to 8$\\times$ on real data\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 16:50:10 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Oswal", "Urvashi", ""], ["Nowak", "Robert", ""]]}, {"id": "1807.03748", "submitter": "A\\\"aron van den Oord", "authors": "Aaron van den Oord, Yazhe Li, Oriol Vinyals", "title": "Representation Learning with Contrastive Predictive Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While supervised learning has enabled great progress in many applications,\nunsupervised learning has not seen such widespread adoption, and remains an\nimportant and challenging endeavor for artificial intelligence. In this work,\nwe propose a universal unsupervised learning approach to extract useful\nrepresentations from high-dimensional data, which we call Contrastive\nPredictive Coding. The key insight of our model is to learn such\nrepresentations by predicting the future in latent space by using powerful\nautoregressive models. We use a probabilistic contrastive loss which induces\nthe latent space to capture information that is maximally useful to predict\nfuture samples. It also makes the model tractable by using negative sampling.\nWhile most prior work has focused on evaluating representations for a\nparticular modality, we demonstrate that our approach is able to learn useful\nrepresentations achieving strong performance on four distinct domains: speech,\nimages, text and reinforcement learning in 3D environments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 16:52:11 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 18:47:12 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Oord", "Aaron van den", ""], ["Li", "Yazhe", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1807.03750", "submitter": "Yehia Elkhatib PhD", "authors": "Yehia Elkhatib", "title": "Navigating Diverse Data Science Learning: Critical Reflections Towards\n  Future Practice", "comments": null, "journal-ref": "4th Workshop on Curricula and Teaching Methods in Cloud Computing,\n  Big Data, and Data Science, 2017", "doi": "10.1109/CloudCom.2017.58", "report-no": null, "categories": "cs.GL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Science is currently a popular field of science attracting expertise\nfrom very diverse backgrounds. Current learning practices need to acknowledge\nthis and adapt to it. This paper summarises some experiences relating to such\nlearning approaches from teaching a postgraduate Data Science module, and draws\nsome learned lessons that are of relevance to others teaching Data Science.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 21:32:18 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Elkhatib", "Yehia", ""]]}, {"id": "1807.03756", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Yoon Kim, Justin Chiu, Demi Guo, Alexander M. Rush", "title": "Latent Alignment and Variational Attention", "comments": "accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural attention has become central to many state-of-the-art models in\nnatural language processing and related domains. Attention networks are an\neasy-to-train and effective method for softly simulating alignment; however,\nthe approach does not marginalize over latent alignments in a probabilistic\nsense. This property makes it difficult to compare attention to other alignment\napproaches, to compose it with probabilistic models, and to perform posterior\ninference conditioned on observed data. A related latent approach, hard\nattention, fixes these issues, but is generally harder to train and less\naccurate. This work considers variational attention networks, alternatives to\nsoft and hard attention for learning latent variable alignment models, with\ntighter approximation bounds based on amortized variational inference. We\nfurther propose methods for reducing the variance of gradients to make these\napproaches computationally feasible. Experiments show that for machine\ntranslation and visual question answering, inefficient exact latent variable\nmodels outperform standard neural attention, but these gains go away when using\nhard attention based training. On the other hand, variational attention retains\nmost of the performance gain but with training speed comparable to neural\nattention.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 16:59:12 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 23:03:21 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Deng", "Yuntian", ""], ["Kim", "Yoon", ""], ["Chiu", "Justin", ""], ["Guo", "Demi", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1807.03765", "submitter": "Chi Jin", "authors": "Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, Michael I. Jordan", "title": "Is Q-learning Provably Efficient?", "comments": "Best paper in ICML 2018 workshop \"Exploration in RL\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) algorithms, such as Q-learning,\ndirectly parameterize and update value functions or policies without explicitly\nmodeling the environment. They are typically simpler, more flexible to use, and\nthus more prevalent in modern deep RL than model-based approaches. However,\nempirical work has suggested that model-free algorithms may require more\nsamples to learn [Deisenroth and Rasmussen 2011, Schulman et al. 2015]. The\ntheoretical question of \"whether model-free algorithms can be made sample\nefficient\" is one of the most fundamental questions in RL, and remains unsolved\neven in the basic scenario with finitely many states and actions.\n  We prove that, in an episodic MDP setting, Q-learning with UCB exploration\nachieves regret $\\tilde{O}(\\sqrt{H^3 SAT})$, where $S$ and $A$ are the numbers\nof states and actions, $H$ is the number of steps per episode, and $T$ is the\ntotal number of steps. This sample efficiency matches the optimal regret that\ncan be achieved by any model-based approach, up to a single $\\sqrt{H}$ factor.\nTo the best of our knowledge, this is the first analysis in the model-free\nsetting that establishes $\\sqrt{T}$ regret without requiring access to a\n\"simulator.\"\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 17:21:35 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Jin", "Chi", ""], ["Allen-Zhu", "Zeyuan", ""], ["Bubeck", "Sebastien", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1807.03769", "submitter": "Vassilis Kekatos", "authors": "Aditie Garg, Mana Jalali, Vassilis Kekatos, Nikolaos Gatsis", "title": "Kernel-Based Learning for Smart Inverter Control", "comments": "Submitted to the 2018 IEEE Global Signal and Information Processing\n  Conf., Symposium on Smart Energy Infrastructures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution grids are currently challenged by frequent voltage excursions\ninduced by intermittent solar generation. Smart inverters have been advocated\nas a fast-responding means to regulate voltage and minimize ohmic losses. Since\noptimal inverter coordination may be computationally challenging and preset\nlocal control rules are subpar, the approach of customized control rules\ndesigned in a quasi-static fashion features as a golden middle. Departing from\naffine control rules, this work puts forth non-linear inverter control\npolicies. Drawing analogies to multi-task learning, reactive control is posed\nas a kernel-based regression task. Leveraging a linearized grid model and given\nanticipated data scenarios, inverter rules are jointly designed at the feeder\nlevel to minimize a convex combination of voltage deviations and ohmic losses\nvia a linearly-constrained quadratic program. Numerical tests using real-world\ndata on a benchmark feeder demonstrate that nonlinear control rules driven also\nby a few non-local readings can attain near-optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 17:46:02 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Garg", "Aditie", ""], ["Jalali", "Mana", ""], ["Kekatos", "Vassilis", ""], ["Gatsis", "Nikolaos", ""]]}, {"id": "1807.03819", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit,\n  {\\L}ukasz Kaiser", "title": "Universal Transformers", "comments": "Published at ICLR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) sequentially process data by updating their\nstate with each new data point, and have long been the de facto choice for\nsequence modeling tasks. However, their inherently sequential computation makes\nthem slow to train. Feed-forward and convolutional architectures have recently\nbeen shown to achieve superior results on some sequence modeling tasks such as\nmachine translation, with the added advantage that they concurrently process\nall inputs in the sequence, leading to easy parallelization and faster training\ntimes. Despite these successes, however, popular feed-forward sequence models\nlike the Transformer fail to generalize in many simple tasks that recurrent\nmodels handle with ease, e.g. copying strings or even simple logical inference\nwhen the string or formula lengths exceed those observed at training time. We\npropose the Universal Transformer (UT), a parallel-in-time self-attentive\nrecurrent sequence model which can be cast as a generalization of the\nTransformer model and which addresses these issues. UTs combine the\nparallelizability and global receptive field of feed-forward sequence models\nlike the Transformer with the recurrent inductive bias of RNNs. We also add a\ndynamic per-position halting mechanism and find that it improves accuracy on\nseveral tasks. In contrast to the standard Transformer, under certain\nassumptions, UTs can be shown to be Turing-complete. Our experiments show that\nUTs outperform standard Transformers on a wide range of algorithmic and\nlanguage understanding tasks, including the challenging LAMBADA language\nmodeling task where UTs achieve a new state of the art, and machine translation\nwhere UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 18:39:15 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 15:17:22 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 16:46:19 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Gouws", "Stephan", ""], ["Vinyals", "Oriol", ""], ["Uszkoreit", "Jakob", ""], ["Kaiser", "\u0141ukasz", ""]]}, {"id": "1807.03845", "submitter": "Sampurna Biswas", "authors": "Sampurna Biswas, Hemant K. Aggarwal, Sunrita Poddar, and Mathews Jacob", "title": "Model-based free-breathing cardiac MRI reconstruction using deep learned\n  \\& STORM priors: MoDL-STORM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model-based reconstruction framework with deep learned (DL)\nand smoothness regularization on manifolds (STORM) priors to recover free\nbreathing and ungated (FBU) cardiac MRI from highly undersampled measurements.\nThe DL priors enable us to exploit the local correlations, while the STORM\nprior enables us to make use of the extensive non-local similarities that are\nsubject dependent. We introduce a novel model-based formulation that allows the\nseamless integration of deep learning methods with available prior information,\nwhich current deep learning algorithms are not capable of. The experimental\nresults demonstrate the preliminary potential of this work in accelerating FBU\ncardiac MRI.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 20:04:14 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Biswas", "Sampurna", ""], ["Aggarwal", "Hemant K.", ""], ["Poddar", "Sunrita", ""], ["Jacob", "Mathews", ""]]}, {"id": "1807.03858", "submitter": "Yuping Luo", "authors": "Yuping Luo, Huazhe Xu, Yuanzhi Li, Yuandong Tian, Trevor Darrell,\n  Tengyu Ma", "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with\n  Theoretical Guarantees", "comments": "Added important notes that the conditions of Theorem 3.1 cannot\n  simultaneously hold for most models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) is considered to be a promising\napproach to reduce the sample complexity that hinders model-free RL. However,\nthe theoretical understanding of such methods has been rather limited. This\npaper introduces a novel algorithmic framework for designing and analyzing\nmodel-based RL algorithms with theoretical guarantees. We design a\nmeta-algorithm with a theoretical guarantee of monotone improvement to a local\nmaximum of the expected reward. The meta-algorithm iteratively builds a lower\nbound of the expected reward based on the estimated dynamical model and sample\ntrajectories, and then maximizes the lower bound jointly over the policy and\nthe model. The framework extends the optimism-in-face-of-uncertainty principle\nto non-linear dynamical models in a way that requires \\textit{no explicit}\nuncertainty quantification. Instantiating our framework with simplification\ngives a variant of model-based RL algorithms Stochastic Lower Bounds\nOptimization (SLBO). Experiments demonstrate that SLBO achieves\nstate-of-the-art performance when only one million or fewer samples are\npermitted on a range of continuous control benchmark tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 20:53:04 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 18:00:46 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 21:09:58 GMT"}, {"version": "v4", "created": "Mon, 21 Jan 2019 20:04:56 GMT"}, {"version": "v5", "created": "Mon, 15 Feb 2021 17:29:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Luo", "Yuping", ""], ["Xu", "Huazhe", ""], ["Li", "Yuanzhi", ""], ["Tian", "Yuandong", ""], ["Darrell", "Trevor", ""], ["Ma", "Tengyu", ""]]}, {"id": "1807.03870", "submitter": "Kun Xu", "authors": "Chao Du, Kun Xu, Chongxuan Li, Jun Zhu, Bo Zhang", "title": "Learning Implicit Generative Models by Teaching Explicit Ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit generative models are difficult to train as no explicit density\nfunctions are defined. Generative adversarial nets (GANs) present a minimax\nframework to train such models, which however can suffer from mode collapse due\nto the nature of the JS-divergence. This paper presents a learning by teaching\n(LBT) approach to learning implicit models, which intrinsically avoids the mode\ncollapse problem by optimizing a KL-divergence rather than the JS-divergence in\nGANs. In LBT, an auxiliary density estimator is introduced to fit the implicit\nmodel's distribution while the implicit model teaches the density estimator to\nmatch the data distribution. LBT is formulated as a bilevel optimization\nproblem, whose optimal generator matches the true data distribution. LBT can be\nnaturally integrated with GANs to derive a hybrid LBT-GAN that enjoys\ncomplimentary benefits. Finally, we present a stochastic gradient ascent\nalgorithm with unrolling to solve the challenging learning problems.\nExperimental results demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 21:32:35 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 05:48:32 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 09:43:06 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Du", "Chao", ""], ["Xu", "Kun", ""], ["Li", "Chongxuan", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1807.03873", "submitter": "Janek Thomas", "authors": "Janek Thomas and Stefan Coors and Bernd Bischl", "title": "Automatic Gradient Boosting", "comments": "6 pages, 1 figure, ICML 2018 AutoML Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning performs predictive modeling with high performing\nmachine learning tools without human interference. This is achieved by making\nmachine learning applications parameter-free, i.e. only a dataset is provided\nwhile the complete model selection and model building process is handled\ninternally through (often meta) optimization. Projects like Auto-WEKA and\nauto-sklearn aim to solve the Combined Algorithm Selection and Hyperparameter\noptimization (CASH) problem resulting in huge configuration spaces. However,\nfor most real-world applications, the optimization over only a few different\nkey learning algorithms can not only be sufficient, but also potentially\nbeneficial. The latter becomes apparent when one considers that models have to\nbe validated, explained, deployed and maintained. Here, less complex model are\noften preferred, for validation or efficiency reasons, or even a strict\nrequirement. Automatic gradient boosting simplifies this idea one step further,\nusing only gradient boosting as a single learning algorithm in combination with\nmodel-based hyperparameter tuning, threshold optimization and encoding of\ncategorical features. We introduce this general framework as well as a concrete\nimplementation called autoxgboost. It is compared to current AutoML projects on\n16 datasets and despite its simplicity is able to achieve comparable results on\nabout half of the datasets as well as performing best on two.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 21:36:23 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 00:19:43 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Thomas", "Janek", ""], ["Coors", "Stefan", ""], ["Bischl", "Bernd", ""]]}, {"id": "1807.03876", "submitter": "Charles Fisher", "authors": "Charles K. Fisher, Aaron M. Smith, Jonathan R. Walsh, and the\n  Coalition Against Major Diseases", "title": "Deep learning for comprehensive forecasting of Alzheimer's Disease\n  progression", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-019-49656-2", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to machine learning from electronic health data can only\npredict a single endpoint. Here, we present an alternative that uses\nunsupervised deep learning to simulate detailed patient trajectories. We use\ndata comprising 18-month trajectories of 44 clinical variables from 1908\npatients with Mild Cognitive Impairment or Alzheimer's Disease to train a model\nfor personalized forecasting of disease progression. We simulate synthetic\npatient data including the evolution of each sub-component of cognitive exams,\nlaboratory tests, and their associations with baseline clinical\ncharacteristics, generating both predictions and their confidence intervals.\nOur unsupervised model predicts changes in total ADAS-Cog scores with the same\naccuracy as specifically trained supervised models and identifies\nsub-components associated with word recall as predictive of progression. The\nability to simultaneously simulate dozens of patient characteristics is a\ncrucial step towards personalized medicine for Alzheimer's Disease.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 21:42:17 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 18:57:03 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Fisher", "Charles K.", ""], ["Smith", "Aaron M.", ""], ["Walsh", "Jonathan R.", ""], ["Diseases", "the Coalition Against Major", ""]]}, {"id": "1807.03877", "submitter": "Kun Xu", "authors": "Kun Xu, Haoyu Liang, Jun Zhu, Hang Su and Bo Zhang", "title": "Deep Structured Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have shown promising results in generating realistic\nimages, but it is still non-trivial to generate images with complicated\nstructures. The main reason is that most of the current generative models fail\nto explore the structures in the images including spatial layout and semantic\nrelations between objects. To address this issue, we propose a novel deep\nstructured generative model which boosts generative adversarial networks (GANs)\nwith the aid of structure information. In particular, the layout or structure\nof the scene is encoded by a stochastic and-or graph (sAOG), in which the\nterminal nodes represent single objects and edges represent relations between\nobjects. With the sAOG appropriately harnessed, our model can successfully\ncapture the intrinsic structure in the scenes and generate images of\ncomplicated scenes accordingly. Furthermore, a detection network is introduced\nto infer scene structures from a image. Experimental results demonstrate the\neffectiveness of our proposed method on both modeling the intrinsic structures,\nand generating realistic images.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 21:45:44 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Xu", "Kun", ""], ["Liang", "Haoyu", ""], ["Zhu", "Jun", ""], ["Su", "Hang", ""], ["Zhang", "Bo", ""]]}, {"id": "1807.03878", "submitter": "Yanjun  Qi Dr.", "authors": "Arshdeep Sekhon, Ritambhara Singh, and Yanjun Qi", "title": "DeepDiff: Deep-learning for predicting Differential gene expression from\n  histone modifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational methods that predict differential gene expression from histone\nmodification signals are highly desirable for understanding how histone\nmodifications control the functional heterogeneity of cells through influencing\ndifferential gene regulation. Recent studies either failed to capture\ncombinatorial effects on differential prediction or primarily only focused on\ncell type-specific analysis. In this paper, we develop a novel attention-based\ndeep learning architecture, DeepDiff, that provides a unified and end-to-end\nsolution to model and to interpret how dependencies among histone modifications\ncontrol the differential patterns of gene regulation. DeepDiff uses a hierarchy\nof multiple Long short-term memory (LSTM) modules to encode the spatial\nstructure of input signals and to model how various histone modifications\ncooperate automatically. We introduce and train two levels of attention jointly\nwith the target prediction, enabling DeepDiff to attend differentially to\nrelevant modifications and to locate important genome positions for each\nmodification. Additionally, DeepDiff introduces a novel deep-learning based\nmulti-task formulation to use the cell-type-specific gene expression\npredictions as auxiliary tasks, encouraging richer feature embeddings in our\nprimary task of differential expression prediction. Using data from Roadmap\nEpigenomics Project (REMC) for ten different pairs of cell types, we show that\nDeepDiff significantly outperforms the state-of-the-art baselines for\ndifferential gene expression prediction. The learned attention weights are\nvalidated by observations from previous studies about how epigenetic mechanisms\nconnect to differential gene expression. Codes and results are available at\n\\url{deepchrome.org}\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 21:45:47 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Sekhon", "Arshdeep", ""], ["Singh", "Ritambhara", ""], ["Qi", "Yanjun", ""]]}, {"id": "1807.03888", "submitter": "Kimin Lee", "authors": "Kimin Lee, Kibok Lee, Honglak Lee, Jinwoo Shin", "title": "A Simple Unified Framework for Detecting Out-of-Distribution Samples and\n  Adversarial Attacks", "comments": "Accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting test samples drawn sufficiently far away from the training\ndistribution statistically or adversarially is a fundamental requirement for\ndeploying a good classifier in many real-world machine learning applications.\nHowever, deep neural networks with the softmax classifier are known to produce\nhighly overconfident posterior distributions even for such abnormal samples. In\nthis paper, we propose a simple yet effective method for detecting any abnormal\nsamples, which is applicable to any pre-trained softmax neural classifier. We\nobtain the class conditional Gaussian distributions with respect to (low- and\nupper-level) features of the deep models under Gaussian discriminant analysis,\nwhich result in a confidence score based on the Mahalanobis distance. While\nmost prior methods have been evaluated for detecting either out-of-distribution\nor adversarial samples, but not both, the proposed method achieves the\nstate-of-the-art performances for both cases in our experiments. Moreover, we\nfound that our proposed method is more robust in harsh cases, e.g., when the\ntraining dataset has noisy labels or small number of samples. Finally, we show\nthat the proposed method enjoys broader usage by applying it to\nclass-incremental learning: whenever out-of-distribution samples are detected,\nour classification rule can incorporate new classes well without further\ntraining deep models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 22:14:04 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 08:47:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lee", "Kimin", ""], ["Lee", "Kibok", ""], ["Lee", "Honglak", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1807.03907", "submitter": "Ioannis Panageas", "authors": "Constantinos Daskalakis and Ioannis Panageas", "title": "The Limit Points of (Optimistic) Gradient Descent in Min-Max\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in Optimization, Game Theory, and the training of\nGenerative Adversarial Networks, the convergence properties of first order\nmethods in min-max problems have received extensive study. It has been\nrecognized that they may cycle, and there is no good understanding of their\nlimit points when they do not. When they converge, do they converge to local\nmin-max solutions? We characterize the limit points of two basic first order\nmethods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent\nAscent (OGDA). We show that both dynamics avoid unstable critical points for\nalmost all initializations. Moreover, for small step sizes and under mild\nassumptions, the set of \\{OGDA\\}-stable critical points is a superset of\n\\{GDA\\}-stable critical points, which is a superset of local min-max solutions\n(strict in some cases). The connecting thread is that the behavior of these\ndynamics can be studied from a dynamical systems perspective.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 00:06:16 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Panageas", "Ioannis", ""]]}, {"id": "1807.03909", "submitter": "Md Kamruzzaman Sarker", "authors": "Md. Kamruzzaman Sarker, Kazi Md. Rokibul Alam, Md. Arifuzzaman", "title": "Emotion Recognition from Speech based on Relevant Feature and Majority\n  Voting", "comments": null, "journal-ref": "International Conference on Informatics, Electronics & Vision\n  (ICIEV) (2014) 1-5", "doi": "10.1109/ICIEV.2014.6850685", "report-no": null, "categories": "cs.SD cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to detect emotion from human speech employing\nmajority voting technique over several machine learning techniques. The\ncontribution of this work is in two folds: firstly it selects those features of\nspeech which is most promising for classification and secondly it uses the\nmajority voting technique that selects the exact class of emotion. Here,\nmajority voting technique has been applied over Neural Network (NN), Decision\nTree (DT), Support Vector Machine (SVM) and K-Nearest Neighbor (KNN). Input\nvector of NN, DT, SVM and KNN consists of various acoustic and prosodic\nfeatures like Pitch, Mel-Frequency Cepstral coefficients etc. From speech\nsignal many feature have been extracted and only promising features have been\nselected. To consider a feature as promising, Fast Correlation based feature\nselection (FCBF) and Fisher score algorithms have been used and only those\nfeatures are selected which are highly ranked by both of them. The proposed\napproach has been tested on Berlin dataset of emotional speech [3] and\nElectromagnetic Articulography (EMA) dataset [4]. The experimental result shows\nthat majority voting technique attains better accuracy over individual machine\nlearning techniques. The employment of the proposed approach can effectively\nrecognize the emotion of human beings in case of social robot, intelligent chat\nclient, call-center of a company etc.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 00:25:13 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Sarker", "Md. Kamruzzaman", ""], ["Alam", "Kazi Md. Rokibul", ""], ["Arifuzzaman", "Md.", ""]]}, {"id": "1807.03915", "submitter": "Thomas Manzini", "authors": "Hai Pham, Thomas Manzini, Paul Pu Liang, Barnabas Poczos", "title": "Seq2Seq2Sentiment: Multimodal Sequence to Sequence Models for Sentiment\n  Analysis", "comments": "8 pages of content, 11 pages total, 2 figures. Published as a\n  workshop paper at ACL 2018, Proceedings of Grand Challenge and Workshop on\n  Human Multimodal Language (Challenge-HML). 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine learning is a core research area spanning the language,\nvisual and acoustic modalities. The central challenge in multimodal learning\ninvolves learning representations that can process and relate information from\nmultiple modalities. In this paper, we propose two methods for unsupervised\nlearning of joint multimodal representations using sequence to sequence\n(Seq2Seq) methods: a \\textit{Seq2Seq Modality Translation Model} and a\n\\textit{Hierarchical Seq2Seq Modality Translation Model}. We also explore\nmultiple different variations on the multimodal inputs and outputs of these\nseq2seq models. Our experiments on multimodal sentiment analysis using the\nCMU-MOSI dataset indicate that our methods learn informative multimodal\nrepresentations that outperform the baselines and achieve improved performance\non multimodal sentiment analysis, specifically in the Bimodal case where our\nmodel is able to improve F1 Score by twelve points. We also discuss future\ndirections for multimodal Seq2Seq methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 01:13:13 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 11:14:31 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Pham", "Hai", ""], ["Manzini", "Thomas", ""], ["Liang", "Paul Pu", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1807.03920", "submitter": "Chuanhe Shan", "authors": "Matthew Nero, Chuanhe Shan, Li-C. Wang, Nik Sumikawa", "title": "Discovering Interesting Plots in Production Yield Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analytic process is iterative between two agents, an analyst and an\nanalytic toolbox. Each iteration comprises three main steps: preparing a\ndataset, running an analytic tool, and evaluating the result, where dataset\npreparation and result evaluation, conducted by the analyst, are largely\ndomain-knowledge driven. In this work, the focus is on automating the result\nevaluation step. The underlying problem is to identify plots that are deemed\ninteresting by an analyst. We propose a methodology to learn such analyst's\nintent based on Generative Adversarial Networks (GANs) and demonstrate its\napplications in the context of production yield optimization using data\ncollected from several product lines.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 01:42:23 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Nero", "Matthew", ""], ["Shan", "Chuanhe", ""], ["Wang", "Li-C.", ""], ["Sumikawa", "Nik", ""]]}, {"id": "1807.03929", "submitter": "Rafael Stern", "authors": "Afonso Fernandes Vaz, Rafael Izbicki, Rafael Bassi Stern", "title": "Quantification under prior probability shift: the ratio estimator and\n  its extensions", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantification problem consists of determining the prevalence of a given\nlabel in a target population. However, one often has access to the labels in a\nsample from the training population but not in the target population. A common\nassumption in this situation is that of prior probability shift, that is, once\nthe labels are known, the distribution of the features is the same in the\ntraining and target populations. In this paper, we derive a new lower bound for\nthe risk of the quantification problem under the prior shift assumption.\nComplementing this lower bound, we present a new approximately minimax class of\nestimators, ratio estimators, which generalize several previous proposals in\nthe literature. Using a weaker version of the prior shift assumption, which can\nbe tested, we show that ratio estimators can be used to build confidence\nintervals for the quantification problem. We also extend the ratio estimator so\nthat it can: (i) incorporate labels from the target population, when they are\navailable and (ii) estimate how the prevalence of positive labels varies\naccording to a function of certain covariates.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 02:19:57 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 17:18:03 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Vaz", "Afonso Fernandes", ""], ["Izbicki", "Rafael", ""], ["Stern", "Rafael Bassi", ""]]}, {"id": "1807.03931", "submitter": "Behnoosh Parsa", "authors": "Behnoosh Parsa, Keshav Rajasekaran, Franziska Meier, Ashis G. Banerjee", "title": "A Hierarchical Bayesian Linear Regression Model with Local Features for\n  Stochastic Dynamics Approximation", "comments": "38 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in model-based control of stochastic dynamical systems\nis that the state transition dynamics are involved, and it is not easy or\nefficient to make good-quality predictions of the states. Moreover, there are\nnot many representational models for the majority of autonomous systems, as it\nis not easy to build a compact model that captures the entire dynamical\nsubtleties and uncertainties. In this work, we present a hierarchical Bayesian\nlinear regression model with local features to learn the dynamics of a\nmicro-robotic system as well as two simpler examples, consisting of a\nstochastic mass-spring damper and a stochastic double inverted pendulum on a\ncart. The model is hierarchical since we assume non-stationary priors for the\nmodel parameters. These non-stationary priors make the model more flexible by\nimposing priors on the priors of the model. To solve the maximum likelihood\n(ML) problem for this hierarchical model, we use the variational expectation\nmaximization (EM) algorithm, and enhance the procedure by introducing hidden\ntarget variables. The algorithm yields parsimonious model structures, and\nconsistently provides fast and accurate predictions for all our examples\ninvolving large training and test sets. This demonstrates the effectiveness of\nthe method in learning stochastic dynamics, which makes it suitable for future\nuse in a paradigm, such as model-based reinforcement learning, to compute\noptimal control policies in real time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 02:24:20 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 01:10:58 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Parsa", "Behnoosh", ""], ["Rajasekaran", "Keshav", ""], ["Meier", "Franziska", ""], ["Banerjee", "Ashis G.", ""]]}, {"id": "1807.03933", "submitter": "Poongjin Cho", "authors": "Poongjin Cho, Minhyuk Lee, Woojin Chang", "title": "Instance-based entropy fuzzy support vector machine for imbalanced data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced classification has been a major challenge for machine learning\nbecause many standard classifiers mainly focus on balanced datasets and tend to\nhave biased results towards the majority class. We modify entropy fuzzy support\nvector machine (EFSVM) and introduce instance-based entropy fuzzy support\nvector machine (IEFSVM). Both EFSVM and IEFSVM use the entropy information of\nk-nearest neighbors to determine the fuzzy membership value for each sample\nwhich prioritizes the importance of each sample. IEFSVM considers the diversity\nof entropy patterns for each sample when increasing the size of neighbors, k,\nwhile EFSVM uses single entropy information of the fixed size of neighbors for\nall samples. By varying k, we can reflect the component change of sample's\nneighbors from near to far distance in the determination of fuzzy value\nmembership. Numerical experiments on 35 public and 12 real-world imbalanced\ndatasets are performed to validate IEFSVM and area under the receiver operating\ncharacteristic curve (AUC) is used to compare its performance with other SVMs\nand machine learning methods. IEFSVM shows a much higher AUC value for datasets\nwith high imbalance ratio, implying that IEFSVM is effective in dealing with\nthe class imbalance problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 02:33:57 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Cho", "Poongjin", ""], ["Lee", "Minhyuk", ""], ["Chang", "Woojin", ""]]}, {"id": "1807.03953", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Shin Kamada", "title": "Adaptive Learning Method of Recurrent Temporal Deep Belief Network to\n  Analyze Time Series Data", "comments": "8 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1807.03487, arXiv:1807.03486", "journal-ref": "Proc. of The International Joint Conference on Neural Networks\n  (IJCNN 2017)", "doi": "10.1109/IJCNN.2017.7966140", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has the hierarchical network architecture to represent the\ncomplicated features of input patterns. Such architecture is well known to\nrepresent higher learning capability compared with some conventional models if\nthe best set of parameters in the optimal network structure is found. We have\nbeen developing the adaptive learning method that can discover the optimal\nnetwork structure in Deep Belief Network (DBN). The learning method can\nconstruct the network structure with the optimal number of hidden neurons in\neach Restricted Boltzmann Machine and with the optimal number of layers in the\nDBN during learning phase. The network structure of the learning method can be\nself-organized according to given input patterns of big data set. In this\npaper, we embed the adaptive learning method into the recurrent temporal RBM\nand the self-generated layer into DBN. In order to verify the effectiveness of\nour proposed method, the experimental results are higher classification\ncapability than the conventional methods in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 05:34:32 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ichimura", "Takumi", ""], ["Kamada", "Shin", ""]]}, {"id": "1807.04001", "submitter": "Ismail Elezi", "authors": "Benjamin Bruno Meier, Ismail Elezi, Mohammadreza Amirian, Oliver Durr\n  and Thilo Stadelmann", "title": "Learning Neural Models for End-to-End Clustering", "comments": "Accepted for publication on ANNPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end neural network architecture that, once trained,\ndirectly outputs a probabilistic clustering of a batch of input examples in one\npass. It estimates a distribution over the number of clusters $k$, and for each\n$1 \\leq k \\leq k_\\mathrm{max}$, a distribution over the individual cluster\nassignment for each data point. The network is trained in advance in a\nsupervised fashion on separate data to learn grouping by any perceptual\nsimilarity criterion based on pairwise labels (same/different group). It can\nthen be applied to different data containing different groups. We demonstrate\npromising performance on high-dimensional data like images (COIL-100) and\nspeech (TIMIT). We call this ``learning to cluster'' and show its conceptual\ndifference to deep metric learning, semi-supervise clustering and other related\napproaches while having the advantage of performing learnable clustering fully\nend-to-end.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 08:45:45 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Meier", "Benjamin Bruno", ""], ["Elezi", "Ismail", ""], ["Amirian", "Mohammadreza", ""], ["Durr", "Oliver", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1807.04010", "submitter": "Ruibo Tu", "authors": "Ruibo Tu, Kun Zhang, Paul Ackermann, Bo Christer Bertilson, Clark\n  Glymour, Hedvig Kjellstr\\\"om, Cheng Zhang", "title": "Causal Discovery in the Presence of Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data are ubiquitous in many domains including healthcare. When these\ndata entries are not missing completely at random, the (conditional)\nindependence relations in the observed data may be different from those in the\ncomplete data generated by the underlying causal process. Consequently, simply\napplying existing causal discovery methods to the observed data may lead to\nwrong conclusions. In this paper, we aim at developing a causal discovery\nmethod to recover the underlying causal structure from observed data that\nfollow different missingness mechanisms, including missing completely at random\n(MCAR), missing at random (MAR), and missing not at random (MNAR). With\nmissingness mechanisms represented by missingness graphs, we analyse conditions\nunder which additional correction is needed to derive conditional\nindependence/dependence relations in the complete data. Based on our analysis,\nwe propose the Missing Value PC (MVPC) algorithm for both continuous and binary\nvariables, which extends the PC algorithm to incorporate additional\ncorrections. Our proposed MVPC is shown in theory to give asymptotically\ncorrect results even on data that are MAR or MNAR. Experimental results on\nsynthetic data show that the proposed algorithm is able to find correct causal\nrelations even in the general case of MNAR. Moreover, we create a neuropathic\npain diagnostic simulator for evaluating causal discovery methods. Evaluated on\nsuch simulated neuropathic pain diagnosis records and the other two real world\napplications, MVPC outperforms the other benchmark methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:01:29 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 10:37:09 GMT"}, {"version": "v3", "created": "Sat, 9 Mar 2019 08:24:43 GMT"}, {"version": "v4", "created": "Sun, 12 Jul 2020 13:42:13 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tu", "Ruibo", ""], ["Zhang", "Kun", ""], ["Ackermann", "Paul", ""], ["Bertilson", "Bo Christer", ""], ["Glymour", "Clark", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Zhang", "Cheng", ""]]}, {"id": "1807.04013", "submitter": "Yongming Shen", "authors": "Yongming Shen (1), Tianchu Ji (1), Michael Ferdman (1), Peter Milder\n  (1) ((1) Stony Brook University)", "title": "Medusa: A Scalable Interconnect for Many-Port DNN Accelerators and Wide\n  DRAM Controller Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the increasing demand and computational intensity of deep neural\nnetworks (DNNs), industry and academia have turned to accelerator technologies.\nIn particular, FPGAs have been shown to provide a good balance between\nperformance and energy efficiency for accelerating DNNs. While significant\nresearch has focused on how to build efficient layer processors, the\ncomputational building blocks of DNN accelerators, relatively little attention\nhas been paid to the on-chip interconnects that sit between the layer\nprocessors and the FPGA's DRAM controller.\n  We observe a disparity between DNN accelerator interfaces, which tend to\ncomprise many narrow ports, and FPGA DRAM controller interfaces, which tend to\nbe wide buses. This mismatch causes traditional interconnects to consume\nsignificant FPGA resources. To address this problem, we designed Medusa: an\noptimized FPGA memory interconnect which transposes data in the interconnect\nfabric, tailoring the interconnect to the needs of DNN layer processors.\nCompared to a traditional FPGA interconnect, our design can reduce LUT and FF\nuse by 4.7x and 6.0x, and improves frequency by 1.8x.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:06:20 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Shen", "Yongming", "", "Stony Brook University"], ["Ji", "Tianchu", "", "Stony Brook University"], ["Ferdman", "Michael", "", "Stony Brook University"], ["Milder", "Peter", "", "Stony Brook University"]]}, {"id": "1807.04015", "submitter": "Thanh-Tung Hoang", "authors": "Hoang Thanh-Tung, Truyen Tran", "title": "On Catastrophic Forgetting and Mode Collapse in Generative Adversarial\n  Networks", "comments": "This is an extended version of our paper in ICML'18 Workshop on\n  Theoretical Foundation and Applications of Deep Generative Models. Accepted\n  to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that Generative Adversarial Networks (GANs) suffer\nfrom catastrophic forgetting even when they are trained to approximate a single\ntarget distribution. We show that GAN training is a continual learning problem\nin which the sequence of changing model distributions is the sequence of tasks\nto the discriminator. The level of mismatch between tasks in the sequence\ndetermines the level of forgetting. Catastrophic forgetting is interrelated to\nmode collapse and can make the training of GANs non-convergent. We investigate\nthe landscape of the discriminator's output in different variants of GANs and\nfind that when a GAN converges to a good equilibrium, real training datapoints\nare wide local maxima of the discriminator. We empirically show the\nrelationship between the sharpness of local maxima and mode collapse and\ngeneralization in GANs. We show how catastrophic forgetting prevents the\ndiscriminator from making real datapoints local maxima, and thus causes\nnon-convergence. Finally, we study methods for preventing catastrophic\nforgetting in GANs.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:08:34 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 06:37:05 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 20:10:35 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 04:23:48 GMT"}, {"version": "v5", "created": "Fri, 2 Aug 2019 15:21:05 GMT"}, {"version": "v6", "created": "Wed, 16 Oct 2019 15:04:16 GMT"}, {"version": "v7", "created": "Thu, 17 Oct 2019 01:06:13 GMT"}, {"version": "v8", "created": "Sat, 21 Mar 2020 04:31:17 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Thanh-Tung", "Hoang", ""], ["Tran", "Truyen", ""]]}, {"id": "1807.04020", "submitter": "Nicolas Gillis", "authors": "Atif Muhammad Syed, Sameer Qazi, Nicolas Gillis", "title": "Improved SVD-based Initialization for Nonnegative Matrix Factorization\n  using Low-Rank Correction", "comments": "12 pages, 1 figure, 5 tables, submitted to pattern recognition\n  letters", "journal-ref": "Pattern Recognition Letters 122, pp. 53-59, 2019", "doi": "10.1016/j.patrec.2019.02.018", "report-no": null, "categories": "cs.NA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the iterative nature of most nonnegative matrix factorization\n(\\textsc{NMF}) algorithms, initialization is a key aspect as it significantly\ninfluences both the convergence and the final solution obtained. Many\ninitialization schemes have been proposed for NMF, among which one of the most\npopular class of methods are based on the singular value decomposition (SVD).\nHowever, these SVD-based initializations do not satisfy a rather natural\ncondition, namely that the error should decrease as the rank of factorization\nincreases. In this paper, we propose a novel SVD-based \\textsc{NMF}\ninitialization to specifically address this shortcoming by taking into account\nthe SVD factors that were discarded to obtain a nonnegative initialization.\nThis method, referred to as nonnegative SVD with low-rank correction\n(NNSVD-LRC), allows us to significantly reduce the initial error at a\nnegligible additional computational cost using the low-rank structure of the\ndiscarded SVD factors. NNSVD-LRC has two other advantages compared to previous\nSVD-based initializations: (1) it provably generates sparse initial factors,\nand (2) it is faster as it only requires to compute a truncated SVD of rank\n$\\lceil r/2 + 1 \\rceil$ where $r$ is the factorization rank of the sought NMF\ndecomposition (as opposed to a rank-$r$ truncated SVD for other methods). We\nshow on several standard dense and sparse data sets that our new method\ncompetes favorably with state-of-the-art SVD-based initializations for NMF.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:21:31 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Syed", "Atif Muhammad", ""], ["Qazi", "Sameer", ""], ["Gillis", "Nicolas", ""]]}, {"id": "1807.04040", "submitter": "Jeevan Manavalan", "authors": "Jeevan Manavalan, Matthew Howard", "title": "Learning Singularity Avoidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increase in complexity of robotic systems and the rise in non-expert\nusers, it can be assumed that task constraints are not explicitly known. In\ntasks where avoiding singularity is critical to its success, this paper\nprovides an approach, especially for non-expert users, for the system to learn\nthe constraints contained in a set of demonstrations, such that they can be\nused to optimise an autonomous controller to avoid singularity, without having\nto explicitly know the task constraints. The proposed approach avoids\nsingularity, and thereby unpredictable behaviour when carrying out a task, by\nmaximising the learnt manipulability throughout the motion of the constrained\nsystem, and is not limited to kinematic systems. Its benefits are demonstrated\nthrough comparisons with other control policies which show that the constrained\nmanipulability of a system learnt through demonstration can be used to avoid\nsingularities in cases where these other policies would fail. In the absence of\nthe systems manipulability subject to a tasks constraints, the proposed\napproach can be used instead to infer these with results showing errors less\nthan 10^-5 in 3DOF simulated systems as well as 10^-2 using a 7DOF real world\nrobotic system.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 09:46:05 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 22:03:01 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Manavalan", "Jeevan", ""], ["Howard", "Matthew", ""]]}, {"id": "1807.04056", "submitter": "Nicolo' Savioli", "authors": "Nicolo' Savioli, Silvia Visentin, Erich Cosmi, Enrico Grisan, Pablo\n  Lamata, Giovanni Montana", "title": "Temporal Convolution Networks for Real-Time Abdominal Fetal Aorta\n  Analysis with Ultrasound", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The automatic analysis of ultrasound sequences can substantially improve the\nefficiency of clinical diagnosis. In this work we present our attempt to\nautomate the challenging task of measuring the vascular diameter of the fetal\nabdominal aorta from ultrasound images. We propose a neural network\narchitecture consisting of three blocks: a convolutional layer for the\nextraction of imaging features, a Convolution Gated Recurrent Unit (C-GRU) for\nenforcing the temporal coherence across video frames and exploiting the\ntemporal redundancy of a signal, and a regularized loss function, called\n\\textit{CyclicLoss}, to impose our prior knowledge about the periodicity of the\nobserved signal. We present experimental evidence suggesting that the proposed\narchitecture can reach an accuracy substantially superior to previously\nproposed methods, providing an average reduction of the mean squared error from\n$0.31 mm^2$ (state-of-art) to $0.09 mm^2$, and a relative error reduction from\n$8.1\\%$ to $5.3\\%$. The mean execution speed of the proposed approach of 289\nframes per second makes it suitable for real time clinical use.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 10:22:38 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Savioli", "Nicolo'", ""], ["Visentin", "Silvia", ""], ["Cosmi", "Erich", ""], ["Grisan", "Enrico", ""], ["Lamata", "Pablo", ""], ["Montana", "Giovanni", ""]]}, {"id": "1807.04065", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Steven Van Vaerenbergh, Danilo Comminiello, Simone\n  Totaro, Aurelio Uncini", "title": "Recurrent Neural Networks with Flexible Gates using Kernel Activation\n  Functions", "comments": "Accepted for presentation at 2018 IEEE International Workshop on\n  Machine Learning for Signal Processing (MLSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gated recurrent neural networks have achieved remarkable results in the\nanalysis of sequential data. Inside these networks, gates are used to control\nthe flow of information, allowing to model even very long-term dependencies in\nthe data. In this paper, we investigate whether the original gate equation (a\nlinear projection followed by an element-wise sigmoid) can be improved. In\nparticular, we design a more flexible architecture, with a small number of\nadaptable parameters, which is able to model a wider range of gating functions\nthan the classical one. To this end, we replace the sigmoid function in the\nstandard gate with a non-parametric formulation extending the recently proposed\nkernel activation function (KAF), with the addition of a residual\nskip-connection. A set of experiments on sequential variants of the MNIST\ndataset shows that the adoption of this novel gate allows to improve accuracy\nwith a negligible cost in terms of computational power and with a large\nspeed-up in the number of training iterations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 10:54:46 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Scardapane", "Simone", ""], ["Van Vaerenbergh", "Steven", ""], ["Comminiello", "Danilo", ""], ["Totaro", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1807.04073", "submitter": "Weiping Zheng", "authors": "Weiping Zheng, Zhenyao Mo, Jiantao Yi", "title": "A punishment voting algorithm based on super categories construction for\n  acoustic scene classification", "comments": "There is a minor mistake found in the voting process. So, We are very\n  sorry about this mistake and request to withdraw this manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In acoustic scene classification researches, audio segment is usually split\ninto multiple samples. Majority voting is then utilized to ensemble the results\nof the samples. In this paper, we propose a punishment voting algorithm based\non the super categories construction method for acoustic scene classification.\nSpecifically, we propose a DenseNet-like model as the base classifier. The base\nclassifier is trained by the CQT spectrograms generated from the raw audio\nsegments. Taking advantage of the results of the base classifier, we propose a\nsuper categories construction method using the spectral clustering. Super\nclassifiers corresponding to the constructed super categories are further\ntrained. Finally, the super classifiers are utilized to enhance the majority\nvoting of the base classifier by punishment voting. Experiments show that the\npunishment voting obviously improves the performances on both the DCASE2017\nDevelopment dataset and the LITIS Rouen dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 11:14:19 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 05:14:42 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Zheng", "Weiping", ""], ["Mo", "Zhenyao", ""], ["Yi", "Jiantao", ""]]}, {"id": "1807.04081", "submitter": "Aasheesh Barvey", "authors": "Aasheesh Barvey, Jitin Kapila, Kumarjit Pathak", "title": "Proactive Intervention to Downtrend Employee Attrition using Artificial\n  Intelligence Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To predict the employee attrition beforehand and to enable management to take\nindividualized preventive action. Using Ensemble classification modeling\ntechniques and Linear Regression. Model could predict over 91% accurate\nemployee prediction, lead-time in separation and individual reasons causing\nattrition. Prior intimation of employee attrition enables manager to take\npreventive actions to retain employee or to manage the business consequences of\nattrition. Once deployed this will model can help in downtrend Employee\nAttrition, will help manager to manage team more effectively. Model does not\ncover the natural calamities, and unforeseen events occurring at an individual\nlevel like accident, death etc.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 11:38:03 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Barvey", "Aasheesh", ""], ["Kapila", "Jitin", ""], ["Pathak", "Kumarjit", ""]]}, {"id": "1807.04093", "submitter": "Vladimir Rybalkin", "authors": "Vladimir Rybalkin, Alessandro Pappalardo, Muhammad Mohsin Ghaffar,\n  Giulio Gambardella, Norbert Wehn, Michaela Blott", "title": "FINN-L: Library Extensions and Design Trade-off Analysis for Variable\n  Precision LSTM Networks on FPGAs", "comments": "Accepted for publication, 28th International Conference on Field\n  Programmable Logic and Applications (FPL), August, 2018, Dublin, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that many types of artificial neural networks, including\nrecurrent networks, can achieve a high classification accuracy even with\nlow-precision weights and activations. The reduction in precision generally\nyields much more efficient hardware implementations in regards to hardware\ncost, memory requirements, energy, and achievable throughput. In this paper, we\npresent the first systematic exploration of this design space as a function of\nprecision for Bidirectional Long Short-Term Memory (BiLSTM) neural network.\nSpecifically, we include an in-depth investigation of precision vs. accuracy\nusing a fully hardware-aware training flow, where during training quantization\nof all aspects of the network including weights, input, output and in-memory\ncell activations are taken into consideration. In addition, hardware resource\ncost, power consumption and throughput scalability are explored as a function\nof precision for FPGA-based implementations of BiLSTM, and multiple approaches\nof parallelizing the hardware. We provide the first open source HLS library\nextension of FINN for parameterizable hardware architectures of LSTM layers on\nFPGAs which offers full precision flexibility and allows for parameterizable\nperformance scaling offering different levels of parallelism within the\narchitecture. Based on this library, we present an FPGA-based accelerator for\nBiLSTM neural network designed for optical character recognition, along with\nnumerous other experimental proof points for a Zynq UltraScale+ XCZU7EV MPSoC\nwithin the given design space.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 11:52:59 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Rybalkin", "Vladimir", ""], ["Pappalardo", "Alessandro", ""], ["Ghaffar", "Muhammad Mohsin", ""], ["Gambardella", "Giulio", ""], ["Wehn", "Norbert", ""], ["Blott", "Michaela", ""]]}, {"id": "1807.04098", "submitter": "C. H. Bryan Liu", "authors": "Georg L. Grob, \\^Angelo Cardoso, C. H. Bryan Liu, Duncan A. Little,\n  Benjamin Paul Chamberlain", "title": "A Recurrent Neural Network Survival Model: Predicting Web User Return\n  Time", "comments": "Accepted into ECML PKDD 2018; 8 figures and 1 table", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2018. Lecture Notes in Computer Science, vol 11053. pp 152-168", "doi": "10.1007/978-3-030-10997-4_10", "report-no": null, "categories": "cs.LG cs.CY cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size of a website's active user base directly affects its value. Thus, it\nis important to monitor and influence a user's likelihood to return to a site.\nEssential to this is predicting when a user will return. Current state of the\nart approaches to solve this problem come in two flavors: (1) Recurrent Neural\nNetwork (RNN) based solutions and (2) survival analysis methods. We observe\nthat both techniques are severely limited when applied to this problem.\nSurvival models can only incorporate aggregate representations of users instead\nof automatically learning a representation directly from a raw time series of\nuser actions. RNNs can automatically learn features, but can not be directly\ntrained with examples of non-returning users who have no target value for their\nreturn time. We develop a novel RNN survival model that removes the limitations\nof the state of the art methods. We demonstrate that this model can\nsuccessfully be applied to return time prediction on a large e-commerce dataset\nwith a superior ability to discriminate between returning and non-returning\nusers than either method applied in isolation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 12:12:48 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Grob", "Georg L.", ""], ["Cardoso", "\u00c2ngelo", ""], ["Liu", "C. H. Bryan", ""], ["Little", "Duncan A.", ""], ["Chamberlain", "Benjamin Paul", ""]]}, {"id": "1807.04106", "submitter": "Philip Bachman", "authors": "Philip Bachman, Riashat Islam, Alessandro Sordoni, Zafarali Ahmed", "title": "VFunc: a Deep Generative Model for Functions", "comments": "To be presented at the ICML 2018 workshop on Prediction and\n  Generative Modeling in Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep generative model for functions. Our model provides a\njoint distribution p(f, z) over functions f and latent variables z which lets\nus efficiently sample from the marginal p(f) and maximize a variational lower\nbound on the entropy H(f). We can thus maximize objectives of the form\nE_{f~p(f)}[R(f)] + c*H(f), where R(f) denotes, e.g., a data log-likelihood term\nor an expected reward. Such objectives encompass Bayesian deep learning in\nfunction space, rather than parameter space, and Bayesian deep RL with\nrepresentations of uncertainty that offer benefits over bootstrapping and\nparameter noise. In this short paper we describe our model, situate it in the\ncontext of prior work, and present proof-of-concept experiments for regression\nand RL.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 12:38:30 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Bachman", "Philip", ""], ["Islam", "Riashat", ""], ["Sordoni", "Alessandro", ""], ["Ahmed", "Zafarali", ""]]}, {"id": "1807.04109", "submitter": "Matias Valdenegro-Toro", "authors": "Samy Nascimento, Matias Valdenegro-Toro", "title": "Modeling and Soft-fault Diagnosis of Underwater Thrusters with Recurrent\n  Neural Networks", "comments": "CAMS 2018 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noncritical soft-faults and model deviations are a challenge for Fault\nDetection and Diagnosis (FDD) of resident Autonomous Underwater Vehicles\n(AUVs). Such systems may have a faster performance degradation due to the\npermanent exposure to the marine environment, and constant monitoring of\ncomponent conditions is required to ensure their reliability. This works\npresents an evaluation of Recurrent Neural Networks (RNNs) for a data-driven\nfault detection and diagnosis scheme for underwater thrusters with empirical\ndata. The nominal behavior of the thruster was modeled using the measured\ncontrol input, voltage, rotational speed and current signals. We evaluated the\nperformance of fault classification using all the measured signals compared to\nusing the computed residuals from the nominal model as features.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 12:51:22 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Nascimento", "Samy", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "1807.04119", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Exploiting statistical dependencies of time series with hierarchical\n  correlation reconstruction", "comments": "10 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While we are usually focused on forecasting future values of time series, it\nis often valuable to additionally predict their entire probability\ndistributions, e.g. to evaluate risk, Monte Carlo simulations. On example of\ntime series of $\\approx$ 30000 Dow Jones Industrial Averages, there will be\npresented application of hierarchical correlation reconstruction for this\npurpose: MSE estimating polynomial as joint density for (current value,\ncontext), where context is for example a few previous values. Then substituting\nthe currently observed context and normalizing density to 1, we get predicted\nprobability distribution for the current value. In contrast to standard machine\nlearning approaches like neural networks, optimal polynomial coefficients here\nhave inexpensive direct formula, have controllable accuracy, are unique and\nindependently calculated, each has a specific cumulant-like interpretation, and\nsuch approximation can asymptotically approach complete description of any real\njoint distribution - providing universal tool to quantitatively describe and\nexploit statistical dependencies in time series, systematically enhancing\nARMA/ARCH-like approaches, also based on different distributions than Gaussian\nwhich turns out improper for daily log returns. There is also discussed\napplication for non-stationary time series like calculating linear time trend,\nor adapting coefficients to local statistical behavior.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 13:31:35 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 13:27:52 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2018 12:30:54 GMT"}, {"version": "v4", "created": "Wed, 2 Jan 2019 12:36:35 GMT"}, {"version": "v5", "created": "Wed, 23 Jan 2019 14:48:55 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1807.04162", "submitter": "Alexander Alemi", "authors": "Alexander A. Alemi and Ian Fischer", "title": "TherML: Thermodynamics of Machine Learning", "comments": "Presented at the ICML 2018 workshop on Theoretical Foundations and\n  Applications of Deep Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we offer a framework for reasoning about a wide class of\nexisting objectives in machine learning. We develop a formal correspondence\nbetween this work and thermodynamics and discuss its implications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:39:17 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2018 17:04:46 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2018 20:26:11 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Alemi", "Alexander A.", ""], ["Fischer", "Ian", ""]]}, {"id": "1807.04183", "submitter": "Christopher McCord", "authors": "Dimitris Bertsimas and Christopher McCord", "title": "Optimization over Continuous and Multi-dimensional Decisions with\n  Observational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization of an uncertain objective over continuous and\nmulti-dimensional decision spaces in problems in which we are only provided\nwith observational data. We propose a novel algorithmic framework that is\ntractable, asymptotically consistent, and superior to comparable methods on\nexample problems. Our approach leverages predictive machine learning methods\nand incorporates information on the uncertainty of the predicted outcomes for\nthe purpose of prescribing decisions. We demonstrate the efficacy of our method\non examples involving both synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:07:12 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 17:16:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["McCord", "Christopher", ""]]}, {"id": "1807.04188", "submitter": "Thierry Moreau", "authors": "Thierry Moreau, Tianqi Chen, Luis Vega, Jared Roesch, Eddie Yan,\n  Lianmin Zheng, Josh Fromm, Ziheng Jiang, Luis Ceze, Carlos Guestrin, Arvind\n  Krishnamurthy", "title": "A Hardware-Software Blueprint for Flexible Deep Learning Specialization", "comments": "6 pages plus references, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized Deep Learning (DL) acceleration stacks, designed for a specific\nset of frameworks, model architectures, operators, and data types, offer the\nallure of high performance while sacrificing flexibility. Changes in\nalgorithms, models, operators, or numerical systems threaten the viability of\nspecialized hardware accelerators. We propose VTA, a programmable deep learning\narchitecture template designed to be extensible in the face of evolving\nworkloads. VTA achieves this flexibility via a parametrizable architecture,\ntwo-level ISA, and a JIT compiler. The two-level ISA is based on (1) a task-ISA\nthat explicitly orchestrates concurrent compute and memory tasks and (2) a\nmicrocode-ISA which implements a wide variety of operators with single-cycle\ntensor-tensor operations. Next, we propose a runtime system equipped with a JIT\ncompiler for flexible code-generation and heterogeneous execution that enables\neffective use of the VTA architecture. VTA is integrated and open-sourced into\nApache TVM, a state-of-the-art deep learning compilation stack that provides\nflexibility for diverse models and divergent hardware backends. We propose a\nflow that performs design space exploration to generate a customized hardware\narchitecture and software operator library that can be leveraged by mainstream\nlearning frameworks. We demonstrate our approach by deploying optimized deep\nlearning models used for object classification and style transfer on edge-class\nFPGAs.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:19:30 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 03:51:47 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 00:50:43 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Moreau", "Thierry", ""], ["Chen", "Tianqi", ""], ["Vega", "Luis", ""], ["Roesch", "Jared", ""], ["Yan", "Eddie", ""], ["Zheng", "Lianmin", ""], ["Fromm", "Josh", ""], ["Jiang", "Ziheng", ""], ["Ceze", "Luis", ""], ["Guestrin", "Carlos", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1807.04193", "submitter": "Inaki Estella", "authors": "Inaki Estella Aguerri and Abdellatif Zaidi", "title": "Distributed Variational Representation Learning", "comments": "35 pages, 10 figures, submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of distributed representation learning is one in which multiple\nsources of information $X_1,\\ldots,X_K$ are processed separately so as to learn\nas much information as possible about some ground truth $Y$. We investigate\nthis problem from information-theoretic grounds, through a generalization of\nTishby's centralized Information Bottleneck (IB) method to the distributed\nsetting. Specifically, $K$ encoders, $K \\geq 2$, compress their observations\n$X_1,\\ldots,X_K$ separately in a manner such that, collectively, the produced\nrepresentations preserve as much information as possible about $Y$. We study\nboth discrete memoryless (DM) and memoryless vector Gaussian data models. For\nthe discrete model, we establish a single-letter characterization of the\noptimal tradeoff between complexity (or rate) and relevance (or information)\nfor a class of memoryless sources (the observations $X_1,\\ldots,X_K$ being\nconditionally independent given $Y$). For the vector Gaussian model, we provide\nan explicit characterization of the optimal complexity-relevance tradeoff.\nFurthermore, we develop a variational bound on the complexity-relevance\ntradeoff which generalizes the evidence lower bound (ELBO) to the distributed\nsetting. We also provide two algorithms that allow to compute this bound: i) a\nBlahut-Arimoto type iterative algorithm which enables to compute optimal\ncomplexity-relevance encoding mappings by iterating over a set of\nself-consistent equations, and ii) a variational inference type algorithm in\nwhich the encoding mappings are parametrized by neural networks and the bound\napproximated by Markov sampling and optimized with stochastic gradient descent.\nNumerical results on synthetic and real datasets are provided to support the\nefficiency of the approaches and algorithms developed in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:25:09 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 12:14:57 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2019 15:55:06 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Aguerri", "Inaki Estella", ""], ["Zaidi", "Abdellatif", ""]]}, {"id": "1807.04209", "submitter": "Weijie J. Su", "authors": "Cynthia Dwork and Weijie J. Su and Li Zhang", "title": "Differentially Private False Discovery Rate Control", "comments": "To appear in The Journal of Privacy and Confidentiality", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides a rigorous framework for privacy-preserving\ndata analysis. This paper proposes the first differentially private procedure\nfor controlling the false discovery rate (FDR) in multiple hypothesis testing.\nInspired by the Benjamini-Hochberg procedure (BHq), our approach is to first\nrepeatedly add noise to the logarithms of the $p$-values to ensure differential\nprivacy and to select an approximately smallest $p$-value serving as a\npromising candidate at each iteration; the selected $p$-values are further\nsupplied to the BHq and our private procedure releases only the rejected ones.\nMoreover, we develop a new technique that is based on a backward submartingale\nfor proving FDR control of a broad class of multiple testing procedures,\nincluding our private procedure, and both the BHq step-up and step-down\nprocedures. As a novel aspect, the proof works for arbitrary dependence between\nthe true null and false null test statistics, while FDR control is maintained\nup to a small multiplicative factor.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:53:09 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 16:24:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dwork", "Cynthia", ""], ["Su", "Weijie J.", ""], ["Zhang", "Li", ""]]}, {"id": "1807.04222", "submitter": "Juncai He", "authors": "Juncai He, Xiaodong Jia, Jinchao Xu, Lian Zhang, Liang Zhao", "title": "Make $\\ell_1$ Regularization Effective in Training Sparse CNN", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed Sensing using $\\ell_1$ regularization is among the most powerful\nand popular sparsification technique in many applications, but why has it not\nbeen used to obtain sparse deep learning model such as convolutional neural\nnetwork (CNN)? This paper is aimed to provide an answer to this question and to\nshow how to make it work. We first demonstrate that the commonly used\nstochastic gradient decent (SGD) and variants training algorithm is not an\nappropriate match with $\\ell_1$ regularization and then replace it with a\ndifferent training algorithm based on a regularized dual averaging (RDA)\nmethod. RDA was originally designed specifically for convex problem, but with\nnew theoretical insight and algorithmic modifications (using proper\ninitialization and adaptivity), we have made it an effective match with\n$\\ell_1$ regularization to achieve a state-of-the-art sparsity for CNN compared\nto other weight pruning methods without compromising accuracy (achieving 95\\%\nsparsity for ResNet18 on CIFAR-10, for example).\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 16:06:23 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 03:21:48 GMT"}, {"version": "v3", "created": "Sat, 14 Jul 2018 11:28:38 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2019 19:29:47 GMT"}, {"version": "v5", "created": "Wed, 3 Jun 2020 19:22:03 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["He", "Juncai", ""], ["Jia", "Xiaodong", ""], ["Xu", "Jinchao", ""], ["Zhang", "Lian", ""], ["Zhao", "Liang", ""]]}, {"id": "1807.04225", "submitter": "Adam Santoro", "authors": "David G.T. Barrett, Felix Hill, Adam Santoro, Ari S. Morcos, Timothy\n  Lillicrap", "title": "Measuring abstract reasoning in neural networks", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether neural networks can learn abstract reasoning or whether they merely\nrely on superficial statistics is a topic of recent debate. Here, we propose a\ndataset and challenge designed to probe abstract reasoning, inspired by a\nwell-known human IQ test. To succeed at this challenge, models must cope with\nvarious generalisation `regimes' in which the training and test data differ in\nclearly-defined ways. We show that popular models such as ResNets perform\npoorly, even when the training and test sets differ only minimally, and we\npresent a novel architecture, with a structure designed to encourage reasoning,\nthat does significantly better. When we vary the way in which the test\nquestions and training data differ, we find that our model is notably\nproficient at certain forms of generalisation, but notably weak at others. We\nfurther show that the model's ability to generalise improves markedly if it is\ntrained to predict symbolic explanations for its answers. Altogether, we\nintroduce and explore ways to both measure and induce stronger abstract\nreasoning in neural networks. Our freely-available dataset should motivate\nfurther progress in this direction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 16:14:25 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Barrett", "David G. T.", ""], ["Hill", "Felix", ""], ["Santoro", "Adam", ""], ["Morcos", "Ari S.", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1807.04239", "submitter": "Sourya Dey", "authors": "Sourya Dey, Keith M. Chugg and Peter A. Beerel", "title": "Morse Code Datasets for Machine Learning", "comments": "Presented at the 9th International Conference on Computing,\n  Communication and Networking Technologies (ICCCNT)", "journal-ref": "in 9th International Conference on Computing, Communication and\n  Networking Technologies (ICCCNT), pp. 1-7, Jul 2018", "doi": "10.1109/ICCCNT.2018.8494011", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to generate synthetic datasets of tunable difficulty\non classification of Morse code symbols for supervised machine learning\nproblems, in particular, neural networks. The datasets are spatially\none-dimensional and have a small number of input features, leading to high\ndensity of input information content. This makes them particularly challenging\nwhen implementing network complexity reduction methods. We explore how network\nperformance is affected by deliberately adding various forms of noise and\nexpanding the feature set and dataset size. Finally, we establish several\nmetrics to indicate the difficulty of a dataset, and evaluate their merits. The\nalgorithm and datasets are open-source.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 16:41:49 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 00:33:37 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dey", "Sourya", ""], ["Chugg", "Keith M.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "1807.04241", "submitter": "Yang Zhou", "authors": "Yang Zhou, Yan Huang", "title": "DeepMove: Learning Place Representations through Large Scale Movement\n  Data", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and reasoning about places and their relationships are critical\nfor many applications. Places are traditionally curated by a small group of\npeople as place gazetteers and are represented by an ID with spatial extent,\ncategory, and other descriptions. However, a place context is described to a\nlarge extent by movements made from/to other places. Places are linked and\nrelated to each other by these movements. This important context is missing\nfrom the traditional representation.\n  We present DeepMove, a novel approach for learning latent representations of\nplaces. DeepMove advances the current deep learning based place representations\nby directly model movements between places. We demonstrate DeepMove's latent\nrepresentations on place categorization and clustering tasks on large place and\nmovement datasets with respect to important parameters. Our results show that\nDeepMove outperforms state-of-the-art baselines. DeepMove's representations can\nprovide up to 15% higher than competing methods in matching rate of place\ncategory and result in up to 39% higher silhouette coefficient value for place\nclusters.\n  DeepMove is spatial and temporal context aware. It is scalable. It\noutperforms competing models using much smaller training dataset (a month or\n1/12 of data). These qualities make it suitable for a broad class of real-world\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 16:47:36 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 20:14:36 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Zhou", "Yang", ""], ["Huang", "Yan", ""]]}, {"id": "1807.04245", "submitter": "Laurence Yang", "authors": "Laurence Yang, Michael A. Saunders, Jean-Christophe Lachance, Bernhard\n  O. Palsson, Jos\\'e Bento", "title": "Estimating Cellular Goals from High-Dimensional Biological Data", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330775", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization-based models have been used to predict cellular behavior for\nover 25 years. The constraints in these models are derived from genome\nannotations, measured macro-molecular composition of cells, and by measuring\nthe cell's growth rate and metabolism in different conditions. The cellular\ngoal (the optimization problem that the cell is trying to solve) can be\nchallenging to derive experimentally for many organisms, including human or\nmammalian cells, which have complex metabolic capabilities and are not well\nunderstood. Existing approaches to learning goals from data include (a)\nestimating a linear objective function, or (b) estimating linear constraints\nthat model complex biochemical reactions and constrain the cell's operation.\nThe latter approach is important because often the known/observed biochemical\nreactions are not enough to explain observations, and hence there is a need to\nextend automatically the model complexity by learning new chemical reactions.\nHowever, this leads to nonconvex optimization problems, and existing tools\ncannot scale to realistically large metabolic models. Hence, constraint\nestimation is still used sparingly despite its benefits for modeling cell\nmetabolism, which is important for developing novel antimicrobials against\npathogens, discovering cancer drug targets, and producing value-added\nchemicals. Here, we develop the first approach to estimating constraint\nreactions from data that can scale to realistically large metabolic models.\nPrevious tools have been used on problems having less than 75 biochemical\nreactions and 60 metabolites, which limits real-life-size applications. We\nperform extensive experiments using 75 large-scale metabolic network models for\ndifferent organisms (including bacteria, yeasts, and mammals) and show that our\nalgorithm can recover cellular constraint reactions, even when some\nmeasurements are missing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 16:57:57 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 20:44:09 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 09:00:30 GMT"}, {"version": "v4", "created": "Mon, 20 May 2019 05:10:34 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yang", "Laurence", ""], ["Saunders", "Michael A.", ""], ["Lachance", "Jean-Christophe", ""], ["Palsson", "Bernhard O.", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1807.04255", "submitter": "Adel Elmahdy", "authors": "Adel Elmahdy, Soheil Mohajer", "title": "On the Fundamental Limits of Coded Data Shuffling for Distributed\n  Machine Learning", "comments": "This work has been published in IEEE Transactions on Information\n  Theory. A preliminary version of this work was presented at IEEE\n  International Symposium on Information Theory (ISIT), Jun. 2018", "journal-ref": "IEEE Transactions on Information Theory, vol. 66, no. 5, pp.\n  3098-3131, May 2020", "doi": "10.1109/TIT.2020.2964547", "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the data shuffling problem in a distributed learning system, in\nwhich a master node is connected to a set of worker nodes, via a shared link,\nin order to communicate a set of files to the worker nodes. The master node has\naccess to a database of files. In every shuffling iteration, each worker node\nprocesses a new subset of files, and has excess storage to partially cache the\nremaining files, assuming the cached files are uncoded. The caches of the\nworker nodes are updated every iteration, and they should be designed to\nsatisfy any possible unknown permutation of the files in subsequent iterations.\nFor this problem, we characterize the exact load-memory trade-off for\nworst-case shuffling by deriving the minimum communication load for a given\nstorage capacity per worker node. As a byproduct, the exact load-memory\ntrade-off for any shuffling is characterized when the number of files is equal\nto the number of worker nodes. We propose a novel deterministic coded shuffling\nscheme, which improves the state of the art, by exploiting the cache memories\nto create coded functions that can be decoded by several worker nodes. Then, we\nprove the optimality of our proposed scheme by deriving a matching lower bound\nand showing that the placement phase of the proposed coded shuffling scheme is\noptimal over all shuffles.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 17:31:30 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 07:47:42 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Elmahdy", "Adel", ""], ["Mohajer", "Soheil", ""]]}, {"id": "1807.04261", "submitter": "Oscar Leong", "authors": "Paul Hand, Oscar Leong, Vladislav Voroninski", "title": "Phase Retrieval Under a Generative Prior", "comments": "28 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase retrieval problem asks to recover a natural signal $y_0 \\in\n\\mathbb{R}^n$ from $m$ quadratic observations, where $m$ is to be minimized. As\nis common in many imaging problems, natural signals are considered sparse with\nrespect to a known basis, and the generic sparsity prior is enforced via\n$\\ell_1$ regularization. While successful in the realm of linear inverse\nproblems, such $\\ell_1$ methods have encountered possibly fundamental\nlimitations, as no computationally efficient algorithm for phase retrieval of a\n$k$-sparse signal has been proven to succeed with fewer than $O(k^2\\log n)$\ngeneric measurements, exceeding the theoretical optimum of $O(k \\log n)$. In\nthis paper, we propose a novel framework for phase retrieval by 1) modeling\nnatural signals as being in the range of a deep generative neural network $G :\n\\mathbb{R}^k \\rightarrow \\mathbb{R}^n$ and 2) enforcing this prior directly by\noptimizing an empirical risk objective over the domain of the generator. Our\nformulation has provably favorable global geometry for gradient methods, as\nsoon as $m = O(kd^2\\log n)$, where $d$ is the depth of the network.\nSpecifically, when suitable deterministic conditions on the generator and\nmeasurement matrix are met, we construct a descent direction for any point\noutside of a small neighborhood around the unique global minimizer and its\nnegative multiple, and show that such conditions hold with high probability\nunder Gaussian ensembles of multilayer fully-connected generator networks and\nmeasurement matrices. This formulation for structured phase retrieval thus has\ntwo advantages over sparsity based methods: 1) deep generative priors can more\ntightly represent natural signals and 2) information theoretically optimal\nsample complexity. We corroborate these results with experiments showing that\nexploiting generative models in phase retrieval tasks outperforms sparse phase\nretrieval methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 17:52:07 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Hand", "Paul", ""], ["Leong", "Oscar", ""], ["Voroninski", "Vladislav", ""]]}, {"id": "1807.04270", "submitter": "Thomas Rademaker", "authors": "Thomas J. Rademaker, Emmanuel Bengio, Paul Fran\\c{c}ois", "title": "Attack and defence in cellular decision-making: lessons from machine\n  learning", "comments": null, "journal-ref": "Phys. Rev. X 9, 031012 (2019)", "doi": "10.1103/PhysRevX.9.031012", "report-no": null, "categories": "physics.bio-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms can be fooled by small well-designed adversarial\nperturbations. This is reminiscent of cellular decision-making where ligands\n(called antagonists) prevent correct signalling, like in early immune\nrecognition. We draw a formal analogy between neural networks used in machine\nlearning and models of cellular decision-making (adaptive proofreading). We\napply attacks from machine learning to simple decision-making models, and show\nexplicitly the correspondence to antagonism by weakly bound ligands. Such\nantagonism is absent in more nonlinear models, which inspired us to implement a\nbiomimetic defence in neural networks filtering out adversarial perturbations.\nWe then apply a gradient-descent approach from machine learning to different\ncellular decision-making models, and we reveal the existence of two regimes\ncharacterized by the presence or absence of a critical point for the gradient.\nThis critical point causes the strongest antagonists to lie close to the\ndecision boundary. This is validated in the loss landscapes of robust neural\nnetworks and cellular decision-making models, and observed experimentally for\nimmune cells. For both regimes, we explain how associated defence mechanisms\nshape the geometry of the loss landscape, and why different adversarial attacks\nare effective in different regimes. Our work connects evolved cellular\ndecision-making to machine learning, and motivates the design of a general\ntheory of adversarial perturbations, both for in vivo and in silico systems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 16:43:30 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 21:18:38 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 15:25:00 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Rademaker", "Thomas J.", ""], ["Bengio", "Emmanuel", ""], ["Fran\u00e7ois", "Paul", ""]]}, {"id": "1807.04271", "submitter": "Ewin Tang", "authors": "Ewin Tang", "title": "A quantum-inspired classical algorithm for recommendation systems", "comments": "32 pages; revised structure of document, improved runtime, simplified\n  algorithm and notation", "journal-ref": null, "doi": "10.1145/3313276.3316310", "report-no": null, "categories": "cs.IR cs.DS cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a classical analogue to Kerenidis and Prakash's quantum\nrecommendation system, previously believed to be one of the strongest\ncandidates for provably exponential speedups in quantum machine learning. Our\nmain result is an algorithm that, given an $m \\times n$ matrix in a data\nstructure supporting certain $\\ell^2$-norm sampling operations, outputs an\n$\\ell^2$-norm sample from a rank-$k$ approximation of that matrix in time\n$O(\\text{poly}(k)\\log(mn))$, only polynomially slower than the quantum\nalgorithm. As a consequence, Kerenidis and Prakash's algorithm does not in fact\ngive an exponential speedup over classical algorithms. Further, under strong\ninput assumptions, the classical recommendation system resulting from our\nalgorithm produces recommendations exponentially faster than previous classical\nsystems, which run in time linear in $m$ and $n$.\n  The main insight of this work is the use of simple routines to manipulate\n$\\ell^2$-norm sampling distributions, which play the role of quantum\nsuperpositions in the classical setting. This correspondence indicates a\npotentially fruitful framework for formally comparing quantum machine learning\nalgorithms to classical machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 20:57:24 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 02:49:30 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 05:03:18 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Tang", "Ewin", ""]]}, {"id": "1807.04302", "submitter": "Steven Atkinson", "authors": "Steven Atkinson and Nicholas Zabaras", "title": "Structured Bayesian Gaussian process latent variable model: applications\n  to data-driven dimensionality reduction and high-dimensional inversion", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.12.037", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a methodology for nonlinear inverse problems using a variational\nBayesian approach where the unknown quantity is a spatial field. A structured\nBayesian Gaussian process latent variable model is used both to construct a\nlow-dimensional generative model of the sample-based stochastic prior as well\nas a surrogate for the forward evaluation. Its Bayesian formulation captures\nepistemic uncertainty introduced by the limited number of input and output\nexamples, automatically selects an appropriate dimensionality for the learned\nlatent representation of the data, and rigorously propagates the uncertainty of\nthe data-driven dimensionality reduction of the stochastic space through the\nforward model surrogate. The structured Gaussian process model explicitly\nleverages spatial information for an informative generative prior to improve\nsample efficiency while achieving computational tractability through Kronecker\nproduct decompositions of the relevant kernel matrices. Importantly, the\nBayesian inversion is carried out by solving a variational optimization\nproblem, replacing traditional computationally-expensive Monte Carlo sampling.\nThe methodology is demonstrated on an elliptic PDE and is shown to return\nwell-calibrated posteriors and is tractable with latent spaces with over 100\ndimensions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 18:03:50 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Atkinson", "Steven", ""], ["Zabaras", "Nicholas", ""]]}, {"id": "1807.04307", "submitter": "Bruno Lecouat", "authors": "Bruno Lecouat, Chuan-Sheng Foo, Houssam Zenati, Vijay Chandrasekhar", "title": "Manifold regularization with GANs for semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks are powerful generative models that are able\nto model the manifold of natural images. We leverage this property to perform\nmanifold regularization by approximating a variant of the Laplacian norm using\na Monte Carlo approximation that is easily computed with the GAN. When\nincorporated into the semi-supervised feature-matching GAN we achieve\nstate-of-the-art results for GAN-based semi-supervised learning on CIFAR-10 and\nSVHN benchmarks, with a method that is significantly easier to implement than\ncompeting methods. We also find that manifold regularization improves the\nquality of generated images, and is affected by the quality of the GAN used to\napproximate the regularizer.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 18:14:04 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Lecouat", "Bruno", ""], ["Foo", "Chuan-Sheng", ""], ["Zenati", "Houssam", ""], ["Chandrasekhar", "Vijay", ""]]}, {"id": "1807.04320", "submitter": "Louis Kim", "authors": "Rebecca L. Russell, Louis Kim, Lei H. Hamilton, Tomo Lazovich, Jacob\n  A. Harer, Onur Ozdemir, Paul M. Ellingwood, Marc W. McConley", "title": "Automated Vulnerability Detection in Source Code Using Deep\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing numbers of software vulnerabilities are discovered every year\nwhether they are reported publicly or discovered internally in proprietary\ncode. These vulnerabilities can pose serious risk of exploit and result in\nsystem compromise, information leaks, or denial of service. We leveraged the\nwealth of C and C++ open-source code available to develop a large-scale\nfunction-level vulnerability detection system using machine learning. To\nsupplement existing labeled vulnerability datasets, we compiled a vast dataset\nof millions of open-source functions and labeled it with carefully-selected\nfindings from three different static analyzers that indicate potential\nexploits. The labeled dataset is available at: https://osf.io/d45bw/. Using\nthese datasets, we developed a fast and scalable vulnerability detection tool\nbased on deep feature representation learning that directly interprets lexed\nsource code. We evaluated our tool on code from both real software packages and\nthe NIST SATE IV benchmark dataset. Our results demonstrate that deep feature\nrepresentation learning on source code is a promising approach for automated\nsoftware vulnerability detection.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 19:29:14 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 00:27:12 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Russell", "Rebecca L.", ""], ["Kim", "Louis", ""], ["Hamilton", "Lei H.", ""], ["Lazovich", "Tomo", ""], ["Harer", "Jacob A.", ""], ["Ozdemir", "Onur", ""], ["Ellingwood", "Paul M.", ""], ["McConley", "Marc W.", ""]]}, {"id": "1807.04369", "submitter": "Vasyl Pihur", "authors": "Vasyl Pihur, Aleksandra Korolova, Frederick Liu, Subhash\n  Sankuratripati, Moti Yung, Dachuan Huang, Ruogu Zeng", "title": "Differentially-Private \"Draw and Discard\" Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel framework for privacy-preserving\nclient-distributed machine learning. It is motivated by the desire to achieve\ndifferential privacy guarantees in the local model of privacy in a way that\nsatisfies all systems constraints using asynchronous client-server\ncommunication and provides attractive model learning properties. We call it\n\"Draw and Discard\" because it relies on random sampling of models for load\ndistribution (scalability), which also provides additional server-side privacy\nprotections and improved model quality through averaging. We present the\nmechanics of client and server components of \"Draw and Discard\" and demonstrate\nhow the framework can be applied to learning Generalized Linear models. We then\nanalyze the privacy guarantees provided by our approach against several types\nof adversaries and showcase experimental results that provide evidence for the\nframework's viability in practical deployments.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 22:28:50 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 20:16:53 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Pihur", "Vasyl", ""], ["Korolova", "Aleksandra", ""], ["Liu", "Frederick", ""], ["Sankuratripati", "Subhash", ""], ["Yung", "Moti", ""], ["Huang", "Dachuan", ""], ["Zeng", "Ruogu", ""]]}, {"id": "1807.04386", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, Keng-Pei Lin, I-Ling Cheng", "title": "Topic Diffusion Discovery based on Sparseness-constrained Non-negative\n  Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent explosion of text data, researchers have been overwhelmed by\never-increasing volume of articles produced by different research communities.\nVarious scholarly search websites, citation recommendation engines, and\nresearch databases have been created to simplify the text search tasks.\nHowever, it is still difficult for researchers to be able to identify potential\nresearch topics without doing intensive reviews on a tremendous number of\narticles published by journals, conferences, meetings, and workshops. In this\npaper, we consider a novel topic diffusion discovery technique that\nincorporates sparseness-constrained Non-negative Matrix Factorization with\ngeneralized Jensen-Shannon divergence to help understand term-topic evolutions\nand identify topic diffusions. Our experimental result shows that this approach\ncan extract more prominent topics from large article databases, visualize\nrelationships between terms of interest and abstract topics, and further help\nresearchers understand whether given terms/topics have been widely explored or\nwhether new topics are emerging from literature.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 00:31:43 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Kang", "Yihuang", ""], ["Lin", "Keng-Pei", ""], ["Cheng", "I-Ling", ""]]}, {"id": "1807.04415", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, Vladimir Zadorozhny", "title": "Process Discovery using Classification Tree Hidden Semi-Markov Model", "comments": "2016 IEEE International Conference on Information Reuse and\n  Integration", "journal-ref": null, "doi": "10.1109/IRI.2016.55", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various and ubiquitous information systems are being used in monitoring,\nexchanging, and collecting information. These systems are generating massive\namount of event sequence logs that may help us understand underlying\nphenomenon. By analyzing these logs, we can learn process models that describe\nsystem procedures, predict the development of the system, or check whether the\nchanges are expected. In this paper, we consider a novel technique that models\nthese sequences of events in temporal-probabilistic manners. Specifically, we\npropose a probabilistic process model that combines hidden semi-Markov model\nand classification trees learning. Our experimental result shows that the\nproposed approach can answer a kind of question-\"what are the most frequent\nsequence of system dynamics relevant to a given sequence of observable\nevents?\". For example, \"Given a series of medical treatments, what are the most\nrelevant patients' health condition pattern changes at different times?\"\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 04:08:44 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Kang", "Yihuang", ""], ["Zadorozhny", "Vladimir", ""]]}, {"id": "1807.04426", "submitter": "Mingao Yuan", "authors": "Mingao Yuan, Yang Feng and Zuofeng Shang", "title": "A likelihood-ratio type test for stochastic block models with bounded\n  degrees", "comments": "In this new submission, we add a comment in introduction stating that\n  > the classic test based on counting the $k_n$-cycles with >\n  $k_n=\\log^{1/4}{n}$ is unrealistic in practice, which is also the >\n  motivation of our regularized LR test", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in network data analysis is to test Erd\\\"{o}s-R\\'{e}nyi\nmodel $\\mathcal{G}\\left(n,\\frac{a+b}{2n}\\right)$ versus a bisection stochastic\nblock model $\\mathcal{G}\\left(n,\\frac{a}{n},\\frac{b}{n}\\right)$, where $a,b>0$\nare constants that represent the expected degrees of the graphs and $n$ denotes\nthe number of nodes. This problem serves as the foundation of many other\nproblems such as testing-based methods for determining the number of\ncommunities (\\cite{BS16,L16}) and community detection (\\cite{MS16}). Existing\nwork has been focusing on growing-degree regime $a,b\\to\\infty$\n(\\cite{BS16,L16,MS16,BM17,B18,GL17a,GL17b}) while leaving the bounded-degree\nregime untreated. In this paper, we propose a likelihood-ratio (LR) type\nprocedure based on regularization to test stochastic block models with bounded\ndegrees. We derive the limit distributions as power Poisson laws under both\nnull and alternative hypotheses, based on which the limit power of the test is\ncarefully analyzed. We also examine a Monte-Carlo method that partly resolves\nthe computational cost issue. The proposed procedures are examined by both\nsimulated and real-world data. The proof depends on a contiguity theory\ndeveloped by Janson \\cite{J95}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:05:09 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 02:21:09 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Yuan", "Mingao", ""], ["Feng", "Yang", ""], ["Shang", "Zuofeng", ""]]}, {"id": "1807.04427", "submitter": "John Dabiri", "authors": "Brooke E. Husic, Kristy L. Schlueter-Kuck, and John O. Dabiri", "title": "Simultaneous Coherent Structure Coloring facilitates interpretable\n  clustering of scientific data by amplifying dissimilarity", "comments": null, "journal-ref": "PLoS ONE 14(3): e0212442 (2019)", "doi": "10.1371/journal.pone.0212442", "report-no": null, "categories": "stat.ML cs.LG physics.bio-ph physics.flu-dyn q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering of data into physically meaningful subsets often requires\nassumptions regarding the number, size, or shape of the subgroups. Here, we\npresent a new method, simultaneous coherent structure coloring (sCSC), which\naccomplishes the task of unsupervised clustering without a priori guidance\nregarding the underlying structure of the data. sCSC performs a sequence of\nbinary splittings on the dataset such that the most dissimilar data points are\nrequired to be in separate clusters. To achieve this, we obtain a set of\northogonal coordinates along which dissimilarity in the dataset is maximized\nfrom a generalized eigenvalue problem based on the pairwise dissimilarity\nbetween the data points to be clustered. This sequence of bifurcations produces\na binary tree representation of the system, from which the number of clusters\nin the data and their interrelationships naturally emerge. To illustrate the\neffectiveness of the method in the absence of a priori assumptions, we apply it\nto three exemplary problems in fluid dynamics. Then, we illustrate its capacity\nfor interpretability using a high-dimensional protein folding simulation\ndataset. While we restrict our examples to dynamical physical systems in this\nwork, we anticipate straightforward translation to other fields where existing\nanalysis tools require ad hoc assumptions on the data structure, lack the\ninterpretability of the present method, or in which the underlying processes\nare less accessible, such as genomics and neuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:14:45 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 00:46:35 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 18:16:51 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Husic", "Brooke E.", ""], ["Schlueter-Kuck", "Kristy L.", ""], ["Dabiri", "John O.", ""]]}, {"id": "1807.04428", "submitter": "Nuri Denizcan Vanli", "authors": "Murat A. Erdogdu, Asuman Ozdaglar, Pablo A. Parrilo, Nuri Denizcan\n  Vanli", "title": "Convergence Rate of Block-Coordinate Maximization Burer-Monteiro Method\n  for Solving Large SDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programming (SDP) with diagonal constraints arise in many\noptimization problems, such as Max-Cut, community detection and group\nsynchronization. Although SDPs can be solved to arbitrary precision in\npolynomial time, generic convex solvers do not scale well with the dimension of\nthe problem. In order to address this issue, Burer and Monteiro proposed to\nreduce the dimension of the problem by appealing to a low-rank factorization\nand solve the subsequent non-convex problem instead. In this paper, we present\ncoordinate ascent based methods to solve this non-convex problem with provable\nconvergence guarantees. More specifically, we prove that the block-coordinate\nmaximization algorithm applied to the non-convex Burer-Monteiro method globally\nconverges to a first-order stationary point with a sublinear rate without any\nassumptions on the problem. We further show that this algorithm converges\nlinearly around a local maximum provided that the objective function exhibits\nquadratic decay. We establish that this condition generically holds when the\nrank of the factorization is sufficiently large. Furthermore, incorporating\nLanczos method to the block-coordinate maximization, we propose an algorithm\nthat is guaranteed to return a solution that provides $1-O(1/r)$ approximation\nto the original SDP without any assumptions, where $r$ is the rank of the\nfactorization. This approximation ratio is known to be optimal (up to\nconstants) under the unique games conjecture, and we can explicitly quantify\nthe number of iterations to obtain such a solution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:18:11 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 06:06:24 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Erdogdu", "Murat A.", ""], ["Ozdaglar", "Asuman", ""], ["Parrilo", "Pablo A.", ""], ["Vanli", "Nuri Denizcan", ""]]}, {"id": "1807.04439", "submitter": "Steven James", "authors": "Benjamin van Niekerk, Steven James, Adam Earle, Benjamin Rosman", "title": "Will it Blend? Composing Value Functions in Reinforcement Learning", "comments": "The 2nd Lifelong Learning: A Reinforcement Learning Approach (LLARLA)\n  Workshop, Stockholm, Sweden, FAIM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important property for lifelong-learning agents is the ability to combine\nexisting skills to solve unseen tasks. In general, however, it is unclear how\nto compose skills in a principled way. We provide a \"recipe\" for optimal value\nfunction composition in entropy-regularised reinforcement learning (RL) and\nthen extend this to the standard RL setting. Composition is demonstrated in a\nvideo game environment, where an agent with an existing library of policies is\nable to solve new tasks without the need for further learning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 06:43:12 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["van Niekerk", "Benjamin", ""], ["James", "Steven", ""], ["Earle", "Adam", ""], ["Rosman", "Benjamin", ""]]}, {"id": "1807.04457", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Thong Le, Pin-Yu Chen, Jinfeng Yi, Huan Zhang, Cho-Jui\n  Hsieh", "title": "Query-Efficient Hard-label Black-box Attack:An Optimization-based\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of attacking a machine learning model in the hard-label\nblack-box setting, where no model information is revealed except that the\nattacker can make queries to probe the corresponding hard-label decisions. This\nis a very challenging problem since the direct extension of state-of-the-art\nwhite-box attacks (e.g., CW or PGD) to the hard-label black-box setting will\nrequire minimizing a non-continuous step function, which is combinatorial and\ncannot be solved by a gradient-based optimizer. The only current approach is\nbased on random walk on the boundary, which requires lots of queries and lacks\nconvergence guarantees. We propose a novel way to formulate the hard-label\nblack-box attack as a real-valued optimization problem which is usually\ncontinuous and can be solved by any zeroth order optimization algorithm. For\nexample, using the Randomized Gradient-Free method, we are able to bound the\nnumber of iterations needed for our algorithm to achieve stationary points. We\ndemonstrate that our proposed method outperforms the previous random walk\napproach to attacking convolutional neural networks on MNIST, CIFAR, and\nImageNet datasets. More interestingly, we show that the proposed algorithm can\nalso be used to attack other discrete and non-continuous machine learning\nmodels, such as Gradient Boosting Decision Trees (GBDT).\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 08:04:27 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Cheng", "Minhao", ""], ["Le", "Thong", ""], ["Chen", "Pin-Yu", ""], ["Yi", "Jinfeng", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1807.04465", "submitter": "Cheng Kang Hsieh", "authors": "Miguel Campo, Cheng-Kang Hsieh, Matt Nickens, JJ Espinoza, Abhinav\n  Taliyan, Julie Rieger, Jean Ho, Bettina Sherick", "title": "Competitive Analysis System for Theatrical Movie Releases Based on Movie\n  Trailer Deep Video Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audience discovery is an important activity at major movie studios. Deep\nmodels that use convolutional networks to extract frame-by-frame features of a\nmovie trailer and represent it in a form that is suitable for prediction are\nnow possible thanks to the availability of pre-built feature extractors trained\non large image datasets. Using these pre-built feature extractors, we are able\nto process hundreds of publicly available movie trailers, extract\nframe-by-frame low level features (e.g., a face, an object, etc) and create\nvideo-level representations. We use the video-level representations to train a\nhybrid Collaborative Filtering model that combines video features with\nhistorical movie attendance records. The trained model not only makes accurate\nattendance and audience prediction for existing movies, but also successfully\nprofiles new movies six to eight months prior to their release.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 08:24:56 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Campo", "Miguel", ""], ["Hsieh", "Cheng-Kang", ""], ["Nickens", "Matt", ""], ["Espinoza", "JJ", ""], ["Taliyan", "Abhinav", ""], ["Rieger", "Julie", ""], ["Ho", "Jean", ""], ["Sherick", "Bettina", ""]]}, {"id": "1807.04489", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan and Didrik Nielsen", "title": "Fast yet Simple Natural-Gradient Descent for Variational Inference in\n  Complex Models", "comments": "Camera-ready version", "journal-ref": "International Symposium on Information Theory and Its Applications\n  (ISITA), 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference plays an important role in advancing machine learning, but\nfaces computational challenges when applied to complex models such as deep\nneural networks. Variational inference circumvents these challenges by\nformulating Bayesian inference as an optimization problem and solving it using\ngradient-based optimization. In this paper, we argue in favor of\nnatural-gradient approaches which, unlike their gradient-based counterparts,\ncan improve convergence by exploiting the information geometry of the\nsolutions. We show how to derive fast yet simple natural-gradient updates by\nusing a duality associated with exponential-family distributions. An attractive\nfeature of these methods is that, by using natural-gradients, they are able to\nextract accurate local approximations for individual model components. We\nsummarize recent results for Bayesian deep learning showing the superiority of\nnatural-gradient approaches over their gradient counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 09:15:46 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 07:59:27 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Nielsen", "Didrik", ""]]}, {"id": "1807.04511", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Bin Gu, Heng Huang", "title": "Training Neural Networks Using Features Replay", "comments": "NeurIPS 2018 Spotlight, Training deep learning faster, Convergence\n  guarantee for Pipeline-based methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network using backpropagation algorithm requires passing\nerror gradients sequentially through the network. The backward locking prevents\nus from updating network layers in parallel and fully leveraging the computing\nresources. Recently, there are several works trying to decouple and parallelize\nthe backpropagation algorithm. However, all of them suffer from severe accuracy\nloss or memory explosion when the neural network is deep. To address these\nchallenging issues, we propose a novel parallel-objective formulation for the\nobjective function of the neural network. After that, we introduce features\nreplay algorithm and prove that it is guaranteed to converge to critical points\nfor the non-convex problem under certain conditions. Finally, we apply our\nmethod to training deep convolutional neural networks, and the experimental\nresults show that the proposed method achieves {faster} convergence, {lower}\nmemory consumption, and {better} generalization error than compared methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 10:14:50 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 22:44:47 GMT"}, {"version": "v3", "created": "Sat, 8 Dec 2018 13:59:34 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 19:43:56 GMT"}, {"version": "v5", "created": "Wed, 29 May 2019 16:54:37 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "1807.04551", "submitter": "Marco Saerens Marco", "authors": "Bertrand Lebichot, Guillaume Guex, Ilkka Kivim\\\"aki and Marco Saerens", "title": "A Constrained Randomized Shortest-Paths Framework for Optimal\n  Exploration", "comments": "Draft manuscript submitted for publication and subject to changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work extends the randomized shortest-paths framework (RSP),\ninterpolating between shortest-path and random-walk routing in a network, in\nthree directions. First, it shows how to deal with equality constraints on a\nsubset of transition probabilities and develops a generic algorithm for solving\nthis constrained RSP problem using Lagrangian duality. Second, it derives a\nsurprisingly simple iterative procedure to compute the optimal, randomized,\nrouting policy generalizing the previously developed \"soft\" Bellman-Ford\nalgorithm. The resulting algorithm allows balancing exploitation and\nexploration in an optimal way by interpolating between a pure random behavior\nand the deterministic, optimal, policy (least-cost paths) while satisfying the\nconstraints. Finally, the two algorithms are applied to Markov decision\nproblems by considering the process as a constrained RSP on a bipartite\nstate-action graph. In this context, the derived \"soft\" value iteration\nalgorithm appears to be closely related to dynamic policy programming as well\nas Kullback-Leibler and path integral control, and similar to a recently\nintroduced reinforcement learning exploration strategy. This shows that this\nstrategy is optimal in the RSP sense - it minimizes expected path cost subject\nto relative entropy constraint. Simulation results on illustrative examples\nshow that the model behaves as expected.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 11:42:04 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Lebichot", "Bertrand", ""], ["Guex", "Guillaume", ""], ["Kivim\u00e4ki", "Ilkka", ""], ["Saerens", "Marco", ""]]}, {"id": "1807.04566", "submitter": "Elsa Dupraz", "authors": "Elsa Dupraz, Dominique Pastor, Fran\\c{c}ois-Xavier Socheleau", "title": "Decentralized Clustering on Compressed Data without Prior Knowledge of\n  the Number of Clusters", "comments": "Submitted to IEEE Transactions on Signal and Information Processing\n  over Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sensor networks, it is not always practical to set up a fusion center.\nTherefore, there is need for fully decentralized clustering algorithms.\nDecentralized clustering algorithms should minimize the amount of data\nexchanged between sensors in order to reduce sensor energy consumption. In this\nrespect, we propose one centralized and one decentralized clustering algorithm\nthat work on compressed data without prior knowledge of the number of clusters.\nIn the standard K-means clustering algorithm, the number of clusters is\nestimated by repeating the algorithm several times, which dramatically\nincreases the amount of exchanged data, while our algorithm can estimate this\nnumber in one run.\n  The proposed clustering algorithms derive from a theoretical framework\nestablishing that, under asymptotic conditions, the cluster centroids are the\nonly fixed-point of a cost function we introduce. This cost function depends on\na weight function which we choose as the p-value of a Wald hypothesis test.\nThis p-value measures the plausibility that a given measurement vector belongs\nto a given cluster. Experimental results show that our two algorithms are\ncompetitive in terms of clustering performance with respect to K-means and\nDB-Scan, while lowering by a factor at least $2$ the amount of data exchanged\nbetween sensors.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 12:20:05 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Dupraz", "Elsa", ""], ["Pastor", "Dominique", ""], ["Socheleau", "Fran\u00e7ois-Xavier", ""]]}, {"id": "1807.04585", "submitter": "Tjeng Wawan Cenggoro Mr.", "authors": "Fanny, Tjeng Wawan Cenggoro", "title": "Deep Learning for Imbalance Data Classification using Class Expert\n  Generative Adversarial Network", "comments": "Accepted in 3rd International Conference on Computer Science and\n  Computational Intelligence, 7-8 September 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without any specific way for imbalance data classification, artificial\nintelligence algorithm cannot recognize data from minority classes easily. In\ngeneral, modifying the existing algorithm by assuming that the training data is\nimbalanced, is the only way to handle imbalance data. However, for a normal\ndata handling, this way mostly produces a deficient result. In this research,\nwe propose a class expert generative adversarial network (CE-GAN) as the\nsolution for imbalance data classification. CE-GAN is a modification in deep\nlearning algorithm architecture that does not have an assumption that the\ntraining data is imbalance data. Moreover, CE-GAN is designed to identify more\ndetail about the character of each class before classification step. CE-GAN has\nbeen proved in this research to give a good performance for imbalance data\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 12:51:24 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 03:11:44 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Fanny", "", ""], ["Cenggoro", "Tjeng Wawan", ""]]}, {"id": "1807.04587", "submitter": "Sergey Bartunov", "authors": "Sergey Bartunov, Adam Santoro, Blake A. Richards, Luke Marris,\n  Geoffrey E. Hinton, Timothy Lillicrap", "title": "Assessing the Scalability of Biologically-Motivated Deep Learning\n  Algorithms and Architectures", "comments": "NIPS 2018. Version 2 contains more experimental data including best\n  hyperparameters found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation of error algorithm (BP) is impossible to implement in a\nreal brain. The recent success of deep networks in machine learning and AI,\nhowever, has inspired proposals for understanding how the brain might learn\nacross multiple layers, and hence how it might approximate BP. As of yet, none\nof these proposals have been rigorously evaluated on tasks where BP-guided deep\nlearning has proved critical, or in architectures more structured than simple\nfully-connected networks. Here we present results on scaling up biologically\nmotivated models of deep learning on datasets which need deep networks with\nappropriate architectures to achieve good performance. We present results on\nthe MNIST, CIFAR-10, and ImageNet datasets and explore variants of\ntarget-propagation (TP) and feedback alignment (FA) algorithms, and explore\nperformance in both fully- and locally-connected architectures. We also\nintroduce weight-transport-free variants of difference target propagation (DTP)\nmodified to remove backpropagation from the penultimate layer. Many of these\nalgorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP\nand FA variants perform significantly worse than BP, especially for networks\ncomposed of locally connected units, opening questions about whether new\narchitectures and algorithms are required to scale these approaches. Our\nresults and implementation details help establish baselines for biologically\nmotivated deep learning schemes going forward.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 12:53:50 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 14:26:44 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Bartunov", "Sergey", ""], ["Santoro", "Adam", ""], ["Richards", "Blake A.", ""], ["Marris", "Luke", ""], ["Hinton", "Geoffrey E.", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1807.04595", "submitter": "Flavio Figueiredo", "authors": "Flavio Figueiredo, Guilherme Borges, Pedro O. S. Vaz de Melo, Renato\n  M. Assun\\c{c}\\~ao", "title": "Fast Estimation of Causal Interactions using Wold Processes", "comments": "32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We here focus on the task of learning Granger causality matrices for\nmultivariate point processes. In order to accomplish this task, our work is the\nfirst to explore the use of Wold processes. By doing so, we are able to develop\nasymptotically fast MCMC learning algorithms. With $N$ being the total number\nof events and $K$ the number of processes, our learning algorithm has a\n$O(N(\\,\\log(N)\\,+\\,\\log(K)))$ cost per iteration. This is much faster than the\n$O(N^3\\,K^2)$ or $O(K^3)$ for the state of the art. Our approach, called\nGrangerBusca, is validated on nine datasets. This is an advance in relation to\nmost prior efforts which focus mostly on subsets of the Memetracker data.\nRegarding accuracy, GrangerBusca is three times more accurate (in Precision@10)\nthan the state of the art for the commonly explored subsets Memetracker. Due to\nGrangerBusca's much lower training complexity, our approach is the only one\nable to train models for larger, full, sets of data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 13:26:57 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 10:03:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Figueiredo", "Flavio", ""], ["Borges", "Guilherme", ""], ["de Melo", "Pedro O. S. Vaz", ""], ["Assun\u00e7\u00e3o", "Renato M.", ""]]}, {"id": "1807.04602", "submitter": "Vincent Margot", "authors": "Vincent Margot, Jean-Patrick Baudry, Frederic Guilloux, Olivier\n  Wintenberger", "title": "Rule Induction Partitioning Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RIPE is a novel deterministic and easily understandable prediction algorithm\ndeveloped for continuous and discrete ordered data. It infers a model, from a\nsample, to predict and to explain a real variable $Y$ given an input variable\n$X \\in \\mathcal X$ (features). The algorithm extracts a sparse set of\nhyperrectangles $\\mathbf r \\subset \\mathcal X$, which can be thought of as\nrules of the form If-Then. This set is then turned into a partition of the\nfeatures space $\\mathcal X$ of which each cell is explained as a list of rules\nwith satisfied their If conditions. The process of RIPE is illustrated on\nsimulated datasets and its efficiency compared with that of other usual\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 13:38:05 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Margot", "Vincent", ""], ["Baudry", "Jean-Patrick", ""], ["Guilloux", "Frederic", ""], ["Wintenberger", "Olivier", ""]]}, {"id": "1807.04629", "submitter": "Hanwei Wu", "authors": "Hanwei Wu and Markus Flierl", "title": "Learning Product Codebooks using Vector Quantized Autoencoders for Image\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector-Quantized Variational Autoencoders (VQ-VAE)[1] provide an unsupervised\nmodel for learning discrete representations by combining vector quantization\nand autoencoders. In this paper, we study the use of VQ-VAE for representation\nlearning for downstream tasks, such as image retrieval. We first describe the\nVQ-VAE in the context of an information-theoretic framework. We show that the\nregularization term on the learned representation is determined by the size of\nthe embedded codebook before the training and it affects the generalization\nability of the model. As a result, we introduce a hyperparameter to balance the\nstrength of the vector quantizer and the reconstruction error. By tuning the\nhyperparameter, the embedded bottleneck quantizer is used as a regularizer that\nforces the output of the encoder to share a constrained coding space such that\nlearned latent features preserve the similarity relations of the data space. In\naddition, we provide a search range for finding the best hyperparameter.\nFinally, we incorporate the product quantization into the bottleneck stage of\nVQ-VAE and propose an end-to-end unsupervised learning model for the image\nretrieval task. The product quantizer has the advantage of generating\nlarge-size codebooks. Fast retrieval can be achieved by using the lookup tables\nthat store the distance between any pair of sub-codewords. State-of-the-art\nretrieval results are achieved by the learned codebooks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:08:31 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 15:42:37 GMT"}, {"version": "v3", "created": "Sun, 11 Nov 2018 18:35:35 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 11:50:21 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Wu", "Hanwei", ""], ["Flierl", "Markus", ""]]}, {"id": "1807.04639", "submitter": "Harris Georgiou", "authors": "Harris Georgiou, Sophia Karagiorgou, Yannis Kontoulis, Nikos Pelekis,\n  Petros Petrou, David Scarlatti, Yannis Theodoridis", "title": "Moving Objects Analytics: Survey on Future Location & Trajectory\n  Prediction Methods", "comments": "45 pages, 11 figures, 2 tables, 127 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous growth of positioning technologies and GPS enabled devices has\nproduced huge volumes of tracking data during the recent years. This source of\ninformation constitutes a rich input for data analytics processes, either\noffline (e.g. cluster analysis, hot motion discovery) or online (e.g.\nshort-term forecasting of forthcoming positions). This paper focuses on\npredictive analytics for moving objects (could be pedestrians, cars, vessels,\nplanes, animals, etc.) and surveys the state-of-the-art in the context of\nfuture location and trajectory prediction. We provide an extensive review of\nover 50 works, also proposing a novel taxonomy of predictive algorithms over\nmoving objects. We also list the properties of several real datasets used in\nthe past for validation purposes of those works and, motivated by this, we\ndiscuss challenges that arise in the transition from conventional to Big Data\napplications.\n  CCS Concepts: Information systems > Spatial-temporal systems; Information\nsystems > Data analytics; Information systems > Data mining; Computing\nmethodologies > Machine learning Additional Key Words and Phrases: mobility\ndata, moving object trajectories, trajectory prediction, future location\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 08:01:38 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Georgiou", "Harris", ""], ["Karagiorgou", "Sophia", ""], ["Kontoulis", "Yannis", ""], ["Pelekis", "Nikos", ""], ["Petrou", "Petros", ""], ["Scarlatti", "David", ""], ["Theodoridis", "Yannis", ""]]}, {"id": "1807.04640", "submitter": "Michael Chang", "authors": "Michael B. Chang, Abhishek Gupta, Sergey Levine, Thomas L. Griffiths", "title": "Automatically Composing Representation Transformations as a Means for\n  Generalization", "comments": "Accepted to the International Conference on Learning Representations\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generally intelligent learner should generalize to more complex tasks than\nit has previously encountered, but the two common paradigms in machine learning\n-- either training a separate learner per task or training a single learner for\nall tasks -- both have difficulty with such generalization because they do not\nleverage the compositional structure of the task distribution. This paper\nintroduces the compositional problem graph as a broadly applicable formalism to\nrelate tasks of different complexity in terms of problems with shared\nsubproblems. We propose the compositional generalization problem for measuring\nhow readily old knowledge can be reused and hence built upon. As a first step\nfor tackling compositional generalization, we introduce the compositional\nrecursive learner, a domain-general framework for learning algorithmic\nprocedures for composing representation transformations, producing a learner\nthat reasons about what computation to execute by making analogies to\npreviously seen problems. We show on a symbolic and a high-dimensional domain\nthat our compositional approach can generalize to more complex problems than\nthe learner has previously encountered, whereas baselines that are not\nexplicitly compositional do not.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 14:33:49 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 06:41:28 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Chang", "Michael B.", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1807.04644", "submitter": "Michael Veale", "authors": "Michael Veale, Reuben Binns and Lilian Edwards", "title": "Algorithms that Remember: Model Inversion Attacks and Data Protection\n  Law", "comments": "15 pages, 1 figure", "journal-ref": "Philosophical Transactions of the Royal Society A 376 (2018)", "doi": "10.1098/rsta.2018.0083", "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many individuals are concerned about the governance of machine learning\nsystems and the prevention of algorithmic harms. The EU's recent General Data\nProtection Regulation (GDPR) has been seen as a core tool for achieving better\ngovernance of this area. While the GDPR does apply to the use of models in some\nlimited situations, most of its provisions relate to the governance of personal\ndata, while models have traditionally been seen as intellectual property. We\npresent recent work from the information security literature around `model\ninversion' and `membership inference' attacks, which indicate that the process\nof turning training data into machine learned systems is not one-way, and\ndemonstrate how this could lead some models to be legally classified as\npersonal data. Taking this as a probing experiment, we explore the different\nrights and obligations this would trigger and their utility, and posit future\ndirections for algorithmic governance and regulation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 14:38:48 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 19:07:51 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Veale", "Michael", ""], ["Binns", "Reuben", ""], ["Edwards", "Lilian", ""]]}, {"id": "1807.04662", "submitter": "Jacob Montiel", "authors": "Jacob Montiel, Jesse Read, Albert Bifet, Talel Abdessalem", "title": "Scikit-Multiflow: A Multi-output Streaming Framework", "comments": "5 pages, Open Source Software", "journal-ref": "Journal of Machine Learning Research, 2019, vol. 1, p. 2915-2914", "doi": "10.5555/3291125.3309634", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scikit-multiflow is a multi-output/multi-label and stream data mining\nframework for the Python programming language. Conceived to serve as a platform\nto encourage democratization of stream learning research, it provides multiple\nstate of the art methods for stream learning, stream generators and evaluators.\nscikit-multiflow builds upon popular open source frameworks including\nscikit-learn, MOA and MEKA. Development follows the FOSS principles and quality\nis enforced by complying with PEP8 guidelines and using continuous integration\nand automatic testing. The source code is publicly available at\nhttps://github.com/scikit-multiflow/scikit-multiflow.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:03:13 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Montiel", "Jacob", ""], ["Read", "Jesse", ""], ["Bifet", "Albert", ""], ["Abdessalem", "Talel", ""]]}, {"id": "1807.04667", "submitter": "Ryan McConville", "authors": "Ryan McConville, Gareth Archer, Ian Craddock, Herman ter Horst, Robert\n  Piechocki, James Pope, Raul Santos-Rodriguez", "title": "Online Heart Rate Prediction using Acceleration from a Wrist Worn\n  Wearable", "comments": "MLMH 2018: 2018 KDD Workshop on Machine Learning for Medicine and\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the prediction of heart rate from acceleration using a\nwrist worn wearable. Although existing photoplethysmography (PPG) heart rate\nsensors provide reliable measurements, they use considerably more energy than\naccelerometers and have a major impact on battery life of wearable devices. By\nusing energy-efficient accelerometers to predict heart rate, significant energy\nsavings can be made. Further, we are interested in understanding patient\nrecovery after a heart rate intervention, where we expect a variation in heart\nrate over time. Therefore, we propose an online approach to tackle the concept\nas time passes. We evaluate the methods on approximately 4 weeks of free living\ndata from three patients over a number of months. We show that our approach can\nachieve good predictive performance (e.g., 2.89 Mean Absolute Error) while\nusing the PPG heart rate sensor infrequently (e.g., 20.25% of the samples).\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 17:08:52 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["McConville", "Ryan", ""], ["Archer", "Gareth", ""], ["Craddock", "Ian", ""], ["ter Horst", "Herman", ""], ["Piechocki", "Robert", ""], ["Pope", "James", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "1807.04676", "submitter": "Jeevan Manavalan", "authors": "Yuchen Zhao, Jeevan Manavalan, Prabhakar Ray, Hsiu-Chin Lin and\n  Matthew Howard", "title": "A Library for Constraint Consistent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces the first, open source software library for Constraint\nConsistent Learning (CCL). It implements a family of data-driven methods that\nare capable of (i) learning state-independent and -dependent constraints, (ii)\ndecomposing the behaviour of redundant systems into task- and null-space parts,\nand (iii) uncovering the underlying null space control policy. It is a tool to\nanalyse and decompose many everyday tasks, such as wiping, reaching and\ndrawing. The library also includes several tutorials that demonstrate its use\nwith both simulated and real world data in a systematic way. This paper\ndocuments the implementation of the library, tutorials and associated helper\nmethods. The software is made freely available to the community, to enable code\nreuse and allow users to gain in-depth experience in statistical learning in\nthis area.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:33:25 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 14:39:37 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhao", "Yuchen", ""], ["Manavalan", "Jeevan", ""], ["Ray", "Prabhakar", ""], ["Lin", "Hsiu-Chin", ""], ["Howard", "Matthew", ""]]}, {"id": "1807.04680", "submitter": "Yuan Zhang", "authors": "Yuan Zhang", "title": "Unseeded low-rank graph matching by transform-based unsupervised point\n  registration", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning a correspondence relationship between nodes of two\nnetworks has drawn much attention of the computer science community and\nrecently that of statisticians. The unseeded version of this problem, in which\nwe do not know any part of the true correspondence, is a long-standing\nchallenge. For low-rank networks, the problem can be translated into an\nunsupervised point registration problem, in which two point sets generated from\nthe same distribution are matchable by an unknown orthonormal transformation.\nConventional methods generally lack consistency guarantee and are usually\ncomputationally costly.\n  In this paper, we propose a novel approach to this problem. Instead of\nsimultaneously estimating the unknown correspondence and orthonormal\ntransformation to match up the two point sets, we match their distributions via\nminimizing our designed loss function capturing the discrepancy between their\nLaplace transforms, thus avoiding the optimization over all possible\ncorrespondences. This dramatically reduces the dimension of the optimization\nproblem from $\\Omega(n^2)$ parameters to $O(d^2)$ parameters, where $d$ is the\nfixed rank, and enables convenient theoretical analysis. In this paper, we\nprovide arguably the first consistency guarantee and explicit error rate for\ngeneral low-rank models. Our method provides control over the computational\ncomplexity ranging from $\\omega(n)$ (any growth rate faster than $n$) to\n$O(n^2)$ while pertaining consistency. We demonstrate the effectiveness of our\nmethod through several numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:37:32 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhang", "Yuan", ""]]}, {"id": "1807.04687", "submitter": "Linara Adilova", "authors": "Linara Adilova, Sven Giesselbach, Stefan R\\\"uping", "title": "Making Efficient Use of a Domain Expert's Time in Relation Extraction", "comments": "DMNLP Workshop paper, ECML-PKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of labeled data is one of the most frequent problems faced in\nmachine learning. This is particularly true in relation extraction in text\nmining, where large corpora of texts exists in many application domains, while\nlabeling of text data requires an expert to invest much time to read the\ndocuments. Overall, state-of-the art models, like the convolutional neural\nnetwork used in this paper, achieve great results when trained on large enough\namounts of labeled data. However, from a practical point of view the question\narises whether this is the most efficient approach when one takes the manual\neffort of the expert into account. In this paper, we report on an alternative\napproach where we first construct a relation extraction model using distant\nsupervision, and only later make use of a domain expert to refine the results.\nDistant supervision provides a mean of labeling data given known relations in a\nknowledge base, but it suffers from noisy labeling. We introduce an active\nlearning based extension, that allows our neural network to incorporate expert\nfeedback and report on first results on a complex data set.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:53:29 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Adilova", "Linara", ""], ["Giesselbach", "Sven", ""], ["R\u00fcping", "Stefan", ""]]}, {"id": "1807.04689", "submitter": "Tim Davidson", "authors": "Luca Falorsi, Pim de Haan, Tim R. Davidson, Nicola De Cao, Maurice\n  Weiler, Patrick Forr\\'e, Taco S. Cohen", "title": "Explorations in Homeomorphic Variational Auto-Encoding", "comments": "16 pages, 8 figures, ICML workshop on Theoretical Foundations and\n  Applications of Deep Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manifold hypothesis states that many kinds of high-dimensional data are\nconcentrated near a low-dimensional manifold. If the topology of this data\nmanifold is non-trivial, a continuous encoder network cannot embed it in a\none-to-one manner without creating holes of low density in the latent space.\nThis is at odds with the Gaussian prior assumption typically made in\nVariational Auto-Encoders (VAEs), because the density of a Gaussian\nconcentrates near a blob-like manifold.\n  In this paper we investigate the use of manifold-valued latent variables.\nSpecifically, we focus on the important case of continuously differentiable\nsymmetry groups (Lie groups), such as the group of 3D rotations\n$\\operatorname{SO}(3)$. We show how a VAE with $\\operatorname{SO}(3)$-valued\nlatent variables can be constructed, by extending the reparameterization trick\nto compact connected Lie groups. Our experiments show that choosing\nmanifold-valued latent variables that match the topology of the latent data\nmanifold, is crucial to preserve the topological structure and learn a\nwell-behaved latent space.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:55:55 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Falorsi", "Luca", ""], ["de Haan", "Pim", ""], ["Davidson", "Tim R.", ""], ["De Cao", "Nicola", ""], ["Weiler", "Maurice", ""], ["Forr\u00e9", "Patrick", ""], ["Cohen", "Taco S.", ""]]}, {"id": "1807.04709", "submitter": "Emma Pierson", "authors": "Emma Pierson, Pang Wei Koh, Tatsunori Hashimoto, Daphne Koller, Jure\n  Leskovec, Nicholas Eriksson, Percy Liang", "title": "Inferring Multidimensional Rates of Aging from Cross-Sectional Data", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling how individuals evolve over time is a fundamental problem in the\nnatural and social sciences. However, existing datasets are often\ncross-sectional with each individual observed only once, making it impossible\nto apply traditional time-series methods. Motivated by the study of human\naging, we present an interpretable latent-variable model that learns temporal\ndynamics from cross-sectional data. Our model represents each individual's\nfeatures over time as a nonlinear function of a low-dimensional,\nlinearly-evolving latent state. We prove that when this nonlinear function is\nconstrained to be order-isomorphic, the model family is identifiable solely\nfrom cross-sectional data provided the distribution of time-independent\nvariation is known. On the UK Biobank human health dataset, our model\nreconstructs the observed data while learning interpretable rates of aging\nassociated with diseases, mortality, and aging risk factors.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:27:40 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 21:38:56 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 18:22:09 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Pierson", "Emma", ""], ["Koh", "Pang Wei", ""], ["Hashimoto", "Tatsunori", ""], ["Koller", "Daphne", ""], ["Leskovec", "Jure", ""], ["Eriksson", "Nicholas", ""], ["Liang", "Percy", ""]]}, {"id": "1807.04715", "submitter": "Konstantinos Skianis", "authors": "Konstantinos Skianis, Nikolaos Tziortziotis, Michalis Vazirgiannis", "title": "Orthogonal Matching Pursuit for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text classification, the problem of overfitting arises due to the high\ndimensionality, making regularization essential. Although classic regularizers\nprovide sparsity, they fail to return highly accurate models. On the contrary,\nstate-of-the-art group-lasso regularizers provide better results at the expense\nof low sparsity. In this paper, we apply a greedy variable selection algorithm,\ncalled Orthogonal Matching Pursuit, for the text classification task. We also\nextend standard group OMP by introducing overlapping Group OMP to handle\noverlapping groups of features. Empirical analysis verifies that both OMP and\noverlapping GOMP constitute powerful regularizers, able to produce effective\nand very sparse models. Code and data are available online:\nhttps://github.com/y3nk0/OMP-for-Text-Classification .\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:43:32 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 11:54:10 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Skianis", "Konstantinos", ""], ["Tziortziotis", "Nikolaos", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1807.04720", "submitter": "Mario Lucic", "authors": "Karol Kurach, Mario Lucic, Xiaohua Zhai, Marcin Michalski, Sylvain\n  Gelly", "title": "A Large-Scale Study on Regularization and Normalization in GANs", "comments": "Revision accepted to ICML'19: More focus on regularization and\n  normalization aspects. Added recent references and promising future\n  directions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a class of deep generative models\nwhich aim to learn a target distribution in an unsupervised fashion. While they\nwere successfully applied to many problems, training a GAN is a notoriously\nchallenging task and requires a significant number of hyperparameter tuning,\nneural architecture engineering, and a non-trivial amount of \"tricks\". The\nsuccess in many practical applications coupled with the lack of a measure to\nquantify the failure modes of GANs resulted in a plethora of proposed losses,\nregularization and normalization schemes, as well as neural architectures. In\nthis work we take a sober view of the current state of GANs from a practical\nperspective. We discuss and evaluate common pitfalls and reproducibility\nissues, open-source our code on Github, and provide pre-trained models on\nTensorFlow Hub.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:56:50 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 13:05:09 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 13:41:42 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Kurach", "Karol", ""], ["Lucic", "Mario", ""], ["Zhai", "Xiaohua", ""], ["Michalski", "Marcin", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1807.04723", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Chinnadhurai Sankar, Michael Pieper, Joelle\n  Pineau, Yoshua Bengio", "title": "The Bottleneck Simulator: A Model-based Deep Reinforcement Learning\n  Approach", "comments": "26 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently shown many impressive successes.\nHowever, one major obstacle towards applying such methods to real-world\nproblems is their lack of data-efficiency. To this end, we propose the\nBottleneck Simulator: a model-based reinforcement learning method which\ncombines a learned, factorized transition model of the environment with rollout\nsimulations to learn an effective policy from few examples. The learned\ntransition model employs an abstract, discrete (bottleneck) state, which\nincreases sample efficiency by reducing the number of model parameters and by\nexploiting structural properties of the environment. We provide a mathematical\nanalysis of the Bottleneck Simulator in terms of fixed points of the learned\npolicy, which reveals how performance is affected by four distinct sources of\nerror: an error related to the abstract space structure, an error related to\nthe transition model estimation variance, an error related to the transition\nmodel estimation bias, and an error related to the transition model class bias.\nFinally, we evaluate the Bottleneck Simulator on two natural language\nprocessing tasks: a text adventure game and a real-world, complex dialogue\nresponse selection task. On both tasks, the Bottleneck Simulator yields\nexcellent performance beating competing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:59:28 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Sankar", "Chinnadhurai", ""], ["Pieper", "Michael", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1807.04734", "submitter": "Bahareh Tolooshams", "authors": "Bahareh Tolooshams, Sourav Dey, and Demba Ba", "title": "Scalable Convolutional Dictionary Learning with Constrained Recurrent\n  Sparse Auto-encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a convolutional dictionary underlying a set of observed signals, can a\ncarefully designed auto-encoder recover the dictionary in the presence of\nnoise? We introduce an auto-encoder architecture, termed constrained recurrent\nsparse auto-encoder (CRsAE), that answers this question in the affirmative.\nGiven an input signal and an approximate dictionary, the encoder finds a sparse\napproximation using FISTA. The decoder reconstructs the signal by applying the\ndictionary to the output of the encoder. The encoder and decoder in CRsAE\nparallel the sparse-coding and dictionary update steps in optimization-based\nalternating-minimization schemes for dictionary learning. As such, the\nparameters of the encoder and decoder are not independent, a constraint which\nwe enforce for the first time. We derive the back-propagation algorithm for\nCRsAE. CRsAE is a framework for blind source separation that, only knowing the\nnumber of sources (dictionary elements), and assuming sparsely-many can\noverlap, is able to separate them. We demonstrate its utility in the context of\nspike sorting, a source separation problem in computational neuroscience. We\ndemonstrate the ability of CRsAE to recover the underlying dictionary and\ncharacterize its sensitivity as a function of SNR.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:18:37 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Dey", "Sourav", ""], ["Ba", "Demba", ""]]}, {"id": "1807.04739", "submitter": "Majd Latah", "authors": "Majd Latah", "title": "When deep learning meets security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning is an emerging research field that has proven its effectiveness\ntowards deploying more efficient intelligent systems. Security, on the other\nhand, is one of the most essential issues in modern communication systems.\nRecently many papers have shown that using deep learning models can achieve\npromising results when applied to the security domain. In this work, we provide\nan overview for the recent studies that apply deep learning techniques to the\nfield of security.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:44:42 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Latah", "Majd", ""]]}, {"id": "1807.04740", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, Reyhane Askari Hemmat, Mohammad Pezeshki, Remi\n  Lepriol, Gabriel Huang, Simon Lacoste-Julien, Ioannis Mitliagkas", "title": "Negative Momentum for Improved Game Dynamics", "comments": "Appears in: Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2019). Minor changes with\n  respect to the AISTATS version: typo corrected in Thm. 6 (squared condition\n  number instead of condition number; and small change in constant) and\n  dependence in $\\beta$ changed in Theorem 5 for the formal statement; not\n  changing the conclusions. 28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Games generalize the single-objective optimization paradigm by introducing\ndifferent objective functions for different players. Differentiable games often\nproceed by simultaneous or alternating gradient updates. In machine learning,\ngames are gaining new importance through formulations like generative\nadversarial networks (GANs) and actor-critic systems. However, compared to\nsingle-objective optimization, game dynamics are more complex and less\nunderstood. In this paper, we analyze gradient-based methods with momentum on\nsimple games. We prove that alternating updates are more stable than\nsimultaneous updates. Next, we show both theoretically and empirically that\nalternating gradient updates with a negative momentum term achieves convergence\nin a difficult toy adversarial problem, but also on the notoriously difficult\nto train saturating GANs.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:46:56 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 23:55:04 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 16:32:10 GMT"}, {"version": "v4", "created": "Tue, 13 Aug 2019 15:18:56 GMT"}, {"version": "v5", "created": "Fri, 28 Aug 2020 21:15:09 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gidel", "Gauthier", ""], ["Hemmat", "Reyhane Askari", ""], ["Pezeshki", "Mohammad", ""], ["Lepriol", "Remi", ""], ["Huang", "Gabriel", ""], ["Lacoste-Julien", "Simon", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "1807.04742", "submitter": "Ashvin Nair", "authors": "Ashvin Nair, Vitchyr Pong, Murtaza Dalal, Shikhar Bahl, Steven Lin,\n  Sergey Levine", "title": "Visual Reinforcement Learning with Imagined Goals", "comments": "15 pages, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an autonomous agent to fulfill a wide range of user-specified goals at\ntest time, it must be able to learn broadly applicable and general-purpose\nskill repertoires. Furthermore, to provide the requisite level of generality,\nthese skills must handle raw sensory input such as images. In this paper, we\npropose an algorithm that acquires such general-purpose skills by combining\nunsupervised representation learning and reinforcement learning of\ngoal-conditioned policies. Since the particular goals that might be required at\ntest-time are not known in advance, the agent performs a self-supervised\n\"practice\" phase where it imagines goals and attempts to achieve them. We learn\na visual representation with three distinct purposes: sampling goals for\nself-supervised practice, providing a structured transformation of raw sensory\ninputs, and computing a reward signal for goal reaching. We also propose a\nretroactive goal relabeling scheme to further improve the sample-efficiency of\nour method. Our off-policy algorithm is efficient enough to learn policies that\noperate on raw image observations and goals for a real-world robotic system,\nand substantially outperforms prior techniques.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:51:16 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 08:44:08 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Nair", "Ashvin", ""], ["Pong", "Vitchyr", ""], ["Dalal", "Murtaza", ""], ["Bahl", "Shikhar", ""], ["Lin", "Steven", ""], ["Levine", "Sergey", ""]]}, {"id": "1807.04778", "submitter": "Erik Partridge", "authors": "Erik Partridge, Jack Sklar, Omar El-lakany", "title": "Improving on Q & A Recurrent Neural Networks Using Noun-Tagging", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, more time is spent on finding a model that works well, rather than\ntuning the model and working directly with the dataset. Our research began as\nan attempt to improve upon a simple Recurrent Neural Network for answering\n\"simple\" first-order questions (QA-RNN), developed by Ferhan Ture and Oliver\nJojic, from Comcast Labs, using the SimpleQuestions dataset. Their baseline\nmodel, a bidirectional, 2-layer LSTM RNN and a GRU RNN, have accuracies of 0.94\nand 0.90, for entity detection and relation prediction, respectively. We fine\ntuned these models by doing substantial hyper-parameter tuning, getting\nresulting accuracies of 0.70 and 0.80, for entity detection and relation\nprediction, respectively. An accuracy of 0.984 was obtained on entity detection\nusing a 1-layer LSTM, where preprocessing was done by removing all words not\npart of a noun chunk from the question. 100% of the dataset was available for\nrelation prediction, but only 20% of the dataset, was available for entity\ndetection, which we believe to be much of the reason for our initial\ndifficulties in replicating their result, despite the fact we were able to\nimprove on their entity detection results.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 18:27:42 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Partridge", "Erik", ""], ["Sklar", "Jack", ""], ["El-lakany", "Omar", ""]]}, {"id": "1807.04800", "submitter": "Adil \\c{C}oban", "authors": "Adil \\c{C}oban and Ilhan Tar{\\i}mer", "title": "Feature Selection for Gender Classification in TUIK Life Satisfaction\n  Survey", "comments": "6 pages, 7 figures, submitted to ICATCES 2018 (http://icatces.org/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As known, attribute selection is a method that is used before the\nclassification of data mining. In this study, a new data set has been created\nby using attributes expressing overall satisfaction in Turkey Statistical\nInstitute (TSI) Life Satisfaction Survey dataset. Attributes are sorted by\nRanking search method using attribute selection algorithms in a data mining\napplication. These selected attributes were subjected to a classification test\nwith Naive Bayes and Random Forest from machine learning algorithms. The\nfeature selection algorithms are compared according to the number of attributes\nselected and the classification accuracy rates achievable with them. In this\nstudy, which is aimed at reducing the dataset volume, the best classification\nresult comes up with 3 attributes selected by the Chi2 algorithm. The best\nclassification rate was 73% with the Random Forest classification algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 19:38:21 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["\u00c7oban", "Adil", ""], ["Tar\u0131mer", "Ilhan", ""]]}, {"id": "1807.04801", "submitter": "David Lowell", "authors": "David Lowell, Zachary C. Lipton, Byron C. Wallace", "title": "Practical Obstacles to Deploying Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) is a widely-used training strategy for maximizing\npredictive performance subject to a fixed annotation budget. In AL one\niteratively selects training examples for annotation, often those for which the\ncurrent model is most uncertain (by some measure). The hope is that active\nsampling leads to better performance than would be achieved under independent\nand identically distributed (i.i.d.) random samples. While AL has shown promise\nin retrospective evaluations, these studies often ignore practical obstacles to\nits use. In this paper we show that while AL may provide benefits when used\nwith specific models and for particular domains, the benefits of current\napproaches do not generalize reliably across models and tasks. This is\nproblematic because in practice one does not have the opportunity to explore\nand compare alternative AL strategies. Moreover, AL couples the training\ndataset with the model used to guide its acquisition. We find that subsequently\ntraining a successor model with an actively-acquired dataset does not\nconsistently outperform training on i.i.d. sampled data. Our findings raise the\nquestion of whether the downsides inherent to AL are worth the modest and\ninconsistent performance gains it tends to afford.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 19:41:20 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 22:43:33 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 18:00:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lowell", "David", ""], ["Lipton", "Zachary C.", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1807.04833", "submitter": "Neill Campbell", "authors": "Andrew R. Lawrence and Carl Henrik Ek and Neill D. F. Campbell", "title": "DP-GP-LVM: A Bayesian Non-Parametric Model for Learning Multivariate\n  Dependency Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-parametric Bayesian latent variable model capable of\nlearning dependency structures across dimensions in a multivariate setting. Our\napproach is based on flexible Gaussian process priors for the generative\nmappings and interchangeable Dirichlet process priors to learn the structure.\nThe introduction of the Dirichlet process as a specific structural prior allows\nour model to circumvent issues associated with previous Gaussian process latent\nvariable models. Inference is performed by deriving an efficient variational\nbound on the marginal log-likelihood on the model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 21:32:27 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Lawrence", "Andrew R.", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1807.04855", "submitter": "Stefan Maetschke", "authors": "Stefan Maetschke, Bhavna Antony, Hiroshi Ishikawa, Gadi Wollstein,\n  Joel S. Schuman, Rahil Garnavi", "title": "A feature agnostic approach for glaucoma detection in OCT volumes", "comments": "13 pages,3 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0219126", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical coherence tomography (OCT) based measurements of retinal layer\nthickness, such as the retinal nerve fibre layer (RNFL) and the ganglion cell\nwith inner plexiform layer (GCIPL) are commonly used for the diagnosis and\nmonitoring of glaucoma. Previously, machine learning techniques have utilized\nsegmentation-based imaging features such as the peripapillary RNFL thickness\nand the cup-to-disc ratio. Here, we propose a deep learning technique that\nclassifies eyes as healthy or glaucomatous directly from raw, unsegmented OCT\nvolumes of the optic nerve head (ONH) using a 3D Convolutional Neural Network\n(CNN). We compared the accuracy of this technique with various feature-based\nmachine learning algorithms and demonstrated the superiority of the proposed\ndeep learning based method.\n  Logistic regression was found to be the best performing classical machine\nlearning technique with an AUC of 0.89. In direct comparison, the deep learning\napproach achieved a substantially higher AUC of 0.94 with the additional\nadvantage of providing insight into which regions of an OCT volume are\nimportant for glaucoma detection.\n  Computing Class Activation Maps (CAM), we found that the CNN identified\nneuroretinal rim and optic disc cupping as well as the lamina cribrosa (LC) and\nits surrounding areas as the regions significantly associated with the glaucoma\nclassification. These regions anatomically correspond to the well established\nand commonly used clinical markers for glaucoma diagnosis such as increased cup\nvolume, cup diameter, and neuroretinal rim thinning at the superior and\ninferior segments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 22:57:19 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 01:15:27 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 02:29:18 GMT"}, {"version": "v4", "created": "Thu, 24 Oct 2019 03:14:22 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Maetschke", "Stefan", ""], ["Antony", "Bhavna", ""], ["Ishikawa", "Hiroshi", ""], ["Wollstein", "Gadi", ""], ["Schuman", "Joel S.", ""], ["Garnavi", "Rahil", ""]]}, {"id": "1807.04863", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Yoon Kim, Alexander M. Rush, David M. Blei", "title": "Avoiding Latent Variable Collapse With Generative Skip Models", "comments": "In the Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2019), Naha, Okinawa, Japan. PMLR:\n  Volume 89. An earlier version of this paper was presented at the Workshop on\n  Theoretical Foundations and Applications of Deep Generative Models, ICML,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders learn distributions of high-dimensional data. They\nmodel data with a deep latent-variable model and then fit the model by\nmaximizing a lower bound of the log marginal likelihood. VAEs can capture\ncomplex distributions, but they can also suffer from an issue known as \"latent\nvariable collapse,\" especially if the likelihood model is powerful.\nSpecifically, the lower bound involves an approximate posterior of the latent\nvariables; this posterior \"collapses\" when it is set equal to the prior, i.e.,\nwhen the approximate posterior is independent of the data. While VAEs learn\ngood generative models, latent variable collapse prevents them from learning\nuseful representations. In this paper, we propose a simple new way to avoid\nlatent variable collapse by including skip connections in our generative model;\nthese connections enforce strong links between the latent variables and the\nlikelihood function. We study generative skip models both theoretically and\nempirically. Theoretically, we prove that skip models increase the mutual\ninformation between the observations and the inferred latent variables.\nEmpirically, we study images (MNIST and Omniglot) and text (Yahoo). Compared to\nexisting VAE architectures, we show that generative skip models maintain\nsimilar predictive performance but lead to less collapse and provide more\nmeaningful representations of the data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 23:37:27 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 19:33:29 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Dieng", "Adji B.", ""], ["Kim", "Yoon", ""], ["Rush", "Alexander M.", ""], ["Blei", "David M.", ""]]}, {"id": "1807.04881", "submitter": "Diego Ihara", "authors": "Diego Ihara Centurion, Neshat Mohammadi and Anastasios Sidiropoulos", "title": "Algorithms for metric learning via contrastive embeddings", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of supervised learning a metric space under\ndiscriminative constraints. Given a universe $X$ and sets ${\\cal S}, {\\cal\nD}\\subset {X \\choose 2}$ of similar and dissimilar pairs, we seek to find a\nmapping $f:X\\to Y$, into some target metric space $M=(Y,\\rho)$, such that\nsimilar objects are mapped to points at distance at most $u$, and dissimilar\nobjects are mapped to points at distance at least $\\ell$. More generally, the\ngoal is to find a mapping of maximum accuracy (that is, fraction of correctly\nclassified pairs). We propose approximation algorithms for various versions of\nthis problem, for the cases of Euclidean and tree metric spaces. For both of\nthese target spaces, we obtain fully polynomial-time approximation schemes\n(FPTAS) for the case of perfect information. In the presence of imperfect\ninformation we present approximation algorithms that run in quasipolynomial\ntime (QPTAS). Our algorithms use a combination of tools from metric embeddings\nand graph partitioning, that could be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 01:35:40 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 03:22:40 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 23:12:57 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Centurion", "Diego Ihara", ""], ["Mohammadi", "Neshat", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1807.04905", "submitter": "Eunsol Choi", "authors": "Eunsol Choi, Omer Levy, Yejin Choi, Luke Zettlemoyer", "title": "Ultra-Fine Entity Typing", "comments": "ACL 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new entity typing task: given a sentence with an entity\nmention, the goal is to predict a set of free-form phrases (e.g. skyscraper,\nsongwriter, or criminal) that describe appropriate types for the target entity.\nThis formulation allows us to use a new type of distant supervision at large\nscale: head words, which indicate the type of the noun phrases they appear in.\nWe show that these ultra-fine types can be crowd-sourced, and introduce new\nevaluation sets that are much more diverse and fine-grained than existing\nbenchmarks. We present a model that can predict open types, and is trained\nusing a multitask objective that pools our new head-word supervision with prior\nsupervision from entity linking. Experimental results demonstrate that our\nmodel is effective in predicting entity types at varying granularity; it\nachieves state of the art performance on an existing fine-grained entity typing\nbenchmark, and sets baselines for our newly-introduced datasets. Our data and\nmodel can be downloaded from: http://nlp.cs.washington.edu/entity_type\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 04:19:03 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Choi", "Eunsol", ""], ["Levy", "Omer", ""], ["Choi", "Yejin", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1807.04919", "submitter": "Rafael Valle", "authors": "Rafael Valle and Wilson Cai and Anish Doshi", "title": "TequilaGAN: How to easily identify GAN samples", "comments": "10 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show strategies to easily identify fake samples generated\nwith the Generative Adversarial Network framework. One strategy is based on the\nstatistical analysis and comparison of raw pixel values and features extracted\nfrom them. The other strategy learns formal specifications from the real data\nand shows that fake samples violate the specifications of the real data. We\nshow that fake samples produced with GANs have a universal signature that can\nbe used to identify fake samples. We provide results on MNIST, CIFAR10, music\nand speech data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 05:25:54 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Valle", "Rafael", ""], ["Cai", "Wilson", ""], ["Doshi", "Anish", ""]]}, {"id": "1807.04932", "submitter": "Benjamin Bloem-Reddy", "authors": "Martin Tegner and Benjamin Bloem-Reddy and Stephen Roberts", "title": "Sequential sampling of Gaussian process latent variable models", "comments": "In 2018 ICML Workshop on Tractable Probabilistic Models (TPM 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring a latent function in a probabilistic\nmodel of data. When dependencies of the latent function are specified by a\nGaussian process and the data likelihood is complex, efficient computation\noften involve Markov chain Monte Carlo sampling with limited applicability to\nlarge data sets. We extend some of these techniques to scale efficiently when\nthe problem exhibits a sequential structure. We propose an approximation that\nenables sequential sampling of both latent variables and associated parameters.\nWe demonstrate strong performance in growing-data settings that would otherwise\nbe unfeasible with naive, non-sequential sampling.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 06:38:21 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 14:08:58 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Tegner", "Martin", ""], ["Bloem-Reddy", "Benjamin", ""], ["Roberts", "Stephen", ""]]}, {"id": "1807.04936", "submitter": "Abhishek Shetty", "authors": "Navin Goyal and Abhishek Shetty", "title": "Non-Gaussian Component Analysis using Entropy Methods", "comments": null, "journal-ref": null, "doi": "10.1145/3313276.3316309", "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Gaussian component analysis (NGCA) is a problem in multidimensional data\nanalysis which, since its formulation in 2006, has attracted considerable\nattention in statistics and machine learning. In this problem, we have a random\nvariable $X$ in $n$-dimensional Euclidean space. There is an unknown subspace\n$\\Gamma$ of the $n$-dimensional Euclidean space such that the orthogonal\nprojection of $X$ onto $\\Gamma$ is standard multidimensional Gaussian and the\northogonal projection of $X$ onto $\\Gamma^{\\perp}$, the orthogonal complement\nof $\\Gamma$, is non-Gaussian, in the sense that all its one-dimensional\nmarginals are different from the Gaussian in a certain metric defined in terms\nof moments. The NGCA problem is to approximate the non-Gaussian subspace\n$\\Gamma^{\\perp}$ given samples of $X$.\n  Vectors in $\\Gamma^{\\perp}$ correspond to `interesting' directions, whereas\nvectors in $\\Gamma$ correspond to the directions where data is very noisy. The\nmost interesting applications of the NGCA model is for the case when the\nmagnitude of the noise is comparable to that of the true signal, a setting in\nwhich traditional noise reduction techniques such as PCA don't apply directly.\nNGCA is also related to dimension reduction and to other data analysis problems\nsuch as ICA. NGCA-like problems have been studied in statistics for a long time\nusing techniques such as projection pursuit.\n  We give an algorithm that takes polynomial time in the dimension $n$ and has\nan inverse polynomial dependence on the error parameter measuring the angle\ndistance between the non-Gaussian subspace and the subspace output by the\nalgorithm. Our algorithm is based on relative entropy as the contrast function\nand fits under the projection pursuit framework. The techniques we develop for\nanalyzing our algorithm maybe of use for other related problems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 06:47:06 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 03:51:53 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 06:06:58 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Goyal", "Navin", ""], ["Shetty", "Abhishek", ""]]}, {"id": "1807.04950", "submitter": "Ismail Elezi", "authors": "Thilo Stadelmann, Mohammadreza Amirian and Ismail Arabaci, Marek\n  Arnold, Gilbert Fran\\c{c}ois Duivesteijn, Ismail Elezi, Melanie Geiger and\n  Stefan L\\\"orwald and Benjamin Bruno Meier, Katharina Rombach and Lukas\n  Tuggener", "title": "Deep Learning in the Wild", "comments": "Invited paper on ANNPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning with neural networks is applied by an increasing number of\npeople outside of classic research environments, due to the vast success of the\nmethodology on a wide range of machine perception tasks. While this interest is\nfueled by beautiful success stories, practical work in deep learning on novel\ntasks without existing baselines remains challenging. This paper explores the\nspecific challenges arising in the realm of real world tasks, based on case\nstudies from research \\& development in conjunction with industry, and extracts\nlessons learned from them. It thus fills a gap between the publication of\nlatest algorithmic and methodical developments, and the usually omitted\nnitty-gritty of how to make them work. Specifically, we give insight into deep\nlearning projects on face matching, print media monitoring, industrial quality\ncontrol, music scanning, strategy game playing, and automated machine learning,\nthereby providing best practices for deep learning in practice.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 07:22:45 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Stadelmann", "Thilo", ""], ["Amirian", "Mohammadreza", ""], ["Arabaci", "Ismail", ""], ["Arnold", "Marek", ""], ["Duivesteijn", "Gilbert Fran\u00e7ois", ""], ["Elezi", "Ismail", ""], ["Geiger", "Melanie", ""], ["L\u00f6rwald", "Stefan", ""], ["Meier", "Benjamin Bruno", ""], ["Rombach", "Katharina", ""], ["Tuggener", "Lukas", ""]]}, {"id": "1807.05027", "submitter": "V\\'it \\v{S}kv\\'ara", "authors": "V\\'it \\v{S}kv\\'ara, Tom\\'a\\v{s} Pevn\\'y, V\\'aclav \\v{S}m\\'idl", "title": "Are generative deep models for novelty detection truly better?", "comments": "7 pages, ODD v5.0 - KDD 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep models have been recently proposed for anomaly detection. This\npaper presents comparison of selected generative deep models and classical\nanomaly detection methods on an extensive number of non--image benchmark\ndatasets. We provide statistical comparison of the selected models, in many\nconfigurations, architectures and hyperparamaters. We arrive to conclusion that\nperformance of the generative models is determined by the process of selection\nof their hyperparameters. Specifically, performance of the deep generative\nmodels deteriorates with decreasing amount of anomalous samples used in\nhyperparameter selection. In practical scenarios of anomaly detection, none of\nthe deep generative models systematically outperforms the kNN.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 12:05:25 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["\u0160kv\u00e1ra", "V\u00edt", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""]]}, {"id": "1807.05031", "submitter": "Stanis{\\l}aw Jastrz\\k{e}bski", "authors": "Stanis{\\l}aw Jastrz\\k{e}bski, Zachary Kenton, Nicolas Ballas, Asja\n  Fischer, Yoshua Bengio, Amos Storkey", "title": "On the Relation Between the Sharpest Directions of DNN Loss and the SGD\n  Step Length", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR) 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) based training of neural networks with a\nlarge learning rate or a small batch-size typically ends in well-generalizing,\nflat regions of the weight space, as indicated by small eigenvalues of the\nHessian of the training loss. However, the curvature along the SGD trajectory\nis poorly understood. An empirical investigation shows that initially SGD\nvisits increasingly sharp regions, reaching a maximum sharpness determined by\nboth the learning rate and the batch-size of SGD. When studying the SGD\ndynamics in relation to the sharpest directions in this initial phase, we find\nthat the SGD step is large compared to the curvature and commonly fails to\nminimize the loss along the sharpest directions. Furthermore, using a reduced\nlearning rate along these directions can improve training speed while leading\nto both sharper and better generalizing solutions compared to vanilla SGD. In\nsummary, our analysis of the dynamics of SGD in the subspace of the sharpest\ndirections shows that they influence the regions that SGD steers to (where\nlarger learning rate or smaller batch size result in wider regions visited),\nthe overall training speed, and the generalization ability of the final model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 12:17:41 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 21:50:08 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 06:57:09 GMT"}, {"version": "v4", "created": "Fri, 15 Mar 2019 16:10:19 GMT"}, {"version": "v5", "created": "Tue, 9 Jul 2019 19:37:11 GMT"}, {"version": "v6", "created": "Mon, 23 Dec 2019 12:50:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Kenton", "Zachary", ""], ["Ballas", "Nicolas", ""], ["Fischer", "Asja", ""], ["Bengio", "Yoshua", ""], ["Storkey", "Amos", ""]]}, {"id": "1807.05053", "submitter": "Alexandros Kouris", "authors": "Alexandros Kouris, Stylianos I. Venieris and Christos-Savvas Bouganis", "title": "CascadeCNN: Pushing the Performance Limits of Quantisation in\n  Convolutional Neural Networks", "comments": "Accepted for publication at the 28th International Conference on\n  Field Programmable Logic & Applications (FPL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CascadeCNN, an automated toolflow that pushes the\nquantisation limits of any given CNN model, aiming to perform high-throughput\ninference. A two-stage architecture tailored for any given CNN-FPGA pair is\ngenerated, consisting of a low- and high-precision unit in a cascade. A\nconfidence evaluation unit is employed to identify misclassified cases from the\nexcessively low-precision unit and forward them to the high-precision unit for\nre-processing. Experiments demonstrate that the proposed toolflow can achieve a\nperformance boost up to 55% for VGG-16 and 48% for AlexNet over the baseline\ndesign for the same resource budget and accuracy, without the need of\nretraining the model or accessing the training data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 13:21:18 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Kouris", "Alexandros", ""], ["Venieris", "Stylianos I.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1807.05054", "submitter": "Jeffrey Cheng", "authors": "Jeffrey Cheng", "title": "AI Reasoning Systems: PAC and Applied Methods", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and logic are distinct and remarkable approaches to prediction.\nMachine learning has experienced a surge in popularity because it is robust to\nnoise and achieves high performance; however, ML experiences many issues with\nknowledge transfer and extrapolation. In contrast, logic is easily intepreted,\nand logical rules are easy to chain and transfer between systems; however,\ninductive logic is brittle to noise. We then explore the premise of combining\nlearning with inductive logic into AI Reasoning Systems. Specifically, we\nsummarize findings from PAC learning (conceptual graphs, robust logics,\nknowledge infusion) and deep learning (DSRL, $\\partial$ILP, DeepLogic) by\nreproducing proofs of tractability, presenting algorithms in pseudocode,\nhighlighting results, and synthesizing between fields. We conclude with\nsuggestions for integrated models by combining the modules listed above and\nwith a list of unsolved (likely intractable) problems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:23:38 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Cheng", "Jeffrey", ""]]}, {"id": "1807.05076", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai and Adam Trischler", "title": "Metalearning with Hebbian Fast Weights", "comments": "8 pages, 3 figures, 4 tables. arXiv admin note: text overlap with\n  arXiv:1712.09926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unify recent neural approaches to one-shot learning with older ideas of\nassociative memory in a model for metalearning. Our model learns jointly to\nrepresent data and to bind class labels to representations in a single shot. It\nbuilds representations via slow weights, learned across tasks through SGD,\nwhile fast weights constructed by a Hebbian learning rule implement one-shot\nbinding for each new task. On the Omniglot, Mini-ImageNet, and Penn Treebank\none-shot learning benchmarks, our model achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 14:40:06 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Trischler", "Adam", ""]]}, {"id": "1807.05077", "submitter": "Satoshi Hara", "authors": "Kouichi Ikeno, Satoshi Hara", "title": "Maximizing Invariant Data Perturbation with Stochastic Optimization", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attribution methods, or saliency maps, are one of the most popular\napproaches for explaining the decisions of complex machine learning models such\nas deep neural networks. In this study, we propose a stochastic optimization\napproach for the perturbation-based feature attribution method. While the\noriginal optimization problem of the perturbation-based feature attribution is\ndifficult to solve because of the complex constraints, we propose to\nreformulate the problem as the maximization of a differentiable function, which\ncan be solved using gradient-based algorithms. In particular, stochastic\noptimization is well-suited for the proposed reformulation, and we can solve\nthe problem using popular algorithms such as SGD, RMSProp, and Adam. The\nexperiment on the image classification with VGG16 shows that the proposed\nmethod could identify relevant parts of the images effectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 11:47:17 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 04:12:54 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ikeno", "Kouichi", ""], ["Hara", "Satoshi", ""]]}, {"id": "1807.05087", "submitter": "Thomas Bonald", "authors": "Thomas Bonald, Bertrand Charpentier", "title": "Learning Graph Representations by Dendrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical graph clustering is a common technique to reveal the multi-scale\nstructure of complex networks. We propose a novel metric for assessing the\nquality of a hierarchical clustering. This metric reflects the ability to\nreconstruct the graph from the dendrogram, which encodes the hierarchy. The\noptimal representation of the graph defines a class of reducible linkages\nleading to regular dendrograms by greedy agglomerative clustering.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 13:51:52 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Bonald", "Thomas", ""], ["Charpentier", "Bertrand", ""]]}, {"id": "1807.05118", "submitter": "Richard Liaw", "authors": "Richard Liaw, Eric Liang, Robert Nishihara, Philipp Moritz, Joseph E.\n  Gonzalez, Ion Stoica", "title": "Tune: A Research Platform for Distributed Model Selection and Training", "comments": "8 Pages, Presented at the 2018 ICML AutoML workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning algorithms are increasingly computationally\ndemanding, requiring specialized hardware and distributed computation to\nachieve high performance in a reasonable time frame. Many hyperparameter search\nalgorithms have been proposed for improving the efficiency of model selection,\nhowever their adaptation to the distributed compute environment is often\nad-hoc. We propose Tune, a unified framework for model selection and training\nthat provides a narrow-waist interface between training scripts and search\nalgorithms. We show that this interface meets the requirements for a broad\nrange of hyperparameter search algorithms, allows straightforward scaling of\nsearch to large clusters, and simplifies algorithm implementation. We\ndemonstrate the implementation of several state-of-the-art hyperparameter\nsearch algorithms in Tune. Tune is available at\nhttp://ray.readthedocs.io/en/latest/tune.html.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:00:17 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Liaw", "Richard", ""], ["Liang", "Eric", ""], ["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Gonzalez", "Joseph E.", ""], ["Stoica", "Ion", ""]]}, {"id": "1807.05154", "submitter": "Hongxiao Bai", "authors": "Hongxiao Bai, Hai Zhao", "title": "Deep Enhanced Representation for Implicit Discourse Relation Recognition", "comments": "13(10) pages, accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation recognition is a challenging task as the relation\nprediction without explicit connectives in discourse parsing needs\nunderstanding of text spans and cannot be easily derived from surface features\nfrom the input sentence pairs. Thus, properly representing the text is very\ncrucial to this task. In this paper, we propose a model augmented with\ndifferent grained text representations, including character, subword, word,\nsentence, and sentence pair levels. The proposed deeper model is evaluated on\nthe benchmark treebank and achieves state-of-the-art accuracy with greater than\n48% in 11-way and $F_1$ score greater than 50% in 4-way classifications for the\nfirst time according to our best knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:57:39 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bai", "Hongxiao", ""], ["Zhao", "Hai", ""]]}, {"id": "1807.05162", "submitter": "Yannis Assael", "authors": "Brendan Shillingford, Yannis Assael, Matthew W. Hoffman, Thomas Paine,\n  C\\'ian Hughes, Utsav Prabhu, Hank Liao, Hasim Sak, Kanishka Rao, Lorrayne\n  Bennett, Marie Mulville, Ben Coppin, Ben Laurie, Andrew Senior, Nando de\n  Freitas", "title": "Large-Scale Visual Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a scalable solution to open-vocabulary visual speech\nrecognition. To achieve this, we constructed the largest existing visual speech\nrecognition dataset, consisting of pairs of text and video clips of faces\nspeaking (3,886 hours of video). In tandem, we designed and trained an\nintegrated lipreading system, consisting of a video processing pipeline that\nmaps raw video to stable videos of lips and sequences of phonemes, a scalable\ndeep neural network that maps the lip videos to sequences of phoneme\ndistributions, and a production-level speech decoder that outputs sequences of\nwords. The proposed system achieves a word error rate (WER) of 40.9% as\nmeasured on a held-out set. In comparison, professional lipreaders achieve\neither 86.4% or 92.9% WER on the same dataset when having access to additional\ntypes of contextual information. Our approach significantly improves on other\nlipreading approaches, including variants of LipNet and of Watch, Attend, and\nSpell (WAS), which are only capable of 89.8% and 76.8% WER respectively.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:21:34 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 16:44:01 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 11:23:03 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shillingford", "Brendan", ""], ["Assael", "Yannis", ""], ["Hoffman", "Matthew W.", ""], ["Paine", "Thomas", ""], ["Hughes", "C\u00edan", ""], ["Prabhu", "Utsav", ""], ["Liao", "Hank", ""], ["Sak", "Hasim", ""], ["Rao", "Kanishka", ""], ["Bennett", "Lorrayne", ""], ["Mulville", "Marie", ""], ["Coppin", "Ben", ""], ["Laurie", "Ben", ""], ["Senior", "Andrew", ""], ["de Freitas", "Nando", ""]]}, {"id": "1807.05185", "submitter": "Smitha Milli", "authors": "Smitha Milli, Ludwig Schmidt, Anca D. Dragan, Moritz Hardt", "title": "Model Reconstruction from Model Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show through theory and experiment that gradient-based explanations of a\nmodel quickly reveal the model itself. Our results speak to a tension between\nthe desire to keep a proprietary model secret and the ability to offer model\nexplanations. On the theoretical side, we give an algorithm that provably\nlearns a two-layer ReLU network in a setting where the algorithm may query the\ngradient of the model with respect to chosen inputs. The number of queries is\nindependent of the dimension and nearly optimal in its dependence on the model\nsize. Of interest not only from a learning-theoretic perspective, this result\nhighlights the power of gradients rather than labels as a learning primitive.\nComplementing our theory, we give effective heuristics for reconstructing\nmodels from gradient explanations that are orders of magnitude more\nquery-efficient than reconstruction attacks relying on prediction interfaces.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:15:00 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Milli", "Smitha", ""], ["Schmidt", "Ludwig", ""], ["Dragan", "Anca D.", ""], ["Hardt", "Moritz", ""]]}, {"id": "1807.05207", "submitter": "Shing Chan", "authors": "Shing Chan and Ahmed H. Elsheikh", "title": "Parametric generation of conditional geological realizations using\n  generative neural networks", "comments": null, "journal-ref": "Computational Geosciences (2019)", "doi": "10.1007/s10596-019-09850-7", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques are increasingly being considered for geological\napplications where -- much like in computer vision -- the challenges are\ncharacterized by high-dimensional spatial data dominated by multipoint\nstatistics. In particular, a novel technique called generative adversarial\nnetworks has been recently studied for geological parametrization and\nsynthesis, obtaining very impressive results that are at least qualitatively\ncompetitive with previous methods. The method obtains a neural network\nparametrization of the geology -- so-called a generator -- that is capable of\nreproducing very complex geological patterns with dimensionality reduction of\nseveral orders of magnitude. Subsequent works have addressed the conditioning\ntask, i.e. using the generator to generate realizations honoring spatial\nobservations (hard data). The current approaches, however, do not provide a\nparametrization of the conditional generation process. In this work, we propose\na method to obtain a parametrization for direct generation of conditional\nrealizations. The main idea is to simply extend the existing generator network\nby stacking a second inference network that learns to perform the conditioning.\nThis inference network is a neural network trained to sample a posterior\ndistribution derived using a Bayesian formulation of the conditioning task. The\nresulting extended neural network thus provides the conditional\nparametrization. Our method is assessed on a benchmark image of binary\nchannelized subsurface, obtaining very promising results for a wide variety of\nconditioning configurations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:46:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 15:54:11 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Chan", "Shing", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "1807.05237", "submitter": "Hiroshi Shinaoka", "authors": "Naoya Chikano, Kazuyoshi Yoshimi, Junya Otsuki, Hiroshi Shinaoka", "title": "irbasis: Open-source database and software for\n  intermediate-representation basis functions of imaginary-time Green's\n  function", "comments": "12 pages, 5 figures", "journal-ref": "Computer Physics Communications240, 181-188 (2019)", "doi": "10.1016/j.cpc.2019.02.006", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cond-mat.str-el cond-mat.supr-con cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The open-source library, irbasis, provides easy-to-use tools for two sets of\northogonal functions named intermediate representation (IR). The IR basis\nenables a compact representation of the Matsubara Green's function and\nefficient calculations of quantum models. The IR basis functions are defined as\nthe solution of an integral equation whose analytical solution is not available\nfor this moment. The library consists of a database of pre-computed\nhigh-precision numerical solutions and computational code for evaluating the\nfunctions from the database. This paper describes technical details and\ndemonstrates how to use the library.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 18:01:59 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 09:07:58 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Chikano", "Naoya", ""], ["Yoshimi", "Kazuyoshi", ""], ["Otsuki", "Junya", ""], ["Shinaoka", "Hiroshi", ""]]}, {"id": "1807.05292", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi", "title": "Neural Networks Regularization Through Representation Learning", "comments": "196 pages, 44 figures, 489 references, INSA Rouen Normandie,\n  Normandie Universit\\'e", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models and deep models are one of the leading and state of the\nart models in machine learning. Most successful deep neural models are the ones\nwith many layers which highly increases their number of parameters. Training\nsuch models requires a large number of training samples which is not always\navailable. One of the fundamental issues in neural networks is overfitting\nwhich is the issue tackled in this thesis. Such problem often occurs when the\ntraining of large models is performed using few training samples. Many\napproaches have been proposed to prevent the network from overfitting and\nimprove its generalization performance such as data augmentation, early\nstopping, parameters sharing, unsupervised learning, dropout, batch\nnormalization, etc.\n  In this thesis, we tackle the neural network overfitting issue from a\nrepresentation learning perspective by considering the situation where few\ntraining samples are available which is the case of many real world\napplications. We propose three contributions. The first one presented in\nchapter 2 is dedicated to dealing with structured output problems to perform\nmultivariate regression when the output variable y contains structural\ndependencies between its components. The second contribution described in\nchapter 3 deals with the classification task where we propose to exploit prior\nknowledge about the internal representation of the hidden layers in neural\nnetworks. Our last contribution presented in chapter 4 showed the interest of\ntransfer learning in applications where only few samples are available. In this\ncontribution, we provide an automatic system based on such learning scheme with\nan application to medical domain. In this application, the task consists in\nlocalizing the third lumbar vertebra in a 3D CT scan. This work has been done\nin collaboration with the clinic Rouen Henri Becquerel Center who provided us\nwith data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 21:57:18 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Belharbi", "Soufiane", ""]]}, {"id": "1807.05306", "submitter": "Chong Huang", "authors": "Chong Huang, Peter Kairouz, Xiao Chen, Lalitha Sankar, Ram Rajagopal", "title": "Generative Adversarial Privacy", "comments": "Talk presentation at Privacy in Machine Learning and Artificial\n  Intelligence (PiMLAI) Workshop, ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.GT cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven framework called generative adversarial privacy\n(GAP). Inspired by recent advancements in generative adversarial networks\n(GANs), GAP allows the data holder to learn the privatization mechanism\ndirectly from the data. Under GAP, finding the optimal privacy mechanism is\nformulated as a constrained minimax game between a privatizer and an adversary.\nWe show that for appropriately chosen adversarial loss functions, GAP provides\nprivacy guarantees against strong information-theoretic adversaries. We also\nevaluate GAP's performance on the GENKI face database.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 23:40:33 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 07:26:27 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 04:32:46 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Huang", "Chong", ""], ["Kairouz", "Peter", ""], ["Chen", "Xiao", ""], ["Sankar", "Lalitha", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1807.05307", "submitter": "Manish Raghavan", "authors": "Jon Kleinberg and Manish Raghavan", "title": "How Do Classifiers Induce Agents To Invest Effort Strategically?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are often used to produce decision-making rules that classify or\nevaluate individuals. When these individuals have incentives to be classified a\ncertain way, they may behave strategically to influence their outcomes. We\ndevelop a model for how strategic agents can invest effort in order to change\nthe outcomes they receive, and we give a tight characterization of when such\nagents can be incentivized to invest specified forms of effort into improving\ntheir outcomes as opposed to \"gaming\" the classifier. We show that whenever any\n\"reasonable\" mechanism can do so, a simple linear mechanism suffices.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 23:46:52 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 14:20:56 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 23:36:26 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2019 02:55:39 GMT"}, {"version": "v5", "created": "Thu, 1 Aug 2019 00:45:55 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Kleinberg", "Jon", ""], ["Raghavan", "Manish", ""]]}, {"id": "1807.05317", "submitter": "Bahar Salehpour", "authors": "Daniel H. Noronha, Bahar Salehpour, and Steven J.E. Wilton", "title": "LeFlow: Enabling Flexible FPGA High-Level Synthesis of Tensorflow Deep\n  Neural Networks", "comments": "To be published in FPGA for Software Programmers (FSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that Field-Programmable Gate Arrays (FPGAs) play an\nimportant role in the acceleration of Machine Learning applications. Initial\nspecification of machine learning applications are often done using a\nhigh-level Python-oriented framework such as Tensorflow, followed by a manual\ntranslation to either C or RTL for synthesis using vendor tools. This manual\ntranslation step is time-consuming and requires expertise that limit the\napplicability of FPGAs in this important domain. In this paper, we present an\nopen-source tool-flow that maps numerical computation models written in\nTensorflow to synthesizable hardware. Unlike other tools, which are often\nconstrained by a small number of inflexible templates, our flow uses Google's\nXLA compiler which emits LLVM code directly from a Tensorflow specification.\nThis LLVM code can then be used with a high-level synthesis tool to\nautomatically generate hardware. We show that our flow allows users to generate\nDeep Neural Networks with very few lines of Python code.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 01:06:13 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Noronha", "Daniel H.", ""], ["Salehpour", "Bahar", ""], ["Wilton", "Steven J. E.", ""]]}, {"id": "1807.05328", "submitter": "Jie Liu", "authors": "Jie Liu, Yu Rong, Martin Takac, Junzhou Huang", "title": "On the Acceleration of L-BFGS with Second-Order Information and\n  Stochastic Batches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework of L-BFGS based on the (approximate)\nsecond-order information with stochastic batches, as a novel approach to the\nfinite-sum minimization problems. Different from the classical L-BFGS where\nstochastic batches lead to instability, we use a smooth estimate for the\nevaluations of the gradient differences while achieving acceleration by\nwell-scaling the initial Hessians. We provide theoretical analyses for both\nconvex and nonconvex cases. In addition, we demonstrate that within the popular\napplications of least-square and cross-entropy losses, the algorithm admits a\nsimple implementation in the distributed environment. Numerical experiments\nsupport the efficiency of our algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 03:48:46 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Liu", "Jie", ""], ["Rong", "Yu", ""], ["Takac", "Martin", ""], ["Huang", "Junzhou", ""]]}, {"id": "1807.05343", "submitter": "Alessandro Betti", "authors": "Giovanni Bellettini, Alessandro Betti, Marco Gori", "title": "Generalization in quasi-periodic environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By and large the behavior of stochastic gradient is regarded as a challenging\nproblem, and it is often presented in the framework of statistical machine\nlearning. This paper offers a novel view on the analysis of on-line models of\nlearning that arises when dealing with a generalized version of stochastic\ngradient that is based on dissipative dynamics. In order to face the complex\nevolution of these models, a systematic treatment is proposed which is based on\nenergy balance equations that are derived by means of the Caldirola-Kanai (CK)\nHamiltonian. According to these equations, learning can be regarded as an\nordering process which corresponds with the decrement of the loss function.\nFinally, the main results established in this paper is that in the case of\nquasi-periodic environments, where the pattern novelty is progressively limited\nas time goes by, the system dynamics yields an asymptotically consistent\nsolution in the weight space, that is the solution maps similar patterns to the\nsame decision.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 07:01:14 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bellettini", "Giovanni", ""], ["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1807.05344", "submitter": "Andrew Jesson D", "authors": "Andrew Jesson and C\\'ecile Low-Kam and Florian Soudan and Nicolas\n  Chapados", "title": "Adversarially Learned Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Adversarially Learned Mixture Model (AMM) is a generative model for\nunsupervised or semi-supervised data clustering. The AMM is the first\nadversarially optimized method to model the conditional dependence between\ninferred continuous and categorical latent variables. Experiments on the MNIST\nand SVHN datasets show that the AMM allows for semantic separation of complex\ndata when little or no labeled data is available. The AMM achieves a\nstate-of-the-art unsupervised clustering error rate of 2.86% on the MNIST\ndataset. A semi-supervised extension of the AMM yields competitive results on\nthe SVHN dataset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 07:17:58 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Jesson", "Andrew", ""], ["Low-Kam", "C\u00e9cile", ""], ["Soudan", "Florian", ""], ["Chapados", "Nicolas", ""]]}, {"id": "1807.05351", "submitter": "Gustavo Publio", "authors": "Gustavo Correa Publio, Diego Esteves, Agnieszka {\\L}awrynowicz,\n  Pan\\v{c}e Panov, Larisa Soldatova, Tommaso Soru, Joaquin Vanschoren, Hamid\n  Zafar", "title": "ML-Schema: Exposing the Semantics of Machine Learning with Schemas and\n  Ontologies", "comments": "Poster, selected for the 2nd Reproducibility in Machine Learning\n  Workshop at ICML 2018, Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ML-Schema, proposed by the W3C Machine Learning Schema Community Group,\nis a top-level ontology that provides a set of classes, properties, and\nrestrictions for representing and interchanging information on machine learning\nalgorithms, datasets, and experiments. It can be easily extended and\nspecialized and it is also mapped to other more domain-specific ontologies\ndeveloped in the area of machine learning and data mining. In this paper we\noverview existing state-of-the-art machine learning interchange formats and\npresent the first release of ML-Schema, a canonical format resulted of more\nthan seven years of experience among different research institutions. We argue\nthat exposing semantics of machine learning algorithms, models, and experiments\nthrough a canonical format may pave the way to better interpretability and to\nrealistically achieve the full interoperability of experiments regardless of\nplatform or adopted workflow solution.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 08:07:31 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Publio", "Gustavo Correa", ""], ["Esteves", "Diego", ""], ["\u0141awrynowicz", "Agnieszka", ""], ["Panov", "Pan\u010de", ""], ["Soldatova", "Larisa", ""], ["Soru", "Tommaso", ""], ["Vanschoren", "Joaquin", ""], ["Zafar", "Hamid", ""]]}, {"id": "1807.05411", "submitter": "Aleksandr Aravkin", "authors": "Peng Zheng, Travis Askham, Steven L. Brunton, J. Nathan Kutz, and\n  Aleksandr Y. Aravkin", "title": "A Unified Framework for Sparse Relaxed Regularized Regression: SR3", "comments": "19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized regression problems are ubiquitous in statistical modeling,\nsignal processing, and machine learning. Sparse regression in particular has\nbeen instrumental in scientific model discovery, including compressed sensing\napplications, variable selection, and high-dimensional analysis. We propose a\nbroad framework for sparse relaxed regularized regression, called SR3. The key\nidea is to solve a relaxation of the regularized problem, which has three\nadvantages over the state-of-the-art: (1) solutions of the relaxed problem are\nsuperior with respect to errors, false positives, and conditioning, (2)\nrelaxation allows extremely fast algorithms for both convex and nonconvex\nformulations, and (3) the methods apply to composite regularizers such as total\nvariation (TV) and its nonconvex variants. We demonstrate the advantages of SR3\n(computational efficiency, higher accuracy, faster convergence rates, greater\nflexibility) across a range of regularized regression problems with synthetic\nand real data, including applications in compressed sensing, LASSO, matrix\ncompletion, TV regularization, and group sparsity. To promote reproducible\nresearch, we also provide a companion MATLAB package that implements these\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 15:37:37 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 15:32:59 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 21:33:30 GMT"}, {"version": "v4", "created": "Thu, 8 Nov 2018 18:59:06 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Zheng", "Peng", ""], ["Askham", "Travis", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""], ["Aravkin", "Aleksandr Y.", ""]]}, {"id": "1807.05459", "submitter": "Sakshi Mishra", "authors": "Sakshi Mishra, Praveen Palanisamy", "title": "Multi-time-horizon Solar Forecasting Using Recurrent Neural Network", "comments": "Accepted at: IEEE Energy Conversion Congress and Exposition (ECCE\n  2018), 7 pages, 5 figures, code available: sakshi-mishra.github.io", "journal-ref": null, "doi": "10.1109/ECCE.2018.8558187", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-stationarity characteristic of the solar power renders traditional\npoint forecasting methods to be less useful due to large prediction errors.\nThis results in increased uncertainties in the grid operation, thereby\nnegatively affecting the reliability and increased cost of operation. This\nresearch paper proposes a unified architecture for multi-time-horizon\npredictions for short and long-term solar forecasting using Recurrent Neural\nNetworks (RNN). The paper describes an end-to-end pipeline to implement the\narchitecture along with the methods to test and validate the performance of the\nprediction model. The results demonstrate that the proposed method based on the\nunified architecture is effective for multi-horizon solar forecasting and\nachieves a lower root-mean-squared prediction error compared to the previous\nbest-performing methods which use one model for each time-horizon. The proposed\nmethod enables multi-horizon forecasts with real-time inputs, which have a high\npotential for practical applications in the evolving smart grid.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 22:12:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mishra", "Sakshi", ""], ["Palanisamy", "Praveen", ""]]}, {"id": "1807.05464", "submitter": "Andreas Bueff Mr.", "authors": "Andreas Bueff, Stefanie Speichert, Vaishak Belle", "title": "Tractable Querying and Learning in Hybrid Domains via Sum-Product\n  Networks", "comments": "Accepted at the 2018 KR Workshop on Hybrid Reasoning and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic representations, such as Bayesian and Markov networks, are\nfundamental to much of statistical machine learning. Thus, learning\nprobabilistic representations directly from data is a deep challenge, the main\ncomputational bottleneck being inference that is intractable. Tractable\nlearning is a powerful new paradigm that attempts to learn distributions that\nsupport efficient probabilistic querying. By leveraging local structure,\nrepresentations such as sum-product networks (SPNs) can capture high tree-width\nmodels with many hidden layers, essentially a deep architecture, while still\nadmitting a range of probabilistic queries to be computable in time polynomial\nin the network size. The leaf nodes in SPNs, from which more intricate mixtures\nare formed, are tractable univariate distributions, and so the literature has\nfocused on Bernoulli and Gaussian random variables. This is clearly a\nrestriction for handling mixed discrete-continuous data, especially if the\ncontinuous features are generated from non-parametric and non-Gaussian\ndistribution families. In this work, we present a framework that systematically\nintegrates SPN structure learning with weighted model integration, a recently\nintroduced computational abstraction for performing inference in hybrid\ndomains, by means of piecewise polynomial approximations of density functions\nof arbitrary shape. Our framework is instantiated by exploiting the notion of\npropositional abstractions, thus minimally interfering with the SPN structure\nlearning module, and supports a powerful query interface for conditioning on\ninterval constraints. Our empirical results show that our approach is\neffective, and allows a study of the trade off between the granularity of the\nlearned model and its predictive power.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 23:25:16 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 16:30:13 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:13:20 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Bueff", "Andreas", ""], ["Speichert", "Stefanie", ""], ["Belle", "Vaishak", ""]]}, {"id": "1807.05490", "submitter": "Zehong Cao Dr.", "authors": "Shiming Chen, Yisong Wang, Chin-Teng Lin, Weiping Ding, Zehong Cao", "title": "Semi-supervised Feature Learning For Improving Writer Identification", "comments": "This manuscript is submitting to Information Science", "journal-ref": "Information Sciences (Volume 482, May 2019, Pages 156-170)", "doi": "10.1016/j.ins.2019.01.024", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is usually used by supervised learning approaches for\noffline writer identification, but such approaches require extra training data\nand potentially lead to overfitting errors. In this study, a semi-supervised\nfeature learning pipeline was proposed to improve the performance of writer\nidentification by training with extra unlabeled data and the original labeled\ndata simultaneously. Specifically, we proposed a weighted label smoothing\nregularization (WLSR) method for data augmentation, which assigned the weighted\nuniform label distribution to the extra unlabeled data. The WLSR method could\nregularize the convolutional neural network (CNN) baseline to allow more\ndiscriminative features to be learned to represent the properties of different\nwriting styles. The experimental results on well-known benchmark datasets\n(ICDAR2013 and CVL) showed that our proposed semi-supervised feature learning\napproach could significantly improve the baseline measurement and perform\ncompetitively with existing writer identification approaches. Our findings\nprovide new insights into offline write identification.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 05:18:20 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 02:08:15 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2018 15:06:38 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chen", "Shiming", ""], ["Wang", "Yisong", ""], ["Lin", "Chin-Teng", ""], ["Ding", "Weiping", ""], ["Cao", "Zehong", ""]]}, {"id": "1807.05515", "submitter": "Shuai Jiang", "authors": "Shuai Jiang, Kan Li and Richard Yi Da Xu", "title": "Magnitude Bounded Matrix Factorisation for Recommender Systems", "comments": "11 pages, 6 figures, TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank matrix factorisation is often used in recommender systems as a way\nof extracting latent features. When dealing with large and sparse datasets,\ntraditional recommendation algorithms face the problem of acquiring large,\nunrestrained, fluctuating values over predictions especially for users/items\nwith very few corresponding observations. Although the problem has been\nsomewhat solved by imposing bounding constraints over its objectives, and/or\nover all entries to be within a fixed range, in terms of gaining better\nrecommendations, these approaches have two major shortcomings that we aim to\nmitigate in this work: one is they can only deal with one pair of fixed bounds\nfor all entries, and the other one is they are very time-consuming when applied\non large scale recommender systems. In this paper, we propose a novel algorithm\nnamed Magnitude Bounded Matrix Factorisation (MBMF), which allows different\nbounds for individual users/items and performs very fast on large scale\ndatasets. The key idea of our algorithm is to construct a model by constraining\nthe magnitudes of each individual user/item feature vector. We achieve this by\nconverting from the Cartesian to Spherical coordinate system with radii set as\nthe corresponding magnitudes, which allows the above constrained optimisation\nproblem to become an unconstrained one. The Stochastic Gradient Descent (SGD)\nmethod is then applied to solve the unconstrained task efficiently. Experiments\non synthetic and real datasets demonstrate that in most cases the proposed MBMF\nis superior over all existing algorithms in terms of accuracy and time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 09:00:05 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Jiang", "Shuai", ""], ["Li", "Kan", ""], ["Da Xu", "Richard Yi", ""]]}, {"id": "1807.05527", "submitter": "Stefanie Speichert", "authors": "Stefanie Speichert, Vaishak Belle", "title": "Learning Probabilistic Logic Programs in Continuous Domains", "comments": "Accepted at the 2018 KR Workshop on Hybrid Reasoning and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of statistical relational learning aims at unifying logic and\nprobability to reason and learn from data. Perhaps the most successful paradigm\nin the field is probabilistic logic programming: the enabling of stochastic\nprimitives in logic programming, which is now increasingly seen to provide a\ndeclarative background to complex machine learning applications. While many\nsystems offer inference capabilities, the more significant challenge is that of\nlearning meaningful and interpretable symbolic representations from data. In\nthat regard, inductive logic programming and related techniques have paved much\nof the way for the last few decades.\n  Unfortunately, a major limitation of this exciting landscape is that much of\nthe work is limited to finite-domain discrete probability distributions.\nRecently, a handful of systems have been extended to represent and perform\ninference with continuous distributions. The problem, of course, is that\nclassical solutions for inference are either restricted to well-known\nparametric families (e.g., Gaussians) or resort to sampling strategies that\nprovide correct answers only in the limit. When it comes to learning, moreover,\ninducing representations remains entirely open, other than \"data-fitting\"\nsolutions that force-fit points to aforementioned parametric families.\n  In this paper, we take the first steps towards inducing probabilistic logic\nprograms for continuous and mixed discrete-continuous data, without being\npigeon-holed to a fixed set of distribution families. Our key insight is to\nleverage techniques from piecewise polynomial function approximation theory,\nyielding a principled way to learn and compositionally construct density\nfunctions. We test the framework and discuss the learned representations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 11:00:00 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 12:45:38 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Speichert", "Stefanie", ""], ["Belle", "Vaishak", ""]]}, {"id": "1807.05560", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang and Jie\n  Tang", "title": "DeepInf: Social Influence Prediction with Deep Learning", "comments": "10 pages, 5 figures, to appear in KDD 2018 proceedings", "journal-ref": null, "doi": "10.1145/3219819.3220077", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social and information networking activities such as on Facebook, Twitter,\nWeChat, and Weibo have become an indispensable part of our everyday life, where\nwe can easily access friends' behaviors and are in turn influenced by them.\nConsequently, an effective social influence prediction for each user is\ncritical for a variety of applications such as online recommendation and\nadvertising.\n  Conventional social influence prediction approaches typically design various\nhand-crafted rules to extract user- and network-specific features. However,\ntheir effectiveness heavily relies on the knowledge of domain experts. As a\nresult, it is usually difficult to generalize them into different domains.\nInspired by the recent success of deep neural networks in a wide range of\ncomputing applications, we design an end-to-end framework, DeepInf, to learn\nusers' latent feature representation for predicting social influence. In\ngeneral, DeepInf takes a user's local network as the input to a graph neural\nnetwork for learning her latent social representation. We design strategies to\nincorporate both network structures and user-specific features into\nconvolutional neural and attention networks. Extensive experiments on Open\nAcademic Graph, Twitter, Weibo, and Digg, representing different types of\nsocial and information networks, demonstrate that the proposed end-to-end\nmodel, DeepInf, significantly outperforms traditional feature engineering-based\napproaches, suggesting the effectiveness of representation learning for social\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 15:11:09 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Tang", "Jian", ""], ["Ma", "Hao", ""], ["Dong", "Yuxiao", ""], ["Wang", "Kuansan", ""], ["Tang", "Jie", ""]]}, {"id": "1807.05561", "submitter": "Danil Kuzin", "authors": "Danil Kuzin, Olga Isupova, Lyudmila Mihaylova", "title": "Spatio-Temporal Structured Sparse Regression with Hierarchical Gaussian\n  Process Priors", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2858207", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new sparse spatio-temporal structured Gaussian\nprocess regression framework for online and offline Bayesian inference. This is\nthe first framework that gives a time-evolving representation of the\ninterdependencies between the components of the sparse signal of interest. A\nhierarchical Gaussian process describes such structure and the\ninterdependencies are represented via the covariance matrices of the prior\ndistributions. The inference is based on the expectation propagation method and\nthe theoretical derivation of the posterior distribution is provided in the\npaper. The inference framework is thoroughly evaluated over synthetic, real\nvideo and electroencephalography (EEG) data where the spatio-temporal evolving\npatterns need to be reconstructed with high accuracy. It is shown that it\nachieves 15% improvement of the F-measure compared with the alternating\ndirection method of multipliers, spatio-temporal sparse Bayesian learning\nmethod and one-level Gaussian process model. Additionally, the required memory\nfor the proposed algorithm is less than in the one-level Gaussian process\nmodel. This structured sparse regression framework is of broad applicability to\nsource localisation and object detection problems with sparse signals.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 15:14:57 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Kuzin", "Danil", ""], ["Isupova", "Olga", ""], ["Mihaylova", "Lyudmila", ""]]}, {"id": "1807.05595", "submitter": "Evan Schwab", "authors": "Evan Schwab, Benjamin D. Haeffele, Ren\\'e Vidal, and Nicolas Charon", "title": "Global Optimality in Separable Dictionary Learning with Applications to\n  the Analysis of Diffusion MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse dictionary learning is a popular method for representing signals as\nlinear combinations of a few elements from a dictionary that is learned from\nthe data. In the classical setting, signals are represented as vectors and the\ndictionary learning problem is posed as a matrix factorization problem where\nthe data matrix is approximately factorized into a dictionary matrix and a\nsparse matrix of coefficients. However, in many applications in computer vision\nand medical imaging, signals are better represented as matrices or tensors\n(e.g. images or videos), where it may be beneficial to exploit the\nmulti-dimensional structure of the data to learn a more compact representation.\nOne such approach is separable dictionary learning, where one learns separate\ndictionaries for different dimensions of the data. However, typical\nformulations involve solving a non-convex optimization problem; thus\nguaranteeing global optimality remains a challenge. In this work, we propose a\nframework that builds upon recent developments in matrix factorization to\nprovide theoretical and numerical guarantees of global optimality for separable\ndictionary learning. We propose an algorithm to find such a globally optimal\nsolution, which alternates between following local descent steps and checking a\ncertificate for global optimality. We illustrate our approach on diffusion\nmagnetic resonance imaging (dMRI) data, a medical imaging modality that\nmeasures water diffusion along multiple angular directions in every voxel of an\nMRI volume. State-of-the-art methods in dMRI either learn dictionaries only for\nthe angular domain of the signals or in some cases learn spatial and angular\ndictionaries independently. In this work, we apply the proposed separable\ndictionary learning framework to learn spatial and angular dMRI dictionaries\njointly and provide preliminary validation on denoising phantom and real dMRI\nbrain data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 19:02:44 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 15:31:47 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Schwab", "Evan", ""], ["Haeffele", "Benjamin D.", ""], ["Vidal", "Ren\u00e9", ""], ["Charon", "Nicolas", ""]]}, {"id": "1807.05597", "submitter": "Marcus Scheunemann", "authors": "Sander G. van Dijk, Marcus M. Scheunemann", "title": "Deep Learning for Semantic Segmentation on Minimal Hardware", "comments": "12 pages, 5 figures, RoboCup International Symposium 2018", "journal-ref": null, "doi": "10.1007/978-3-030-27544-0_29", "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has revolutionised many fields, but it is still challenging to\ntransfer its success to small mobile robots with minimal hardware.\nSpecifically, some work has been done to this effect in the RoboCup humanoid\nfootball domain, but results that are performant and efficient and still\ngenerally applicable outside of this domain are lacking. We propose an approach\nconceptually different from those taken previously. It is based on semantic\nsegmentation and does achieve these desired properties. In detail, it is being\nable to process full VGA images in real-time on a low-power mobile processor.\nIt can further handle multiple image dimensions without retraining, it does not\nrequire specific domain knowledge for achieving a high frame rate and it is\napplicable on a minimal mobile hardware.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 19:15:41 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["van Dijk", "Sander G.", ""], ["Scheunemann", "Marcus M.", ""]]}, {"id": "1807.05620", "submitter": "Dongdong She", "authors": "Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray,\n  Suman Jana", "title": "NEUZZ: Efficient Fuzzing with Neural Program Smoothing", "comments": "To appear in the 40th IEEE Symposium on Security and Privacy, May\n  20--22, 2019, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing has become the de facto standard technique for finding software\nvulnerabilities. However, even state-of-the-art fuzzers are not very efficient\nat finding hard-to-trigger software bugs. Most popular fuzzers use evolutionary\nguidance to generate inputs that can trigger different bugs. Such evolutionary\nalgorithms, while fast and simple to implement, often get stuck in fruitless\nsequences of random mutations. Gradient-guided optimization presents a\npromising alternative to evolutionary guidance. Gradient-guided techniques have\nbeen shown to significantly outperform evolutionary algorithms at solving\nhigh-dimensional structured optimization problems in domains like machine\nlearning by efficiently utilizing gradients or higher-order derivatives of the\nunderlying function. However, gradient-guided approaches are not directly\napplicable to fuzzing as real-world program behaviors contain many\ndiscontinuities, plateaus, and ridges where the gradient-based methods often\nget stuck. We observe that this problem can be addressed by creating a smooth\nsurrogate function approximating the discrete branching behavior of target\nprogram. In this paper, we propose a novel program smoothing technique using\nsurrogate neural network models that can incrementally learn smooth\napproximations of a complex, real-world program's branching behaviors. We\nfurther demonstrate that such neural network models can be used together with\ngradient-guided input generation schemes to significantly improve the fuzzing\nefficiency. Our extensive evaluations demonstrate that NEUZZ significantly\noutperforms 10 state-of-the-art graybox fuzzers on 10 real-world programs both\nat finding new bugs and achieving higher edge coverage. NEUZZ found 31 unknown\nbugs that other fuzzers failed to find in 10 real world programs and achieved\n3X more edge coverage than all of the tested graybox fuzzers for 24 hours\nrunning.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 21:54:31 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 23:17:38 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 03:51:13 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 18:47:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["She", "Dongdong", ""], ["Pei", "Kexin", ""], ["Epstein", "Dave", ""], ["Yang", "Junfeng", ""], ["Ray", "Baishakhi", ""], ["Jana", "Suman", ""]]}, {"id": "1807.05636", "submitter": "Aravindh Mahendran", "authors": "Aravindh Mahendran, James Thewlis, Andrea Vedaldi", "title": "Cross Pixel Optical Flow Similarity for Self-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for learning convolutional neural image\nrepresentations without manual supervision. We use motion cues in the form of\noptical flow, to supervise representations of static images. The obvious\napproach of training a network to predict flow from a single image can be\nneedlessly difficult due to intrinsic ambiguities in this prediction task. We\ninstead propose a much simpler learning goal: embed pixels such that the\nsimilarity between their embeddings matches that between their optical flow\nvectors. At test time, the learned deep network can be used without access to\nvideo or flow information and transferred to tasks such as image\nclassification, detection, and segmentation. Our method, which significantly\nsimplifies previous attempts at using motion for self-supervision, achieves\nstate-of-the-art results in self-supervision using motion cues, competitive\nresults for self-supervision in general, and is overall state of the art in\nself-supervised pretraining for semantic image segmentation, as demonstrated on\nstandard benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 23:48:59 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Mahendran", "Aravindh", ""], ["Thewlis", "James", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1807.05650", "submitter": "Amir Asiaee", "authors": "Amir Asiaee, Hardik Goel, Shalini Ghosh, Vinod Yegneswaran, Arindam\n  Banerjee", "title": "Time Series Deinterleaving of DNS Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream deinterleaving is an important problem with various applications in\nthe cybersecurity domain. In this paper, we consider the specific problem of\ndeinterleaving DNS data streams using machine-learning techniques, with the\nobjective of automating the extraction of malware domain sequences. We first\ndevelop a generative model for user request generation and DNS stream\ninterleaving. Based on these we evaluate various inference strategies for\ndeinterleaving including augmented HMMs and LSTMs on synthetic datasets. Our\nresults demonstrate that state-of-the-art LSTMs outperform more traditional\naugmented HMMs in this application domain.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 01:55:44 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Asiaee", "Amir", ""], ["Goel", "Hardik", ""], ["Ghosh", "Shalini", ""], ["Yegneswaran", "Vinod", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1807.05666", "submitter": "Zhiqiang Liu", "authors": "Ruiguo Yu, Zhiqiang Liu, Xuewei Li, Wenhuan Lu, Mei Yu, Jianrong Wang,\n  Bin Li", "title": "Scene Learning: Deep Convolutional Networks For Wind Power Prediction by\n  Embedding Turbines into Grid Space", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind power prediction is of vital importance in wind power utilization. There\nhave been a lot of researches based on the time series of the wind power or\nspeed, but In fact, these time series cannot express the temporal and spatial\nchanges of wind, which fundamentally hinders the advance of wind power\nprediction. In this paper, a new kind of feature that can describe the process\nof temporal and spatial variation is proposed, namely, Spatio-Temporal\nFeatures. We first map the data collected at each moment from the wind turbine\nto the plane to form the state map, namely, the scene, according to the\nrelative positions. The scene time series over a period of time is a\nmulti-channel image, i.e. the Spatio-Temporal Features. Based on the\nSpatio-Temporal Features, the deep convolutional network is applied to predict\nthe wind power, achieving a far better accuracy than the existing methods.\nCompared with the starge-of-the-art method, the mean-square error (MSE) in our\nmethod is reduced by 49.83%, and the average time cost for training models can\nbe shortened by a factor of more than 150.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 03:27:18 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 02:58:10 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Yu", "Ruiguo", ""], ["Liu", "Zhiqiang", ""], ["Li", "Xuewei", ""], ["Lu", "Wenhuan", ""], ["Yu", "Mei", ""], ["Wang", "Jianrong", ""], ["Li", "Bin", ""]]}, {"id": "1807.05720", "submitter": "Araz Taeihagh", "authors": "Araz Taeihagh, Hazel Si Min Lim", "title": "Governing autonomous vehicles: emerging responses for safety, liability,\n  privacy, cybersecurity, and industry risks", "comments": "Transport Reviews, 2018", "journal-ref": null, "doi": "10.1080/01441647.2018.1494640", "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefits of autonomous vehicles (AVs) are widely acknowledged, but there\nare concerns about the extent of these benefits and AV risks and unintended\nconsequences. In this article, we first examine AVs and different categories of\nthe technological risks associated with them. We then explore strategies that\ncan be adopted to address these risks, and explore emerging responses by\ngovernments for addressing AV risks. Our analyses reveal that, thus far,\ngovernments have in most instances avoided stringent measures in order to\npromote AV developments and the majority of responses are non-binding and focus\non creating councils or working groups to better explore AV implications. The\nUS has been active in introducing legislations to address issues related to\nprivacy and cybersecurity. The UK and Germany, in particular, have enacted laws\nto address liability issues, other countries mostly acknowledge these issues,\nbut have yet to implement specific strategies. To address privacy and\ncybersecurity risks strategies ranging from introduction or amendment of non-AV\nspecific legislation to creating working groups have been adopted. Much less\nattention has been paid to issues such as environmental and employment risks,\nalthough a few governments have begun programmes to retrain workers who might\nbe negatively affected.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 08:18:57 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Taeihagh", "Araz", ""], ["Lim", "Hazel Si Min", ""]]}, {"id": "1807.05726", "submitter": "Yu-Hsun Lin", "authors": "Yu-Hsun Lin, Chun-Nan Chou and Edward Y. Chang", "title": "BRIEF: Backward Reduction of CNNs with Information Flow Analysis", "comments": "IEEE Artificial Intelligence and Virtual Reality (IEEE AIVR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes BRIEF, a backward reduction algorithm that explores\ncompact CNN-model designs from the information flow perspective. This algorithm\ncan remove substantial non-zero weighting parameters (redundant neural\nchannels) of a network by considering its dynamic behavior, which traditional\nmodel-compaction techniques cannot achieve. With the aid of our proposed\nalgorithm, we achieve significant model reduction on ResNet-34 in the ImageNet\nscale (32.3% reduction), which is 3X better than the previous result (10.8%).\nEven for highly optimized models such as SqueezeNet and MobileNet, we can\nachieve additional 10.81% and 37.56% reduction, respectively, with negligible\nperformance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 08:32:54 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 02:57:28 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 02:35:47 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Lin", "Yu-Hsun", ""], ["Chou", "Chun-Nan", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1807.05748", "submitter": "Cagatay Yildiz", "authors": "Cagatay Yildiz, Markus Heinonen, Jukka Intosalmi, Henrik\n  Mannerstr\\\"om, Harri L\\\"ahdesm\\\"aki", "title": "Learning Stochastic Differential Equations With Gaussian Processes\n  Without Gradient Matching", "comments": "The accepted version of the paper to be presented in 2018 IEEE\n  International Workshop on Machine Learning for Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel paradigm for learning non-parametric drift and diffusion\nfunctions for stochastic differential equation (SDE). The proposed model learns\nto simulate path distributions that match observations with non-uniform time\nincrements and arbitrary sparseness, which is in contrast with gradient\nmatching that does not optimize simulated responses. We formulate sensitivity\nequations for learning and demonstrate that our general stochastic distribution\noptimisation leads to robust and efficient learning of SDE systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 09:21:38 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 09:25:36 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Yildiz", "Cagatay", ""], ["Heinonen", "Markus", ""], ["Intosalmi", "Jukka", ""], ["Mannerstr\u00f6m", "Henrik", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1807.05800", "submitter": "Takashi Matsubara", "authors": "Takashi Matsubara, Kenta Hama, Ryosuke Tachibana, Kuniaki Uehara", "title": "Deep Generative Model using Unregularized Score for Anomaly Detection\n  with Heterogeneous Complexity", "comments": "An extended version of a manuscript in Proc. of The 2018\n  International Joint Conference on Neural Networks (IJCNN2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and automated detection of anomalous samples in a natural image\ndataset can be accomplished with a probabilistic model for end-to-end modeling\nof images. Such images have heterogeneous complexity, however, and a\nprobabilistic model overlooks simply shaped objects with small anomalies. This\nis because the probabilistic model assigns undesirably lower likelihoods to\ncomplexly shaped objects that are nevertheless consistent with set standards.\nTo overcome this difficulty, we propose an unregularized score for deep\ngenerative models (DGMs), which are generative models leveraging deep neural\nnetworks. We found that the regularization terms of the DGMs considerably\ninfluence the anomaly score depending on the complexity of the samples. By\nremoving these terms, we obtain an unregularized score, which we evaluated on a\ntoy dataset and real-world manufacturing datasets. Empirical results\ndemonstrate that the unregularized score is robust to the inherent complexity\nof samples and can be used to better detect anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:41:32 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 13:14:38 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Matsubara", "Takashi", ""], ["Hama", "Kenta", ""], ["Tachibana", "Ryosuke", ""], ["Uehara", "Kuniaki", ""]]}, {"id": "1807.05827", "submitter": "Guido Novati", "authors": "Guido Novati and Petros Koumoutsakos", "title": "Remember and Forget for Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay (ER) is a fundamental component of off-policy deep\nreinforcement learning (RL). ER recalls experiences from past iterations to\ncompute gradient estimates for the current policy, increasing data-efficiency.\nHowever, the accuracy of such updates may deteriorate when the policy diverges\nfrom past behaviors and can undermine the performance of ER. Many algorithms\nmitigate this issue by tuning hyper-parameters to slow down policy changes. An\nalternative is to actively enforce the similarity between policy and the\nexperiences in the replay memory. We introduce Remember and Forget Experience\nReplay (ReF-ER), a novel method that can enhance RL algorithms with\nparameterized policies. ReF-ER (1) skips gradients computed from experiences\nthat are too unlikely with the current policy and (2) regulates policy changes\nwithin a trust region of the replayed behaviors. We couple ReF-ER with\nQ-learning, deterministic policy gradient and off-policy gradient methods. We\nfind that ReF-ER consistently improves the performance of continuous-action,\noff-policy RL on fully observable benchmarks and partially observable flow\ncontrol problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 12:57:04 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 19:30:45 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 07:46:18 GMT"}, {"version": "v4", "created": "Mon, 20 May 2019 10:22:43 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Novati", "Guido", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1807.05832", "submitter": "Shufei Zhang Mr", "authors": "Shufei Zhang, Kaizhu Huang, Jianke Zhu and Yang Liu", "title": "Manifold Adversarial Learning", "comments": "11 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed adversarial training methods show the robustness to both\nadversarial and original examples and achieve state-of-the-art results in\nsupervised and semi-supervised learning. All the existing adversarial training\nmethods consider only how the worst perturbed examples (i.e., adversarial\nexamples) could affect the model output. Despite their success, we argue that\nsuch setting may be in lack of generalization, since the output space (or label\nspace) is apparently less informative.In this paper, we propose a novel method,\ncalled Manifold Adversarial Training (MAT). MAT manages to build an adversarial\nframework based on how the worst perturbation could affect the distributional\nmanifold rather than the output space. Particularly, a latent data space with\nthe Gaussian Mixture Model (GMM) will be first derived.On one hand, MAT tries\nto perturb the input samples in the way that would rough the distributional\nmanifold the worst. On the other hand, the deep learning model is trained\ntrying to promote in the latent space the manifold smoothness, measured by the\nvariation of Gaussian mixtures (given the local perturbation around the data\npoint). Importantly, since the latent space is more informative than the output\nspace, the proposed MAT can learn better a robust and compact data\nrepresentation, leading to further performance improvement. The proposed MAT is\nimportant in that it can be considered as a superset of one recently-proposed\ndiscriminative feature learning approach called center loss. We conducted a\nseries of experiments in both supervised and semi-supervised learning on three\nbenchmark data sets, showing that the proposed MAT can achieve remarkable\nperformance, much better than those of the state-of-the-art adversarial\napproaches. We also present a series of visualization which could generate\nfurther understanding or explanation on adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 13:01:41 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 14:28:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zhang", "Shufei", ""], ["Huang", "Kaizhu", ""], ["Zhu", "Jianke", ""], ["Liu", "Yang", ""]]}, {"id": "1807.05836", "submitter": "Pier Francesco Procacci", "authors": "Pier Francesco Procacci and Tomaso Aste", "title": "Forecasting market states", "comments": "13 pages, 5 figures", "journal-ref": "Quantitative Finance 19 (2019) 1491-1498", "doi": "10.1080/14697688.2019.1622313", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel methodology to define, analyze and forecast market states.\nIn our approach market states are identified by a reference sparse precision\nmatrix and a vector of expectation values. In our procedure, each multivariate\nobservation is associated with a given market state accordingly to a\nminimization of a penalized Mahalanobis distance. The procedure is made\ncomputationally very efficient and can be used with a large number of assets.\nWe demonstrate that this procedure is successful at clustering different states\nof the markets in an unsupervised manner. In particular, we describe an\nexperiment with one hundred log-returns and two states in which the methodology\nautomatically associates states prevalently to pre- and post- crisis periods\nwith one state gathering periods with average positive returns and the other\nstate periods with average negative returns, therefore discovering\nspontaneously the common classification of `bull' and `bear' markets. In\nanother experiment, with again one hundred log-returns and two states, we\ndemonstrate that this procedure can be efficiently used to forecast off-sample\nfuture market states with significant prediction accuracy. This methodology\nopens the way to a range of applications in risk management and trading\nstrategies in the context where the correlation structure plays a central role.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:43:39 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 23:02:16 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 21:21:52 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Procacci", "Pier Francesco", ""], ["Aste", "Tomaso", ""]]}, {"id": "1807.05838", "submitter": "Ranju Mandal Dr.", "authors": "Ranju Mandal, Rod M. Connolly, Thomas A. Schlacherz, Bela Stantic", "title": "Assessing fish abundance from underwater video using deep neural\n  networks", "comments": "IJCNN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uses of underwater videos to assess diversity and abundance of fish are being\nrapidly adopted by marine biologists. Manual processing of videos for\nquantification by human analysts is time and labour intensive. Automatic\nprocessing of videos can be employed to achieve the objectives in a cost and\ntime-efficient way. The aim is to build an accurate and reliable fish detection\nand recognition system, which is important for an autonomous robotic platform.\nHowever, there are many challenges involved in this task (e.g. complex\nbackground, deformation, low resolution and light propagation). Recent\nadvancement in the deep neural network has led to the development of object\ndetection and recognition in real time scenarios. An end-to-end deep\nlearning-based architecture is introduced which outperformed the state of the\nart methods and first of its kind on fish assessment task. A Region Proposal\nNetwork (RPN) introduced by an object detector termed as Faster R-CNN was\ncombined with three classification networks for detection and recognition of\nfish species obtained from Remote Underwater Video Stations (RUVS). An accuracy\nof 82.4% (mAP) obtained from the experiments are much higher than previously\nproposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 13:13:37 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Mandal", "Ranju", ""], ["Connolly", "Rod M.", ""], ["Schlacherz", "Thomas A.", ""], ["Stantic", "Bela", ""]]}, {"id": "1807.05849", "submitter": "Junxin Liu", "authors": "Junxin Liu, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, Xing Xie", "title": "Neural Chinese Word Segmentation with Dictionary Knowledge", "comments": "This paper has been accepted by The Seventh CCF International\n  Conference on Natural Language Processing and Chinese Computing (NLPCC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is an important task for Chinese NLP.\nRecently, many neural network based methods have been proposed for CWS.\nHowever, these methods require a large number of labeled sentences for model\ntraining, and usually cannot utilize the useful information in Chinese\ndictionary. In this paper, we propose two methods to exploit the dictionary\ninformation for CWS. The first one is based on pseudo labeled data generation,\nand the second one is based on multi-task learning. The experimental results on\ntwo benchmark datasets validate that our approach can effectively improve the\nperformance of Chinese word segmentation, especially when training data is\ninsufficient.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 04:51:41 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Liu", "Junxin", ""], ["Wu", "Fangzhao", ""], ["Wu", "Chuhan", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1807.05852", "submitter": "Reza Shokri", "authors": "Milad Nasr, Reza Shokri, Amir Houmansadr", "title": "Machine Learning with Membership Privacy using Adversarial\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models leak information about the datasets on which they are\ntrained. An adversary can build an algorithm to trace the individual members of\na model's training dataset. As a fundamental inference attack, he aims to\ndistinguish between data points that were part of the model's training set and\nany other data points from the same distribution. This is known as the tracing\n(and also membership inference) attack. In this paper, we focus on such attacks\nagainst black-box models, where the adversary can only observe the output of\nthe model, but not its parameters. This is the current setting of machine\nlearning as a service in the Internet.\n  We introduce a privacy mechanism to train machine learning models that\nprovably achieve membership privacy: the model's predictions on its training\ndata are indistinguishable from its predictions on other data points from the\nsame distribution. We design a strategic mechanism where the privacy mechanism\nanticipates the membership inference attacks. The objective is to train a model\nsuch that not only does it have the minimum prediction error (high utility),\nbut also it is the most robust model against its corresponding strongest\ninference attack (high privacy). We formalize this as a min-max game\noptimization problem, and design an adversarial training algorithm that\nminimizes the classification loss of the model as well as the maximum gain of\nthe membership inference attack against it. This strategy, which guarantees\nmembership privacy (as prediction indistinguishability), acts also as a strong\nregularizer and significantly generalizes the model.\n  We evaluate our privacy mechanism on deep neural networks using different\nbenchmark datasets. We show that our min-max strategy can mitigate the risk of\nmembership inference attacks (close to the random guess) with a negligible cost\nin terms of the classification error.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 13:35:30 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Nasr", "Milad", ""], ["Shokri", "Reza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1807.05887", "submitter": "Guiliang Liu", "authors": "Guiliang Liu, Oliver Schulte, Wang Zhu and Qingcan Li", "title": "Toward Interpretable Deep Reinforcement Learning with Linear Model\n  U-Trees", "comments": "This paper is accepted by ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has achieved impressive success in many\napplications. A key component of many DRL models is a neural network\nrepresenting a Q function, to estimate the expected cumulative reward following\na state-action pair. The Q function neural network contains a lot of implicit\nknowledge about the RL problems, but often remains unexamined and\nuninterpreted. To our knowledge, this work develops the first mimic learning\nframework for Q functions in DRL. We introduce Linear Model U-trees (LMUTs) to\napproximate neural network predictions. An LMUT is learned using a novel\non-line algorithm that is well-suited for an active play setting, where the\nmimic learner observes an ongoing interaction between the neural net and the\nenvironment. Empirical evaluation shows that an LMUT mimics a Q function\nsubstantially better than five baseline methods. The transparent tree structure\nof an LMUT facilitates understanding the network's learned knowledge by\nanalyzing feature influence, extracting rules, and highlighting the\nsuper-pixels in image inputs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 14:31:35 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Liu", "Guiliang", ""], ["Schulte", "Oliver", ""], ["Zhu", "Wang", ""], ["Li", "Qingcan", ""]]}, {"id": "1807.05924", "submitter": "Navneet Paul", "authors": "Arun Kumar, Navneet Paul and S N Omkar", "title": "Bipedal Walking Robot using Deep Deterministic Policy Gradient", "comments": "Research manuscript submitted to IEEE Symposium Series on\n  Computational Intelligence(SSCI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms have found several applications in the field of\nrobotics and control systems. The control systems community has started to show\ninterest towards several machine learning algorithms from the sub-domains such\nas supervised learning, imitation learning and reinforcement learning to\nachieve autonomous control and intelligent decision making. Amongst many\ncomplex control problems, stable bipedal walking has been the most challenging\nproblem. In this paper, we present an architecture to design and simulate a\nplanar bipedal walking robot(BWR) using a realistic robotics simulator, Gazebo.\nThe robot demonstrates successful walking behaviour by learning through several\nof its trial and errors, without any prior knowledge of itself or the world\ndynamics. The autonomous walking of the BWR is achieved using reinforcement\nlearning algorithm called Deep Deterministic Policy Gradient(DDPG). DDPG is one\nof the algorithms for learning controls in continuous action spaces. After\ntraining the model in simulation, it was observed that, with a proper shaped\nreward function, the robot achieved faster walking or even rendered a running\ngait with an average speed of 0.83 m/s. The gait pattern of the bipedal walker\nwas compared with the actual human walking pattern. The results show that the\nbipedal walking pattern had similar characteristics to that of a human walking\npattern. The video presenting our experiment is available at\nhttps://goo.gl/NHXKqR.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:34:52 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 15:44:28 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Kumar", "Arun", ""], ["Paul", "Navneet", ""], ["Omkar", "S N", ""]]}, {"id": "1807.05926", "submitter": "Luk\\'a\\v{s} Sob\\'i\\v{s}ek PhD", "authors": "Lukas Sobisek, Maria Stachova, Jan Fojtik", "title": "Novel Feature-Based Clustering of Micro-Panel Data (CluMP)", "comments": "R-code is available upon request to the corresponding author. This\n  working paper was submitted to Journal of Classification in April 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-panel data are collected and analysed in many research and industry\nareas. Cluster analysis of micro-panel data is an unsupervised learning\nexploratory method identifying subgroup clusters in a data set which include\nhomogeneous objects in terms of the development dynamics of monitored\nvariables. The supply of clustering methods tailored to micro-panel data is\nlimited. The present paper focuses on a feature-based clustering method,\nintroducing a novel two-step characteristic-based approach designed for this\ntype of data. The proposed CluMP method aims to identify clusters that are at\nleast as internally homogeneous and externally heterogeneous as those obtained\nby alternative methods already implemented in the statistical system R. We\ncompare the clustering performance of the devised algorithm with two extant\nmethods using simulated micro-panel data sets. Our approach has yielded similar\nor better outcomes than the other methods, the advantage of the proposed\nalgorithm being time efficiency which makes it applicable for large data sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:39:22 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Sobisek", "Lukas", ""], ["Stachova", "Maria", ""], ["Fojtik", "Jan", ""]]}, {"id": "1807.05935", "submitter": "Anton Nemchenko", "authors": "Anton Nemchenko, Trent Kyono, Mihaela Van Der Schaar", "title": "Siamese Survival Analysis with Competing Risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival analysis in the presence of multiple possible adverse events, i.e.,\ncompeting risks, is a pervasive problem in many industries (healthcare,\nfinance, etc.). Since only one event is typically observed, the incidence of an\nevent of interest is often obscured by other related competing events. This\nnonidentifiability, or inability to estimate true cause-specific survival\ncurves from empirical data, further complicates competing risk survival\nanalysis. We introduce Siamese Survival Prognosis Network (SSPN), a novel deep\nlearning architecture for estimating personalized risk scores in the presence\nof competing risks. SSPN circumvents the nonidentifiability problem by avoiding\nthe estimation of cause-specific survival curves and instead determines\npairwise concordant time-dependent risks, where longer event times are assigned\nlower risks. Furthermore, SSPN is able to directly optimize an approximation to\nthe C-discrimination index, rather than relying on well-known metrics which are\nunable to capture the unique requirements of survival analysis with competing\nrisks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:56:55 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 22:48:20 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Nemchenko", "Anton", ""], ["Kyono", "Trent", ""], ["Van Der Schaar", "Mihaela", ""]]}, {"id": "1807.05936", "submitter": "Jianlin Su", "authors": "Jianlin Su", "title": "Variational Inference: A Unified Framework of Generative Models and Some\n  Revelations", "comments": "6 pages, 4 figures, fix a bug, fix (19), E(z)-->E(x), fix (2), fix\n  (7), add code link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We reinterpreting the variational inference in a new perspective. Via this\nway, we can easily prove that EM algorithm, VAE, GAN, AAE, ALI(BiGAN) are all\nspecial cases of variational inference. The proof also reveals the loss of\nstandard GAN is incomplete and it explains why we need to train GAN cautiously.\nFrom that, we find out a regularization term to improve stability of GAN\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:57:03 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 04:06:44 GMT"}, {"version": "v3", "created": "Wed, 18 Jul 2018 07:43:29 GMT"}, {"version": "v4", "created": "Fri, 20 Jul 2018 14:41:20 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Su", "Jianlin", ""]]}, {"id": "1807.05960", "submitter": "Dushyant Rao", "authors": "Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan\n  Pascanu, Simon Osindero, and Raia Hadsell", "title": "Meta-Learning with Latent Embedding Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learning techniques are both widely applicable and\nproficient at solving challenging few-shot learning and fast adaptation\nproblems. However, they have practical difficulties when operating on\nhigh-dimensional parameter spaces in extreme low-data regimes. We show that it\nis possible to bypass these limitations by learning a data-dependent latent\ngenerative representation of model parameters, and performing gradient-based\nmeta-learning in this low-dimensional latent space. The resulting approach,\nlatent embedding optimization (LEO), decouples the gradient-based adaptation\nprocedure from the underlying high-dimensional space of model parameters. Our\nevaluation shows that LEO can achieve state-of-the-art performance on the\ncompetitive miniImageNet and tieredImageNet few-shot classification tasks.\nFurther analysis indicates LEO is able to capture uncertainty in the data, and\ncan perform adaptation more effectively by optimizing in latent space.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 16:35:29 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 16:38:43 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 13:36:45 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Rusu", "Andrei A.", ""], ["Rao", "Dushyant", ""], ["Sygnowski", "Jakub", ""], ["Vinyals", "Oriol", ""], ["Pascanu", "Razvan", ""], ["Osindero", "Simon", ""], ["Hadsell", "Raia", ""]]}, {"id": "1807.05981", "submitter": "Stanislas Chambon", "authors": "Stanislas Chambon and Valentin Thorey and Pierrick J. Arnal and\n  Emmanuel Mignot and Alexandre Gramfort", "title": "A deep learning architecture to detect events in EEG signals during\n  sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) during sleep is used by clinicians to evaluate\nvarious neurological disorders. In sleep medicine, it is relevant to detect\nmacro-events (> 10s) such as sleep stages, and micro-events (<2s) such as\nspindles and K-complexes. Annotations of such events require a trained sleep\nexpert, a time consuming and tedious process with a large inter-scorer\nvariability. Automatic algorithms have been developed to detect various types\nof events but these are event-specific. We propose a deep learning method that\njointly predicts locations, durations and types of events in EEG time series.\nIt relies on a convolutional neural network that builds a feature\nrepresentation from raw EEG signals. Numerical experiments demonstrate\nefficiency of this new approach on various event detection tasks compared to\ncurrent state-of-the-art, event specific, algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:29:55 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Chambon", "Stanislas", ""], ["Thorey", "Valentin", ""], ["Arnal", "Pierrick J.", ""], ["Mignot", "Emmanuel", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1807.06036", "submitter": "Michael Conover", "authors": "Michael Conover, Matthew Hayes, Scott Blackburn, Pete Skomoroch, Sam\n  Shah", "title": "Pangloss: Fast Entity Linking in Noisy Text Environments", "comments": "KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of mapping potentially ambiguous terms in text to\ntheir constituent entities in a knowledge base like Wikipedia. This is useful\nfor organizing content, extracting structured data from textual documents, and\nin machine learning relevance applications like semantic search, knowledge\ngraph construction, and question answering. Traditionally, this work has\nfocused on text that has been well-formed, like news articles, but in common\nreal world datasets such as messaging, resumes, or short-form social media,\nnon-grammatical, loosely-structured text adds a new dimension to this problem.\n  This paper presents Pangloss, a production system for entity disambiguation\non noisy text. Pangloss combines a probabilistic linear-time key phrase\nidentification algorithm with a semantic similarity engine based on\ncontext-dependent document embeddings to achieve better than state-of-the-art\nresults (>5% in F1) compared to other research or commercially available\nsystems. In addition, Pangloss leverages a local embedded database with a\ntiered architecture to house its statistics and metadata, which allows rapid\ndisambiguation in streaming contexts and on-device disambiguation in low-memory\nenvironments such as mobile phones.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:04:08 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Conover", "Michael", ""], ["Hayes", "Matthew", ""], ["Blackburn", "Scott", ""], ["Skomoroch", "Pete", ""], ["Shah", "Sam", ""]]}, {"id": "1807.06046", "submitter": "Yuri Chervonyi", "authors": "Yuri Chervonyi, Dragos Harabor, Brian Zhang, Josh Sacks", "title": "Zap: Making Predictions Based on Online User Behavior", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Zap, a generic machine learning pipeline for making\npredictions based on online user behavior. Zap combines well known techniques\nfor processing sequential data with more obscure techniques such as Bloom\nfilters, bucketing, and model calibration into an end-to-end solution. The\npipeline creates website- and task-specific models without knowing anything\nabout the structure of the website. It is designed to minimize the amount of\nwebsite-specific code, which is realized by factoring all website-specific\nlogic into example generators. New example generators can typically be written\nup in a few lines of code.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:18:02 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Chervonyi", "Yuri", ""], ["Harabor", "Dragos", ""], ["Zhang", "Brian", ""], ["Sacks", "Josh", ""]]}, {"id": "1807.06054", "submitter": "Sepehr Akhavan Masouleh", "authors": "Mahdi Azarafrooz, Xuan Zhao, Sepehr Akhavan-Masouleh", "title": "On the Information Theoretic Distance Measures and Bidirectional\n  Helmholtz Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By establishing a connection between bi-directional Helmholtz machines and\ninformation theory, we propose a generalized Helmholtz machine. Theoretical and\nexperimental results show that given \\textit{shallow} architectures, the\ngeneralized model outperforms the previous ones substantially.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:41:16 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Azarafrooz", "Mahdi", ""], ["Zhao", "Xuan", ""], ["Akhavan-Masouleh", "Sepehr", ""]]}, {"id": "1807.06064", "submitter": "Zhanhong Jiang", "authors": "Aaron J. Havens, Zhanhong Jiang, Soumik Sarkar", "title": "Online Robust Policy Learning in the Presence of Unknown Adversaries", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing prospect of deep reinforcement learning (DRL) being used in\ncyber-physical systems has raised concerns around safety and robustness of\nautonomous agents. Recent work on generating adversarial attacks have shown\nthat it is computationally feasible for a bad actor to fool a DRL policy into\nbehaving sub optimally. Although certain adversarial attacks with specific\nattack models have been addressed, most studies are only interested in off-line\noptimization in the data space (e.g., example fitting, distillation). This\npaper introduces a Meta-Learned Advantage Hierarchy (MLAH) framework that is\nattack model-agnostic and more suited to reinforcement learning, via handling\nthe attacks in the decision space (as opposed to data space) and directly\nmitigating learned bias introduced by the adversary. In MLAH, we learn separate\nsub-policies (nominal and adversarial) in an online manner, as guided by a\nsupervisory master agent that detects the presence of the adversary by\nleveraging the advantage function for the sub-policies. We demonstrate that the\nproposed algorithm enables policy learning with significantly lower bias as\ncompared to the state-of-the-art policy learning approaches even in the\npresence of heavy state information attacks. We present algorithm analysis and\nsimulation results using popular OpenAI Gym environments.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 19:17:38 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Havens", "Aaron J.", ""], ["Jiang", "Zhanhong", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1807.06068", "submitter": "Yeounoh Chung", "authors": "Yeounoh Chung, Tim Kraska, Neoklis Polyzotis, Ki Hyun Tae, Steven\n  Euijong Whang", "title": "Automated Data Slicing for Model Validation:A Big data - AI Integration\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning systems become democratized, it becomes increasingly\nimportant to help users easily debug their models. However, current data tools\nare still primitive when it comes to helping users trace model performance\nproblems all the way to the data. We focus on the particular problem of slicing\ndata to identify subsets of the validation data where the model performs\npoorly. This is an important problem in model validation because the overall\nmodel performance can fail to reflect that of the smaller subsets, and slicing\nallows users to analyze the model performance on a more granular-level. Unlike\ngeneral techniques (e.g., clustering) that can find arbitrary slices, our goal\nis to find interpretable slices (which are easier to take action compared to\narbitrary subsets) that are problematic and large. We propose Slice Finder,\nwhich is an interactive framework for identifying such slices using statistical\ntechniques. Applications include diagnosing model fairness and fraud detection,\nwhere identifying slices that are interpretable to humans is crucial. This\nresearch is part of a larger trend of Big data and Artificial Intelligence (AI)\nintegration and opens many opportunities for new research.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 19:21:24 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:36:08 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 01:01:26 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Chung", "Yeounoh", ""], ["Kraska", "Tim", ""], ["Polyzotis", "Neoklis", ""], ["Tae", "Ki Hyun", ""], ["Whang", "Steven Euijong", ""]]}, {"id": "1807.06072", "submitter": "Jungwook Lee", "authors": "Jungwook Lee, Sean Walsh, Ali Harakeh, and Steven L. Waslander", "title": "Leveraging Pre-Trained 3D Object Detection Models For Fast Ground Truth\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training 3D object detectors for autonomous driving has been limited to small\ndatasets due to the effort required to generate annotations. Reducing both task\ncomplexity and the amount of task switching done by annotators is key to\nreducing the effort and time required to generate 3D bounding box annotations.\nThis paper introduces a novel ground truth generation method that combines\nhuman supervision with pretrained neural networks to generate per-instance 3D\npoint cloud segmentation, 3D bounding boxes, and class annotations. The\nannotators provide object anchor clicks which behave as a seed to generate\ninstance segmentation results in 3D. The points belonging to each instance are\nthen used to regress object centroids, bounding box dimensions, and object\norientation. Our proposed annotation scheme requires 30x lower human annotation\ntime. We use the KITTI 3D object detection dataset to evaluate the efficiency\nand the quality of our annotation scheme. We also test the the proposed scheme\non previously unseen data from the Autonomoose self-driving vehicle to\ndemonstrate generalization capabilities of the network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 19:33:09 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Lee", "Jungwook", ""], ["Walsh", "Sean", ""], ["Harakeh", "Ali", ""], ["Waslander", "Steven L.", ""]]}, {"id": "1807.06076", "submitter": "Zahra Shakeri Hossein Abad", "authors": "Zahra Shakeri Hossein Abad, Munib Rahman, Abdullah Cheema, Vincenzo\n  Gervasi, Didar Zowghi, Ken Barker", "title": "Dynamic Visual Analytics for Elicitation Meetings with ELICA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requirements elicitation can be very challenging in projects that require\ndeep domain knowledge about the system at hand. As analysts have the full\ncontrol over the elicitation process, their lack of knowledge about the system\nunder study inhibits them from asking related questions and reduces the\naccuracy of requirements provided by stakeholders. We present ELICA, a generic\ninteractive visual analytics tool to assist analysts during requirements\nelicitation process. ELICA uses a novel information extraction algorithm based\non a combination of Weighted Finite State Transducers (WFSTs) (generative\nmodel) and SVMs (discriminative model). ELICA presents the extracted relevant\ninformation in an interactive GUI (including zooming, panning, and pinching)\nthat allows analysts to explore which parts of the ongoing conversation (or\nspecification document) match with the extracted information. In this\ndemonstration, we show that ELICA is usable and effective in practice, and is\nable to extract the related information in real-time. We also demonstrate how\ncarefully designed features in ELICA facilitate the interactive and dynamic\nprocess of information extraction.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 17:16:35 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Abad", "Zahra Shakeri Hossein", ""], ["Rahman", "Munib", ""], ["Cheema", "Abdullah", ""], ["Gervasi", "Vincenzo", ""], ["Zowghi", "Didar", ""], ["Barker", "Ken", ""]]}, {"id": "1807.06081", "submitter": "Max-Heinrich Laves M. Sc.", "authors": "Max-Heinrich Laves, Jens Bicker, L\\\"uder A. Kahrs, Tobias Ortmaier", "title": "A Dataset of Laryngeal Endoscopic Images with Comparative Study on\n  Convolution Neural Network Based Semantic Segmentation", "comments": "Accepted for publication in International Journal of Computer\n  Assisted Radiology and Surgery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose Automated segmentation of anatomical structures in medical image\nanalysis is a prerequisite for autonomous diagnosis as well as various computer\nand robot aided interventions. Recent methods based on deep convolutional\nneural networks (CNN) have outperformed former heuristic methods. However,\nthose methods were primarily evaluated on rigid, real-world environments. In\nthis study, existing segmentation methods were evaluated for their use on a new\ndataset of transoral endoscopic exploration. Methods Four machine learning\nbased methods SegNet, UNet, ENet and ErfNet were trained with supervision on a\nnovel 7-class dataset of the human larynx. The dataset contains 536 manually\nsegmented images from two patients during laser incisions. The\nIntersection-over-Union (IoU) evaluation metric was used to measure the\naccuracy of each method. Data augmentation and network ensembling were employed\nto increase segmentation accuracy. Stochastic inference was used to show\nuncertainties of the individual models. Patient-to-patient transfer was\ninvestigated using patient-specific fine-tuning. Results In this study, a\nweighted average ensemble network of UNet and ErfNet was best suited for the\nsegmentation of laryngeal soft tissue with a mean IoU of 84.7 %. The highest\nefficiency was achieved by ENet with a mean inference time of 9.22 ms per\nimage. It is shown that 10 additional images from a new patient are sufficient\nfor patient-specific fine-tuning. Conclusion CNN-based methods for semantic\nsegmentation are applicable to endoscopic images of laryngeal soft tissue. The\nsegmentation can be used for active constraints or to monitor morphological\nchanges and autonomously detect pathologies. Further improvements could be\nachieved by using a larger dataset or training the models in a self-supervised\nmanner on additional unlabeled data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 19:56:13 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 18:17:04 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 09:26:26 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 13:42:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Laves", "Max-Heinrich", ""], ["Bicker", "Jens", ""], ["Kahrs", "L\u00fcder A.", ""], ["Ortmaier", "Tobias", ""]]}, {"id": "1807.06083", "submitter": "Yiannis Kanellopoulos Dr.", "authors": "Yiannis Kanellopoulos", "title": "A Model for Evaluating Algorithmic Systems Accountability", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic systems make decisions that have a great impact in our lives. As\nour dependency on them is growing so does the need for transparency and holding\nthem accountable. This paper presents a model for evaluating how transparent\nthese systems are by focusing on their algorithmic part as well as the maturity\nof the organizations that utilize them. We applied this model on a\nclassification algorithm created and utilized by a large financial institution.\nThe results of our analysis indicated that the organization was only partially\nin control of their algorithm and they lacked the necessary benchmark to\ninterpret the deducted results and assess the validity of its inferencing.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 19:12:57 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Kanellopoulos", "Yiannis", ""]]}, {"id": "1807.06093", "submitter": "Rong-Jing Bao", "authors": "Rong-Jing Bao, Hai-Jun Rong, Zhi-Xin Yang, Badong Chen", "title": "Prognostics Estimations with Dynamic States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The health state assessment and remaining useful life (RUL) estimation play\nvery important roles in prognostics and health management (PHM), owing to their\nabilities to reduce the maintenance and improve the safety of machines or\nequipment. However, they generally suffer from this problem of lacking prior\nknowledge to pre-define the exact failure thresholds for a machinery operating\nin a dynamic environment with a high level of uncertainty. In this case,\ndynamic thresholds depicted by the discrete states is a very attractive way to\nestimate the RUL of a dynamic machinery. Currently, there are only very few\nworks considering the dynamic thresholds, and these studies adopted different\nalgorithms to determine the discrete states and predict the continuous states\nseparately, which largely increases the complexity of the learning process. In\nthis paper, we propose a novel prognostics approach for RUL estimation of\naero-engines with self-joint prediction of continuous and discrete states,\nwherein the prediction of continuous and discrete states are conducted\nsimultaneously and dynamically within one learning framework.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 20:23:43 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 01:35:59 GMT"}, {"version": "v3", "created": "Sun, 23 Sep 2018 08:14:23 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Bao", "Rong-Jing", ""], ["Rong", "Hai-Jun", ""], ["Yang", "Zhi-Xin", ""], ["Chen", "Badong", ""]]}, {"id": "1807.06101", "submitter": "Frank Ban", "authors": "Frank Ban, Vijay Bhattiprolu, Karl Bringmann, Pavel Kolev, Euiwoong\n  Lee, David P. Woodruff", "title": "A PTAS for $\\ell_p$-Low Rank Approximation", "comments": "Accepted at SODA'19, 65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent works have studied algorithms for entrywise $\\ell_p$-low\nrank approximation, namely, algorithms which given an $n \\times d$ matrix $A$\n(with $n \\geq d$), output a rank-$k$ matrix $B$ minimizing\n$\\|A-B\\|_p^p=\\sum_{i,j}|A_{i,j}-B_{i,j}|^p$ when $p > 0$; and\n$\\|A-B\\|_0=\\sum_{i,j}[A_{i,j}\\neq B_{i,j}]$ for $p=0$.\n  On the algorithmic side, for $p \\in (0,2)$, we give the first\n$(1+\\epsilon)$-approximation algorithm running in time\n$n^{\\text{poly}(k/\\epsilon)}$. Further, for $p = 0$, we give the first\nalmost-linear time approximation scheme for what we call the Generalized Binary\n$\\ell_0$-Rank-$k$ problem. Our algorithm computes $(1+\\epsilon)$-approximation\nin time $(1/\\epsilon)^{2^{O(k)}/\\epsilon^{2}} \\cdot nd^{1+o(1)}$.\n  On the hardness of approximation side, for $p \\in (1,2)$, assuming the Small\nSet Expansion Hypothesis and the Exponential Time Hypothesis (ETH), we show\nthat there exists $\\delta := \\delta(\\alpha) > 0$ such that the entrywise\n$\\ell_p$-Rank-$k$ problem has no $\\alpha$-approximation algorithm running in\ntime $2^{k^{\\delta}}$.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 20:48:13 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 18:12:11 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 00:11:16 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ban", "Frank", ""], ["Bhattiprolu", "Vijay", ""], ["Bringmann", "Karl", ""], ["Kolev", "Pavel", ""], ["Lee", "Euiwoong", ""], ["Woodruff", "David P.", ""]]}, {"id": "1807.06144", "submitter": "Ruggiero Santeramo", "authors": "Ruggiero Santeramo, Samuel Withey, Giovanni Montana", "title": "Longitudinal detection of radiological abnormalities with time-modulated\n  LSTM", "comments": "Submitted to 4th MICCAI Workshop on Deep Learning in Medical Imaging\n  Analysis", "journal-ref": "DLMIA/ML-CDS@MICCAI 2018", "doi": "10.1007/978-3-030-00889-5_37", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been successfully employed in\nrecent years for the detection of radiological abnormalities in medical images\nsuch as plain x-rays. To date, most studies use CNNs on individual examinations\nin isolation and discard previously available clinical information. In this\nstudy we set out to explore whether Long-Short-Term-Memory networks (LSTMs) can\nbe used to improve classification performance when modelling the entire\nsequence of radiographs that may be available for a given patient, including\ntheir reports. A limitation of traditional LSTMs, though, is that they\nimplicitly assume equally-spaced observations, whereas the radiological exams\nare event-based, and therefore irregularly sampled. Using both a simulated\ndataset and a large-scale chest x-ray dataset, we demonstrate that a simple\nmodification of the LSTM architecture, which explicitly takes into account the\ntime lag between consecutive observations, can boost classification\nperformance. Our empirical results demonstrate improved detection of commonly\nreported abnormalities on chest x-rays such as cardiomegaly, consolidation,\npleural effusion and hiatus hernia.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 22:53:46 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Santeramo", "Ruggiero", ""], ["Withey", "Samuel", ""], ["Montana", "Giovanni", ""]]}, {"id": "1807.06149", "submitter": "Tom Hanika", "authors": "Daniel Borchmann, Tom Hanika, Sergei Obiedkov", "title": "Probably approximately correct learning of Horn envelopes from queries", "comments": "21 pages, 1 figure", "journal-ref": "Discrete Applied Mathematics Volume 273 (2020), Pages 30-42", "doi": "10.1016/j.dam.2019.02.036", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for learning the Horn envelope of an arbitrary domain\nusing an expert, or an oracle, capable of answering certain types of queries\nabout this domain. Attribute exploration from formal concept analysis is a\nprocedure that solves this problem, but the number of queries it may ask is\nexponential in the size of the resulting Horn formula in the worst case. We\nrecall a well-known polynomial-time algorithm for learning Horn formulas with\nmembership and equivalence queries and modify it to obtain a polynomial-time\nprobably approximately correct algorithm for learning the Horn envelope of an\narbitrary domain.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 23:24:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Borchmann", "Daniel", ""], ["Hanika", "Tom", ""], ["Obiedkov", "Sergei", ""]]}, {"id": "1807.06158", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Generative Adversarial Imitation from Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation from observation (IfO) is the problem of learning directly from\nstate-only demonstrations without having access to the demonstrator's actions.\nThe lack of action information both distinguishes IfO from most of the\nliterature in imitation learning, and also sets it apart as a method that may\nenable agents to learn from a large set of previously inapplicable resources\nsuch as internet videos. In this paper, we propose both a general framework for\nIfO approaches and also a new IfO approach based on generative adversarial\nnetworks called generative adversarial imitation from observation (GAIfO). We\nconduct experiments in two different settings: (1) when demonstrations consist\nof low-dimensional, manually-defined state features, and (2) when\ndemonstrations consist of high-dimensional, raw visual data. We demonstrate\nthat our approach performs comparably to classical imitation learning\napproaches (which have access to the demonstrator's actions) and significantly\noutperforms existing imitation from observation methods in high-dimensional\nsimulation environments.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:25:15 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 18:12:35 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 05:08:02 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 04:56:56 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1807.06160", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj", "title": "Layer-wise Relevance Propagation for Explainable Recommendations", "comments": "Accepted in Proceedings of the EARS Workshop at SIGIR 2018", "journal-ref": "Homanga Bharadhwaj. 2018. Layer-wise Relevance Propagation for\n  Explainable Recommendations. In Proceedings of SIGIR 2018 Workshop on\n  ExplainAble Recommendation and Search (EARS'18). ACM, New York, NY, USA", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of explanations in a deep-learning based\nmodel for recommendations by leveraging the technique of layer-wise relevance\npropagation. We use a Deep Convolutional Neural Network to extract relevant\nfeatures from the input images before identifying similarity between the images\nin feature space. Relationships between the images are identified by the model\nand layer-wise relevance propagation is used to infer pixel-level details of\nthe images that may have significantly informed the model's choice. We evaluate\nour method on an Amazon products dataset and demonstrate the efficacy of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:38:31 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bharadhwaj", "Homanga", ""]]}, {"id": "1807.06161", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Shruti Joshi", "title": "Explanations for Temporal Recommendations", "comments": "Accepted at the XAI Workshop in IJCAI/ECAI 2018", "journal-ref": "Homanga Bharadhwaj and Shruti Joshi. \"Explanations for Temporal\n  Recommendations\" IJCAI-18 Workshop on Explainable AI (XAI). 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are an integral part of Artificial Intelligence (AI)\nand have become increasingly important in the growing age of commercialization\nin AI. Deep learning (DL) techniques for recommendation systems (RS) provide\npowerful latent-feature models for effective recommendation but suffer from the\nmajor drawback of being non-interpretable. In this paper we describe a\nframework for explainable temporal recommendations in a DL model. We consider\nan LSTM based Recurrent Neural Network (RNN) architecture for recommendation\nand a neighbourhood-based scheme for generating explanations in the model. We\ndemonstrate the effectiveness of our approach through experiments on the\nNetflix dataset by jointly optimizing for both prediction accuracy and\nexplainability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:38:40 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Joshi", "Shruti", ""]]}, {"id": "1807.06168", "submitter": "Gautam Kamath", "authors": "Gautam Kamath, Christos Tzamos", "title": "Anaconda: A Non-Adaptive Conditional Sampling Algorithm for Distribution\n  Testing", "comments": "SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate distribution testing with access to non-adaptive conditional\nsamples. In the conditional sampling model, the algorithm is given the\nfollowing access to a distribution: it submits a query set $S$ to an oracle,\nwhich returns a sample from the distribution conditioned on being from $S$. In\nthe non-adaptive setting, all query sets must be specified in advance of\nviewing the outcomes.\n  Our main result is the first polylogarithmic-query algorithm for equivalence\ntesting, deciding whether two unknown distributions are equal to or far from\neach other. This is an exponential improvement over the previous best upper\nbound, and demonstrates that the complexity of the problem in this model is\nintermediate to the the complexity of the problem in the standard sampling\nmodel and the adaptive conditional sampling model. We also significantly\nimprove the sample complexity for the easier problems of uniformity and\nidentity testing. For the former, our algorithm requires only $\\tilde O(\\log\nn)$ queries, matching the information-theoretic lower bound up to a $O(\\log\n\\log n)$-factor.\n  Our algorithm works by reducing the problem from $\\ell_1$-testing to\n$\\ell_\\infty$-testing, which enjoys a much cheaper sample complexity.\nNecessitated by the limited power of the non-adaptive model, our algorithm is\nvery simple to state. However, there are significant challenges in the\nanalysis, due to the complex structure of how two arbitrary distributions may\ndiffer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 01:12:23 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 18:47:27 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kamath", "Gautam", ""], ["Tzamos", "Christos", ""]]}, {"id": "1807.06170", "submitter": "Francisco Javier Marmolejo-Coss\\'io", "authors": "Paul W. Goldberg, Francisco J. Marmolejo-Coss\\'io", "title": "Learning Convex Partitions and Computing Game-theoretic Equilibria from\n  Best Response Queries", "comments": "38 pages, 7 figures, second version strengthens lower bound in\n  Theorem 6, adds footnotes with additional comments and fixes typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that an $m$-simplex is partitioned into $n$ convex regions having\ndisjoint interiors and distinct labels, and we may learn the label of any point\nby querying it. The learning objective is to know, for any point in the\nsimplex, a label that occurs within some distance $\\epsilon$ from that point.\nWe present two algorithms for this task: Constant-Dimension Generalised Binary\nSearch (CD-GBS), which for constant $m$ uses $poly(n, \\log \\left(\n\\frac{1}{\\epsilon} \\right))$ queries, and Constant-Region Generalised Binary\nSearch (CR-GBS), which uses CD-GBS as a subroutine and for constant $n$ uses\n$poly(m, \\log \\left( \\frac{1}{\\epsilon} \\right))$ queries.\n  We show via Kakutani's fixed-point theorem that these algorithms provide\nbounds on the best-response query complexity of computing approximate\nwell-supported equilibria of bimatrix games in which one of the players has a\nconstant number of pure strategies. We also partially extend our results to\ngames with multiple players, establishing further query complexity bounds for\ncomputing approximate well-supported equilibria in this setting.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 01:15:48 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 16:07:40 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Goldberg", "Paul W.", ""], ["Marmolejo-Coss\u00edo", "Francisco J.", ""]]}, {"id": "1807.06173", "submitter": "Michael Burkhart", "authors": "Michael C. Burkhart", "title": "A Discriminative Approach to Bayesian Filtering with Applications to\n  Human Neural Decoding", "comments": "Ph.D. dissertation, Brown University, Division of Applied Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stationary state-space model that relates a sequence of hidden states\nand corresponding measurements or observations, Bayesian filtering provides a\nprincipled statistical framework for inferring the posterior distribution of\nthe current state given all measurements up to the present time. For example,\nthe Apollo lunar module implemented a Kalman filter to infer its location from\na sequence of earth-based radar measurements and land safely on the moon.\n  To perform Bayesian filtering, we require a measurement model that describes\nthe conditional distribution of each observation given state. The Kalman filter\ntakes this measurement model to be linear, Gaussian. Here we show how a\nnonlinear, Gaussian approximation to the distribution of state given\nobservation can be used in conjunction with Bayes' rule to build a nonlinear,\nnon-Gaussian measurement model. The resulting approach, called the\nDiscriminative Kalman Filter (DKF), retains fast closed-form updates for the\nposterior. We argue there are many cases where the distribution of state given\nmeasurement is better-approximated as Gaussian, especially when the\ndimensionality of measurements far exceeds that of states and the Bernstein-von\nMises theorem applies. Online neural decoding for brain-computer interfaces\nprovides a motivating example, where filtering incorporates increasingly\ndetailed measurements of neural activity to provide users control over external\ndevices. Within the BrainGate2 clinical trial, the DKF successfully enabled\nthree volunteers with quadriplegia to control an on-screen cursor in real-time\nusing mental imagery alone. Participant \"T9\" used the DKF to type out messages\non a tablet PC.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 01:36:57 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Burkhart", "Michael C.", ""]]}, {"id": "1807.06180", "submitter": "Reza Sohrabi", "authors": "Milad Doostan, Reza Sohrabi, Badrul Chowdhury", "title": "A Data-Driven Approach for Predicting Vegetation-Related Outages in\n  Power Distribution Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel data-driven approach for predicting the number of\nvegetation-related outages that occur in power distribution systems on a\nmonthly basis. In order to develop an approach that is able to successfully\nfulfill this objective, there are two main challenges that ought to be\naddressed. The first challenge is to define the extent of the target area. An\nunsupervised machine learning approach is proposed to overcome this difficulty.\nThe second challenge is to correctly identify the main causes of\nvegetation-related outages and to thoroughly investigate their nature. In this\npaper, these outages are categorized into two main groups: growth-related and\nweather-related outages, and two types of models, namely time series and\nnon-linear machine learning regression models are proposed to conduct the\nprediction tasks, respectively. Moreover, various features that can explain the\nvariability in vegetation-related outages are engineered and employed. Actual\noutage data, obtained from a major utility in the U.S., in addition to\ndifferent types of weather and geographical data are utilized to build the\nproposed approach. Finally, by utilizing various time series models and machine\nlearning methods, a comprehensive case study is carried out to demonstrate how\nthe proposed approach can be used to successfully predict the number of\nvegetation-related outages and to help decision-makers to detect vulnerable\nzones in their systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 02:09:09 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 20:56:05 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Doostan", "Milad", ""], ["Sohrabi", "Reza", ""], ["Chowdhury", "Badrul", ""]]}, {"id": "1807.06190", "submitter": "Orestes Manzanilla-Salazar M.Sc.", "authors": "Orestes Manzanilla-Salazar (1) and Brunilde Sans\\`o (1) ((1)\n  Polytechnique Montr\\'eal)", "title": "Privacy-preserving classifiers recognize shared mobility behaviours from\n  WiFi network imperfect data", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves the concept that it is feasible to accurately recognize\nspecific human mobility shared patterns, based solely on the connection logs\nbetween portable devices and WiFi Access Points (APs), while preserving user's\nprivacy. We gathered data from the Eduroam WiFi network of Polytechnique\nMontreal, making omission of device tracking or physical layer data. The\nbehaviors we chose to detect were the movements associated to the end of an\nacademic class, and the patterns related to the small break periods between\nclasses. Stringent conditions were self-imposed in our experiments. The data is\nknown to have errors noise, and be susceptible to information loss. No\ncountermeasures were adopted to mitigate any of these issues. Data\npre-processing consists of basic statistics that were used in aggregating the\ndata in time intervals. We obtained accuracy values of 93.7 % and 83.3 % (via\nBagged Trees) when recognizing behaviour patterns of breaks between classes and\nend-of-classes, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 02:51:52 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 18:39:56 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Manzanilla-Salazar", "Orestes", ""], ["Sans\u00f2", "Brunilde", ""]]}, {"id": "1807.06214", "submitter": "Jaime Roquero Gimenez", "authors": "Jaime Roquero Gimenez, Amirata Ghorbani, James Zou", "title": "Knockoffs for the mass: new feature importance statistics with false\n  discovery guarantees", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in machine learning and statistics is to identify\nfeatures that causally affect the outcome. This is often impossible to do from\npurely observational data, and a natural relaxation is to identify features\nthat are correlated with the outcome even conditioned on all other observed\nfeatures. For example, we want to identify that smoking really is correlated\nwith cancer conditioned on demographics. The knockoff procedure is a recent\nbreakthrough in statistics that, in theory, can identify truly correlated\nfeatures while guaranteeing that the false discovery is limited. The idea is to\ncreate synthetic data -- knockoffs -- that captures correlations amongst the\nfeatures. However there are substantial computational and practical challenges\nto generating and using knockoffs. This paper makes several key advances that\nenable knockoff application to be more efficient and powerful. We develop an\nefficient algorithm to generate valid knockoffs from Bayesian Networks. Then we\nsystematically evaluate knockoff test statistics and develop new statistics\nwith improved power. The paper combines new mathematical guarantees with\nsystematic experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 04:06:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:47:31 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Gimenez", "Jaime Roquero", ""], ["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "1807.06228", "submitter": "Yao Ming", "authors": "Yao Ming and Huamin Qu and Enrico Bertini", "title": "RuleMatrix: Visualizing and Understanding Classifiers with Rules", "comments": "Accepted by IEEE Conference of Visual Analytics Science and\n  Technology 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing adoption of machine learning techniques, there is a surge of\nresearch interest towards making machine learning systems more transparent and\ninterpretable. Various visualizations have been developed to help model\ndevelopers understand, diagnose, and refine machine learning models. However, a\nlarge number of potential but neglected users are the domain experts with\nlittle knowledge of machine learning but are expected to work with machine\nlearning systems. In this paper, we present an interactive visualization\ntechnique to help users with little expertise in machine learning to\nunderstand, explore and validate predictive models. By viewing the model as a\nblack box, we extract a standardized rule-based knowledge representation from\nits input-output behavior. We design RuleMatrix, a matrix-based visualization\nof rules to help users navigate and verify the rules and the black-box model.\nWe evaluate the effectiveness of RuleMatrix via two use cases and a usability\nstudy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 05:29:10 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ming", "Yao", ""], ["Qu", "Huamin", ""], ["Bertini", "Enrico", ""]]}, {"id": "1807.06302", "submitter": "Alessandro Betti", "authors": "Giuseppe Marra, Dario Zanca, Alessandro Betti, Marco Gori", "title": "Learning Neuron Non-Linearities with Kernel-Based Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of deep neural architectures has been widely supported in\nterms of both experimental and foundational principles. There is also clear\nevidence that the activation function (e.g. the rectifier and the LSTM units)\nplays a crucial role in the complexity of learning. Based on this remark, this\npaper discusses an optimal selection of the neuron non-linearity in a\nfunctional framework that is inspired from classic regularization arguments. It\nis shown that the best activation function is represented by a kernel expansion\nin the training set, that can be effectively approximated over an opportune set\nof points modeling 1-D clusters. The idea can be naturally extended to\nrecurrent networks, where the expressiveness of kernel-based activation\nfunctions turns out to be a crucial ingredient to capture long-term\ndependencies. We give experimental evidence of this property by a set of\nchallenging experiments, where we compare the results with neural architectures\nbased on state of the art LSTM cells.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 09:40:56 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 07:45:30 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Marra", "Giuseppe", ""], ["Zanca", "Dario", ""], ["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1807.06333", "submitter": "Fabio Patrizi", "authors": "Giuseppe De Giacomo and Luca Iocchi and Marco Favorito and Fabio\n  Patrizi", "title": "Foundations for Restraining Bolts: Reinforcement Learning with LTLf/LDLf\n  restraining specifications", "comments": null, "journal-ref": "ICAPS 2019: 128-136", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate on the concept of \"restraining bolt\", envisioned\nin Science Fiction. Specifically we introduce a novel problem in AI. We have\ntwo distinct sets of features extracted from the world, one by the agent and\none by the authority imposing restraining specifications (the \"restraining\nbolt\"). The two sets are apparently unrelated since of interest to independent\nparties, however they both account for (aspects of) the same world. We consider\nthe case in which the agent is a reinforcement learning agent on the first set\nof features, while the restraining bolt is specified logically using linear\ntime logic on finite traces LTLf/LDLf over the second set of features. We show\nformally, and illustrate with examples, that, under general circumstances, the\nagent can learn while shaping its goals to suitably conform (as much as\npossible) to the restraining bolt specifications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 10:51:04 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 11:19:04 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["De Giacomo", "Giuseppe", ""], ["Iocchi", "Luca", ""], ["Favorito", "Marco", ""], ["Patrizi", "Fabio", ""]]}, {"id": "1807.06343", "submitter": "Luigi Carratino", "authors": "Luigi Carratino, Alessandro Rudi, Lorenzo Rosasco", "title": "Learning with SGD and Random Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketching and stochastic gradient methods are arguably the most common\ntechniques to derive efficient large scale learning algorithms. In this paper,\nwe investigate their application in the context of nonparametric statistical\nlearning. More precisely, we study the estimator defined by stochastic gradient\nwith mini batches and random features. The latter can be seen as form of\nnonlinear sketching and used to define approximate kernel methods. The\nconsidered estimator is not explicitly penalized/constrained and regularization\nis implicit. Indeed, our study highlights how different parameters, such as\nnumber of features, iterations, step-size and mini-batch size control the\nlearning properties of the solutions. We do this by deriving optimal finite\nsample bounds, under standard assumptions. The obtained results are\ncorroborated and illustrated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 11:10:10 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 18:44:30 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 10:52:54 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Carratino", "Luigi", ""], ["Rudi", "Alessandro", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1807.06358", "submitter": "Huaibo Huang", "authors": "Huaibo Huang, Zhihang Li, Ran He, Zhenan Sun, Tieniu Tan", "title": "IntroVAE: Introspective Variational Autoencoders for Photographic Image\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel introspective variational autoencoder (IntroVAE) model for\nsynthesizing high-resolution photographic images. IntroVAE is capable of\nself-evaluating the quality of its generated samples and improving itself\naccordingly. Its inference and generator models are jointly trained in an\nintrospective way. On one hand, the generator is required to reconstruct the\ninput images from the noisy outputs of the inference model as normal VAEs. On\nthe other hand, the inference model is encouraged to classify between the\ngenerated and real samples while the generator tries to fool it as GANs. These\ntwo famous generative frameworks are integrated in a simple yet efficient\nsingle-stream architecture that can be trained in a single stage. IntroVAE\npreserves the advantages of VAEs, such as stable training and nice latent\nmanifold. Unlike most other hybrid models of VAEs and GANs, IntroVAE requires\nno extra discriminators, because the inference model itself serves as a\ndiscriminator to distinguish between the generated and real samples.\nExperiments demonstrate that our method produces high-resolution\nphoto-realistic images (e.g., CELEBA images at \\(1024^{2}\\)), which are\ncomparable to or better than the state-of-the-art GANs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 11:37:31 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 13:46:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Huang", "Huaibo", ""], ["Li", "Zhihang", ""], ["He", "Ran", ""], ["Sun", "Zhenan", ""], ["Tan", "Tieniu", ""]]}, {"id": "1807.06362", "submitter": "Jean Michel Loubes", "authors": "Philippe Besse and Eustasio del Barrio and Paula Gordaliza and\n  Jean-Michel Loubes", "title": "Confidence Intervals for Testing Disparate Impact in Fair Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the asymptotic distribution of the major indexes used in the\nstatistical literature to quantify disparate treatment in machine learning. We\naim at promoting the use of confidence intervals when testing the so-called\ngroup disparate impact. We illustrate on some examples the importance of using\nconfidence intervals and not a single value.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 11:48:19 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Besse", "Philippe", ""], ["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1807.06391", "submitter": "Matthias Dorfer", "authors": "Matthias Dorfer and Florian Henkel and Gerhard Widmer", "title": "Learning to Listen, Read, and Follow: Score Following as a Reinforcement\n  Learning Game", "comments": "Published in the Proceedings of the 19th International Society for\n  Music Information Retrieval Conference, Paris, France, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score following is the process of tracking a musical performance (audio) with\nrespect to a known symbolic representation (a score). We start this paper by\nformulating score following as a multimodal Markov Decision Process, the\nmathematical foundation for sequential decision making. Given this formal\ndefinition, we address the score following task with state-of-the-art deep\nreinforcement learning (RL) algorithms such as synchronous advantage actor\ncritic (A2C). In particular, we design multimodal RL agents that simultaneously\nlearn to listen to music, read the scores from images of sheet music, and\nfollow the audio along in the sheet, in an end-to-end fashion. All this\nbehavior is learned entirely from scratch, based on a weak and potentially\ndelayed reward signal that indicates to the agent how close it is to the\ncorrect position in the score. Besides discussing the theoretical advantages of\nthis learning paradigm, we show in experiments that it is in fact superior\ncompared to previously proposed methods for score following in raw sheet music\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 12:49:18 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Dorfer", "Matthias", ""], ["Henkel", "Florian", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1807.06399", "submitter": "Maxwell Nye", "authors": "Maxwell Nye, Andrew Saxe", "title": "Are Efficient Deep Representations Learnable?", "comments": "Presented at ICLR 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many theories of deep learning have shown that a deep network can require\ndramatically fewer resources to represent a given function compared to a\nshallow network. But a question remains: can these efficient representations be\nlearned using current deep learning techniques? In this work, we test whether\nstandard deep learning methods can in fact find the efficient representations\nposited by several theories of deep representation. Specifically, we train deep\nneural networks to learn two simple functions with known efficient solutions:\nthe parity function and the fast Fourier transform. We find that using\ngradient-based optimization, a deep network does not learn the parity function,\nunless initialized very close to a hand-coded exact solution. We also find that\na deep linear neural network does not learn the fast Fourier transform, even in\nthe best-case scenario of infinite training data, unless the weights are\ninitialized very close to the exact hand-coded solution. Our results suggest\nthat not every element of the class of compositional functions can be learned\nefficiently by a deep network, and further restrictions are necessary to\nunderstand what functions are both efficiently representable and learnable.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 13:08:21 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Nye", "Maxwell", ""], ["Saxe", "Andrew", ""]]}, {"id": "1807.06414", "submitter": "Mehdi Ben Lazreg", "authors": "Mehdi Ben Lazreg, Morten Goodwin", "title": "Combining a Context Aware Neural Network with a Denoising Autoencoder\n  for Measuring String Similarities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarities between strings is central for many established and\nfast growing research areas including information retrieval, biology, and\nnatural language processing. The traditional approach for string similarity\nmeasurements is to define a metric over a word space that quantifies and sums\nup the differences between characters in two strings. The state-of-the-art in\nthe area has, surprisingly, not evolved much during the last few decades. The\nmajority of the metrics are based on a simple comparison between character and\ncharacter distributions without consideration for the context of the words.\nThis paper proposes a string metric that encompasses similarities between\nstrings based on (1) the character similarities between the words including.\nNon-Standard and standard spellings of the same words, and (2) the context of\nthe words. Our proposal is a neural network composed of a denoising autoencoder\nand what we call a context encoder specifically designed to find similarities\nbetween the words based on their context. The experimental results show that\nthe resulting metrics succeeds in 85.4\\% of the cases in finding the correct\nversion of a non-standard spelling among the closest words, compared to 63.2\\%\nwith the established Normalised-Levenshtein distance. Besides, we show that\nwords used in similar context are with our approach calculated to be similar\nthan words with different contexts, which is a desirable property missing in\nestablished string metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 12:29:23 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Lazreg", "Mehdi Ben", ""], ["Goodwin", "Morten", ""]]}, {"id": "1807.06446", "submitter": "Haoyu Yang", "authors": "Haoyu Yang, Shuhe Li, Cyrus Tabery, Bingqing Lin, Bei Yu", "title": "Bridging the Gap Between Layout Pattern Sampling and Hotspot Detection\n  via Batch Active Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layout hotpot detection is one of the main steps in modern VLSI design. A\ntypical hotspot detection flow is extremely time consuming due to the\ncomputationally expensive mask optimization and lithographic simulation. Recent\nresearches try to facilitate the procedure with a reduced flow including\nfeature extraction, training set generation and hotspot detection, where\nfeature extraction methods and hotspot detection engines are deeply studied.\nHowever, the performance of hotspot detectors relies highly on the quality of\nreference layout libraries which are costly to obtain and usually predetermined\nor randomly sampled in previous works. In this paper, we propose an active\nlearning-based layout pattern sampling and hotspot detection flow, which\nsimultaneously optimizes the machine learning model and the training set that\naims to achieve similar or better hotspot detection performance with much\nsmaller number of training instances. Experimental results show that our\nproposed method can significantly reduce lithography simulation overhead while\nattaining satisfactory detection accuracy on designs under both DUV and EUV\nlithography technologies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:51:42 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Yang", "Haoyu", ""], ["Li", "Shuhe", ""], ["Tabery", "Cyrus", ""], ["Lin", "Bingqing", ""], ["Yu", "Bei", ""]]}, {"id": "1807.06473", "submitter": "Wen Sun", "authors": "Wen Sun, Alina Beygelzimer, Hal Daum\\'e III, John Langford, Paul\n  Mineiro", "title": "Contextual Memory Trees", "comments": "ICM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and study a Contextual Memory Tree (CMT), a learning memory\ncontroller that inserts new memories into an experience store of unbounded\nsize. It is designed to efficiently query for memories from that store,\nsupporting logarithmic time insertion and retrieval operations. Hence CMT can\nbe integrated into existing statistical learning algorithms as an augmented\nmemory unit without substantially increasing training and inference\ncomputation. Furthermore CMT operates as a reduction to classification,\nallowing it to benefit from advances in representation or architecture. We\ndemonstrate the efficacy of CMT by augmenting existing multi-class and\nmulti-label classification algorithms with CMT and observe statistical\nimprovement. We also test CMT learning on several image-captioning tasks to\ndemonstrate that it performs computationally better than a simple nearest\nneighbors memory system while benefitting from reward learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:36:22 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 16:32:08 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 04:33:19 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sun", "Wen", ""], ["Beygelzimer", "Alina", ""], ["Daum\u00e9", "Hal", "III"], ["Langford", "John", ""], ["Mineiro", "Paul", ""]]}, {"id": "1807.06481", "submitter": "Weiming Feng", "authors": "Weiming Feng, Nisheeth K. Vishnoi, Yitong Yin", "title": "Dynamic Sampling from Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of sampling from a graphical model when\nthe model itself is changing dynamically with time. This problem derives its\ninterest from a variety of inference, learning, and sampling settings in\nmachine learning, computer vision, statistical physics, and theoretical\ncomputer science. While the problem of sampling from a static graphical model\nhas received considerable attention, theoretical works for its dynamic variants\nhave been largely lacking. The main contribution of this paper is an algorithm\nthat can sample dynamically from a broad class of graphical models over\ndiscrete random variables. Our algorithm is parallel and Las Vegas: it knows\nwhen to stop and it outputs samples from the exact distribution. We also\nprovide sufficient conditions under which this algorithm runs in time\nproportional to the size of the update, on general graphical models as well as\nwell-studied specific spin systems. In particular we obtain, for the Ising\nmodel (ferromagnetic or anti-ferromagnetic) and for the hardcore model the\nfirst dynamic sampling algorithms that can handle both edge and vertex updates\n(addition, deletion, change of functions), both efficient within regimes that\nare close to the respective uniqueness regimes, beyond which, even for the\nstatic and approximate sampling, no local algorithms were known or the problem\nitself is intractable. Our dynamic sampling algorithm relies on a local\nresampling algorithm and a new \"equilibrium\" property that is shown to be\nsatisfied by our algorithm at each step, and enables us to prove its\ncorrectness. This equilibrium property is robust enough to guarantee the\ncorrectness of our algorithm, helps us improve bounds on fast convergence on\nspecific models, and should be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:54:06 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 09:18:58 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Feng", "Weiming", ""], ["Vishnoi", "Nisheeth K.", ""], ["Yin", "Yitong", ""]]}, {"id": "1807.06489", "submitter": "Rafid Mahmood", "authors": "Rafid Mahmood, Aaron Babier, Andrea McNiven, Adam Diamant, Timothy C.\n  Y. Chan", "title": "Automated Treatment Planning in Radiation Therapy using Generative\n  Adversarial Networks", "comments": "15 pages. Accepted for publication in PMLR. Presented at Machine\n  Learning for Health Care", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge-based planning (KBP) is an automated approach to radiation therapy\ntreatment planning that involves predicting desirable treatment plans before\nthey are then corrected to deliverable ones. We propose a generative\nadversarial network (GAN) approach for predicting desirable 3D dose\ndistributions that eschews the previous paradigms of site-specific feature\nengineering and predicting low-dimensional representations of the plan.\nExperiments on a dataset of oropharyngeal cancer patients show that our\napproach significantly outperforms previous methods on several clinical\nsatisfaction criteria and similarity metrics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:15:16 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Mahmood", "Rafid", ""], ["Babier", "Aaron", ""], ["McNiven", "Andrea", ""], ["Diamant", "Adam", ""], ["Chan", "Timothy C. Y.", ""]]}, {"id": "1807.06497", "submitter": "Yannik Peeters", "authors": "Yannik Peeters, Arnoud V. den Boer, Michel Mandjes", "title": "Continuous Assortment Optimization with Logit Choice Probabilities under\n  Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider assortment optimization over a continuous spectrum of products\nrepresented by the unit interval, where the seller's problem consists of\ndetermining the optimal subset of products to offer to potential customers. To\ndescribe the relation between assortment and customer choice, we propose a\nprobabilistic choice model that forms the continuous counterpart of the widely\nstudied discrete multinomial logit model. We consider the seller's problem\nunder incomplete information, propose a stochastic-approximation type of\npolicy, and show that its regret -- its performance loss compared to the\noptimal policy -- is only logarithmic in the time horizon. We complement this\nresult by showing a matching lower bound on the regret of any policy, implying\nthat our policy is asymptotically optimal. We then show that adding a capacity\nconstraint significantly changes the structure of the problem: we construct a\npolicy and show that its regret after $T$ time periods is bounded above by a\nconstant times $T^{2/3}$ (up to a logarithmic term); in addition, we show that\nthe regret of any policy is bounded from below by a positive constant times\n$T^{2/3}$, so that also in the capacitated case we obtain asymptotic\noptimality. Numerical illustrations show that our policies outperform or are on\npar with alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:19:51 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 10:28:55 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 16:32:05 GMT"}, {"version": "v4", "created": "Wed, 14 Apr 2021 10:34:00 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Peeters", "Yannik", ""], ["Boer", "Arnoud V. den", ""], ["Mandjes", "Michel", ""]]}, {"id": "1807.06530", "submitter": "Salaheddin Alakkari", "authors": "Salaheddin Alakkari, John Dingliana", "title": "An Acceleration Scheme for Memory Limited, Streaming PCA", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an acceleration scheme for online memory-limited\nPCA methods. Our scheme converges to the first $k>1$ eigenvectors in a single\ndata pass. We provide empirical convergence results of our scheme based on the\nspiked covariance model. Our scheme does not require any predefined parameters\nsuch as the eigengap and hence is well facilitated for streaming data\nscenarios. Furthermore, we apply our scheme to challenging time-varying systems\nwhere online PCA methods fail to converge. Specifically, we discuss a family of\ntime-varying systems that are based on Molecular Dynamics simulations where\nbatch PCA converges to the actual analytic solution of such systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:25:01 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Alakkari", "Salaheddin", ""], ["Dingliana", "John", ""]]}, {"id": "1807.06538", "submitter": "Konno Tomohiko", "authors": "Tomohiko Konno and Michiaki Iwazume", "title": "Cavity Filling: Pseudo-Feature Generation for Multi-Class Imbalanced\n  Data Problems in Deep Learning", "comments": "The slides are available at https://goo.gl/SPsSDh in English and at\n  https://goo.gl/RFHYAa in Japanese. 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we generate pseudo-features based on the multivariate probability\ndistributions obtained from the feature maps in layers of trained deep neural\nnetworks. Further, we augment the minor-class data based on these generated\npseudo-features to overcome the imbalanced data problems. The proposed method,\ni.e., cavity filling, improves the deep learning capabilities in several\nproblems because all the real-world data are observed to be imbalanced.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:34:47 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 02:37:09 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 01:22:27 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 02:45:11 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 08:50:34 GMT"}, {"version": "v6", "created": "Sun, 13 Oct 2019 14:47:42 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Konno", "Tomohiko", ""], ["Iwazume", "Michiaki", ""]]}, {"id": "1807.06540", "submitter": "Konno Tomohiko", "authors": "Tomohiko Konno and Michiaki Iwazume", "title": "Icing on the Cake: An Easy and Quick Post-Learnig Method You Can Try\n  After Deep Learning", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We found an easy and quick post-learning method named \"Icing on the Cake\" to\nenhance a classification performance in deep learning. The method is that we\ntrain only the final classifier again after an ordinary training is done.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:35:51 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Konno", "Tomohiko", ""], ["Iwazume", "Michiaki", ""]]}, {"id": "1807.06555", "submitter": "Minghai Qin", "authors": "Minghai Qin, Dejan Vucinic", "title": "Training Recurrent Neural Networks against Noisy Computations during\n  Inference", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the robustness of recurrent neural networks when the computations\nwithin the network are noisy. One of the motivations for looking into this\nproblem is to reduce the high power cost of conventional computing of neural\nnetwork operations through the use of analog neuromorphic circuits. Traditional\nGPU/CPU-centered deep learning architectures exhibit bottlenecks in\npower-restricted applications, such as speech recognition in embedded systems.\nThe use of specialized neuromorphic circuits, where analog signals passed\nthrough memory-cell arrays are sensed to accomplish matrix-vector\nmultiplications, promises large power savings and speed gains but brings with\nit the problems of limited precision of computations and unavoidable analog\nnoise.\n  In this paper we propose a method, called {\\em Deep Noise Injection\ntraining}, to train RNNs to obtain a set of weights/biases that is much more\nrobust against noisy computation during inference. We explore several RNN\narchitectures, such as vanilla RNN and long-short-term memories (LSTM), and\nshow that after convergence of Deep Noise Injection training the set of trained\nweights/biases has more consistent performance over a wide range of noise\npowers entering the network during inference. Surprisingly, we find that Deep\nNoise Injection training improves overall performance of some networks even for\nnumerically accurate inference.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:03:39 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Qin", "Minghai", ""], ["Vucinic", "Dejan", ""]]}, {"id": "1807.06560", "submitter": "Renato Luiz de Freitas Cunha", "authors": "Ana Paula Appel, Renato L. F. Cunha, Charu C. Aggarwal, Marcela Megumi\n  Terakado", "title": "Using link and content over time for embedding generation in Dynamic\n  Attributed Networks", "comments": "10 pages, 4 figures, published at ECML-PKDD 2018", "journal-ref": null, "doi": "10.1007/978-3-030-10928-8_1", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of combining link, content and temporal\nanalysis for community detection and prediction in evolving networks. Such\ntemporal and content-rich networks occur in many real-life settings, such as\nbibliographic networks and question answering forums. Most of the work in the\nliterature (that uses both content and structure) deals with static snapshots\nof networks, and they do not reflect the dynamic changes occurring over\nmultiple snapshots. Incorporating dynamic changes in the communities into the\nanalysis can also provide useful insights about the changes in the network such\nas the migration of authors across communities. In this work, we propose\nChimera, a shared factorization model that can simultaneously account for graph\nlinks, content, and temporal analysis. This approach works by extracting the\nlatent semantic structure of the network in multidimensional form, but in a way\nthat takes into account the temporal continuity of these embeddings. Such an\napproach simplifies temporal analysis of the underlying network by using the\nembedding as a surrogate. A consequence of this simplification is that it is\nalso possible to use this temporal sequence of embeddings to predict future\ncommunities. We present experimental results illustrating the effectiveness of\nthe approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:09:08 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 21:05:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Appel", "Ana Paula", ""], ["Cunha", "Renato L. F.", ""], ["Aggarwal", "Charu C.", ""], ["Terakado", "Marcela Megumi", ""]]}, {"id": "1807.06572", "submitter": "Corey Hudson", "authors": "Leanne S. Whitmore, Anthe George, Corey M. Hudson", "title": "Explicating feature contribution using Random Forest proximity distances", "comments": "Presented at IJCAI/ECAI 2018 Workshop on Explainable Artificial\n  Intelligence (XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Random Forests, proximity distances are a metric representation of data\ninto decision space. By observing how changes in input map to the movement of\ninstances in this space we are able to determine the independent contribution\nof each feature to the decision-making process. For binary feature vectors,\nthis process is fully specified. As these changes in input move particular\ninstances nearer to the in-group or out-group, the independent contribution of\neach feature can be uncovered. Using this technique, we are able to calculate\nthe contribution of each feature in determining how black-box decisions were\nmade. This allows explication of the decision-making process, audit of the\nclassifier, and post-hoc analysis of errors in classification.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:25:32 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Whitmore", "Leanne S.", ""], ["George", "Anthe", ""], ["Hudson", "Corey M.", ""]]}, {"id": "1807.06574", "submitter": "John Halloran", "authors": "Rishabh Iyer, John T. Halloran, Kai Wei", "title": "Jensen: An Easily-Extensible C++ Toolkit for Production-Level Machine\n  Learning and Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Jensen, an easily extensible and scalable toolkit for\nproduction-level machine learning and convex optimization. Jensen implements a\nframework of convex (or loss) functions, convex optimization algorithms\n(including Gradient Descent, L-BFGS, Stochastic Gradient Descent, Conjugate\nGradient, etc.), and a family of machine learning classifiers and regressors\n(Logistic Regression, SVMs, Least Square Regression, etc.). This framework\nmakes it possible to deploy and train models with a few lines of code, and also\nextend and build upon this by integrating new loss functions and optimization\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:31:59 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Iyer", "Rishabh", ""], ["Halloran", "John T.", ""], ["Wei", "Kai", ""]]}, {"id": "1807.06576", "submitter": "YeongHyeon Park", "authors": "YeongHyeon Park, Il Dong Yun", "title": "Comparison of RNN Encoder-Decoder Models for Anomaly Detection", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare different types of Recurrent Neural Network (RNN)\nEncoder-Decoders in anomaly detection viewpoint. We focused on finding the\nmodel that can learn the same data more effectively. We compared multiple\nmodels under the same conditions, such as the number of parameters, optimizer,\nand learning rate. However, the difference is whether to predict the future\nsequence or restore the current sequence. We constructed the dataset with\nsimple vectors and used them for the experiment. Finally, we experimentally\nconfirmed that the model performs better when the model restores the current\nsequence, rather than predict the future sequence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:35:08 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 05:56:28 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Park", "YeongHyeon", ""], ["Yun", "Il Dong", ""]]}, {"id": "1807.06610", "submitter": "Davis Liang", "authors": "Davis Liang, Zhiheng Huang, Zachary C. Lipton", "title": "Learning Noise-Invariant Representations for Robust Speech Recognition", "comments": "Under Review at IEEE SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite rapid advances in speech recognition, current models remain brittle\nto superficial perturbations to their inputs. Small amounts of noise can\ndestroy the performance of an otherwise state-of-the-art model. To harden\nmodels against background noise, practitioners often perform data augmentation,\nadding artificially-noised examples to the training set, carrying over the\noriginal label. In this paper, we hypothesize that a clean example and its\nsuperficially perturbed counterparts shouldn't merely map to the same class ---\nthey should map to the same representation. We propose\ninvariant-representation-learning (IRL): At each training iteration, for each\ntraining example,we sample a noisy counterpart. We then apply a penalty term to\ncoerce matched representations at each layer (above some chosen layer). Our key\nresults, demonstrated on the Librispeech dataset are the following: (i) IRL\nsignificantly reduces character error rates (CER) on both 'clean' (3.3% vs\n6.5%) and 'other' (11.0% vs 18.1%) test sets; (ii) on several out-of-domain\nnoise settings (different from those seen during training), IRL's benefits are\neven more pronounced. Careful ablations confirm that our results are not simply\ndue to shrinking activations at the chosen layers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 18:15:14 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Liang", "Davis", ""], ["Huang", "Zhiheng", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1807.06613", "submitter": "Maximilian H\\\"uttenrauch", "authors": "Maximilian H\\\"uttenrauch, Adrian \\v{S}o\\v{s}i\\'c, Gerhard Neumann", "title": "Deep Reinforcement Learning for Swarm Systems", "comments": "31 pages, 12 figures, version 3 (published in JMLR Volume 20)", "journal-ref": "Journal of Machine Learning Research 20(54):1-31, 2019", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep reinforcement learning (RL) methods have been applied\nsuccessfully to multi-agent scenarios. Typically, these methods rely on a\nconcatenation of agent states to represent the information content required for\ndecentralized decision making. However, concatenation scales poorly to swarm\nsystems with a large number of homogeneous agents as it does not exploit the\nfundamental properties inherent to these systems: (i) the agents in the swarm\nare interchangeable and (ii) the exact number of agents in the swarm is\nirrelevant. Therefore, we propose a new state representation for deep\nmulti-agent RL based on mean embeddings of distributions. We treat the agents\nas samples of a distribution and use the empirical mean embedding as input for\na decentralized policy. We define different feature spaces of the mean\nembedding using histograms, radial basis functions and a neural network learned\nend-to-end. We evaluate the representation on two well known problems from the\nswarm literature (rendezvous and pursuit evasion), in a globally and locally\nobservable setup. For the local setup we furthermore introduce simple\ncommunication protocols. Of all approaches, the mean embedding representation\nusing neural network features enables the richest information exchange between\nneighboring agents facilitating the development of more complex collective\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 18:27:03 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 13:57:21 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 10:27:01 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1807.06629", "submitter": "Hao Yu", "authors": "Hao Yu and Sen Yang and Shenghuo Zhu", "title": "Parallel Restarted SGD with Faster Convergence and Less Communication:\n  Demystifying Why Model Averaging Works for Deep Learning", "comments": "No change has been made on the technical proof since V1. V2 changes\n  the title to emphasize its value in deep learning; polishes the writing; and\n  adds numerical simulations. This version further corrects a few typos in V2\n  posted a few days ago. A short version of this paper is accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed training of deep neural networks, parallel mini-batch SGD is\nwidely used to speed up the training process by using multiple workers. It uses\nmultiple workers to sample local stochastic gradient in parallel, aggregates\nall gradients in a single server to obtain the average, and update each\nworker's local model using a SGD update with the averaged gradient. Ideally,\nparallel mini-batch SGD can achieve a linear speed-up of the training time\n(with respect to the number of workers) compared with SGD over a single worker.\nHowever, such linear scalability in practice is significantly limited by the\ngrowing demand for gradient communication as more workers are involved. Model\naveraging, which periodically averages individual models trained over parallel\nworkers, is another common practice used for distributed training of deep\nneural networks since (Zinkevich et al. 2010) (McDonald, Hall, and Mann 2010).\nCompared with parallel mini-batch SGD, the communication overhead of model\naveraging is significantly reduced. Impressively, tremendous experimental works\nhave verified that model averaging can still achieve a good speed-up of the\ntraining time as long as the averaging interval is carefully controlled.\nHowever, it remains a mystery in theory why such a simple heuristic works so\nwell. This paper provides a thorough and rigorous theoretical study on why\nmodel averaging can work as well as parallel mini-batch SGD with significantly\nless communication overhead.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 19:14:17 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 09:09:49 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 07:57:46 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Yu", "Hao", ""], ["Yang", "Sen", ""], ["Zhu", "Shenghuo", ""]]}, {"id": "1807.06630", "submitter": "Balint Daroczy", "authors": "B\\'alint Dar\\'oczy, Rita Aleksziev, Andr\\'as Bencz\\'ur", "title": "Expressive power of outer product manifolds on feed-forward neural\n  networks", "comments": "11 pages, 8 figures, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical neural networks are exponentially more efficient than their\ncorresponding \"shallow\" counterpart with the same expressive power, but involve\nhuge number of parameters and require tedious amounts of training. Our main\nidea is to mathematically understand and describe the hierarchical structure of\nfeedforward neural networks by reparametrization invariant Riemannian metrics.\nBy computing or approximating the tangent subspace, we better utilize the\noriginal network via sparse representations that enables switching to shallow\nnetworks after a very early training stage. Our experiments show that the\nproposed approximation of the metric improves and sometimes even surpasses the\nachievable performance of the original network significantly even after a few\nepochs of training the original feedforward network.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 19:19:29 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Dar\u00f3czy", "B\u00e1lint", ""], ["Aleksziev", "Rita", ""], ["Bencz\u00far", "Andr\u00e1s", ""]]}, {"id": "1807.06650", "submitter": "Tim Sainburg", "authors": "Tim Sainburg, Marvin Thielk, Brad Theilman, Benjamin Migliori, Timothy\n  Gentner", "title": "Generative adversarial interpolative autoencoding: adversarial training\n  on latent space interpolations encourage convex latent distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural network architecture based upon the Autoencoder (AE) and\nGenerative Adversarial Network (GAN) that promotes a convex latent distribution\nby training adversarially on latent space interpolations. By using an AE as\nboth the generator and discriminator of a GAN, we pass a pixel-wise error\nfunction across the discriminator, yielding an AE which produces non-blurry\nsamples that match both high- and low-level features of the original images.\nInterpolations between images in this space remain within the latent-space\ndistribution of real images as trained by the discriminator, and therfore\npreserve realistic resemblances to the network inputs. Code available at\nhttps://github.com/timsainb/GAIA\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:12:59 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 01:10:26 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 23:39:44 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Sainburg", "Tim", ""], ["Thielk", "Marvin", ""], ["Theilman", "Brad", ""], ["Migliori", "Benjamin", ""], ["Gentner", "Timothy", ""]]}, {"id": "1807.06651", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Kevin Raji Cherian, Ananth Ravi Narayan, Jie\n  Yuan, Da Tang, Tony Jebara", "title": "Item Recommendation with Variational Autoencoders and Heterogenous\n  Priors", "comments": "Accepted for the 3rd Workshop on Deep Learning for Recommender\n  Systems (DLRS 2018), held in conjunction with the 12th ACM Conference on\n  Recommender Systems (RecSys 2018) in Vancouver, Canada", "journal-ref": null, "doi": "10.1145/3270323.327032", "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Variational Autoencoders (VAEs) have been shown to be highly\neffective in both standard collaborative filtering applications and extensions\nsuch as incorporation of implicit feedback. We extend VAEs to collaborative\nfiltering with side information, for instance when ratings are combined with\nexplicit text feedback from the user. Instead of using a user-agnostic standard\nGaussian prior, we incorporate user-dependent priors in the latent VAE space to\nencode users' preferences as functions of the review text. Taking into account\nboth the rating and the text information to represent users in this multimodal\nlatent space is promising to improve recommendation quality. Our proposed model\nis shown to outperform the existing VAE models for collaborative filtering (up\nto 29.41% relative improvement in ranking metric) along with other baselines\nthat incorporate both user ratings and text for item recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:14:02 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 03:54:31 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Cherian", "Kevin Raji", ""], ["Narayan", "Ananth Ravi", ""], ["Yuan", "Jie", ""], ["Tang", "Da", ""], ["Jebara", "Tony", ""]]}, {"id": "1807.06653", "submitter": "Xu Ji", "authors": "Xu Ji, Jo\\~ao F. Henriques, Andrea Vedaldi", "title": "Invariant Information Clustering for Unsupervised Image Classification\n  and Segmentation", "comments": "International Conference on Computer Vision 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel clustering objective that learns a neural network\nclassifier from scratch, given only unlabelled data samples. The model\ndiscovers clusters that accurately match semantic classes, achieving\nstate-of-the-art results in eight unsupervised clustering benchmarks spanning\nimage classification and segmentation. These include STL10, an unsupervised\nvariant of ImageNet, and CIFAR10, where we significantly beat the accuracy of\nour closest competitors by 6.6 and 9.5 absolute percentage points respectively.\nThe method is not specialised to computer vision and operates on any paired\ndataset samples; in our experiments we use random transforms to obtain a pair\nfrom each image. The trained network directly outputs semantic labels, rather\nthan high dimensional representations that need external processing to be\nusable for semantic clustering. The objective is simply to maximise mutual\ninformation between the class assignments of each pair. It is easy to implement\nand rigorously grounded in information theory, meaning we effortlessly avoid\ndegenerate solutions that other clustering methods are susceptible to. In\naddition to the fully unsupervised mode, we also test two semi-supervised\nsettings. The first achieves 88.8% accuracy on STL10 classification, setting a\nnew global state-of-the-art over all existing methods (whether supervised,\nsemi-supervised or unsupervised). The second shows robustness to 90% reductions\nin label coverage, of relevance to applications that wish to make use of small\namounts of labels. github.com/xu-ji/IIC\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:17:29 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 23:06:58 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 00:44:00 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2019 14:32:16 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Ji", "Xu", ""], ["Henriques", "Jo\u00e3o F.", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1807.06656", "submitter": "Leo Duan", "authors": "Leo L. Duan, Xia Wang, Rhonda D. Szczesniak", "title": "Mixed-Stationary Gaussian Process for Flexible Non-Stationary Modeling\n  of Spatial Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are commonplace in spatial statistics. Although many\nnon-stationary models have been developed, there is arguably a lack of\nflexibility compared to equipping each location with its own parameters.\nHowever, the latter suffers from intractable computation and can lead to\noverfitting. Taking the instantaneous stationarity idea, we construct a\nnon-stationary GP with the stationarity parameter individually set at each\nlocation. Then we utilize the non-parametric mixture model to reduce the\neffective number of unique parameters. Different from a simple mixture of\nindependent GPs, the mixture in stationarity allows the components to be\nspatial correlated, leading to improved prediction efficiency. Theoretical\nproperties are examined and a linearly scalable algorithm is provided. The\napplication is shown through several simulated scenarios as well as the massive\nspatiotemporally correlated temperature data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:21:27 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Duan", "Leo L.", ""], ["Wang", "Xia", ""], ["Szczesniak", "Rhonda D.", ""]]}, {"id": "1807.06657", "submitter": "Alejandro Mottini", "authors": "Alejandro Mottini, Alix Lheritier, Rodrigo Acuna-Agost", "title": "Airline Passenger Name Record Generation using Generative Adversarial\n  Networks", "comments": "ICML 2018 - workshop on Theoretical Foundations and Applications of\n  Deep Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Passenger Name Records (PNRs) are at the heart of the travel industry.\nCreated when an itinerary is booked, they contain travel and passenger\ninformation. It is usual for airlines and other actors in the industry to\ninter-exchange and access each other's PNR, creating the challenge of using\nthem without infringing data ownership laws. To address this difficulty, we\npropose a method to generate realistic synthetic PNRs using Generative\nAdversarial Networks (GANs). Unlike other GAN applications, PNRs consist of\ncategorical and numerical features with missing/NaN values, which makes the use\nof GANs challenging. We propose a solution based on Cram\\'{e}r GANs,\ncategorical feature embedding and a Cross-Net architecture. The method was\ntested on a real PNR dataset, and evaluated in terms of distribution matching,\nmemorization, and performance of predictive models for two real business\nproblems: client segmentation and passenger nationality prediction. Results\nshow that the generated data matches well with the real PNRs without memorizing\nthem, and that it can be used to train models for real business applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:22:15 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Mottini", "Alejandro", ""], ["Lheritier", "Alix", ""], ["Acuna-Agost", "Rodrigo", ""]]}, {"id": "1807.06667", "submitter": "Samvit Jain", "authors": "Samvit Jain, Xin Wang, Joseph Gonzalez", "title": "Accel: A Corrective Fusion Network for Efficient Semantic Segmentation\n  on Video", "comments": "CVPR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Accel, a novel semantic video segmentation system that achieves\nhigh accuracy at low inference cost by combining the predictions of two network\nbranches: (1) a reference branch that extracts high-detail features on a\nreference keyframe, and warps these features forward using frame-to-frame\noptical flow estimates, and (2) an update branch that computes features of\nadjustable quality on the current frame, performing a temporal update at each\nvideo frame. The modularity of the update branch, where feature subnetworks of\nvarying layer depth can be inserted (e.g. ResNet-18 to ResNet-101), enables\noperation over a new, state-of-the-art accuracy-throughput trade-off spectrum.\nOver this curve, Accel models achieve both higher accuracy and faster inference\ntimes than the closest comparable single-frame segmentation networks. In\ngeneral, Accel significantly outperforms previous work on efficient semantic\nvideo segmentation, correcting warping-related error that compounds on datasets\nwith complex dynamics. Accel is end-to-end trainable and highly modular: the\nreference network, the optical flow network, and the update network can each be\nselected independently, depending on application requirements, and then jointly\nfine-tuned. The result is a robust, general system for fast, high-accuracy\nsemantic segmentation on video.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:45:23 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 03:28:11 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 23:47:24 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 20:36:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jain", "Samvit", ""], ["Wang", "Xin", ""], ["Gonzalez", "Joseph", ""]]}, {"id": "1807.06689", "submitter": "Nick Hynes", "authors": "Nick Hynes, Raymond Cheng, Dawn Song", "title": "Efficient Deep Learning on Multi-Source Private Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models benefit from large and diverse datasets. Using such\ndatasets, however, often requires trusting a centralized data aggregator. For\nsensitive applications like healthcare and finance this is undesirable as it\ncould compromise patient privacy or divulge trade secrets. Recent advances in\nsecure and privacy-preserving computation, including trusted hardware enclaves\nand differential privacy, offer a way for mutually distrusting parties to\nefficiently train a machine learning model without revealing the training data.\nIn this work, we introduce Myelin, a deep learning framework which combines\nthese privacy-preservation primitives, and use it to establish a baseline level\nof performance for fully private machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 22:18:19 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Hynes", "Nick", ""], ["Cheng", "Raymond", ""], ["Song", "Dawn", ""]]}, {"id": "1807.06696", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu, Wee Sun Lee", "title": "Integrating Algorithmic Planning and Deep Learning for Partially\n  Observable Navigation", "comments": "MLPC workshop, ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to take a novel approach to robot system design where each\nbuilding block of a larger system is represented as a differentiable program,\ni.e. a deep neural network. This representation allows for integrating\nalgorithmic planning and deep learning in a principled manner, and thus combine\nthe benefits of model-free and model-based methods. We apply the proposed\napproach to a challenging partially observable robot navigation task. The robot\nmust navigate to a goal in a previously unseen 3-D environment without knowing\nits initial location, and instead relying on a 2-D floor map and visual\nobservations from an onboard camera. We introduce the Navigation Networks\n(NavNets) that encode state estimation, planning and acting in a single,\nend-to-end trainable recurrent neural network. In preliminary simulation\nexperiments we successfully trained navigation networks to solve the\nchallenging partially observable navigation task.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 22:51:14 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1807.06699", "submitter": "Kai Arulkumaran", "authors": "Ryutaro Tanno, Kai Arulkumaran, Daniel C. Alexander, Antonio\n  Criminisi, Aditya Nori", "title": "Adaptive Neural Trees", "comments": "International Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks and decision trees operate on largely separate\nparadigms; typically, the former performs representation learning with\npre-specified architectures, while the latter is characterised by learning\nhierarchies over pre-specified features with data-driven architectures. We\nunite the two via adaptive neural trees (ANTs) that incorporates representation\nlearning into edges, routing functions and leaf nodes of a decision tree, along\nwith a backpropagation-based training algorithm that adaptively grows the\narchitecture from primitive modules (e.g., convolutional layers). We\ndemonstrate that, whilst achieving competitive performance on classification\nand regression datasets, ANTs benefit from (i) lightweight inference via\nconditional computation, (ii) hierarchical separation of features useful to the\ntask e.g. learning meaningful class associations, such as separating natural\nvs. man-made objects, and (iii) a mechanism to adapt the architecture to the\nsize and complexity of the training dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 23:01:35 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 20:36:03 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 12:24:20 GMT"}, {"version": "v4", "created": "Wed, 13 Feb 2019 16:00:57 GMT"}, {"version": "v5", "created": "Sun, 9 Jun 2019 19:32:34 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tanno", "Ryutaro", ""], ["Arulkumaran", "Kai", ""], ["Alexander", "Daniel C.", ""], ["Criminisi", "Antonio", ""], ["Nori", "Aditya", ""]]}, {"id": "1807.06711", "submitter": "Daniel Luckett", "authors": "Daniel J. Luckett, Eric B. Laber, Samer S. El-Kamary, Cheng Fan, Ravi\n  Jhaveri, Charles M. Perou, Fatma M. Shebl, and Michael R. Kosorok", "title": "Receiver Operating Characteristic Curves and Confidence Bands for\n  Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems that appear in biomedical decision making, such as diagnosing\ndisease and predicting response to treatment, can be expressed as binary\nclassification problems. The costs of false positives and false negatives vary\nacross application domains and receiver operating characteristic (ROC) curves\nprovide a visual representation of this trade-off. Nonparametric estimators for\nthe ROC curve, such as a weighted support vector machine (SVM), are desirable\nbecause they are robust to model misspecification. While weighted SVMs have\ngreat potential for estimating ROC curves, their theoretical properties were\nheretofore underdeveloped. We propose a method for constructing confidence\nbands for the SVM ROC curve and provide the theoretical justification for the\nSVM ROC curve by showing that the risk function of the estimated decision rule\nis uniformly consistent across the weight parameter. We demonstrate the\nproposed confidence band method and the superior sensitivity and specificity of\nthe weighted SVM compared to commonly used methods in diagnostic medicine using\nsimulation studies. We present two illustrative examples: diagnosis of\nhepatitis C and a predictive model for treatment response in breast cancer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 23:54:44 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Luckett", "Daniel J.", ""], ["Laber", "Eric B.", ""], ["El-Kamary", "Samer S.", ""], ["Fan", "Cheng", ""], ["Jhaveri", "Ravi", ""], ["Perou", "Charles M.", ""], ["Shebl", "Fatma M.", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "1807.06712", "submitter": "Mike Ludkovski", "authors": "Xiong Lyu, Mickael Binois, Michael Ludkovski", "title": "Evaluating Gaussian Process Metamodels and Sequential Designs for Noisy\n  Level Set Estimation", "comments": "8 figures. Major update compared to v1 including multiple new\n  sections and new plots. All Tables have been re-done", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the level set for which a noisy black-box\nfunction exceeds a given threshold. To efficiently reconstruct the level set,\nwe investigate Gaussian process (GP) metamodels. Our focus is on strongly\nstochastic samplers, in particular with heavy-tailed simulation noise and low\nsignal-to-noise ratio. To guard against noise misspecification, we assess the\nperformance of three variants: (i) GPs with Student-$t$ observations; (ii)\nStudent-$t$ processes (TPs); and (iii) classification GPs modeling the sign of\nthe response. In conjunction with these metamodels, we analyze several\nacquisition functions for guiding the sequential experimental designs,\nextending existing stepwise uncertainty reduction criteria to the stochastic\ncontour-finding context. This also motivates our development of (approximate)\nupdating formulas to efficiently compute such acquisition functions. Our\nschemes are benchmarked by using a variety of synthetic experiments in 1--6\ndimensions. We also consider an application of level set estimation for\ndetermining the optimal exercise policy of Bermudan options in finance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 00:06:12 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 03:47:23 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lyu", "Xiong", ""], ["Binois", "Mickael", ""], ["Ludkovski", "Michael", ""]]}, {"id": "1807.06713", "submitter": "Matt Barnes", "authors": "Matt Barnes and Artur Dubrawski", "title": "On the Interaction Effects Between Prediction and Clustering", "comments": null, "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019, Volume 89", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems increasingly depend on pipelines of multiple\nalgorithms to provide high quality and well structured predictions. This paper\nargues interaction effects between clustering and prediction (e.g.\nclassification, regression) algorithms can cause subtle adverse behaviors\nduring cross-validation that may not be initially apparent. In particular, we\nfocus on the problem of estimating the out-of-cluster (OOC) prediction loss\ngiven an approximate clustering with probabilistic error rate $p_0$.\nTraditional cross-validation techniques exhibit significant empirical bias in\nthis setting, and the few attempts to estimate and correct for these effects\nare intractable on larger datasets. Further, no previous work has been able to\ncharacterize the conditions under which these empirical effects occur, and if\nthey do, what properties they have. We precisely answer these questions by\nproviding theoretical properties which hold in various settings, and prove that\nexpected out-of-cluster loss behavior rapidly decays with even minor clustering\nerrors. Fortunately, we are able to leverage these same properties to construct\nhypothesis tests and scalable estimators necessary for correcting the problem.\nEmpirical results on benchmark datasets validate our theoretical results and\ndemonstrate how scaling techniques provide solutions to new classes of\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 00:13:31 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 23:20:23 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Barnes", "Matt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1807.06714", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin, Jinfeng Yi, Boqing Gong and Deliang Fan", "title": "Defend Deep Neural Networks Against Adversarial Examples via Fixed and\n  Dynamic Quantized Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep neural networks (DNNs) are vulnerable to\nadversarial attacks. To this end, many defense approaches that attempt to\nimprove the robustness of DNNs have been proposed. In a separate and yet\nrelated area, recent works have explored to quantize neural network weights and\nactivation functions into low bit-width to compress model size and reduce\ncomputational complexity. In this work, we find that these two different\ntracks, namely the pursuit of network compactness and robustness, can be merged\ninto one and give rise to networks of both advantages. To the best of our\nknowledge, this is the first work that uses quantization of activation\nfunctions to defend against adversarial examples. We also propose to train\nrobust neural networks by using adaptive quantization techniques for the\nactivation functions. Our proposed Dynamic Quantized Activation (DQA) is\nverified through a wide range of experiments with the MNIST and CIFAR-10\ndatasets under different white-box attack methods, including FGSM, PGD, and C &\nW attacks. Furthermore, Zeroth Order Optimization and substitute model-based\nblack-box attacks are also considered in this work. The experimental results\nclearly show that the robustness of DNNs could be greatly improved using the\nproposed DQA.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 00:21:12 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 23:54:10 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["Yi", "Jinfeng", ""], ["Gong", "Boqing", ""], ["Fan", "Deliang", ""]]}, {"id": "1807.06722", "submitter": "Abdul Karim", "authors": "Abdul Karim, Avinash Mishra, MA Hakim Newton, Abdul Sattar", "title": "Machine Learning Interpretability: A Science rather than a tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term \"interpretability\" is oftenly used by machine learning researchers\neach with their own intuitive understanding of it. There is no universal well\nagreed upon definition of interpretability in machine learning. As any type of\nscience discipline is mainly driven by the set of formulated questions rather\nthan by different tools in that discipline, e.g. astrophysics is the discipline\nthat learns the composition of stars, not as the discipline that use the\nspectroscopes. Similarly, we propose that machine learning interpretability\nshould be a discipline that answers specific questions related to\ninterpretability. These questions can be of statistical, causal and\ncounterfactual nature. Therefore, there is a need to look into the\ninterpretability problem of machine learning in the context of questions that\nneed to be addressed rather than different tools. We discuss about a\nhypothetical interpretability framework driven by a question based scientific\napproach rather than some specific machine learning model. Using a question\nbased notion of interpretability, we can step towards understanding the science\nof machine learning rather than its engineering. This notion will also help us\nunderstanding any specific problem more in depth rather than relying solely on\nmachine learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 00:50:18 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 07:23:45 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Karim", "Abdul", ""], ["Mishra", "Avinash", ""], ["Newton", "MA Hakim", ""], ["Sattar", "Abdul", ""]]}, {"id": "1807.06732", "submitter": "Justin Gilmer", "authors": "Justin Gilmer, Ryan P. Adams, Ian Goodfellow, David Andersen, George\n  E. Dahl", "title": "Motivating the Rules of the Game for Adversarial Example Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning have led to broad deployment of systems with\nimpressive performance on important problems. Nonetheless, these systems can be\ninduced to make errors on data that are surprisingly similar to examples the\nlearned system handles correctly. The existence of these errors raises a\nvariety of questions about out-of-sample generalization and whether bad actors\nmight use such examples to abuse deployed systems. As a result of these\nsecurity concerns, there has been a flurry of recent papers proposing\nalgorithms to defend against such malicious perturbations of correctly handled\nexamples. It is unclear how such misclassifications represent a different kind\nof security problem than other errors, or even other attacker-produced examples\nthat have no specific relationship to an uncorrupted input. In this paper, we\nargue that adversarial example defense papers have, to date, mostly considered\nabstract, toy games that do not relate to any specific security concern.\nFurthermore, defense papers have not yet precisely described all the abilities\nand limitations of attackers that would be relevant in practical security.\nTowards this end, we establish a taxonomy of motivations, constraints, and\nabilities for more plausible adversaries. Finally, we provide a series of\nrecommendations outlining a path forward for future work to more clearly\narticulate the threat model and perform more meaningful evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 01:17:27 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 01:57:37 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Gilmer", "Justin", ""], ["Adams", "Ryan P.", ""], ["Goodfellow", "Ian", ""], ["Andersen", "David", ""], ["Dahl", "George E.", ""]]}, {"id": "1807.06736", "submitter": "Jingxuan Zhang", "authors": "Jing-Xuan Zhang, Zhen-Hua Ling, Li-Rong Dai", "title": "Forward Attention in Sequence-to-sequence Acoustic Modelling for Speech\n  Synthesis", "comments": "5 pages, 3 figures, 2 tables. Published in IEEE International\n  Conference on Acoustics, Speech and Signal Processing 2018 (ICASSP2018)", "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (2018) 4789-4793", "doi": "10.1109/ICASSP.2018.8462020", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a forward attention method for the sequenceto- sequence\nacoustic modeling of speech synthesis. This method is motivated by the nature\nof the monotonic alignment from phone sequences to acoustic sequences. Only the\nalignment paths that satisfy the monotonic condition are taken into\nconsideration at each decoder timestep. The modified attention probabilities at\neach timestep are computed recursively using a forward algorithm. A transition\nagent for forward attention is further proposed, which helps the attention\nmechanism to make decisions whether to move forward or stay at each decoder\ntimestep. Experimental results show that the proposed forward attention method\nachieves faster convergence speed and higher stability than the baseline\nattention method. Besides, the method of forward attention with transition\nagent can also help improve the naturalness of synthetic speech and control the\nspeed of synthetic speech effectively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 01:59:26 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhang", "Jing-Xuan", ""], ["Ling", "Zhen-Hua", ""], ["Dai", "Li-Rong", ""]]}, {"id": "1807.06752", "submitter": "Tong Chen", "authors": "Tong Chen and Wenjia Niu and Yingxiao Xiang and Xiaoxuan Bai and\n  Jiqiang Liu and Zhen Han and Gang Li", "title": "Gradient Band-based Adversarial Training for Generalized Attack Immunity\n  of A3C Path Finding", "comments": "25 pages 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As adversarial attacks pose a serious threat to the security of AI system in\npractice, such attacks have been extensively studied in the context of computer\nvision applications. However, few attentions have been paid to the adversarial\nresearch on automatic path finding. In this paper, we show dominant adversarial\nexamples are effective when targeting A3C path finding, and design a Common\nDominant Adversarial Examples Generation Method (CDG) to generate dominant\nadversarial examples against any given map. In addition, we propose Gradient\nBand-based Adversarial Training, which trained with a single randomly choose\ndominant adversarial example without taking any modification, to realize the\n\"1:N\" attack immunity for generalized dominant adversarial examples. Extensive\nexperimental results show that, the lowest generation precision for CDG\nalgorithm is 91.91%, and the lowest immune precision for Gradient Band-based\nAdversarial Training is 93.89%, which can prove that our method can realize the\ngeneralized attack immunity of A3C path finding with a high confidence.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 02:57:16 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Chen", "Tong", ""], ["Niu", "Wenjia", ""], ["Xiang", "Yingxiao", ""], ["Bai", "Xiaoxuan", ""], ["Liu", "Jiqiang", ""], ["Han", "Zhen", ""], ["Li", "Gang", ""]]}, {"id": "1807.06756", "submitter": "Zhen Li", "authors": "Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Yawei Zhu, and Zhaoxuan\n  Chen", "title": "SySeVR: A Framework for Using Deep Learning to Detect Software\n  Vulnerabilities", "comments": "To be published in IEEE TDSC", "journal-ref": null, "doi": "10.1109/TDSC.2021.3051525", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of software vulnerabilities (or vulnerabilities for short) is\nan important problem that has yet to be tackled, as manifested by the many\nvulnerabilities reported on a daily basis. This calls for machine learning\nmethods for vulnerability detection. Deep learning is attractive for this\npurpose because it alleviates the requirement to manually define features.\nDespite the tremendous success of deep learning in other application domains,\nits applicability to vulnerability detection is not systematically understood.\nIn order to fill this void, we propose the first systematic framework for using\ndeep learning to detect vulnerabilities in C/C++ programs with source code. The\nframework, dubbed Syntax-based, Semantics-based, and Vector Representations\n(SySeVR), focuses on obtaining program representations that can accommodate\nsyntax and semantic information pertinent to vulnerabilities. Our experiments\nwith 4 software products demonstrate the usefulness of the framework: we detect\n15 vulnerabilities that are not reported in the National Vulnerability\nDatabase. Among these 15 vulnerabilities, 7 are unknown and have been reported\nto the vendors, and the other 8 have been \"silently\" patched by the vendors\nwhen releasing newer versions of the pertinent software products.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:26:39 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 01:41:57 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 00:04:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Zhen", ""], ["Zou", "Deqing", ""], ["Xu", "Shouhuai", ""], ["Jin", "Hai", ""], ["Zhu", "Yawei", ""], ["Chen", "Zhaoxuan", ""]]}, {"id": "1807.06757", "submitter": "Vladlen Koltun", "authors": "Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey\n  Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik,\n  Roozbeh Mottaghi, Manolis Savva, and Amir R. Zamir", "title": "On Evaluation of Embodied Navigation Agents", "comments": "Report of a working group on empirical methodology in navigation\n  research. Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Skillful mobile operation in three-dimensional environments is a primary\ntopic of study in Artificial Intelligence. The past two years have seen a surge\nof creative work on navigation. This creative output has produced a plethora of\nsometimes incompatible task definitions and evaluation protocols. To coordinate\nongoing and future research in this area, we have convened a working group to\nstudy empirical methodology in navigation research. The present document\nsummarizes the consensus recommendations of this working group. We discuss\ndifferent problem statements and the role of generalization, present evaluation\nmeasures, and provide standard scenarios that can be used for benchmarking.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:28:02 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Anderson", "Peter", ""], ["Chang", "Angel", ""], ["Chaplot", "Devendra Singh", ""], ["Dosovitskiy", "Alexey", ""], ["Gupta", "Saurabh", ""], ["Koltun", "Vladlen", ""], ["Kosecka", "Jana", ""], ["Malik", "Jitendra", ""], ["Mottaghi", "Roozbeh", ""], ["Savva", "Manolis", ""], ["Zamir", "Amir R.", ""]]}, {"id": "1807.06763", "submitter": "Matthew Schlegel", "authors": "Matthew Schlegel, Andrew Jacobsen, Zaheer Abbas, Andrew Patterson,\n  Adam White, and Martha White", "title": "General Value Function Networks", "comments": "Published in the Journal of Artificial Intelligence Research", "journal-ref": "Journal of Artificial Intelligence Research, 70, 497-543 (2021)", "doi": "10.1613/jair.1.12105", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State construction is important for learning in partially observable\nenvironments. A general purpose strategy for state construction is to learn the\nstate update using a Recurrent Neural Network (RNN), which updates the internal\nstate using the current internal state and the most recent observation. This\ninternal state provides a summary of the observed sequence, to facilitate\naccurate predictions and decision-making. At the same time, specifying and\ntraining RNNs is notoriously tricky, particularly as the common strategy to\napproximate gradients back in time, called truncated Back-prop Through Time\n(BPTT), can be sensitive to the truncation window. Further,\ndomain-expertise--which can usually help constrain the function class and so\nimprove trainability--can be difficult to incorporate into complex recurrent\nunits used within RNNs. In this work, we explore how to use multi-step\npredictions to constrain the RNN and incorporate prior knowledge. In\nparticular, we revisit the idea of using predictions to construct state and\nask: does constraining (parts of) the state to consist of predictions about the\nfuture improve RNN trainability? We formulate a novel RNN architecture, called\na General Value Function Network (GVFN), where each internal state component\ncorresponds to a prediction about the future represented as a value function.\nWe first provide an objective for optimizing GVFNs, and derive several\nalgorithms to optimize this objective. We then show that GVFNs are more robust\nto the truncation level, in many cases only requiring one-step gradient\nupdates.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:51:08 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 03:49:01 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 02:54:31 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 18:50:25 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Schlegel", "Matthew", ""], ["Jacobsen", "Andrew", ""], ["Abbas", "Zaheer", ""], ["Patterson", "Andrew", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1807.06766", "submitter": "Soham De", "authors": "Soham De, Anirbit Mukherjee, Enayat Ullah", "title": "Convergence guarantees for RMSProp and ADAM in non-convex optimization\n  and an empirical comparison to Nesterov acceleration", "comments": "Presented on 14th July 2018 at the ICML Workshop on Modern Trends in\n  Nonconvex Optimization for Machine Learning. In this version, we have made\n  changes to the setup of our Theorem 3.1, and added additional experimental\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RMSProp and ADAM continue to be extremely popular algorithms for training\nneural nets but their theoretical convergence properties have remained unclear.\nFurther, recent work has seemed to suggest that these algorithms have worse\ngeneralization properties when compared to carefully tuned stochastic gradient\ndescent or its momentum variants. In this work, we make progress towards a\ndeeper understanding of ADAM and RMSProp in two ways. First, we provide proofs\nthat these adaptive gradient algorithms are guaranteed to reach criticality for\nsmooth non-convex objectives, and we give bounds on the running time.\n  Next we design experiments to empirically study the convergence and\ngeneralization properties of RMSProp and ADAM against Nesterov's Accelerated\nGradient method on a variety of common autoencoder setups and on VGG-9 with\nCIFAR-10. Through these experiments we demonstrate the interesting sensitivity\nthat ADAM has to its momentum parameter $\\beta_1$. We show that at very high\nvalues of the momentum parameter ($\\beta_1 = 0.99$) ADAM outperforms a\ncarefully tuned NAG on most of our experiments, in terms of getting lower\ntraining and test losses. On the other hand, NAG can sometimes do better when\nADAM's $\\beta_1$ is set to the most commonly used value: $\\beta_1 = 0.9$,\nindicating the importance of tuning the hyperparameters of ADAM to get better\ngeneralization performance.\n  We also report experiments on different autoencoders to demonstrate that NAG\nhas better abilities in terms of reducing the gradient norms, and it also\nproduces iterates which exhibit an increasing trend for the minimum eigenvalue\nof the Hessian of the loss function at the iterates.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:58:02 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 16:44:35 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 21:57:15 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["De", "Soham", ""], ["Mukherjee", "Anirbit", ""], ["Ullah", "Enayat", ""]]}, {"id": "1807.06786", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Kyungyun Lee, Jiyoung Park, Jangyeon Park, Juhan Nam", "title": "Deep Content-User Embedding Model for Music Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning based recommendation systems have been actively\nexplored to solve the cold-start problem using a hybrid approach. However, the\nmajority of previous studies proposed a hybrid model where collaborative\nfiltering and content-based filtering modules are independently trained. The\nend-to-end approach that takes different modality data as input and jointly\ntrains the model can provide better optimization but it has not been fully\nexplored yet. In this work, we propose deep content-user embedding model, a\nsimple and intuitive architecture that combines the user-item interaction and\nmusic audio content. We evaluate the model on music recommendation and music\nauto-tagging tasks. The results show that the proposed model significantly\noutperforms the previous work. We also discuss various directions to improve\nthe proposed model further.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 06:13:15 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Lee", "Jongpil", ""], ["Lee", "Kyungyun", ""], ["Park", "Jiyoung", ""], ["Park", "Jangyeon", ""], ["Nam", "Juhan", ""]]}, {"id": "1807.06819", "submitter": "Byung Cheol Song", "authors": "Seung Hyun Lee, Dae Ha Kim, Byung Cheol Song", "title": "Self-supervised Knowledge Distillation Using Singular Value\n  Decomposition", "comments": "accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve deep neural network (DNN)'s huge training dataset and its high\ncomputation issue, so-called teacher-student (T-S) DNN which transfers the\nknowledge of T-DNN to S-DNN has been proposed. However, the existing T-S-DNN\nhas limited range of use, and the knowledge of T-DNN is insufficiently\ntransferred to S-DNN. To improve the quality of the transferred knowledge from\nT-DNN, we propose a new knowledge distillation using singular value\ndecomposition (SVD). In addition, we define a knowledge transfer as a\nself-supervised task and suggest a way to continuously receive information from\nT-DNN. Simulation results show that a S-DNN with a computational cost of 1/5 of\nthe T-DNN can be up to 1.1\\% better than the T-DNN in terms of classification\naccuracy. Also assuming the same computational cost, our S-DNN outperforms the\nS-DNN driven by the state-of-the-art distillation with a performance advantage\nof 1.79\\%. code is available on https://github.com/sseung0703/SSKD\\_SVD.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 08:52:05 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Lee", "Seung Hyun", ""], ["Kim", "Dae Ha", ""], ["Song", "Byung Cheol", ""]]}, {"id": "1807.06824", "submitter": "Stefan Feuerriegel", "authors": "Stefan Feuerriegel and Helmut Prendinger", "title": "News-based trading strategies", "comments": null, "journal-ref": "Feuerriegel, Stefan, and Helmut Prendinger. \"News-based trading\n  strategies.\" Decision Support Systems 90 (2016): 65-74", "doi": "10.1016/j.dss.2016.06.020", "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The marvel of markets lies in the fact that dispersed information is\ninstantaneously processed and used to adjust the price of goods, services and\nassets. Financial markets are particularly efficient when it comes to\nprocessing information; such information is typically embedded in textual news\nthat is then interpreted by investors. Quite recently, researchers have started\nto automatically determine news sentiment in order to explain stock price\nmovements. Interestingly, this so-called news sentiment works fairly well in\nexplaining stock returns. In this paper, we design trading strategies that\nutilize textual news in order to obtain profits on the basis of novel\ninformation entering the market. We thus propose approaches for automated\ndecision-making based on supervised and reinforcement learning. Altogether, we\ndemonstrate how news-based data can be incorporated into an investment system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 09:08:09 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Feuerriegel", "Stefan", ""], ["Prendinger", "Helmut", ""]]}, {"id": "1807.06906", "submitter": "Arber Zela", "authors": "Arber Zela, Aaron Klein, Stefan Falkner and Frank Hutter", "title": "Towards Automated Deep Learning: Efficient Joint Neural Architecture and\n  Hyperparameter Search", "comments": "11 pages, 3 figures, 3 tables, ICML 2018 AutoML Workshop", "journal-ref": "ICML 2018 AutoML Workshop", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing work on neural architecture search (NAS) tunes hyperparameters\nin a separate post-processing step, we demonstrate that architectural choices\nand other hyperparameter settings interact in a way that can render this\nseparation suboptimal. Likewise, we demonstrate that the common practice of\nusing very few epochs during the main NAS and much larger numbers of epochs\nduring a post-processing step is inefficient due to little correlation in the\nrelative rankings for these two training regimes. To combat both of these\nproblems, we propose to use a recent combination of Bayesian optimization and\nHyperband for efficient joint neural architecture and hyperparameter search.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:11:08 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Zela", "Arber", ""], ["Klein", "Aaron", ""], ["Falkner", "Stefan", ""], ["Hutter", "Frank", ""]]}, {"id": "1807.06918", "submitter": "Joeran Beel", "authors": "Joeran Beel and Barry Smyth and Andrew Collins", "title": "RARD II: The 94 Million Related-Article Recommendation Dataset", "comments": null, "journal-ref": "1st Workshop on Algorithm Selection and Meta-Learning in\n  Information Retrieval (AMIR). 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper is to introduce and describe a new\nrecommender-systems dataset (RARD II). It is based on data from Mr. DLib, a\nrecommender-system as-a-service in the digital library and\nreference-management-software domain. As such, RARD II complements datasets\nfrom other domains such as books, movies, and music. The dataset encompasses\n94m recommendations, delivered in the two years from September 2016 to\nSeptember 2018. The dataset covers an item-space of 24m unique items. RARD II\nprovides a range of rich recommendation data, beyond conventional ratings. For\nexample, in addition to the usual (implicit) ratings matrices, RARD II includes\nthe original recommendation logs, which provide a unique insight into many\naspects of the algorithms that generated the recommendations. The logs enable\nresearchers to conduct various analyses about a real-world recommender system.\nThis includes the evaluation of meta-learning approaches for predicting\nalgorithm performance. In this paper, we summarise the key features of this\ndataset release, describe how it was generated and discuss some of its unique\nfeatures. Compared to its predecessor RARD, RARD II contains 64% more\nrecommendations, 187% more features (algorithms, parameters, and statistics),\n50% more clicks, 140% more documents, and one additional service partner\n(JabRef).\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:27:33 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 08:46:06 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 10:47:36 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Beel", "Joeran", ""], ["Smyth", "Barry", ""], ["Collins", "Andrew", ""]]}, {"id": "1807.06919", "submitter": "Cinjon Resnick", "authors": "Cinjon Resnick, Roberta Raileanu, Sanyam Kapoor, Alexander\n  Peysakhovich, Kyunghyun Cho, Joan Bruna", "title": "Backplay: \"Man muss immer umkehren\"", "comments": "AAAI-19 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) requires a large number of trials to\nlearn a good policy, especially in environments with sparse rewards. We explore\na method to improve the sample efficiency when we have access to\ndemonstrations. Our approach, Backplay, uses a single demonstration to\nconstruct a curriculum for a given task. Rather than starting each training\nepisode in the environment's fixed initial state, we start the agent near the\nend of the demonstration and move the starting point backwards during the\ncourse of training until we reach the initial state. Our contributions are that\nwe analytically characterize the types of environments where Backplay can\nimprove training speed, demonstrate the effectiveness of Backplay both in large\ngrid worlds and a complex four player zero-sum game (Pommerman), and show that\nBackplay compares favorably to other competitive methods known to improve\nsample efficiency. This includes reward shaping, behavioral cloning, and\nreverse curriculum generation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:28:59 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 21:09:36 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 20:13:45 GMT"}, {"version": "v4", "created": "Mon, 31 Dec 2018 15:16:18 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Resnick", "Cinjon", ""], ["Raileanu", "Roberta", ""], ["Kapoor", "Sanyam", ""], ["Peysakhovich", "Alexander", ""], ["Cho", "Kyunghyun", ""], ["Bruna", "Joan", ""]]}, {"id": "1807.06945", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee, Gene Whipps, Prudhvi Gurram and Vahid Tarokh", "title": "Cyclostationary Statistical Models and Algorithms for Anomaly Detection\n  Using Multi-Modal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is proposed to detect anomalies in multi-modal data. A deep\nneural network-based object detector is employed to extract counts of objects\nand sub-events from the data. A cyclostationary model is proposed to model\nregular patterns of behavior in the count sequences. The anomaly detection\nproblem is formulated as a problem of detecting deviations from learned\ncyclostationary behavior. Sequential algorithms are proposed to detect\nanomalies using the proposed model. The proposed algorithms are shown to be\nasymptotically efficient in a well-defined sense. The developed algorithms are\napplied to a multi-modal data consisting of CCTV imagery and social media posts\nto detect a 5K run in New York City.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 14:56:37 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Banerjee", "Taposh", ""], ["Whipps", "Gene", ""], ["Gurram", "Prudhvi", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1807.06956", "submitter": "Daiki Tamada", "authors": "Daiki Tamada, Marie-Luise Kromrey, Hiroshi Onishi, Utaroh Motosugi", "title": "Method for motion artifact reduction using a convolutional neural\n  network for dynamic contrast enhanced MRI of the liver", "comments": "11 pages, 6 figures", "journal-ref": "Magnetic Resonance in Medical Sciences 19.1 (2020): 64-76", "doi": "10.2463/mrms.mp.2018-0156", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To improve the quality of images obtained via dynamic\ncontrast-enhanced MRI (DCE-MRI) that include motion artifacts and blurring\nusing a deep learning approach. Methods: A multi-channel convolutional neural\nnetwork (MARC) based method is proposed for reducing the motion artifacts and\nblurring caused by respiratory motion in images obtained via DCE-MRI of the\nliver. The training datasets for the neural network included images with and\nwithout respiration-induced motion artifacts or blurring, and the distortions\nwere generated by simulating the phase error in k-space. Patient studies were\nconducted using a multi-phase T1-weighted spoiled gradient echo sequence for\nthe liver containing breath-hold failures during data acquisition. The trained\nnetwork was applied to the acquired images to analyze the filtering\nperformance, and the intensities and contrast ratios before and after denoising\nwere compared via Bland-Altman plots. Results: The proposed network was found\nto significantly reduce the magnitude of the artifacts and blurring induced by\nrespiratory motion, and the contrast ratios of the images after processing via\nthe network were consistent with those of the unprocessed images. Conclusion: A\ndeep learning based method for removing motion artifacts in images obtained via\nDCE-MRI in the liver was demonstrated and validated.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:16:31 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 06:09:25 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Tamada", "Daiki", ""], ["Kromrey", "Marie-Luise", ""], ["Onishi", "Hiroshi", ""], ["Motosugi", "Utaroh", ""]]}, {"id": "1807.06957", "submitter": "Peyman Tavallali", "authors": "Peyman Tavallali, Gary B. Doran Jr., Lukas Mandrake", "title": "Discrete linear-complexity reinforcement learning in continuous action\n  spaces for Q-learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we sketch an algorithm that extends the Q-learning\nalgorithms to the continuous action space domain. Our method is based on the\ndiscretization of the action space. Despite the commonly used discretization\nmethods, our method does not increase the discretized problem dimensionality\nexponentially. We will show that our proposed method is linear in complexity\nwhen the discretization is employed. The variant of the Q-learning algorithm\npresented in this work, labeled as Finite Step Q-Learning (FSQ), can be\ndeployed to both shallow and deep neural network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 22:57:11 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 20:14:30 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Tavallali", "Peyman", ""], ["Doran", "Gary B.", "Jr."], ["Mandrake", "Lukas", ""]]}, {"id": "1807.06972", "submitter": "Veronica Morfi", "authors": "Veronica Morfi, Dan Stowell", "title": "Data-Efficient Weakly Supervised Learning for Low-Resource Audio Event\n  Detection Using Deep Learning", "comments": "5 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1807.03697", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a method to perform audio event detection under the common\nconstraint that only limited training data are available. In training a deep\nlearning system to perform audio event detection, two practical problems arise.\nFirstly, most datasets are \"weakly labelled\" having only a list of events\npresent in each recording without any temporal information for training.\nSecondly, deep neural networks need a very large amount of labelled training\ndata to achieve good quality performance, yet in practice it is difficult to\ncollect enough samples for most classes of interest. In this paper, we propose\na data-efficient training of a stacked convolutional and recurrent neural\nnetwork. This neural network is trained in a multi instance learning setting\nfor which we introduce a new loss function that leads to improved training\ncompared to the usual approaches for weakly supervised learning. We\nsuccessfully test our approach on two low-resource datasets that lack temporal\nlabels.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:03:55 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 15:19:02 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Morfi", "Veronica", ""], ["Stowell", "Dan", ""]]}, {"id": "1807.06981", "submitter": "Robin Vogel", "authors": "Robin Vogel, Aur\\'elien Bellet, St\\'ephan Cl\\'emen\\c{c}on", "title": "A Probabilistic Theory of Supervised Similarity Learning for Pointwise\n  ROC Curve Optimization", "comments": "8 pages main paper, 22 pages with appendices, proceedings of ICML\n  2018", "journal-ref": "PMLR 80 (2018) 5062-5071", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many machine learning techniques depends on the choice of\nan appropriate similarity or distance measure on the input space. Similarity\nlearning (or metric learning) aims at building such a measure from training\ndata so that observations with the same (resp. different) label are as close\n(resp. far) as possible. In this paper, similarity learning is investigated\nfrom the perspective of pairwise bipartite ranking, where the goal is to rank\nthe elements of a database by decreasing order of the probability that they\nshare the same label with some query data point, based on the similarity\nscores. A natural performance criterion in this setting is pointwise ROC\noptimization: maximize the true positive rate under a fixed false positive\nrate. We study this novel perspective on similarity learning through a rigorous\nprobabilistic framework. The empirical version of the problem gives rise to a\nconstrained optimization formulation involving U-statistics, for which we\nderive universal learning rates as well as faster rates under a noise\nassumption on the data distribution. We also address the large-scale setting by\nanalyzing the effect of sampling-based approximations. Our theoretical results\nare supported by illustrative numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:47:54 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Vogel", "Robin", ""], ["Bellet", "Aur\u00e9lien", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""]]}, {"id": "1807.07013", "submitter": "Phil Long", "authors": "Anindya De, Philip M. Long and Rocco A. Servedio", "title": "Learning Sums of Independent Random Variables with Sparse Collective\n  Support", "comments": "Conference version in FOCS'18; Journal version to appear in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the learnability of sums of independent integer random variables\ngiven a bound on the size of the union of their supports. For $\\mathcal{A}\n\\subset \\mathbf{Z}_{+}$, a sum of independent random variables with collective\nsupport $\\mathcal{A}$} (called an $\\mathcal{A}$-sum in this paper) is a\ndistribution $\\mathbf{S} = \\mathbf{X}_1 + \\cdots + \\mathbf{X}_N$ where the\n$\\mathbf{X}_i$'s are mutually independent (but not necessarily identically\ndistributed) integer random variables with $\\cup_i \\mathsf{supp}(\\mathbf{X}_i)\n\\subseteq \\mathcal{A}.$ We give two main algorithmic results for learning such\ndistributions:\n  1. For the case $| \\mathcal{A} | = 3$, we give an algorithm for learning\n$\\mathcal{A}$-sums to accuracy $\\epsilon$ that uses $\\mathsf{poly}(1/\\epsilon)$\nsamples and runs in time $\\mathsf{poly}(1/\\epsilon)$, independent of $N$ and of\nthe elements of $\\mathcal{A}$.\n  2. For an arbitrary constant $k \\geq 4$, if $\\mathcal{A} = \\{ a_1,...,a_k\\}$\nwith $0 \\leq a_1 < ... < a_k$, we give an algorithm that uses\n$\\mathsf{poly}(1/\\epsilon) \\cdot \\log \\log a_k$ samples (independent of $N$)\nand runs in time $\\mathsf{poly}(1/\\epsilon, \\log a_k).$\n  We prove an essentially matching lower bound: if $|\\mathcal{A}| = 4$, then\nany algorithm must use $\\Omega(\\log \\log a_4) $ samples even for learning to\nconstant accuracy. We also give similar-in-spirit (but quantitatively very\ndifferent) algorithmic results, and essentially matching lower bounds, for the\ncase in which $\\mathcal{A}$ is not known to the learner.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 16:02:35 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:14:33 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["De", "Anindya", ""], ["Long", "Philip M.", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1807.07023", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Subhendu Roy, Jin Miao, Jiamin Chen, Bei Yu", "title": "Cross-layer Optimization for High Speed Adders: A Pareto Driven Machine\n  Learning Approach", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of maturity to the modern electronic design automation (EDA) tools,\noptimized designs at architectural stage may become sub-optimal after going\nthrough physical design flow. Adder design has been such a long studied\nfundamental problem in VLSI industry yet designers cannot achieve optimal\nsolutions by running EDA tools on the set of available prefix adder\narchitectures. In this paper, we enhance a state-of-the-art prefix adder\nsynthesis algorithm to obtain a much wider solution space in architectural\ndomain. On top of that, a machine learning-based design space exploration\nmethodology is applied to predict the Pareto frontier of the adders in physical\ndomain, which is infeasible by exhaustively running EDA tools for innumerable\narchitectural solutions. Considering the high cost of obtaining the true values\nfor learning, an active learning algorithm is utilized to select the\nrepresentative data during learning process, which uses less labeled data while\nachieving better quality of Pareto frontier. Experimental results demonstrate\nthat our framework can achieve Pareto frontier of high quality over a wide\ndesign space, bridging the gap between architectural and physical designs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 16:23:26 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 04:37:28 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Ma", "Yuzhe", ""], ["Roy", "Subhendu", ""], ["Miao", "Jin", ""], ["Chen", "Jiamin", ""], ["Yu", "Bei", ""]]}, {"id": "1807.07049", "submitter": "Lerrel Pinto Mr", "authors": "Abhinav Gupta, Adithyavairavan Murali, Dhiraj Gandhi, Lerrel Pinto", "title": "Robot Learning in Homes: Improving Generalization and Reducing Dataset\n  Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven approaches to solving robotic tasks have gained a lot of traction\nin recent years. However, most existing policies are trained on large-scale\ndatasets collected in curated lab settings. If we aim to deploy these models in\nunstructured visual environments like people's homes, they will be unable to\ncope with the mismatch in data distribution. In such light, we present the\nfirst systematic effort in collecting a large dataset for robotic grasping in\nhomes. First, to scale and parallelize data collection, we built a low cost\nmobile manipulator assembled for under 3K USD. Second, data collected using low\ncost robots suffer from noisy labels due to imperfect execution and calibration\nerrors. To handle this, we develop a framework which factors out the noise as a\nlatent variable. Our model is trained on 28K grasps collected in several houses\nunder an array of different environmental conditions. We evaluate our models by\nphysically executing grasps on a collection of novel objects in multiple unseen\nhomes. The models trained with our home dataset showed a marked improvement of\n43.7% over a baseline model trained with data collected in lab. Our\narchitecture which explicitly models the latent noise in the dataset also\nperformed 10% better than one that did not factor out the noise. We hope this\neffort inspires the robotics community to look outside the lab and embrace\nlearning based approaches to handle inaccurate cheap robots.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 17:25:28 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Gupta", "Abhinav", ""], ["Murali", "Adithyavairavan", ""], ["Gandhi", "Dhiraj", ""], ["Pinto", "Lerrel", ""]]}, {"id": "1807.07099", "submitter": "Pavel Kharyuk", "authors": "Pavel Kharyuk, Dmitry Nazarenko, Ivan Oseledets", "title": "Comparative study of Discrete Wavelet Transforms and Wavelet Tensor\n  Train decomposition to feature extraction of FTIR data of medicinal plants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier-transform infra-red (FTIR) spectra of samples from 7 plant species\nwere used to explore the influence of preprocessing and feature extraction on\nefficiency of machine learning algorithms. Wavelet Tensor Train (WTT) and\nDiscrete Wavelet Transforms (DWT) were compared as feature extraction\ntechniques for FTIR data of medicinal plants. Various combinations of signal\nprocessing steps showed different behavior when applied to classification and\nclustering tasks. Best results for WTT and DWT found through grid search were\nsimilar, significantly improving quality of clustering as well as\nclassification accuracy for tuned logistic regression in comparison to original\nspectra. Unlike DWT, WTT has only one parameter to be tuned (rank), making it a\nmore versatile and easier to use as a data processing tool in various signal\nprocessing applications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 18:41:23 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Kharyuk", "Pavel", ""], ["Nazarenko", "Dmitry", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1807.07132", "submitter": "Chih-Hao Fang", "authors": "Chih-Hao Fang, Sudhir B Kylasa, Fred Roosta, Michael W. Mahoney,\n  Ananth Grama", "title": "Newton-ADMM: A Distributed GPU-Accelerated Optimizer for Multiclass\n  Classification Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order optimization methods, such as stochastic gradient descent (SGD)\nand its variants, are widely used in machine learning applications due to their\nsimplicity and low per-iteration costs. However, they often require larger\nnumbers of iterations, with associated communication costs in distributed\nenvironments. In contrast, Newton-type methods, while having higher\nper-iteration costs, typically require a significantly smaller number of\niterations, which directly translates to reduced communication costs. In this\npaper, we present a novel distributed optimizer for classification problems,\nwhich integrates a GPU-accelerated Newton-type solver with the global consensus\nformulation of Alternating Direction of Method Multipliers (ADMM). By\nleveraging the communication efficiency of ADMM, GPU-accelerated inexact-Newton\nsolver, and an effective spectral penalty parameter selection strategy, we show\nthat our proposed method (i) yields better generalization performance on\nseveral classification problems; (ii) significantly outperforms\nstate-of-the-art methods in distributed time to solution; and (iii) offers\nbetter scaling on large distributed platforms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 20:18:11 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 17:58:50 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 14:35:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Fang", "Chih-Hao", ""], ["Kylasa", "Sudhir B", ""], ["Roosta", "Fred", ""], ["Mahoney", "Michael W.", ""], ["Grama", "Ananth", ""]]}, {"id": "1807.07147", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov and Ivan P. Yamshchikov", "title": "Guess who? Multilingual approach for the automated generation of\n  author-stylized poetry", "comments": null, "journal-ref": null, "doi": "10.1109/SLT.2018.8639573", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of stylized text generation in a\nmultilingual setup. A version of a language model based on a long short-term\nmemory (LSTM) artificial neural network with extended phonetic and semantic\nembeddings is used for stylized poetry generation. The quality of the resulting\npoems generated by the network is estimated through bilingual evaluation\nunderstudy (BLEU), a survey and a new cross-entropy based metric that is\nsuggested for the problems of such type. The experiments show that the proposed\nmodel consistently outperforms random sample and vanilla-LSTM baselines, humans\nalso tend to associate machine generated texts with the target author.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:13:20 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 21:08:53 GMT"}, {"version": "v3", "created": "Mon, 17 Sep 2018 16:27:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1807.07156", "submitter": "Fahad Panolan", "authors": "Fedor V. Fomin, Petr A. Golovach, Daniel Lokshtanov, Fahad Panolan,\n  Saket Saurabh", "title": "Approximation Schemes for Low-Rank Binary Matrix Approximation Problems", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a randomized linear time approximation scheme for a generic\nproblem about clustering of binary vectors subject to additional constrains.\nThe new constrained clustering problem encompasses a number of problems and by\nsolving it, we obtain the first linear time-approximation schemes for a number\nof well-studied fundamental problems concerning clustering of binary vectors\nand low-rank approximation of binary matrices. Among the problems solvable by\nour approach are \\textsc{Low GF(2)-Rank Approximation}, \\textsc{Low\nBoolean-Rank Approximation}, and various versions of \\textsc{Binary\nClustering}. For example, for \\textsc{Low GF(2)-Rank Approximation} problem,\nwhere for an $m\\times n$ binary matrix $A$ and integer $r>0$, we seek for a\nbinary matrix $B$ of $GF_2$ rank at most $r$ such that $\\ell_0$ norm of matrix\n$A-B$ is minimum, our algorithm, for any $\\epsilon>0$ in time $\nf(r,\\epsilon)\\cdot n\\cdot m$, where $f$ is some computable function, outputs a\n$(1+\\epsilon)$-approximate solution with probability at least\n$(1-\\frac{1}{e})$. Our approximation algorithms substantially improve the\nrunning times and approximation factors of previous works. We also give\n(deterministic) PTASes for these problems running in time\n$n^{f(r)\\frac{1}{\\epsilon^2}\\log \\frac{1}{\\epsilon}}$, where $f$ is some\nfunction depending on the problem. Our algorithm for the constrained clustering\nproblem is based on a novel sampling lemma, which is interesting in its own.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 21:11:35 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""]]}, {"id": "1807.07173", "submitter": "Qiang Hao", "authors": "Qiang Hao, April Galyardt, Bradley Barnes, Robert Maribe Branch, Ewan\n  Wright", "title": "Automatic Identification of Ineffective Online Student Questions in\n  Computing Education", "comments": null, "journal-ref": "Proceedings of IEEE Frontiers in Education (FIE' 18), San Jose,\n  CA, 2018", "doi": "10.1109/FIE.2018.8658642", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Research Full Paper explores automatic identification of ineffective\nlearning questions in the context of large-scale computer science classes. The\nimmediate and accurate identification of ineffective learning questions opens\nthe door to possible automated facilitation on a large scale, such as alerting\nlearners to revise questions and providing adaptive question revision\nsuggestions. To achieve this, 983 questions were collected from a question &\nanswer platform implemented by an introductory programming course over three\nsemesters in a large research university in the Southeastern United States.\nQuestions were firstly manually classified into three hierarchical categories:\n1) learning-irrelevant questions, 2) effective learning-relevant questions, 3)\nineffective learningrelevant questions. The inter-rater reliability of the\nmanual classification (Cohen's Kappa) was .88. Four different machine learning\nalgorithms were then used to automatically classify the questions, including\nNaive Bayes Multinomial, Logistic Regression, Support Vector Machines, and\nBoosted Decision Tree. Both flat and single path strategies were explored, and\nthe most effective algorithms under both strategies were identified and\ndiscussed. This study contributes to the automatic determination of learning\nquestion quality in computer science, and provides evidence for the feasibility\nof automated facilitation of online question & answer in large scale computer\nscience classes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 22:21:19 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 18:10:07 GMT"}, {"version": "v3", "created": "Sun, 10 Mar 2019 19:47:53 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Hao", "Qiang", ""], ["Galyardt", "April", ""], ["Barnes", "Bradley", ""], ["Branch", "Robert Maribe", ""], ["Wright", "Ewan", ""]]}, {"id": "1807.07187", "submitter": "Walid Krichene", "authors": "Walid Krichene, Nicolas Mayoraz, Steffen Rendle, Li Zhang, Xinyang Yi,\n  Lichan Hong, Ed Chi, John Anderson", "title": "Efficient Training on Very Large Corpora via Gramian Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning similarity functions over very large corpora\nusing neural network embedding models. These models are typically trained using\nSGD with sampling of random observed and unobserved pairs, with a number of\nsamples that grows quadratically with the corpus size, making it expensive to\nscale to very large corpora. We propose new efficient methods to train these\nmodels without having to sample unobserved pairs. Inspired by matrix\nfactorization, our approach relies on adding a global quadratic penalty to all\npairs of examples and expressing this term as the matrix-inner-product of two\ngeneralized Gramians. We show that the gradient of this term can be efficiently\ncomputed by maintaining estimates of the Gramians, and develop variance\nreduction schemes to improve the quality of the estimates. We conduct\nlarge-scale experiments that show a significant improvement in training time\nand generalization quality compared to traditional sampling methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 23:45:33 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Krichene", "Walid", ""], ["Mayoraz", "Nicolas", ""], ["Rendle", "Steffen", ""], ["Zhang", "Li", ""], ["Yi", "Xinyang", ""], ["Hong", "Lichan", ""], ["Chi", "Ed", ""], ["Anderson", "John", ""]]}, {"id": "1807.07207", "submitter": "Natalia da Silva", "authors": "Natalia da Silva, Dianne Cook and Eun-Kyung Lee", "title": "A Projection Pursuit Forest Algorithm for Supervised Classification", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics, (2021), 1-13", "doi": "10.1080/10618600.2020.1870480", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new ensemble learning method for classification\nproblems called projection pursuit random forest (PPF). PPF uses the PPtree\nalgorithm introduced in Lee et al. (2013). In PPF, trees are constructed by\nsplitting on linear combinations of randomly chosen variables. Projection\npursuit is used to choose a projection of the variables that best separates the\nclasses. Utilizing linear combinations of variables to separate classes takes\nthe correlation between variables into account which allows PPF to outperform a\ntraditional random forest when separations between groups occurs in\ncombinations of variables.\n  The method presented here can be used in multi-class problems and is\nimplemented into an R (R Core Team, 2018) package, PPforest, which is available\non CRAN, with development versions at https://github.com/natydasilva/PPforest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 01:11:47 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 18:09:29 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["da Silva", "Natalia", ""], ["Cook", "Dianne", ""], ["Lee", "Eun-Kyung", ""]]}, {"id": "1807.07215", "submitter": "Robert Garrard", "authors": "Sarah Cornell-Farrow and Robert Garrard", "title": "Machine Learning Classifiers Do Not Improve the Prediction of Academic\n  Risk: Evidence from Australia", "comments": "15 pages, 2 tables, 6 figures. Note that previous versions of this\n  paper contained an error in our codes. The error has been rectified and the\n  paper substantially rewritten", "journal-ref": null, "doi": "10.1080/23737484.2020.1752849", "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods tend to outperform traditional statistical models at\nprediction. In the prediction of academic achievement, ML models have not shown\nsubstantial improvement over logistic regression. So far, these results have\nalmost entirely focused on college achievement, due to the availability of\nadministrative datasets, and have contained relatively small sample sizes by ML\nstandards. In this article we apply popular machine learning models to a large\ndataset ($n=1.2$ million) containing primary and middle school performance on a\nstandardized test given annually to Australian students. We show that machine\nlearning models do not outperform logistic regression for detecting students\nwho will perform in the `below standard' band of achievement upon sitting their\nnext test, even in a large-$n$ setting.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 02:01:36 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 05:46:13 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 05:28:56 GMT"}, {"version": "v4", "created": "Tue, 28 Jan 2020 05:09:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cornell-Farrow", "Sarah", ""], ["Garrard", "Robert", ""]]}, {"id": "1807.07217", "submitter": "Zining Zhu", "authors": "Zining Zhu, Jekaterina Novikova, Frank Rudzicz", "title": "Deconfounding age effects with fair representation learning when\n  assessing dementia", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most prevalent symptoms among the elderly population, dementia,\ncan be detected by classifiers trained on linguistic features extracted from\nnarrative transcripts. However, these linguistic features are impacted in a\nsimilar but different fashion by the normal aging process. Aging is therefore a\nconfounding factor, whose effects have been hard for machine learning\nclassifiers (especially deep neural network based models) to ignore. We show\nDNN models are capable of estimating ages based on linguistic features.\nPredicting dementia based on this aging bias could lead to potentially\nnon-generalizable accuracies on clinical datasets, if not properly\ndeconfounded.\n  In this paper, we propose to address this deconfounding problem with fair\nrepresentation learning. We build neural network classifiers that learn\nlow-dimensional representations reflecting the impacts of dementia yet\ndiscarding the effects of age. To evaluate these classifiers, we specify a\nmodel-agnostic score $\\Delta_{eo}^{(N)}$ measuring how classifier results are\ndeconfounded from age. Our best models compromise accuracy by only 2.56\\% and\n1.54\\% on two clinical datasets compared to DNNs, and their $\\Delta_{eo}^{(2)}$\nscores are better than statistical (residulization and inverse probability\nweight) adjustments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 02:05:40 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 14:18:23 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 14:39:49 GMT"}, {"version": "v4", "created": "Sat, 7 Sep 2019 14:06:00 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhu", "Zining", ""], ["Novikova", "Jekaterina", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1807.07258", "submitter": "Jindong Wang", "authors": "Jindong Wang and Wenjie Feng and Yiqiang Chen and Han Yu and Meiyu\n  Huang and Philip S. Yu", "title": "Visual Domain Adaptation with Manifold Embedded Distribution Alignment", "comments": "ACM Multimedia conference 2018 (ACM MM) ORAL paper; top 10 papers; 9\n  pages; code available at http://transferlearning.xyz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Visual domain adaptation aims to learn robust classifiers for the target\ndomain by leveraging knowledge from a source domain. Existing methods either\nattempt to align the cross-domain distributions, or perform manifold subspace\nlearning. However, there are two significant challenges: (1) degenerated\nfeature transformation, which means that distribution alignment is often\nperformed in the original feature space, where feature distortions are hard to\novercome. On the other hand, subspace learning is not sufficient to reduce the\ndistribution divergence. (2) unevaluated distribution alignment, which means\nthat existing distribution alignment methods only align the marginal and\nconditional distributions with equal importance, while they fail to evaluate\nthe different importance of these two distributions in real applications. In\nthis paper, we propose a Manifold Embedded Distribution Alignment (MEDA)\napproach to address these challenges. MEDA learns a domain-invariant classifier\nin Grassmann manifold with structural risk minimization, while performing\ndynamic distribution alignment to quantitatively account for the relative\nimportance of marginal and conditional distributions. To the best of our\nknowledge, MEDA is the first attempt to perform dynamic distribution alignment\nfor manifold domain adaptation. Extensive experiments demonstrate that MEDA\nshows significant improvements in classification accuracy compared to\nstate-of-the-art traditional and deep methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 06:45:42 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 08:15:38 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Wang", "Jindong", ""], ["Feng", "Wenjie", ""], ["Chen", "Yiqiang", ""], ["Yu", "Han", ""], ["Huang", "Meiyu", ""], ["Yu", "Philip S.", ""]]}, {"id": "1807.07281", "submitter": "Wei Ping", "authors": "Wei Ping, Kainan Peng, Jitong Chen", "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "comments": "Published at ICLR 2019. (v3: add important details & discussion in\n  Appendix A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new solution for parallel wave generation by\nWaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we\ndistill a Gaussian inverse autoregressive flow from the autoregressive WaveNet\nby minimizing a regularized KL divergence between their highly-peaked output\ndistributions. Our method computes the KL divergence in closed-form, which\nsimplifies the training algorithm and provides very efficient distillation. In\naddition, we introduce the first text-to-wave neural architecture for speech\nsynthesis, which is fully convolutional and enables fast end-to-end training\nfrom scratch. It significantly outperforms the previous pipeline that connects\na text-to-spectrogram model to a separately trained WaveNet (Ping et al.,\n2018). We also successfully distill a parallel waveform synthesizer conditioned\non the hidden representation in this end-to-end model.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:15:41 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 07:34:16 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 00:22:40 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Ping", "Wei", ""], ["Peng", "Kainan", ""], ["Chen", "Jitong", ""]]}, {"id": "1807.07282", "submitter": "Andrey Lavrentyev", "authors": "Dmitry Shalyga, Pavel Filonov, Andrey Lavrentyev", "title": "Anomaly Detection for Water Treatment System based on Neural Network\n  with Automatic Architecture Optimization", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue to develop our neural network (NN) based forecasting approach to\nanomaly detection (AD) using the Secure Water Treatment (SWaT) industrial\ncontrol system (ICS) testbed dataset. We propose genetic algorithms (GA) to\nfind the best NN architecture for a given dataset, using the NAB metric to\nassess the quality of different architectures. The drawbacks of the F1-metric\nare analyzed. Several techniques are proposed to improve the quality of AD:\nexponentially weighted smoothing, mean p-powered error measure, individual\nerror weight for each variable, disjoint prediction windows. Based on the\ntechniques used, an approach to anomaly interpretation is introduced.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:22:21 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Shalyga", "Dmitry", ""], ["Filonov", "Pavel", ""], ["Lavrentyev", "Andrey", ""]]}, {"id": "1807.07291", "submitter": "Chi Hong", "authors": "Chi Hong, Amirmasoud Ghiassi, Yichi Zhou, Robert Birke, Lydia Y. Chen", "title": "Online Label Aggregation: A Variational Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labeled data is more a norm than a rarity for crowd sourced contents.\nIt is effective to distill noise and infer correct labels through aggregation\nresults from crowd workers. To ensure the time relevance and overcome slow\nresponses of workers, online label aggregation is increasingly requested,\ncalling for solutions that can incrementally infer true label distribution via\nsubsets of data items. In this paper, we propose a novel online label\naggregation framework, BiLA, which employs variational Bayesian inference\nmethod and designs a novel stochastic optimization scheme for incremental\ntraining. BiLA is flexible to accommodate any generating distribution of labels\nby the exact computation of its posterior distribution. We also derive the\nconvergence bound of the proposed optimizer. We compare BiLA with the state of\nthe art based on minimax entropy, neural networks and expectation maximization\nalgorithms, on synthetic and real-world data sets. Our evaluation results on\nvarious online scenarios show that BiLA can effectively infer the true labels,\nwith an error rate reduction of at least 10 to 1.5 percent points for synthetic\nand real-world datasets, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:39:30 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 23:38:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hong", "Chi", ""], ["Ghiassi", "Amirmasoud", ""], ["Zhou", "Yichi", ""], ["Birke", "Robert", ""], ["Chen", "Lydia Y.", ""]]}, {"id": "1807.07298", "submitter": "Joeran Beel", "authors": "Joeran Beel and Andrew Collins and Oliver Kopp and Linus W. Dietz and\n  Petr Knoth", "title": "Online Evaluations for Everyone: Mr. DLib's Living Lab for Scholarly\n  Recommendations", "comments": "Published at the 41st European Conference on Information Retrieval\n  (ECIR) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-15719-7_27", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first 'living lab' for scholarly recommender systems. This\nlab allows recommender-system researchers to conduct online evaluations of\ntheir novel algorithms for scholarly recommendations, i.e., recommendations for\nresearch papers, citations, conferences, research grants, etc. Recommendations\nare delivered through the living lab's API to platforms such as reference\nmanagement software and digital libraries. The living lab is built on top of\nthe recommender-system as-a-service Mr. DLib. Current partners are the\nreference management software JabRef and the CORE research team. We present the\narchitecture of Mr. DLib's living lab as well as usage statistics on the first\nsixteen months of operating it. During this time, 1,826,643 recommendations\nwere delivered with an average click-through rate of 0.21%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:55:09 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 08:42:02 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Beel", "Joeran", ""], ["Collins", "Andrew", ""], ["Kopp", "Oliver", ""], ["Dietz", "Linus W.", ""], ["Knoth", "Petr", ""]]}, {"id": "1807.07306", "submitter": "Daniel Braithwaite", "authors": "D. T. Braithwaite, W. B. Kleijn", "title": "Bounded Information Rate Variational Autoencoders", "comments": "Presented at KDD 2018 Deep Learning Day. Minor changes and correction\n  of rate calculations, overall results remain the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new member of the family of Variational Autoencoders\n(VAE) that constrains the rate of information transferred by the latent layer.\nThe latent layer is interpreted as a communication channel, the information\nrate of which is bound by imposing a pre-set signal-to-noise ratio. The new\nconstraint subsumes the mutual information between the input and latent\nvariables, combining naturally with the likelihood objective of the observed\ndata as used in a conventional VAE. The resulting Bounded-Information-Rate\nVariational Autoencoder (BIR-VAE) provides a meaningful latent representation\nwith an information resolution that can be specified directly in bits by the\nsystem designer. The rate constraint can be used to prevent overtraining, and\nthe method naturally facilitates quantisation of the latent variables at the\nset rate. Our experiments confirm that the BIR-VAE has a meaningful latent\nrepresentation and that its performance is at least as good as state-of-the-art\ncompeting algorithms, but with lower computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 09:13:57 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 09:38:22 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Braithwaite", "D. T.", ""], ["Kleijn", "W. B.", ""]]}, {"id": "1807.07333", "submitter": "Javid Dadashkarimi", "authors": "Javid Dadashkarimi and Sekhar Tatikonda", "title": "Sequence to Logic with Copy and Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating logical form equivalents of human language is a fresh way to\nemploy neural architectures where long short-term memory effectively captures\ndependencies in both encoder and decoder units.\n  The logical form of the sequence usually preserves information from the\nnatural language side in the form of similar tokens, and recently a copying\nmechanism has been proposed which increases the probability of outputting\ntokens from the source input through decoding.\n  In this paper we propose a caching mechanism as a more general form of the\ncopying mechanism which also weighs all the words from the source vocabulary\naccording to their relation to the current decoding context.\n  Our results confirm that the proposed method achieves improvements in\nsequence/token-level accuracy on sequence to logical form tasks. Further\nexperiments on cross-domain adversarial attacks show substantial improvements\nwhen using the most influential examples of other domains for training.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 10:32:52 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Dadashkarimi", "Javid", ""], ["Tatikonda", "Sekhar", ""]]}, {"id": "1807.07346", "submitter": "Esteban Garc\\'ia-Cuesta Dr.", "authors": "Esteban Garc\\'ia-Cuesta (Data Science Laboratory, School of\n  Arquitecture, Engineering and Design, Universidad Europea de Madrid, Spain),\n  Jos\\'e M. G\\'omez-P\\'erez (Expert System, Spain)", "title": "Indexing Execution Patterns in Workflow Provenance Graphs through\n  Generalized Trie Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, scientific workflows have become mature enough to be\nused in a production style. However, despite the increasing maturity, there is\nstill a shortage of tools for searching, adapting, and reusing workflows that\nhinders a more generalized adoption by the scientific communities. Indeed, due\nto the limited availability of machine-readable scientific metadata and the\nheterogeneity of workflow specification formats and representations, new ways\nto leverage alternative sources of information that complement existing\napproaches are needed. In this paper we address such limitations by applying\nstatistically enriched generalized trie structures to exploit workflow\nexecution provenance information in order to assist the analysis, indexing and\nsearch of scientific workflows. Our method bridges the gap between the\ndescription of what a workflow is supposed to do according to its specification\nand related metadata and what it actually does as recorded in its provenance\nexecution trace. In doing so, we also prove that the proposed method\noutperforms SPARQL 1.1 Property Paths for querying provenance graphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 11:29:40 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Garc\u00eda-Cuesta", "Esteban", "", "Data Science Laboratory, School of\n  Arquitecture, Engineering and Design, Universidad Europea de Madrid, Spain"], ["G\u00f3mez-P\u00e9rez", "Jos\u00e9 M.", "", "Expert System, Spain"]]}, {"id": "1807.07362", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Nicol\\'as Navarro-Guerrero, Sven Magg, Stefan Wermter", "title": "Speeding up the Hyperparameter Optimization of Deep Convolutional Neural\n  Networks", "comments": "15 pages, published in the International Journal of Computational\n  Intelligence and Applications", "journal-ref": "International Journal of Computational Intelligence and\n  Applications (2018), Vol. 17, No. 02", "doi": "10.1142/S1469026818500086", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most learning algorithms require the practitioner to manually set the values\nof many hyperparameters before the learning process can begin. However, with\nmodern algorithms, the evaluation of a given hyperparameter setting can take a\nconsiderable amount of time and the search space is often very\nhigh-dimensional. We suggest using a lower-dimensional representation of the\noriginal data to quickly identify promising areas in the hyperparameter space.\nThis information can then be used to initialize the optimization algorithm for\nthe original, higher-dimensional data. We compare this approach with the\nstandard procedure of optimizing the hyperparameters only on the original\ninput.\n  We perform experiments with various state-of-the-art hyperparameter\noptimization algorithms such as random search, the tree of parzen estimators\n(TPEs), sequential model-based algorithm configuration (SMAC), and a genetic\nalgorithm (GA). Our experiments indicate that it is possible to speed up the\noptimization process by using lower-dimensional data representations at the\nbeginning, while increasing the dimensionality of the input later in the\noptimization process. This is independent of the underlying optimization\nprocedure, making the approach promising for many existing hyperparameter\noptimization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 12:25:29 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Hinz", "Tobias", ""], ["Navarro-Guerrero", "Nicol\u00e1s", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1807.07404", "submitter": "Michaela Regneri", "authors": "Michaela Regneri, Malte Hoffmann, Jurij Kost, Niklas Pietsch, Timo\n  Schulz, and Sabine Stamm", "title": "Analyzing Hypersensitive AI: Instability in Corporate-Scale Machine\n  Learning", "comments": "7 pages, presented as poster at IJCAI-ECAI Workshop on Explainable AI", "journal-ref": "Proceedings of the 2nd Workshop on Explainable Artificial\n  Intelligence (XAI 2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive geometric models deliver excellent results for many Machine\nLearning use cases. Despite their undoubted performance, neural predictive\nalgorithms can show unexpected degrees of instability and variance,\nparticularly when applied to large datasets. We present an approach to measure\nchanges in geometric models with respect to both output consistency and\ntopological stability. Considering the example of a recommender system using\nword2vec, we analyze the influence of single data points, approximation methods\nand parameter settings. Our findings can help to stabilize models where needed\nand to detect differences in informational value of data points on a large\nscale.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:02:14 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Regneri", "Michaela", ""], ["Hoffmann", "Malte", ""], ["Kost", "Jurij", ""], ["Pietsch", "Niklas", ""], ["Schulz", "Timo", ""], ["Stamm", "Sabine", ""]]}, {"id": "1807.07418", "submitter": "Sudip Mittal", "authors": "Nitika Khurana, Sudip Mittal, Anupam Joshi", "title": "Preventing Poisoning Attacks on AI based Threat Intelligence Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems become more ubiquitous, securing them becomes an emerging\nchallenge. Over the years, with the surge in online social media use and the\ndata available for analysis, AI systems have been built to extract, represent\nand use this information. The credibility of this information extracted from\nopen sources, however, can often be questionable. Malicious or incorrect\ninformation can cause a loss of money, reputation, and resources; and in\ncertain situations, pose a threat to human life. In this paper, we use an\nensembled semi-supervised approach to determine the credibility of Reddit posts\nby estimating their reputation score to ensure the validity of information\ningested by AI systems. We demonstrate our approach in the cybersecurity\ndomain, where security analysts utilize these systems to determine possible\nthreats by analyzing the data scattered on social media websites, forums,\nblogs, etc.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 13:40:37 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Khurana", "Nitika", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""]]}, {"id": "1807.07468", "submitter": "Kaveh Bastani", "authors": "Kaveh Bastani, Hamed Namavari, Jeffry Shaffer", "title": "Latent Dirichlet Allocation (LDA) for Topic Modeling of the CFPB\n  Consumer Complaints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A text mining approach is proposed based on latent Dirichlet allocation (LDA)\nto analyze the Consumer Financial Protection Bureau (CFPB) consumer complaints.\nThe proposed approach aims to extract latent topics in the CFPB complaint\nnarratives, and explores their associated trends over time. The time trends\nwill then be used to evaluate the effectiveness of the CFPB regulations and\nexpectations on financial institutions in creating a consumer oriented culture\nthat treats consumers fairly and prioritizes consumer protection in their\ndecision making processes. The proposed approach can be easily operationalized\nas a decision support system to automate detection of emerging topics in\nconsumer complaints. Hence, the technology-human partnership between the\nproposed approach and the CFPB team could certainly improve consumer\nprotections from unfair, deceptive or abusive practices in the financial\nmarkets by providing more efficient and effective investigations of consumer\ncomplaint narratives.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 17:26:57 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Bastani", "Kaveh", ""], ["Namavari", "Hamed", ""], ["Shaffer", "Jeffry", ""]]}, {"id": "1807.07490", "submitter": "William Drozd", "authors": "William Drozd and Michael D. Wagner", "title": "FuzzerGym: A Competitive Framework for Fuzzing and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is a commonly used technique designed to test software by\nautomatically crafting program inputs. Currently, the most successful fuzzing\nalgorithms emphasize simple, low-overhead strategies with the ability to\nefficiently monitor program state during execution. Through compile-time\ninstrumentation, these approaches have access to numerous aspects of program\nstate including coverage, data flow, and heterogeneous fault detection and\nclassification. However, existing approaches utilize blind random mutation\nstrategies when generating test inputs. We present a different approach that\nuses this state information to optimize mutation operators using reinforcement\nlearning (RL). By integrating OpenAI Gym with libFuzzer we are able to\nsimultaneously leverage advancements in reinforcement learning as well as\nfuzzing to achieve deeper coverage across several varied benchmarks. Our\ntechnique connects the rich, efficient program monitors provided by LLVM\nSantizers with a deep neural net to learn mutation selection strategies\ndirectly from the input data. The cross-language, asynchronous architecture we\ndeveloped enables us to apply any OpenAI Gym compatible deep reinforcement\nlearning algorithm to any fuzzing problem with minimal slowdown.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 15:22:35 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Drozd", "William", ""], ["Wagner", "Michael D.", ""]]}, {"id": "1807.07506", "submitter": "Karthikeyan Shanmugam", "authors": "Amit Dhurandhar, Karthikeyan Shanmugam, Ronny Luss, Peder Olsen", "title": "Improving Simple Models with Confidence Profiles", "comments": "16 pages; Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method called ProfWeight for transferring\ninformation from a pre-trained deep neural network that has a high test\naccuracy to a simpler interpretable model or a very shallow network of low\ncomplexity and a priori low test accuracy. We are motivated by applications in\ninterpretability and model deployment in severely memory constrained\nenvironments (like sensors). Our method uses linear probes to generate\nconfidence scores through flattened intermediate representations. Our transfer\nmethod involves a theoretically justified weighting of samples during the\ntraining of the simple model using confidence scores of these intermediate\nlayers. The value of our method is first demonstrated on CIFAR-10, where our\nweighting method significantly improves (3-4%) networks with only a fraction of\nthe number of Resnet blocks of a complex Resnet model. We further demonstrate\noperationally significant results on a real manufacturing problem, where we\ndramatically increase the test accuracy of a CART model (the domain standard)\nby roughly 13%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 15:58:14 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 07:11:52 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Shanmugam", "Karthikeyan", ""], ["Luss", "Ronny", ""], ["Olsen", "Peder", ""]]}, {"id": "1807.07525", "submitter": "Vineeth S. Bhaskara", "authors": "Vineeth S. Bhaskara, Debanjan Bhattacharyya", "title": "Emulating malware authors for proactive protection using GANs over a\n  distributed image visualization of dynamic file behavior", "comments": "22 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware authors have always been at an advantage of being able to\nadversarially test and augment their malicious code, before deploying the\npayload, using anti-malware products at their disposal. The anti-malware\ndevelopers and threat experts, on the other hand, do not have such a privilege\nof tuning anti-malware products against zero-day attacks pro-actively. This\nallows the malware authors to being a step ahead of the anti-malware products,\nfundamentally biasing the cat and mouse game played by the two parties. In this\npaper, we propose a way that would enable machine learning based threat\nprevention models to bridge that gap by being able to tune against a deep\ngenerative adversarial network (GAN), which takes up the role of a malware\nauthor and generates new types of malware. The GAN is trained over a reversible\ndistributed RGB image representation of known malware behaviors, encoding the\nsequence of API call ngrams and the corresponding term frequencies. The\ngenerated images represent synthetic malware that can be decoded back to the\nunderlying API call sequence information. The image representation is not only\ndemonstrated as a general technique of incorporating necessary priors for\nexploiting convolutional neural network architectures for generative or\ndiscriminative modeling, but also as a visualization method for easy manual\nsoftware or malware categorization, by having individual API ngram information\ndistributed across the image space. In addition, we also propose using\nsmart-definitions for detecting malwares based on perceptual hashing of these\nimages. Such hashes are potentially more effective than cryptographic hashes\nthat do not carry any meaningful similarity metric, and hence, do not\ngeneralize well.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 16:35:59 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 16:43:23 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Bhaskara", "Vineeth S.", ""], ["Bhattacharyya", "Debanjan", ""]]}, {"id": "1807.07530", "submitter": "Thommen George Karimpanal", "authors": "Thommen George Karimpanal, Roland Bouffanais", "title": "Self-Organizing Maps as a Storage and Transfer Mechanism in\n  Reinforcement Learning", "comments": "7 pages, 7 figures, presented at ALA Workshop, FAIM, Stockholm, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of reusing information from previously learned tasks (source tasks)\nfor the learning of new tasks (target tasks) has the potential to significantly\nimprove the sample efficiency reinforcement learning agents. In this work, we\ndescribe an approach to concisely store and represent learned task knowledge,\nand reuse it by allowing it to guide the exploration of an agent while it\nlearns new tasks. In order to do so, we use a measure of similarity that is\ndefined directly in the space of parameterized representations of the value\nfunctions. This similarity measure is also used as a basis for a variant of the\ngrowing self-organizing map algorithm, which is simultaneously used to enable\nthe storage of previously acquired task knowledge in an adaptive and scalable\nmanner.We empirically validate our approach in a simulated navigation\nenvironment and discuss possible extensions to this approach along with\npotential applications where it could be particularly useful.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 16:49:51 GMT"}], "update_date": "2018-07-21", "authors_parsed": [["Karimpanal", "Thommen George", ""], ["Bouffanais", "Roland", ""]]}, {"id": "1807.07540", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "Bayesian filtering unifies adaptive and non-adaptive neural network\n  optimization methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the problem of neural network optimization as Bayesian\nfiltering, where the observations are the backpropagated gradients. While\nneural network optimization has previously been studied using natural gradient\nmethods which are closely related to Bayesian inference, they were unable to\nrecover standard optimizers such as Adam and RMSprop with a root-mean-square\ngradient normalizer, instead getting a mean-square normalizer. To recover the\nroot-mean-square normalizer, we find it necessary to account for the temporal\ndynamics of all the other parameters as they are geing optimized. The resulting\noptimizer, AdaBayes, adaptively transitions between SGD-like and Adam-like\nbehaviour, automatically recovers AdamW, a state of the art variant of Adam\nwith decoupled weight decay, and has generalisation performance competitive\nwith SGD.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:12:48 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 16:06:59 GMT"}, {"version": "v3", "created": "Thu, 23 May 2019 16:18:51 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 11:03:07 GMT"}, {"version": "v5", "created": "Thu, 16 Apr 2020 10:07:02 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "1807.07543", "submitter": "Colin Raffel", "authors": "David Berthelot, Colin Raffel, Aurko Roy, Ian Goodfellow", "title": "Understanding and Improving Interpolation in Autoencoders via an\n  Adversarial Regularizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders provide a powerful framework for learning compressed\nrepresentations by encoding all of the information needed to reconstruct a data\npoint in a latent code. In some cases, autoencoders can \"interpolate\": By\ndecoding the convex combination of the latent codes for two datapoints, the\nautoencoder can produce an output which semantically mixes characteristics from\nthe datapoints. In this paper, we propose a regularization procedure which\nencourages interpolated outputs to appear more realistic by fooling a critic\nnetwork which has been trained to recover the mixing coefficient from\ninterpolated data. We then develop a simple benchmark task where we can\nquantitatively measure the extent to which various autoencoders can interpolate\nand show that our regularizer dramatically improves interpolation in this\nsetting. We also demonstrate empirically that our regularizer produces latent\ncodes which are more effective on downstream tasks, suggesting a possible link\nbetween interpolation abilities and learning useful representations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:17:23 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 18:26:40 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Berthelot", "David", ""], ["Raffel", "Colin", ""], ["Roy", "Aurko", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1807.07545", "submitter": "Jo\\~ao Loula", "authors": "Jo\\~ao Loula, Marco Baroni, Brenden M. Lake", "title": "Rearranging the Familiar: Testing Compositional Generalization in\n  Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic compositionality is the ability to recombine meaningful units with\nregular and predictable outcomes, and it's seen as key to humans' capacity for\ngeneralization in language. Recent work has studied systematic compositionality\nin modern seq2seq models using generalization to novel navigation instructions\nin a grounded environment as a probing tool, requiring models to quickly\nbootstrap the meaning of new words. We extend this framework here to settings\nwhere the model needs only to recombine well-trained functional words (such as\n\"around\" and \"right\") in novel contexts. Our findings confirm and strengthen\nthe earlier ones: seq2seq models can be impressively good at generalizing to\nnovel combinations of previously-seen input, but only when they receive\nextensive training on the specific pattern to be generalized (e.g.,\ngeneralizing from many examples of \"X around right\" to \"jump around right\"),\nwhile failing when generalization requires novel application of compositional\nrules (e.g., inferring the meaning of \"around right\" from those of \"right\" and\n\"around\").\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:23:13 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Loula", "Jo\u00e3o", ""], ["Baroni", "Marco", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1807.07547", "submitter": "Christophe Giraud", "authors": "Christophe Giraud and Nicolas Verzelen", "title": "Partial recovery bounds for clustering with the relaxed $K$means", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the clustering performances of the relaxed $K$means in the\nsetting of sub-Gaussian Mixture Model (sGMM) and Stochastic Block Model (SBM).\nAfter identifying the appropriate signal-to-noise ratio (SNR), we prove that\nthe misclassification error decay exponentially fast with respect to this SNR.\nThese partial recovery bounds for the relaxed $K$means improve upon results\ncurrently known in the sGMM setting. In the SBM setting, applying the relaxed\n$K$means SDP allows to handle general connection probabilities whereas other\nSDPs investigated in the literature are restricted to the assortative case\n(where within group probabilities are larger than between group probabilities).\nAgain, this partial recovery bound complements the state-of-the-art results.\nAll together, these results put forward the versatility of the relaxed\n$K$means.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:33:30 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 15:53:02 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 15:48:07 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Giraud", "Christophe", ""], ["Verzelen", "Nicolas", ""]]}, {"id": "1807.07560", "submitter": "Samaneh Azadi", "authors": "Samaneh Azadi, Deepak Pathak, Sayna Ebrahimi, Trevor Darrell", "title": "Compositional GAN: Learning Image-Conditional Binary Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can produce images of remarkable\ncomplexity and realism but are generally structured to sample from a single\nlatent source ignoring the explicit spatial interaction between multiple\nentities that could be present in a scene. Capturing such complex interactions\nbetween different objects in the world, including their relative scaling,\nspatial layout, occlusion, or viewpoint transformation is a challenging\nproblem. In this work, we propose a novel self-consistent\nComposition-by-Decomposition (CoDe) network to compose a pair of objects. Given\nobject images from two distinct distributions, our model can generate a\nrealistic composite image from their joint distribution following the texture\nand shape of the input objects. We evaluate our approach through qualitative\nexperiments and user evaluations. Our results indicate that the learned model\ncaptures potential interactions between the two object domains, and generates\nrealistic composed scenes at test time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:57:16 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 09:12:37 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 17:04:47 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Azadi", "Samaneh", ""], ["Pathak", "Deepak", ""], ["Ebrahimi", "Sayna", ""], ["Darrell", "Trevor", ""]]}, {"id": "1807.07569", "submitter": "Sungmin Cha", "authors": "Sungmin Cha, Taesup Moon", "title": "Fully Convolutional Pixel Adaptive Image Denoiser", "comments": "17 pages (including Supplementary Materials), ICCV 2019 camera ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new image denoising algorithm, dubbed as Fully Convolutional\nAdaptive Image DEnoiser (FC-AIDE), that can learn from an offline supervised\ntraining set with a fully convolutional neural network as well as adaptively\nfine-tune the supervised model for each given noisy image. We significantly\nextend the framework of the recently proposed Neural AIDE, which formulates the\ndenoiser to be context-based pixelwise mappings and utilizes the unbiased\nestimator of MSE for such denoisers. The two main contributions we make are; 1)\nimplementing a novel fully convolutional architecture that boosts the base\nsupervised model, and 2) introducing regularization methods for the adaptive\nfine-tuning such that a stronger and more robust adaptivity can be attained. As\na result, FC-AIDE is shown to possess many desirable features; it outperforms\nthe recent CNN-based state-of-the-art denoisers on all of the benchmark\ndatasets we tested, and gets particularly strong for various challenging\nscenarios, e.g., with mismatched image/noise characteristics or with scarce\nsupervised training data. The source code of our algorithm is available at\nhttps://github.com/csm9493/FC-AIDE-Keras.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 14:34:11 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 11:28:15 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 22:25:46 GMT"}, {"version": "v4", "created": "Sun, 27 Oct 2019 20:24:23 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cha", "Sungmin", ""], ["Moon", "Taesup", ""]]}, {"id": "1807.07603", "submitter": "Mahdi Azarafrooz", "authors": "Mahdi Azarafrooz", "title": "Doubly Stochastic Adversarial Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any autoencoder network can be turned into a generative model by imposing an\narbitrary prior distribution on its hidden code vector. Variational Autoencoder\n(VAE) [2] uses a KL divergence penalty to impose the prior, whereas Adversarial\nAutoencoder (AAE) [1] uses {\\it generative adversarial networks} GAN [3]. GAN\ntrades the complexities of {\\it sampling} algorithms with the complexities of\n{\\it searching} Nash equilibrium in minimax games. Such minimax architectures\nget trained with the help of data examples and gradients flowing through a\ngenerator and an adversary. A straightforward modification of AAE is to replace\nthe adversary with the maximum mean discrepancy (MMD) test [4-5]. This\nreplacement leads to a new type of probabilistic autoencoder, which is also\ndiscussed in our paper. We propose a novel probabilistic autoencoder in which\nthe adversary of AAE is replaced with a space of {\\it stochastic} functions.\nThis replacement introduces a new source of randomness, which can be considered\nas a continuous control for encouraging {\\it explorations}. This prevents the\nadversary from fitting too closely to the generator and therefore leads to a\nmore diverse set of generated samples.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 18:51:31 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Azarafrooz", "Mahdi", ""]]}, {"id": "1807.07610", "submitter": "Rishi Sonthalia", "authors": "Anna C. Gilbert and Rishi Sonthalia", "title": "Unsupervised Metric Learning in Presence of Missing Data", "comments": null, "journal-ref": "2018 56th Annual Allerton Conference on Communication, Control,\n  and Computing (Allerton)", "doi": "10.1109/ALLERTON.2018.8635955", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many machine learning tasks, the input data lie on a low-dimensional\nmanifold embedded in a high dimensional space and, because of this\nhigh-dimensional structure, most algorithms are inefficient. The typical\nsolution is to reduce the dimension of the input data using standard dimension\nreduction algorithms such as ISOMAP, LAPLACIAN EIGENMAPS or LLES. This\napproach, however, does not always work in practice as these algorithms require\nthat we have somewhat ideal data. Unfortunately, most data sets either have\nmissing entries or unacceptably noisy values. That is, real data are far from\nideal and we cannot use these algorithms directly. In this paper, we focus on\nthe case when we have missing data. Some techniques, such as matrix completion,\ncan be used to fill in missing data but these methods do not capture the\nnon-linear structure of the manifold. Here, we present a new algorithm\nMR-MISSING that extends these previous algorithms and can be used to compute\nlow dimensional representation on data sets with missing entries. We\ndemonstrate the effectiveness of our algorithm by running three different\nexperiments. We visually verify the effectiveness of our algorithm on synthetic\nmanifolds, we numerically compare our projections against those computed by\nfirst filling in data using nlPCA and mDRUR on the MNIST data set, and we also\nshow that we can do classification on MNIST with missing data. We also provide\na theoretical guarantee for MR-MISSING under some simplifying assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 19:04:17 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 16:32:30 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 17:11:01 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Gilbert", "Anna C.", ""], ["Sonthalia", "Rishi", ""]]}, {"id": "1807.07612", "submitter": "Mahdi Azarafrooz", "authors": "Mahdi Azarafrooz", "title": "Adaptive Variational Particle Filtering in Non-stationary Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online convex optimization is a sequential prediction framework with the goal\nto track and adapt to the environment through evaluating proper convex loss\nfunctions. We study efficient particle filtering methods from the perspective\nof such a framework.\n  We formulate an efficient particle filtering methods for the non-stationary\nenvironment by making connections with the online mirror descent algorithm\nwhich is known to be a universal online convex optimization algorithm.\n  As a result of this connection, our proposed particle filtering algorithm\nproves to achieve optimal particle efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 19:06:20 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Azarafrooz", "Mahdi", ""]]}, {"id": "1807.07621", "submitter": "Christopher Aicher", "authors": "Christopher Aicher and Emily B. Fox", "title": "Approximate Collapsed Gibbs Clustering with Expectation Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for approximating collapsed Gibbs sampling in\ngenerative latent variable cluster models. Collapsed Gibbs is a popular MCMC\nmethod, which integrates out variables in the posterior to improve mixing.\nUnfortunately for many complex models, integrating out these variables is\neither analytically or computationally intractable. We efficiently approximate\nthe necessary collapsed Gibbs integrals by borrowing ideas from expectation\npropagation. We present two case studies where exact collapsed Gibbs sampling\nis intractable: mixtures of Student-t's and time series clustering. Our\nexperiments on real and synthetic data show that our approximate sampler\nenables a runtime-accuracy tradeoff in sampling these types of models,\nproviding results with competitive accuracy much more rapidly than the naive\nGibbs samplers one would otherwise rely on in these scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 19:40:35 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Aicher", "Christopher", ""], ["Fox", "Emily B.", ""]]}, {"id": "1807.07623", "submitter": "Julian Zimmert", "authors": "Julian Zimmert and Yevgeny Seldin", "title": "Tsallis-INF: An Optimal Algorithm for Stochastic and Adversarial Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an algorithm that achieves the optimal (within constants)\npseudo-regret in both adversarial and stochastic multi-armed bandits without\nprior knowledge of the regime and time horizon. The algorithm is based on\nonline mirror descent (OMD) with Tsallis entropy regularization with power\n$\\alpha=1/2$ and reduced-variance loss estimators. More generally, we define an\nadversarial regime with a self-bounding constraint, which includes stochastic\nregime, stochastically constrained adversarial regime (Wei and Luo), and\nstochastic regime with adversarial corruptions (Lykouris et al.) as special\ncases, and show that the algorithm achieves logarithmic regret guarantee in\nthis regime and all of its special cases simultaneously with the adversarial\nregret guarantee.} The algorithm also achieves adversarial and stochastic\noptimality in the utility-based dueling bandit setting. We provide empirical\nevaluation of the algorithm demonstrating that it significantly outperforms\nUCB1 and EXP3 in stochastic environments. We also provide examples of\nadversarial environments, where UCB1 and Thompson Sampling exhibit almost\nlinear regret, whereas our algorithm suffers only logarithmic regret. To the\nbest of our knowledge, this is the first example demonstrating vulnerability of\nThompson Sampling in adversarial environments. Last, but not least, we present\na general stochastic analysis and a general adversarial analysis of OMD\nalgorithms with Tsallis entropy regularization for $\\alpha\\in[0,1]$ and explain\nthe reason why $\\alpha=1/2$ works best.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 19:42:19 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 08:28:23 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 09:27:40 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 12:18:15 GMT"}, {"version": "v5", "created": "Mon, 18 Jan 2021 08:24:06 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zimmert", "Julian", ""], ["Seldin", "Yevgeny", ""]]}, {"id": "1807.07627", "submitter": "Daniel Canaday", "authors": "Daniel Canaday, Aaron Griffith, Daniel Gauthier", "title": "Rapid Time Series Prediction with a Hardware-Based Reservoir Computer", "comments": null, "journal-ref": null, "doi": "10.1063/1.5048199", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a neural network approach for processing\ntime-dependent signals that has seen rapid development in recent years.\nPhysical implementations of the technique using optical reservoirs have\ndemonstrated remarkable accuracy and processing speed at benchmark tasks.\nHowever, these approaches require an electronic output layer to maintain high\nperformance, which limits their use in tasks such as time-series prediction,\nwhere the output is fed back into the reservoir. We present here a reservoir\ncomputing scheme that has rapid processing speed both by the reservoir and the\noutput layer. The reservoir is realized by an autonomous, time-delay, Boolean\nnetwork configured on a field-programmable gate array. We investigate the\ndynamical properties of the network and observe the fading memory property that\nis critical for successful reservoir computing. We demonstrate the utility of\nthe technique by training a reservoir to learn the short- and long-term\nbehavior of a chaotic system. We find accuracy comparable to state-of-the-art\nsoftware approaches of similar network size, but with a superior real-time\nprediction rate up to 160 MHz.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 20:13:03 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 16:33:30 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Canaday", "Daniel", ""], ["Griffith", "Aaron", ""], ["Gauthier", "Daniel", ""]]}, {"id": "1807.07663", "submitter": "Aliasghar Mortazi", "authors": "Aliasghar Mortazi and Ulas Bagci", "title": "Automatically Designing CNN Architectures for Medical Image Segmentation", "comments": "Accepted to Machine Learning in Medical Imaging (MLMI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network architectures have traditionally been designed and\nexplored with human expertise in a long-lasting trial-and-error process. This\nprocess requires huge amount of time, expertise, and resources. To address this\ntedious problem, we propose a novel algorithm to optimally find hyperparameters\nof a deep network architecture automatically. We specifically focus on\ndesigning neural architectures for medical image segmentation task. Our\nproposed method is based on a policy gradient reinforcement learning for which\nthe reward function is assigned a segmentation evaluation utility (i.e., dice\nindex). We show the efficacy of the proposed method with its low computational\ncost in comparison with the state-of-the-art medical image segmentation\nnetworks. We also present a new architecture design, a densely connected\nencoder-decoder CNN, as a strong baseline architecture to apply the proposed\nhyperparameter search algorithm. We apply the proposed algorithm to each layer\nof the baseline architectures. As an application, we train the proposed system\non cine cardiac MR images from Automated Cardiac Diagnosis Challenge (ACDC)\nMICCAI 2017. Starting from a baseline segmentation architecture, the resulting\nnetwork architecture obtains the state-of-the-art results in accuracy without\nperforming any trial-and-error based architecture design approaches or close\nsupervision of the hyperparameters changes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 23:47:12 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Mortazi", "Aliasghar", ""], ["Bagci", "Ulas", ""]]}, {"id": "1807.07665", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Junhyuk Oh, Honglak Lee", "title": "Hierarchical Reinforcement Learning for Zero-shot Generalization with\n  Subtask Dependencies", "comments": "In NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new RL problem where the agent is required to generalize to a\npreviously-unseen environment characterized by a subtask graph which describes\na set of subtasks and their dependencies. Unlike existing hierarchical\nmultitask RL approaches that explicitly describe what the agent should do at a\nhigh level, our problem only describes properties of subtasks and relationships\namong them, which requires the agent to perform complex reasoning to find the\noptimal subtask to execute. To solve this problem, we propose a neural subtask\ngraph solver (NSGS) which encodes the subtask graph using a recursive neural\nnetwork embedding. To overcome the difficulty of training, we propose a novel\nnon-parametric gradient-based policy, graph reward propagation, to pre-train\nour NSGS agent and further finetune it through actor-critic method. The\nexperimental results on two 2D visual domains show that our agent can perform\ncomplex reasoning to find a near-optimal way of executing the subtask graph and\ngeneralize well to the unseen subtask graphs. In addition, we compare our agent\nwith a Monte-Carlo tree search (MCTS) method showing that our method is much\nmore efficient than MCTS, and the performance of NSGS can be further improved\nby combining it with MCTS.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 23:51:55 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 05:00:38 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 20:52:03 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 22:10:33 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sohn", "Sungryull", ""], ["Oh", "Junhyuk", ""], ["Lee", "Honglak", ""]]}, {"id": "1807.07706", "submitter": "Atilim Gunes Baydin", "authors": "At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Lukas Heinrich, Wahid Bhimji, Lei\n  Shao, Saeid Naderiparizi, Andreas Munk, Jialin Liu, Bradley Gram-Hansen,\n  Gilles Louppe, Lawrence Meadows, Philip Torr, Victor Lee, Prabhat, Kyle\n  Cranmer, Frank Wood", "title": "Efficient Probabilistic Inference in the Quest for Physics Beyond the\n  Standard Model", "comments": "20 pages, 9 figures", "journal-ref": "In Advances in Neural Information Processing Systems 33 (NeurIPS),\n  Vancouver, Canada, 2019", "doi": null, "report-no": null, "categories": "cs.LG hep-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel probabilistic programming framework that couples directly\nto existing large-scale simulators through a cross-platform probabilistic\nexecution protocol, which allows general-purpose inference engines to record\nand control random number draws within simulators in a language-agnostic way.\nThe execution of existing simulators as probabilistic programs enables highly\ninterpretable posterior inference in the structured model defined by the\nsimulator code base. We demonstrate the technique in particle physics, on a\nscientifically accurate simulation of the tau lepton decay, which is a key\ningredient in establishing the properties of the Higgs boson. Inference\nefficiency is achieved via inference compilation where a deep recurrent neural\nnetwork is trained to parameterize proposal distributions and control the\nstochastic simulator in a sequential importance sampling scheme, at a fraction\nof the computational cost of a Markov chain Monte Carlo baseline.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 04:24:51 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 19:20:02 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 02:35:07 GMT"}, {"version": "v4", "created": "Mon, 3 Feb 2020 22:01:22 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 14:20:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Heinrich", "Lukas", ""], ["Bhimji", "Wahid", ""], ["Shao", "Lei", ""], ["Naderiparizi", "Saeid", ""], ["Munk", "Andreas", ""], ["Liu", "Jialin", ""], ["Gram-Hansen", "Bradley", ""], ["Louppe", "Gilles", ""], ["Meadows", "Lawrence", ""], ["Torr", "Philip", ""], ["Lee", "Victor", ""], ["Prabhat", "", ""], ["Cranmer", "Kyle", ""], ["Wood", "Frank", ""]]}, {"id": "1807.07716", "submitter": "Po-Yu Kao", "authors": "Po-Yu Kao and Thuyen Ngo and Angela Zhang and Jefferson W. Chen and\n  B.S. Manjunath", "title": "Brain Tumor Segmentation and Tractographic Feature Extraction from\n  Structural MR Images for Overall Survival Prediction", "comments": "14 pages, 5 figures, 4 tables, accepted by BrainLes 2018 MICCAI\n  workshop", "journal-ref": "4th International Workshop, BrainLes 2018, Held in Conjunction\n  with MICCAI 2018", "doi": "10.1007/978-3-030-11726-9_12", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces a novel methodology to integrate human brain\nconnectomics and parcellation for brain tumor segmentation and survival\nprediction. For segmentation, we utilize an existing brain parcellation atlas\nin the MNI152 1mm space and map this parcellation to each individual subject\ndata. We use deep neural network architectures together with hard negative\nmining to achieve the final voxel level classification. For survival\nprediction, we present a new method for combining features from connectomics\ndata, brain parcellation information, and the brain tumor mask. We leverage the\naverage connectome information from the Human Connectome Project and map each\nsubject brain volume onto this common connectome space. From this, we compute\ntractographic features that describe potential neural disruptions due to the\nbrain tumor. These features are then used to predict the overall survival of\nthe subjects. The main novelty in the proposed methods is the use of normalized\nbrain parcellation data and tractography data from the human connectome project\nfor analyzing MR images for segmentation and survival prediction. Experimental\nresults are reported on the BraTS2018 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 07:10:24 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 04:09:24 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 23:20:28 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kao", "Po-Yu", ""], ["Ngo", "Thuyen", ""], ["Zhang", "Angela", ""], ["Chen", "Jefferson W.", ""], ["Manjunath", "B. S.", ""]]}, {"id": "1807.07741", "submitter": "Luiza Sayfullina", "authors": "Luiza Sayfullina, Eric Malmi and Juho Kannala", "title": "Learning Representations for Soft Skill Matching", "comments": "Accepted by 7th International Conference - Analysis of Images, Social\n  networks and Texts, http://aistconf.org/ (Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Employers actively look for talents having not only specific hard skills but\nalso various soft skills. To analyze the soft skill demands on the job market,\nit is important to be able to detect soft skill phrases from job advertisements\nautomatically. However, a naive matching of soft skill phrases can lead to\nfalse positive matches when a soft skill phrase, such as friendly, is used to\ndescribe a company, a team, or another entity, rather than a desired candidate.\n  In this paper, we propose a phrase-matching-based approach which\ndifferentiates between soft skill phrases referring to a candidate vs.\nsomething else. The disambiguation is formulated as a binary text\nclassification problem where the prediction is made for the potential soft\nskill based on the context where it occurs. To inform the model about the soft\nskill for which the prediction is made, we develop several approaches,\nincluding soft skill masking and soft skill tagging.\n  We compare several neural network based approaches, including CNN, LSTM and\nHierarchical Attention Model. The proposed tagging-based input representation\nusing LSTM achieved the highest recall of 83.92% on the job dataset when fixing\na precision to 95%.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 08:40:10 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Sayfullina", "Luiza", ""], ["Malmi", "Eric", ""], ["Kannala", "Juho", ""]]}, {"id": "1807.07752", "submitter": "Shaunak Joshi", "authors": "Shaunak Joshi and Deepali Deshpande", "title": "Twitter Sentiment Analysis System", "comments": "5 pages", "journal-ref": "International Journal of Computer Applications (2018)", "doi": "10.5120/ijca2018917319", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is increasingly used by humans to express their feelings and\nopinions in the form of short text messages. Detecting sentiments in the text\nhas a wide range of applications including identifying anxiety or depression of\nindividuals and measuring well-being or mood of a community. Sentiments can be\nexpressed in many ways that can be seen such as facial expression and gestures,\nspeech and by written text. Sentiment Analysis in text documents is essentially\na content-based classification problem involving concepts from the domains of\nNatural Language Processing as well as Machine Learning. In this paper,\nsentiment recognition based on textual data and the techniques used in\nsentiment analysis are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 09:19:08 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Joshi", "Shaunak", ""], ["Deshpande", "Deepali", ""]]}, {"id": "1807.07754", "submitter": "Marina Vinyes", "authors": "Marina Vinyes, Guillaume Obozinski", "title": "Learning the effect of latent variables in Gaussian Graphical models\n  with unobserved variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The edge structure of the graph defining an undirected graphical model\ndescribes precisely the structure of dependence between the variables in the\ngraph. In many applications, the dependence structure is unknown and it is\ndesirable to learn it from data, often because it is a preliminary step to be\nable to ascertain causal effects. This problem, known as structure learning, is\nhard in general, but for Gaussian graphical models it is slightly easier\nbecause the structure of the graph is given by the sparsity pattern of the\nprecision matrix of the joint distribution, and because independence coincides\nwith decorrelation. A major difficulty too often ignored in structure learning\nis the fact that if some variables are not observed, the marginal dependence\ngraph over the observed variables will possibly be significantly more complex\nand no longer reflect the direct dependencies that are potentially associated\nwith causal effects. In this work, we consider a family of latent variable\nGaussian graphical models in which the graph of the joint distribution between\nobserved and unobserved variables is sparse, and the unobserved variables are\nconditionally independent given the others. Prior work was able to recover the\nconnectivity between observed variables, but could only identify the subspace\nspanned by unobserved variables, whereas we propose a convex optimization\nformulation based on structured matrix sparsity to estimate the complete\nconnectivity of the complete graph including unobserved variables, given the\nknowledge of the number of missing variables, and a priori knowledge of their\nlevel of connectivity. Our formulation is supported by a theoretical result of\nidentifiability of the latent dependence structure for sparse graphs in the\ninfinite data limit. We propose an algorithm leveraging recent active set\nmethods, which performs well in the experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 09:35:25 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 07:15:22 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Vinyes", "Marina", ""], ["Obozinski", "Guillaume", ""]]}, {"id": "1807.07769", "submitter": "Kevin Eykholt", "authors": "Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati,\n  Florian Tramer, Atul Prakash, Tadayoshi Kohno, Dawn Song", "title": "Physical Adversarial Examples for Object Detectors", "comments": "This paper is the extended version of the USENIX WOOT 2018 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial\nexamples-maliciously crafted inputs that cause DNNs to make incorrect\npredictions. Recent work has shown that these attacks generalize to the\nphysical domain, to create perturbations on physical objects that fool image\nclassifiers under a variety of real-world conditions. Such attacks pose a risk\nto deep learning models used in safety-critical cyber-physical systems. In this\nwork, we extend physical attacks to more challenging object detection models, a\nbroader class of deep learning algorithms widely used to detect and label\nmultiple objects within a scene. Improving upon a previous physical attack on\nimage classifiers, we create perturbed physical objects that are either ignored\nor mislabeled by object detection models. We implement a Disappearance Attack,\nin which we cause a Stop sign to \"disappear\" according to the detector-either\nby covering thesign with an adversarial Stop sign poster, or by adding\nadversarial stickers onto the sign. In a video recorded in a controlled lab\nenvironment, the state-of-the-art YOLOv2 detector failed to recognize these\nadversarial Stop signs in over 85% of the video frames. In an outdoor\nexperiment, YOLO was fooled by the poster and sticker attacks in 72.5% and\n63.5% of the video frames respectively. We also use Faster R-CNN, a different\nobject detection model, to demonstrate the transferability of our adversarial\nperturbations. The created poster perturbation is able to fool Faster R-CNN in\n85.9% of the video frames in a controlled lab environment, and 40.2% of the\nvideo frames in an outdoor environment. Finally, we present preliminary results\nwith a new Creation Attack, where in innocuous physical stickers fool a model\ninto detecting nonexistent objects.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:14:27 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 18:07:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Eykholt", "Kevin", ""], ["Evtimov", "Ivan", ""], ["Fernandes", "Earlence", ""], ["Li", "Bo", ""], ["Rahmati", "Amir", ""], ["Tramer", "Florian", ""], ["Prakash", "Atul", ""], ["Kohno", "Tadayoshi", ""], ["Song", "Dawn", ""]]}, {"id": "1807.07778", "submitter": "Dongyang Ao", "authors": "Dongyang Ao, Corneliu Octavian Dumitru, Gottfried Schwarz and Mihai\n  Datcu", "title": "Dialectical GAN for SAR Image Translation: From Sentinel-1 to TerraSAR-X", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contrary to optical images, Synthetic Aperture Radar (SAR) images are in\ndifferent electromagnetic spectrum where the human visual system is not\naccustomed to. Thus, with more and more SAR applications, the demand for\nenhanced high-quality SAR images has increased considerably. However,\nhigh-quality SAR images entail high costs due to the limitations of current SAR\ndevices and their image processing resources. To improve the quality of SAR\nimages and to reduce the costs of their generation, we propose a Dialectical\nGenerative Adversarial Network (Dialectical GAN) to generate high-quality SAR\nimages. This method is based on the analysis of hierarchical SAR information\nand the \"dialectical\" structure of GAN frameworks. As a demonstration, a\ntypical example will be shown where a low-resolution SAR image (e.g., a\nSentinel-1 image) with large ground coverage is translated into a\nhigh-resolution SAR image (e.g., a TerraSAR-X image). Three traditional\nalgorithms are compared, and a new algorithm is proposed based on a network\nframework by combining conditional WGAN-GP (Wasserstein Generative Adversarial\nNetwork - Gradient Penalty) loss functions and Spatial Gram matrices under the\nrule of dialectics. Experimental results show that the SAR image translation\nworks very well when we compare the results of our proposed method with the\nselected traditional methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:26:32 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Ao", "Dongyang", ""], ["Dumitru", "Corneliu Octavian", ""], ["Schwarz", "Gottfried", ""], ["Datcu", "Mihai", ""]]}, {"id": "1807.07789", "submitter": "Aur\\'elien Bellet", "authors": "Kuan Liu and Aur\\'elien Bellet", "title": "Escaping the Curse of Dimensionality in Similarity Learning: Efficient\n  Frank-Wolfe Algorithm and Generalization Bounds", "comments": "Long version of arXiv:1411.2374 (AISTATS 2015), to appear in\n  Neurocomputing. Matlab code: https://github.com/bellet/HDSL", "journal-ref": null, "doi": "10.1016/j.neucom.2018.12.060", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity and metric learning provides a principled approach to construct a\ntask-specific similarity from weakly supervised data. However, these methods\nare subject to the curse of dimensionality: as the number of features grows\nlarge, poor generalization is to be expected and training becomes intractable\ndue to high computational and memory costs. In this paper, we propose a\nsimilarity learning method that can efficiently deal with high-dimensional\nsparse data. This is achieved through a parameterization of similarity\nfunctions by convex combinations of sparse rank-one matrices, together with the\nuse of a greedy approximate Frank-Wolfe algorithm which provides an efficient\nway to control the number of active features. We show that the convergence rate\nof the algorithm, as well as its time and memory complexity, are independent of\nthe data dimension. We further provide a theoretical justification of our\nmodeling choices through an analysis of the generalization error, which depends\nlogarithmically on the sparsity of the solution rather than on the number of\nfeatures. Our experiments on datasets with up to one million features\ndemonstrate the ability of our approach to generalize well despite the high\ndimensionality as well as its superiority compared to several competing\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 11:18:00 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 09:35:34 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2019 21:46:38 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 17:02:07 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Liu", "Kuan", ""], ["Bellet", "Aur\u00e9lien", ""]]}, {"id": "1807.07803", "submitter": "Santiago Estrada", "authors": "Santiago Estrada, Sailesh Conjeti, Muneer Ahmad, Nassir Navab and\n  Martin Reuter", "title": "Competition vs. Concatenation in Skip Connections of Fully Convolutional\n  Networks", "comments": "Paper accepted on MICCAI-MLMI 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increased information sharing through short and long-range skip connections\nbetween layers in fully convolutional networks have demonstrated significant\nimprovement in performance for semantic segmentation. In this paper, we propose\nCompetitive Dense Fully Convolutional Networks (CDFNet) by introducing\ncompetitive maxout activations in place of naive feature concatenation for\ninducing competition amongst layers. Within CDFNet, we propose two\narchitectural contributions, namely competitive dense block (CDB) and\ncompetitive unpooling block (CUB) to induce competition at local and global\nscales for short and long-range skip connections respectively. This extension\nis demonstrated to boost learning of specialized sub-networks targeted at\nsegmenting specific anatomies, which in turn eases the training of complex\ntasks. We present the proof-of-concept on the challenging task of whole body\nsegmentation in the publicly available VISCERAL benchmark and demonstrate\nimproved performance over multiple learning and registration based\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 12:06:06 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Estrada", "Santiago", ""], ["Conjeti", "Sailesh", ""], ["Ahmad", "Muneer", ""], ["Navab", "Nassir", ""], ["Reuter", "Martin", ""]]}, {"id": "1807.07818", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji, Zsolt Kem\\'eny, Gianfranco Pedone, Andr\\'as\n  Kuti, J\\'ozsef V\\'ancza", "title": "Wireless Multi-Sensor Networks for Smart Cities: A Prototype System with\n  Statistical Data Analysis", "comments": "9 pages, 8 figures, 3 tables, 27 references", "journal-ref": "IEEE Sensors Journal, Volume 17, Issue 23, 2017, pp. 7667-7676", "doi": "10.1109/JSEN.2017.2736785", "report-no": null, "categories": "cs.CY cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As urbanization proceeds at an astonishing rate, cities have to continuously\nimprove their solutions that affect the safety, health and overall wellbeing of\ntheir residents. Smart city projects worldwide build on advanced sensor,\ninformation and communication technologies to help dealing with issues like air\npollution, waste management, traffic optimization, and energy efficiency. The\npaper reports about the prototype of a smart city initiative in Budapest which\napplies various sensors installed on the public lighting system and a\ncloud-based analytical module. While the installed wireless multi-sensor\nnetwork gathers information about a number of stressors, the module integrates\nand statistically processes the data. The module can handle inconsistent,\nmissing and noisy data and can extrapolate the measurements in time and space,\nnamely, it can create short-term forecasts and smoothed maps, both accompanied\nby reliability estimates. The resulting database uses geometric representations\nand can serve as an information centre for public services.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 12:51:15 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""], ["Kem\u00e9ny", "Zsolt", ""], ["Pedone", "Gianfranco", ""], ["Kuti", "Andr\u00e1s", ""], ["V\u00e1ncza", "J\u00f3zsef", ""]]}, {"id": "1807.07838", "submitter": "Fabio Pierazzi Dr", "authors": "Feargus Pendlebury, Fabio Pierazzi, Roberto Jordaney, Johannes Kinder,\n  Lorenzo Cavallaro", "title": "TESSERACT: Eliminating Experimental Bias in Malware Classification\n  across Space and Time", "comments": "This arXiv version (v4) corresponds to the one published at USENIX\n  Security Symposium 2019, with a fixed typo in Equation (4), which reported an\n  extra normalization factor of (1/N). The results in the paper and the\n  released implementation of the TESSERACT framework remain valid and correct\n  as they rely on Python's numpy implementation of area under the curve", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is Android malware classification a solved problem? Published F1 scores of up\nto 0.99 appear to leave very little room for improvement. In this paper, we\nargue that results are commonly inflated due to two pervasive sources of\nexperimental bias: \"spatial bias\" caused by distributions of training and\ntesting data that are not representative of a real-world deployment; and\n\"temporal bias\" caused by incorrect time splits of training and testing sets,\nleading to impossible configurations. We propose a set of space and time\nconstraints for experiment design that eliminates both sources of bias. We\nintroduce a new metric that summarizes the expected robustness of a classifier\nin a real-world setting, and we present an algorithm to tune its performance.\nFinally, we demonstrate how this allows us to evaluate mitigation strategies\nfor time decay such as active learning. We have implemented our solutions in\nTESSERACT, an open source evaluation framework for comparing malware\nclassifiers in a realistic setting. We used TESSERACT to evaluate three Android\nmalware classifiers from the literature on a dataset of 129K applications\nspanning over three years. Our evaluation confirms that earlier published\nresults are biased, while also revealing counter-intuitive performance and\nshowing that appropriate tuning can lead to significant improvements.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 13:46:13 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 17:05:53 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 14:35:39 GMT"}, {"version": "v4", "created": "Thu, 12 Sep 2019 14:03:44 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Pendlebury", "Feargus", ""], ["Pierazzi", "Fabio", ""], ["Jordaney", "Roberto", ""], ["Kinder", "Johannes", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "1807.07860", "submitter": "Ziwei Liu", "authors": "Hang Zhou, Yu Liu, Ziwei Liu, Ping Luo, Xiaogang Wang", "title": "Talking Face Generation by Adversarially Disentangled Audio-Visual\n  Representation", "comments": "AAAI Conference on Artificial Intelligence (AAAI 2019) Oral\n  Presentation. Code, models, and video results are available on our webpage:\n  https://liuziwei7.github.io/projects/TalkingFace.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Talking face generation aims to synthesize a sequence of face images that\ncorrespond to a clip of speech. This is a challenging task because face\nappearance variation and semantics of speech are coupled together in the subtle\nmovements of the talking face regions. Existing works either construct specific\nface appearance model on specific subjects or model the transformation between\nlip motion and speech. In this work, we integrate both aspects and enable\narbitrary-subject talking face generation by learning disentangled audio-visual\nrepresentation. We find that the talking face sequence is actually a\ncomposition of both subject-related information and speech-related information.\nThese two spaces are then explicitly disentangled through a novel\nassociative-and-adversarial training process. This disentangled representation\nhas an advantage where both audio and video can serve as inputs for generation.\nExtensive experiments show that the proposed approach generates realistic\ntalking face sequences on arbitrary subjects with much clearer lip motion\npatterns than previous work. We also demonstrate the learned audio-visual\nrepresentation is extremely useful for the tasks of automatic lip reading and\naudio-video retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 14:26:32 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 16:40:06 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Zhou", "Hang", ""], ["Liu", "Yu", ""], ["Liu", "Ziwei", ""], ["Luo", "Ping", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1807.07868", "submitter": "Michael Kampffmeyer", "authors": "Michael Kampffmeyer, Sigurd L{\\o}kse, Filippo M. Bianchi, Robert\n  Jenssen, Lorenzo Livi", "title": "The Deep Kernelized Autoencoder", "comments": "This work extends the preliminary (conference) version of this paper\n  (arXiv:1702.02526), Applied Soft Computing, Elsevier, 2018", "journal-ref": null, "doi": "10.1016/j.asoc.2018.07.029", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders learn data representations (codes) in such a way that the input\nis reproduced at the output of the network. However, it is not always clear\nwhat kind of properties of the input data need to be captured by the codes.\nKernel machines have experienced great success by operating via inner-products\nin a theoretically well-defined reproducing kernel Hilbert space, hence\ncapturing topological properties of input data. In this paper, we enhance the\nautoencoder's ability to learn effective data representations by aligning inner\nproducts between codes with respect to a kernel matrix. By doing so, the\nproposed kernelized autoencoder allows learning similarity-preserving\nembeddings of input data, where the notion of similarity is explicitly\ncontrolled by the user and encoded in a positive semi-definite kernel matrix.\nExperiments are performed for evaluating both reconstruction and kernel\nalignment performance in classification tasks and visualization of\nhigh-dimensional data. Additionally, we show that our method is capable to\nemulate kernel principal component analysis on a denoising task, obtaining\ncompetitive results at a much lower computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 14:47:32 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 10:03:50 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kampffmeyer", "Michael", ""], ["L\u00f8kse", "Sigurd", ""], ["Bianchi", "Filippo M.", ""], ["Jenssen", "Robert", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1807.07879", "submitter": "Julius Von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Alexander Mey, Marco Loog", "title": "Semi-Generative Modelling: Covariate-Shift Adaptation with Cause and\n  Effect Features", "comments": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan.\n  (Camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current methods for covariate-shift adaptation use unlabelled data to compute\nimportance weights or domain-invariant features, while the final model is\ntrained on labelled data only. Here, we consider a particular case of covariate\nshift which allows us also to learn from unlabelled data, that is, combining\nadaptation with semi-supervised learning. Using ideas from causality, we argue\nthat this requires learning with both causes, $X_C$, and effects, $X_E$, of a\ntarget variable, $Y$, and show how this setting leads to what we call a\nsemi-generative model, $P(Y,X_E|X_C,\\theta)$. Our approach is robust to domain\nshifts in the distribution of causal features and leverages unlabelled data by\nlearning a direct map from causes to effects. Experiments on synthetic data\ndemonstrate significant improvements in classification over purely-supervised\nand importance-weighting baselines.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 14:57:18 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 21:23:08 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1807.07909", "submitter": "Szymon Jaroszewicz", "authors": "Micha{\\l} So{\\l}tys and Szymon Jaroszewicz", "title": "Boosting algorithms for uplift modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling is an area of machine learning which aims at predicting the\ncausal effect of some action on a given individual. The action may be a medical\nprocedure, marketing campaign, or any other circumstance controlled by the\nexperimenter. Building an uplift model requires two training sets: the\ntreatment group, where individuals have been subject to the action, and the\ncontrol group, where no action has been performed. An uplift model allows then\nto assess the gain resulting from taking the action on a given individual, such\nas the increase in probability of patient recovery or of a product being\npurchased. This paper describes an adaptation of the well-known boosting\ntechniques to the uplift modeling case. We formulate three desirable properties\nwhich an uplift boosting algorithm should have. Since all three properties\ncannot be satisfied simultaneously, we propose three uplift boosting\nalgorithms, each satisfying two of them. Experiments demonstrate the usefulness\nof the proposed methods, which often dramatically improve performance of the\nbase models and are thus new and powerful tools for uplift modeling.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 15:57:27 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["So\u0142tys", "Micha\u0142", ""], ["Jaroszewicz", "Szymon", ""]]}, {"id": "1807.07924", "submitter": "Nabil Mustafa", "authors": "Monika Csikos and Andrey Kupavskii and Nabil H. Mustafa", "title": "Optimal Bounds on the VC-dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VC-dimension of a set system is a way to capture its complexity and has\nbeen a key parameter studied extensively in machine learning and geometry\ncommunities. In this paper, we resolve two longstanding open problems on\nbounding the VC-dimension of two fundamental set systems: $k$-fold\nunions/intersections of half-spaces, and the simplices set system. Among other\nimplications, it settles an open question in machine learning that was first\nstudied in the 1989 foundational paper of Blumer, Ehrenfeucht, Haussler and\nWarmuth as well as by Eisenstat and Angluin and Johnson.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 16:32:22 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Csikos", "Monika", ""], ["Kupavskii", "Andrey", ""], ["Mustafa", "Nabil H.", ""]]}, {"id": "1807.07946", "submitter": "Seyed Shahabeddin Nabavi", "authors": "Seyed shahabeddin Nabavi, Mrigank Rochan, Yang, Wang", "title": "Future Semantic Segmentation with Convolutional LSTM", "comments": "Accepted to BMVC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting semantic segmentation of future frames\nin a video. Given several observed frames in a video, our goal is to predict\nthe semantic segmentation map of future frames that are not yet observed. A\nreliable solution to this problem is useful in many applications that require\nreal-time decision making, such as autonomous driving. We propose a novel model\nthat uses convolutional LSTM (ConvLSTM) to encode the spatiotemporal\ninformation of observed frames for future prediction. We also extend our model\nto use bidirectional ConvLSTM to capture temporal information in both\ndirections. Our proposed approach outperforms other state-of-the-art methods on\nthe benchmark dataset.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 17:31:06 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Nabavi", "Seyed shahabeddin", ""], ["Rochan", "Mrigank", ""], ["Yang", "", ""], ["Wang", "", ""]]}, {"id": "1807.07959", "submitter": "Sam  Keene", "authors": "Frank Longueira, Sam Keene", "title": "A Fully Convolutional Neural Network Approach to End-to-End Speech\n  Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will describe a novel approach to the cocktail party problem that\nrelies on a fully convolutional neural network (FCN) architecture. The FCN\ntakes noisy audio data as input and performs nonlinear, filtering operations to\nproduce clean audio data of the target speech at the output. Our method learns\na model for one specific speaker, and is then able to extract that speakers\nvoice from babble background noise. Results from experimentation indicate the\nability to generalize to new speakers and robustness to new noise environments\nof varying signal-to-noise ratios. A potential application of this method would\nbe for use in hearing aids. A pre-trained model could be quickly fine tuned for\nan individuals family members and close friends, and deployed onto a hearing\naid to assist listeners in noisy environments.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 01:20:06 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Longueira", "Frank", ""], ["Keene", "Sam", ""]]}, {"id": "1807.07965", "submitter": "Arindam Chowdhury", "authors": "Arindam Chowdhury and Lovekesh Vig", "title": "An Efficient End-to-End Neural Model for Handwritten Text Recognition", "comments": "Accepted at British Machine Vision Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline handwritten text recognition from images is an important problem for\nenterprises attempting to digitize large volumes of handmarked scanned\ndocuments/reports. Deep recurrent models such as Multi-dimensional LSTMs have\nbeen shown to yield superior performance over traditional Hidden Markov Model\nbased approaches that suffer from the Markov assumption and therefore lack the\nrepresentational power of RNNs. In this paper we introduce a novel approach\nthat combines a deep convolutional network with a recurrent Encoder-Decoder\nnetwork to map an image to a sequence of characters corresponding to the text\npresent in the image. The entire model is trained end-to-end using Focal Loss,\nan improvement over the standard Cross-Entropy loss that addresses the class\nimbalance problem, inherent to text recognition. To enhance the decoding\ncapacity of the model, Beam Search algorithm is employed which searches for the\nbest sequence out of a set of hypotheses based on a joint distribution of\nindividual characters. Our model takes as input a downsampled version of the\noriginal image thereby making it both computationally and memory efficient. The\nexperimental results were benchmarked against two publicly available datasets,\nIAM and RIMES. We surpass the state-of-the-art word level accuracy on the\nevaluation set of both datasets by 3.5% & 1.1%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 09:55:09 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 13:31:24 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Chowdhury", "Arindam", ""], ["Vig", "Lovekesh", ""]]}, {"id": "1807.07978", "submitter": "Andrew Ilyas", "authors": "Andrew Ilyas, Logan Engstrom, Aleksander Madry", "title": "Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors", "comments": "To appear at ICLR 2019; Code available at\n  https://git.io/blackbox-bandits", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating adversarial examples in a black-box\nsetting in which only loss-oracle access to a model is available. We introduce\na framework that conceptually unifies much of the existing work on black-box\nattacks, and we demonstrate that the current state-of-the-art methods are\noptimal in a natural sense. Despite this optimality, we show how to improve\nblack-box attacks by bringing a new element into the problem: gradient priors.\nWe give a bandit optimization-based algorithm that allows us to seamlessly\nintegrate any such priors, and we explicitly identify and incorporate two\nexamples. The resulting methods use two to four times fewer queries and fail\ntwo to five times less often than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:00:27 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 18:12:24 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 02:56:51 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Madry", "Aleksander", ""]]}, {"id": "1807.07987", "submitter": "Vadim Sokolov", "authors": "Nicholas G. Polson and Vadim O. Sokolov", "title": "Deep Learning", "comments": "arXiv admin note: text overlap with arXiv:1602.06561", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is a high dimensional data reduction technique for\nconstructing high-dimensional predictors in input-output models. DL is a form\nof machine learning that uses hierarchical layers of latent features. In this\narticle, we review the state-of-the-art of deep learning from a modeling and\nalgorithmic perspective. We provide a list of successful areas of applications\nin Artificial Intelligence (AI), Image Processing, Robotics and Automation.\nDeep learning is predictive in its nature rather then inferential and can be\nviewed as a black-box methodology for high-dimensional function estimation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:20:34 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 11:27:28 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Polson", "Nicholas G.", ""], ["Sokolov", "Vadim O.", ""]]}, {"id": "1807.07998", "submitter": "Cem Tarhan", "authors": "Cem Tarhan, Gozde Bozdagi Akar", "title": "Convolutional Neural Networks Analyzed via Inverse Problem Theory and\n  Sparse Representations", "comments": "PostPrint IET Signal Processing Journal", "journal-ref": null, "doi": "10.1049/iet-spr.2018.5220", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems in imaging such as denoising, deblurring, superresolution\n(SR) have been addressed for many decades. In recent years, convolutional\nneural networks (CNNs) have been widely used for many inverse problem areas.\nAlthough their indisputable success, CNNs are not mathematically validated as\nto how and what they learn. In this paper, we prove that during training, CNN\nelements solve for inverse problems which are optimum solutions stored as CNN\nneuron filters. We discuss the necessity of mutual coherence between CNN layer\nelements in order for a network to converge to the optimum solution. We prove\nthat required mutual coherence can be provided by the usage of residual\nlearning and skip connections. We have set rules over training sets and depth\nof networks for better convergence, i.e. performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:45:09 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 22:33:44 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Tarhan", "Cem", ""], ["Akar", "Gozde Bozdagi", ""]]}, {"id": "1807.08023", "submitter": "Ulugbek Kamilov", "authors": "Xiaojian Xu and Ulugbek S. Kamilov", "title": "signProx: One-Bit Proximal Algorithm for Nonconvex Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is one of the most widely used optimization\nmethods for parallel and distributed processing of large datasets. One of the\nkey limitations of distributed SGD is the need to regularly communicate the\ngradients between different computation nodes. To reduce this communication\nbottleneck, recent work has considered a one-bit variant of SGD, where only the\nsign of each gradient element is used in optimization. In this paper, we extend\nthis idea by proposing a stochastic variant of the proximal-gradient method\nthat also uses one-bit per update element. We prove the theoretical convergence\nof the method for non-convex optimization under a set of explicit assumptions.\nOur results indicate that the compressed method can match the convergence rate\nof the uncompressed one, making the proposed method potentially appealing for\ndistributed processing of large datasets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 20:47:32 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 19:10:47 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Xu", "Xiaojian", ""], ["Kamilov", "Ulugbek S.", ""]]}, {"id": "1807.08046", "submitter": "Tyler Johnson", "authors": "Tyler B. Johnson, Carlos Guestrin", "title": "A Fast, Principled Working Set Algorithm for Exploiting Piecewise Linear\n  Structure in Convex Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By reducing optimization to a sequence of smaller subproblems, working set\nalgorithms achieve fast convergence times for many machine learning problems.\nDespite such performance, working set implementations often resort to\nheuristics to determine subproblem size, makeup, and stopping criteria. We\npropose BlitzWS, a working set algorithm with useful theoretical guarantees.\nOur theory relates subproblem size and stopping criteria to the amount of\nprogress during each iteration. This result motivates strategies for optimizing\nalgorithmic parameters and discarding irrelevant components as BlitzWS\nprogresses toward a solution. BlitzWS applies to many convex problems,\nincluding training L1-regularized models and support vector machines. We\nshowcase this versatility with empirical comparisons, which demonstrate BlitzWS\nis indeed a fast algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 22:27:41 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Johnson", "Tyler B.", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1807.08048", "submitter": "Haoyang Fan", "authors": "Haoyang Fan, Fan Zhu, Changchun Liu, Liangliang Zhang, Li Zhuang, Dong\n  Li, Weicheng Zhu, Jiangtao Hu, Hongye Li, Qi Kong", "title": "Baidu Apollo EM Motion Planner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we introduce a real-time motion planning system based on\nthe Baidu Apollo (open source) autonomous driving platform. The developed\nsystem aims to address the industrial level-4 motion planning problem while\nconsidering safety, comfort and scalability. The system covers multilane and\nsingle-lane autonomous driving in a hierarchical manner: (1) The top layer of\nthe system is a multilane strategy that handles lane-change scenarios by\ncomparing lane-level trajectories computed in parallel. (2) Inside the\nlane-level trajectory generator, it iteratively solves path and speed\noptimization based on a Frenet frame. (3) For path and speed optimization, a\ncombination of dynamic programming and spline-based quadratic programming is\nproposed to construct a scalable and easy-to-tune framework to handle traffic\nrules, obstacle decisions and smoothness simultaneously. The planner is\nscalable to both highway and lower-speed city driving scenarios. We also\ndemonstrate the algorithm through scenario illustrations and on-road test\nresults.\n  The system described in this manuscript has been deployed to dozens of Baidu\nApollo autonomous driving vehicles since Apollo v1.5 was announced in September\n2017. As of May 16th, 2018, the system has been tested under 3,380 hours and\napproximately 68,000 kilometers (42,253 miles) of closed-loop autonomous\ndriving under various urban scenarios.\n  The algorithm described in this manuscript is available at\nhttps://github.com/ApolloAuto/apollo/tree/master/modules/planning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 22:34:17 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Fan", "Haoyang", ""], ["Zhu", "Fan", ""], ["Liu", "Changchun", ""], ["Zhang", "Liangliang", ""], ["Zhuang", "Li", ""], ["Li", "Dong", ""], ["Zhu", "Weicheng", ""], ["Hu", "Jiangtao", ""], ["Li", "Hongye", ""], ["Kong", "Qi", ""]]}, {"id": "1807.08058", "submitter": "Markus N Rabe", "authors": "Gil Lederman and Markus N. Rabe and Edward A. Lee and Sanjit A. Seshia", "title": "Learning Heuristics for Quantified Boolean Formulas through Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how to learn efficient heuristics for automated reasoning\nalgorithms for quantified Boolean formulas through deep reinforcement learning.\nWe focus on a backtracking search algorithm, which can already solve formulas\nof impressive size - up to hundreds of thousands of variables. The main\nchallenge is to find a representation of these formulas that lends itself to\nmaking predictions in a scalable way. For a family of challenging problems, we\nlearned a heuristic that solves significantly more formulas compared to the\nexisting handwritten heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 23:59:36 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 07:23:14 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 19:38:45 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Lederman", "Gil", ""], ["Rabe", "Markus N.", ""], ["Lee", "Edward A.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1807.08088", "submitter": "Mark Eisen", "authors": "Mark Eisen, Clark Zhang, Luiz F. O. Chamon, Daniel D. Lee, Alejandro\n  Ribeiro", "title": "Learning Optimal Resource Allocations in Wireless Systems", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2908906", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the design of optimal resource allocation policies in\nwireless communication systems which are generically modeled as a functional\noptimization problem with stochastic constraints. These optimization problems\nhave the structure of a learning problem in which the statistical loss appears\nas a constraint, motivating the development of learning methodologies to\nattempt their solution. To handle stochastic constraints, training is\nundertaken in the dual domain. It is shown that this can be done with small\nloss of optimality when using near-universal learning parameterizations. In\nparticular, since deep neural networks (DNN) are near-universal their use is\nadvocated and explored. DNNs are trained here with a model-free primal-dual\nmethod that simultaneously learns a DNN parametrization of the resource\nallocation policy and optimizes the primal and dual variables. Numerical\nsimulations demonstrate the strong performance of the proposed approach on a\nnumber of common wireless resource allocation problems.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 06:00:36 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 21:08:40 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Eisen", "Mark", ""], ["Zhang", "Clark", ""], ["Chamon", "Luiz F. O.", ""], ["Lee", "Daniel D.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1807.08091", "submitter": "Karthik Gurumoorthy", "authors": "Karthik S. Gurumoorthy, Amit Dhurandhar", "title": "Streaming Methods for Restricted Strongly Convex Functions with\n  Applications to Prototype Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that if the optimization function is\nrestricted-strongly-convex (RSC) and restricted-smooth (RSM) -- a rich subclass\nof weakly submodular functions -- then a streaming algorithm with constant\nfactor approximation guarantee is possible. More generally, our results are\napplicable to any monotone weakly submodular function with submodularity ratio\nbounded from above. This (positive) result which provides a sufficient\ncondition for having a constant factor streaming guarantee for weakly\nsubmodular functions may be of special interest given the recent negative\nresult (Elenberg et al., 2017) for the general class of weakly submodular\nfunctions. We apply our streaming algorithms for creating compact synopsis of\nlarge complex datasets, by selecting $m$ representative elements, by optimizing\na suitable RSC and RSM objective function. Above results hold even with\nadditional constraints such as learning non-negative weights, for\ninterpretability, for each selected element indicative of its importance. We\nempirically evaluate our algorithms on two real datasets: MNIST- a handwritten\ndigits dataset and Letters- a UCI dataset containing the alphabet written in\ndifferent fonts and styles. We observe that our algorithms are orders of\nmagnitude faster than the state-of-the-art streaming algorithm for weakly\nsubmodular functions and with our main algorithm still providing equally good\nsolutions in practice.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 06:16:42 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Gurumoorthy", "Karthik S.", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "1807.08108", "submitter": "Zukang Liao", "authors": "Zukang Liao", "title": "Simultaneous Adversarial Training - Learn from Others Mistakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are maliciously tweaked images that can easily fool\nmachine learning techniques, such as neural networks, but they are normally not\nvisually distinguishable for human beings. One of the main approaches to solve\nthis problem is to retrain the networks using those adversarial examples,\nnamely adversarial training. However, standard adversarial training might not\nactually change the decision boundaries but cause the problem of gradient\nmasking, resulting in a weaker ability to generate adversarial examples.\nTherefore, it cannot alleviate the problem of black-box attacks, where\nadversarial examples generated from other networks can transfer to the targeted\none. In order to reduce the problem of black-box attacks, we propose a novel\nmethod that allows two networks to learn from each others' adversarial examples\nand become resilient to black-box attacks. We also combine this method with a\nsimple domain adaptation to further improve the performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 08:28:21 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 04:53:14 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 02:13:28 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Liao", "Zukang", ""]]}, {"id": "1807.08133", "submitter": "John Kelleher", "authors": "John D. Kelleher and Simon Dobnik", "title": "What is not where: the challenge of integrating spatial representations\n  into deep learning architectures", "comments": "15 pages, 10 figures, Appears in CLASP Papers in Computational\n  Linguistics Vol 1: Proceedings of the Conference on Logic and Machine\n  Learning in Natural Language (LaML 2017), pp. 41-52", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines to what degree current deep learning architectures for\nimage caption generation capture spatial language. On the basis of the\nevaluation of examples of generated captions from the literature we argue that\nsystems capture what objects are in the image data but not where these objects\nare located: the captions generated by these systems are the output of a\nlanguage model conditioned on the output of an object detector that cannot\ncapture fine-grained location information. Although language models provide\nuseful knowledge for image captions, we argue that deep learning image\ncaptioning architectures should also model geometric relations between objects.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:55:17 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kelleher", "John D.", ""], ["Dobnik", "Simon", ""]]}, {"id": "1807.08140", "submitter": "Vishwak Srinivasan", "authors": "Adepu Ravi Sankar, Vishwak Srinivasan and Vineeth N Balasubramanian", "title": "On the Analysis of Trajectories of Gradient Descent in the Optimization\n  of Deep Neural Networks", "comments": "4 pages + 1 figure (main, excluding references), 5 pages + 4 figures\n  (appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical analysis of the error landscape of deep neural networks has\ngarnered significant interest in recent years. In this work, we theoretically\nstudy the importance of noise in the trajectories of gradient descent towards\noptimal solutions in multi-layer neural networks. We show that adding noise (in\ndifferent ways) to a neural network while training increases the rank of the\nproduct of weight matrices of a multi-layer linear neural network. We thus\nstudy how adding noise can assist reaching a global optimum when the product\nmatrix is full-rank (under certain conditions). We establish theoretical\nfoundations between the noise induced into the neural network - either to the\ngradient, to the architecture, or to the input/output to a neural network - and\nthe rank of product of weight matrices. We corroborate our theoretical findings\nwith empirical results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 12:32:36 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Sankar", "Adepu Ravi", ""], ["Srinivasan", "Vishwak", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1807.08158", "submitter": "Roberto Pirrone", "authors": "Roberto Pirrone, Vincenzo Cannella, Sergio Monteleone, Gabriella\n  Giordano", "title": "Linear density-based clustering with a discrete density model", "comments": "40 pages, 9 figures, 9 tables, 4 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density-based clustering techniques are used in a wide range of data mining\napplications. One of their most attractive features con- sists in not making\nuse of prior knowledge of the number of clusters that a dataset contains along\nwith their shape. In this paper we propose a new algorithm named Linear DBSCAN\n(Lin-DBSCAN), a simple approach to clustering inspired by the density model\nintroduced with the well known algorithm DBSCAN. Designed to minimize the\ncomputational cost of density based clustering on geospatial data, Lin-DBSCAN\nfeatures a linear time complexity that makes it suitable for real-time\napplications on low-resource devices. Lin-DBSCAN uses a discrete version of the\ndensity model of DBSCAN that takes ad- vantage of a grid-based scan and merge\napproach. The name of the algorithm stems exactly from its main features\noutlined above. The algorithm was tested with well known data sets.\nExperimental results prove the efficiency and the validity of this approach\nover DBSCAN in the context of spatial data clustering, enabling the use of a\ndensity-based clustering technique on large datasets with low computational\ncost.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 14:03:45 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Pirrone", "Roberto", ""], ["Cannella", "Vincenzo", ""], ["Monteleone", "Sergio", ""], ["Giordano", "Gabriella", ""]]}, {"id": "1807.08169", "submitter": "Jibon Naher", "authors": "Matiur Rahman Minar, Jibon Naher", "title": "Recent Advances in Deep Learning: An Overview", "comments": "31 pages including bibliography", "journal-ref": null, "doi": "10.13140/RG.2.2.24831.10403", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is one of the newest trends in Machine Learning and Artificial\nIntelligence research. It is also one of the most popular scientific research\ntrends now-a-days. Deep learning methods have brought revolutionary advances in\ncomputer vision and machine learning. Every now and then, new and new deep\nlearning techniques are being born, outperforming state-of-the-art machine\nlearning and even existing deep learning techniques. In recent years, the world\nhas seen many major breakthroughs in this field. Since deep learning is\nevolving at a huge speed, its kind of hard to keep track of the regular\nadvances especially for new researchers. In this paper, we are going to briefly\ndiscuss about recent advances in Deep Learning for past few years.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 15:40:10 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Minar", "Matiur Rahman", ""], ["Naher", "Jibon", ""]]}, {"id": "1807.08207", "submitter": "Humphrey Sheil", "authors": "Humphrey Sheil, Omer Rana, Ronan Reilly", "title": "Predicting purchasing intent: Automatic Feature Learning using Recurrent\n  Neural Networks", "comments": "Accepted to SIGIR eCom workshop, Ann Arbor, Michigan, USA, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural network for predicting purchasing intent in an Ecommerce\nsetting. Our main contribution is to address the significant investment in\nfeature engineering that is usually associated with state-of-the-art methods\nsuch as Gradient Boosted Machines. We use trainable vector spaces to model\nvaried, semi-structured input data comprising categoricals, quantities and\nunique instances. Multi-layer recurrent neural networks capture both\nsession-local and dataset-global event dependencies and relationships for user\nsessions of any length. An exploration of model design decisions including\nparameter sharing and skip connections further increase model accuracy. Results\non benchmark datasets deliver classification accuracy within 98% of\nstate-of-the-art on one and exceed state-of-the-art on the second without the\nneed for any domain / dataset-specific feature engineering on both short and\nlong event sequences.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 22:29:36 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Sheil", "Humphrey", ""], ["Rana", "Omer", ""], ["Reilly", "Ronan", ""]]}, {"id": "1807.08216", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Cs. Cs\\'aji, Marco C. Campi, Erik Weyer", "title": "Sign-Perturbed Sums: A New System Identification Approach for\n  Constructing Exact Non-Asymptotic Confidence Regions in Linear Regression\n  Models", "comments": "12 pages, 7 figures, 8 tables, 32 references", "journal-ref": "IEEE Transactions on Signal Processing, Volume 63, Issue 1, 2015,\n  pp. 169-181", "doi": "10.1109/TSP.2014.2369000", "report-no": null, "categories": "eess.SP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new system identification method, called Sign-Perturbed Sums\n(SPS), for constructing non-asymptotic confidence regions under mild\nstatistical assumptions. SPS is introduced for linear regression models,\nincluding but not limited to FIR systems, and we show that the SPS confidence\nregions have exact confidence probabilities, i.e., they contain the true\nparameter with a user-chosen exact probability for any finite data set.\nMoreover, we also prove that the SPS regions are star convex with the\nLeast-Squares (LS) estimate as a star center. The main assumptions of SPS are\nthat the noise terms are independent and symmetrically distributed about zero,\nbut they can be nonstationary, and their distributions need not be known. The\npaper also proposes a computationally efficient ellipsoidal outer approximation\nalgorithm for SPS. Finally, SPS is demonstrated through a number of simulation\nexperiments.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 00:43:35 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Cs.", ""], ["Campi", "Marco C.", ""], ["Weyer", "Erik", ""]]}, {"id": "1807.08233", "submitter": "Surya Dantuluri", "authors": "Surya Dantuluri", "title": "Rapid Autonomous Car Control based on Spatial and Temporal Visual Cues", "comments": "8 pages, 23 figures, Video link of Salient Object Visualization:\n  https://youtu.be/lFjsN7KcKIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel approach to modern car control utilizing a combination of\nDeep Convolutional Neural Networks and Long Short-Term Memory Systems: Both of\nwhich are a subsection of Hierarchical Representations Learning, more commonly\nknown as Deep Learning. Using Deep Convolutional Neural Networks and Long\nShort-Term Memory Systems (DCNN/LSTM), we propose an end-to-end approach to\naccurately predict steering angles and throttle values. We use this algorithm\non our latest robot, El Toro Grande 1 (ETG) which is equipped with a variety of\nsensors in order to localize itself in its environment. Using previous training\ndata and the data that it collects during circuit and drag races, it predicts\nthrottle and steering angles in order to stay on path and avoid colliding into\nother robots. This allows ETG to theoretically race on any track with\nsufficient training data.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 03:41:30 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Dantuluri", "Surya", ""]]}, {"id": "1807.08237", "submitter": "Xingjun Ma", "authors": "Yisen Wang, Bo Dai, Lingkai Kong, Sarah Monazam Erfani, James Bailey,\n  Hongyuan Zha", "title": "Learning Deep Hidden Nonlinear Dynamics from Aggregate Data", "comments": "In Proceedings of the Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning nonlinear dynamics from diffusion data is a challenging problem\nsince the individuals observed may be different at different time points,\ngenerally following an aggregate behaviour. Existing work cannot handle the\ntasks well since they model such dynamics either directly on observations or\nenforce the availability of complete longitudinal individual-level\ntrajectories. However, in most of the practical applications, these\nrequirements are unrealistic: the evolving dynamics may be too complex to be\nmodeled directly on observations, and individual-level trajectories may not be\navailable due to technical limitations, experimental costs and/or privacy\nissues. To address these challenges, we formulate a model of diffusion dynamics\nas the {\\em hidden stochastic process} via the introduction of hidden variables\nfor flexibility, and learn the hidden dynamics directly on {\\em aggregate\nobservations} without any requirement for individual-level trajectories. We\npropose a dynamic generative model with Wasserstein distance for LEarninG dEep\nhidden Nonlinear Dynamics (LEGEND) and prove its theoretical guarantees as\nwell. Experiments on a range of synthetic and real-world datasets illustrate\nthat LEGEND has very strong performance compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 05:59:41 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 12:07:43 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Wang", "Yisen", ""], ["Dai", "Bo", ""], ["Kong", "Lingkai", ""], ["Erfani", "Sarah Monazam", ""], ["Bailey", "James", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1807.08241", "submitter": "Malik Aqeel Anwar", "authors": "Malik Aqeel Anwar, Arijit Raychowdhury", "title": "NAVREN-RL: Learning to fly in real environment via end-to-end deep\n  reinforcement learning using monocular images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NAVREN-RL, an approach to NAVigate an unmanned aerial vehicle in\nan indoor Real ENvironment via end-to-end reinforcement learning RL. A suitable\nreward function is designed keeping in mind the cost and weight constraints for\nmicro drone with minimum number of sensing modalities. Collection of small\nnumber of expert data and knowledge based data aggregation is integrated into\nthe RL process to aid convergence. Experimentation is carried out on a Parrot\nAR drone in different indoor arenas and the results are compared with other\nbaseline technologies. We demonstrate how the drone successfully avoids\nobstacles and navigates across different arenas.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 06:10:04 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Anwar", "Malik Aqeel", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1807.08265", "submitter": "Mark Scanlon", "authors": "Quan Le, Ois\\'in Boydell, Brian Mac Namee, Mark Scanlon", "title": "Deep learning at the shallow end: Malware classification for non-domain\n  experts", "comments": null, "journal-ref": "Digital Investigation, Volume 26, Supplement, 2018, Pages\n  S118-S126, ISSN 1742-2876", "doi": "10.1016/j.diin.2018.04.024", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current malware detection and classification approaches generally rely on\ntime consuming and knowledge intensive processes to extract patterns\n(signatures) and behaviors from malware, which are then used for\nidentification. Moreover, these signatures are often limited to local,\ncontiguous sequences within the data whilst ignoring their context in relation\nto each other and throughout the malware file as a whole. We present a Deep\nLearning based malware classification approach that requires no expert domain\nknowledge and is based on a purely data driven approach for complex pattern and\nfeature identification.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 10:07:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Le", "Quan", ""], ["Boydell", "Ois\u00edn", ""], ["Mac Namee", "Brian", ""], ["Scanlon", "Mark", ""]]}, {"id": "1807.08280", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Multi-scale Alignment and Contextual History for Attention Mechanism in\n  Sequence-to-sequence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequence-to-sequence model is a neural network module for mapping two\nsequences of different lengths. The sequence-to-sequence model has three core\nmodules: encoder, decoder, and attention. Attention is the bridge that connects\nthe encoder and decoder modules and improves model performance in many tasks.\nIn this paper, we propose two ideas to improve sequence-to-sequence model\nperformance by enhancing the attention module. First, we maintain the history\nof the location and the expected context from several previous time-steps.\nSecond, we apply multiscale convolution from several previous attention vectors\nto the current decoder state. We utilized our proposed framework for\nsequence-to-sequence speech recognition and text-to-speech systems. The results\nreveal that our proposed extension could improve performance significantly\ncompared to a standard attention baseline.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 13:10:30 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1807.08312", "submitter": "Mahdi Hajibabaei", "authors": "Mahdi Hajibabaei, Dengxin Dai", "title": "Unified Hypersphere Embedding for Speaker Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental improvements in accuracy of Convolutional Neural Networks are\nusually achieved through use of deeper and more complex models trained on\nlarger datasets. However, enlarging dataset and models increases the\ncomputation and storage costs and cannot be done indefinitely. In this work, we\nseek to improve the identification and verification accuracy of a\ntext-independent speaker recognition system without use of extra data or deeper\nand more complex models by augmenting the training and testing data, finding\nthe optimal dimensionality of embedding space and use of more discriminative\nloss functions. Results of experiments on VoxCeleb dataset suggest that: (i)\nSimple repetition and random time-reversion of utterances can reduce prediction\nerrors by up to 18%. (ii) Lower dimensional embeddings are more suitable for\nverification. (iii) Use of proposed logistic margin loss function leads to\nunified embeddings with state-of-the-art identification and competitive\nverification accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 16:26:31 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Hajibabaei", "Mahdi", ""], ["Dai", "Dengxin", ""]]}, {"id": "1807.08315", "submitter": "Nicholas Mastronarde", "authors": "Nikhilesh Sharma, Nicholas Mastronarde, Jacob Chakareski", "title": "Accelerated Structure-Aware Reinforcement Learning for Delay-Sensitive\n  Energy Harvesting Wireless Sensors", "comments": "arXiv admin note: text overlap with arXiv:1803.09778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an energy-harvesting wireless sensor transmitting\nlatency-sensitive data over a fading channel. The sensor injects captured data\npackets into its transmission queue and relies on ambient energy harvested from\nthe environment to transmit them. We aim to find the optimal scheduling policy\nthat decides whether or not to transmit the queue's head-of-line packet at each\ntransmission opportunity such that the expected packet queuing delay is\nminimized given the available harvested energy. No prior knowledge of the\nstochastic processes that govern the channel, captured data, or harvested\nenergy dynamics are assumed, thereby necessitating the use of online learning\nto optimize the scheduling policy. We formulate this scheduling problem as a\nMarkov decision process (MDP) and analyze the structural properties of its\noptimal value function. In particular, we show that it is non-decreasing and\nhas increasing differences in the queue backlog and that it is non-increasing\nand has increasing differences in the battery state. We exploit this structure\nto formulate a novel accelerated reinforcement learning (RL) algorithm to solve\nthe scheduling problem online at a much faster learning rate, while limiting\nthe induced computational complexity. Our experiments demonstrate that the\nproposed algorithm closely approximates the performance of an optimal offline\nsolution that requires a priori knowledge of the channel, captured data, and\nharvested energy dynamics. Simultaneously, by leveraging the value function's\nstructure, our approach achieves competitive performance relative to a\nstate-of-the-art RL algorithm, at potentially orders of magnitude lower\ncomplexity. Finally, considerable performance gains are demonstrated over the\nwell-known and widely used Q-learning algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 16:41:50 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 18:17:57 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Sharma", "Nikhilesh", ""], ["Mastronarde", "Nicholas", ""], ["Chakareski", "Jacob", ""]]}, {"id": "1807.08360", "submitter": "Lijun Yu", "authors": "Lijun Yu, Dawei Zhang, Xiangqun Chen, Xing Xie", "title": "MOBA-Slice: A Time Slice Based Evaluation Framework of Relative\n  Advantage between Teams in MOBA Games", "comments": "Computer Games Workshop at IJCAI 2018, Stockholm, Friday 13 July,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplayer Online Battle Arena (MOBA) is currently one of the most popular\ngenres of digital games around the world. The domain of knowledge contained in\nthese complicated games is large. It is hard for humans and algorithms to\nevaluate the real-time game situation or predict the game result. In this\npaper, we introduce MOBA-Slice, a time slice based evaluation framework of\nrelative advantage between teams in MOBA games. MOBA-Slice is a quantitative\nevaluation method based on learning, similar to the value network of AlphaGo.\nIt establishes a foundation for further MOBA related research including AI\ndevelopment. In MOBA-Slice, with an analysis of the deciding factors of MOBA\ngame results, we design a neural network model to fit our discounted evaluation\nfunction. Then we apply MOBA-Slice to Defense of the Ancients 2 (DotA2), a\ntypical and popular MOBA game. Experiments on a large number of match replays\nshow that our model works well on arbitrary matches. MOBA-Slice not only has an\naccuracy 3.7% higher than DotA Plus Assistant at result prediction, but also\nsupports the prediction of the remaining time of the game, and then realizes\nthe evaluation of relative advantage between teams.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 20:20:43 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Yu", "Lijun", ""], ["Zhang", "Dawei", ""], ["Chen", "Xiangqun", ""], ["Xie", "Xing", ""]]}, {"id": "1807.08362", "submitter": "James Foulds", "authors": "James Foulds and Rashidul Islam and Kamrun Naher Keya and Shimei Pan", "title": "An Intersectional Definition of Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose definitions of fairness in machine learning and artificial\nintelligence systems that are informed by the framework of intersectionality, a\ncritical lens arising from the Humanities literature which analyzes how\ninterlocking systems of power and oppression affect individuals along\noverlapping dimensions including gender, race, sexual orientation, class, and\ndisability. We show that our criteria behave sensibly for any subset of the set\nof protected attributes, and we prove economic, privacy, and generalization\nguarantees. We provide a learning algorithm which respects our intersectional\nfairness criteria. Case studies on census data and the COMPAS criminal\nrecidivism dataset demonstrate the utility of our methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 20:37:45 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 22:25:00 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 04:12:17 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Foulds", "James", ""], ["Islam", "Rashidul", ""], ["Keya", "Kamrun Naher", ""], ["Pan", "Shimei", ""]]}, {"id": "1807.08364", "submitter": "Kunal Menda", "authors": "Kunal Menda, Katherine Driggs-Campbell, Mykel J. Kochenderfer", "title": "EnsembleDAgger: A Bayesian Approach to Safe Imitation Learning", "comments": "Accepted to the 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While imitation learning is often used in robotics, the approach frequently\nsuffers from data mismatch and compounding errors. DAgger is an iterative\nalgorithm that addresses these issues by aggregating training data from both\nthe expert and novice policies, but does not consider the impact of safety. We\npresent a probabilistic extension to DAgger, which attempts to quantify the\nconfidence of the novice policy as a proxy for safety. Our method,\nEnsembleDAgger, approximates a Gaussian Process using an ensemble of neural\nnetworks. Using the variance as a measure of confidence, we compute a decision\nrule that captures how much we doubt the novice, thus determining when it is\nsafe to allow the novice to act. With this approach, we aim to maximize the\nnovice's share of actions, while constraining the probability of failure. We\ndemonstrate improved safety and learning performance compared to other DAgger\nvariants and classic imitation learning on an inverted pendulum and in the\nMuJoCo HalfCheetah environment.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 20:52:56 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 20:47:20 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 18:03:57 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Menda", "Kunal", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1807.08372", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen, Freddy Lecue, Jeff Z. Pan, Ian Horrocks, Huajun Chen", "title": "Knowledge-based Transfer Learning Explanation", "comments": "Accepted by International Conference on Principles of Knowledge\n  Representation and Reasoning, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning explanation can significantly boost machine learning's\napplication in decision making, but the usability of current methods is limited\nin human-centric explanation, especially for transfer learning, an important\nmachine learning branch that aims at utilizing knowledge from one learning\ndomain (i.e., a pair of dataset and prediction task) to enhance prediction\nmodel training in another learning domain. In this paper, we propose an\nontology-based approach for human-centric explanation of transfer learning.\nThree kinds of knowledge-based explanatory evidence, with different\ngranularities, including general factors, particular narrators and core\ncontexts are first proposed and then inferred with both local ontologies and\nexternal knowledge bases. The evaluation with US flight data and DBpedia has\npresented their confidence and availability in explaining the transferability\nof feature representation in flight departure delay forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 21:32:12 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Lecue", "Freddy", ""], ["Pan", "Jeff Z.", ""], ["Horrocks", "Ian", ""], ["Chen", "Huajun", ""]]}, {"id": "1807.08383", "submitter": "Yubin Park", "authors": "Yubin Park and Joyce C. Ho", "title": "PaloBoost: An Overfitting-robust TreeBoost with Out-of-Bag Sample\n  Regularization Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient TreeBoost is often found in many winning solutions in\npublic data science challenges. Unfortunately, the best performance requires\nextensive parameter tuning and can be prone to overfitting. We propose\nPaloBoost, a Stochastic Gradient TreeBoost model that uses novel regularization\ntechniques to guard against overfitting and is robust to parameter settings.\nPaloBoost uses the under-utilized out-of-bag samples to perform gradient-aware\npruning and estimate adaptive learning rates. Unlike other Stochastic Gradient\nTreeBoost models that use the out-of-bag samples to estimate test errors,\nPaloBoost treats the samples as a second batch of training samples to prune the\ntrees and adjust the learning rates. As a result, PaloBoost can dynamically\nadjust tree depths and learning rates to achieve faster learning at the start\nand slower learning as the algorithm converges. We illustrate how these\nregularization techniques can be efficiently implemented and propose a new\nformula for calculating feature importance to reflect the node coverages and\nlearning rates. Extensive experimental results on seven datasets demonstrate\nthat PaloBoost is robust to overfitting, is less sensitivity to the parameters,\nand can also effectively identify meaningful features.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 23:29:28 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Park", "Yubin", ""], ["Ho", "Joyce C.", ""]]}, {"id": "1807.08388", "submitter": "Markus Foote", "authors": "Markus D. Foote (1), Blake E. Zimmerman (1), Amit Sawant (2), Sarang\n  Joshi (1) ((1) Scientific Computing and Imaging Institute, Department of\n  Bioengineering, University of Utah, (2) Department of Radiation Oncology, The\n  University of Maryland School of Medicine)", "title": "Real-Time 2D-3D Deformable Registration with Deep Learning and\n  Application to Lung Radiotherapy Targeting", "comments": null, "journal-ref": "IPMI 2019. Lecture Notes in Computer Science, vol 11492. Springer,\n  Cham (2019)", "doi": "10.1007/978-3-030-20351-1_20", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiation therapy presents a need for dynamic tracking of a target tumor\nvolume. Fiducial markers such as implanted gold seeds have been used to gate\nradiation delivery but the markers are invasive and gating significantly\nincreases treatment time. Pretreatment acquisition of a respiratory correlated\n4DCT allows for determination of accurate motion tracking which is useful in\ntreatment planning. We design a patient-specific motion subspace and a deep\nconvolutional neural network to recover anatomical positions from a single\nfluoroscopic projection in real-time. We use this deep network to approximate\nthe nonlinear inverse of a diffeomorphic deformation composed with radiographic\nprojection. This network recovers subspace coordinates to define the\npatient-specific deformation of the lungs from a baseline anatomic position.\nThe geometric accuracy of the subspace deformations on real patient data is\nsimilar to accuracy attained by original image registration between individual\nrespiratory-phase image volumes.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 23:45:34 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:49:30 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Foote", "Markus D.", ""], ["Zimmerman", "Blake E.", ""], ["Sawant", "Amit", ""], ["Joshi", "Sarang", ""]]}, {"id": "1807.08390", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji", "title": "Score Permutation Based Finite Sample Inference for Generalized\n  AutoRegressive Conditional Heteroskedasticity (GARCH) Models", "comments": "19th International Conference on Artificial Intelligence and\n  Statistics (AISTATS)", "journal-ref": "Proceedings of Machine Learning Research, Volume 51, 2016, pp.\n  296-304", "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM math.DS q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard model of (conditional) heteroscedasticity, i.e., the phenomenon\nthat the variance of a process changes over time, is the Generalized\nAutoRegressive Conditional Heteroskedasticity (GARCH) model, which is\nespecially important for economics and finance. GARCH models are typically\nestimated by the Quasi-Maximum Likelihood (QML) method, which works under mild\nstatistical assumptions. Here, we suggest a finite sample approach, called\nScoPe, to construct distribution-free confidence regions around the QML\nestimate, which have exact coverage probabilities, despite no additional\nassumptions about moments are made. ScoPe is inspired by the recently developed\nSign-Perturbed Sums (SPS) method, which however cannot be applied in the GARCH\ncase. ScoPe works by perturbing the score function using randomly permuted\nresiduals. This produces alternative samples which lead to exact confidence\nregions. Experiments on simulated and stock market data are also presented, and\nScoPe is compared with the asymptotic theory and bootstrap approaches.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 00:02:36 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""]]}, {"id": "1807.08405", "submitter": "Trent Houliston", "authors": "Trent Houliston and Stephan K. Chalup", "title": "Visual Mesh: Real-time Object Detection Using Constant Sample Density", "comments": "12 pages, 6 figures, RoboCup International Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an enhancement of convolutional neural networks for\nobject detection in resource-constrained robotics through a geometric input\ntransformation called Visual Mesh. It uses object geometry to create a graph in\nvision space, reducing computational complexity by normalizing the pixel and\nfeature density of objects. The experiments compare the Visual Mesh with\nseveral other fast convolutional neural networks. The results demonstrate\nexecution times sixteen times quicker than the fastest competitor tested, while\nachieving outstanding accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 02:21:31 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Houliston", "Trent", ""], ["Chalup", "Stephan K.", ""]]}, {"id": "1807.08446", "submitter": "Ibrahim Jubran", "authors": "Ibrahim Jubran and Dan Feldman", "title": "Aligning Points to Lines: Provable Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new optimization technique for minimizing the sum $\\sum_{i=1}^n\nf_i(x)$ of $n$ non-convex real functions that satisfy a property that we call\npiecewise log-Lipschitz. This is by forging links between techniques in\ncomputational geometry, combinatorics and convex optimization. As an example\napplication, we provide the first constant-factor approximation algorithms\nwhose running-time is polynomial in $n$ for the fundamental problem of\n\\emph{Points-to-Lines alignment}: Given $n$ points $p_1,\\cdots,p_n$ and $n$\nlines $\\ell_1,\\cdots,\\ell_n$ on the plane and $z>0$, compute the matching\n$\\pi:[n]\\to[n]$ and alignment (rotation matrix $R$ and a translation vector\n$t$) that minimize the sum of Euclidean distances $\\sum_{i=1}^n\n\\mathrm{dist}(Rp_i-t,\\ell_{\\pi(i)})^z$ between each point to its corresponding\nline.\n  This problem is non-trivial even if $z=1$ and the matching $\\pi$ is given. If\n$\\pi$ is given, the running time of our algorithms is $O(n^3)$, and even\nnear-linear in $n$ using core-sets that support: streaming, dynamic, and\ndistributed parallel computations in poly-logarithmic update time.\nGeneralizations for handling e.g. outliers or pseudo-distances such as\n$M$-estimators for the problem are also provided.\n  Experimental results and open source code show that our provable algorithms\nimprove existing heuristics also in practice. A companion demonstration video\nin the context of Augmented Reality shows how such algorithms may be used in\nreal-time systems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:45:15 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 09:10:27 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 16:47:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jubran", "Ibrahim", ""], ["Feldman", "Dan", ""]]}, {"id": "1807.08447", "submitter": "Rakshit Trivedi", "authors": "Rakshit Trivedi and Bunyamin Sisman and Jun Ma and Christos Faloutsos\n  and Hongyuan Zha and Xin Luna Dong", "title": "LinkNBed: Multi-Graph Representation Learning with Entity Linkage", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs have emerged as an important model for studying complex\nmulti-relational data. This has given rise to the construction of numerous\nlarge scale but incomplete knowledge graphs encoding information extracted from\nvarious resources. An effective and scalable approach to jointly learn over\nmultiple graphs and eventually construct a unified graph is a crucial next step\nfor the success of knowledge-based inference for many downstream applications.\nTo this end, we propose LinkNBed, a deep relational learning framework that\nlearns entity and relationship representations across multiple graphs. We\nidentify entity linkage across graphs as a vital component to achieve our goal.\nWe design a novel objective that leverage entity linkage and build an efficient\nmulti-task training procedure. Experiments on link prediction and entity\nlinkage demonstrate substantial improvements over the state-of-the-art\nrelational learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:47:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Trivedi", "Rakshit", ""], ["Sisman", "Bunyamin", ""], ["Ma", "Jun", ""], ["Faloutsos", "Christos", ""], ["Zha", "Hongyuan", ""], ["Dong", "Xin Luna", ""]]}, {"id": "1807.08452", "submitter": "Somnuk Phon-Amnuaisuk", "authors": "Somnuk Phon-Amnuaisuk", "title": "Learning to Play Pong using Policy Gradient Learning", "comments": "19 pages, 9 figures. Expanded from a conference paper titled 'What\n  does a policy network learn after mastering a Pong game?\" by the same author.\n  MIWAI 2017 pp. 213-222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activities in reinforcement learning (RL) revolve around learning the Markov\ndecision process (MDP) model, in particular, the following parameters: state\nvalues, V; state-action values, Q; and policy, pi. These parameters are\ncommonly implemented as an array. Scaling up the problem means scaling up the\nsize of the array and this will quickly lead to a computational bottleneck. To\nget around this, the RL problem is commonly formulated to learn a specific task\nusing hand-crafted input features to curb the size of the array. In this\nreport, we discuss an alternative end-to-end Deep Reinforcement Learning (DRL)\napproach where the DRL attempts to learn general task representations which in\nour context refers to learning to play the Pong game from a sequence of screen\nsnapshots without game-specific hand-crafted features. We apply artificial\nneural networks (ANN) to approximate a policy of the RL model. The policy\nnetwork, via Policy Gradients (PG) method, learns to play the Pong game from a\nsequence of frames without any extra semantics apart from the pixel information\nand the score. In contrast to the traditional tabular RL approach where the\ncontents in the array have clear interpretations such as V or Q, the\ninterpretation of knowledge content from the weights of the policy network is\nmore illusive. In this work, we experiment with various Deep ANN architectures\ni.e., Feed forward ANN (FFNN), Convolution ANN (CNN) and Asynchronous Advantage\nActor-Critic (A3C). We also examine the activation of hidden nodes and the\nweights between the input and the hidden layers, before and after the DRL has\nsuccessfully learnt to play the Pong game. Insights into the internal learning\nmechanisms and future research directions are then discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:55:23 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Phon-Amnuaisuk", "Somnuk", ""]]}, {"id": "1807.08459", "submitter": "Qiang Zhu", "authors": "Qiang Zhu and Xixiang Lv", "title": "2P-DNN : Privacy-Preserving Deep Neural Networks Based on Homomorphic\n  Cryptosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS), such as Microsoft Azure, Amazon AWS,\noffers an effective DNN model to complete the machine learning task for small\nbusinesses and individuals who are restricted to the lacking data and computing\npower. However, here comes an issue that user privacy is ex-posed to the MLaaS\nserver, since users need to upload their sensitive data to the MLaaS server. In\norder to preserve their privacy, users can encrypt their data before uploading\nit. This makes it difficult to run the DNN model because it is not designed for\nrunning in ciphertext domain. In this paper, using the Paillier homomorphic\ncryptosystem we present a new Privacy-Preserving Deep Neural Network model that\nwe called 2P-DNN. This model can fulfill the machine leaning task in ciphertext\ndomain. By using 2P-DNN, MLaaS is able to provide a Privacy-Preserving machine\nlearning ser-vice for users. We build our 2P-DNN model based on LeNet-5, and\ntest it with the encrypted MNIST dataset. The classification accuracy is more\nthan 97%, which is close to the accuracy of LeNet-5 running with the MNIST\ndataset and higher than that of other existing Privacy-Preserving machine\nlearning models\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 07:32:12 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Zhu", "Qiang", ""], ["Lv", "Xixiang", ""]]}, {"id": "1807.08465", "submitter": "Philipp Blandfort", "authors": "Philipp Blandfort, Desmond Patton, William R. Frey, Svebor Karaman,\n  Surabhi Bhargava, Fei-Tzin Lee, Siddharth Varia, Chris Kedzie, Michael B.\n  Gaskell, Rossano Schifanella, Kathleen McKeown, Shih-Fu Chang", "title": "Multimodal Social Media Analysis for Gang Violence Prevention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gang violence is a severe issue in major cities across the U.S. and recent\nstudies [Patton et al. 2017] have found evidence of social media communications\nthat can be linked to such violence in communities with high rates of exposure\nto gang activity. In this paper we partnered computer scientists with social\nwork researchers, who have domain expertise in gang violence, to analyze how\npublic tweets with images posted by youth who mention gang associations on\nTwitter can be leveraged to automatically detect psychosocial factors and\nconditions that could potentially assist social workers and violence outreach\nworkers in prevention and early intervention programs. To this end, we\ndeveloped a rigorous methodology for collecting and annotating tweets. We\ngathered 1,851 tweets and accompanying annotations related to visual concepts\nand the psychosocial codes: aggression, loss, and substance use. These codes\nare relevant to social work interventions, as they represent possible pathways\nto violence on social media. We compare various methods for classifying tweets\ninto these three classes, using only the text of the tweet, only the image of\nthe tweet, or both modalities as input to the classifier. In particular, we\nanalyze the usefulness of mid-level visual concepts and the role of different\nmodalities for this tweet classification task. Our experiments show that\nindividually, text information dominates classification performance of the loss\nclass, while image information dominates the aggression and substance use\nclasses. Our multimodal approach provides a very promising improvement (18%\nrelative in mean average precision) over the best single modality approach.\nFinally, we also illustrate the complexity of understanding social media data\nand elaborate on open challenges.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 07:52:52 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Blandfort", "Philipp", ""], ["Patton", "Desmond", ""], ["Frey", "William R.", ""], ["Karaman", "Svebor", ""], ["Bhargava", "Surabhi", ""], ["Lee", "Fei-Tzin", ""], ["Varia", "Siddharth", ""], ["Kedzie", "Chris", ""], ["Gaskell", "Michael B.", ""], ["Schifanella", "Rossano", ""], ["McKeown", "Kathleen", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1807.08479", "submitter": "Ya Li", "authors": "Ya Li, Mingming Gong, Xinmei Tian, Tongliang Liu, Dacheng Tao", "title": "Domain Generalization via Conditional Invariant Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain generalization aims to apply knowledge gained from multiple labeled\nsource domains to unseen target domains. The main difficulty comes from the\ndataset bias: training data and test data have different distributions, and the\ntraining set contains heterogeneous samples from different distributions. Let\n$X$ denote the features, and $Y$ be the class labels. Existing domain\ngeneralization methods address the dataset bias problem by learning a\ndomain-invariant representation $h(X)$ that has the same marginal distribution\n$\\mathbb{P}(h(X))$ across multiple source domains. The functional relationship\nencoded in $\\mathbb{P}(Y|X)$ is usually assumed to be stable across domains\nsuch that $\\mathbb{P}(Y|h(X))$ is also invariant. However, it is unclear\nwhether this assumption holds in practical problems. In this paper, we consider\nthe general situation where both $\\mathbb{P}(X)$ and $\\mathbb{P}(Y|X)$ can\nchange across all domains. We propose to learn a feature representation which\nhas domain-invariant class conditional distributions $\\mathbb{P}(h(X)|Y)$. With\nthe conditional invariant representation, the invariance of the joint\ndistribution $\\mathbb{P}(h(X),Y)$ can be guaranteed if the class prior\n$\\mathbb{P}(Y)$ does not change across training and test domains. Extensive\nexperiments on both synthetic and real data demonstrate the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 08:33:46 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Li", "Ya", ""], ["Gong", "Mingming", ""], ["Tian", "Xinmei", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1807.08501", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Sagie Benaim, Lior Wolf", "title": "Risk Bounds for Unsupervised Cross-Domain Mapping with IPMs", "comments": "arXiv admin note: text overlap with arXiv:1709.00074", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent empirical success of unsupervised cross-domain mapping algorithms,\nbetween two domains that share common characteristics, is not well-supported by\ntheoretical justifications. This lacuna is especially troubling, given the\nclear ambiguity in such mappings.\n  We work with adversarial training methods based on IPMs and derive a novel\nrisk bound, which upper bounds the risk between the learned mapping $h$ and the\ntarget mapping $y$, by a sum of three terms: (i) the risk between $h$ and the\nmost distant alternative mapping that was learned by the same cross-domain\nmapping algorithm, (ii) the minimal discrepancy between the target domain and\nthe domain obtained by applying a hypothesis $h^*$ on the samples of the source\ndomain, where $h^*$ is a hypothesis selectable by the same algorithm. The bound\nis directly related to Occam's razor and encourages the selection of the\nminimal architecture that supports a small mapping discrepancy and (iii) an\napproximation error term that decreases as the complexity of the class of\ndiscriminators increases and is empirically shown to be small.\n  The bound leads to multiple algorithmic consequences, including a method for\nhyperparameters selection and for early stopping in cross-domain mapping GANs.\nWe also demonstrate a novel capability for unsupervised learning of estimating\nconfidence in the mapping of every specific sample.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 09:33:51 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 11:49:35 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 16:37:33 GMT"}, {"version": "v4", "created": "Mon, 2 Nov 2020 12:05:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Galanti", "Tomer", ""], ["Benaim", "Sagie", ""], ["Wolf", "Lior", ""]]}, {"id": "1807.08518", "submitter": "Mark Collier", "authors": "Mark Collier and Joeran Beel", "title": "Implementing Neural Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Turing Machines (NTMs) are an instance of Memory Augmented Neural\nNetworks, a new class of recurrent neural networks which decouple computation\nfrom memory by introducing an external memory unit. NTMs have demonstrated\nsuperior performance over Long Short-Term Memory Cells in several sequence\nlearning tasks. A number of open source implementations of NTMs exist but are\nunstable during training and/or fail to replicate the reported performance of\nNTMs. This paper presents the details of our successful implementation of a\nNTM. Our implementation learns to solve three sequential learning tasks from\nthe original NTM paper. We find that the choice of memory contents\ninitialization scheme is crucial in successfully implementing a NTM. Networks\nwith memory contents initialized to small constant values converge on average 2\ntimes faster than the next best memory contents initialization scheme.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 10:35:18 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 11:48:54 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2018 21:42:07 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Collier", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "1807.08534", "submitter": "Bin Liu", "authors": "Bin Liu", "title": "Particle Filtering Methods for Stochastic Optimization with Application\n  to Large-Scale Empirical Risk Minimization", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with sequential filtering based stochastic\noptimization (FSO) approaches that leverage a probabilistic perspective to\nimplement the incremental proximity method (IPM). The present FSO methods are\nderived based on the Kalman filter (KF) and the extended KF (EKF). In contrast\nwith typical methods such as stochastic gradient descent (SGD) and IPMs, they\ndo not need to pre-schedule the learning rate for convergence. Nevertheless,\nthey have limitations that inherit from the KF mechanism. As the particle\nfiltering (PF) method outperforms KF and its variants remarkably for nonlinear\nnon-Gaussian sequential filtering problems, it is natural to ask if FSO methods\ncan benefit from PF to get around of their limitations. We provide an\naffirmative answer to this question by developing two PF based stochastic\noptimizers (PFSOs). For performance evaluation, we apply them to address\nnonlinear least-square fitting with simulated data, and empirical risk\nminimization for binary classification of real data sets. Experimental results\ndemonstrate that PFSOs outperform remarkably a benchmark SGD algorithm, the\nvanilla IPM, and KF-type FSO methods in terms of numerical stability,\nconvergence speed, and flexibility in handling diverse types of loss functions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 11:14:33 GMT"}, {"version": "v10", "created": "Tue, 5 Nov 2019 04:05:44 GMT"}, {"version": "v11", "created": "Tue, 7 Jan 2020 06:32:04 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 05:16:37 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 14:34:09 GMT"}, {"version": "v4", "created": "Thu, 28 Feb 2019 01:30:06 GMT"}, {"version": "v5", "created": "Fri, 1 Mar 2019 01:49:36 GMT"}, {"version": "v6", "created": "Mon, 4 Mar 2019 03:07:17 GMT"}, {"version": "v7", "created": "Tue, 5 Mar 2019 09:01:58 GMT"}, {"version": "v8", "created": "Thu, 9 May 2019 13:18:27 GMT"}, {"version": "v9", "created": "Mon, 4 Nov 2019 07:44:01 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Liu", "Bin", ""]]}, {"id": "1807.08583", "submitter": "Manuel Schmuck", "authors": "Manuel Schmuck, Luca Benini, Abbas Rahimi", "title": "Hardware Optimizations of Dense Binary Hyperdimensional Computing:\n  Rematerialization of Hypervectors, Binarized Bundling, and Combinational\n  Associative Memory", "comments": "25 pages, 4 tables, 21 figures. Published as a journal paper at the\n  ACM JETC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-inspired hyperdimensional (HD) computing models neural activity\npatterns of the very size of the brain's circuits with points of a\nhyperdimensional space, that is, with hypervectors. Hypervectors are\n$D$-dimensional (pseudo)random vectors with independent and identically\ndistributed (i.i.d.) components constituting ultra-wide holographic words: $D =\n10,000$ bits, for instance. At its very core, HD computing manipulates a set of\nseed hypervectors to build composite hypervectors representing objects of\ninterest. It demands memory optimizations with simple operations for an e cient\nhardware realization. In this paper, we propose hardware techniques for\noptimizations of HD computing, in a synthesizable VHDL library, to enable\nco-located implementation of both learning and classification tasks on only a\nsmall portion of Xilinx(R) UltraScale(TM) FPGAs: (1) We propose simple logical\noperations to rematerialize the hypervectors on the fly rather than loading\nthem from memory. These operations massively reduce the memory footprint by\ndirectly computing the composite hypervectors whose individual seed\nhypervectors do not need to be stored in memory. (2) Bundling a series of\nhypervectors over time requires a multibit counter per every hypervector\ncomponent. We instead propose a binarized back-to-back bundling without\nrequiring any counters. This truly enables on-chip learning with minimal\nresources as every hypervector component remains binary over the course of\ntraining to avoid otherwise multibit component. (3) For every classification\nevent, an associative memory is in charge of finding the closest match between\na set of learned hypervectors and a query hypervector by using a distance\nmetric. This operator is proportional to [...]\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 15:42:56 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 15:24:35 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Schmuck", "Manuel", ""], ["Benini", "Luca", ""], ["Rahimi", "Abbas", ""]]}, {"id": "1807.08596", "submitter": "Tinghuan Chen", "authors": "Qianru Zhang, Meng Zhang, Tinghuan Chen, Zhifei Sun, Yuzhe Ma, Bei Yu", "title": "Recent Advances in Convolutional Neural Network Acceleration", "comments": "submitted to Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, convolutional neural networks (CNNs) have shown great\nperformance in various fields such as image classification, pattern\nrecognition, and multi-media compression. Two of the feature properties, local\nconnectivity and weight sharing, can reduce the number of parameters and\nincrease processing speed during training and inference. However, as the\ndimension of data becomes higher and the CNN architecture becomes more\ncomplicated, the end-to-end approach or the combined manner of CNN is\ncomputationally intensive, which becomes limitation to CNN's further\nimplementation. Therefore, it is necessary and urgent to implement CNN in a\nfaster way. In this paper, we first summarize the acceleration methods that\ncontribute to but not limited to CNN by reviewing a broad variety of research\npapers. We propose a taxonomy in terms of three levels, i.e.~structure level,\nalgorithm level, and implementation level, for acceleration methods. We also\nanalyze the acceleration methods in terms of CNN architecture compression,\nalgorithm optimization, and hardware-based improvement. At last, we give a\ndiscussion on different perspectives of these acceleration and optimization\nmethods within each level. The discussion shows that the methods in each level\nstill have large exploration space. By incorporating such a wide range of\ndisciplines, we expect to provide a comprehensive reference for researchers who\nare interested in CNN acceleration.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:25:46 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Zhang", "Qianru", ""], ["Zhang", "Meng", ""], ["Chen", "Tinghuan", ""], ["Sun", "Zhifei", ""], ["Ma", "Yuzhe", ""], ["Yu", "Bei", ""]]}, {"id": "1807.08599", "submitter": "Pawel Mlynarski", "authors": "Pawel Mlynarski, Herv\\'e Delingette, Antonio Criminisi, Nicholas\n  Ayache", "title": "3D Convolutional Neural Networks for Tumor Segmentation using Long-range\n  2D Context", "comments": "Submitted to the journal Computerized Medical Imaging and Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient deep learning approach for the challenging task of\ntumor segmentation in multisequence MR images. In recent years, Convolutional\nNeural Networks (CNN) have achieved state-of-the-art performances in a large\nvariety of recognition tasks in medical imaging. Because of the considerable\ncomputational cost of CNNs, large volumes such as MRI are typically processed\nby subvolumes, for instance slices (axial, coronal, sagittal) or small 3D\npatches. In this paper we introduce a CNN-based model which efficiently\ncombines the advantages of the short-range 3D context and the long-range 2D\ncontext. To overcome the limitations of specific choices of neural network\narchitectures, we also propose to merge outputs of several cascaded 2D-3D\nmodels by a voxelwise voting strategy. Furthermore, we propose a network\narchitecture in which the different MR sequences are processed by separate\nsubnetworks in order to be more robust to the problem of missing MR sequences.\nFinally, a simple and efficient algorithm for training large CNN models is\nintroduced. We evaluate our method on the public benchmark of the BRATS 2017\nchallenge on the task of multiclass segmentation of malignant brain tumors. Our\nmethod achieves good performances and produces accurate segmentations with\nmedian Dice scores of 0.918 (whole tumor), 0.883 (tumor core) and 0.854\n(enhancing core). Our approach can be naturally applied to various tasks\ninvolving segmentation of lesions or organs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:31:51 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Mlynarski", "Pawel", ""], ["Delingette", "Herv\u00e9", ""], ["Criminisi", "Antonio", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1807.08636", "submitter": "Maarten Grachten", "authors": "Maarten Grachten, Emmanuel Deruty, Alexandre Tanguy", "title": "Auto-adaptive Resonance Equalization using Dilated Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In music and audio production, attenuation of spectral resonances is an\nimportant step towards a technically correct result. In this paper we present a\ntwo-component system to automate the task of resonance equalization. The first\ncomponent is a dynamic equalizer that automatically detects resonances and\noffers to attenuate them by a user-specified factor. The second component is a\ndeep neural network that predicts the optimal attenuation factor based on the\nwindowed audio. The network is trained and validated on empirical data gathered\nfrom an experiment in which sound engineers choose their preferred attenuation\nfactors for a set of tracks. We test two distinct network architectures for the\npredictive model and find that a dilated residual network operating directly on\nthe audio signal is on a par with a network architecture that requires a prior\naudio feature extraction stage. Both architectures predict human-preferred\nresonance attenuation factors significantly better than a baseline approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 14:18:56 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Grachten", "Maarten", ""], ["Deruty", "Emmanuel", ""], ["Tanguy", "Alexandre", ""]]}, {"id": "1807.08652", "submitter": "Albert Mestres Sugra\\~nes", "authors": "Albert Mestres, Eduard Alarc\\'on, Yusheng Ji, Albert Cabellos-Aparicio", "title": "Understanding the Modeling of Computer Network Delays using Neural\n  Networks", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in networking are proposing the use of Machine Learning (ML)\ntechniques for the control and operation of the network. In this context, ML\ncan be used as a computer network modeling technique to build models that\nestimate the network performance. Indeed, network modeling is a central\ntechnique to many networking functions, for instance in the field of\noptimization, in which the model is used to search a configuration that\nsatisfies the target policy. In this paper, we aim to provide an answer to the\nfollowing question: Can neural networks accurately model the delay of a\ncomputer network as a function of the input traffic? For this, we assume the\nnetwork as a black-box that has as input a traffic matrix and as output delays.\nThen we train different neural networks models and evaluate its accuracy under\ndifferent fundamental network characteristics: topology, size, traffic\nintensity and routing. With this, we aim to have a better understanding of\ncomputer network modeling with neural nets and ultimately provide practical\nguidelines on how such models need to be trained.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 14:49:45 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Mestres", "Albert", ""], ["Alarc\u00f3n", "Eduard", ""], ["Ji", "Yusheng", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "1807.08655", "submitter": "Aki Nikolaidis", "authors": "Aki Nikolaidis", "title": "Training Humans and Machines", "comments": "4 pages, Computational Cognitive Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For many years, researchers in psychology, education, statistics, and machine\nlearning have been developing practical methods to improve learning speed,\nretention, and generalizability, and this work has been successful. Many of\nthese methods are rooted in common underlying principles that seem to drive\nlearning and overlearning in both humans and machines. I present a review of a\nsmall part of this work to point to potentially novel applications in both\nmachine and human learning that may be worth exploring.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 21:06:06 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Nikolaidis", "Aki", ""]]}, {"id": "1807.08706", "submitter": "Jasper Van Der Waa", "authors": "Jasper van der Waa, Jurriaan van Diggelen, Karel van den Bosch, Mark\n  Neerincx", "title": "Contrastive Explanations for Reinforcement Learning in terms of Expected\n  Consequences", "comments": "XAI workshop on the IJCAI conference 2018, Stockholm, Sweden", "journal-ref": "IJCAI-18 Workshop on Explainable AI (XAI). Vol. 37. 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models become increasingly proficient in complex tasks.\nHowever, even for experts in the field, it can be difficult to understand what\nthe model learned. This hampers trust and acceptance, and it obstructs the\npossibility to correct the model. There is therefore a need for transparency of\nmachine learning models. The development of transparent classification models\nhas received much attention, but there are few developments for achieving\ntransparent Reinforcement Learning (RL) models. In this study we propose a\nmethod that enables a RL agent to explain its behavior in terms of the expected\nconsequences of state transitions and outcomes. First, we define a translation\nof states and actions to a description that is easier to understand for human\nusers. Second, we developed a procedure that enables the agent to obtain the\nconsequences of a single action, as well as its entire policy. The method\ncalculates contrasts between the consequences of a policy derived from a user\nquery, and of the learned policy of the agent. Third, a format for generating\nexplanations was constructed. A pilot survey study was conducted to explore\npreferences of users for different explanation properties. Results indicate\nthat human users tend to favor explanations about policy rather than about\nsingle actions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:32:38 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["van der Waa", "Jasper", ""], ["van Diggelen", "Jurriaan", ""], ["Bosch", "Karel van den", ""], ["Neerincx", "Mark", ""]]}, {"id": "1807.08716", "submitter": "Mahdi Nazemi", "authors": "Mahdi Nazemi, Ghasem Pasandi, Massoud Pedram", "title": "NullaNet: Training Deep Neural Networks for Reduced-Memory-Access\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successfully deployed in a wide variety of\napplications including computer vision and speech recognition. However,\ncomputational and storage complexity of these models has forced the majority of\ncomputations to be performed on high-end computing platforms or on the cloud.\nTo cope with computational and storage complexity of these models, this paper\npresents a training method that enables a radically different approach for\nrealization of deep neural networks through Boolean logic minimization. The\naforementioned realization completely removes the energy-hungry step of\naccessing memory for obtaining model parameters, consumes about two orders of\nmagnitude fewer computing resources compared to realizations that use\nfloatingpoint operations, and has a substantially lower latency.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:50:31 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 05:22:38 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Nazemi", "Mahdi", ""], ["Pasandi", "Ghasem", ""], ["Pedram", "Massoud", ""]]}, {"id": "1807.08725", "submitter": "Quanming Yao", "authors": "Quanming Yao, James T Kwok, Bo Han", "title": "FasTer: Fast Tensor Completion with Nonconvex Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensor completion problem aims to recover a tensor from limited\nobservations, which has many real-world applications. Due to the easy\noptimization, the convex overlapping nuclear norm has been popularly used for\ntensor completion. However, it over-penalizes top singular values and lead to\nbiased estimations. In this paper, we propose to use the nonconvex regularizer,\nwhich can less penalize large singular values, instead of the convex one for\ntensor completion. However, as the new regularizer is nonconvex and overlapped\nwith each other, existing algorithms are either too slow or suffer from the\nhuge memory cost. To address these issues, we develop an efficient and scalable\nalgorithm, which is based on the proximal average (PA) algorithm, for\nreal-world problems. Compared with the direct usage of PA algorithm, the\nproposed algorithm runs orders faster and needs orders less space. We further\nspeed up the proposed algorithm with the acceleration technique, and show the\nconvergence to critical points is still guaranteed. Experimental comparisons of\nthe proposed approach are made with various other tensor completion approaches.\nEmpirical results show that the proposed algorithm is very fast and can produce\nmuch better recovery performance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 17:12:01 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 20:37:49 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 17:31:37 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Yao", "Quanming", ""], ["Kwok", "James T", ""], ["Han", "Bo", ""]]}, {"id": "1807.08792", "submitter": "Armin Mehrabian", "authors": "Armin Mehrabian, Yousra Al-Kabani, Volker J Sorger, Tarek El-Ghazawi", "title": "PCNNA: A Photonic Convolutional Neural Network Accelerator", "comments": "5 Pages, 6 Figures, IEEE SOCC 2018", "journal-ref": null, "doi": "10.1109/SOCC.2018.8618542", "report-no": null, "categories": "cs.ET cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have been the centerpiece of many\napplications including but not limited to computer vision, speech processing,\nand Natural Language Processing (NLP). However, the computationally expensive\nconvolution operations impose many challenges to the performance and\nscalability of CNNs. In parallel, photonic systems, which are traditionally\nemployed for data communication, have enjoyed recent popularity for data\nprocessing due to their high bandwidth, low power consumption, and\nreconfigurability. Here we propose a Photonic Convolutional Neural Network\nAccelerator (PCNNA) as a proof of concept design to speedup the convolution\noperation for CNNs. Our design is based on the recently introduced silicon\nphotonic microring weight banks, which use broadcast-and-weight protocol to\nperform Multiply And Accumulate (MAC) operation and move data through layers of\na neural network. Here, we aim to exploit the synergy between the inherent\nparallelism of photonics in the form of Wavelength Division Multiplexing (WDM)\nand sparsity of connections between input feature maps and kernels in CNNs.\nWhile our full system design offers up to more than 3 orders of magnitude\nspeedup in execution time, its optical core potentially offers more than 5\norder of magnitude speedup compared to state-of-the-art electronic\ncounterparts.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 19:22:50 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Mehrabian", "Armin", ""], ["Al-Kabani", "Yousra", ""], ["Sorger", "Volker J", ""], ["El-Ghazawi", "Tarek", ""]]}, {"id": "1807.08820", "submitter": "Yanbo Xu", "authors": "Yanbo Xu, Siddharth Biswal, Shriprasad R Deshpande, Kevin O Maher,\n  Jimeng Sun", "title": "RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient\n  Monitoring Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the improvement of medical data capturing, vast amount of continuous\npatient monitoring data, e.g., electrocardiogram (ECG), real-time vital signs\nand medications, become available for clinical decision support at intensive\ncare units (ICUs). However, it becomes increasingly challenging to model such\ndata, due to high density of the monitoring data, heterogeneous data types and\nthe requirement for interpretable models. Integration of these high-density\nmonitoring data with the discrete clinical events (including diagnosis,\nmedications, labs) is challenging but potentially rewarding since richness and\ngranularity in such multimodal data increase the possibilities for accurate\ndetection of complex problems and predicting outcomes (e.g., length of stay and\nmortality). We propose Recurrent Attentive and Intensive Model (RAIM) for\njointly analyzing continuous monitoring data and discrete clinical events. RAIM\nintroduces an efficient attention mechanism for continuous monitoring data\n(e.g., ECG), which is guided by discrete clinical events (e.g, medication\nusage). We apply RAIM in predicting physiological decompensation and length of\nstay in those critically ill patients at ICU. With evaluations on MIMIC- III\nWaveform Database Matched Subset, we obtain an AUC-ROC score of 90.18% for\npredicting decompensation and an accuracy of 86.82% for forecasting length of\nstay with our final model, which outperforms our six baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 20:39:35 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Xu", "Yanbo", ""], ["Biswal", "Siddharth", ""], ["Deshpande", "Shriprasad R", ""], ["Maher", "Kevin O", ""], ["Sun", "Jimeng", ""]]}, {"id": "1807.08825", "submitter": "Denali Molitor", "authors": "Denali Molitor and Deanna Needell", "title": "Hierarchical Classification using Binary Data", "comments": "AAAI Magazine special Issue on Deep Models, Machine Learning and\n  Artificial Intelligence Applications in National and International Security,\n  June, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification problems, especially those that categorize data into a\nlarge number of classes, the classes often naturally follow a hierarchical\nstructure. That is, some classes are likely to share similar structures and\nfeatures. Those characteristics can be captured by considering a hierarchical\nrelationship among the class labels. Here, we extend a recent simple\nclassification approach on binary data in order to efficiently classify\nhierarchical data. In certain settings, specifically, when some classes are\nsignificantly easier to identify than others, we showcase computational and\naccuracy advantages.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 20:55:31 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Molitor", "Denali", ""], ["Needell", "Deanna", ""]]}, {"id": "1807.08844", "submitter": "Sebastien Motsch", "authors": "Adrien Motsch, Sebastien Motsch, and Thibaut Saguet", "title": "Lesion segmentation using U-Net network", "comments": "4 pages, ISIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explains the method used in the segmentation challenge (Task 1) in\nthe International Skin Imaging Collaboration's (ISIC) Skin Lesion Analysis\nTowards Melanoma Detection challenge held in 2018. We have trained a U-Net\nnetwork to perform the segmentation. The key elements for the training were\nfirst to adjust the loss function to incorporate unbalanced proportion of\nbackground and second to perform post-processing operation to adjust the\ncontour of the prediction.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 21:54:35 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Motsch", "Adrien", ""], ["Motsch", "Sebastien", ""], ["Saguet", "Thibaut", ""]]}, {"id": "1807.08855", "submitter": "Nisar Ahmed", "authors": "Zhaozhong Chen, Christoffer Heckman, Simon Julier, Nisar Ahmed", "title": "Weak in the NEES?: Auto-tuning Kalman Filters with Bayesian Optimization", "comments": "Final version presented at FUSION 2018 Conference, Cambridge, UK,\n  July 2018 (submitted June 1, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman filters are routinely used for many data fusion applications including\nnavigation, tracking, and simultaneous localization and mapping problems.\nHowever, significant time and effort is frequently required to tune various\nKalman filter model parameters, e.g. process noise covariance, pre-whitening\nfilter models for non-white noise, etc. Conventional optimization techniques\nfor tuning can get stuck in poor local minima and can be expensive to implement\nwith real sensor data. To address these issues, a new \"black box\" Bayesian\noptimization strategy is developed for automatically tuning Kalman filters. In\nthis approach, performance is characterized by one of two stochastic objective\nfunctions: normalized estimation error squared (NEES) when ground truth state\nmodels are available, or the normalized innovation error squared (NIS) when\nonly sensor data is available. By intelligently sampling the parameter space to\nboth learn and exploit a nonparametric Gaussian process surrogate function for\nthe NEES/NIS costs, Bayesian optimization can efficiently identify multiple\nlocal minima and provide uncertainty quantification on its results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 23:02:09 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Chen", "Zhaozhong", ""], ["Heckman", "Christoffer", ""], ["Julier", "Simon", ""], ["Ahmed", "Nisar", ""]]}, {"id": "1807.08887", "submitter": "Minjie Wang", "authors": "Minjie Wang, Chien-chin Huang, Jinyang Li", "title": "Supporting Very Large Models using Automatic Dataflow Graph Partitioning", "comments": "Revision for Eurosys'19", "journal-ref": null, "doi": "10.1145/3302424.3303953", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Tofu, a system that partitions very large DNN models\nacross multiple GPU devices to reduce per-GPU memory footprint. Tofu is\ndesigned to partition a dataflow graph of fine-grained tensor operators in\norder to work transparently with a general-purpose deep learning platform like\nMXNet. In order to automatically partition each operator, we propose to\ndescribe the semantics of an operator in a simple language which represents\ntensors as lambda functions mapping from tensor coordinates to values. To\noptimally partition different operators in a dataflow graph, Tofu uses a\nrecursive search algorithm that minimizes the total communication cost. Our\nexperiments on an 8-GPU machine show that Tofu enables the training of very\nlarge CNN and RNN models. It also achieves 25% - 400% speedup over alternative\napproaches to train very large models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 02:57:28 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 23:59:26 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Wang", "Minjie", ""], ["Huang", "Chien-chin", ""], ["Li", "Jinyang", ""]]}, {"id": "1807.08894", "submitter": "Lin Shao", "authors": "Lin Shao, Ye Tian, Jeannette Bohg", "title": "ClusterNet: 3D Instance Segmentation in RGB-D Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for instance-level segmentation that uses RGB-D data as\ninput and provides detailed information about the location, geometry and number\nof individual objects in the scene. This level of understanding is fundamental\nfor autonomous robots. It enables safe and robust decision-making under the\nlarge uncertainty of the real-world. In our model, we propose to use the first\nand second order moments of the object occupancy function to represent an\nobject instance. We train an hourglass Deep Neural Network (DNN) where each\npixel in the output votes for the 3D position of the corresponding object\ncenter and for the object's size and pose. The final instance segmentation is\nachieved through clustering in the space of moments. The object-centric\ntraining loss is defined on the output of the clustering. Our method\noutperforms the state-of-the-art instance segmentation method on our\nsynthesized dataset. We show that our method generalizes well on real-world\ndata achieving visually better segmentation results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 03:42:53 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 05:23:11 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Shao", "Lin", ""], ["Tian", "Ye", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1807.08904", "submitter": "Xiaofeng Cao", "authors": "Xiaofeng Cao, Ivor W. Tsang, Guandong Xu", "title": "A Structured Perspective of Volumes on Active Learning", "comments": "This paper has been withdrawn. The first author quitted the PhD study\n  from AAI, University of Technology Sydney. The manuscript stopped updating", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning (AL) is a learning task that requires learners interactively\nquery the labels of the sampled unlabeled instances to minimize the training\noutputs with human supervisions. In theoretical study, learners approximate the\nversion space which covers all possible classification hypothesis into a\nbounded convex body and try to shrink the volume of it into a half-space by a\ngiven cut size. However, only the hypersphere with finite VC dimensions has\nobtained formal approximation guarantees that hold when the classes of\nEuclidean space are separable with a margin. In this paper, we approximate the\nversion space to a structured {hypersphere} that covers most of the hypotheses,\nand then divide the available AL sampling approaches into two kinds of\nstrategies: Outer Volume Sampling and Inner Volume Sampling. After providing\nprovable guarantees for the performance of AL in version space, we aggregate\nthe two kinds of volumes to eliminate their sampling biases via finding the\noptimal inscribed hyperspheres in the enclosing space of outer volume. To touch\nthe version space from Euclidean space, we propose a theoretical bridge called\nVolume-based Model that increases the `sampling target-independent'. In\nnon-linear feature space, spanned by kernel, we use sequential optimization to\nglobally optimize the original space to a sparse space by halving the size of\nthe kernel space. Then, the EM (Expectation Maximization) model which returns\nthe local center helps us to find a local representation. To describe this\nprocess, we propose an easy-to-implement algorithm called Volume-based AL\n(VAL).\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 04:53:45 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 23:53:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Cao", "Xiaofeng", ""], ["Tsang", "Ivor W.", ""], ["Xu", "Guandong", ""]]}, {"id": "1807.08912", "submitter": "James Harrison", "authors": "James Harrison, Apoorva Sharma, Marco Pavone", "title": "Meta-Learning Priors for Efficient Online Bayesian Regression", "comments": "Workshop on the Algorithmic Foundations of Robotics (WAFR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process (GP) regression has seen widespread use in robotics due to\nits generality, simplicity of use, and the utility of Bayesian predictions. The\npredominant implementation of GP regression is a nonparameteric kernel-based\napproach, as it enables fitting of arbitrary nonlinear functions. However, this\napproach suffers from two main drawbacks: (1) it is computationally\ninefficient, as computation scales poorly with the number of samples; and (2)\nit can be data inefficient, as encoding prior knowledge that can aid the model\nthrough the choice of kernel and associated hyperparameters is often\nchallenging and unintuitive. In this work, we propose ALPaCA, an algorithm for\nefficient Bayesian regression which addresses these issues. ALPaCA uses a\ndataset of sample functions to learn a domain-specific, finite-dimensional\nfeature encoding, as well as a prior over the associated weights, such that\nBayesian linear regression in this feature space yields accurate online\npredictions of the posterior predictive density. These features are neural\nnetworks, which are trained via a meta-learning (or \"learning-to-learn\")\napproach. ALPaCA extracts all prior information directly from the dataset,\nrather than restricting prior information to the choice of kernel\nhyperparameters. Furthermore, by operating in the weight space, it\nsubstantially reduces sample complexity. We investigate the performance of\nALPaCA on two simple regression problems, two simulated robotic systems, and on\na lane-change driving task performed by humans. We find our approach\noutperforms kernel-based GP regression, as well as state of the art\nmeta-learning approaches, thereby providing a promising plug-in tool for many\nregression tasks in robotics where scalability and data-efficiency are\nimportant.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 05:46:04 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 01:32:42 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Harrison", "James", ""], ["Sharma", "Apoorva", ""], ["Pavone", "Marco", ""]]}, {"id": "1807.08919", "submitter": "Maxwell Nye", "authors": "Luke B. Hewitt, Maxwell I. Nye, Andreea Gane, Tommi Jaakkola, Joshua\n  B. Tenenbaum", "title": "The Variational Homoencoder: Learning to learn high capacity generative\n  models from few examples", "comments": "UAI 2018 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Bayesian methods can unify many related tasks (e.g. k-shot\nclassification, conditional and unconditional generation) as inference within a\nsingle generative model. However, when this generative model is expressed as a\npowerful neural network such as a PixelCNN, we show that existing learning\ntechniques typically fail to effectively use latent variables. To address this,\nwe develop a modification of the Variational Autoencoder in which encoded\nobservations are decoded to new elements from the same class. This technique,\nwhich we call a Variational Homoencoder (VHE), produces a hierarchical latent\nvariable model which better utilises latent variables. We use the VHE framework\nto learn a hierarchical PixelCNN on the Omniglot dataset, which outperforms all\nexisting models on test set likelihood and achieves strong performance on\none-shot generation and classification tasks. We additionally validate the VHE\non natural images from the YouTube Faces database. Finally, we develop\nextensions of the model that apply to richer dataset structures such as\nfactorial and hierarchical categories.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 06:05:43 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Hewitt", "Luke B.", ""], ["Nye", "Maxwell I.", ""], ["Gane", "Andreea", ""], ["Jaakkola", "Tommi", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1807.08920", "submitter": "Yang Hu Dr.", "authors": "Yang Hu, Guihua Wen, Mingnan Luo, Dan Dai, Jiajiong Ma, Zhiwen Yu", "title": "Competitive Inner-Imaging Squeeze and Excitation for Residual Network", "comments": "Code is available at\n  https://github.com/scut-aitcm/Competitive-Inner-Imaging-SENet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual networks, which use a residual unit to supplement the identity\nmappings, enable very deep convolutional architecture to operate well, however,\nthe residual architecture has been proved to be diverse and redundant, which\nmay leads to low-efficient modeling. In this work, we propose a competitive\nsqueeze-excitation (SE) mechanism for the residual network. Re-scaling the\nvalue for each channel in this structure will be determined by the residual and\nidentity mappings jointly, and this design enables us to expand the meaning of\nchannel relationship modeling in residual blocks. Modeling of the competition\nbetween residual and identity mappings cause the identity flow to control the\ncomplement of the residual feature maps for itself. Furthermore, we design a\nnovel inner-imaging competitive SE block to shrink the consumption and re-image\nthe global features of intermediate network structure, by using the\ninner-imaging mechanism, we can model the channel-wise relations with\nconvolution in spatial. We carry out experiments on the CIFAR, SVHN, and\nImageNet datasets, and the proposed method can challenge state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 06:13:25 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 14:55:37 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 16:52:45 GMT"}, {"version": "v4", "created": "Sun, 23 Dec 2018 02:56:45 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hu", "Yang", ""], ["Wen", "Guihua", ""], ["Luo", "Mingnan", ""], ["Dai", "Dan", ""], ["Ma", "Jiajiong", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1807.08934", "submitter": "Vinod Kumar Chauhan", "authors": "Vinod Kumar Chauhan, Anuj Sharma, Kalpana Dahiya", "title": "SAAGs: Biased Stochastic Variance Reduction Methods for Large-scale\n  Learning", "comments": "Final journal version. Appl Intell (2019)", "journal-ref": null, "doi": "10.1007/s10489-019-01450-3", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic approximation is one of the effective approach to deal with the\nlarge-scale machine learning problems and the recent research has focused on\nreduction of variance, caused by the noisy approximations of the gradients. In\nthis paper, we have proposed novel variants of SAAG-I and II (Stochastic\nAverage Adjusted Gradient) (Chauhan et al. 2017), called SAAG-III and IV,\nrespectively. Unlike SAAG-I, starting point is set to average of previous epoch\nin SAAG-III, and unlike SAAG-II, the snap point and starting point are set to\naverage and last iterate of previous epoch in SAAG-IV, respectively. To\ndetermine the step size, we have used Stochastic Backtracking-Armijo line\nSearch (SBAS) which performs line search only on selected mini-batch of data\npoints. Since backtracking line search is not suitable for large-scale problems\nand the constants used to find the step size, like Lipschitz constant, are not\nalways available so SBAS could be very effective in such cases. We have\nextended SAAGs (I, II, III and IV) to solve non-smooth problems and designed\ntwo update rules for smooth and non-smooth problems. Moreover, our theoretical\nresults have proved linear convergence of SAAG-IV for all the four combinations\nof smoothness and strong-convexity, in expectation. Finally, our experimental\nstudies have proved the efficacy of proposed methods against the state-of-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 07:36:21 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 10:04:22 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 05:04:23 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Chauhan", "Vinod Kumar", ""], ["Sharma", "Anuj", ""], ["Dahiya", "Kalpana", ""]]}, {"id": "1807.08941", "submitter": "Joost Broekens", "authors": "Joost Broekens", "title": "A Temporal Difference Reinforcement Learning Theory of Emotion: unifying\n  emotion, cognition and adaptive behavior", "comments": "pre-print, don't cite verbatim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions are intimately tied to motivation and the adaptation of behavior,\nand many animal species show evidence of emotions in their behavior. Therefore,\nemotions must be related to powerful mechanisms that aid survival, and,\nemotions must be evolutionary continuous phenomena. How and why did emotions\nevolve in nature, how do events get emotionally appraised, how do emotions\nrelate to cognitive complexity, and, how do they impact behavior and learning?\nIn this article I propose that all emotions are manifestations of reward\nprocessing, in particular Temporal Difference (TD) error assessment.\nReinforcement Learning (RL) is a powerful computational model for the learning\nof goal oriented tasks by exploration and feedback. Evidence indicates that\nRL-like processes exist in many animal species. Key in the processing of\nfeedback in RL is the notion of TD error, the assessment of how much better or\nworse a situation just became, compared to what was previously expected (or,\nthe estimated gain or loss of utility - or well-being - resulting from new\nevidence). I propose a TDRL Theory of Emotion and discuss its ramifications for\nour understanding of emotions in humans, animals and machines, and present\npsychological, neurobiological and computational evidence in its support.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 07:50:14 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Broekens", "Joost", ""]]}, {"id": "1807.08959", "submitter": "Bruno Torresani", "authors": "Marie-Christine Roubaud (I2M), Jean-Marc Lina (ETS), Julie Carrier\n  (CEAMS), B Torr\\'esani (I2M)", "title": "Space-Time Extension of the MEM Approach for Electromagnetic\n  Neuroimaging", "comments": null, "journal-ref": "IEEE International Workshop on Machine Learning for Signal\n  Processing, Sep 2018, Aalborg, Denmark", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wavelet Maximum Entropy on the Mean (wMEM) approach to the MEG inverse\nproblem is revisited and extended to infer brain activity from full space-time\ndata. The resulting dimensionality increase is tackled using a collection of\ntechniques , that includes time and space dimension reduction (using\nrespectively wavelet and spatial filter based reductions), Kronecker product\nmodeling for covariance matrices, and numerical manipulation of the free energy\ndirectly in matrix form. This leads to a smooth numerical optimization problem\nof reasonable dimension, solved using standard approaches. The method is\napplied to the MEG inverse problem. Results of a simulation study in the\ncontext of slow wave localization from sleep MEG data are presented and\ndiscussed.\n  Index Terms: MEG inverse problem, maximum entropy on the mean, wavelet\ndecomposition, spatial filters, Kronecker covariance factorization, sleep slow\nwaves.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 08:42:58 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Roubaud", "Marie-Christine", "", "I2M"], ["Lina", "Jean-Marc", "", "ETS"], ["Carrier", "Julie", "", "CEAMS"], ["Torr\u00e9sani", "B", "", "I2M"]]}, {"id": "1807.08993", "submitter": "Sara Nasiri", "authors": "Sara Nasiri, Matthias Jung, Julien Helsper, Madjid Fathi", "title": "Deep-CLASS at ISIC Machine Learning Challenge 2018", "comments": "4 pages, 1 Appendix, 2 figures, 1 table. ISIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the method and evaluation results of MedAusbild team for\nISIC challenge task. Since early 2017, our team has worked on melanoma\nclassification [1][6], and has employed deep learning since beginning of 2018\n[7]. Deep learning helps researchers absolutely to treat and detect diseases by\nanalyzing medical data (e.g., medical images). One of the representative models\namong the various deep-learning models is a convolutional neural network (CNN).\nAlthough our team has an experience with segmentation and classification of\nbenign and malignant skin-lesions, we have participated in the task 3 of ISIC\nChallenge 2018 for classification of seven skin diseases, explained in this\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:43:53 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Nasiri", "Sara", ""], ["Jung", "Matthias", ""], ["Helsper", "Julien", ""], ["Fathi", "Madjid", ""]]}, {"id": "1807.09010", "submitter": "Mokhtar Z. Alaya", "authors": "Mokhtar Z. Alaya (MODAL'X, Univ Paris Nanterre) and Olga Klopp (ESSEC\n  Business School and CREST)", "title": "Collective Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion aims to reconstruct a data matrix based on observations of\na small number of its entries. Usually in matrix completion a single matrix is\nconsidered, which can be, for example, a rating matrix in recommendation\nsystem. However, in practical situations, data is often obtained from multiple\nsources which results in a collection of matrices rather than a single one. In\nthis work, we consider the problem of collective matrix completion with\nmultiple and heterogeneous matrices, which can be count, binary, continuous,\netc. We first investigate the setting where, for each source, the matrix\nentries are sampled from an exponential family distribution. Then, we relax the\nassumption of exponential family distribution for the noise and we investigate\nthe distribution-free case. In this setting, we do not assume any specific\nmodel for the observations. The estimation procedures are based on minimizing\nthe sum of a goodness-of-fit term and the nuclear norm penalization of the\nwhole collective matrix. We prove that the proposed estimators achieve fast\nrates of convergence under the two considered settings and we corroborate our\nresults with numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 10:13:30 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 10:34:15 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 14:33:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Alaya", "Mokhtar Z.", "", "MODAL'X, Univ Paris Nanterre"], ["Klopp", "Olga", "", "ESSEC\n  Business School and CREST"]]}, {"id": "1807.09011", "submitter": "Axel Brando Guillaumes", "authors": "Axel Brando, Jose A. Rodr\\'iguez-Serrano, Mauricio Ciprian, Roberto\n  Maestre, Jordi Vitri\\`a", "title": "Uncertainty Modelling in Deep Networks: Forecasting Short and Noisy\n  Series", "comments": "17 pages, 5 figures, Applied Data Science Track of The European\n  Conference on Machine Learning and Principles and Practice of Knowledge\n  Discovery in Databases (ECML-PKDD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is a consolidated, state-of-the-art Machine Learning tool to\nfit a function when provided with large data sets of examples. However, in\nregression tasks, the straightforward application of Deep Learning models\nprovides a point estimate of the target. In addition, the model does not take\ninto account the uncertainty of a prediction. This represents a great\nlimitation for tasks where communicating an erroneous prediction carries a\nrisk. In this paper we tackle a real-world problem of forecasting impending\nfinancial expenses and incomings of customers, while displaying predictable\nmonetary amounts on a mobile app. In this context, we investigate if we would\nobtain an advantage by applying Deep Learning models with a Heteroscedastic\nmodel of the variance of a network's output. Experimentally, we achieve a\nhigher accuracy than non-trivial baselines. More importantly, we introduce a\nmechanism to discard low-confidence predictions, which means that they will not\nbe visible to users. This should help enhance the user experience of our\nproduct.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 10:15:49 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Brando", "Axel", ""], ["Rodr\u00edguez-Serrano", "Jose A.", ""], ["Ciprian", "Mauricio", ""], ["Maestre", "Roberto", ""], ["Vitri\u00e0", "Jordi", ""]]}, {"id": "1807.09077", "submitter": "Rianne de Heide", "authors": "Allard Hendriksen, Rianne de Heide, Peter Gr\\\"unwald", "title": "Optional Stopping with Bayes Factors: a categorization and extension of\n  folklore results, with an application to invariant situations", "comments": "29 pages", "journal-ref": null, "doi": "10.1214/20-BA1234", "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often claimed that Bayesian methods, in particular Bayes factor methods\nfor hypothesis testing, can deal with optional stopping. We first give an\noverview, using elementary probability theory, of three different mathematical\nmeanings that various authors give to this claim: (1) stopping rule\nindependence, (2) posterior calibration and (3) (semi-) frequentist robustness\nto optional stopping. We then prove theorems to the effect that these claims do\nindeed hold in a general measure-theoretic setting. For claims of type (2) and\n(3), such results are new. By allowing for non-integrable measures based on\nimproper priors, we obtain particularly strong results for the practically\nimportant case of models with nuisance parameters satisfying a group invariance\n(such as location or scale). We also discuss the practical relevance of\n(1)--(3), and conclude that whether Bayes factor methods actually perform well\nunder optional stopping crucially depends on details of models, priors and the\ngoal of the analysis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 13:01:34 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 12:17:00 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 09:43:48 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Hendriksen", "Allard", ""], ["de Heide", "Rianne", ""], ["Gr\u00fcnwald", "Peter", ""]]}, {"id": "1807.09089", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Alexis Boukouvalas, Qing Zhao", "title": "Decision Variance in Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning has traditionally focused on the expected rewards. In this\npaper, a risk-averse online learning problem under the performance measure of\nthe mean-variance of the rewards is studied. Both the bandit and full\ninformation settings are considered. The performance of several existing\npolicies is analyzed, and new fundamental limitations on risk-averse learning\nis established. In particular, it is shown that although a logarithmic\ndistribution-dependent regret in time $T$ is achievable (similar to the\nrisk-neutral problem), the worst-case (i.e. minimax) regret is lower bounded by\n$\\Omega(T)$ (in contrast to the $\\Omega(\\sqrt{T})$ lower bound in the\nrisk-neutral problem). This sharp difference from the risk-neutral counterpart\nis caused by the the variance in the player's decisions, which, while absent in\nthe regret under the expected reward criterion, contributes to excess\nmean-variance due to the non-linearity of this risk measure. The role of the\ndecision variance in regret performance reflects a risk-averse player's desire\nfor robust decisions and outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 13:20:49 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 17:51:58 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Vakili", "Sattar", ""], ["Boukouvalas", "Alexis", ""], ["Zhao", "Qing", ""]]}, {"id": "1807.09097", "submitter": "Tiago Cunha", "authors": "Tiago Cunha, Carlos Soares, Andr\\'e C.P.L.F. de Carvalho", "title": "Algorithm Selection for Collaborative Filtering: the influence of graph\n  metafeatures and multicriteria metatargets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To select the best algorithm for a new problem is an expensive and difficult\ntask. However, there are automatic solutions to address this problem: using\nMetalearning, which takes advantage of problem characteristics (i.e.\nmetafeatures), one is able to predict the relative performance of algorithms.\nIn the Collaborative Filtering scope, recent works have proposed diverse\nmetafeatures describing several dimensions of this problem. Despite interesting\nand effective findings, it is still unknown whether these are the most\neffective metafeatures. Hence, this work proposes a new set of graph\nmetafeatures, which approach the Collaborative Filtering problem from a Graph\nTheory perspective. Furthermore, in order to understand whether metafeatures\nfrom multiple dimensions are a better fit, we investigate the effects of\ncomprehensive metafeatures. These metafeatures are a selection of the best\nmetafeatures from all existing Collaborative Filtering metafeatures. The impact\nof the most representative metafeatures is investigated in a controlled\nexperimental setup. Another contribution we present is the use of a\nPareto-Efficient ranking procedure to create multicriteria metatargets. These\nnew rankings of algorithms, which take into account multiple evaluation\nmeasures, allow to explore the algorithm selection problem in a fairer and more\ndetailed way. According to the experimental results, the graph metafeatures are\na good alternative to related work metafeatures. However, the results have\nshown that the feature selection procedure used to create the comprehensive\nmetafeatures is is not effective, since there is no gain in predictive\nperformance. Finally, an extensive metaknowledge analysis was conducted to\nidentify the most influential metafeatures.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:37:52 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Cunha", "Tiago", ""], ["Soares", "Carlos", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""]]}, {"id": "1807.09119", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Swaraj Khadanga, Shafiq R. Joty, Louis Kazaglis,\n  Jaideep Srivastava", "title": "A Structured Learning Approach with Neural Conditional Random Fields for\n  Sleep Staging", "comments": "Accepted at IEEE International Conference on BigData 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep plays a vital role in human health, both mental and physical. Sleep\ndisorders like sleep apnea are increasing in prevalence, with the rapid\nincrease in factors like obesity. Sleep apnea is most commonly treated with\nContinuous Positive Air Pressure (CPAP) therapy. Presently, however, there is\nno mechanism to monitor a patient's progress with CPAP. Accurate detection of\nsleep stages from CPAP flow signal is crucial for such a mechanism. We propose,\nfor the first time, an automated sleep staging model based only on the flow\nsignal. Deep neural networks have recently shown high accuracy on sleep staging\nby eliminating handcrafted features. However, these methods focus exclusively\non extracting informative features from the input signal, without paying much\nattention to the dynamics of sleep stages in the output sequence. We propose an\nend-to-end framework that uses a combination of deep convolution and recurrent\nneural networks to extract high-level features from raw flow signal with a\nstructured output layer based on a conditional random field to model the\ntemporal transition structure of the sleep stages. We improve upon the previous\nmethods by 10% using our model, that can be augmented to the previous sleep\nstaging deep learning methods. We also show that our method can be used to\naccurately track sleep metrics like sleep efficiency calculated from sleep\nstages that can be deployed for monitoring the response of CPAP therapy on\nsleep apnea patients. Apart from the technical contributions, we expect this\nstudy to motivate new research questions in sleep science.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:11:53 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 20:46:48 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Aggarwal", "Karan", ""], ["Khadanga", "Swaraj", ""], ["Joty", "Shafiq R.", ""], ["Kazaglis", "Louis", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1807.09142", "submitter": "Kiewan Villatel", "authors": "Kiewan Villatel (SEQUEL), Elena Smirnova, J\\'er\\'emie Mary, Philippe\n  Preux (SEQUEL)", "title": "Recurrent Neural Networks for Long and Short-Term Sequential\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems objectives can be broadly characterized as modeling user\npreferences over short-or long-term time horizon. A large body of previous\nresearch studied long-term recommendation through dimensionality reduction\ntechniques applied to the historical user-item interactions. A recently\nintroduced session-based recommendation setting highlighted the importance of\nmodeling short-term user preferences. In this task, Recurrent Neural Networks\n(RNN) have shown to be successful at capturing the nuances of user's\ninteractions within a short time window. In this paper, we evaluate RNN-based\nmodels on both short-term and long-term recommendation tasks. Our experimental\nresults suggest that RNNs are capable of predicting immediate as well as\ndistant user interactions. We also find the best performing configuration to be\na stacked RNN with layer normalization and tied item embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 11:38:04 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Villatel", "Kiewan", "", "SEQUEL"], ["Smirnova", "Elena", "", "SEQUEL"], ["Mary", "J\u00e9r\u00e9mie", "", "SEQUEL"], ["Preux", "Philippe", "", "SEQUEL"]]}, {"id": "1807.09151", "submitter": "Roman Khudorozhkov", "authors": "Roman Khudorozhkov, Alexander Koryagin, Alexey Kozhevin", "title": "Clearing noisy annotations for computed tomography imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the problems on the way to successful implementation of neural\nnetworks is the quality of annotation. For instance, different annotators can\nannotate images in a different way and very often their decisions do not match\nexactly and in extreme cases are even mutually exclusive which results in noisy\nannotations and, consequently, inaccurate predictions.\n  To avoid that problem in the task of computed tomography (CT) imaging\nsegmentation we propose a clearing algorithm for annotations. It consists of 3\nstages:\n  - annotators scoring, which assigns a higher confidence level to better\nannotators;\n  - nodules scoring, which assigns a higher confidence level to nodules\nconfirmed by good annotators;\n  - nodules merging, which aggregates annotations according to nodules\nconfidence.\n  In general, the algorithm can be applied to many different tasks (namely,\nbinary and multi-class semantic segmentation, and also with trivial adjustments\nto classification and regression) where there are several annotators labeling\neach image.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:42:57 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Khudorozhkov", "Roman", ""], ["Koryagin", "Alexander", ""], ["Kozhevin", "Alexey", ""]]}, {"id": "1807.09161", "submitter": "Renato Luiz de Freitas Cunha", "authors": "Renato L. de F. Cunha, Eduardo R. Rodrigues, Matheus Palhares Viana,\n  Dario Augusto Borges Oliveira", "title": "An argument in favor of strong scaling for deep neural networks with\n  small datasets", "comments": "8 pages, 5 figures, Presented at HPML 2018 -\n  http://hpml2018.github.io/", "journal-ref": null, "doi": "10.1109/CAHPC.2018.8645881", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the popularization of deep learning frameworks and\nlarge datasets, researchers have started parallelizing their models in order to\ntrain faster. This is crucially important, because they typically explore many\nhyperparameters in order to find the best ones for their applications. This\nprocess is time consuming and, consequently, speeding up training improves\nproductivity. One approach to parallelize deep learning models followed by many\nresearchers is based on weak scaling. The minibatches increase in size as new\nGPUs are added to the system. In addition, new learning rates schedules have\nbeen proposed to fix optimization issues that occur with large minibatch sizes.\nIn this paper, however, we show that the recommendations provided by recent\nwork do not apply to models that lack large datasets. In fact, we argument in\nfavor of using strong scaling for achieving reliable performance in such cases.\nWe evaluated our approach with up to 32 GPUs and show that weak scaling not\nonly does not have the same accuracy as the sequential model, it also fails to\nconverge most of time. Meanwhile, strong scaling has good scalability while\nhaving exactly the same accuracy of a sequential implementation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 14:48:19 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 12:23:39 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 22:59:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Cunha", "Renato L. de F.", ""], ["Rodrigues", "Eduardo R.", ""], ["Viana", "Matheus Palhares", ""], ["Oliveira", "Dario Augusto Borges", ""]]}, {"id": "1807.09177", "submitter": "Raul Fernandez", "authors": "Raul Fernandez-Fernandez, Juan G. Victores, David Estevez and Carlos\n  Balaguer", "title": "Robot Imitation through Vision, Kinesthetic and Force Features with\n  Online Adaptation to Changing Environments", "comments": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Goal-Directed Actions (CGDA) is a robot imitation framework that\nencodes actions as the changes they produce on the environment. While it\npresents numerous advantages with respect to other robot imitation frameworks\nin terms of generalization and portability, final robot joint trajectories for\nthe execution of actions are not necessarily encoded within the model. This is\nstudied as an optimization problem, and the solution is computed through\nevolutionary algorithms in simulated environments. Evolutionary algorithms\nrequire a large number of evaluations, which had made the use of these\nalgorithms in real world applications very challenging. This paper presents\nonline evolutionary strategies, as a change of paradigm within CGDA execution.\nOnline evolutionary strategies shift and merge motor execution into the\nplanning loop. A concrete online evolutionary strategy, Online Evolved\nTrajectories (OET), is presented. OET drastically reduces computational times\nbetween motor executions, and enables working in real world dynamic\nenvironments and/or with human collaboration. Its performance has been measured\nagainst Full Trajectory Evolution (FTE) and Incrementally Evolved Trajectories\n(IET), obtaining the best overall results. Experimental evaluations are\nperformed on the TEO full-sized humanoid robot with \"paint\" and \"iron\" actions\nthat together involve vision, kinesthetic and force features.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 15:22:24 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 16:55:06 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 10:20:47 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Fernandez-Fernandez", "Raul", ""], ["Victores", "Juan G.", ""], ["Estevez", "David", ""], ["Balaguer", "Carlos", ""]]}, {"id": "1807.09200", "submitter": "Vithursan Thangarasa", "authors": "Vithursan Thangarasa, Graham W. Taylor", "title": "Self-Paced Learning with Adaptive Deep Visual Embeddings", "comments": "Published as a conference paper at BMVC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting the most appropriate data examples to present a deep neural network\n(DNN) at different stages of training is an unsolved challenge. Though\npractitioners typically ignore this problem, a non-trivial data scheduling\nmethod may result in a significant improvement in both convergence and\ngeneralization performance. In this paper, we introduce Self-Paced Learning\nwith Adaptive Deep Visual Embeddings (SPL-ADVisE), a novel end-to-end training\nprotocol that unites self-paced learning (SPL) and deep metric learning (DML).\nWe leverage the Magnet Loss to train an embedding convolutional neural network\n(CNN) to learn a salient representation space. The student CNN classifier\ndynamically selects similar instance-level training examples to form a\nmini-batch, where the easiness from the cross-entropy loss and the true\ndiverseness of examples from the learned metric space serve as sample\nimportance priors. To demonstrate the effectiveness of SPL-ADVisE, we use deep\nCNN architectures for the task of supervised image classification on several\ncoarse- and fine-grained visual recognition datasets. Results show that, across\nall datasets, the proposed method converges faster and reaches a higher final\naccuracy than other SPL variants, particularly on fine-grained classes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 16:01:00 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Thangarasa", "Vithursan", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1807.09202", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra and Francesco Giannini and Michelangelo Diligenti and\n  Marco Gori", "title": "Constraint-Based Visual Generation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30508-6_45", "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years the systematic adoption of deep learning to visual\ngeneration has produced impressive results that, amongst others, definitely\nbenefit from the massive exploration of convolutional architectures. In this\npaper, we propose a general approach to visual generation that combines\nlearning capabilities with logic descriptions of the target to be generated.\nThe process of generation is regarded as a constrained satisfaction problem,\nwhere the constraints describe a set of properties that characterize the\ntarget. Interestingly, the constraints can also involve logic variables, while\nall of them are converted into real-valued functions by means of the t-norm\ntheory. We use deep architectures to model the involved variables, and propose\na computational scheme where the learning process carries out a satisfaction of\nthe constraints. We propose some examples in which the theory can naturally be\nused, including the modeling of GAN and auto-encoders, and report promising\nresults in problems with the generation of handwritten characters and face\ntransformations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 22:56:15 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 09:44:10 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 14:37:06 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Marra", "Giuseppe", ""], ["Giannini", "Francesco", ""], ["Diligenti", "Michelangelo", ""], ["Gori", "Marco", ""]]}, {"id": "1807.09236", "submitter": "Johan Ugander", "authors": "Stephen Ragain, Alexander Peysakhovich, Johan Ugander", "title": "Improving pairwise comparison models using Empirical Bayes shrinkage", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison data arises in many important contexts, e.g. shopping, web clicks,\nor sports competitions. Typically we are given a dataset of comparisons and\nwish to train a model to make predictions about the outcome of unseen\ncomparisons. In many cases available datasets have relatively few comparisons\n(e.g. there are only so many NFL games per year) or efficiency is important\n(e.g. we want to quickly estimate the relative appeal of a product). In such\nsettings it is well known that shrinkage estimators outperform maximum\nlikelihood estimators. A complicating matter is that standard comparison models\nsuch as the conditional multinomial logit model are only models of conditional\noutcomes (who wins) and not of comparisons themselves (who competes). As such,\ndifferent models of the comparison process lead to different shrinkage\nestimators. In this work we derive a collection of methods for estimating the\npairwise uncertainty of pairwise predictions based on different assumptions\nabout the comparison process. These uncertainty estimates allow us both to\nexamine model uncertainty as well as perform Empirical Bayes shrinkage\nestimation of the model parameters. We demonstrate that our shrunk estimators\noutperform standard maximum likelihood methods on real comparison data from\nonline comparison surveys as well as from several sports contexts.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:12:04 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Ragain", "Stephen", ""], ["Peysakhovich", "Alexander", ""], ["Ugander", "Johan", ""]]}, {"id": "1807.09244", "submitter": "Jiajun Wu", "authors": "David Zheng, Vinson Luo, Jiajun Wu, Joshua B. Tenenbaum", "title": "Unsupervised Learning of Latent Physical Properties Using\n  Perception-Prediction Networks", "comments": "UAI 2018 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for the completely unsupervised learning of latent\nobject properties from their interactions: the perception-prediction network\n(PPN). Consisting of a perception module that extracts representations of\nlatent object properties and a prediction module that uses those extracted\nproperties to simulate system dynamics, the PPN can be trained in an end-to-end\nfashion purely from samples of object dynamics. The representations of latent\nobject properties learned by PPNs not only are sufficient to accurately\nsimulate the dynamics of systems comprised of previously unseen objects, but\nalso can be translated directly into human-interpretable properties (e.g.,\nmass, coefficient of restitution) in an entirely unsupervised manner.\nCrucially, PPNs also generalize to novel scenarios: their gradient-based\ntraining can be applied to many dynamical systems and their graph-based\nstructure functions over systems comprised of different numbers of objects. Our\nresults demonstrate the efficacy of graph-based neural architectures in\nobject-centric inference and prediction tasks, and our model has the potential\nto discover relevant object properties in systems that are not yet well\nunderstood.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:28:27 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 19:03:07 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Zheng", "David", ""], ["Luo", "Vinson", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1807.09245", "submitter": "Jiajun Wu", "authors": "Tianfan Xue, Jiajun Wu, Katherine L. Bouman, William T. Freeman", "title": "Visual Dynamics: Stochastic Future Generation via Layered Cross\n  Convolutional Networks", "comments": "Journal preprint of arXiv:1607.02586 (IEEE TPAMI, 2019). The first\n  two authors contributed equally to this work. Project page:\n  http://visualdynamics.csail.mit.edu", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (TPAMI), vol. 41, no. 9, pp. 2236-2250, 2019", "doi": "10.1109/TPAMI.2018.2854726", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of synthesizing a number of likely future frames from a\nsingle input image. In contrast to traditional methods that have tackled this\nproblem in a deterministic or non-parametric way, we propose to model future\nframes in a probabilistic manner. Our probabilistic model makes it possible for\nus to sample and synthesize many possible future frames from a single input\nimage. To synthesize realistic movement of objects, we propose a novel network\nstructure, namely a Cross Convolutional Network; this network encodes image and\nmotion information as feature maps and convolutional kernels, respectively. In\nexperiments, our model performs well on synthetic data, such as 2D shapes and\nanimated game sprites, and on real-world video frames. We present analyses of\nthe learned network representations, showing it is implicitly learning a\ncompact encoding of object appearance and motion. We also demonstrate a few of\nits applications, including visual analogy-making and video extrapolation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:28:31 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 19:17:56 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 23:11:54 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Xue", "Tianfan", ""], ["Wu", "Jiajun", ""], ["Bouman", "Katherine L.", ""], ["Freeman", "William T.", ""]]}, {"id": "1807.09259", "submitter": "Paul Henderson", "authors": "Paul Henderson, Vittorio Ferrari", "title": "Learning to Generate and Reconstruct 3D Meshes with only 2D Supervision", "comments": "BMVC 2018 (Oral). Differentiable renderer available at\n  https://github.com/pmh47/dirt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework tackling two problems: class-specific 3D\nreconstruction from a single image, and generation of new 3D shape samples.\nThese tasks have received considerable attention recently; however, existing\napproaches rely on 3D supervision, annotation of 2D images with keypoints or\nposes, and/or training with multiple views of each object instance. Our\nframework is very general: it can be trained in similar settings to these\nexisting approaches, while also supporting weaker supervision scenarios.\nImportantly, it can be trained purely from 2D images, without ground-truth pose\nannotations, and with a single view per instance. We employ meshes as an output\nrepresentation, instead of voxels used in most prior work. This allows us to\nexploit shading information during training, which previous 2D-supervised\nmethods cannot. Thus, our method can learn to generate and reconstruct concave\nobject classes. We evaluate our approach on synthetic data in various settings,\nshowing that (i) it learns to disentangle shape from pose; (ii) using shading\nin the loss improves performance; (iii) our model is comparable or superior to\nstate-of-the-art voxel-based approaches on quantitative metrics, while\nproducing results that are visually more pleasing; (iv) it still performs well\nwhen given supervision weaker than in prior works.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:54:51 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 18:00:21 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 18:59:50 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Henderson", "Paul", ""], ["Ferrari", "Vittorio", ""]]}, {"id": "1807.09289", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Dustin Tran, Timothy Lillicrap, Alex Irpan, James\n  Davidson", "title": "Noise Contrastive Priors for Functional Uncertainty", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining reliable uncertainty estimates of neural network predictions is a\nlong standing challenge. Bayesian neural networks have been proposed as a\nsolution, but it remains open how to specify their prior. In particular, the\ncommon practice of an independent normal prior in weight space imposes\nrelatively weak constraints on the function posterior, allowing it to\ngeneralize in unforeseen ways on inputs outside of the training distribution.\nWe propose noise contrastive priors (NCPs) to obtain reliable uncertainty\nestimates. The key idea is to train the model to output high uncertainty for\ndata points outside of the training distribution. NCPs do so using an input\nprior, which adds noise to the inputs of the current mini batch, and an output\nprior, which is a wide distribution given these inputs. NCPs are compatible\nwith any model that can output uncertainty estimates, are easy to scale, and\nyield reliable uncertainty estimates throughout training. Empirically, we show\nthat NCPs prevent overfitting outside of the training distribution and result\nin uncertainty estimates that are useful for active learning. We demonstrate\nthe scalability of our method on the flight delays data set, where we\nsignificantly improve upon previously published results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 18:08:45 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 20:06:34 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 00:18:00 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Hafner", "Danijar", ""], ["Tran", "Dustin", ""], ["Lillicrap", "Timothy", ""], ["Irpan", "Alex", ""], ["Davidson", "James", ""]]}, {"id": "1807.09295", "submitter": "Rishi Sharma", "authors": "Rishi Sharma, Shane Barratt, Stefano Ermon, Vijay Pande", "title": "Improved Training with Curriculum GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Curriculum GANs, a curriculum learning strategy\nfor training Generative Adversarial Networks that increases the strength of the\ndiscriminator over the course of training, thereby making the learning task\nprogressively more difficult for the generator. We demonstrate that this\nstrategy is key to obtaining state-of-the-art results in image generation. We\nalso show evidence that this strategy may be broadly applicable to improving\nGAN training in other data modalities.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 18:27:20 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Sharma", "Rishi", ""], ["Barratt", "Shane", ""], ["Ermon", "Stefano", ""], ["Pande", "Vijay", ""]]}, {"id": "1807.09306", "submitter": "Antonio Vergari", "authors": "Antonio Vergari, Alejandro Molina, Robert Peharz, Zoubin Ghahramani,\n  Kristian Kersting, Isabel Valera", "title": "Automatic Bayesian Density Analysis", "comments": "In proceedings of the Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Making sense of a dataset in an automatic and unsupervised fashion is a\nchallenging problem in statistics and AI. Classical approaches for {exploratory\ndata analysis} are usually not flexible enough to deal with the uncertainty\ninherent to real-world data: they are often restricted to fixed latent\ninteraction models and homogeneous likelihoods; they are sensitive to missing,\ncorrupt and anomalous data; moreover, their expressiveness generally comes at\nthe price of intractable inference. As a result, supervision from statisticians\nis usually needed to find the right model for the data. However, since domain\nexperts are not necessarily also experts in statistics, we propose Automatic\nBayesian Density Analysis (ABDA) to make exploratory data analysis accessible\nat large. Specifically, ABDA allows for automatic and efficient missing value\nestimation, statistical data type and likelihood discovery, anomaly detection\nand dependency structure mining, on top of providing accurate density\nestimation. Extensive empirical evidence shows that ABDA is a suitable tool for\nautomatic exploratory analysis of mixed continuous and discrete tabular data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 18:58:12 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 10:41:40 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 14:20:13 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Vergari", "Antonio", ""], ["Molina", "Alejandro", ""], ["Peharz", "Robert", ""], ["Ghahramani", "Zoubin", ""], ["Kersting", "Kristian", ""], ["Valera", "Isabel", ""]]}, {"id": "1807.09312", "submitter": "Alexander Kuvaev", "authors": "Alexander Kuvaev, Roman Khudorozhkov", "title": "A Simple Probabilistic Model for Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article focuses on determining the predictive uncertainty of a model on\nthe example of atrial fibrillation detection problem by a single-lead ECG\nsignal. To this end, the model predicts parameters of the beta distribution\nover class probabilities instead of these probabilities themselves. It was\nshown that the described approach allows to detect atypical recordings and\nsignificantly improve the quality of the algorithm on confident predictions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 19:14:29 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Kuvaev", "Alexander", ""], ["Khudorozhkov", "Roman", ""]]}, {"id": "1807.09341", "submitter": "Thanard Kurutach", "authors": "Thanard Kurutach, Aviv Tamar, Ge Yang, Stuart Russell, Pieter Abbeel", "title": "Learning Plannable Representations with Causal InfoGAN", "comments": "ICML / IJCAI / AAMAS 2018 Workshop on Planning and Learning (PAL-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep generative models have been shown to 'imagine'\nconvincing high-dimensional observations such as images, audio, and even video,\nlearning directly from raw data. In this work, we ask how to imagine\ngoal-directed visual plans -- a plausible sequence of observations that\ntransition a dynamical system from its current configuration to a desired goal\nstate, which can later be used as a reference trajectory for control. We focus\non systems with high-dimensional observations, such as images, and propose an\napproach that naturally combines representation learning and planning. Our\nframework learns a generative model of sequential observations, where the\ngenerative process is induced by a transition in a low-dimensional planning\nmodel, and an additional noise. By maximizing the mutual information between\nthe generated observations and the transition in the planning model, we obtain\na low-dimensional representation that best explains the causal nature of the\ndata. We structure the planning model to be compatible with efficient planning\nalgorithms, and we propose several such models based on either discrete or\ncontinuous states. Finally, to generate a visual plan, we project the current\nand goal observations onto their respective states in the planning model, plan\na trajectory, and then use the generative model to transform the trajectory to\na sequence of observations. We demonstrate our method on imagining plausible\nvisual plans of rope manipulation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 20:46:05 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kurutach", "Thanard", ""], ["Tamar", "Aviv", ""], ["Yang", "Ge", ""], ["Russell", "Stuart", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1807.09351", "submitter": "Lei Su", "authors": "Pengfei Fan, Tianrui Zhao, and Lei Su", "title": "Deep learning the high variability and randomness inside multimode\n  fibres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimode fibres (MMF) are remarkable high-capacity information channels\nowing to the large number of transmitting fibre modes, and have recently\nattracted significant renewed interest in applications such as optical\ncommunication, imaging, and optical trapping. At the same time, the optical\ntransmitting modes inside MMFs are highly sensitive to external perturbations\nand environmental changes, resulting in MMF transmission channels being highly\nvariable and random. This largely limits the practical application of MMFs and\nhinders the full exploitation of their information capacity. Despite great\nresearch efforts made to overcome the high variability and randomness inside\nMMFs, any geometric change to the MMF leads to completely different\ntransmission matrices, which unavoidably fails at the information recovery.\nHere, we show the successful binary image transmission using deep learning\nthrough a single MMF, which is stationary or subject to dynamic shape\nvariations. We found that a single convolutional neural network has excellent\ngeneralisation capability with various MMF transmission states. This deep\nneural network can be trained by multiple MMF transmission states to accurately\npredict unknown information at the other end of the MMF at any of these states,\nwithout knowing which state is present. Our results demonstrate that deep\nlearning is a promising solution to address the variability and randomness\nchallenge of MMF based information channels. This deep-learning approach is the\nstarting point of developing future high-capacity MMF optical systems and\ndevices, and is applicable to optical systems concerning other diffusing media.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 21:32:03 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Fan", "Pengfei", ""], ["Zhao", "Tianrui", ""], ["Su", "Lei", ""]]}, {"id": "1807.09356", "submitter": "Joseph Marino", "authors": "Joseph Marino, Yisong Yue, Stephan Mandt", "title": "Iterative Amortized Inference", "comments": "International Conference on Machine Learning (ICML) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference models are a key component in scaling variational inference to deep\nlatent variable models, most notably as encoder networks in variational\nauto-encoders (VAEs). By replacing conventional optimization-based inference\nwith a learned model, inference is amortized over data examples and therefore\nmore computationally efficient. However, standard inference models are\nrestricted to direct mappings from data to approximate posterior estimates. The\nfailure of these models to reach fully optimized approximate posterior\nestimates results in an amortization gap. We aim toward closing this gap by\nproposing iterative inference models, which learn to perform inference\noptimization through repeatedly encoding gradients. Our approach generalizes\nstandard inference models in VAEs and provides insight into several empirical\nfindings, including top-down inference techniques. We demonstrate the inference\noptimization capabilities of iterative inference models and show that they\noutperform standard inference models on several benchmark data sets of images\nand text.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 21:07:25 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Marino", "Joseph", ""], ["Yue", "Yisong", ""], ["Mandt", "Stephan", ""]]}, {"id": "1807.09374", "submitter": "Hananel Hazan", "authors": "Hananel Hazan, Daniel J. Saunders, Darpan T. Sanghavi, Hava T.\n  Siegelmann, Robert Kozma", "title": "Unsupervised Learning with Self-Organizing Spiking Neural Networks", "comments": null, "journal-ref": "Proceeding WCCI 2018", "doi": "10.1109/IJCNN.2018.8489673", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a system comprising a hybridization of self-organized map (SOM)\nproperties with spiking neural networks (SNNs) that retain many of the features\nof SOMs. Networks are trained in an unsupervised manner to learn a\nself-organized lattice of filters via excitatory-inhibitory interactions among\npopulations of neurons. We develop and test various inhibition strategies, such\nas growing with inter-neuron distance and two distinct levels of inhibition.\nThe quality of the unsupervised learning algorithm is evaluated using examples\nwith known labels. Several biologically-inspired classification tools are\nproposed and compared, including population-level confidence rating, and\nn-grams using spike motif algorithm. Using the optimal choice of parameters,\nour approach produces improvements over state-of-art spiking neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 22:08:57 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Hazan", "Hananel", ""], ["Saunders", "Daniel J.", ""], ["Sanghavi", "Darpan T.", ""], ["Siegelmann", "Hava T.", ""], ["Kozma", "Robert", ""]]}, {"id": "1807.09382", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S.Dalalyan and Lionel Riou-Durand", "title": "On sampling from a log-concave density using kinetic Langevin diffusions", "comments": "In this version, the bound in Theorem 3 is better than in previous\n  versions, in terms of its dependence on the condition number", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Langevin diffusion processes and their discretizations are often used for\nsampling from a target density. The most convenient framework for assessing the\nquality of such a sampling scheme corresponds to smooth and strongly\nlog-concave densities defined on $\\mathbb R^p$. The present work focuses on\nthis framework and studies the behavior of Monte Carlo algorithms based on\ndiscretizations of the kinetic Langevin diffusion. We first prove the geometric\nmixing property of the kinetic Langevin diffusion with a mixing rate that is,\nin the overdamped regime, optimal in terms of its dependence on the condition\nnumber. We then use this result for obtaining improved guarantees of sampling\nusing the kinetic Langevin Monte Carlo method, when the quality of sampling is\nmeasured by the Wasserstein distance. We also consider the situation where the\nHessian of the log-density of the target distribution is Lipschitz-continuous.\nIn this case, we introduce a new discretization of the kinetic Langevin\ndiffusion and prove that this leads to a substantial improvement of the upper\nbound on the sampling error measured in Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:04:49 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 10:15:13 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2018 13:31:53 GMT"}, {"version": "v4", "created": "Mon, 5 Nov 2018 17:42:34 GMT"}, {"version": "v5", "created": "Fri, 16 Nov 2018 16:54:48 GMT"}, {"version": "v6", "created": "Wed, 26 Dec 2018 10:28:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Dalalyan", "Arnak S.", ""], ["Riou-Durand", "Lionel", ""]]}, {"id": "1807.09384", "submitter": "Aysegul Dundar", "authors": "Aysegul Dundar, Ming-Yu Liu, Ting-Chun Wang, John Zedlewski, Jan Kautz", "title": "Domain Stylization: A Strong, Simple Baseline for Synthetic to Real\n  Image Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have largely failed to effectively utilize synthetic\ndata when applied to real images due to the covariate shift problem. In this\npaper, we show that by applying a straightforward modification to an existing\nphotorealistic style transfer algorithm, we achieve state-of-the-art\nsynthetic-to-real domain adaptation results. We conduct extensive experimental\nvalidations on four synthetic-to-real tasks for semantic segmentation and\nobject detection, and show that our approach exceeds the performance of any\ncurrent state-of-the-art GAN-based image translation approach as measured by\nsegmentation and object detection metrics. Furthermore we offer a distance\nbased analysis of our method which shows a dramatic reduction in Frechet\nInception distance between the source and target domains, offering a\nquantitative metric that demonstrates the effectiveness of our algorithm in\nbridging the synthetic-to-real gap.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:06:49 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Dundar", "Aysegul", ""], ["Liu", "Ming-Yu", ""], ["Wang", "Ting-Chun", ""], ["Zedlewski", "John", ""], ["Kautz", "Jan", ""]]}, {"id": "1807.09386", "submitter": "Max Simchowitz", "authors": "Max Simchowitz", "title": "On the Randomized Complexity of Minimizing a Convex Quadratic Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a convex, quadratic objective of the form\n$f_{\\mathbf{A},\\mathbf{b}}(x) := \\frac{1}{2}x^\\top \\mathbf{A} x - \\langle\n\\mathbf{b}, x \\rangle$ for $\\mathbf{A} \\succ 0 $ is a fundamental problem in\nmachine learning and optimization. In this work, we prove gradient-query\ncomplexity lower bounds for minimizing convex quadratic functions which apply\nto both deterministic and \\emph{randomized} algorithms. Specifically, for\n$\\kappa > 1$, we exhibit a distribution over $(\\mathbf{A},\\mathbf{b})$ with\ncondition number $\\mathrm{cond}(\\mathbf{A}) \\le \\kappa$, such that any\n\\emph{randomized} algorithm requires $\\Omega(\\sqrt{\\kappa})$ gradient queries\nto find a solution $\\hat x$ for which $\\|\\hat x - \\mathbf x_\\star\\| \\le\n\\epsilon_0\\|\\mathbf{x}_{\\star}\\|$, where $\\mathbf x_{\\star} =\n\\mathbf{A}^{-1}\\mathbf{b}$ is the optimal solution, and $\\epsilon_0$ a small\nconstant. Setting $\\kappa =1/\\epsilon$, this lower bound implies the minimax\nrate of $T = \\Omega(\\lambda_1(\\mathbf{A})\\|\\mathbf\nx_\\star\\|^2/\\sqrt{\\epsilon})$ queries required to minimize an arbitrary convex\nquadratic function up to error $f(\\hat{x}) - f(\\mathbf x_\\star) \\le \\epsilon$.\n  Our lower bound holds for a distribution derived from classical ensembles in\nrandom matrix theory, and relies on a careful reduction from adaptively\nestimating a planted vector $\\mathbf u$ in a deformed Wigner model. A key step\nin deriving sharp lower bounds is demonstrating that the optimization error\n$\\mathbf x_\\star - \\hat x$ cannot align too closely with $\\mathbf{u}$. To this\nend, we prove an upper bound on the cosine between $\\mathbf x_\\star - \\hat x$\nand $\\mathbf u$ in terms of the MMSE of estimating the plant $\\mathbf u$ in a\ndeformed Wigner model. We then bound the MMSE by carefully modifying a result\ndue to Lelarge and Miolane 2016, which rigorously establishes a general\nreplica-symmetric formula for planted matrix models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:23:49 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 02:25:18 GMT"}, {"version": "v3", "created": "Sat, 28 Jul 2018 21:21:52 GMT"}, {"version": "v4", "created": "Thu, 2 Aug 2018 18:41:14 GMT"}, {"version": "v5", "created": "Wed, 8 Aug 2018 18:58:11 GMT"}, {"version": "v6", "created": "Sun, 23 Sep 2018 22:21:22 GMT"}, {"version": "v7", "created": "Tue, 16 Apr 2019 08:11:37 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Simchowitz", "Max", ""]]}, {"id": "1807.09387", "submitter": "Timothy Mann", "authors": "Timothy A. Mann and Sven Gowal and Andr\\'as Gy\\\"orgy and Ray Jiang and\n  Huiyi Hu and Balaji Lakshminarayanan and Prav Srinivasan", "title": "Learning from Delayed Outcomes via Proxies with Applications to\n  Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting delayed outcomes is an important problem in recommender systems\n(e.g., if customers will finish reading an ebook). We formalize the problem as\nan adversarial, delayed online learning problem and consider how a proxy for\nthe delayed outcome (e.g., if customers read a third of the book in 24 hours)\ncan help minimize regret, even though the proxy is not available when making a\nprediction. Motivated by our regret analysis, we propose two neural network\narchitectures: Factored Forecaster (FF) which is ideal if the proxy is\ninformative of the outcome in hindsight, and Residual Factored Forecaster (RFF)\nthat is robust to a non-informative proxy. Experiments on two real-world\ndatasets for predicting human behavior show that RFF outperforms both FF and a\ndirect forecaster that does not make use of the proxy. Our results suggest that\nexploiting proxies by factorization is a promising way to mitigate the impact\nof long delays in human-behavior prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:25:24 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 17:11:37 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Mann", "Timothy A.", ""], ["Gowal", "Sven", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Jiang", "Ray", ""], ["Hu", "Huiyi", ""], ["Lakshminarayanan", "Balaji", ""], ["Srinivasan", "Prav", ""]]}, {"id": "1807.09388", "submitter": "Kai Xu", "authors": "Kai Xu, Zhikang Zhang, Fengbo Ren", "title": "LAPRAN: A Scalable Laplacian Pyramid Reconstructive Adversarial Network\n  for Flexible Compressive Sensing Reconstruction", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the single-image compressive sensing (CS) and\nreconstruction problem. We propose a scalable Laplacian pyramid reconstructive\nadversarial network (LAPRAN) that enables high-fidelity, flexible and fast CS\nimages reconstruction. LAPRAN progressively reconstructs an image following the\nconcept of Laplacian pyramid through multiple stages of reconstructive\nadversarial networks (RANs). At each pyramid level, CS measurements are fused\nwith a contextual latent vector to generate a high-frequency image residual.\nConsequently, LAPRAN can produce hierarchies of reconstructed images and each\nwith an incremental resolution and improved quality. The scalable pyramid\nstructure of LAPRAN enables high-fidelity CS reconstruction with a flexible\nresolution that is adaptive to a wide range of compression ratios (CRs), which\nis infeasible with existing methods. Experimental results on multiple public\ndatasets show that LAPRAN offers an average 7.47dB and 5.98dB PSNR, and an\naverage 57.93% and 33.20% SSIM improvement compared to model-based and\ndata-driven baselines, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:28:17 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 18:45:27 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 18:36:57 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Xu", "Kai", ""], ["Zhang", "Zhikang", ""], ["Ren", "Fengbo", ""]]}, {"id": "1807.09405", "submitter": "Alfredo Torrico", "authors": "Sebastian Pokutta and Mohit Singh and Alfredo Torrico", "title": "Efficient algorithms for robust submodular maximization under matroid\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider robust submodular maximization with matroid\nconstraints. We give an efficient bi-criteria approximation algorithm that\noutputs a small family of feasible sets whose union has (nearly) optimal\nobjective value. This algorithm theoretically performs less function calls than\nprevious works at cost of adding more elements to the final solution. We also\nprovide significant implementation improvements showing that our algorithm\noutperforms the algorithms in the existing literature. We finally assess the\nperformance of our contributions in three real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 01:09:50 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Pokutta", "Sebastian", ""], ["Singh", "Mohit", ""], ["Torrico", "Alfredo", ""]]}, {"id": "1807.09419", "submitter": "Sushma Kumari", "authors": "Sushma Kumari", "title": "Topics in Random Matrices and Statistical Machine Learning", "comments": "125 pages, 11 figures, 2 flow-diagrams, Doctoral thesis in\n  Mathematics defended in July 2018 at Department of Mathematics, Kyoto\n  University (Supervisors: Dr. Beno${\\^i}$t Collins and Dr. Vladimir G. Pestov)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis consists of two independent parts: random matrices, which form\nthe first one-third of this thesis, and machine learning, which constitutes the\nremaining part. The main results of this thesis are as follows: a necessary and\nsufficient condition for the inverse moments of $(m,n,\\beta)$-Laguerre matrices\nand compound Wishart matrices to be finite; the universal weak consistency and\nthe strong consistency of the $k$-nearest neighbor rule in metrically\nsigma-finite dimensional spaces and metrically finite dimensional spaces\nrespectively. In Part I, the Chapter 1 introduces the $(m,n,\\beta)$-Laguerre\nmatrix, Wishart and compound Wishart matrix and their joint eigenvalue\ndistribution. While in Chapter 2, a necessary and sufficient condition to have\nfinite inverse moments has been derived. In Part II, the Chapter 1 introduces\nthe various notions of metric dimension and differentiation property followed\nby our proof for the necessary part of Preiss' result. Further, Chapter 2 gives\nan introduction to the mathematical concepts in statistical machine learning\nand then the $k$-nearest neighbor rule is presented in Chapter 3 with a proof\nof Stone's theorem. In chapters 4 and 5, we present our main results and some\npossible future directions based on it.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 02:44:04 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Kumari", "Sushma", ""]]}, {"id": "1807.09427", "submitter": "Sanyam Kapoor", "authors": "Sanyam Kapoor", "title": "Multi-Agent Reinforcement Learning: A Report on Challenges and\n  Approaches", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is a learning paradigm concerned with learning to\ncontrol a system so as to maximize an objective over the long term. This\napproach to learning has received immense interest in recent times and success\nmanifests itself in the form of human-level performance on games like\n\\textit{Go}. While RL is emerging as a practical component in real-life\nsystems, most successes have been in Single Agent domains. This report will\ninstead specifically focus on challenges that are unique to Multi-Agent Systems\ninteracting in mixed cooperative and competitive environments. The report\nconcludes with advances in the paradigm of training Multi-Agent Systems called\n\\textit{Decentralized Actor, Centralized Critic}, based on an extension of MDPs\ncalled \\textit{Decentralized Partially Observable MDP}s, which has seen a\nrenewed interest lately.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 03:56:04 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Kapoor", "Sanyam", ""]]}, {"id": "1807.09443", "submitter": "Stefan Elfwing PhD", "authors": "Stefan Elfwing, Eiji Uchibe, Kenji Doya", "title": "Unbounded Output Networks for Classification", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed the expected energy-based restricted Boltzmann machine (EE-RBM)\nas a discriminative RBM method for classification. Two characteristics of the\nEE-RBM are that the output is unbounded and that the target value of correct\nclassification is set to a value much greater than one. In this study, by\nadopting features of the EE-RBM approach to feed-forward neural networks, we\npropose the UnBounded output network (UBnet) which is characterized by three\nfeatures: (1) unbounded output units; (2) the target value of correct\nclassification is set to a value much greater than one; and (3) the models are\ntrained by a modified mean-squared error objective. We evaluate our approach\nusing the MNIST, CIFAR-10, and CIFAR-100 benchmark datasets. We first\ndemonstrate, for shallow UBnets on MNIST, that a setting of the target value\nequal to the number of hidden units significantly outperforms a setting of the\ntarget value equal to one, and it also outperforms standard neural networks by\nabout 25\\%. We then validate our approach by achieving high-level\nclassification performance on the three datasets using unbounded output\nresidual networks. We finally use MNIST to analyze the learned features and\nweights, and we demonstrate that UBnets are much more robust against\nadversarial examples than the standard approach of using a softmax output layer\nand training the networks by a cross-entropy objective.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 05:57:51 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Elfwing", "Stefan", ""], ["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "1807.09462", "submitter": "Maarten van Smeden", "authors": "Bas B.L. Penning de Vries, Maarten van Smeden, Rolf H.H. Groenwold", "title": "Propensity score estimation using classification and regression trees in\n  the presence of missing covariate data", "comments": "29 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data mining and machine learning techniques such as classification and\nregression trees (CART) represent a promising alternative to conventional\nlogistic regression for propensity score estimation. Whereas incomplete data\npreclude the fitting of a logistic regression on all subjects, CART is\nappealing in part because some implementations allow for incomplete records to\nbe incorporated in the tree fitting and provide propensity score estimates for\nall subjects. Based on theoretical considerations, we argue that the automatic\nhandling of missing data by CART may however not be appropriate. Using a series\nof simulation experiments, we examined the performance of different approaches\nto handling missing covariate data; (i) applying the CART algorithm directly to\nthe (partially) incomplete data, (ii) complete case analysis, and (iii)\nmultiple imputation. Performance was assessed in terms of bias in estimating\nexposure-outcome effects \\add{among the exposed}, standard error, mean squared\nerror and coverage. Applying the CART algorithm directly to incomplete data\nresulted in bias, even in scenarios where data were missing completely at\nrandom. Overall, multiple imputation followed by CART resulted in the best\nperformance. Our study showed that automatic handling of missing data in CART\ncan cause serious bias and does not outperform multiple imputation as a means\nto account for missing data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 07:46:43 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["de Vries", "Bas B. L. Penning", ""], ["van Smeden", "Maarten", ""], ["Groenwold", "Rolf H. H.", ""]]}, {"id": "1807.09469", "submitter": "Qian Wang", "authors": "Qian Wang, Hang Li, Zhi Chen, Dou Zhao, Shuang Ye, and Jiansheng Cai", "title": "Supervised and Semi-Supervised Deep Neural Networks for CSI-Based\n  Authentication", "comments": "This paper has been submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the viewpoint of physical-layer authentication, spoofing attacks can be\nfoiled by checking channel state information (CSI). Existing CSI-based\nauthentication algorithms mostly require a deep knowledge of the channel to\ndeliver decent performance. In this paper, we investigate CSI-based\nauthenticators that can spare the effort to predetermine channel properties by\nutilizing deep neural networks (DNNs). We first propose a convolutional neural\nnetwork (CNN)-enabled authenticator that is able to extract the local features\nin CSI. Next, we employ the recurrent neural network (RNN) to capture the\ndependencies between different frequencies in CSI. In addition, we propose to\nuse the convolutional recurrent neural network (CRNN)---a combination of the\nCNN and the RNN---to learn local and contextual information in CSI for user\nauthentication. To effectively train these DNNs, one needs a large amount of\nlabeled channel records. However, it is often expensive to label large channel\nobservations in the presence of a spoofer. In view of this, we further study a\ncase in which only a small part of the the channel observations are labeled. To\nhandle it, we extend these DNNs-enabled approaches into semi-supervised ones.\nThis extension is based on a semi-supervised learning technique that employs\nboth the labeled and unlabeled data to train a DNN. To be specific, our\nsemi-supervised method begins by generating pseudo labels for the unlabeled\nchannel samples through implementing the K-means algorithm in a semi-supervised\nmanner. Subsequently, both the labeled and pseudo labeled data are exploited to\npre-train a DNN, which is then fine-tuned based on the labeled channel records.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 08:05:28 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Wang", "Qian", ""], ["Li", "Hang", ""], ["Chen", "Zhi", ""], ["Zhao", "Dou", ""], ["Ye", "Shuang", ""], ["Cai", "Jiansheng", ""]]}, {"id": "1807.09499", "submitter": "Konstantin Shmelkov", "authors": "Konstantin Shmelkov, Cordelia Schmid, Karteek Alahari", "title": "How good is my GAN?", "comments": "Accepted to ECCV2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are one of the most popular methods\nfor generating images today. While impressive results have been validated by\nvisual inspection, a number of quantitative criteria have emerged only\nrecently. We argue here that the existing ones are insufficient and need to be\nin adequation with the task at hand. In this paper we introduce two measures\nbased on image classification---GAN-train and GAN-test, which approximate the\nrecall (diversity) and precision (quality of the image) of GANs respectively.\nWe evaluate a number of recent GAN approaches based on these two measures and\ndemonstrate a clear difference in performance. Furthermore, we observe that the\nincreasing difficulty of the dataset, from CIFAR10 over CIFAR100 to ImageNet,\nshows an inverse correlation with the quality of the GANs, as clearly evident\nfrom our measures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 09:31:17 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Shmelkov", "Konstantin", ""], ["Schmid", "Cordelia", ""], ["Alahari", "Karteek", ""]]}, {"id": "1807.09510", "submitter": "Luca Carcano", "authors": "Luca Carcano, Emanuele Plebani, Danilo Pietro Pau, Marco Piastra", "title": "Pre-trainable Reservoir Computing with Recursive Neural Gas", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESN) are a class of Recurrent Neural Networks (RNN) that\nhas gained substantial popularity due to their effectiveness, ease of use and\npotential for compact hardware implementation. An ESN contains the three\nnetwork layers input, reservoir and readout where the reservoir is the truly\nrecurrent network. The input and reservoir layers of an ESN are initialized at\nrandom and never trained afterwards and the training of the ESN is applied to\nthe readout layer only. The alternative of Recursive Neural Gas (RNG) is one of\nthe many proposals of fully-trainable reservoirs that can be found in the\nliterature. Although some improvements in performance have been reported with\nRNG, to the best of authors' knowledge, no experimental comparative results are\nknown with benchmarks for which ESN is known to yield excellent results. This\nwork describes an accurate model of RNG together with some extensions to the\nmodels presented in the literature and shows comparative results on three\nwell-known and accepted datasets. The experimental results obtained show that,\nunder specific circumstances, RNG-based reservoirs can achieve better\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 10:05:46 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Carcano", "Luca", ""], ["Plebani", "Emanuele", ""], ["Pau", "Danilo Pietro", ""], ["Piastra", "Marco", ""]]}, {"id": "1807.09511", "submitter": "Xiaoran Xu", "authors": "Xiaoran Xu, Songpeng Zu, Yuan Zhang, Hanning Zhou, and Wei Feng", "title": "Backprop-Q: Generalized Backpropagation for Stochastic Computation\n  Graphs", "comments": "NeurIPS 2018 Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, it is appealing to learn a model carrying out\nstochastic operations internally, known as stochastic computation graphs\n(SCGs), rather than learning a deterministic mapping. However, standard\nbackpropagation is not applicable to SCGs. We attempt to address this issue\nfrom the angle of cost propagation, with local surrogate costs, called\nQ-functions, constructed and learned for each stochastic node in an SCG. Then,\nthe SCG can be trained based on these surrogate costs using standard\nbackpropagation. We propose the entire framework as a solution to generalize\nbackpropagation for SCGs, which resembles an actor-critic architecture but\nbased on a graph. For broad applicability, we study a variety of SCG structures\nfrom one cost to multiple costs. We utilize recent advances in reinforcement\nlearning (RL) and variational Bayes (VB), such as off-policy critic learning\nand unbiased-and-low-variance gradient estimation, and review them in the\ncontext of SCGs. The generalized backpropagation extends transported learning\nsignals beyond gradients between stochastic nodes while preserving the benefit\nof backpropagating gradients through deterministic nodes. Experimental\nsuggestions and concerns are listed to help design and test any specific model\nusing this framework.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 10:06:24 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 08:43:31 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Xu", "Xiaoran", ""], ["Zu", "Songpeng", ""], ["Zhang", "Yuan", ""], ["Zhou", "Hanning", ""], ["Feng", "Wei", ""]]}, {"id": "1807.09519", "submitter": "Siddhartha Mishra", "authors": "Siddhartha Mishra", "title": "A machine learning framework for data driven acceleration of\n  computations of differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a machine learning framework to accelerate numerical computations\nof time-dependent ODEs and PDEs. Our method is based on recasting\n(generalizations of) existing numerical methods as artificial neural networks,\nwith a set of trainable parameters. These parameters are determined in an\noffline training process by (approximately) minimizing suitable (possibly\nnon-convex) loss functions by (stochastic) gradient descent methods. The\nproposed algorithm is designed to be always consistent with the underlying\ndifferential equation. Numerical experiments involving both linear and\nnon-linear ODE and PDE model problems demonstrate a significant gain in\ncomputational efficiency over standard numerical methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 10:33:20 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Mishra", "Siddhartha", ""]]}, {"id": "1807.09534", "submitter": "Ufuk Can Bi\\c{c}ici", "authors": "Ufuk Can Bi\\c{c}ici, Cem Keskin, Lale Akarun", "title": "Conditional Information Gain Networks", "comments": "ICPR 2018 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models owe their representational power to the high\nnumber of learnable parameters. It is often infeasible to run these largely\nparametrized deep models in limited resource environments, like mobile phones.\nNetwork models employing conditional computing are able to reduce computational\nrequirements while achieving high representational power, with their ability to\nmodel hierarchies. We propose Conditional Information Gain Networks, which\nallow the feed forward deep neural networks to execute conditionally, skipping\nparts of the model based on the sample and the decision mechanisms inserted in\nthe architecture. These decision mechanisms are trained using cost functions\nbased on differentiable Information Gain, inspired by the training procedures\nof decision trees. These information gain based decision mechanisms are\ndifferentiable and can be trained end-to-end using a unified framework with a\ngeneral cost function, covering both classification and decision losses. We\ntest the effectiveness of the proposed method on MNIST and recently introduced\nFashion MNIST datasets and show that our information gain based conditional\nexecution approach can achieve better or comparable classification results\nusing significantly fewer parameters, compared to standard convolutional neural\nnetwork baselines.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 11:26:46 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Bi\u00e7ici", "Ufuk Can", ""], ["Keskin", "Cem", ""], ["Akarun", "Lale", ""]]}, {"id": "1807.09561", "submitter": "Lewis Mitchell", "authors": "Ahmad Hany Hossny, Terry Moschou, Grant Osborne, Lewis Mitchell, Nick\n  Lothian", "title": "Enhancing keyword correlation for event detection in social networks\n  using SVD and k-means: Twitter case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting textual features from tweets is a challenging process due to the\nnoisy nature of the content and the weak signal of most of the words used. In\nthis paper, we propose using singular value decomposition (SVD) with clustering\nto enhance the signals of the textual features in the tweets to improve the\ncorrelation with events. The proposed technique applies SVD to the time series\nvector for each feature to factorize the matrix of feature/day counts, in order\nto ensure the independence of the feature vectors. Afterwards, the k-means\nclustering is applied to build a look-up table that maps members of each\ncluster to the cluster-centroid. The lookup table is used to map each feature\nin the original data to the centroid of its cluster, then we calculate the sum\nof the term frequency vectors of all features in each cluster to the\nterm-frequency-vector of the cluster centroid. To test the technique we\ncalculated the correlations of the cluster centroids with the golden standard\nrecord (GSR) vector before and after summing the vectors of the cluster members\nto the centroid-vector. The proposed method is applied to multiple correlation\ntechniques including the Pearson, Spearman, distance correlation and Kendal\nTao. The experiments have also considered the different word forms and lengths\nof the features including keywords, n-grams, skip-grams and bags-of-words. The\ncorrelation results are enhanced significantly as the highest correlation\nscores have increased from 0.3 to 0.6, and the average correlation scores have\nincreased from 0.3 to 0.4.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 12:56:25 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Hossny", "Ahmad Hany", ""], ["Moschou", "Terry", ""], ["Osborne", "Grant", ""], ["Mitchell", "Lewis", ""], ["Lothian", "Nick", ""]]}, {"id": "1807.09571", "submitter": "Xianglan Jin", "authors": "Xianglan Jin and Hyoung-Nam Kim", "title": "Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider signal detection algorithms in a multiple-input\nmultiple-output (MIMO) decode-forward (DF) relay channel with one source, one\nrelay, and one destination. The existing suboptimal near maximum likelihood\n(NML) detector and the NML with two-level pair-wise error probability\n(NMLw2PEP) detector achieve excellent performance with instantaneous channel\nstate information (CSI) of the source-relay (SR) link and with statistical CSI\nof the SR link, respectively. However, the NML detectors require an\nexponentially increasing complexity as the number of transmit antennas\nincreases. Using deep learning algorithms, NML-based detection networks\n(NMLDNs) are proposed with and without the CSI of the SR link at the\ndestination. The NMLDNs detect signals in changing channels after a single\ntraining using a large number of randomly distributed channels. The detection\nnetworks require much lower detection complexity than the exhaustive search NML\ndetectors while exhibiting good performance. To evaluate the performance, we\nintroduce semidefinite relaxation detectors with polynomial complexity based on\nthe NML detectors. Additionally, new linear detectors based on the zero\ngradient of the NML metrics are proposed. Applying various detection algorithms\nat the relay (DetR) and detection algorithms at the destination (DetD), we\npresent some DetR-DetD methods in MIMO DF relay channels. An appropriate\nDetR-DetD method can be employed according to the required error probability\nand detection complexity. The complexity analysis and simulation results\nvalidate the arguments of this paper.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 02:31:37 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Jin", "Xianglan", ""], ["Kim", "Hyoung-Nam", ""]]}, {"id": "1807.09574", "submitter": "Bander Ali", "authors": "Bander Ali Saleh Al-rimy, Mohd Aizaini Maarof, Syed Zainudeen Mohd\n  Shaid", "title": "Redundancy Coefficient Gradual Up-weighting-based Mutual Information\n  Feature Selection Technique for Crypto-ransomware Early Detection", "comments": null, "journal-ref": "Future Generation Computer Systems, Volume 115, 2021, Pages\n  641-658", "doi": "10.1016/j.future.2020.10.002", "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crypto-ransomware is characterized by its irreversible effect even after the\ndetection and removal. As such, the early detection is crucial to protect user\ndata and files of being held to ransom. Several solutions have proposed\nutilizing the data extracted during the initial phases of the attacks before\nthe encryption takes place. However, the lack of enough data at the early\nphases of the attack along with high dimensional features space renders the\nmodel prone to overfitting which decreases its detection accuracy. To this end,\nthis paper proposed a novel redundancy coefficient gradual up-weighting\napproach that was incorporated to the calculation of redundancy term of mutual\ninformation to improve the feature selection process and enhance the accuracy\nof the detection model. Several machine learning classifiers were used to\nevaluate the detection performance of the proposed techniques. The experimental\nresults show that the accuracy of proposed techniques achieved higher detection\naccuracy. Those results demonstrate the efficacy of the proposed techniques for\nthe early detection tasks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 00:36:18 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Al-rimy", "Bander Ali Saleh", ""], ["Maarof", "Mohd Aizaini", ""], ["Shaid", "Syed Zainudeen Mohd", ""]]}, {"id": "1807.09586", "submitter": "Antoine Tixier", "authors": "Antoine J.-P. Tixier, Maria-Evgenia G. Rossi, Fragkiskos D. Malliaros,\n  Jesse Read, Michalis Vazirgiannis", "title": "Perturb and Combine to Identify Influential Spreaders in Real-World\n  Networks", "comments": "Accepted at ASONAM 2019", "journal-ref": "ASONAM 2019", "doi": "10.1145/3341161.3342866", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some of the most effective influential spreader detection algorithms are\nunstable to small perturbations of the network structure. Inspired by bagging\nin Machine Learning, we propose the first Perturb and Combine (P&C) procedure\nfor networks. It (1) creates many perturbed versions of a given graph, (2)\napplies a node scoring function separately to each graph, and (3) combines the\nresults. Experiments conducted on real-world networks of various sizes with the\nk-core, generalized k-core, and PageRank algorithms reveal that P&C brings\nsubstantial improvements. Moreover, this performance boost can be obtained at\nalmost no extra cost through parallelization. Finally, a bias-variance analysis\nsuggests that P&C works mainly by reducing bias, and that therefore, it should\nbe capable of improving the performance of all vertex scoring functions,\nincluding stable ones.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 13:43:15 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 11:30:12 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 13:20:52 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Tixier", "Antoine J. -P.", ""], ["Rossi", "Maria-Evgenia G.", ""], ["Malliaros", "Fragkiskos D.", ""], ["Read", "Jesse", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1807.09596", "submitter": "Yash Deshpande", "authors": "Yash Deshpande, Andrea Montanari, Elchanan Mossel, Subhabrata Sen", "title": "Contextual Stochastic Block Models", "comments": "28 pages, 1 figure, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first information theoretic tight analysis for inference of\nlatent community structure given a sparse graph along with high dimensional\nnode covariates, correlated with the same latent communities. Our work bridges\nrecent theoretical breakthroughs in the detection of latent community structure\nwithout nodes covariates and a large body of empirical work using diverse\nheuristics for combining node covariates with graphs for inference. The\ntightness of our analysis implies in particular, the information theoretical\nnecessity of combining the different sources of information. Our analysis holds\nfor networks of large degrees as well as for a Gaussian version of the model.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 03:34:35 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Deshpande", "Yash", ""], ["Montanari", "Andrea", ""], ["Mossel", "Elchanan", ""], ["Sen", "Subhabrata", ""]]}, {"id": "1807.09597", "submitter": "Shruti Palaskar", "authors": "Shruti Palaskar and Florian Metze", "title": "Acoustic-to-Word Recognition with Sequence-to-Sequence Models", "comments": "9 pages, 3 figures, Under Review at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic-to-Word recognition provides a straightforward solution to\nend-to-end speech recognition without needing external decoding, language model\nre-scoring or lexicon. While character-based models offer a natural solution to\nthe out-of-vocabulary problem, word models can be simpler to decode and may\nalso be able to directly recognize semantically meaningful units. We present\neffective methods to train Sequence-to-Sequence models for direct word-level\nrecognition (and character-level recognition) and show an absolute improvement\nof 4.4-5.0\\% in Word Error Rate on the Switchboard corpus compared to prior\nwork. In addition to these promising results, word-based models are more\ninterpretable than character models, which have to be composed into words using\na separate decoding step. We analyze the encoder hidden states and the\nattention behavior, and show that location-aware attention naturally represents\nwords as a single speech-word-vector, despite spanning multiple frames in the\ninput. We finally show that the Acoustic-to-Word model also learns to segment\nspeech into words with a mean standard deviation of 3 frames as compared with\nhuman annotated forced-alignments for the Switchboard corpus.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:29:43 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 11:28:14 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Palaskar", "Shruti", ""], ["Metze", "Florian", ""]]}, {"id": "1807.09617", "submitter": "Soham Chatterjee Mr.", "authors": "Soham Chatterjee, Archana Iyer, Satya Avva, Abhai Kollara, Malaikannan\n  Sankarasubbu", "title": "Convolutional Neural Networks In Classifying Cancer Through DNA\n  Methylation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA Methylation has been the most extensively studied epigenetic mark.\nUsually a change in the genotype, DNA sequence, leads to a change in the\nphenotype, observable characteristics of the individual. But DNA methylation,\nwhich happens in the context of CpG (cytosine and guanine bases linked by\nphosphate backbone) dinucleotides, does not lead to a change in the original\nDNA sequence but has the potential to change the phenotype. DNA methylation is\nimplicated in various biological processes and diseases including cancer. Hence\nthere is a strong interest in understanding the DNA methylation patterns across\nvarious epigenetic related ailments in order to distinguish and diagnose the\ntype of disease in its early stages. In this work, the relationship between\nmethylated versus unmethylated CpG regions and cancer types is explored using\nConvolutional Neural Networks (CNNs). A CNN based Deep Learning model that can\nclassify the cancer of a new DNA methylation profile based on the learning from\npublicly available DNA methylation datasets is then proposed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:11:58 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Chatterjee", "Soham", ""], ["Iyer", "Archana", ""], ["Avva", "Satya", ""], ["Kollara", "Abhai", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1807.09623", "submitter": "Alon Talmor", "authors": "Alon Talmor and Jonathan Berant", "title": "Repartitioning of the ComplexWebQuestions Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Talmor and Berant (2018) introduced ComplexWebQuestions - a dataset\nfocused on answering complex questions by decomposing them into a sequence of\nsimpler questions and extracting the answer from retrieved web snippets. In\ntheir work the authors used a pre-trained reading comprehension (RC) model\n(Salant and Berant, 2018) to extract the answer from the web snippets. In this\nshort note we show that training a RC model directly on the training data of\nComplexWebQuestions reveals a leakage from the training set to the test set\nthat allows to obtain unreasonably high performance. As a solution, we\nconstruct a new partitioning of ComplexWebQuestions that does not suffer from\nthis leakage and publicly release it. We also perform an empirical evaluation\non these two datasets and show that training a RC model on the training data\nsubstantially improves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:15:40 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1807.09639", "submitter": "Yingting Wu", "authors": "Yingting Wu and Hai Zhao", "title": "Finding Better Subword Segmentation for Neural Machine Translation", "comments": "12 pages, accepted by CCL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For different language pairs, word-level neural machine translation (NMT)\nmodels with a fixed-size vocabulary suffer from the same problem of\nrepresenting out-of-vocabulary (OOV) words. The common practice usually\nreplaces all these rare or unknown words with a <UNK> token, which limits the\ntranslation performance to some extent. Most of recent work handled such a\nproblem by splitting words into characters or other specially extracted subword\nunits to enable open-vocabulary translation. Byte pair encoding (BPE) is one of\nthe successful attempts that has been shown extremely competitive by providing\neffective subword segmentation for NMT systems. In this paper, we extend the\nBPE style segmentation to a general unsupervised framework with three\nstatistical measures: frequency (FRQ), accessor variety (AV) and description\nlength gain (DLG). We test our approach on two translation tasks: German to\nEnglish and Chinese to English. The experimental results show that AV and DLG\nenhanced systems outperform the FRQ baseline in the frequency weighted schemes\nat different significant levels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:43:46 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Wu", "Yingting", ""], ["Zhao", "Hai", ""]]}, {"id": "1807.09644", "submitter": "Austin Benson", "authors": "Austin R. Benson", "title": "Three hypergraph eigenvector centralities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigenvector centrality is a standard network analysis tool for determining\nthe importance of (or ranking of) entities in a connected system that is\nrepresented by a graph. However, many complex systems and datasets have natural\nmulti-way interactions that are more faithfully modeled by a hypergraph. Here\nwe extend the notion of graph eigenvector centrality to uniform hypergraphs.\nTraditional graph eigenvector centralities are given by a positive eigenvector\nof the adjacency matrix, which is guaranteed to exist by the Perron-Frobenius\ntheorem under some mild conditions. The natural representation of a hypergraph\nis a hypermatrix (colloquially, a tensor). Using recently established\nPerron-Frobenius theory for tensors, we develop three tensor eigenvectors\ncentralities for hypergraphs, each with different interpretations. We show that\nthese centralities can reveal different information on real-world data by\nanalyzing hypergraphs constructed from n-gram frequencies, co-tagging on stack\nexchange, and drug combinations observed in patient emergency room visits.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:49:53 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 22:39:25 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 12:07:07 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Benson", "Austin R.", ""]]}, {"id": "1807.09647", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue", "title": "Variational Bayesian Reinforcement Learning with Regret Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration-exploitation trade-off in reinforcement learning\nand we show that an agent imbued with an epistemic-risk-seeking utility\nfunction is able to explore efficiently, as measured by regret. The parameter\nthat controls how risk-seeking the agent is can be optimized to minimize\nregret, or annealed according to a schedule. We call the resulting algorithm\nK-learning and we show that the K-values that the agent maintains are\noptimistic for the expected optimal Q-values at each state-action pair. The\nutility function approach induces a natural Boltzmann exploration policy for\nwhich the 'temperature' parameter is equal to the risk-seeking parameter. This\npolicy achieves a Bayesian regret bound of $\\tilde O(L^{3/2} \\sqrt{SAT})$,\nwhere L is the time horizon, S is the number of states, A is the number of\nactions, and T is the total number of elapsed time-steps. K-learning can be\ninterpreted as mirror descent in the policy space, and it is similar to other\nwell-known methods in the literature, including Q-learning, soft-Q-learning,\nand maximum entropy policy gradient. K-learning is simple to implement, as it\nonly requires adding a bonus to the reward at each state-action and then\nsolving a Bellman equation. We conclude with a numerical example demonstrating\nthat K-learning is competitive with other state-of-the-art algorithms in\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:56:09 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 10:52:26 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["O'Donoghue", "Brendan", ""]]}, {"id": "1807.09659", "submitter": "Qianli Liao", "authors": "Qianli Liao, Brando Miranda, Andrzej Banburski, Jack Hidary, Tomaso\n  Poggio", "title": "A Surprising Linear Relationship Predicts Test Performance in Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two networks with the same training loss on a dataset, when would they\nhave drastically different test losses and errors? Better understanding of this\nquestion of generalization may improve practical applications of deep networks.\nIn this paper we show that with cross-entropy loss it is surprisingly simple to\ninduce significantly different generalization performances for two networks\nthat have the same architecture, the same meta parameters and the same training\nerror: one can either pretrain the networks with different levels of\n\"corrupted\" data or simply initialize the networks with weights of different\nGaussian standard deviations. A corollary of recent theoretical results on\noverfitting shows that these effects are due to an intrinsic problem of\nmeasuring test performance with a cross-entropy/exponential-type loss, which\ncan be decomposed into two components both minimized by SGD -- one of which is\nnot related to expected classification performance. However, if we factor out\nthis component of the loss, a linear relationship emerges between training and\ntest losses. Under this transformation, classical generalization bounds are\nsurprisingly tight: the empirical/training loss is very close to the\nexpected/test loss. Furthermore, the empirical relation between classification\nerror and normalized cross-entropy loss seem to be approximately monotonic\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 15:20:02 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Liao", "Qianli", ""], ["Miranda", "Brando", ""], ["Banburski", "Andrzej", ""], ["Hidary", "Jack", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1807.09705", "submitter": "Todd Huster", "authors": "Todd Huster, Cho-Yu Jason Chiang, and Ritu Chadha", "title": "Limitations of the Lipschitz constant as a defense against adversarial\n  examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent papers have discussed utilizing Lipschitz constants to limit\nthe susceptibility of neural networks to adversarial examples. We analyze\nrecently proposed methods for computing the Lipschitz constant. We show that\nthe Lipschitz constant may indeed enable adversarially robust neural networks.\nHowever, the methods currently employed for computing it suffer from\ntheoretical and practical limitations. We argue that addressing this\nshortcoming is a promising direction for future research into certified\nadversarial defenses.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 16:31:05 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Huster", "Todd", ""], ["Chiang", "Cho-Yu Jason", ""], ["Chadha", "Ritu", ""]]}, {"id": "1807.09737", "submitter": "Hans Kersting", "authors": "Hans Kersting, T. J. Sullivan, Philipp Hennig", "title": "Convergence Rates of Gaussian ODE Filters", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently-introduced class of probabilistic (uncertainty-aware) solvers for\nordinary differential equations (ODEs) applies Gaussian (Kalman) filtering to\ninitial value problems. These methods model the true solution $x$ and its first\n$q$ derivatives \\emph{a priori} as a Gauss--Markov process $\\boldsymbol{X}$,\nwhich is then iteratively conditioned on information about $\\dot{x}$. This\narticle establishes worst-case local convergence rates of order $q+1$ for a\nwide range of versions of this Gaussian ODE filter, as well as global\nconvergence rates of order $q$ in the case of $q=1$ and an integrated Brownian\nmotion prior, and analyses how inaccurate information on $\\dot{x}$ coming from\napproximate evaluations of $f$ affects these rates. Moreover, we show that, in\nthe globally convergent case, the posterior credible intervals are well\ncalibrated in the sense that they globally contract at the same rate as the\ntruncation error. We illustrate these theoretical results by numerical\nexperiments which might indicate their generalizability to $q \\in\n\\{2,3,\\dots\\}$.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 17:33:55 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 18:11:45 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 16:54:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kersting", "Hans", ""], ["Sullivan", "T. J.", ""], ["Hennig", "Philipp", ""]]}, {"id": "1807.09741", "submitter": "Qingyuan Feng", "authors": "Qingyuan Feng, Evgenia Dueva, Artem Cherkasov and Martin Ester", "title": "PADME: A Deep Learning-based Framework for Drug-Target Interaction\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In silico drug-target interaction (DTI) prediction is an important and\nchallenging problem in biomedical research with a huge potential benefit to the\npharmaceutical industry and patients. Most existing methods for DTI prediction\nincluding deep learning models generally have binary endpoints, which could be\nan oversimplification of the problem, and those methods are typically unable to\nhandle cold-target problems, i.e., problems involving target protein that never\nappeared in the training set. Towards this, we contrived PADME (Protein And\nDrug Molecule interaction prEdiction), a framework based on Deep Neural\nNetworks, to predict real-valued interaction strength between compounds and\nproteins without requiring feature engineering. PADME takes both compound and\nprotein information as inputs, so it is capable of solving cold-target (and\ncold-drug) problems. To our knowledge, we are the first to combine Molecular\nGraph Convolution (MGC) for compound featurization with protein descriptors for\nDTI prediction. We used multiple cross-validation split schemes and evaluation\nmetrics to measure the performance of PADME on multiple datasets, including the\nToxCast dataset, and PADME consistently dominates baseline methods. The results\nof a case study, which predicts the binding affinity between various compounds\nand androgen receptor (AR), suggest PADME's potential in drug development. The\nscalability of PADME is another advantage in the age of Big Data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 17:46:47 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 23:50:49 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 00:09:20 GMT"}, {"version": "v4", "created": "Wed, 21 Aug 2019 04:27:16 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Feng", "Qingyuan", ""], ["Dueva", "Evgenia", ""], ["Cherkasov", "Artem", ""], ["Ester", "Martin", ""]]}, {"id": "1807.09751", "submitter": "Han Xiao", "authors": "Han Xiao, Yidong Chen, Xiaodong Shi", "title": "Multi-Perspective Neural Architecture for Recommendation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, there starts a research trend to leverage neural architecture for\nrecommendation systems. Though several deep recommender models are proposed,\nmost methods are too simple to characterize users' complex preference. In this\npaper, for a fine-grain analysis, users' ratings are explained from multiple\nperspectives, based on which, we propose our neural architecture. Specifically,\nour model employs several sequential stages to encode the user and item into\nhidden representations. In one stage, the user and item are represented from\nmultiple perspectives and in each perspective, the representations of user and\nitem put attentions to each other. Last, we metric the output representations\nof final stage to approach the users' rating. Extensive experiments demonstrate\nthat our method achieves substantial improvements against baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:06:39 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Xiao", "Han", ""], ["Chen", "Yidong", ""], ["Shi", "Xiaodong", ""]]}, {"id": "1807.09761", "submitter": "Sujith Mangalathu", "authors": "Sujith Mangalathu and Jong-Su Jeon", "title": "Stripe-Based Fragility Analysis of Concrete Bridge Classes Using Machine\n  Learning Techniques", "comments": "10 Figure, 4 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework for the generation of bridge-specific fragility utilizing the\ncapabilities of machine learning and stripe-based approach is presented in this\npaper. The proposed methodology using random forests helps to generate or\nupdate fragility curves for a new set of input parameters with less\ncomputational effort and expensive re-simulation. The methodology does not\nplace any assumptions on the demand model of various components and helps to\nidentify the relative importance of each uncertain variable in their seismic\ndemand model. The methodology is demonstrated through the case studies of\nmulti-span concrete bridges in California. Geometric, material and structural\nuncertainties are accounted for in the generation of bridge models and\nfragility curves. It is also noted that the traditional lognormality assumption\non the demand model leads to unrealistic fragility estimates. Fragility results\nobtained the proposed methodology curves can be deployed in risk assessment\nplatform such as HAZUS for regional loss estimation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 01:29:13 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Mangalathu", "Sujith", ""], ["Jeon", "Jong-Su", ""]]}, {"id": "1807.09809", "submitter": "Mark Collier", "authors": "Mark Collier and Hector Urdiales Llorens", "title": "Deep Contextual Multi-armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual multi-armed bandit problems arise frequently in important\nindustrial applications. Existing solutions model the context either linearly,\nwhich enables uncertainty driven (principled) exploration, or non-linearly, by\nusing epsilon-greedy exploration policies. Here we present a deep learning\nframework for contextual multi-armed bandits that is both non-linear and\nenables principled exploration at the same time. We tackle the exploration vs.\nexploitation trade-off through Thompson sampling by exploiting the connection\nbetween inference time dropout and sampling from the posterior over the weights\nof a Bayesian neural network. In order to adjust the level of exploration\nautomatically as more data is made available to the model, the dropout rate is\nlearned rather than considered a hyperparameter. We demonstrate that our\napproach substantially reduces regret on two tasks (the UCI Mushroom task and\nthe Casino Parity task) when compared to 1) non-contextual bandits, 2)\nepsilon-greedy deep contextual bandits, and 3) fixed dropout rate deep\ncontextual bandits. Our approach is currently being applied to marketing\noptimization problems at HubSpot.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 18:25:45 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Collier", "Mark", ""], ["Llorens", "Hector Urdiales", ""]]}, {"id": "1807.09810", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey, Moitreya Chatterjee, Narendra Ahuja", "title": "Coreset-Based Neural Network Compression", "comments": "Camera-Ready version for ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Convolutional Neural Network (CNN) compression algorithm\nbased on coreset representations of filters. We exploit the redundancies extant\nin the space of CNN weights and neuronal activations (across samples) in order\nto obtain compression. Our method requires no retraining, is easy to implement,\nand obtains state-of-the-art compression performance across a wide variety of\nCNN architectures. Coupled with quantization and Huffman coding, we create\nnetworks that provide AlexNet-like accuracy, with a memory footprint that is\n$832\\times$ smaller than the original AlexNet, while also introducing\nsignificant reductions in inference time as well. Additionally these compressed\nnetworks when fine-tuned, successfully generalize to other domains as well.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 18:26:49 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Chatterjee", "Moitreya", ""], ["Ahuja", "Narendra", ""]]}, {"id": "1807.09813", "submitter": "Simon Bussy", "authors": "Simon Bussy, Mokhtar Z. Alaya, Anne-Sophie Jannot, Agathe Guilloux", "title": "Binacox: automatic cut-point detection in high-dimensional Cox model\n  with applications in genetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the binacox, a prognostic method to deal with the problem of\ndetecting multiple cut-points per features in a multivariate setting where a\nlarge number of continuous features are available. The method is based on the\nCox model and combines one-hot encoding with the binarsity penalty, which uses\ntotal-variation regularization together with an extra linear constraint, and\nenables feature selection. Original nonasymptotic oracle inequalities for\nprediction (in terms of Kullback-Leibler divergence) and estimation with a fast\nrate of convergence are established. The statistical performance of the method\nis examined in an extensive Monte Carlo simulation study, and then illustrated\non three publicly available genetic cancer datasets. On these high-dimensional\ndatasets, our proposed method significantly outperforms state-of-the-art\nsurvival models regarding risk prediction in terms of the C-index, with a\ncomputing time orders of magnitude faster. In addition, it provides powerful\ninterpretability from a clinical perspective by automatically pinpointing\nsignificant cut-points in relevant variables.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 18:31:54 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 15:07:41 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 17:01:04 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 15:03:15 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Bussy", "Simon", ""], ["Alaya", "Mokhtar Z.", ""], ["Jannot", "Anne-Sophie", ""], ["Guilloux", "Agathe", ""]]}, {"id": "1807.09821", "submitter": "Simon Bussy", "authors": "Simon Bussy, Rapha\\\"el Veil, Vincent Looten, Anita Burgun, St\\'ephane\n  Ga\\\"iffas, Agathe Guilloux, Brigitte Ranque, Anne-Sophie Jannot", "title": "Comparison of methods for early-readmission prediction in a\n  high-dimensional heterogeneous covariates and time-to-event outcome framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Choosing the most performing method in terms of outcome\nprediction or variables selection is a recurring problem in prognosis studies,\nleading to many publications on methods comparison. But some aspects have\nreceived little attention. First, most comparison studies treat prediction\nperformance and variable selection aspects separately. Second, methods are\neither compared within a binary outcome setting (based on an arbitrarily chosen\ndelay) or within a survival setting, but not both. In this paper, we propose a\ncomparison methodology to weight up those different settings both in terms of\nprediction and variables selection, while incorporating advanced machine\nlearning strategies. Methods: Using a high-dimensional case study on a\nsickle-cell disease (SCD) cohort, we compare 8 statistical methods. In the\nbinary outcome setting, we consider logistic regression (LR), support vector\nmachine (SVM), random forest (RF), gradient boosting (GB) and neural network\n(NN); while on the survival analysis setting, we consider the Cox Proportional\nHazards (PH), the CURE and the C-mix models. We then compare performances of\nall methods both in terms of risk prediction and variable selection, with a\nfocus on the use of Elastic-Net regularization technique. Results: Among all\nassessed statistical methods assessed, the C-mix model yields the better\nperformances in both the two considered settings, as well as interesting\ninterpretation aspects. There is some consistency in selected covariates across\nmethods within a setting, but not much across the two settings. Conclusions: It\nappears that learning withing the survival setting first, and then going back\nto a binary prediction using the survival estimates significantly enhance\nbinary predictions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 18:45:21 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Bussy", "Simon", ""], ["Veil", "Rapha\u00ebl", ""], ["Looten", "Vincent", ""], ["Burgun", "Anita", ""], ["Ga\u00efffas", "St\u00e9phane", ""], ["Guilloux", "Agathe", ""], ["Ranque", "Brigitte", ""], ["Jannot", "Anne-Sophie", ""]]}, {"id": "1807.09830", "submitter": "Luis Argerich", "authors": "Leandro Palma, Luis Argerich", "title": "Iterative evaluation of LSTM cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we present a modification in the conventional flow of\ninformation through a LSTM network, which we consider well suited for RNNs in\ngeneral. The modification leads to a iterative scheme where the computations\nperformed by the LSTM cell are repeated over a constant input and cell state\nvalues, while updating the hidden state a finite number of times. We provide\ntheoretical and empirical evidence to support the augmented capabilities of the\niterative scheme and show examples related to language modeling. The\nmodification yields an enhancement in the model performance comparable with the\noriginal model augmented more than 3 times in terms of the total amount of\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 13:57:23 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Palma", "Leandro", ""], ["Argerich", "Luis", ""]]}, {"id": "1807.09834", "submitter": "Jo\\~ao Borrego", "authors": "Jo\\~ao Borrego, Atabak Dehban, Rui Figueiredo, Plinio Moreno,\n  Alexandre Bernardino and Jos\\'e Santos-Victor", "title": "Applying Domain Randomization to Synthetic Data for Object Category\n  Detection", "comments": "17 pages, 9 figures. Under review for ACCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning-based object detection techniques have\nrevolutionized their applicability in several fields. However, since these\nmethods rely on unwieldy and large amounts of data, a common practice is to\ndownload models pre-trained on standard datasets and fine-tune them for\nspecific application domains with a small set of domain relevant images. In\nthis work, we show that using synthetic datasets that are not necessarily\nphoto-realistic can be a better alternative to simply fine-tune pre-trained\nnetworks. Specifically, our results show an impressive 25% improvement in the\nmAP metric over a fine-tuning baseline when only about 200 labelled images are\navailable to train. Finally, an ablation study of our results is presented to\ndelineate the individual contribution of different components in the\nrandomization pipeline.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:08:57 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Borrego", "Jo\u00e3o", ""], ["Dehban", "Atabak", ""], ["Figueiredo", "Rui", ""], ["Moreno", "Plinio", ""], ["Bernardino", "Alexandre", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1807.09842", "submitter": "Muhammad Mahbubur Rahman", "authors": "Muhammad Mahbubur Rahman, Tim Finin", "title": "Understanding and representing the semantics of large structured\n  documents", "comments": "10 pages, 6 figures, 28 references and 2 tables", "journal-ref": "Semantic Deep Learning at ISWC 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding large, structured documents like scholarly articles, requests\nfor proposals or business reports is a complex and difficult task. It involves\ndiscovering a document's overall purpose and subject(s), understanding the\nfunction and meaning of its sections and subsections, and extracting low level\nentities and facts about them. In this research, we present a deep learning\nbased document ontology to capture the general purpose semantic structure and\ndomain specific semantic concepts from a large number of academic articles and\nbusiness documents. The ontology is able to describe different functional parts\nof a document, which can be used to enhance semantic indexing for a better\nunderstanding by human beings and machines. We evaluate our models through\nextensive experiments on datasets of scholarly articles from arXiv and Request\nfor Proposal documents.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 04:14:51 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Finin", "Tim", ""]]}, {"id": "1807.09844", "submitter": "John Kelleher", "authors": "Simon Dobnik and John D. Kelleher", "title": "Modular Mechanistic Networks: On Bridging Mechanistic and\n  Phenomenological Models with Deep Neural Networks in Natural Language\n  Processing", "comments": "18 pages, 1 figure, Appears in CLASP Papers in Computational\n  Linguistics Vol. 1: Proceedings of the Conference on Logic and Machine\n  Learning in Natural Language (LaML 2017)", "journal-ref": "CLASP Papers in Computational Linguistics Vol. 1: Proceedings of\n  the Conference on Logic and Machine Learning in Natural Language (LaML 2017).\n  ISSN: 2002-9764. URI: http://hdl.handle.net/2077/54911", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) can be done using either top-down (theory\ndriven) and bottom-up (data driven) approaches, which we call mechanistic and\nphenomenological respectively. The approaches are frequently considered to\nstand in opposition to each other. Examining some recent approaches in deep\nlearning we argue that deep neural networks incorporate both perspectives and,\nfurthermore, that leveraging this aspect of deep learning may help in solving\ncomplex problems within language technology, such as modelling language and\nperception in the domain of spatial cognition.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:37:15 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 15:45:24 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Dobnik", "Simon", ""], ["Kelleher", "John D.", ""]]}, {"id": "1807.09865", "submitter": "Samuel Weisenthal", "authors": "Samuel J. Weisenthal, Caroline Quill, Samir Farooq, Henry Kautz,\n  Martin S. Zand", "title": "Predicting Acute Kidney Injury at Hospital Re-entry Using\n  High-dimensional Electronic Health Record Data", "comments": "In revision", "journal-ref": null, "doi": "10.1371/journal.pone.0204920", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute Kidney Injury (AKI), a sudden decline in kidney function, is associated\nwith increased mortality, morbidity, length of stay, and hospital cost. Since\nAKI is sometimes preventable, there is great interest in prediction. Most\nexisting studies consider all patients and therefore restrict to features\navailable in the first hours of hospitalization. Here, the focus is instead on\nrehospitalized patients, a cohort in which rich longitudinal features from\nprior hospitalizations can be analyzed. Our objective is to provide a risk\nscore directly at hospital re-entry. Gradient boosting, penalized logistic\nregression (with and without stability selection), and a recurrent neural\nnetwork are trained on two years of adult inpatient EHR data (3,387 attributes\nfor 34,505 patients who generated 90,013 training samples with 5,618 cases and\n84,395 controls). Predictions are internally evaluated with 50 iterations of\n5-fold grouped cross-validation with special emphasis on calibration, an\nanalysis of which is performed at the patient as well as hospitalization level.\nError is assessed with respect to diagnosis, race, age, gender, AKI\nidentification method, and hospital utilization. In an additional experiment,\nthe regularization penalty is severely increased to induce parsimony and\ninterpretability. Predictors identified for rehospitalized patients are also\nreported with a special analysis of medications that might be modifiable risk\nfactors. Insights from this study might be used to construct a predictive tool\nfor AKI in rehospitalized patients. An accurate estimate of AKI risk at\nhospital entry might serve as a prior for an admitting provider or another\npredictive algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 21:19:48 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 13:17:15 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Weisenthal", "Samuel J.", ""], ["Quill", "Caroline", ""], ["Farooq", "Samir", ""], ["Kautz", "Henry", ""], ["Zand", "Martin S.", ""]]}, {"id": "1807.09870", "submitter": "Felipe del Rio", "authors": "Felipe del Rio and Pablo Messina and Vicente Dominguez and Denis Parra", "title": "Do Better ImageNet Models Transfer Better... for Image Recommendation?", "comments": "Submitted to KTL Workshop co-located at RecSys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual embeddings from Convolutional Neural Networks (CNN) trained on the\nImageNet dataset for the ILSVRC challenge have shown consistently good\nperformance for transfer learning and are widely used in several tasks,\nincluding image recommendation. However, some important questions have not yet\nbeen answered in order to use these embeddings for a larger scope of\nrecommendation domains: a) Do CNNs that perform better in ImageNet are also\nbetter for transfer learning in content-based image recommendation?, b) Does\nfine-tuning help to improve performance? and c) Which is the best way to\nperform the fine-tuning?\n  In this paper we compare several CNN models pre-trained with ImageNet to\nevaluate their transfer learning performance to an artwork image recommendation\ntask. Our results indicate that models with better performance in the ImageNet\nchallenge do not always imply better transfer learning for recommendation tasks\n(e.g. NASNet vs. ResNet). Our results also show that fine-tuning can be helpful\neven with a small dataset, but not every fine-tuning works. Our results can\ninform other researchers and practitioners on how to train their CNNs for\nbetter transfer learning towards image recommendation systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 21:34:55 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 16:56:52 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2018 11:52:52 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["del Rio", "Felipe", ""], ["Messina", "Pablo", ""], ["Dominguez", "Vicente", ""], ["Parra", "Denis", ""]]}, {"id": "1807.09875", "submitter": "Caio Corro", "authors": "Caio Corro, Ivan Titov", "title": "Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a\n  Structured Variational Autoencoder", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human annotation for syntactic parsing is expensive, and large resources are\navailable only for a fraction of languages. A question we ask is whether one\ncan leverage abundant unlabeled texts to improve syntactic parsers, beyond just\nusing the texts to obtain more generalisable lexical features (i.e. beyond word\nembeddings). To this end, we propose a novel latent-variable generative model\nfor semi-supervised syntactic dependency parsing. As exact inference is\nintractable, we introduce a differentiable relaxation to obtain approximate\nsamples and compute gradients with respect to the parser parameters. Our method\n(Differentiable Perturb-and-Parse) relies on differentiable dynamic programming\nover stochastically perturbed edge scores. We demonstrate effectiveness of our\napproach with experiments on English, French and Swedish.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 21:42:55 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 19:45:49 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Corro", "Caio", ""], ["Titov", "Ivan", ""]]}, {"id": "1807.09901", "submitter": "Dung Phan", "authors": "Dung Phan, Nicola Paoletti, Timothy Zhang, Radu Grosu, Scott A.\n  Smolka, Scott D. Stoller", "title": "Neural State Classification for Hybrid Systems", "comments": "ATVA2018 extended version", "journal-ref": null, "doi": "10.1007/978-3-030-01090-4_25", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the State Classification Problem (SCP) for hybrid systems, and\npresent Neural State Classification (NSC) as an efficient solution technique.\nSCP generalizes the model checking problem as it entails classifying each state\n$s$ of a hybrid automaton as either positive or negative, depending on whether\nor not $s$ satisfies a given time-bounded reachability specification. This is\nan interesting problem in its own right, which NSC solves using\nmachine-learning techniques, Deep Neural Networks in particular. State\nclassifiers produced by NSC tend to be very efficient (run in constant time and\nspace), but may be subject to classification errors. To quantify and mitigate\nsuch errors, our approach comprises: i) techniques for certifying, with\nstatistical guarantees, that an NSC classifier meets given accuracy levels; ii)\ntuning techniques, including a novel technique based on adversarial sampling,\nthat can virtually eliminate false negatives (positive states classified as\nnegative), thereby making the classifier more conservative. We have applied NSC\nto six nonlinear hybrid system benchmarks, achieving an accuracy of 99.25% to\n99.98%, and a false-negative rate of 0.0033 to 0, which we further reduced to\n0.0015 to 0 after tuning the classifier. We believe that this level of accuracy\nis acceptable in many practical applications, and that these results\ndemonstrate the promise of the NSC approach.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 00:27:17 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Phan", "Dung", ""], ["Paoletti", "Nicola", ""], ["Zhang", "Timothy", ""], ["Grosu", "Radu", ""], ["Smolka", "Scott A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1807.09902", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Manoj Plakal, Frederic Font, Daniel P. W. Ellis,\n  Xavier Favory, Jordi Pons, Xavier Serra", "title": "General-purpose Tagging of Freesound Audio with AudioSet Labels: Task\n  Description, Dataset, and Baseline", "comments": "Camera ready for DCASE Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes Task 2 of the DCASE 2018 Challenge, titled\n\"General-purpose audio tagging of Freesound content with AudioSet labels\". This\ntask was hosted on the Kaggle platform as \"Freesound General-Purpose Audio\nTagging Challenge\". The goal of the task is to build an audio tagging system\nthat can recognize the category of an audio clip from a subset of 41 diverse\ncategories drawn from the AudioSet Ontology. We present the task, the dataset\nprepared for the competition, and a baseline system.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 00:30:54 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 14:23:02 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2018 02:25:28 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Plakal", "Manoj", ""], ["Font", "Frederic", ""], ["Ellis", "Daniel P. W.", ""], ["Favory", "Xavier", ""], ["Pons", "Jordi", ""], ["Serra", "Xavier", ""]]}, {"id": "1807.09904", "submitter": "Maria Bauza Villalonga", "authors": "Maria Bauza, Francois R. Hogan and Alberto Rodriguez", "title": "A Data-Efficient Approach to Precise and Controlled Pushing", "comments": "Maria Bauza and Francois R. Hogan contributed equally to this work.\n  10 pages, 5 figures", "journal-ref": "CoRL 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decades of research in control theory have shown that simple controllers,\nwhen provided with timely feedback, can control complex systems. Pushing is an\nexample of a complex mechanical system that is difficult to model accurately\ndue to unknown system parameters such as coefficients of friction and pressure\ndistributions. In this paper, we explore the data-complexity required for\ncontrolling, rather than modeling, such a system. Results show that a\nmodel-based control approach, where the dynamical model is learned from data,\nis capable of performing complex pushing trajectories with a minimal amount of\ntraining data (10 data points). The dynamics of pushing interactions are\nmodeled using a Gaussian process (GP) and are leveraged within a model\npredictive control approach that linearizes the GP and imposes actuator and\ntask constraints for a planar manipulation task.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 00:37:28 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 15:44:23 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bauza", "Maria", ""], ["Hogan", "Francois R.", ""], ["Rodriguez", "Alberto", ""]]}, {"id": "1807.09912", "submitter": "Tailin Wu", "authors": "Tailin Wu, John Peurifoy, Isaac L. Chuang, Max Tegmark", "title": "Meta-learning autoencoders for few-shot prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to humans, machine learning models generally require significantly\nmore training examples and fail to extrapolate from experience to solve\npreviously unseen challenges. To help close this performance gap, we augment\nsingle-task neural networks with a meta-recognition model which learns a\nsuccinct model code via its autoencoder structure, using just a few informative\nexamples. The model code is then employed by a meta-generative model to\nconstruct parameters for the task-specific model. We demonstrate that for\npreviously unseen tasks, without additional training, this Meta-Learning\nAutoencoder (MeLA) framework can build models that closely match the true\nunderlying models, with loss significantly lower than given by fine-tuned\nbaseline networks, and performance that compares favorably with\nstate-of-the-art meta-learning algorithms. MeLA also adds the ability to\nidentify influential training examples and predict which additional data will\nbe most valuable to acquire to improve model prediction.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 01:26:14 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Wu", "Tailin", ""], ["Peurifoy", "John", ""], ["Chuang", "Isaac L.", ""], ["Tegmark", "Max", ""]]}, {"id": "1807.09932", "submitter": "Patryk Orzechowski", "authors": "Patryk Orzechowski and Jason H. Moore", "title": "EBIC: an open source software for high-dimensional and big data\n  biclustering analyses", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: In this paper we present the latest release of EBIC, a\nnext-generation biclustering algorithm for mining genetic data. The major\ncontribution of this paper is adding support for big data, making it possible\nto efficiently run large genomic data mining analyses. Additional enhancements\ninclude integration with R and Bioconductor and an option to remove influence\nof missing value on the final result.\n  Results: EBIC was applied to datasets of different sizes, including a large\nDNA methylation dataset with 436,444 rows. For the largest dataset we observed\nover 6.6 fold speedup in computation time on a cluster of 8 GPUs compared to\nrunning the method on a single GPU. This proves high scalability of the\nalgorithm.\n  Availability: The latest version of EBIC could be downloaded from\nhttp://github.com/EpistasisLab/ebic . Installation and usage instructions are\nalso available online.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 02:57:19 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Orzechowski", "Patryk", ""], ["Moore", "Jason H.", ""]]}, {"id": "1807.09936", "submitter": "Jiaming Song", "authors": "Jiaming Song, Hongyu Ren, Dorsa Sadigh, Stefano Ermon", "title": "Multi-Agent Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms can be used to learn a policy from expert\ndemonstrations without access to a reward signal. However, most existing\napproaches are not applicable in multi-agent settings due to the existence of\nmultiple (Nash) equilibria and non-stationary environments. We propose a new\nframework for multi-agent imitation learning for general Markov games, where we\nbuild upon a generalized notion of inverse reinforcement learning. We further\nintroduce a practical multi-agent actor-critic algorithm with good empirical\nperformance. Our method can be used to imitate complex behaviors in\nhigh-dimensional environments with multiple cooperative or competing agents.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:21:49 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Song", "Jiaming", ""], ["Ren", "Hongyu", ""], ["Sadigh", "Dorsa", ""], ["Ermon", "Stefano", ""]]}, {"id": "1807.09937", "submitter": "Jiren Zhu", "authors": "Jiren Zhu, Russell Kaplan, Justin Johnson and Li Fei-Fei", "title": "HiDDeN: Hiding Data With Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep neural networks are highly sensitive to tiny\nperturbations of input images, giving rise to adversarial examples. Though this\nproperty is usually considered a weakness of learned models, we explore whether\nit can be beneficial. We find that neural networks can learn to use invisible\nperturbations to encode a rich amount of useful information. In fact, one can\nexploit this capability for the task of data hiding. We jointly train encoder\nand decoder networks, where given an input message and cover image, the encoder\nproduces a visually indistinguishable encoded image, from which the decoder can\nrecover the original message. We show that these encodings are competitive with\nexisting data hiding algorithms, and further that they can be made robust to\nnoise: our models learn to reconstruct hidden information in an encoded image\ndespite the presence of Gaussian blurring, pixel-wise dropout, cropping, and\nJPEG compression. Even though JPEG is non-differentiable, we show that a robust\nmodel can be trained using differentiable approximations. Finally, we\ndemonstrate that adversarial training improves the visual quality of encoded\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:25:15 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Zhu", "Jiren", ""], ["Kaplan", "Russell", ""], ["Johnson", "Justin", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1807.09946", "submitter": "Avanti Shrikumar", "authors": "Avanti Shrikumar, Jocelin Su, Anshul Kundaje", "title": "Computationally Efficient Measures of Internal Neuron Importance", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of assigning importance to individual neurons in a network is\nof interest when interpreting deep learning models. In recent work, Dhamdhere\net al. proposed Total Conductance, a \"natural refinement of Integrated\nGradients\" for attributing importance to internal neurons. Unfortunately, the\nauthors found that calculating conductance in tensorflow required the addition\nof several custom gradient operators and did not scale well. In this work, we\nshow that the formula for Total Conductance is mathematically equivalent to\nPath Integrated Gradients computed on a hidden layer in the network. We provide\na scalable implementation of Total Conductance using standard tensorflow\ngradient operators that we call Neuron Integrated Gradients. We compare Neuron\nIntegrated Gradients to DeepLIFT, a pre-existing computationally efficient\napproach that is applicable to calculating internal neuron importance. We find\nthat DeepLIFT produces strong empirical results and is faster to compute, but\nbecause it lacks the theoretical properties of Neuron Integrated Gradients, it\nmay not always be preferred in practice. Colab notebook reproducing results:\nhttp://bit.ly/neuronintegratedgradients\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:47:45 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Shrikumar", "Avanti", ""], ["Su", "Jocelin", ""], ["Kundaje", "Anshul", ""]]}, {"id": "1807.09958", "submitter": "Bo Dai", "authors": "Bo Dai, Deming Ye, and Dahua Lin", "title": "Rethinking the Form of Latent States in Image Captioning", "comments": "ECCV 2018, first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNNs and their variants have been widely adopted for image captioning. In\nRNNs, the production of a caption is driven by a sequence of latent states.\nExisting captioning models usually represent latent states as vectors, taking\nthis practice for granted. We rethink this choice and study an alternative\nformulation, namely using two-dimensional maps to encode latent states. This is\nmotivated by the curiosity about a question: how the spatial structures in the\nlatent states affect the resultant captions? Our study on MSCOCO and Flickr30k\nleads to two significant observations. First, the formulation with 2D states is\ngenerally more effective in captioning, consistently achieving higher\nperformance with comparable parameter sizes. Second, 2D states preserve spatial\nlocality. Taking advantage of this, we visually reveal the internal dynamics in\nthe process of caption generation, as well as the connections between input\nvisual domain and output linguistic domain.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 05:26:15 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Dai", "Bo", ""], ["Ye", "Deming", ""], ["Lin", "Dahua", ""]]}, {"id": "1807.09962", "submitter": "Beomjoon Kim", "authors": "Beomjoon Kim and Zi Wang and Leslie Pack Kaelbling and Tomas\n  Lozano-Perez", "title": "Learning to guide task and motion planning using score-space\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a learning algorithm that speeds up the search in\ntask and motion planning problems. Our algorithm proposes solutions to three\ndifferent challenges that arise in learning to improve planning efficiency:\nwhat to predict, how to represent a planning problem instance, and how to\ntransfer knowledge from one problem instance to another. We propose a method\nthat predicts constraints on the search space based on a generic representation\nof a planning problem instance, called score-space, where we represent a\nproblem instance in terms of the performance of a set of solutions attempted so\nfar. Using this representation, we transfer knowledge, in the form of\nconstraints, from previous problems based on the similarity in score space. We\ndesign a sequential algorithm that efficiently predicts these constraints, and\nevaluate it in three different challenging task and motion planning problems.\nResults indicate that our approach performs orders of magnitudes faster than an\nunguided planner\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 05:35:18 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kim", "Beomjoon", ""], ["Wang", "Zi", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "1807.09967", "submitter": "Artit Wangperawong", "authors": "Xinyi Liu and Artit Wangperawong", "title": "A Collaborative Approach to Angel and Venture Capital Investment\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.IR cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization was used to generate investment recommendations for\ninvestors. An iterative conjugate gradient method was used to optimize the\nregularized squared-error loss function. The number of latent factors, number\nof iterations, and regularization values were explored. Overfitting can be\naddressed by either early stopping or regularization parameter tuning. The\nmodel achieved the highest average prediction accuracy of 13.3%. With a similar\nmodel, the same dataset was used to generate investor recommendations for\ncompanies undergoing fundraising, which achieved highest prediction accuracy of\n11.1%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 06:14:08 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Liu", "Xinyi", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1807.09979", "submitter": "Piyush Pandita", "authors": "Piyush Pandita, Ilias Bilionis and Jitesh Panchal", "title": "Bayesian Optimal Design of Experiments For Inferring The Statistical\n  Expectation Of A Black-Box Function", "comments": "27 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimal design of experiments (BODE) has been successful in\nacquiring information about a quantity of interest (QoI) which depends on a\nblack-box function. BODE is characterized by sequentially querying the function\nat specific designs selected by an infill-sampling criterion. However, most\ncurrent BODE methods operate in specific contexts like optimization, or\nlearning a universal representation of the black-box function. The objective of\nthis paper is to design a BODE for estimating the statistical expectation of a\nphysical response surface. This QoI is omnipresent in uncertainty propagation\nand design under uncertainty problems. Our hypothesis is that an optimal BODE\nshould be maximizing the expected information gain in the QoI. We represent the\ninformation gain from a hypothetical experiment as the Kullback-Liebler (KL)\ndivergence between the prior and the posterior probability distributions of the\nQoI. The prior distribution of the QoI is conditioned on the observed data and\nthe posterior distribution of the QoI is conditioned on the observed data and a\nhypothetical experiment. The main contribution of this paper is the derivation\nof a semi-analytic mathematical formula for the expected information gain about\nthe statistical expectation of a physical response. The developed BODE is\nvalidated on synthetic functions with varying number of input-dimensions. We\ndemonstrate the performance of the methodology on a steel wire manufacturing\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 07:09:56 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 18:47:21 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 13:33:34 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Pandita", "Piyush", ""], ["Bilionis", "Ilias", ""], ["Panchal", "Jitesh", ""]]}, {"id": "1807.10079", "submitter": "Mohammed AL Zamil Prof.", "authors": "Mohammed GH. I. AL Zamil", "title": "Automatic Detection of Node-Replication Attack in Vehicular Ad-hoc\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in smart cities applications enforce security threads such as\nnode replication attacks. Such attack is take place when the attacker plants a\nreplicated network node within the network. Vehicular Ad hoc networks are\nconnecting sensors that have limited resources and required the response time\nto be as low as possible. In this type networks, traditional detection\nalgorithms of node replication attacks are not efficient. In this paper, we\npropose an initial idea to apply a newly adapted statistical methodology that\ncan detect node replication attacks with high performance as compared to\nstate-of-the-art techniques. We provide a sufficient description of this\nmethodology and a road-map for testing and experiment its performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 11:54:48 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 09:24:16 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 23:51:52 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Zamil", "Mohammed GH. I. AL", ""]]}, {"id": "1807.10096", "submitter": "Georgios Leontidis", "authors": "Fabio De Sousa Ribeiro, Francesco Caliva, Dionysios Chionis,\n  Abdelhamid Dokhane, Antonios Mylonakis, Christophe Demaziere, Georgios\n  Leontidis and Stefanos Kollias", "title": "Towards a Deep Unified Framework for Nuclear Reactor Perturbation\n  Analysis", "comments": "8 pages, 8 figures, 5 tables; typos corrected, added references,\n  minor alterations, results unchanged", "journal-ref": null, "doi": "10.1109/SSCI.2018.8628637", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take the first steps towards a novel unified framework for\nthe analysis of perturbations in both the Time and Frequency domains. The\nidentification of type and source of such perturbations is fundamental for\nmonitoring reactor cores and guarantee safety while running at nominal\nconditions. A 3D Convolutional Neural Network (3D-CNN) was employed to analyse\nperturbations happening in the frequency domain, such as an absorber of\nvariable strength or propagating perturbation. Recurrent neural networks (RNN),\nspecifically Long Short-Term Memory (LSTM) networks were used to study signal\nsequences related to perturbations induced in the time domain, including the\nvibrations of fuel assemblies and the fluctuations of thermal-hydraulic\nparameters at the inlet of the reactor coolant loops. 512 dimensional\nrepresentations were extracted from the 3D-CNN and LSTM architectures, and used\nas input to a fused multi-sigmoid classification layer to recognise the\nperturbation type. If the perturbation is in the frequency domain, a separate\nfully-connected layer utilises said representations to regress the coordinates\nof its source. The results showed that the perturbation type can be recognised\nwith high accuracy in all cases, and frequency domain scenario sources can be\nlocalised with high precision.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 12:34:25 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 21:06:57 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ribeiro", "Fabio De Sousa", ""], ["Caliva", "Francesco", ""], ["Chionis", "Dionysios", ""], ["Dokhane", "Abdelhamid", ""], ["Mylonakis", "Antonios", ""], ["Demaziere", "Christophe", ""], ["Leontidis", "Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1807.10110", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Ville Hautam\\\"aki", "title": "ToriLLE: Learning Environment for Hand-to-Hand Combat", "comments": "https://github.com/Miffyli/ToriLLE . Accepted to IEEE Conference on\n  Games 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Toribash Learning Environment (ToriLLE), a learning environment\nfor machine learning agents based on the video game Toribash. Toribash is a\nMuJoCo-like environment of two humanoid character fighting each other\nhand-to-hand, controlled by changing actuation modes of the joints. Competitive\nnature of Toribash as well its focused domain provide a platform for evaluating\nself-play methods, and evaluating machine learning agents against human\nplayers. In this paper we describe the environment with ToriLLE's capabilities\nand limitations, and experimentally show its applicability as a learning\nenvironment. The source code of the environment and conducted experiments can\nbe found at https://github.com/Miffyli/ToriLLE.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:27:35 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 14:12:22 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 10:29:48 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "1807.10117", "submitter": "Guoqiang Zhang", "authors": "G. Zhang and H. Li", "title": "Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, self-normalizing neural networks (SNNs) have been proposed with the\nintention to avoid batch or weight normalization. The key step in SNNs is to\nproperly scale the exponential linear unit (referred to as SELU) to inherently\nincorporate normalization based on central limit theory. SELU is a\nmonotonically increasing function, where it has an approximately constant\nnegative output for large negative input. In this work, we propose a new\nactivation function to break the monotonicity property of SELU while still\npreserving the self-normalizing property. Differently from SELU, the new\nfunction introduces a bump-shaped function in the region of negative input by\nregularizing a linear function with a scaled exponential function, which is\nreferred to as a scaled exponentially-regularized linear unit (SERLU). The\nbump-shaped function has approximately zero response to large negative input\nwhile being able to push the output of SERLU towards zero mean statistically.\nTo effectively combat over-fitting, we develop a so-called shift-dropout for\nSERLU, which includes standard dropout as a special case. Experimental results\non MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provide\nconsistently promising results in comparison to other 5 activation functions\nincluding ELU, SELU, Swish, Leakly ReLU and ReLU.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:33:49 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 09:16:41 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Zhang", "G.", ""], ["Li", "H.", ""]]}, {"id": "1807.10119", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Ran Chen, Wei Li, Fanhua Shang, Wenjian Yu, Minsik Cho, Bei\n  Yu", "title": "A Unified Approximation Framework for Compressing and Accelerating Deep\n  Neural Networks", "comments": "8 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved significant success in a variety of\nreal world applications, i.e., image classification. However, tons of\nparameters in the networks restrict the efficiency of neural networks due to\nthe large model size and the intensive computation. To address this issue,\nvarious approximation techniques have been investigated, which seek for a light\nweighted network with little performance degradation in exchange of smaller\nmodel size or faster inference. Both low-rankness and sparsity are appealing\nproperties for the network approximation. In this paper we propose a unified\nframework to compress the convolutional neural networks (CNNs) by combining\nthese two properties, while taking the nonlinear activation into consideration.\nEach layer in the network is approximated by the sum of a structured sparse\ncomponent and a low-rank component, which is formulated as an optimization\nproblem. Then, an extended version of alternating direction method of\nmultipliers (ADMM) with guaranteed convergence is presented to solve the\nrelaxed optimization problem. Experiments are carried out on VGG-16, AlexNet\nand GoogLeNet with large image classification datasets. The results outperform\nprevious work in terms of accuracy degradation, compression rate and speedup\nratio. The proposed method is able to remarkably compress the model (with up to\n4.9x reduction of parameters) at a cost of little loss or without loss on\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:36:19 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 05:37:24 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 03:06:00 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ma", "Yuzhe", ""], ["Chen", "Ran", ""], ["Li", "Wei", ""], ["Shang", "Fanhua", ""], ["Yu", "Wenjian", ""], ["Cho", "Minsik", ""], ["Yu", "Bei", ""]]}, {"id": "1807.10129", "submitter": "Andrew Fitzgibbon", "authors": "Filip \\v{S}rajer, Zuzana Kukelova, Andrew Fitzgibbon", "title": "A Benchmark of Selected Algorithmic Differentiation Tools on Some\n  Problems in Computer Vision and Machine Learning", "comments": "Previous versions of this article appeared at AD2016---7th\n  International Conference on Algorithmic Differentiation, and in Optimization\n  Methods and Software, Taylor and Francis, Feb 2018 (online)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic differentiation (AD) allows exact computation of derivatives\ngiven only an implementation of an objective function. Although many AD tools\nare available, a proper and efficient implementation of AD methods is not\nstraightforward. The existing tools are often too different to allow for a\ngeneral test suite. In this paper, we compare fifteen ways of computing\nderivatives including eleven automatic differentiation tools implementing\nvarious methods and written in various languages (C++, F#, MATLAB, Julia and\nPython), two symbolic differentiation tools, finite differences, and\nhand-derived computation.\n  We look at three objective functions from computer vision and machine\nlearning. These objectives are for the most part simple, in the sense that no\niterative loops are involved, and conditional statements are encapsulated in\nfunctions such as {\\tt abs} or {\\tt logsumexp}. However, it is important for\nthe success of algorithmic differentiation that such `simple' objective\nfunctions are handled efficiently, as so many problems in computer vision and\nmachine learning are of this form.\n  Of course, our results depend on programmer skill, and familiarity with the\ntools. However, we contend that this paper presents an important datapoint: a\nskilled programmer devoting roughly a week to each tool produced the timings we\npresent. We have made our implementations available as open source to allow the\ncommunity to replicate and update these benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:42:30 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["\u0160rajer", "Filip", ""], ["Kukelova", "Zuzana", ""], ["Fitzgibbon", "Andrew", ""]]}, {"id": "1807.10165", "submitter": "Zongwei Zhou", "authors": "Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, Jianming\n  Liang", "title": "UNet++: A Nested U-Net Architecture for Medical Image Segmentation", "comments": "8 pages, 3 figures, 3 tables, accepted by 4th Deep Learning in\n  Medical Image Analysis (DLMIA) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present UNet++, a new, more powerful architecture for\nmedical image segmentation. Our architecture is essentially a deeply-supervised\nencoder-decoder network where the encoder and decoder sub-networks are\nconnected through a series of nested, dense skip pathways. The re-designed skip\npathways aim at reducing the semantic gap between the feature maps of the\nencoder and decoder sub-networks. We argue that the optimizer would deal with\nan easier learning task when the feature maps from the decoder and encoder\nnetworks are semantically similar. We have evaluated UNet++ in comparison with\nU-Net and wide U-Net architectures across multiple medical image segmentation\ntasks: nodule segmentation in the low-dose CT scans of chest, nuclei\nsegmentation in the microscopy images, liver segmentation in abdominal CT\nscans, and polyp segmentation in colonoscopy videos. Our experiments\ndemonstrate that UNet++ with deep supervision achieves an average IoU gain of\n3.9 and 3.4 points over U-Net and wide U-Net, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 04:08:21 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Zhou", "Zongwei", ""], ["Siddiquee", "Md Mahfuzur Rahman", ""], ["Tajbakhsh", "Nima", ""], ["Liang", "Jianming", ""]]}, {"id": "1807.10166", "submitter": "Simon Moura", "authors": "Moura Simon, Amini Massih-Reza, Louhichi Sana, Clausel Marianne", "title": "Rademacher Generalization Bounds for Classifier Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new framework to study the generalization\nproperty of classifier chains trained over observations associated with\nmultiple and interdependent class labels. The results are based on large\ndeviation inequalities for Lipschitz functions of weakly dependent sequences\nproposed by Rio in 2000. We believe that the resulting generalization error\nbound brings many advantages and could be adapted to other frameworks that\nconsider interdependent outputs. First, it explicitly exhibits the dependencies\nbetween class labels. Secondly, it provides insights of the effect of the order\nof the chain on the algorithm generalization performances. Finally, the two\ndependency coefficients that appear in the bound could also be used to design\nnew strategies to decide the order of the chain.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 14:27:14 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Simon", "Moura", ""], ["Massih-Reza", "Amini", ""], ["Sana", "Louhichi", ""], ["Marianne", "Clausel", ""]]}, {"id": "1807.10211", "submitter": "Jing Zhang", "authors": "Jing Zhang, Huibing Wang, Yonggong Ren", "title": "Robust Tracking via Weighted Online Extreme Learning Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tracking method based on the extreme learning machine (ELM) is efficient\nand effective. ELM randomly generates input weights and biases in the hidden\nlayer, and then calculates and computes the output weights by reducing the\niterative solution to the problem of linear equations. Therefore, ELM offers\nthe satisfying classification performance and fast training time than other\ndiscriminative models in tracking. However, the original ELM method often\nsuffers from the problem of the imbalanced classification distribution, which\nis caused by few target objects, leading to under-fitting and more background\nsamples leading to over-fitting. Worse still, it reduces the robustness of\ntracking under special conditions including occlusion, illumination, etc. To\naddress above problems, in this paper, we present a robust tracking algorithm.\nFirst, we introduce the local weight matrix that is the dynamic creation from\nthe data distribution at the current frame in the original ELM so as to balance\nbetween the empirical and structure risk, and fully learn the target object to\nenhance the classification performance. Second, we improve it to the\nincremental learning method ensuring tracking real-time and efficient. Finally,\nthe forgetting factor is used to strengthen the robustness for changing of the\nclassification distribution with time. Meanwhile, we propose a novel optimized\nmethod to obtain the optimal sample as the target object, which avoids tracking\ndrift resulting from noisy samples. Therefore, our tracking method can fully\nlearn both of the target object and background information to enhance the\ntracking performance, and it is evaluated in 20 challenge image sequences with\ndifferent attributes including illumination, occlusion, deformation, etc.,\nwhich achieves better performance than several state-of-the-art methods in\nterms of effectiveness and robustness.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 15:57:19 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Zhang", "Jing", ""], ["Wang", "Huibing", ""], ["Ren", "Yonggong", ""]]}, {"id": "1807.10215", "submitter": "Jen-Tang Lu", "authors": "Jen-Tang Lu, Stefano Pedemonte, Bernardo Bizzo, Sean Doyle, Katherine\n  P. Andriole, Mark H. Michalski, R. Gilberto Gonzalez, Stuart R. Pomerantz", "title": "DeepSPINE: Automated Lumbar Vertebral Segmentation, Disc-level\n  Designation, and Spinal Stenosis Grading Using Deep Learning", "comments": "Accepted as spotlight talk at Machine Learning for Healthcare (MLHC)\n  2018. Supplementary Video: https://bit.ly/DeepSPINE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high prevalence of spinal stenosis results in a large volume of MRI\nimaging, yet interpretation can be time-consuming with high inter-reader\nvariability even among the most specialized radiologists. In this paper, we\ndevelop an efficient methodology to leverage the subject-matter-expertise\nstored in large-scale archival reporting and image data for a deep-learning\napproach to fully-automated lumbar spinal stenosis grading. Specifically, we\nintroduce three major contributions: (1) a natural-language-processing scheme\nto extract level-by-level ground-truth labels from free-text radiology reports\nfor the various types and grades of spinal stenosis (2) accurate vertebral\nsegmentation and disc-level localization using a U-Net architecture combined\nwith a spine-curve fitting method, and (3) a multi-input, multi-task, and\nmulti-class convolutional neural network to perform central canal and foraminal\nstenosis grading on both axial and sagittal imaging series inputs with the\nextracted report-derived labels applied to corresponding imaging level\nsegments. This study uses a large dataset of 22796 disc-levels extracted from\n4075 patients. We achieve state-of-the-art performance on lumbar spinal\nstenosis classification and expect the technique will increase both radiology\nworkflow efficiency and the perceived value of radiology reports for referring\nclinicians and patients.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 15:59:49 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lu", "Jen-Tang", ""], ["Pedemonte", "Stefano", ""], ["Bizzo", "Bernardo", ""], ["Doyle", "Sean", ""], ["Andriole", "Katherine P.", ""], ["Michalski", "Mark H.", ""], ["Gonzalez", "R. Gilberto", ""], ["Pomerantz", "Stuart R.", ""]]}, {"id": "1807.10225", "submitter": "Hoo Chang Shin", "authors": "Hoo-Chang Shin, Neil A Tenenholtz, Jameson K Rogers, Christopher G\n  Schwarz, Matthew L Senjem, Jeffrey L Gunter, Katherine Andriole, Mark\n  Michalski", "title": "Medical Image Synthesis for Data Augmentation and Anonymization using\n  Generative Adversarial Networks", "comments": "Accepted for 2018 Workshop on Simulation and Synthesis in Medical\n  Imaging - SASHIMI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data diversity is critical to success when training deep learning models.\nMedical imaging data sets are often imbalanced as pathologic findings are\ngenerally rare, which introduces significant challenges when training deep\nlearning models. In this work, we propose a method to generate synthetic\nabnormal MRI images with brain tumors by training a generative adversarial\nnetwork using two publicly available data sets of brain MRI. We demonstrate two\nunique benefits that the synthetic images provide. First, we illustrate\nimproved performance on tumor segmentation by leveraging the synthetic images\nas a form of data augmentation. Second, we demonstrate the value of generative\nmodels as an anonymization tool, achieving comparable tumor segmentation\nresults when trained on the synthetic data versus when trained on real subject\ndata. Together, these results offer a potential solution to two of the largest\nchallenges facing machine learning in medical imaging, namely the small\nincidence of pathological findings, and the restrictions around sharing of\npatient data.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 16:25:18 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 19:11:23 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Shin", "Hoo-Chang", ""], ["Tenenholtz", "Neil A", ""], ["Rogers", "Jameson K", ""], ["Schwarz", "Christopher G", ""], ["Senjem", "Matthew L", ""], ["Gunter", "Jeffrey L", ""], ["Andriole", "Katherine", ""], ["Michalski", "Mark", ""]]}, {"id": "1807.10251", "submitter": "Hongyu Guo", "authors": "Hongyu Guo, Yongyi Mao, Ali Al-Bashabsheh and Richong Zhang", "title": "Aggregated Learning: A Deep Learning Framework Based on\n  Information-Bottleneck Vector Quantization", "comments": "with Supplementary Materials, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the notion of information bottleneck (IB), we formulate a\nquantization problem called \"IB quantization\". We show that IB quantization is\nequivalent to learning based on the IB principle. Under this equivalence, the\nstandard neural network models can be viewed as scalar (single sample) IB\nquantizers. It is known, from conventional rate-distortion theory, that scalar\nquantizers are inferior to vector (multi-sample) quantizers. Such a deficiency\nthen inspires us to develop a novel learning framework, AgrLearn, that\ncorresponds to vector IB quantizers for learning with neural networks. Unlike\nstandard networks, AgrLearn simultaneously optimizes against multiple data\nsamples. We experimentally verify that AgrLearn can result in significant\nimprovements when applied to several current deep learning architectures for\nimage recognition and text classification. We also empirically show that\nAgrLearn can reduce up to 80% of the training samples needed for ResNet\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:22:29 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 20:55:00 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 04:29:27 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Guo", "Hongyu", ""], ["Mao", "Yongyi", ""], ["Al-Bashabsheh", "Ali", ""], ["Zhang", "Richong", ""]]}, {"id": "1807.10261", "submitter": "Li Ying-Ying", "authors": "Jan Hajer, Ying-Ying Li, Tao Liu, He Wang", "title": "Novelty Detection Meets Collider Physics", "comments": "6 pages. 5 figures. Version for journal submission. Comments are\n  welcome", "journal-ref": "Phys. Rev. D 101, 076015 (2020)", "doi": "10.1103/PhysRevD.101.076015", "report-no": null, "categories": "hep-ph cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection is the machine learning task to recognize data, which\nbelong to an unknown pattern. Complementary to supervised learning, it allows\nto analyze data model-independently. We demonstrate the potential role of\nnovelty detection in collider physics, using autoencoder-based deep neural\nnetwork. Explicitly, we develop a set of density-based novelty evaluators,\nwhich are sensitive to the clustering of unknown-pattern testing data or\nnew-physics signal events, for the design of detection algorithms. We also\nexplore the influence of the known-pattern data fluctuations, arising from\nnon-signal regions, on detection sensitivity. Strategies to address it are\nproposed. The algorithms are applied to detecting fermionic di-top partner and\nresonant di-top productions at LHC, and exotic Higgs decays of two specific\nmodes at a $e^+e^-$ future collider. With parton-level analysis, we conclude\nthat potentially the new-physics benchmarks can be recognized with high\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:42:34 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 09:35:58 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Hajer", "Jan", ""], ["Li", "Ying-Ying", ""], ["Liu", "Tao", ""], ["Wang", "He", ""]]}, {"id": "1807.10262", "submitter": "Jiaming Xu", "authors": "Elchanan Mossel and Jiaming Xu", "title": "Seeded Graph Matching via Large Neighborhood Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a well known noisy model of the graph isomorphism problem. In this\nmodel, the goal is to perfectly recover the vertex correspondence between two\nedge-correlated Erd\\H{o}s-R\\'{e}nyi random graphs, with an initial seed set of\ncorrectly matched vertex pairs revealed as side information. For seeded\nproblems, our result provides a significant improvement over previously known\nresults. We show that it is possible to achieve the information-theoretic limit\nof graph sparsity in time polynomial in the number of vertices $n$. Moreover,\nwe show the number of seeds needed for exact recovery in polynomial-time can be\nas low as $n^{3\\epsilon}$ in the sparse graph regime (with the average degree\nsmaller than $n^{\\epsilon}$) and $\\Omega(\\log n)$ in the dense graph regime.\n  Our results also shed light on the unseeded problem. In particular, we give\nsub-exponential time algorithms for sparse models and an $n^{O(\\log n)}$\nalgorithm for dense models for some parameters, including some that are not\ncovered by recent results of Barak et al.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:44:00 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Mossel", "Elchanan", ""], ["Xu", "Jiaming", ""]]}, {"id": "1807.10268", "submitter": "Andrzej Kucik", "authors": "Andrzej Stanis{\\l}aw Kucik, Konstantin Korovin", "title": "Premise selection with neural networks and distributed representation of\n  features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the problem of selecting relevant premises for a proof of a given\nstatement. When stated as a binary classification task for pairs (conjecture,\naxiom), it can be efficiently solved using artificial neural networks. The key\ndifference between our advance to solve this problem and previous approaches is\nthe use of just functional signatures of premises. To further improve the\nperformance of the model, we use dimensionality reduction technique, to replace\nlong and sparse signature vectors with their compact and dense embedded\nversions. These are obtained by firstly defining the concept of a context for\neach functor symbol, and then training a simple neural network to predict the\ndistribution of other functor symbols in the context of this functor. After\ntraining the network, the output of its hidden layer is used to construct a\nlower dimensional embedding of a functional signature (for each premise) with a\ndistributed representation of features. This allows us to use 512-dimensional\nembeddings for conjecture-axiom pairs, containing enough information about the\noriginal statements to reach the accuracy of 76.45% in premise selection task,\nonly with simple two-layer densely connected neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:54:58 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kucik", "Andrzej Stanis\u0142aw", ""], ["Korovin", "Konstantin", ""]]}, {"id": "1807.10272", "submitter": "Anish Athalye", "authors": "Logan Engstrom, Andrew Ilyas, Anish Athalye", "title": "Evaluating and Understanding the Robustness of Adversarial Logit Pairing", "comments": "NeurIPS SECML 2018. Source code at\n  https://github.com/labsix/adversarial-logit-pairing-analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the robustness of Adversarial Logit Pairing, a recently proposed\ndefense against adversarial examples. We find that a network trained with\nAdversarial Logit Pairing achieves 0.6% accuracy in the threat model in which\nthe defense is considered. We provide a brief overview of the defense and the\nthreat models/claims considered, as well as a discussion of the methodology and\nresults of our attack, which may offer insights into the reasons underlying the\nvulnerability of ALP to adversarial attack.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:58:26 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 19:07:57 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Athalye", "Anish", ""]]}, {"id": "1807.10278", "submitter": "Hao Yan", "authors": "Hao Yan, Kamran Paynabar, Massimo Pacella", "title": "Structured Point Cloud Data Analysis via Regularized Tensor Regression\n  for Process Modeling and Optimization", "comments": "Technometrics, accepted", "journal-ref": "Technometrics 61.3 (2019): 385-395", "doi": "10.1080/00401706.2018.1529628", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced 3D metrology technologies such as Coordinate Measuring Machine (CMM)\nand laser 3D scanners have facilitated the collection of massive point cloud\ndata, beneficial for process monitoring, control and optimization. However, due\nto their high dimensionality and structure complexity, modeling and analysis of\npoint clouds are still a challenge. In this paper, we utilize multilinear\nalgebra techniques and propose a set of tensor regression approaches to model\nthe variational patterns of point clouds and to link them to process variables.\nThe performance of the proposed methods is evaluated through simulations and a\nreal case study of turning process optimization.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 02:57:49 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 15:46:11 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 08:33:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Yan", "Hao", ""], ["Paynabar", "Kamran", ""], ["Pacella", "Massimo", ""]]}, {"id": "1807.10300", "submitter": "Raban Iten", "authors": "Raban Iten, Tony Metger, Henrik Wilming, Lidia del Rio, Renato Renner", "title": "Discovering physical concepts with neural networks", "comments": "4 pages main text + 11 pages appendix, changes since v2: improved\n  references and presentation", "journal-ref": "Phys. Rev. Lett. 124, 010508 (2020)", "doi": "10.1103/PhysRevLett.124.010508", "report-no": null, "categories": "quant-ph cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of neural networks at solving concrete physics problems,\ntheir use as a general-purpose tool for scientific discovery is still in its\ninfancy. Here, we approach this problem by modelling a neural network\narchitecture after the human physical reasoning process, which has similarities\nto representation learning. This allows us to make progress towards the\nlong-term goal of machine-assisted scientific discovery from experimental data\nwithout making prior assumptions about the system. We apply this method to toy\nexamples and show that the network finds the physically relevant parameters,\nexploits conservation laws to make predictions, and can help to gain conceptual\ninsights, e.g. Copernicus' conclusion that the solar system is heliocentric.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 18:07:01 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 16:21:54 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 10:31:04 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Iten", "Raban", ""], ["Metger", "Tony", ""], ["Wilming", "Henrik", ""], ["del Rio", "Lidia", ""], ["Renner", "Renato", ""]]}, {"id": "1807.10328", "submitter": "Evan Greene", "authors": "Evan Greene, Greg Finak, Raphael Gottardo", "title": "Selective Clustering Annotated using Modes of Projections", "comments": "Submitted for journal review (JMLR) on July 21, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective clustering annotated using modes of projections (SCAMP) is a new\nclustering algorithm for data in $\\mathbb{R}^p$. SCAMP is motivated from the\npoint of view of non-parametric mixture modeling. Rather than maximizing a\nclassification likelihood to determine cluster assignments, SCAMP casts\nclustering as a search and selection problem. One consequence of this problem\nformulation is that the number of clusters is $\\textbf{not}$ a SCAMP tuning\nparameter. The search phase of SCAMP consists of finding sub-collections of the\ndata matrix, called candidate clusters, that obey shape constraints along each\ncoordinate projection. An extension of the dip test of Hartigan and Hartigan\n(1985) is developed to assist the search. Selection occurs by scoring each\ncandidate cluster with a preference function that quantifies prior belief about\nthe mixture composition. Clustering proceeds by selecting candidates to\nmaximize their total preference score. SCAMP concludes by annotating each\nselected cluster with labels that describe how cluster-level statistics compare\nto certain dataset-level quantities. SCAMP can be run multiple times on a\nsingle data matrix. Comparison of annotations obtained across iterations\nprovides a measure of clustering uncertainty. Simulation studies and\napplications to real data are considered. A C++ implementation with R interface\nis $\\href{https://github.com/RGLab/scamp}{available\\ online}$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 19:22:20 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Greene", "Evan", ""], ["Finak", "Greg", ""], ["Gottardo", "Raphael", ""]]}, {"id": "1807.10335", "submitter": "Siddharth Krishna Kumar", "authors": "Siddharth Krishna Kumar", "title": "A general metric for identifying adversarial images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that a determined adversary can fool a neural network by\nmaking imperceptible adversarial perturbations to an image. Recent studies have\nshown that these perturbations can be detected even without information about\nthe neural network if the strategy taken by the adversary is known beforehand.\nUnfortunately, these studies suffer from the generalization limitation -- the\ndetection method has to be recalibrated every time the adversary changes his\nstrategy. In this study, we attempt to overcome the generalization limitation\nby deriving a metric which reliably identifies adversarial images even when the\napproach taken by the adversary is unknown. Our metric leverages key\ndifferences between the spectra of clean and adversarial images when an image\nis treated as a matrix. Our metric is able to detect adversarial images across\ndifferent datasets and attack strategies without any additional re-calibration.\nIn addition, our approach provides geometric insights into several unanswered\nquestions about adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 19:29:37 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Kumar", "Siddharth Krishna", ""]]}, {"id": "1807.10363", "submitter": "Peter St. John PhD", "authors": "Peter C. St. John, Caleb Phillips, Travis W. Kemper, A. Nolan Wilson,\n  Michael F. Crowley, Mark R. Nimlos, Ross E. Larsen", "title": "Message-passing neural networks for high-throughput polymer screening", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": "10.1063/1.5099132", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have shown promise in predicting molecular\nproperties, and given sufficient training data machine learning approaches can\nenable rapid high-throughput virtual screening of large libraries of compounds.\nGraph-based neural network architectures have emerged in recent years as the\nmost successful approach for predictions based on molecular structure, and have\nconsistently achieved the best performance on benchmark quantum chemical\ndatasets. However, these models have typically required optimized 3D structural\ninformation for the molecule to achieve the highest accuracy. These 3D\ngeometries are costly to compute for high levels of theory, limiting the\napplicability and practicality of machine learning methods in high-throughput\nscreening applications. In this study, we present a new database of candidate\nmolecules for organic photovoltaic applications, comprising approximately\n91,000 unique chemical structures.Compared to existing datasets, this dataset\ncontains substantially larger molecules (up to 200 atoms) as well as\nextrapolated properties for long polymer chains. We show that message-passing\nneural networks trained with and without 3D structural information for these\nmolecules achieve similar accuracy, comparable to state-of-the-art methods on\nexisting benchmark datasets. These results therefore emphasize that for larger\nmolecules with practical applications, near-optimal prediction results can be\nobtained without using optimized 3D geometry as an input. We further show that\nlearned molecular representations can be leveraged to reduce the training data\nrequired to transfer predictions to a new DFT functional.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 20:53:42 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 23:14:40 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["John", "Peter C. St.", ""], ["Phillips", "Caleb", ""], ["Kemper", "Travis W.", ""], ["Wilson", "A. Nolan", ""], ["Crowley", "Michael F.", ""], ["Nimlos", "Mark R.", ""], ["Larsen", "Ross E.", ""]]}, {"id": "1807.10399", "submitter": "Murat Kocaoglu", "authors": "Murat Kocaoglu, Sanjay Shakkottai, Alexandros G. Dimakis, Constantine\n  Caramanis, Sriram Vishwanath", "title": "Applications of Common Entropy for Causal Inference", "comments": "In Proceedings of NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of discovering the simplest latent variable that can\nmake two observed discrete variables conditionally independent. The minimum\nentropy required for such a latent is known as common entropy in information\ntheory. We extend this notion to Renyi common entropy by minimizing the Renyi\nentropy of the latent variable. To efficiently compute common entropy, we\npropose an iterative algorithm that can be used to discover the trade-off\nbetween the entropy of the latent variable and the conditional mutual\ninformation of the observed variables. We show two applications of common\nentropy in causal inference: First, under the assumption that there are no\nlow-entropy mediators, it can be used to distinguish causation from spurious\ncorrelation among almost all joint distributions on simple causal graphs with\ntwo observed variables. Second, common entropy can be used to improve\nconstraint-based methods such as PC or FCI algorithms in the small-sample\nregime, where these methods are known to struggle. We propose a modification to\nthese constraint-based methods to assess if a separating set found by these\nalgorithms is valid using common entropy. We finally evaluate our algorithms on\nsynthetic and real data to establish their performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 23:30:09 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 21:20:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kocaoglu", "Murat", ""], ["Shakkottai", "Sanjay", ""], ["Dimakis", "Alexandros G.", ""], ["Caramanis", "Constantine", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1807.10422", "submitter": "Ding Zhao", "authors": "Wenshuo Wang, Weiyang Zhang, Ding Zhao", "title": "Understanding V2V Driving Scenarios through Traffic Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantically understanding complex drivers' encountering behavior, wherein\ntwo or multiple vehicles are spatially close to each other, does potentially\nbenefit autonomous car's decision-making design. This paper presents a\nframework of analyzing various encountering behaviors through decomposing\ndriving encounter data into small building blocks, called driving primitives,\nusing nonparametric Bayesian learning (NPBL) approaches, which offers a\nflexible way to gain an insight into the complex driving encounters without any\nprerequisite knowledge. The effectiveness of our proposed primitive-based\nframework is validated based on 976 naturalistic driving encounters, from which\nmore than 4000 driving primitives are learned using NPBL - a sticky HDP-HMM,\ncombined a hidden Markov model (HMM) with a hierarchical Dirichlet process\n(HDP). After that, a dynamic time warping method integrated with k-means\nclustering is then developed to cluster all these extracted driving primitives\ninto groups. Experimental results find that there exist 20 kinds of driving\nprimitives capable of representing the basic components of driving encounters\nin our database. This primitive-based analysis methodology potentially reveals\nunderlying information of vehicle-vehicle encounters for self-driving\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 03:29:41 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Wang", "Wenshuo", ""], ["Zhang", "Weiyang", ""], ["Zhao", "Ding", ""]]}, {"id": "1807.10444", "submitter": "Qiyu Kang", "authors": "Qiyu Kang, Wee Peng Tay", "title": "Task Recommendation in Crowdsourcing Based on Learning Preferences and\n  Reliabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Workers participating in a crowdsourcing platform can have a wide range of\nabilities and interests. An important problem in crowdsourcing is the task\nrecommendation problem, in which tasks that best match a particular worker's\npreferences and reliabilities are recommended to that worker. A task\nrecommendation scheme that assigns tasks more likely to be accepted by a worker\nwho is more likely to complete it reliably results in better performance for\nthe task requester. Without prior information about a worker, his preferences\nand reliabilities need to be learned over time. In this paper, we propose a\nmulti-armed bandit (MAB) framework to learn a worker's preferences and his\nreliabilities for different categories of tasks. However, unlike the classical\nMAB problem, the reward from the worker's completion of a task is unobservable.\nWe therefore include the use of gold tasks (i.e., tasks whose solutions are\nknown \\emph{a priori} and which do not produce any rewards) in our task\nrecommendation procedure. Our model could be viewed as a new variant of MAB, in\nwhich the random rewards can only be observed at those time steps where gold\ntasks are used, and the accuracy of estimating the expected reward of\nrecommending a task to a worker depends on the number of gold tasks used. We\nshow that the optimal regret is $O(\\sqrt{n})$, where $n$ is the number of tasks\nrecommended to the worker. We develop three task recommendation strategies to\ndetermine the number of gold tasks for different task categories, and show that\nthey are order optimal. Simulations verify the efficiency of our approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 05:46:38 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Kang", "Qiyu", ""], ["Tay", "Wee Peng", ""]]}, {"id": "1807.10454", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Cho-Jui Hsieh", "title": "Rob-GAN: Generator, Discriminator, and Adversarial Attacker", "comments": "CVPR'19 camera ready, project url:\n  https://github.com/xuanqing94/RobGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two important concepts in adversarial deep learning---adversarial\ntraining and generative adversarial network (GAN). Adversarial training is the\ntechnique used to improve the robustness of discriminator by combining\nadversarial attacker and discriminator in the training phase. GAN is commonly\nused for image generation by jointly optimizing discriminator and generator. We\nshow these two concepts are indeed closely related and can be used to\nstrengthen each other---adding a generator to the adversarial training\nprocedure can improve the robustness of discriminators, and adding an\nadversarial attack to GAN training can improve the convergence speed and lead\nto better generators. Combining these two insights, we develop a framework\ncalled Rob-GAN to jointly optimize generator and discriminator in the presence\nof adversarial attacks---the generator generates fake images to fool\ndiscriminator; the adversarial attacker perturbs real images to fool the\ndiscriminator, and the discriminator wants to minimize loss under fake and\nadversarial images. Through this end-to-end training procedure, we are able to\nsimultaneously improve the convergence speed of GAN training, the quality of\nsynthetic images, and the robustness of discriminator under strong adversarial\nattacks. Experimental results demonstrate that the obtained classifier is more\nrobust than the state-of-the-art adversarial training approach, and the\ngenerator outperforms SN-GAN on ImageNet-143.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 06:50:43 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 16:57:47 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 21:12:02 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1807.10455", "submitter": "Jun-Kun Wang", "authors": "Jun-Kun Wang and Jacob Abernethy", "title": "Acceleration through Optimistic No-Regret Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a smooth convex function by reducing\nthe optimization to computing the Nash equilibrium of a particular zero-sum\nconvex-concave game. Zero-sum games can be solved using online learning\ndynamics, where a classical technique involves simulating two no-regret\nalgorithms that play against each other and, after $T$ rounds, the average\niterate is guaranteed to solve the original optimization problem with error\ndecaying as $O(\\log T/T)$. In this paper we show that the technique can be\nenhanced to a rate of $O(1/T^2)$ by extending recent work \\cite{RS13,SALS15}\nthat leverages \\textit{optimistic learning} to speed up equilibrium\ncomputation. The resulting optimization algorithm derived from this analysis\ncoincides \\textit{exactly} with the well-known \\NA \\cite{N83a} method, and\nindeed the same story allows us to recover several variants of the Nesterov's\nalgorithm via small tweaks. We are also able to establish the accelerated\nlinear rate for a function which is both strongly-convex and smooth. This\nmethodology unifies a number of different iterative optimization methods: we\nshow that the \\HB algorithm is precisely the non-optimistic variant of \\NA, and\nrecent prior work already established a similar perspective on \\FW\n\\cite{AW17,ALLW18}.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 06:51:04 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 23:43:01 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 14:56:22 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Jun-Kun", ""], ["Abernethy", "Jacob", ""]]}, {"id": "1807.10458", "submitter": "Zhenghao Peng", "authors": "Zhenghao Peng, Xuyang Chen, Chengwen Xu, Naifeng Jing, Xiaoyao Liang,\n  Cewu Lu, Li Jiang", "title": "AXNet: ApproXimate computing using an end-to-end trainable neural\n  network", "comments": "Accepted by ICCAD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based approximate computing is a universal architecture\npromising to gain tremendous energy-efficiency for many error resilient\napplications. To guarantee the approximation quality, existing works deploy two\nneural networks (NNs), e.g., an approximator and a predictor. The approximator\nprovides the approximate results, while the predictor predicts whether the\ninput data is safe to approximate with the given quality requirement. However,\nit is non-trivial and time-consuming to make these two neural network\ncoordinate---they have different optimization objectives---by training them\nseparately. This paper proposes a novel neural network structure---AXNet---to\nfuse two NNs to a holistic end-to-end trainable NN. Leveraging the philosophy\nof multi-task learning, AXNet can tremendously improve the invocation\n(proportion of safe-to-approximate samples) and reduce the approximation error.\nThe training effort also decrease significantly. Experiment results show 50.7%\nmore invocation and substantial cuts of training time when compared to existing\nneural network based approximate computing framework.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 06:59:46 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 08:57:46 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Peng", "Zhenghao", ""], ["Chen", "Xuyang", ""], ["Xu", "Chengwen", ""], ["Jing", "Naifeng", ""], ["Liang", "Xiaoyao", ""], ["Lu", "Cewu", ""], ["Jiang", "Li", ""]]}, {"id": "1807.10478", "submitter": "Lorenzo Livi", "authors": "Andrea Ceni, Peter Ashwin, Lorenzo Livi", "title": "Interpreting recurrent neural networks behaviour via excitable network\n  attractors", "comments": "revised version", "journal-ref": null, "doi": "10.1007/s12559-019-09634-2", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction: Machine learning provides fundamental tools both for scientific\nresearch and for the development of technologies with significant impact on\nsociety. It provides methods that facilitate the discovery of regularities in\ndata and that give predictions without explicit knowledge of the rules\ngoverning a system. However, a price is paid for exploiting such flexibility:\nmachine learning methods are typically black-boxes where it is difficult to\nfully understand what the machine is doing or how it is operating. This poses\nconstraints on the applicability and explainability of such methods. Methods:\nOur research aims to open the black-box of recurrent neural networks, an\nimportant family of neural networks used for processing sequential data. We\npropose a novel methodology that provides a mechanistic interpretation of\nbehaviour when solving a computational task. Our methodology uses mathematical\nconstructs called excitable network attractors, which are invariant sets in\nphase space composed of stable attractors and excitable connections between\nthem. Results and Discussion: As the behaviour of recurrent neural networks\ndepends both on training and on inputs to the system, we introduce an algorithm\nto extract network attractors directly from the trajectory of a neural network\nwhile solving tasks. Simulations conducted on a controlled benchmark task\nconfirm the relevance of these attractors for interpreting the behaviour of\nrecurrent neural networks, at least for tasks that involve learning a finite\nnumber of stable states and transitions between them.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 08:02:45 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 10:02:41 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 16:24:50 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 11:38:47 GMT"}, {"version": "v5", "created": "Tue, 19 Feb 2019 16:21:30 GMT"}, {"version": "v6", "created": "Sun, 10 Mar 2019 09:35:27 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ceni", "Andrea", ""], ["Ashwin", "Peter", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1807.10487", "submitter": "Karthik Desingh", "authors": "Karthik Desingh, Anthony Opipari, Odest Chadwicke Jenkins", "title": "Pull Message Passing for Nonparametric Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a \"pull\" approach to approximate products of Gaussian mixtures\nwithin message updates for Nonparametric Belief Propagation (NBP) inference.\nExisting NBP methods often represent messages between continuous-valued latent\nvariables as Gaussian mixture models. To avoid computational intractability in\nloopy graphs, NBP necessitates an approximation of the product of such\nmixtures. Sampling-based product approximations have shown effectiveness for\nNBP inference. However, such approximations used within the traditional \"push\"\nmessage update procedures quickly become computationally prohibitive for\nmulti-modal distributions over high-dimensional variables. In contrast, we\npropose a \"pull\" method, as the Pull Message Passing for Nonparametric Belief\npropagation (PMPNBP) algorithm, and demonstrate its viability for efficient\ninference. We report results using an experiment from an existing NBP method,\nPAMPAS, for inferring the pose of an articulated structure in clutter. Results\nfrom this illustrative problem found PMPNBP has a greater ability to\nefficiently scale the number of components in its mixtures and, consequently,\nimprove inference accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 08:24:55 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Desingh", "Karthik", ""], ["Opipari", "Anthony", ""], ["Jenkins", "Odest Chadwicke", ""]]}, {"id": "1807.10494", "submitter": "Mohammad Mehdi Keikha", "authors": "Mohammad Mehdi Keikha, Maseud Rahgozar, Masoud Asadpour", "title": "DeepLink: A Novel Link Prediction Framework based on Deep Learning", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, link prediction has attracted more attentions from various\ndisciplines such as computer science, bioinformatics and economics. In this\nproblem, unknown links between nodes are discovered based on numerous\ninformation such as network topology, profile information and user generated\ncontents. Most of the previous researchers have focused on the structural\nfeatures of the networks. While the recent researches indicate that contextual\ninformation can change the network topology. Although, there are number of\nvaluable researches which combine structural and content information, but they\nface with the scalability issue due to feature engineering. Because, majority\nof the extracted features are obtained by a supervised or semi supervised\nalgorithm. Moreover, the existing features are not general enough to indicate\ngood performance on different networks with heterogeneous structures. Besides,\nmost of the previous researches are presented for undirected and unweighted\nnetworks. In this paper, a novel link prediction framework called \"DeepLink\" is\npresented based on deep learning techniques. In contrast to the previous\nresearches which fail to automatically extract best features for the link\nprediction, deep learning reduces the manual feature engineering. In this\nframework, both the structural and content information of the nodes are\nemployed. The framework can use different structural feature vectors, which are\nprepared by various link prediction methods. It considers all proximity orders\nthat are presented in a network during the structural feature learning. We have\nevaluated the performance of DeepLink on two real social network datasets\nincluding Telegram and irBlogs. On both datasets, the proposed framework\noutperforms several structural and hybrid approaches for link prediction\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 08:50:13 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Keikha", "Mohammad Mehdi", ""], ["Rahgozar", "Maseud", ""], ["Asadpour", "Masoud", ""]]}, {"id": "1807.10495", "submitter": "Nils Strodthoff", "authors": "Nils Strodthoff, Bar{\\i}\\c{s} G\\\"oktepe, Thomas Schierl, Cornelius\n  Hellge and Wojciech Samek", "title": "Enhanced Machine Learning Techniques for Early HARQ Feedback Prediction\n  in 5G", "comments": "14 pages, 15 figures; accepted version", "journal-ref": "IEEE JSAC 37 (2019), no. 11, 2573-2587", "doi": "10.1109/JSAC.2019.2934001", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Early Hybrid Automatic Repeat reQuest (E-HARQ) feedback\nschemes enhanced by machine learning techniques as a path towards\nultra-reliable and low-latency communication (URLLC). To this end, we propose\nmachine learning methods to predict the outcome of the decoding process ahead\nof the end of the transmission. We discuss different input features and\nclassification algorithms ranging from traditional methods to newly developed\nsupervised autoencoders. These methods are evaluated based on their prospects\nof complying with the URLLC requirements of effective block error rates below\n$10^{-5}$ at small latency overheads. We provide realistic performance\nestimates in a system model incorporating scheduling effects to demonstrate the\nfeasibility of E-HARQ across different signal-to-noise ratios, subcode lengths,\nchannel conditions and system loads, and show the benefit over regular HARQ and\nexisting E-HARQ schemes without machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 08:51:02 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 08:14:04 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Strodthoff", "Nils", ""], ["G\u00f6ktepe", "Bar\u0131\u015f", ""], ["Schierl", "Thomas", ""], ["Hellge", "Cornelius", ""], ["Samek", "Wojciech", ""]]}, {"id": "1807.10511", "submitter": "Asan Agibetov", "authors": "Asan Agibetov and Matthias Samwald", "title": "Global and local evaluation of link prediction tasks with neural\n  embeddings", "comments": "Accepted to 4th Semantic Deep Learning (SemDeep-4) Workshop at the\n  ISWC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus our attention on the link prediction problem for knowledge graphs,\nwhich is treated herein as a binary classification task on neural embeddings of\nthe entities. By comparing, combining and extending different methodologies for\nlink prediction on graph-based data coming from different domains, we formalize\na unified methodology for the quality evaluation benchmark of neural embeddings\nfor knowledge graphs. This benchmark is then used to empirically investigate\nthe potential of training neural embeddings globally for the entire graph, as\nopposed to the usual way of training embeddings locally for a specific\nrelation. This new way of testing the quality of the embeddings evaluates the\nperformance of binary classifiers for scalable link prediction with limited\ndata. Our evaluation pipeline is made open source, and with this we aim to draw\nmore attention of the community towards an important issue of transparency and\nreproducibility of the neural embeddings evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 09:45:04 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "1807.10565", "submitter": "Odysseas Zisimopoulos", "authors": "Odysseas Zisimopoulos, Evangello Flouty, Imanol Luengo, Petros\n  Giataganas, Jean Nehme, Andre Chow, and Danail Stoyanov", "title": "DeepPhase: Surgical Phase Recognition in CATARACTS Videos", "comments": "8 pages, 3 figures, 1 table, MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated surgical workflow analysis and understanding can assist surgeons to\nstandardize procedures and enhance post-surgical assessment and indexing, as\nwell as, interventional monitoring. Computer-assisted interventional (CAI)\nsystems based on video can perform workflow estimation through surgical\ninstruments' recognition while linking them to an ontology of procedural\nphases. In this work, we adopt a deep learning paradigm to detect surgical\ninstruments in cataract surgery videos which in turn feed a surgical phase\ninference recurrent network that encodes temporal aspects of phase steps within\nthe phase classification. Our models present comparable to state-of-the-art\nresults for surgical tool detection and phase recognition with accuracies of 99\nand 78% respectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 08:50:03 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Zisimopoulos", "Odysseas", ""], ["Flouty", "Evangello", ""], ["Luengo", "Imanol", ""], ["Giataganas", "Petros", ""], ["Nehme", "Jean", ""], ["Chow", "Andre", ""], ["Stoyanov", "Danail", ""]]}, {"id": "1807.10569", "submitter": "Gerald Friedland", "authors": "Gerald Friedland, Jingkang Wang, Ruoxi Jia, Bo Li", "title": "The Helmholtz Method: Using Perceptual Compression to Reduce Machine\n  Learning Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a fundamental answer to a frequently asked question in\nmultimedia computing and machine learning: Do artifacts from perceptual\ncompression contribute to error in the machine learning process and if so, how\nmuch? Our approach to the problem is a reinterpretation of the Helmholtz Free\nEnergy formula from physics to explain the relationship between content and\nnoise when using sensors (such as cameras or microphones) to capture multimedia\ndata. The reinterpretation allows a bit-measurement of the noise contained in\nimages, audio, and video by combining a classifier with perceptual compression,\nsuch as JPEG or MP3. Our experiments on CIFAR-10 as well as Fraunhofer's\nIDMT-SMT-Audio-Effects dataset indicate that, at the right quality level,\nperceptual compression is actually not harmful but contributes to a significant\nreduction of complexity of the machine learning process. That is, our noise\nquantification method can be used to speed up the training of deep learning\nclassifiers significantly while maintaining, or sometimes even improving,\noverall classification accuracy. Moreover, our results provide insights into\nthe reasons for the success of deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 01:49:50 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Friedland", "Gerald", ""], ["Wang", "Jingkang", ""], ["Jia", "Ruoxi", ""], ["Li", "Bo", ""]]}, {"id": "1807.10570", "submitter": "Pedram Ghazi", "authors": "Pedram Ghazi, Antti P. Happonen, Jani Boutellier, and Heikki Huttunen", "title": "Embedded Implementation of a Deep Learning Smile Detector", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the real time deployment of deep learning algorithms\nin low resource computational environments. As the use case, we compare the\naccuracy and speed of neural networks for smile detection using different\nneural network architectures and their system level implementation on NVidia\nJetson embedded platform. We also propose an asynchronous multithreading scheme\nfor parallelizing the pipeline. Within this framework, we experimentally\ncompare thirteen widely used network topologies. The experiments show that low\ncomplexity architectures can achieve almost equal performance as larger ones,\nwith a fraction of computation required.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 07:37:37 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ghazi", "Pedram", ""], ["Happonen", "Antti P.", ""], ["Boutellier", "Jani", ""], ["Huttunen", "Heikki", ""]]}, {"id": "1807.10571", "submitter": "Jun Cheng", "authors": "Jun Cheng", "title": "Sparse Range-constrained Learning and Its Application for Medical Image\n  Grading", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2018.2851607", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse learning has been shown to be effective in solving many real-world\nproblems. Finding sparse representations is a fundamentally important topic in\nmany fields of science including signal processing, computer vision, genome\nstudy and medical imaging. One important issue in applying sparse\nrepresentation is to find the basis to represent the data,especially in\ncomputer vision and medical imaging where the data is not necessary incoherent.\nIn medical imaging, clinicians often grade the severity or measure the risk\nscore of a disease based on images. This process is referred to as medical\nimage grading. Manual grading of the disease severity or risk score is often\nused. However, it is tedious, subjective and expensive. Sparse learning has\nbeen used for automatic grading of medical images for different diseases. In\nthe grading, we usually begin with one step to find a sparse representation of\nthe testing image using a set of reference images or atoms from the dictionary.\nThen in the second step, the selected atoms are used as references to compute\nthe grades of the testing images. Since the two steps are conducted\nsequentially, the objective function in the first step is not necessarily\noptimized for the second step. In this paper, we propose a novel sparse\nrange-constrained learning(SRCL)algorithm for medical image grading.Different\nfrom most of existing sparse learning algorithms, SRCL integrates the objective\nof finding a sparse representation and that of grading the image into one\nfunction. It aims to find a sparse representation of the testing image based on\natoms that are most similar in both the data or feature representation and the\nmedical grading scores. We apply the new proposed SRCL to CDR computation and\ncataract grading. Experimental results show that the proposed method is able to\nimprove the accuracy in cup-to-disc ratio computation and cataract grading.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 06:59:45 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Cheng", "Jun", ""]]}, {"id": "1807.10572", "submitter": "Hongyu Li", "authors": "Tianqi Han, Zhihui Fu, and Hongyu Li", "title": "Two-Layer Mixture Network Ensemble for Apparel Attributes Classification", "comments": "To be published in Proc. of AIFT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing apparel attributes has recently drawn great interest in the\ncomputer vision community. Methods based on various deep neural networks have\nbeen proposed for image classification, which could be applied to apparel\nattributes recognition. An interesting problem raised is how to ensemble these\nmethods to further improve the accuracy. In this paper, we propose a two-layer\nmixture framework for ensemble different networks. In the first layer of this\nframework, two types of ensemble learning methods, bagging and boosting, are\nseparately applied. Different from traditional methods, our bagging process\nmakes use of the whole training set, not random subsets, to train each model in\nthe ensemble, where several differentiated deep networks are used to promote\nmodel variance. To avoid the bias of small-scale samples, the second layer only\nadopts bagging to mix the results obtained with bagging and boosting in the\nfirst layer. Experimental results demonstrate that the proposed mixture\nframework outperforms any individual network model or either independent\nensemble method in apparel attributes classification.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 10:16:27 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Han", "Tianqi", ""], ["Fu", "Zhihui", ""], ["Li", "Hongyu", ""]]}, {"id": "1807.10573", "submitter": "Pan Wei", "authors": "Pan Wei, Lucas Cagle, Tasmia Reza, John Ball and James Gafford", "title": "LiDAR and Camera Detection Fusion in a Real Time Industrial Multi-Sensor\n  Collision Avoidance System", "comments": "34 pages", "journal-ref": "MDPI journal Electronics, 7(6), 84, May, 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision avoidance is a critical task in many applications, such as ADAS\n(advanced driver-assistance systems), industrial automation and robotics. In an\nindustrial automation setting, certain areas should be off limits to an\nautomated vehicle for protection of people and high-valued assets. These areas\ncan be quarantined by mapping (e.g., GPS) or via beacons that delineate a\nno-entry area. We propose a delineation method where the industrial vehicle\nutilizes a LiDAR {(Light Detection and Ranging)} and a single color camera to\ndetect passive beacons and model-predictive control to stop the vehicle from\nentering a restricted space. The beacons are standard orange traffic cones with\na highly reflective vertical pole attached. The LiDAR can readily detect these\nbeacons, but suffers from false positives due to other reflective surfaces such\nas worker safety vests. Herein, we put forth a method for reducing false\npositive detection from the LiDAR by projecting the beacons in the camera\nimagery via a deep learning method and validating the detection using a neural\nnetwork-learned projection from the camera to the LiDAR space. Experimental\ndata collected at Mississippi State University's Center for Advanced Vehicular\nSystems (CAVS) shows the effectiveness of the proposed system in keeping the\ntrue detection while mitigating false positives.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 16:55:09 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Wei", "Pan", ""], ["Cagle", "Lucas", ""], ["Reza", "Tasmia", ""], ["Ball", "John", ""], ["Gafford", "James", ""]]}, {"id": "1807.10574", "submitter": "Pan Wei", "authors": "John E. Ball, Pan Wei", "title": "Deep Learning Hyperspectral Image Classification Using Multiple\n  Class-based Denoising Autoencoders, Mixed Pixel Training Augmentation, and\n  Morphological Operations", "comments": null, "journal-ref": "IGARSS, June 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we present a system for hyperspectral image segmentation that\nutilizes multiple class--based denoising autoencoders which are efficiently\ntrained. Moreover, we present a novel hyperspectral data augmentation method\nfor labelled HSI data using linear mixtures of pixels from each class, which\nhelps the system with edge pixels which are almost always mixed pixels.\nFinally, we utilize a deep neural network and morphological hole-filling to\nprovide robust image classification. Results run on the Salinas dataset verify\nthe high performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 23:49:30 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ball", "John E.", ""], ["Wei", "Pan", ""]]}, {"id": "1807.10581", "submitter": "Heung-Il Suk", "authors": "Bum-Chae Kim, Jun-Sik Choi, Heung-Il Suk", "title": "Multi-Scale Gradual Integration CNN for False Positive Reduction in\n  Pulmonary Nodule Detection", "comments": "11 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is a global and dangerous disease, and its early detection is\ncrucial to reducing the risks of mortality. In this regard, it has been of\ngreat interest in developing a computer-aided system for pulmonary nodules\ndetection as early as possible on thoracic CT scans. In general, a nodule\ndetection system involves two steps: (i) candidate nodule detection at a high\nsensitivity, which captures many false positives and (ii) false positive\nreduction from candidates. However, due to the high variation of nodule\nmorphological characteristics and the possibility of mistaking them for\nneighboring organs, candidate nodule detection remains a challenge. In this\nstudy, we propose a novel Multi-scale Gradual Integration Convolutional Neural\nNetwork (MGI-CNN), designed with three main strategies: (1) to use multi-scale\ninputs with different levels of contextual information, (2) to use abstract\ninformation inherent in different input scales with gradual integration, and\n(3) to learn multi-stream feature integration in an end-to-end manner. To\nverify the efficacy of the proposed network, we conducted exhaustive\nexperiments on the LUNA16 challenge datasets by comparing the performance of\nthe proposed method with state-of-the-art methods in the literature. On two\ncandidate subsets of the LUNA16 dataset, i.e., V1 and V2, our method achieved\nan average CPM of 0.908 (V1) and 0.942 (V2), outperforming comparable methods\nby a large margin. Our MGI-CNN is implemented in Python using TensorFlow and\nthe source code is available from 'https://github.com/ku-milab/MGICNN.'\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 10:08:12 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Kim", "Bum-Chae", ""], ["Choi", "Jun-Sik", ""], ["Suk", "Heung-Il", ""]]}, {"id": "1807.10583", "submitter": "Bishesh Khanal", "authors": "Bishesh Khanal, Alberto Gomez, Nicolas Toussaint, Steven McDonagh,\n  Veronika Zimmer, Emily Skelton, Jacqueline Matthew, Daniel Grzech, Robert\n  Wright, Chandni Gupta, Benjamin Hou, Daniel Rueckert, Julia A.Schnabel, and\n  Bernhard Kainz", "title": "EchoFusion: Tracking and Reconstruction of Objects in 4D Freehand\n  Ultrasound Imaging without External Trackers", "comments": "MICCAI Workshop on Perinatal, Preterm and Paediatric Image analysis\n  (PIPPI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is the most widely used fetal imaging technique. However, US\nimages have limited capture range, and suffer from view dependent artefacts\nsuch as acoustic shadows. Compounding of overlapping 3D US acquisitions into a\nhigh-resolution volume can extend the field of view and remove image artefacts,\nwhich is useful for retrospective analysis including population based studies.\nHowever, such volume reconstructions require information about relative\ntransformations between probe positions from which the individual volumes were\nacquired. In prenatal US scans, the fetus can move independently from the\nmother, making external trackers such as electromagnetic or optical tracking\nunable to track the motion between probe position and the moving fetus. We\nprovide a novel methodology for image-based tracking and volume reconstruction\nby combining recent advances in deep learning and simultaneous localisation and\nmapping (SLAM). Tracking semantics are established through the use of a\nResidual 3D U-Net and the output is fed to the SLAM algorithm. As a proof of\nconcept, experiments are conducted on US volumes taken from a whole body fetal\nphantom, and from the heads of real fetuses. For the fetal head segmentation,\nwe also introduce a novel weak annotation approach to minimise the required\nmanual effort for ground truth annotation. We evaluate our method\nqualitatively, and quantitatively with respect to tissue discrimination\naccuracy and tracking robustness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 12:07:50 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Khanal", "Bishesh", ""], ["Gomez", "Alberto", ""], ["Toussaint", "Nicolas", ""], ["McDonagh", "Steven", ""], ["Zimmer", "Veronika", ""], ["Skelton", "Emily", ""], ["Matthew", "Jacqueline", ""], ["Grzech", "Daniel", ""], ["Wright", "Robert", ""], ["Gupta", "Chandni", ""], ["Hou", "Benjamin", ""], ["Rueckert", "Daniel", ""], ["Schnabel", "Julia A.", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1807.10584", "submitter": "Kristoffer Wickstr{\\o}m", "authors": "Kristoffer Wickstr{\\o}m, Michael Kampffmeyer and Robert Jenssen", "title": "Uncertainty and Interpretability in Convolutional Neural Networks for\n  Semantic Segmentation of Colorectal Polyps", "comments": "To appear in IEEE MLSP 2018", "journal-ref": null, "doi": "10.1016/j.media.2019.101619", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are propelling advances in a range of\ndifferent computer vision tasks such as object detection and object\nsegmentation. Their success has motivated research in applications of such\nmodels for medical image analysis. If CNN-based models are to be helpful in a\nmedical context, they need to be precise, interpretable, and uncertainty in\npredictions must be well understood. In this paper, we develop and evaluate\nrecent advances in uncertainty estimation and model interpretability in the\ncontext of semantic segmentation of polyps from colonoscopy images. We evaluate\nand enhance several architectures of Fully Convolutional Networks (FCNs) for\nsemantic segmentation of colorectal polyps and provide a comparison between\nthese models. Our highest performing model achieves a 76.06\\% mean IOU accuracy\non the EndoScene dataset, a considerable improvement over the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:01:01 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Wickstr\u00f8m", "Kristoffer", ""], ["Kampffmeyer", "Michael", ""], ["Jenssen", "Robert", ""]]}, {"id": "1807.10588", "submitter": "Mikael Agn", "authors": "Mikael Agn (1), Per Munck af Rosensch\\\"old (2), Oula Puonti (3),\n  Michael J. Lundemann (4), Laura Mancini (5 and 6), Anastasia Papadaki (5 and\n  6), Steffi Thust (5 and 6), John Ashburner (7), Ian Law (8), Koen Van Leemput\n  (1 and 9) ((1) Department of Applied Mathematics and Computer Science,\n  Technical University of Denmark, Denmark, (2) Radiation Physics, Department\n  of Hematology, Oncology and Radiation Physics, Sk{\\aa}ne University Hospital,\n  Lund, Sweden, (3) Danish Research Centre for Magnetic Resonance, Copenhagen\n  University Hospital Hvidovre, Denmark, (4) Department of Oncology, Copenhagen\n  University Hospital Rigshospitalet, Denmark, (5) Neuroradiological Academic\n  Unit, Department of Brain Repair and Rehabilitation, UCL Institute of\n  Neurology, University College London, UK, (6) Lysholm Department of\n  Neuroradiology, National Hospital for Neurology and Neurosurgery, UCLH NHS\n  Foundation Trust, UK, (7) Wellcome Centre for Human Neuroimaging, UCL\n  Institute of Neurology, University College London, UK, (8) Department of\n  Clinical Physiology, Nuclear Medicine and PET, Copenhagen University Hospital\n  Rigshospitalet, Denmark, (9) Athinoula A. Martinos Center for Biomedical\n  Imaging, Massachusetts General Hospital, Harvard Medical School, USA)", "title": "A Modality-Adaptive Method for Segmenting Brain Tumors and\n  Organs-at-Risk in Radiation Therapy Planning", "comments": "corrected one reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method for simultaneously segmenting brain tumors\nand an extensive set of organs-at-risk for radiation therapy planning of\nglioblastomas. The method combines a contrast-adaptive generative model for\nwhole-brain segmentation with a new spatial regularization model of tumor shape\nusing convolutional restricted Boltzmann machines. We demonstrate\nexperimentally that the method is able to adapt to image acquisitions that\ndiffer substantially from any available training data, ensuring its\napplicability across treatment sites; that its tumor segmentation accuracy is\ncomparable to that of the current state of the art; and that it captures most\norgans-at-risk sufficiently well for radiation therapy planning purposes. The\nproposed method may be a valuable step towards automating the delineation of\nbrain tumors and organs-at-risk in glioblastoma patients undergoing radiation\ntherapy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 20:16:00 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 19:41:38 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Agn", "Mikael", "", "5 and 6"], ["Rosensch\u00f6ld", "Per Munck af", "", "5 and 6"], ["Puonti", "Oula", "", "5 and 6"], ["Lundemann", "Michael J.", "", "5 and 6"], ["Mancini", "Laura", "", "5 and 6"], ["Papadaki", "Anastasia", "", "5 and\n  6"], ["Thust", "Steffi", "", "5 and 6"], ["Ashburner", "John", "", "1 and 9"], ["Law", "Ian", "", "1 and 9"], ["Van Leemput", "Koen", "", "1 and 9"]]}, {"id": "1807.10591", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov, Hugo Latapie, Enzo Fenoglio", "title": "Metric Embedding Autoencoders for Unsupervised Cross-Dataset Transfer\n  Learning", "comments": "ICANN 2018 (The 27th International Conference on Artificial Neural\n  Networks) proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-dataset transfer learning is an important problem in person\nre-identification (Re-ID). Unfortunately, not too many deep transfer Re-ID\nmodels exist for realistic settings of practical Re-ID systems. We propose a\npurely deep transfer Re-ID model consisting of a deep convolutional neural\nnetwork and an autoencoder. The latent code is divided into metric embedding\nand nuisance variables. We then utilize an unsupervised training method that\ndoes not rely on co-training with non-deep models. Our experiments show\nimprovements over both the baseline and competitors' transfer learning models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 09:59:34 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""], ["Latapie", "Hugo", ""], ["Fenoglio", "Enzo", ""]]}, {"id": "1807.10600", "submitter": "Yue Zhang", "authors": "Yue Zhang, Wanli Chen, Yifan Chen and Xiaoying Tang", "title": "A post-processing method to improve the white matter hyperintensity\n  segmentation accuracy for randomly-initialized U-net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  White matter hyperintensity (WMH) is commonly found in elder individuals and\nappears to be associated with brain diseases. U-net is a convolutional network\nthat has been widely used for biomedical image segmentation. Recently, U-net\nhas been successfully applied to WMH segmentation. Random initialization is\nusally used to initialize the model weights in the U-net. However, the model\nmay coverage to different local optima with different randomly initialized\nweights. We find a combination of thresholding and averaging the outputs of\nU-nets with different random initializations can largely improve the WMH\nsegmentation accuracy. Based on this observation, we propose a post-processing\ntechnique concerning the way how averaging and thresholding are conducted.\nSpecifically, we first transfer the score maps from three U-nets to binary\nmasks via thresholding and then average those binary masks to obtain the final\nWMH segmentation. Both quantitative analysis (via the Dice similarity\ncoefficient) and qualitative analysis (via visual examinations) reveal the\nsuperior performance of the proposed method. This post-processing technique is\nindependent of the model used. As such, it can also be applied to situations\nwhere other deep learning models are employed, especially when random\ninitialization is adopted and pre-training is unavailable.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 12:45:45 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Zhang", "Yue", ""], ["Chen", "Wanli", ""], ["Chen", "Yifan", ""], ["Tang", "Xiaoying", ""]]}, {"id": "1807.10602", "submitter": "Ramanarayan Mohanty", "authors": "Ramanarayan Mohanty, S L Happy, Nilesh Suthar, and Aurobinda Routray", "title": "A Trace Lasso Regularized L1-norm Graph Cut for Highly Correlated Noisy\n  Hyperspectral Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an adaptive trace lasso regularized L1-norm based graph\ncut method for dimensionality reduction of Hyperspectral images, called as\n`Trace Lasso-L1 Graph Cut' (TL-L1GC). The underlying idea of this method is to\ngenerate the optimal projection matrix by considering both the sparsity as well\nas the correlation of the data samples. The conventional L2-norm used in the\nobjective function is sensitive to noise and outliers. Therefore, in this work\nL1-norm is utilized as a robust alternative to L2-norm. Besides, for further\nimprovement of the results, we use a penalty function of trace lasso with the\nL1GC method. It adaptively balances the L2-norm and L1-norm simultaneously by\nconsidering the data correlation along with the sparsity. We obtain the optimal\nprojection matrix by maximizing the ratio of between-class dispersion to\nwithin-class dispersion using L1-norm with trace lasso as the penalty.\nFurthermore, an iterative procedure for this TL-L1GC method is proposed to\nsolve the optimization function. The effectiveness of this proposed method is\nevaluated on two benchmark HSI datasets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 07:44:56 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Mohanty", "Ramanarayan", ""], ["Happy", "S L", ""], ["Suthar", "Nilesh", ""], ["Routray", "Aurobinda", ""]]}, {"id": "1807.10623", "submitter": "Ashutosh Maurya", "authors": "Ashutosh K. Maurya", "title": "Learning low dimensional word based linear classifiers using Data Shared\n  Adaptive Bootstrap Aggregated Lasso with application to IMDb data", "comments": "arXiv admin note: text overlap with arXiv:1204.1177 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a new supervised ensemble learning method called\nData Shared Adaptive Bootstrap Aggregated (AdaBag) Lasso for capturing low\ndimensional useful features for word based sentiment analysis and mining\nproblems. The literature on ensemble methods is very rich in both statistics\nand machine learning. The algorithm is a substantial upgrade of the Data Shared\nLasso uplift algorithm. The most significant conceptual addition to the\nexisting literature lies in the final selection of bag of predictors through a\nspecial bootstrap aggregation scheme. We apply the algorithm to one simulated\ndata and perform dimension reduction in grouped IMDb data (drama, comedy and\nhorror) to extract reduced set of word features for predicting sentiment\nratings of movie reviews demonstrating different aspects. We also compare the\nperformance of the present method with the classical Principal Components with\nassociated Linear Discrimination (PCA-LD) as baseline. There are few\nlimitations in the algorithm. Firstly, the algorithm workflow does not\nincorporate online sequential data acquisition and it does not use sentence\nbased models which are common in ANN algorithms . Our results produce slightly\nhigher error rate compare to the reported state-of-the-art as a consequence.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:55:35 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 05:58:00 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Maurya", "Ashutosh K.", ""]]}, {"id": "1807.10629", "submitter": "Bastian Seifert", "authors": "Bastian Seifert, Katharina Korn, Steffen Hartmann, Christian Uhl", "title": "Dynamical Component Analysis (DyCA): Dimensionality Reduction For\n  High-Dimensional Deterministic Time-Series", "comments": "Published in Proc. 2018 IEEE INTERNATIONAL WORKSHOP ON MACHINE\n  LEARNING FOR SIGNAL PROCESSING; 7 figures; Corrected formula (16)", "journal-ref": null, "doi": "10.1109/MLSP.2018.8517024", "report-no": null, "categories": "eess.SP cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate signal processing is often based on dimensionality reduction\ntechniques. We propose a new method, Dynamical Component Analysis (DyCA),\nleading to a classification of the underlying dynamics and - for a certain type\nof dynamics - to a signal subspace representing the dynamics of the data. In\nthis paper the algorithm is derived leading to a generalized eigenvalue problem\nof correlation matrices. The application of the DyCA on high-dimensional\nchaotic signals is presented both for simulated data as well as real EEG data\nof epileptic seizures.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 10:57:39 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 09:38:09 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Seifert", "Bastian", ""], ["Korn", "Katharina", ""], ["Hartmann", "Steffen", ""], ["Uhl", "Christian", ""]]}, {"id": "1807.10643", "submitter": "Lucas Lamata", "authors": "Yongcheng Ding, Lucas Lamata, Mikel Sanz, Xi Chen, and Enrique Solano", "title": "Experimental Implementation of a Quantum Autoencoder via Quantum Adders", "comments": null, "journal-ref": "Advanced Quantum Technologies 1800065, 2019", "doi": "10.1002/qute.201800065", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum autoencoders allow for reducing the amount of resources in a quantum\ncomputation by mapping the original Hilbert space onto a reduced space with the\nrelevant information. Recently, it was proposed to employ approximate quantum\nadders to implement quantum autoencoders in quantum technologies. Here, we\ncarry out the experimental implementation of this proposal in the Rigetti cloud\nquantum computer employing up to three qubits. The experimental fidelities are\nin good agreement with the theoretical prediction, thus proving the feasibility\nto realize quantum autoencoders via quantum adders in state-of-the-art\nsuperconducting quantum technologies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 14:13:30 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 09:09:16 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Ding", "Yongcheng", ""], ["Lamata", "Lucas", ""], ["Sanz", "Mikel", ""], ["Chen", "Xi", ""], ["Solano", "Enrique", ""]]}, {"id": "1807.10668", "submitter": "Alexei Tsygvintsev", "authors": "Alexei Tsygvintsev", "title": "On the overfly algorithm in deep learning of neural networks", "comments": "To appear in Applied Mathematics and Computation", "journal-ref": "Applied Mathematics and Computation, Vol. 349, (2019), 348-358", "doi": "10.1016/j.amc.2018.12.055", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the supervised backpropagation training of\nmultilayer neural networks from a dynamical systems point of view. We discuss\nsome links with the qualitative theory of differential equations and introduce\nthe overfly algorithm to tackle the local minima problem. Our approach is based\non the existence of first integrals of the generalised gradient system with\nbuild-in dissipation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:06:26 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 12:28:26 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2018 15:05:34 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 21:07:14 GMT"}, {"version": "v5", "created": "Wed, 7 Nov 2018 15:56:07 GMT"}, {"version": "v6", "created": "Sat, 29 Dec 2018 09:57:19 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Tsygvintsev", "Alexei", ""]]}, {"id": "1807.10675", "submitter": "Sajawel Ahmed", "authors": "Sajawel Ahmed, Alexander Mehler", "title": "Resource-Size matters: Improving Neural Named Entity Recognition with\n  Optimized Large Corpora", "comments": "ICMLA 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study improves the performance of neural named entity recognition by a\nmargin of up to 11% in F-score on the example of a low-resource language like\nGerman, thereby outperforming existing baselines and establishing a new\nstate-of-the-art on each single open-source dataset. Rather than designing\ndeeper and wider hybrid neural architectures, we gather all available resources\nand perform a detailed optimization and grammar-dependent morphological\nprocessing consisting of lemmatization and part-of-speech tagging prior to\nexposing the raw data to any training process. We test our approach in a\nthreefold monolingual experimental setup of a) single, b) joint, and c)\noptimized training and shed light on the dependency of downstream-tasks on the\nsize of corpora used to compute word embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:05:20 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ahmed", "Sajawel", ""], ["Mehler", "Alexander", ""]]}, {"id": "1807.10680", "submitter": "Klaus Broelemann", "authors": "Klaus Broelemann, Gjergji Kasneci", "title": "Combining Restricted Boltzmann Machines with Neural Networks for Latent\n  Truth Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent truth discovery, LTD for short, refers to the problem of aggregating\nltiple claims from various sources in order to estimate the plausibility of\natements about entities. In the absence of a ground truth, this problem is\nhighly challenging, when some sources provide conflicting claims and others no\nclaims at all. In this work we provide an unsupervised stochastic inference\nprocedure on top of a model that combines restricted Boltzmann machines with\nfeed-forward neural networks to accurately infer the reliability of sources as\nwell as the plausibility of statements about entities. In comparison to prior\nwork our approach stands out (1) by allowing the incorporation of arbitrary\nfeatures about sources and claims, (2) by generalizing from reliability per\nsource towards a reliability function, and thus (3) enabling the estimation of\nsource reliability even for sources that have provided no or very few claims,\n(4) by building on efficient and scalable stochastic inference algorithms, and\n(5) by outperforming the state-of-the-art by a considerable margin.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:19:31 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Broelemann", "Klaus", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "1807.10681", "submitter": "Marina Sapir", "authors": "Marina Sapir", "title": "Learnable: Theory vs Applications", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two different views on machine learning problem: Applied learning (machine\nlearning with business applications) and Agnostic PAC learning are formalized\nand compared here. I show that, under some conditions, the theory of PAC\nLearnable provides a way to solve the Applied learning problem. However, the\ntheory requires to have the training sets so large, that it would make the\nlearning practically useless. I suggest shedding some theoretical\nmisconceptions about learning to make the theory more aligned with the needs\nand experience of practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:21:43 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Sapir", "Marina", ""]]}, {"id": "1807.10693", "submitter": "Zhanyu Ma", "authors": "Zhanyu Ma and Yuping Lai", "title": "Infinite Mixture of Inverted Dirichlet Distributions", "comments": "Technical Report of ongoing work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a novel Bayesian estimation method for the Dirichlet\nprocess (DP) mixture of the inverted Dirichlet distributions, which has been\nshown to be very flexible for modeling vectors with positive elements. The\nrecently proposed extended variational inference (EVI) framework is adopted to\nderive an analytically tractable solution. The convergency of the proposed\nalgorithm is theoretically guaranteed by introducing single lower bound\napproximation to the original objective function in the VI framework. In\nprinciple, the proposed model can be viewed as an infinite inverted Dirichelt\nmixture model (InIDMM) that allows the automatic determination of the number of\nmixture components from data. Therefore, the problem of pre-determining the\noptimal number of mixing components has been overcome. Moreover, the problems\nof over-fitting and under-fitting are avoided by the Bayesian estimation\napproach. Comparing with several recently proposed DP-related methods, the good\nperformance and effectiveness of the proposed method have been demonstrated\nwith both synthesized data and real data evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:43:04 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 09:49:04 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ma", "Zhanyu", ""], ["Lai", "Yuping", ""]]}, {"id": "1807.10695", "submitter": "Ruolong Lian", "authors": "Jin Hee Kim, Brett Grady, Ruolong Lian, John Brothers, Jason H.\n  Anderson", "title": "FPGA-Based CNN Inference Accelerator Synthesized from Multi-Threaded C\n  Software", "comments": null, "journal-ref": "J. H. Kim, B. Grady, R. Lian, J. Brothers and J. H. Anderson,\n  \"FPGA-based CNN inference accelerator synthesized from multi-threaded C\n  software,\" 2017 30th IEEE International System-on-Chip Conference (SOCC),\n  Munich, 2017, pp. 268-273", "doi": "10.1109/SOCC.2017.8226056", "report-no": null, "categories": "cs.LG cs.AR cs.PF cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep-learning inference accelerator is synthesized from a C-language\nsoftware program parallelized with Pthreads. The software implementation uses\nthe well-known producer/consumer model with parallel threads interconnected by\nFIFO queues. The LegUp high-level synthesis (HLS) tool synthesizes threads into\nparallel FPGA hardware, translating software parallelism into spatial\nparallelism. A complete system is generated where convolution, pooling and\npadding are realized in the synthesized accelerator, with remaining tasks\nexecuting on an embedded ARM processor. The accelerator incorporates reduced\nprecision, and a novel approach for zero-weight-skipping in convolution. On a\nmid-sized Intel Arria 10 SoC FPGA, peak performance on VGG-16 is 138 effective\nGOPS.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:46:16 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Kim", "Jin Hee", ""], ["Grady", "Brett", ""], ["Lian", "Ruolong", ""], ["Brothers", "John", ""], ["Anderson", "Jason H.", ""]]}, {"id": "1807.10707", "submitter": "Yihan Li", "authors": "Igor Gotlibovych, Stuart Crawford, Dileep Goyal, Jiaqi Liu, Yaniv\n  Kerem, David Benaron, Defne Yilmaz, Gregory Marcus, Yihan Li", "title": "End-to-end Deep Learning from Raw Sensor Data: Atrial Fibrillation\n  Detection using Wearables", "comments": "7 pages, 5 figures, KDD 2018 Deep Learning Day accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convolutional-recurrent neural network architecture with long\nshort-term memory for real-time processing and classification of digital sensor\ndata. The network implicitly performs typical signal processing tasks such as\nfiltering and peak detection, and learns time-resolved embeddings of the input\nsignal. We use a prototype multi-sensor wearable device to collect over 180h of\nphotoplethysmography (PPG) data sampled at 20Hz, of which 36h are during atrial\nfibrillation (AFib). We use end-to-end learning to achieve state-of-the-art\nresults in detecting AFib from raw PPG data. For classification labels output\nevery 0.8s, we demonstrate an area under ROC curve of 0.9999, with false\npositive and false negative rates both below $2\\times 10^{-3}$. This\nconstitutes a significant improvement on previous results utilising\ndomain-specific feature engineering, such as heart rate extraction, and brings\nlarge-scale atrial fibrillation screenings within imminent reach.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 16:17:31 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Gotlibovych", "Igor", ""], ["Crawford", "Stuart", ""], ["Goyal", "Dileep", ""], ["Liu", "Jiaqi", ""], ["Kerem", "Yaniv", ""], ["Benaron", "David", ""], ["Yilmaz", "Defne", ""], ["Marcus", "Gregory", ""], ["Li", "Yihan", ""]]}, {"id": "1807.10728", "submitter": "Dmitry Kopitkov", "authors": "Dmitry Kopitkov and Vadim Indelman", "title": "Deep PDF: Probabilistic Surface Optimization and Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probability density function (pdf) encodes the entire stochastic knowledge\nabout data distribution, where data may represent stochastic observations in\nrobotics, transition state pairs in reinforcement learning or any other\nempirically acquired modality. Inferring data pdf is of prime importance,\nallowing to analyze various model hypotheses and perform smart decision making.\nHowever, most density estimation techniques are limited in their representation\nexpressiveness to specific kernel type or predetermined distribution family,\nand have other restrictions. For example, kernel density estimation (KDE)\nmethods require meticulous parameter search and are extremely slow at querying\nnew points. In this paper we present a novel non-parametric density estimation\napproach, DeepPDF, that uses a neural network to approximate a target pdf given\nsamples from thereof. Such a representation provides high inference accuracy\nfor a wide range of target pdfs using a relatively simple network structure,\nmaking our method highly statistically robust. This is done via a new\nstochastic optimization algorithm, \\emph{Probabilistic Surface Optimization}\n(PSO), that turns to advantage the stochastic nature of sample points in order\nto force network output to be identical to the output of a target pdf. Once\ntrained, query point evaluation can be efficiently done in DeepPDF by a simple\nnetwork forward pass, with linear complexity in the number of query points.\nMoreover, the PSO algorithm is capable of inferring the frequency of data\nsamples and may also be used in other statistical tasks such as conditional\nestimation and distribution transformation. We compare the derived approach\nwith KDE methods showing its superior performance and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 16:55:33 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 11:20:58 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Kopitkov", "Dmitry", ""], ["Indelman", "Vadim", ""]]}, {"id": "1807.10752", "submitter": "John Shin", "authors": "Sky C. Cheung, John Y. Shin, Yenson Lau, Zhengyu Chen, Ju Sun, Yuqian\n  Zhang, John N. Wright, Abhay N. Pasupathy", "title": "Dictionary Learning in Fourier Transform Scanning Tunneling Spectroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern high-resolution microscopes, such as the scanning tunneling\nmicroscope, are commonly used to study specimens that have dense and aperiodic\nspatial structure. Extracting meaningful information from images obtained from\nsuch microscopes remains a formidable challenge. Fourier analysis is commonly\nused to analyze the underlying structure of fundamental motifs present in an\nimage. However, the Fourier transform fundamentally suffers from severe phase\nnoise when applied to aperiodic images. Here, we report the development of a\nnew algorithm based on nonconvex optimization, applicable to any microscopy\nmodality, that directly uncovers the fundamental motifs present in a real-space\nimage. Apart from being quantitatively superior to traditional Fourier\nanalysis, we show that this novel algorithm also uncovers phase sensitive\ninformation about the underlying motif structure. We demonstrate its usefulness\nby studying scanning tunneling microscopy images of a Co-doped iron arsenide\nsuperconductor and prove that the application of the algorithm allows for the\ncomplete recovery of quasiparticle interference in this material. Our phase\nsensitive quasiparticle interference imaging results indicate that the pairing\nsymmetry in optimally doped NaFeAs is consistent with a sign-changing s+- order\nparameter.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 20:56:26 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Cheung", "Sky C.", ""], ["Shin", "John Y.", ""], ["Lau", "Yenson", ""], ["Chen", "Zhengyu", ""], ["Sun", "Ju", ""], ["Zhang", "Yuqian", ""], ["Wright", "John N.", ""], ["Pasupathy", "Abhay N.", ""]]}, {"id": "1807.10755", "submitter": "Victor Lorena De Farias Souza", "authors": "Victor L. F. Souza, Adriano L. I. Oliveira, and Robert Sabourin", "title": "A writer-independent approach for offline signature verification using\n  deep convolutional neural networks features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of features extracted using a deep convolutional neural network (CNN)\ncombined with a writer-dependent (WD) SVM classifier resulted in significant\nimprovement in performance of handwritten signature verification (HSV) when\ncompared to the previous state-of-the-art methods. In this work it is\ninvestigated whether the use of these CNN features provide good results in a\nwriter-independent (WI) HSV context, based on the dichotomy transformation\ncombined with the use of an SVM writer-independent classifier. The experiments\nperformed in the Brazilian and GPDS datasets show that (i) the proposed\napproach outperformed other WI-HSV methods from the literature, (ii) in the\nglobal threshold scenario, the proposed approach was able to outperform the\nwriter-dependent method with CNN features in the Brazilian dataset, (iii) in an\nuser threshold scenario, the results are similar to those obtained by the\nwriter-dependent method with CNN features.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 22:09:45 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Souza", "Victor L. F.", ""], ["Oliveira", "Adriano L. I.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1807.10756", "submitter": "Woochan Hwang", "authors": "Sejin Park, Woochan Hwang, Kyu Hwan Jung, Joon Beom Seo, Namkug Kim", "title": "False Positive Reduction by Actively Mining Negative Samples for\n  Pulmonary Nodule Detection in Chest Radiographs", "comments": "Presented at the 2nd SIIM C-MIMI(SIIM Conference on Machine\n  Intelligence in Medical Imaging)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating large quantities of quality labeled data in medical imaging is\nvery time consuming and expensive. The performance of supervised algorithms for\nvarious tasks on imaging has improved drastically over the years, however the\navailability of data to train these algorithms have become one of the main\nbottlenecks for implementation. To address this, we propose a semi-supervised\nlearning method where pseudo-negative labels from unlabeled data are used to\nfurther refine the performance of a pulmonary nodule detection network in chest\nradiographs. After training with the proposed network, the false positive rate\nwas reduced to 0.1266 from 0.4864 while maintaining sensitivity at 0.89.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 23:29:39 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Park", "Sejin", ""], ["Hwang", "Woochan", ""], ["Jung", "Kyu Hwan", ""], ["Seo", "Joon Beom", ""], ["Kim", "Namkug", ""]]}, {"id": "1807.10787", "submitter": "Yi Ren", "authors": "Ruijin Cang, Hope Yao, Yi Ren", "title": "One-Shot Generation of Near-Optimal Topology through Theory-Driven\n  Machine Learning", "comments": "accepted to Computer-Aided Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theory-driven mechanism for learning a neural network model\nthat performs generative topology design in one shot given a problem setting,\ncircumventing the conventional iterative process that computational design\ntasks usually entail. The proposed mechanism can lead to machines that quickly\nresponse to new design requirements based on its knowledge accumulated through\npast experiences of design generation. Achieving such a mechanism through\nsupervised learning would require an impractically large amount of\nproblem-solution pairs for training, due to the known limitation of deep neural\nnetworks in knowledge generalization. To this end, we introduce an interaction\nbetween a student (the neural network) and a teacher (the optimality conditions\nunderlying topology optimization): The student learns from existing data and is\ntested on unseen problems. Deviation of the student's solutions from the\noptimality conditions is quantified, and used for choosing new data points to\nlearn from. We call this learning mechanism \"theory-driven\", as it explicitly\nuses domain-specific theories to guide the learning, thus distinguishing itself\nfrom purely data-driven supervised learning. We show through a compliance\nminimization problem that the proposed learning mechanism leads to topology\ngeneration with near-optimal structural compliance, much improved from standard\nsupervised learning under the same computational budget.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 18:36:06 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 22:19:00 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 21:24:24 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Cang", "Ruijin", ""], ["Yao", "Hope", ""], ["Ren", "Yi", ""]]}, {"id": "1807.10805", "submitter": "Mahtab Ahmed", "authors": "Mahtab Ahmed, Muhammad Rifayat Samee, Robert E. Mercer", "title": "Improving Neural Sequence Labelling using Additional Linguistic\n  Information", "comments": "9 pages, 1 figure, Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sequence labelling is the task of assigning categorical labels to a data\nsequence. In Natural Language Processing, sequence labelling can be applied to\nvarious fundamental problems, such as Part of Speech (POS) tagging, Named\nEntity Recognition (NER), and Chunking. In this study, we propose a method to\nadd various linguistic features to the neural sequence framework to improve\nsequence labelling. Besides word level knowledge, sense embeddings are added to\nprovide semantic information. Additionally, selective readings of character\nembeddings are added to capture contextual as well as morphological features\nfor each word in a sentence. Compared to previous methods, these added\nlinguistic features allow us to design a more concise model and perform more\nefficient training. Our proposed architecture achieves state of the art results\non the benchmark datasets of POS, NER, and chunking. Moreover, the convergence\nrate of our model is significantly better than the previous state of the art\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 19:07:33 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Ahmed", "Mahtab", ""], ["Samee", "Muhammad Rifayat", ""], ["Mercer", "Robert E.", ""]]}, {"id": "1807.10831", "submitter": "Kamlesh Pawar", "authors": "Kamlesh Pawar, Zhaolin Chen, N. Jon Shah, and Gary F. Egan", "title": "MoCoNet: Motion Correction in 3D MPRAGE images using a Convolutional\n  Neural Network approach", "comments": null, "journal-ref": null, "doi": "10.1002/nbm.4225", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: The suppression of motion artefacts from MR images is a challenging\ntask. The purpose of this paper is to develop a standalone novel technique to\nsuppress motion artefacts from MR images using a data-driven deep learning\napproach. Methods: A deep learning convolutional neural network (CNN) was\ndeveloped to remove motion artefacts in brain MR images. A CNN was trained on\nsimulated motion corrupted images to identify and suppress artefacts due to the\nmotion. The network was an encoder-decoder CNN architecture where the encoder\ndecomposed the motion corrupted images into a set of feature maps. The feature\nmaps were then combined by the decoder network to generate a motion-corrected\nimage. The network was tested on an unseen simulated dataset and an\nexperimental, motion corrupted in vivo brain dataset. Results: The trained\nnetwork was able to suppress the motion artefacts in the simulated motion\ncorrupted images, and the mean percentage error in the motion corrected images\nwas 2.69 % with a standard deviation of 0.95 %. The network was able to\neffectively suppress the motion artefacts from the experimental dataset,\ndemonstrating the generalisation capability of the trained network. Conclusion:\nA novel and generic motion correction technique has been developed that can\nsuppress motion artefacts from motion corrupted MR images. The proposed\ntechnique is a standalone post-processing method that does not interfere with\ndata acquisition or reconstruction parameters, thus making it suitable for a\nmultitude of MR sequences.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:24:54 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Pawar", "Kamlesh", ""], ["Chen", "Zhaolin", ""], ["Shah", "N. Jon", ""], ["Egan", "Gary F.", ""]]}, {"id": "1807.10875", "submitter": "Augustus Odena", "authors": "Augustus Odena, Ian Goodfellow", "title": "TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing", "comments": "Preprint - work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are notoriously difficult to interpret and debug.\nThis is particularly true of neural networks. In this work, we introduce\nautomated software testing techniques for neural networks that are well-suited\nto discovering errors which occur only for rare inputs. Specifically, we\ndevelop coverage-guided fuzzing (CGF) methods for neural networks. In CGF,\nrandom mutations of inputs to a neural network are guided by a coverage metric\ntoward the goal of satisfying user-specified constraints. We describe how fast\napproximate nearest neighbor algorithms can provide this coverage metric. We\nthen discuss the application of CGF to the following goals: finding numerical\nerrors in trained neural networks, generating disagreements between neural\nnetworks and quantized versions of those networks, and surfacing undesirable\nbehavior in character level language models. Finally, we release an open source\nlibrary called TensorFuzz that implements the described techniques.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 02:11:40 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Odena", "Augustus", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1807.10876", "submitter": "Mohammad Etemad", "authors": "Mohammad Etemad", "title": "Transportation Modes Classification Using Feature Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting transportation modes from GPS (Global Positioning System) records\nis a hot topic in the trajectory mining domain. Each GPS record is called a\ntrajectory point and a trajectory is a sequence of these points. Trajectory\nmining has applications including but not limited to transportation mode\ndetection, tourism, traffic congestion, smart cities management, animal\nbehaviour analysis, environmental preservation, and traffic dynamics are some\nof the trajectory mining applications. Transportation modes prediction as one\nof the tasks in human mobility and vehicle mobility applications plays an\nimportant role in resource allocation, traffic management systems, tourism\nplanning and accident detection. In this work, the proposed framework in Etemad\net al. is extended to consider other aspects in the task of transportation\nmodes prediction. Wrapper search and information retrieval methods were\ninvestigated to find the best subset of trajectory features. Finding the best\nclassifier and the best feature subset, the framework is compared against two\nrelated papers that applied deep learning methods. The results show that our\nframework achieved better performance. Moreover, the ground truth noise removal\nimproved accuracy of transportation modes prediction task; however, the\nassumption of having access to test set labels in pre-processing task is\ninvalid. Furthermore, the cross validation approaches were investigated and the\nperformance results show that the random cross validation method provides\noptimistic results.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 02:38:35 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Etemad", "Mohammad", ""]]}, {"id": "1807.10934", "submitter": "Leye Wang", "authors": "Di Chai, Leye Wang, Qiang Yang", "title": "Bike Flow Prediction with Multi-Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fundamental issue in managing bike sharing systems is the bike flow\nprediction. Due to the hardness of predicting the flow for a single station,\nrecent research works often predict the bike flow at cluster-level. While such\nstudies gain satisfactory prediction accuracy, they cannot directly guide some\nfine-grained bike sharing system management issues at station-level. In this\npaper, we revisit the problem of the station-level bike flow prediction, aiming\nto boost the prediction accuracy leveraging the breakthroughs of deep learning\ntechniques. We propose a new multi-graph convolutional neural network model to\npredict the bike flow at station-level, where the key novelty is viewing the\nbike sharing system from the graph perspective. More specifically, we construct\nmultiple inter-station graphs for a bike sharing system. In each graph, nodes\nare stations, and edges are a certain type of relations between stations. Then,\nmultiple graphs are constructed to reflect heterogeneous relationships (e.g.,\ndistance, ride record correlation). Afterward, we fuse the multiple graphs and\nthen apply the convolutional layers on the fused graph to predict station-level\nfuture bike flow. In addition to the estimated bike flow value, our model also\ngives the prediction confidence interval so as to help the bike sharing system\nmanagers make decisions. Using New York City and Chicago bike sharing data for\nexperiments, our model can outperform state-of-the-art station-level prediction\nmodels by reducing 25.1% and 17.0% of prediction error in New York City and\nChicago, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 13:35:37 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chai", "Di", ""], ["Wang", "Leye", ""], ["Yang", "Qiang", ""]]}, {"id": "1807.10956", "submitter": "Shihua Zhang", "authors": "Wenwen Min, Juan Liu, Shihua Zhang", "title": "Group-sparse SVD Models and Their Applications in Biological Data", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Singular Value Decomposition (SVD) models have been proposed for\nbiclustering high dimensional gene expression data to identify block patterns\nwith similar expressions. However, these models do not take into account prior\ngroup effects upon variable selection. To this end, we first propose\ngroup-sparse SVD models with group Lasso (GL1-SVD) and group L0-norm penalty\n(GL0-SVD) for non-overlapping group structure of variables. However, such\ngroup-sparse SVD models limit their applicability in some problems with\noverlapping structure. Thus, we also propose two group-sparse SVD models with\noverlapping group Lasso (OGL1-SVD) and overlapping group L0-norm penalty\n(OGL0-SVD). We first adopt an alternating iterative strategy to solve GL1-SVD\nbased on a block coordinate descent method, and GL0-SVD based on a projection\nmethod. The key of solving OGL1-SVD is a proximal operator with overlapping\ngroup Lasso penalty. We employ an alternating direction method of multipliers\n(ADMM) to solve the proximal operator. Similarly, we develop an approximate\nmethod to solve OGL0-SVD. Applications of these methods and comparison with\ncompeting ones using simulated data demonstrate their effectiveness. Extensive\napplications of them onto several real gene expression data with gene prior\ngroup knowledge identify some biologically interpretable gene modules.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 16:13:14 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Min", "Wenwen", ""], ["Liu", "Juan", ""], ["Zhang", "Shihua", ""]]}, {"id": "1807.10957", "submitter": "Aidean Sharghi", "authors": "Aidean Sharghi, Ali Borji, Chengtao Li, Tianbao Yang, Boqing Gong", "title": "Improving Sequential Determinantal Point Processes for Supervised Video\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now much easier than ever before to produce videos. While the\nubiquitous video data is a great source for information discovery and\nextraction, the computational challenges are unparalleled. Automatically\nsummarizing the videos has become a substantial need for browsing, searching,\nand indexing visual content. This paper is in the vein of supervised video\nsummarization using sequential determinantal point process (SeqDPP), which\nmodels diversity by a probabilistic distribution. We improve this model in two\nfolds. In terms of learning, we propose a large-margin algorithm to address the\nexposure bias problem in SeqDPP. In terms of modeling, we design a new\nprobabilistic distribution such that, when it is integrated into SeqDPP, the\nresulting model accepts user input about the expected length of the summary.\nMoreover, we also significantly extend a popular video summarization dataset by\n1) more egocentric videos, 2) dense user annotations, and 3) a refined\nevaluation scheme. We conduct extensive experiments on this dataset (about 60\nhours of videos in total) and compare our approach to several competitive\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 16:24:15 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 23:49:25 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Sharghi", "Aidean", ""], ["Borji", "Ali", ""], ["Li", "Chengtao", ""], ["Yang", "Tianbao", ""], ["Gong", "Boqing", ""]]}, {"id": "1807.10997", "submitter": "Hanchen Xu", "authors": "Hanchen Xu and Alejandro D. Dom\\'inguez-Garc\\'ia and Peter W. Sauer", "title": "Optimal Tap Setting of Voltage Regulation Transformers Using Batch\n  Reinforcement Learning", "comments": null, "journal-ref": "in IEEE Transactions on Power Systems, vol. 35, no. 3, pp.\n  1990-2001, May 2020", "doi": "10.1109/TPWRS.2019.2948132", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of setting the tap positions of load\ntap changers (LTCs) for voltage regulation in radial power distribution systems\nunder uncertain load dynamics. The objective is to find a policy to determine\nthe tap positions that only uses measurements of voltage magnitudes and\ntopology information so as to minimize the voltage deviation across the system.\nWe formulate this problem as a Markov decision process (MDP), and propose a\nbatch reinforcement learning (RL) algorithm to solve it. By taking advantage of\na linearized power flow model, we propose an effective algorithm to estimate\nthe voltage magnitudes under different tap settings, which allows the RL\nalgorithm to explore the state and action spaces freely offline without\nimpacting the system operation. To circumvent the \"curse of dimensionality\"\nresulted from the large state and action spaces, we propose a sequential\nlearning algorithm to learn an action-value function for each LTC, based on\nwhich the optimal tap positions can be directly determined. The effectiveness\nof the proposed algorithm is validated via numerical simulations on the IEEE\n13-bus and 123-bus distribution test feeders.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 03:40:09 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 00:14:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Xu", "Hanchen", ""], ["Dom\u00ednguez-Garc\u00eda", "Alejandro D.", ""], ["Sauer", "Peter W.", ""]]}, {"id": "1807.11014", "submitter": "Qianqian Xu", "authors": "Qianqian Xu, Jiechao Xiong, Xinwei Sun, Zhiyong Yang, Xiaochun Cao,\n  Qingming Huang, and Yuan Yao", "title": "A Margin-based MLE for Crowdsourced Partial Ranking", "comments": "9 pages, Accepted by ACM Multimedia 2018 as a full paper", "journal-ref": null, "doi": "10.1145/3240508.3240597", "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A preference order or ranking aggregated from pairwise comparison data is\ncommonly understood as a strict total order. However, in real-world scenarios,\nsome items are intrinsically ambiguous in comparisons, which may very well be\nan inherent uncertainty of the data. In this case, the conventional total order\nranking can not capture such uncertainty with mere global ranking or utility\nscores. In this paper, we are specifically interested in the recent surge in\ncrowdsourcing applications to predict partial but more accurate (i.e., making\nless incorrect statements) orders rather than complete ones. To do so, we\npropose a novel framework to learn some probabilistic models of partial orders\nas a \\emph{margin-based Maximum Likelihood Estimate} (MLE) method. We prove\nthat the induced MLE is a joint convex optimization problem with respect to all\nthe parameters, including the global ranking scores and margin parameter.\nMoreover, three kinds of generalized linear models are studied, including the\nbasic uniform model, Bradley-Terry model, and Thurstone-Mosteller model,\nequipped with some theoretical analysis on FDR and Power control for the\nproposed methods. The validity of these models are supported by experiments\nwith both simulated and real-world datasets, which shows that the proposed\nmodels exhibit improvements compared with traditional state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 07:09:00 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Xu", "Qianqian", ""], ["Xiong", "Jiechao", ""], ["Sun", "Xinwei", ""], ["Yang", "Zhiyong", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""], ["Yao", "Yuan", ""]]}, {"id": "1807.11023", "submitter": "Mohammed Ali Al-Garadi Dr", "authors": "Mohammed Ali Al-Garadi, Amr Mohamed, Abdulla Al-Ali, Xiaojiang Du,\n  Mohsen Guizani", "title": "A Survey of Machine and Deep Learning Methods for Internet of Things\n  (IoT) Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) integrates billions of smart devices that can\ncommunicate with one another with minimal human intervention. It is one of the\nfastest developing fields in the history of computing, with an estimated 50\nbillion devices by the end of 2020. On the one hand, IoT play a crucial role in\nenhancing several real-life smart applications that can improve life quality.\nOn the other hand, the crosscutting nature of IoT systems and the\nmultidisciplinary components involved in the deployment of such systems\nintroduced new security challenges. Implementing security measures, such as\nencryption, authentication, access control, network security and application\nsecurity, for IoT devices and their inherent vulnerabilities is ineffective.\nTherefore, existing security methods should be enhanced to secure the IoT\nsystem effectively. Machine learning and deep learning (ML/DL) have advanced\nconsiderably over the last few years, and machine intelligence has transitioned\nfrom laboratory curiosity to practical machinery in several important\napplications. Consequently, ML/DL methods are important in transforming the\nsecurity of IoT systems from merely facilitating secure communication between\ndevices to security-based intelligence systems. The goal of this work is to\nprovide a comprehensive survey of ML /DL methods that can be used to develop\nenhanced security methods for IoT systems. IoT security threats that are\nrelated to inherent or newly introduced threats are presented, and various\npotential IoT system attack surfaces and the possible threats related to each\nsurface are discussed. We then thoroughly review ML/DL methods for IoT security\nand present the opportunities, advantages and shortcomings of each method. We\ndiscuss the opportunities and challenges involved in applying ML/DL to IoT\nsecurity. These opportunities and challenges can serve as potential future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 08:58:38 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Al-Garadi", "Mohammed Ali", ""], ["Mohamed", "Amr", ""], ["Al-Ali", "Abdulla", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1807.11027", "submitter": "Yuan Zhang", "authors": "Yuan Zhang", "title": "Consistent polynomial-time unseeded graph matching for Lipschitz\n  graphons", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a consistent polynomial-time method for the unseeded node matching\nproblem for networks with smooth underlying structures. Despite widely\nconjectured by the research community that the structured graph matching\nproblem to be significantly easier than its worst case counterpart, well-known\nto be NP-hard, the statistical version of the problem has stood a challenge\nthat resisted any solution both provable and polynomial-time. The closest\nexisting work requires quasi-polynomial time. Our method is based on the latest\nadvances in graphon estimation techniques and analysis on the concentration of\nempirical Wasserstein distances. Its core is a simple yet unconventional\nsampling-and-matching scheme that reduces the problem from unseeded to seeded.\nOur method allows flexible efficiencies, is convenient to analyze and\npotentially can be extended to more general settings. Our work enables a rich\nvariety of subsequent estimations and inferences.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:25:37 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhang", "Yuan", ""]]}, {"id": "1807.11074", "submitter": "Doron Sobol", "authors": "Doron Sobol, Lior Wolf and Yaniv Taigman", "title": "Visual Analogies between Atari Games for Studying Transfer Learning in\n  RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we ask the following question: Can visual analogies, learned in\nan unsupervised way, be used in order to transfer knowledge between pairs of\ngames and even play one game using an agent trained for another game? We\nattempt to answer this research question by creating visual analogies between a\npair of games: a source game and a target game. For example, given a video\nframe in the target game, we map it to an analogous state in the source game\nand then attempt to play using a trained policy learned for the source game. We\ndemonstrate convincing visual mapping between four pairs of games (eight\nmappings), which are used to evaluate three transfer learning approaches.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 15:44:55 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Sobol", "Doron", ""], ["Wolf", "Lior", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1807.11089", "submitter": "Pramit Saha", "authors": "Pramit Saha, Praneeth Srungarapu and Sidney Fels", "title": "Towards Automatic Speech Identification from Vocal Tract Shape Dynamics\n  in Real-time MRI", "comments": "To appear in the INTERSPEECH 2018 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vocal tract configurations play a vital role in generating distinguishable\nspeech sounds, by modulating the airflow and creating different resonant\ncavities in speech production. They contain abundant information that can be\nutilized to better understand the underlying speech production mechanism. As a\nstep towards automatic mapping of vocal tract shape geometry to acoustics, this\npaper employs effective video action recognition techniques, like Long-term\nRecurrent Convolutional Networks (LRCN) models, to identify different\nvowel-consonant-vowel (VCV) sequences from dynamic shaping of the vocal tract.\nSuch a model typically combines a CNN based deep hierarchical visual feature\nextractor with Recurrent Networks, that ideally makes the network\nspatio-temporally deep enough to learn the sequential dynamics of a short video\nclip for video classification tasks. We use a database consisting of 2D\nreal-time MRI of vocal tract shaping during VCV utterances by 17 speakers. The\ncomparative performances of this class of algorithms under various parameter\nsettings and for various classification tasks are discussed. Interestingly, the\nresults show a marked difference in the model performance in the context of\nspeech classification with respect to generic sequence or video classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 17:36:08 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Saha", "Pramit", ""], ["Srungarapu", "Praneeth", ""], ["Fels", "Sidney", ""]]}, {"id": "1807.11091", "submitter": "Tianyun Zhang", "authors": "Tianyun Zhang, Shaokai Ye, Kaiqi Zhang, Xiaolong Ma, Ning Liu, Linfeng\n  Zhang, Jian Tang, Kaisheng Ma, Xue Lin, Makan Fardad and Yanzhi Wang", "title": "StructADMM: A Systematic, High-Efficiency Framework of Structured Weight\n  Pruning for DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning methods of DNNs have been demonstrated to achieve a good model\npruning rate without loss of accuracy, thereby alleviating the significant\ncomputation/storage requirements of large-scale DNNs. Structured weight pruning\nmethods have been proposed to overcome the limitation of irregular network\nstructure and demonstrated actual GPU acceleration. However, in prior work the\npruning rate (degree of sparsity) and GPU acceleration are limited (to less\nthan 50%) when accuracy needs to be maintained. In this work,we overcome these\nlimitations by proposing a unified, systematic framework of structured weight\npruning for DNNs. It is a framework that can be used to induce different types\nof structured sparsity, such as filter-wise, channel-wise, and shape-wise\nsparsity, as well non-structured sparsity. The proposed framework incorporates\nstochastic gradient descent with ADMM, and can be understood as a dynamic\nregularization method in which the regularization target is analytically\nupdated in each iteration. Without loss of accuracy on the AlexNet model, we\nachieve 2.58X and 3.65X average measured speedup on two GPUs, clearly\noutperforming the prior work. The average speedups reach 3.15X and 8.52X when\nallowing a moderate ac-curacy loss of 2%. In this case the model compression\nfor convolutional layers is 15.0X, corresponding to 11.93X measured CPU\nspeedup. Our experiments on ResNet model and on other data sets like UCF101 and\nCIFAR-10 demonstrate the consistently higher performance of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 18:07:04 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 18:52:21 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 02:37:46 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zhang", "Tianyun", ""], ["Ye", "Shaokai", ""], ["Zhang", "Kaiqi", ""], ["Ma", "Xiaolong", ""], ["Liu", "Ning", ""], ["Zhang", "Linfeng", ""], ["Tang", "Jian", ""], ["Ma", "Kaisheng", ""], ["Lin", "Xue", ""], ["Fardad", "Makan", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1807.11121", "submitter": "Jacob Beck", "authors": "Jacob Beck and Zoe Papakipos", "title": "Neural Mesh: Introducing a Notion of Space and Conservation of Energy to\n  Neural Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are based on a simplified model of the brain. In this\nproject, we wanted to relax the simplifying assumptions of a traditional neural\nnetwork by making a model that more closely emulates the low level interactions\nof neurons. Like in an RNN, our model has a state that persists between time\nsteps, so that the energies of neurons persist. However, unlike an RNN, our\nstate consists of a 2 dimensional matrix, rather than a 1 dimensional vector,\nthereby introducing a concept of distance to other neurons within the state. In\nour model, neurons can only fire to adjacent neurons, as in the brain. Like in\nthe brain, we only allow neurons to fire in a time step if they contain enough\nenergy, or excitement. We also enforce a notion of conservation of energy, so\nthat a neuron cannot excite its neighbors more than the excitement it already\ncontained at that time step. Taken together, these two features allow signals\nin the form of activations to flow around in our network over time, making our\nneural mesh more closely model signals traveling through the brain the brain.\nAlthough our main goal is to design an architecture to more closely emulate the\nbrain in the hope of having a correct internal representation of information by\nthe time we know how to properly train a general intelligence, we did benchmark\nour neural mash on a specific task. We found that by increasing the runtime of\nthe mesh, we were able to increase its accuracy without increasing the number\nof parameters.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 23:14:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Beck", "Jacob", ""], ["Papakipos", "Zoe", ""]]}, {"id": "1807.11125", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yu Wang and Siqi Sun and Sarah Panda and Jingjing Liu\n  and Jianfeng Gao", "title": "Microsoft Dialogue Challenge: Building End-to-End Task-Completion\n  Dialogue Systems", "comments": "SLT 2018 Special Session: http://www.slt2018.org/news/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This proposal introduces a Dialogue Challenge for building end-to-end\ntask-completion dialogue systems, with the goal of encouraging the dialogue\nresearch community to collaborate and benchmark on standard datasets and\nunified experimental environment. In this special session, we will release\nhuman-annotated conversational data in three domains (movie-ticket booking,\nrestaurant reservation, and taxi booking), as well as an experiment platform\nwith built-in simulators in each domain, for training and evaluation purposes.\nThe final submitted systems will be evaluated both in simulated setting and by\nhuman judges.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 23:51:08 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 23:47:59 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Li", "Xiujun", ""], ["Wang", "Yu", ""], ["Sun", "Siqi", ""], ["Panda", "Sarah", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1807.11143", "submitter": "Mingyuan Zhou", "authors": "Mingzhang Yin, Mingyuan Zhou", "title": "ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To backpropagate the gradients through stochastic binary layers, we propose\nthe augment-REINFORCE-merge (ARM) estimator that is unbiased, exhibits low\nvariance, and has low computational complexity. Exploiting variable\naugmentation, REINFORCE, and reparameterization, the ARM estimator achieves\nadaptive variance reduction for Monte Carlo integration by merging two\nexpectations via common random numbers. The variance-reduction mechanism of the\nARM estimator can also be attributed to either antithetic sampling in an\naugmented space, or the use of an optimal anti-symmetric \"self-control\"\nbaseline function together with the REINFORCE estimator in that augmented\nspace. Experimental results show the ARM estimator provides state-of-the-art\nperformance in auto-encoding variational inference and maximum likelihood\nestimation, for discrete latent variable models with one or multiple stochastic\nbinary layers. Python code for reproducible research is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 02:21:07 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 22:34:47 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1807.11156", "submitter": "ShihChung Lo Ph.D.", "authors": "ShihChung B. Lo, Matthew T. Freedman, and Seong K. Mun", "title": "Transformationally Identical and Invariant Convolutional Neural Networks\n  by Combining Symmetric Operations or Input Vectors", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformationally invariant processors constructed by transformed input\nvectors or operators have been suggested and applied to many applications. In\nthis study, transformationally identical processing based on combining results\nof all sub-processes with corresponding transformations at one of the\nprocessing steps or at the beginning step were found to be equivalent for a\ngiven condition. This property can be applied to most convolutional neural\nnetwork (CNN) systems. Specifically, a transformationally identical CNN can be\nconstructed by arranging internally symmetric operations in parallel with the\nsame transformation family that includes a flatten layer with weights sharing\namong their corresponding transformation elements. Other transformationally\nidentical CNNs can be constructed by averaging transformed input vectors of the\nfamily at the input layer followed by an ordinary CNN process or by a set of\nsymmetric operations. Interestingly, we found that both types of\ntransformationally identical CNN systems are mathematically equivalent by\neither applying an averaging operation to corresponding elements of all\nsub-channels before the activation function or without using a non-linear\nactivation function.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 03:14:50 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 13:32:14 GMT"}, {"version": "v3", "created": "Mon, 20 Aug 2018 10:32:55 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Lo", "ShihChung B.", ""], ["Freedman", "Matthew T.", ""], ["Mun", "Seong K.", ""]]}, {"id": "1807.11158", "submitter": "Tianyu Guo", "authors": "Tianyu Guo, Chang Xu, Shiyi He, Boxin Shi, Chao Xu, and Dacheng Tao", "title": "Robust Student Network Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks bring in impressive accuracy in various applications,\nbut the success often relies on the heavy network architecture. Taking\nwell-trained heavy networks as teachers, classical teacher-student learning\nparadigm aims to learn a student network that is lightweight yet accurate. In\nthis way, a portable student network with significantly fewer parameters can\nachieve a considerable accuracy which is comparable to that of teacher network.\nHowever, beyond accuracy, robustness of the learned student network against\nperturbation is also essential for practical uses. Existing teacher-student\nlearning frameworks mainly focus on accuracy and compression ratios, but ignore\nthe robustness. In this paper, we make the student network produce more\nconfident predictions with the help of the teacher network, and analyze the\nlower bound of the perturbation that will destroy the confidence of the student\nnetwork. Two important objectives regarding prediction scores and gradients of\nexamples are developed to maximize this lower bound, so as to enhance the\nrobustness of the student network without sacrificing the performance.\nExperiments on benchmark datasets demonstrate the efficiency of the proposed\napproach to learn robust student networks which have satisfying accuracy and\ncompact sizes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 03:27:04 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 01:01:55 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Guo", "Tianyu", ""], ["Xu", "Chang", ""], ["He", "Shiyi", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Tao", "Dacheng", ""]]}, {"id": "1807.11161", "submitter": "Hao Min Liu", "authors": "Hao-Min Liu, Yi-Hsuan Yang", "title": "Lead Sheet Generation and Arrangement by Conditional Generative\n  Adversarial Network", "comments": "7 pages, 7 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on automatic music generation has seen great progress due to the\ndevelopment of deep neural networks. However, the generation of\nmulti-instrument music of arbitrary genres still remains a challenge. Existing\nresearch either works on lead sheets or multi-track piano-rolls found in MIDIs,\nbut both musical notations have their limits. In this work, we propose a new\ntask called lead sheet arrangement to avoid such limits. A new recurrent\nconvolutional generative model for the task is proposed, along with three new\nsymbolic-domain harmonic features to facilitate learning from unpaired lead\nsheets and MIDIs. Our model can generate lead sheets and their arrangements of\neight-bar long. Audio samples of the generated result can be found at\nhttps://drive.google.com/open?id=1c0FfODTpudmLvuKBbc23VBCgQizY6-Rk\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 03:48:04 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Hao-Min", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1807.11167", "submitter": "Haizi Yu", "authors": "Haizi Yu, Igor Mineyev, Lav R. Varshney", "title": "A Group-Theoretic Approach to Computational Abstraction: Symmetry-Driven\n  Hierarchical Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction plays a key role in concept learning and knowledge discovery;\nthis paper is concerned with computational abstraction. In particular, we study\nthe nature of abstraction through a group-theoretic approach, formalizing it as\nsymmetry-driven---as opposed to data-driven---hierarchical clustering. Thus,\nthe resulting clustering framework is data-free, feature-free, similarity-free,\nand globally hierarchical---the four key features that distinguish it from\ncommon data clustering models such as $k$-means. Beyond a theoretical\nfoundation for abstraction, we also present a top-down and a bottom-up approach\nto establish an algorithmic foundation for practical abstraction-generating\nmethods. Lastly, via both a theoretical explanation and a real-world\napplication, we illustrate that further coupling of our abstraction framework\nwith statistics realizes Shannon's information lattice and even further, brings\nlearning into the picture. This not only presents one use case of our proposed\ncomputational abstraction, but also gives a first step towards a principled and\ncognitive way of automatic concept learning and knowledge discovery.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 04:28:52 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 16:52:41 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yu", "Haizi", ""], ["Mineyev", "Igor", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1807.11169", "submitter": "Simina Br\\^anzei", "authors": "Simina Br\\^anzei and Yuval Peres", "title": "Online Learning with an Almost Perfect Expert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multiclass online learning problem where a forecaster makes a\nsequence of predictions using the advice of $n$ experts. Our main contribution\nis to analyze the regime where the best expert makes at most $b$ mistakes and\nto show that when $b = o(\\log_4{n})$, the expected number of mistakes made by\nthe optimal forecaster is at most $\\log_4{n} + o(\\log_4{n})$. We also describe\nan adversary strategy showing that this bound is tight and that the worst case\nis attained for binary prediction.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 04:34:59 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 15:20:35 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Br\u00e2nzei", "Simina", ""], ["Peres", "Yuval", ""]]}, {"id": "1807.11205", "submitter": "Xianyan Jia", "authors": "Xianyan Jia, Shutao Song, Wei He, Yangzihao Wang, Haidong Rong, Feihu\n  Zhou, Liqiang Xie, Zhenyu Guo, Yuanzhou Yang, Liwei Yu, Tiegang Chen,\n  Guangxiao Hu, Shaohuai Shi, Xiaowen Chu", "title": "Highly Scalable Deep Learning Training System with Mixed-Precision:\n  Training ImageNet in Four Minutes", "comments": "arXiv admin note: text overlap with arXiv:1803.03383 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronized stochastic gradient descent (SGD) optimizers with data\nparallelism are widely used in training large-scale deep neural networks.\nAlthough using larger mini-batch sizes can improve the system scalability by\nreducing the communication-to-computation ratio, it may hurt the generalization\nability of the models. To this end, we build a highly scalable deep learning\ntraining system for dense GPU clusters with three main contributions: (1) We\npropose a mixed-precision training method that significantly improves the\ntraining throughput of a single GPU without losing accuracy. (2) We propose an\noptimization approach for extremely large mini-batch size (up to 64k) that can\ntrain CNN models on the ImageNet dataset without losing accuracy. (3) We\npropose highly optimized all-reduce algorithms that achieve up to 3x and 11x\nspeedup on AlexNet and ResNet-50 respectively than NCCL-based training on a\ncluster with 1024 Tesla P40 GPUs. On training ResNet-50 with 90 epochs, the\nstate-of-the-art GPU-based system with 1024 Tesla P100 GPUs spent 15 minutes\nand achieved 74.9\\% top-1 test accuracy, and another KNL-based system with 2048\nIntel KNLs spent 20 minutes and achieved 75.4\\% accuracy. Our training system\ncan achieve 75.8\\% top-1 test accuracy in only 6.6 minutes using 2048 Tesla P40\nGPUs. When training AlexNet with 95 epochs, our system can achieve 58.7\\% top-1\ntest accuracy within 4 minutes, which also outperforms all other existing\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 07:40:44 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Jia", "Xianyan", ""], ["Song", "Shutao", ""], ["He", "Wei", ""], ["Wang", "Yangzihao", ""], ["Rong", "Haidong", ""], ["Zhou", "Feihu", ""], ["Xie", "Liqiang", ""], ["Guo", "Zhenyu", ""], ["Yang", "Yuanzhou", ""], ["Yu", "Liwei", ""], ["Chen", "Tiegang", ""], ["Hu", "Guangxiao", ""], ["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1807.11228", "submitter": "Mikhail Belyaev", "authors": "Yaroslav Shmulev and Mikhail Belyaev", "title": "Predicting Conversion of Mild Cognitive Impairments to Alzheimer's\n  Disease and Exploring Impact of Neuroimaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, a lot of scientific efforts are concentrated on the diagnosis of\nAlzheimer's Disease (AD) applying deep learning methods to neuroimaging data.\nEven for 2017, there were published more than a hundred papers dedicated to AD\ndiagnosis, whereas only a few works considered a problem of mild cognitive\nimpairments (MCI) conversion to the AD. However, the conversion prediction is\nan important problem since approximately 15% of patients with MCI converges to\nthe AD every year. In the current work, we are focusing on the conversion\nprediction using brain Magnetic Resonance Imaging and clinical data, such as\ndemographics, cognitive assessments, genetic, and biochemical markers. First of\nall, we applied state-of-the-art deep learning algorithms on the neuroimaging\ndata and compared these results with two machine learning algorithms that we\nfit using the clinical data. As a result, the models trained on the clinical\ndata outperform the deep learning algorithms applied to the MR images. To\nexplore the impact of neuroimaging further, we trained a deep feed-forward\nembedding using similarity learning with Histogram loss on all available MRIs\nand obtained 64-dimensional vector representation of neuroimaging data. The use\nof learned representation from the deep embedding allowed to increase the\nquality of prediction based on the neuroimaging. Finally, the current results\non this dataset show that the neuroimaging does affect conversion prediction,\nhowever, cannot noticeably increase the quality of the prediction. The best\nresults of predicting MCI-to-AD conversion are provided by XGBoost algorithm\ntrained on the clinical and embedding data. The resulting accuracy is 0.76 +-\n0.01 and the area under the ROC curve - 0.86 +- 0.01.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:39:47 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Shmulev", "Yaroslav", ""], ["Belyaev", "Mikhail", ""]]}, {"id": "1807.11236", "submitter": "Liu Yongcheng", "authors": "Yongcheng Liu, Bin Fan, Lingfeng Wang, Jun Bai, Shiming Xiang,\n  Chunhong Pan", "title": "Semantic Labeling in Very High Resolution Images via a Self-Cascaded\n  Convolutional Neural Network", "comments": "accepted by ISPRS Journal of Photogrammetry and Remote Senseing 2017", "journal-ref": null, "doi": "10.1016/j.isprsjprs.2017.12.007", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic labeling for very high resolution (VHR) images in urban areas, is of\nsignificant importance in a wide range of remote sensing applications. However,\nmany confusing manmade objects and intricate fine-structured objects make it\nvery difficult to obtain both coherent and accurate labeling results. For this\nchallenging task, we propose a novel deep model with convolutional neural\nnetworks (CNNs), i.e., an end-to-end self-cascaded network (ScasNet).\nSpecifically, for confusing manmade objects, ScasNet improves the labeling\ncoherence with sequential global-to-local contexts aggregation. Technically,\nmulti-scale contexts are captured on the output of a CNN encoder, and then they\nare successively aggregated in a self-cascaded manner. Meanwhile, for\nfine-structured objects, ScasNet boosts the labeling accuracy with a\ncoarse-to-fine refinement strategy. It progressively refines the target objects\nusing the low-level features learned by CNN's shallow layers. In addition, to\ncorrect the latent fitting residual caused by multi-feature fusion inside\nScasNet, a dedicated residual correction scheme is proposed. It greatly\nimproves the effectiveness of ScasNet. Extensive experimental results on three\npublic datasets, including two challenging benchmarks, show that ScasNet\nachieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:49:25 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Yongcheng", ""], ["Fan", "Bin", ""], ["Wang", "Lingfeng", ""], ["Bai", "Jun", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1807.11272", "submitter": "Katar\\'ina T\\'othov\\'a", "authors": "Katar\\'ina T\\'othov\\'a, Sarah Parisot, Matthew C. H. Lee, Esther\n  Puyol-Ant\\'on, Lisa M. Koch, Andrew P. King, Ender Konukoglu, and Marc\n  Pollefeys", "title": "Uncertainty Quantification in CNN-Based Surface Prediction Using Shape\n  Priors", "comments": "Accepted to ShapeMI MICCAI 2018: Workshop on Shape in Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Surface reconstruction is a vital tool in a wide range of areas of medical\nimage analysis and clinical research. Despite the fact that many methods have\nproposed solutions to the reconstruction problem, most, due to their\ndeterministic nature, do not directly address the issue of quantifying\nuncertainty associated with their predictions. We remedy this by proposing a\nnovel probabilistic deep learning approach capable of simultaneous surface\nreconstruction and associated uncertainty prediction. The method incorporates\nprior shape information in the form of a principal component analysis (PCA)\nmodel. Experiments using the UK Biobank data show that our probabilistic\napproach outperforms an analogous deterministic PCA-based method in the task of\n2D organ delineation and quantifies uncertainty by formulating distributions\nover predicted surface vertex positions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 10:24:26 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["T\u00f3thov\u00e1", "Katar\u00edna", ""], ["Parisot", "Sarah", ""], ["Lee", "Matthew C. H.", ""], ["Puyol-Ant\u00f3n", "Esther", ""], ["Koch", "Lisa M.", ""], ["King", "Andrew P.", ""], ["Konukoglu", "Ender", ""], ["Pollefeys", "Marc", ""]]}, {"id": "1807.11320", "submitter": "Gustav Eje Henter", "authors": "Gustav Eje Henter, Arne Leijon and W. Bastiaan Kleijn", "title": "Kernel Density Estimation-Based Markov Models with Hidden State", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov models of stochastic processes where the next-step\nconditional distribution is defined by a kernel density estimator (KDE),\nsimilar to Markov forecast densities and certain time-series bootstrap schemes.\nThe KDE Markov models (KDE-MMs) we discuss are nonlinear, nonparametric, fully\nprobabilistic representations of stationary processes, based on techniques with\nstrong asymptotic consistency properties. The models generate new data by\nconcatenating points from the training data sequences in a context-sensitive\nmanner, together with some additive driving noise. We present novel EM-type\nmaximum-likelihood algorithms for data-driven bandwidth selection in KDE-MMs.\nAdditionally, we augment the KDE-MMs with a hidden state, yielding a new model\nclass, KDE-HMMs. The added state variable captures non-Markovian long memory\nand signal structure (e.g., slow oscillations), complementing the short-range\ndependences described by the Markov process. The resulting joint Markov and\nhidden-Markov structure is appealing for modelling complex real-world processes\nsuch as speech signals. We present guaranteed-ascent EM-update equations for\nmodel parameters in the case of Gaussian kernels, as well as relaxed update\nformulas that greatly accelerate training in practice. Experiments demonstrate\nincreased held-out set probability for KDE-HMMs on several challenging natural\nand synthetic data series, compared to traditional techniques such as\nautoregressive models, HMMs, and their combinations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 12:44:26 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Henter", "Gustav Eje", ""], ["Leijon", "Arne", ""], ["Kleijn", "W. Bastiaan", ""]]}, {"id": "1807.11346", "submitter": "Gon\\c{c}alo Mordido", "authors": "Gon\\c{c}alo Mordido, Haojin Yang, Christoph Meinel", "title": "Dropout-GAN: Learning from a Dynamic Ensemble of Discriminators", "comments": "Extended version of ACM KDD'18 Deep Learning Day", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to incorporate adversarial dropout in generative multi-adversarial\nnetworks, by omitting or dropping out, the feedback of each discriminator in\nthe framework with some probability at the end of each batch. Our approach\nforces the single generator not to constrain its output to satisfy a single\ndiscriminator, but, instead, to satisfy a dynamic ensemble of discriminators.\nWe show that this leads to a more generalized generator, promoting variety in\nthe generated samples and avoiding the common mode collapse problem commonly\nexperienced with generative adversarial networks (GANs). We further provide\nevidence that the proposed framework, named Dropout-GAN, promotes sample\ndiversity both within and across epochs, eliminating mode collapse and\nstabilizing training.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 13:45:16 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 09:33:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mordido", "Gon\u00e7alo", ""], ["Yang", "Haojin", ""], ["Meinel", "Christoph", ""]]}, {"id": "1807.11374", "submitter": "Rishi Sharma", "authors": "Rishi Sharma, Amir Barati Farimani, Joe Gomes, Peter Eastman, Vijay\n  Pande", "title": "Weakly-Supervised Deep Learning of Heat Transport via Physics Informed\n  Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In typical machine learning tasks and applications, it is necessary to obtain\nor create large labeled datasets in order to to achieve high performance.\nUnfortunately, large labeled datasets are not always available and can be\nexpensive to source, creating a bottleneck towards more widely applicable\nmachine learning. The paradigm of weak supervision offers an alternative that\nallows for integration of domain-specific knowledge by enforcing constraints\nthat a correct solution to the learning problem will obey over the output\nspace. In this work, we explore the application of this paradigm to 2-D\nphysical systems governed by non-linear differential equations. We demonstrate\nthat knowledge of the partial differential equations governing a system can be\nencoded into the loss function of a neural network via an appropriately chosen\nconvolutional kernel. We demonstrate this by showing that the steady-state\nsolution to the 2-D heat equation can be learned directly from initial\nconditions by a convolutional neural network, in the absence of labeled\ntraining data. We also extend recent work in the progressive growing of fully\nconvolutional networks to achieve high accuracy (< 1.5% error) at multiple\nscales of the heat-flow problem, including at the very large scale (1024x1024).\nFinally, we demonstrate that this method can be used to speed up exact\ncalculation of the solution to the differential equations via finite\ndifference.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:58:56 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 18:40:09 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Sharma", "Rishi", ""], ["Farimani", "Amir Barati", ""], ["Gomes", "Joe", ""], ["Eastman", "Peter", ""], ["Pande", "Vijay", ""]]}, {"id": "1807.11393", "submitter": "Bin Liu", "authors": "Bin Liu and Grigorios Tsoumakas", "title": "Making Classifier Chains Resilient to Class Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is an intrinsic characteristic of multi-label data. Most of\nthe labels in multi-label data sets are associated with a small number of\ntraining examples, much smaller compared to the size of the data set. Class\nimbalance poses a key challenge that plagues most multi-label learning methods.\nEnsemble of Classifier Chains (ECC), one of the most prominent multi-label\nlearning methods, is no exception to this rule, as each of the binary models it\nbuilds is trained from all positive and negative examples of a label. To make\nECC resilient to class imbalance, we first couple it with random undersampling.\nWe then present two extensions of this basic approach, where we build a varying\nnumber of binary models per label and construct chains of different sizes, in\norder to improve the exploitation of majority examples with approximately the\nsame computational budget. Experimental results on 16 multi-label datasets\ndemonstrate the effectiveness of the proposed approaches in a variety of\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 15:13:49 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 09:35:01 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 07:04:06 GMT"}, {"version": "v4", "created": "Tue, 6 Nov 2018 09:46:41 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Liu", "Bin", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1807.11398", "submitter": "Eyke H\\\"ullermeier", "authors": "Viktor Bengs, Robert Busa-Fekete, Adil El Mesaoudi-Paul and Eyke\n  H\\\"ullermeier", "title": "Preference-based Online Learning with Dueling Bandits: A Survey", "comments": "108 pages", "journal-ref": "Journal of Machine Learning Research, 22(7):1-108, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, the notion of multi-armed bandits refers to a class of\nonline learning problems, in which an agent is supposed to simultaneously\nexplore and exploit a given set of choice alternatives in the course of a\nsequential decision process. In the standard setting, the agent learns from\nstochastic feedback in the form of real-valued rewards. In many applications,\nhowever, numerical reward signals are not readily available -- instead, only\nweaker information is provided, in particular relative preferences in the form\nof qualitative comparisons between pairs of alternatives. This observation has\nmotivated the study of variants of the multi-armed bandit problem, in which\nmore general representations are used both for the type of feedback to learn\nfrom and the target of prediction. The aim of this paper is to provide a survey\nof the state of the art in this field, referred to as preference-based\nmulti-armed bandits or dueling bandits. To this end, we provide an overview of\nproblems that have been considered in the literature as well as methods for\ntackling them. Our taxonomy is mainly based on the assumptions made by these\nmethods about the data-generating process and, related to this, the properties\nof the preference-based feedback.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 15:40:54 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 12:57:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bengs", "Viktor", ""], ["Busa-Fekete", "Robert", ""], ["Mesaoudi-Paul", "Adil El", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1807.11407", "submitter": "Thomas Robert", "authors": "Thomas Robert, Nicolas Thome, Matthieu Cord", "title": "HybridNet: Classification and Reconstruction Cooperation for\n  Semi-Supervised Learning", "comments": "Accepted at ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new model for leveraging unlabeled data to\nimprove generalization performances of image classifiers: a two-branch\nencoder-decoder architecture called HybridNet. The first branch receives\nsupervision signal and is dedicated to the extraction of invariant\nclass-related representations. The second branch is fully unsupervised and\ndedicated to model information discarded by the first branch to reconstruct\ninput data. To further support the expected behavior of our model, we propose\nan original training objective. It favors stability in the discriminative\nbranch and complementarity between the learned representations in the two\nbranches. HybridNet is able to outperform state-of-the-art results on CIFAR-10,\nSVHN and STL-10 in various semi-supervised settings. In addition,\nvisualizations and ablation studies validate our contributions and the behavior\nof the model on both CIFAR-10 and STL-10 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:00:08 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Robert", "Thomas", ""], ["Thome", "Nicolas", ""], ["Cord", "Matthieu", ""]]}, {"id": "1807.11408", "submitter": "Rina Friedberg", "authors": "Rina Friedberg, Julie Tibshirani, Susan Athey, Stefan Wager", "title": "Local Linear Forests", "comments": "Forthcoming in the Journal of Computational and Graphical Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are a powerful method for non-parametric regression, but are\nlimited in their ability to fit smooth signals, and can show poor predictive\nperformance in the presence of strong, smooth effects. Taking the perspective\nof random forests as an adaptive kernel method, we pair the forest kernel with\na local linear regression adjustment to better capture smoothness. The\nresulting procedure, local linear forests, enables us to improve on asymptotic\nrates of convergence for random forests with smooth signals, and provides\nsubstantial gains in accuracy on both real and simulated data. We prove a\ncentral limit theorem valid under regularity conditions on the forest and\nsmoothness constraints, and propose a computationally efficient construction\nfor confidence intervals. Moving to a causal inference application, we discuss\nthe merits of local regression adjustments for heterogeneous treatment effect\nestimation, and give an example on a dataset exploring the effect word choice\nhas on attitudes to the social safety net. Last, we include simulation results\non real and generated data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:01:53 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 03:24:46 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 16:19:08 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 23:50:48 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Friedberg", "Rina", ""], ["Tibshirani", "Julie", ""], ["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1807.11414", "submitter": "Gaurav Singh", "authors": "Gaurav Singh and John Shawe-Taylor", "title": "Faster Convergence & Generalization in DNNs", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have gained tremendous popularity in last few years.\nThey have been applied for the task of classification in almost every domain.\nDespite the success, deep networks can be incredibly slow to train for even\nmoderate sized models on sufficiently large datasets. Additionally, these\nnetworks require large amounts of data to be able to generalize. The importance\nof speeding up convergence, and generalization in deep networks can not be\noverstated. In this work, we develop an optimization algorithm based on\ngeneralized-optimal updates derived from minibatches that lead to faster\nconvergence. Towards the end, we demonstrate on two benchmark datasets that the\nproposed method achieves two orders of magnitude speed up over traditional\nback-propagation, and is more robust to noise/over-fitting.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:06:26 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 01:41:19 GMT"}, {"version": "v3", "created": "Wed, 10 Oct 2018 17:50:42 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Singh", "Gaurav", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1807.11419", "submitter": "Tselil Schramm", "authors": "Prasad Raghavendra, Tselil Schramm, David Steurer", "title": "High-dimensional estimation via sum-of-squares proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation is the computational task of recovering a hidden parameter $x$\nassociated with a distribution $D_x$, given a measurement $y$ sampled from the\ndistribution. High dimensional estimation problems arise naturally in\nstatistics, machine learning, and complexity theory.\n  Many high dimensional estimation problems can be formulated as systems of\npolynomial equations and inequalities, and thus give rise to natural\nprobability distributions over polynomial systems. Sum-of-squares proofs\nprovide a powerful framework to reason about polynomial systems, and further\nthere exist efficient algorithms to search for low-degree sum-of-squares\nproofs.\n  Understanding and characterizing the power of sum-of-squares proofs for\nestimation problems has been a subject of intense study in recent years. On one\nhand, there is a growing body of work utilizing sum-of-squares proofs for\nrecovering solutions to polynomial systems when the system is feasible. On the\nother hand, a general technique referred to as pseudocalibration has been\ndeveloped towards showing lower bounds on the degree of sum-of-squares proofs.\nFinally, the existence of sum-of-squares refutations of a polynomial system has\nbeen shown to be intimately connected to the existence of spectral algorithms.\nIn this article we survey these developments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:13:57 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 00:56:07 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Raghavendra", "Prasad", ""], ["Schramm", "Tselil", ""], ["Steurer", "David", ""]]}, {"id": "1807.11429", "submitter": "Arjun Pakrashi", "authors": "Arjun Pakrashi, Brian Mac Namee", "title": "Kalman Filter-based Heuristic Ensemble (KFHE): A new perspective on\n  multi-class ensemble classification using Kalman filters", "comments": null, "journal-ref": "Volume 485, June 2019, Pages 456-485", "doi": "10.1016/j.ins.2019.02.017", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new perspective on multi-class ensemble\nclassification that considers training an ensemble as a state estimation\nproblem. The new perspective considers the final ensemble classifier model as a\nstatic state, which can be estimated using a Kalman filter that combines noisy\nestimates made by individual classifier models. A new algorithm based on this\nperspective, the Kalman Filter-based Heuristic Ensemble (KFHE), is also\npresented in this paper which shows the practical applicability of the new\nperspective. Experiments performed on 30 datasets compare KFHE with\nstate-of-the-art multi-class ensemble classification algorithms and show the\npotential and effectiveness of the new perspective and algorithm. Existing\nensemble approaches trade off classification accuracy against robustness to\nclass label noise, but KFHE is shown to be significantly better or at least as\ngood as the state-of-the-art algorithms for datasets both with and without\nclass label noise.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:38:51 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 21:02:48 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 21:22:03 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1807.11436", "submitter": "Yu-Ting Chen", "authors": "Yu-Ting Chen, Wen-Yen Chang, Hai-Lun Lu, Tingfan Wu, Min Sun", "title": "Leveraging Motion Priors in Videos for Improving Human Segmentation", "comments": "ECCV2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite many advances in deep-learning based semantic segmentation,\nperformance drop due to distribution mismatch is often encountered in the real\nworld. Recently, a few domain adaptation and active learning approaches have\nbeen proposed to mitigate the performance drop. However, very little attention\nhas been made toward leveraging information in videos which are naturally\ncaptured in most camera systems. In this work, we propose to leverage \"motion\nprior\" in videos for improving human segmentation in a weakly-supervised active\nlearning setting. By extracting motion information using optical flow in\nvideos, we can extract candidate foreground motion segments (referred to as\nmotion prior) potentially corresponding to human segments. We propose to learn\na memory-network-based policy model to select strong candidate segments\n(referred to as strong motion prior) through reinforcement learning. The\nselected segments have high precision and are directly used to finetune the\nmodel. In a newly collected surveillance camera dataset and a publicly\navailable UrbanStreet dataset, our proposed method improves the performance of\nhuman segmentation across multiple scenes and modalities (i.e., RGB to Infrared\n(IR)). Last but not least, our method is empirically complementary to existing\ndomain adaptation approaches such that additional performance gain is achieved\nby combining our weakly-supervised active learning approach with domain\nadaptation approaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:52:04 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chen", "Yu-Ting", ""], ["Chang", "Wen-Yen", ""], ["Lu", "Hai-Lun", ""], ["Wu", "Tingfan", ""], ["Sun", "Min", ""]]}, {"id": "1807.11440", "submitter": "Weidi Xie", "authors": "Weidi Xie, Li Shen and Andrew Zisserman", "title": "Comparator Networks", "comments": "To appear in ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of this work is set-based verification, e.g. to decide if two\nsets of images of a face are of the same person or not. The traditional\napproach to this problem is to learn to generate a feature vector per image,\naggregate them into one vector to represent the set, and then compute the\ncosine similarity between sets. Instead, we design a neural network\narchitecture that can directly learn set-wise verification. Our contributions\nare: (i) We propose a Deep Comparator Network (DCN) that can ingest a pair of\nsets (each may contain a variable number of images) as inputs, and compute a\nsimilarity between the pair--this involves attending to multiple discriminative\nlocal regions (landmarks), and comparing local descriptors between pairs of\nfaces; (ii) To encourage high-quality representations for each set, internal\ncompetition is introduced for recalibration based on the landmark score; (iii)\nInspired by image retrieval, a novel hard sample mining regime is proposed to\ncontrol the sampling process, such that the DCN is complementary to the\nstandard image classification models. Evaluations on the IARPA Janus face\nrecognition benchmarks show that the comparator networks outperform the\nprevious state-of-the-art results by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:54:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Xie", "Weidi", ""], ["Shen", "Li", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1807.11459", "submitter": "Parijat Dube", "authors": "Parijat Dube, Bishwaranjan Bhattacharjee, Elisabeth Petit-Bois,\n  Matthew Hill", "title": "Improving Transferability of Deep Neural Networks", "comments": "15 pages, 11 figures, 2 tables, Workshop on Domain Adaptation for\n  Visual Understanding (Joint IJCAI/ECAI/AAMAS/ICML 2018 Workshop) Keywords:\n  deep learning, transfer learning, finetuning, deep neural network,\n  experimental", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from small amounts of labeled data is a challenge in the area of\ndeep learning. This is currently addressed by Transfer Learning where one\nlearns the small data set as a transfer task from a larger source dataset.\nTransfer Learning can deliver higher accuracy if the hyperparameters and source\ndataset are chosen well. One of the important parameters is the learning rate\nfor the layers of the neural network. We show through experiments on the\nImageNet22k and Oxford Flowers datasets that improvements in accuracy in range\nof 127% can be obtained by proper choice of learning rates. We also show that\nthe images/label parameter for a dataset can potentially be used to determine\noptimal learning rates for the layers to get the best overall accuracy. We\nadditionally validate this method on a sample of real-world image\nclassification tasks from a public visual recognition API.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 17:34:24 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Dube", "Parijat", ""], ["Bhattacharjee", "Bishwaranjan", ""], ["Petit-Bois", "Elisabeth", ""], ["Hill", "Matthew", ""]]}, {"id": "1807.11470", "submitter": "Gustav Eje Henter", "authors": "Gustav Eje Henter, Jaime Lorenzo-Trueba, Xin Wang and Junichi\n  Yamagishi", "title": "Deep Encoder-Decoder Models for Unsupervised Learning of Controllable\n  Speech Synthesis", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating versatile and appropriate synthetic speech requires control over\nthe output expression separate from the spoken text. Important non-textual\nspeech variation is seldom annotated, in which case output control must be\nlearned in an unsupervised fashion. In this paper, we perform an in-depth study\nof methods for unsupervised learning of control in statistical speech\nsynthesis. For example, we show that popular unsupervised training heuristics\ncan be interpreted as variational inference in certain autoencoder models. We\nadditionally connect these models to VQ-VAEs, another, recently-proposed class\nof deep variational autoencoders, which we show can be derived from a very\nsimilar mathematical argument. The implications of these new probabilistic\ninterpretations are discussed. We illustrate the utility of the various\napproaches with an application to acoustic modelling for emotional speech\nsynthesis, where the unsupervised methods for learning expression control\n(without access to emotional labels) are found to give results that in many\naspects match or surpass the previous best supervised approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 17:59:28 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 12:53:06 GMT"}, {"version": "v3", "created": "Sun, 9 Sep 2018 17:01:07 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Henter", "Gustav Eje", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1807.11537", "submitter": "Maruti Mudunuru", "authors": "M. K. Mudunuru, N. Panda, S. Karra, G. Srinivasan, V. T. Chau, E.\n  Rougier, A. Hunter, and H. S. Viswanathan", "title": "Estimating Failure in Brittle Materials using Graph Theory", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In brittle fracture applications, failure paths, regions where the failure\noccurs and damage statistics, are some of the key quantities of interest (QoI).\nHigh-fidelity models for brittle failure that accurately predict these QoI\nexist but are highly computationally intensive, making them infeasible to\nincorporate in upscaling and uncertainty quantification frameworks. The goal of\nthis paper is to provide a fast heuristic to reasonably estimate quantities\nsuch as failure path and damage in the process of brittle failure. Towards this\ngoal, we first present a method to predict failure paths under tensile loading\nconditions and low-strain rates. The method uses a $k$-nearest neighbors\nalgorithm built on fracture process zone theory, and identifies the set of all\npossible pre-existing cracks that are likely to join early to form a large\ncrack. The method then identifies zone of failure and failure paths using\nweighted graphs algorithms. We compare these failure paths to those computed\nwith a high-fidelity model called the Hybrid Optimization Software Simulation\nSuite (HOSS). A probabilistic evolution model for average damage in a system is\nalso developed that is trained using 150 HOSS simulations and tested on 40\nsimulations. A non-parametric approach based on confidence intervals is used to\ndetermine the damage evolution over time along the dominant failure path. For\nupscaling, damage is the key QoI needed as an input by the continuum models.\nThis needs to be informed accurately by the surrogate models for calculating\neffective modulii at continuum-scale. We show that for the proposed average\ndamage evolution model, the prediction accuracy on the test data is more than\n90\\%. In terms of the computational time, the proposed models are $\\approx\n\\mathcal{O}(10^6)$ times faster compared to high-fidelity HOSS.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 19:21:57 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Mudunuru", "M. K.", ""], ["Panda", "N.", ""], ["Karra", "S.", ""], ["Srinivasan", "G.", ""], ["Chau", "V. T.", ""], ["Rougier", "E.", ""], ["Hunter", "A.", ""], ["Viswanathan", "H. S.", ""]]}, {"id": "1807.11545", "submitter": "Hazrat Ali", "authors": "Kashif Sultan, Hazrat Ali and Zhongshan Zhang", "title": "Call Detail Records Driven Anomaly Detection and Traffic Prediction in\n  Mobile Cellular Networks", "comments": "IEEE Access Journal paper", "journal-ref": "10.1109/ACCESS.2018.2859756", "doi": "10.1109/ACCESS.2018.2859756", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile networks possess information about the users as well as the network.\nSuch information is useful for making the network end-to-end visible and\nintelligent. Big data analytics can efficiently analyze user and network\ninformation, unearth meaningful insights with the help of machine learning\ntools. Utilizing big data analytics and machine learning, this work contributes\nin three ways. First, we utilize the call detail records (CDR) data to detect\nanomalies in the network. For authentication and verification of anomalies, we\nuse k-means clustering, an unsupervised machine learning algorithm. Through\neffective detection of anomalies, we can proceed to suitable design for\nresource distribution as well as fault detection and avoidance. Second, we\nprepare anomaly-free data by removing anomalous activities and train a neural\nnetwork model. By passing anomaly and anomaly-free data through this model, we\nobserve the effect of anomalous activities in training of the model and also\nobserve mean square error of anomaly and anomaly free data. Lastly, we use an\nautoregressive integrated moving average (ARIMA) model to predict future\ntraffic for a user. Through simple visualization, we show that anomaly free\ndata better generalizes the learning models and performs better on prediction\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 19:37:56 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Sultan", "Kashif", ""], ["Ali", "Hazrat", ""], ["Zhang", "Zhongshan", ""]]}, {"id": "1807.11560", "submitter": "Monica Hernandez", "authors": "Monica Hernandez", "title": "Efficient Gauss-Newton-Krylov momentum conservation constrained\n  PDE-LDDMM using the band-limited vector field parameterization", "comments": "arXiv admin note: substantial text overlap with arXiv:1807.04638,\n  arXiv:1807.05117", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of non-rigid registration methods proposed in the framework of\nPDE-constrained Large Deformation Diffeomorphic Metric Mapping is a\nparticularly interesting family of physically meaningful diffeomorphic\nregistration methods. PDE-constrained LDDMM methods are formulated as\nconstrained variational problems, where the different physical models are\nimposed using the associated partial differential equations as hard\nconstraints. Inexact Newton-Krylov optimization has shown an excellent\nnumerical accuracy and an extraordinarily fast convergence rate in this\nframework. However, the Galerkin representation of the non-stationary velocity\nfields does not provide proper geodesic paths. In a previous work, we proposed\na method for PDE-constrained LDDMM parameterized in the space of initial\nvelocity fields under the EPDiff equation. The proposed method provided\ngeodesics in the framework of PDE-constrained LDDMM, and it showed performance\ncompetitive to benchmark PDE-constrained LDDMM and EPDiff-LDDMM methods.\nHowever, the major drawback of this method was the large memory load inherent\nto PDE-constrained LDDMM methods and the increased computational time with\nrespect to the benchmark methods. In this work we optimize the computational\ncomplexity of the method using the band-limited vector field parameterization\nclosing the loop with our previous works.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 10:19:47 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Hernandez", "Monica", ""]]}, {"id": "1807.11573", "submitter": "Pan Wei", "authors": "John E. Ball, Derek T. Anderson, Pan Wei", "title": "State-of-the-art and gaps for deep learning on limited training data in\n  remote sensing", "comments": "arXiv admin note: text overlap with arXiv:1709.00308", "journal-ref": "IGARSS June 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning usually requires big data, with respect to both volume and\nvariety. However, most remote sensing applications only have limited training\ndata, of which a small subset is labeled. Herein, we review three\nstate-of-the-art approaches in deep learning to combat this challenge. The\nfirst topic is transfer learning, in which some aspects of one domain, e.g.,\nfeatures, are transferred to another domain. The next is unsupervised learning,\ne.g., autoencoders, which operate on unlabeled data. The last is generative\nadversarial networks, which can generate realistic looking data that can fool\nthe likes of both a deep learning network and human. The aim of this article is\nto raise awareness of this dilemma, to direct the reader to existing work and\nto highlight current gaps that need solving.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 23:44:50 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Ball", "John E.", ""], ["Anderson", "Derek T.", ""], ["Wei", "Pan", ""]]}, {"id": "1807.11582", "submitter": "Patrick Huber", "authors": "Patrick Huber and Jan Niehues and Alex Waibel", "title": "A Hierarchical Approach to Neural Context-Aware Modeling", "comments": "8 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new recurrent neural network topology to enhance\nstate-of-the-art machine learning systems by incorporating a broader context.\nOur approach overcomes recent limitations with extended narratives through a\nmulti-layered computational approach to generate an abstract context\nrepresentation. Therefore, the developed system captures the narrative on\nword-level, sentence-level, and context-level. Through the hierarchical set-up,\nour proposed model summarizes the most salient information on each level and\ncreates an abstract representation of the extended context. We subsequently use\nthis representation to enhance neural language processing systems on the task\nof semantic error detection. To show the potential of the newly introduced\ntopology, we compare the approach against a context-agnostic set-up including a\nstandard neural language model and a supervised binary classification network.\nThe performance measures on the error detection task show the advantage of the\nhierarchical context-aware topologies, improving the baseline by 12.75%\nrelative for unsupervised models and 20.37% relative for supervised models.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 11:10:03 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 10:17:55 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Huber", "Patrick", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1807.11620", "submitter": "Qunwei Li", "authors": "Tiexing Wang, Qunwei Li, Donald J. Bucci, Yingbin Liang, Biao Chen,\n  Pramod K. Varshney", "title": "K-medoids Clustering of Data Sequences with Composite Distributions", "comments": "12 two-column pages, submitted to IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2019.2901370", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies clustering of data sequences using the k-medoids\nalgorithm. All the data sequences are assumed to be generated from\n\\emph{unknown} continuous distributions, which form clusters with each cluster\ncontaining a composite set of closely located distributions (based on a certain\ndistance metric between distributions). The maximum intra-cluster distance is\nassumed to be smaller than the minimum inter-cluster distance, and both values\nare assumed to be known. The goal is to group the data sequences together if\ntheir underlying generative distributions (which are unknown) belong to one\ncluster. Distribution distance metrics based k-medoids algorithms are proposed\nfor known and unknown number of distribution clusters. Upper bounds on the\nerror probability and convergence results in the large sample regime are also\nprovided. It is shown that the error probability decays exponentially fast as\nthe number of samples in each data sequence goes to infinity. The error\nexponent has a simple form regardless of the distance metric applied when\ncertain conditions are satisfied. In particular, the error exponent is\ncharacterized when either the Kolmogrov-Smirnov distance or the maximum mean\ndiscrepancy are used as the distance metric. Simulation results are provided to\nvalidate the analysis.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 01:10:04 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wang", "Tiexing", ""], ["Li", "Qunwei", ""], ["Bucci", "Donald J.", ""], ["Liang", "Yingbin", ""], ["Chen", "Biao", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1807.11622", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado, Marc G. Bellemare, Michael Bowling", "title": "Count-Based Exploration with the Successor Representation", "comments": "This paper appears in the Proceedings of the 34th AAAI Conference on\n  Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a simple approach for exploration in reinforcement\nlearning (RL) that allows us to develop theoretically justified algorithms in\nthe tabular case but that is also extendable to settings where function\napproximation is required. Our approach is based on the successor\nrepresentation (SR), which was originally introduced as a representation\ndefining state generalization by the similarity of successor states. Here we\nshow that the norm of the SR, while it is being learned, can be used as a\nreward bonus to incentivize exploration. In order to better understand this\ntransient behavior of the norm of the SR we introduce the substochastic\nsuccessor representation (SSR) and we show that it implicitly counts the number\nof times each state (or feature) has been observed. We use this result to\nintroduce an algorithm that performs as well as some theoretically\nsample-efficient approaches. Finally, we extend these ideas to a deep RL\nalgorithm and show that it achieves state-of-the-art performance in Atari 2600\ngames when in a low sample-complexity regime.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 01:25:44 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 02:56:53 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 16:24:45 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 16:48:02 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bellemare", "Marc G.", ""], ["Bowling", "Michael", ""]]}, {"id": "1807.11626", "submitter": "Mingxing Tan", "authors": "Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler,\n  Andrew Howard, Quoc V. Le", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile", "comments": "Published in CVPR 2019", "journal-ref": "CVPR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing convolutional neural networks (CNN) for mobile devices is\nchallenging because mobile models need to be small and fast, yet still\naccurate. Although significant efforts have been dedicated to design and\nimprove mobile CNNs on all dimensions, it is very difficult to manually balance\nthese trade-offs when there are so many architectural possibilities to\nconsider. In this paper, we propose an automated mobile neural architecture\nsearch (MNAS) approach, which explicitly incorporate model latency into the\nmain objective so that the search can identify a model that achieves a good\ntrade-off between accuracy and latency. Unlike previous work, where latency is\nconsidered via another, often inaccurate proxy (e.g., FLOPS), our approach\ndirectly measures real-world inference latency by executing the model on mobile\nphones. To further strike the right balance between flexibility and search\nspace size, we propose a novel factorized hierarchical search space that\nencourages layer diversity throughout the network. Experimental results show\nthat our approach consistently outperforms state-of-the-art mobile CNN models\nacross multiple vision tasks. On the ImageNet classification task, our MnasNet\nachieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x\nfaster than MobileNetV2 [29] with 0.5% higher accuracy and 2.3x faster than\nNASNet [36] with 1.2% higher accuracy. Our MnasNet also achieves better mAP\nquality than MobileNets for COCO object detection. Code is at\nhttps://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 01:34:21 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 17:10:45 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 01:30:05 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Tan", "Mingxing", ""], ["Chen", "Bo", ""], ["Pang", "Ruoming", ""], ["Vasudevan", "Vijay", ""], ["Sandler", "Mark", ""], ["Howard", "Andrew", ""], ["Le", "Quoc V.", ""]]}, {"id": "1807.11648", "submitter": "Alireza Rezaei", "authors": "Piotr Indyk, Sepideh Mahabadi, Shayan Oveis Gharan, Alireza Rezaei", "title": "Composable Core-sets for Determinant Maximization Problems via Spectral\n  Spanners", "comments": "To appear in SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a spectral generalization of classical combinatorial graph spanners\nto the spectral setting. Given a set of vectors $V\\subseteq \\Re^d$, we say a\nset $U\\subseteq V$ is an $\\alpha$-spectral spanner if for all $v\\in V$ there is\na probability distribution $\\mu_v$ supported on $U$ such that $$vv^\\intercal\n\\preceq \\alpha\\cdot\\mathbb{E}_{u\\sim\\mu_v} uu^\\intercal.$$ We show that any set\n$V$ has an $\\tilde{O}(d)$-spectral spanner of size $\\tilde{O}(d)$ and this\nbound is almost optimal in the worst case.\n  We use spectral spanners to study composable core-sets for spectral problems.\nWe show that for many objective functions one can use a spectral spanner,\nindependent of the underlying functions, as a core-set and obtain almost\noptimal composable core-sets. For example, for the determinant maximization\nproblem we obtain an $\\tilde{O}(k)^k$-composable core-set and we show that this\nis almost optimal in the worst case.\n  Our algorithm is a spectral analogue of the classical greedy algorithm for\nfinding (combinatorial) spanners in graphs. We expect that our spanners find\nmany other applications in distributed or parallel models of computation. Our\nproof is spectral. As a side result of our techniques, we show that the rank of\ndiagonally dominant lower-triangular matrices are robust under `small\nperturbations' which could be of independent interests.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 03:27:34 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 20:04:07 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Indyk", "Piotr", ""], ["Mahabadi", "Sepideh", ""], ["Gharan", "Shayan Oveis", ""], ["Rezaei", "Alireza", ""]]}, {"id": "1807.11655", "submitter": "Ho Bae", "authors": "Ho Bae, Jaehee Jang, Dahuin Jung, Hyemi Jang, Heonseok Ha, Hyungyu\n  Lee, Sungroh Yoon", "title": "Security and Privacy Issues in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To promote secure and private artificial intelligence (SPAI), we review\nstudies on the model security and data privacy of DNNs. Model security allows\nsystem to behave as intended without being affected by malicious external\ninfluences that can compromise its integrity and efficiency. Security attacks\ncan be divided based on when they occur: if an attack occurs during training,\nit is known as a poisoning attack, and if it occurs during inference (after\ntraining) it is termed an evasion attack. Poisoning attacks compromise the\ntraining process by corrupting the data with malicious examples, while evasion\nattacks use adversarial examples to disrupt entire classification process.\nDefenses proposed against such attacks include techniques to recognize and\nremove malicious data, train a model to be insensitive to such data, and mask\nthe model's structure and parameters to render attacks more challenging to\nimplement. Furthermore, the privacy of the data involved in model training is\nalso threatened by attacks such as the model-inversion attack, or by dishonest\nservice providers of AI applications. To maintain data privacy, several\nsolutions that combine existing data-privacy techniques have been proposed,\nincluding differential privacy and modern cryptography techniques. In this\npaper, we describe the notions of some of methods, e.g., homomorphic\nencryption, and review their advantages and challenges when implemented in\ndeep-learning models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 04:18:26 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 07:35:31 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 17:25:45 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 00:55:18 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Bae", "Ho", ""], ["Jang", "Jaehee", ""], ["Jung", "Dahuin", ""], ["Jang", "Hyemi", ""], ["Ha", "Heonseok", ""], ["Lee", "Hyungyu", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1807.11682", "submitter": "Asifullah Khan", "authors": "Asifullah Khan, Aneela Zameer, Tauseef Jamal, Ahmad Raza", "title": "Deep Belief Networks Based Feature Generation and Regression for\n  Predicting Wind Power", "comments": "Pages:31 Figure:11 Table:5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind energy forecasting helps to manage power production, and hence, reduces\nenergy cost. Deep Neural Networks (DNN) mimics hierarchical learning in the\nhuman brain and thus possesses hierarchical, distributed, and multi-task\nlearning capabilities. Based on aforementioned characteristics, we report Deep\nBelief Network (DBN) based forecast engine for wind power prediction because of\nits good generalization and unsupervised pre-training attributes. The proposed\nDBN-WP forecast engine, which exhibits stochastic feature generation\ncapabilities and is composed of multiple Restricted Boltzmann Machines,\ngenerates suitable features for wind power prediction using atmospheric\nproperties as input. DBN-WP, due to its unsupervised pre-training of RBM layers\nand generalization capabilities, is able to learn the fluctuations in the\nmeteorological properties and thus is able to perform effective mapping of the\nwind power. In the deep network, a regression layer is appended at the end to\npredict sort-term wind power. It is experimentally shown that the deep learning\nand unsupervised pre-training capabilities of DBN based model has comparable\nand in some cases better results than hybrid and complex learning techniques\nproposed for wind power prediction. The proposed prediction system based on\nDBN, achieves mean values of RMSE, MAE and SDE as 0.124, 0.083 and 0.122,\nrespectively. Statistical analysis of several independent executions of the\nproposed DBN-WP wind power prediction system demonstrates the stability of the\nsystem. The proposed DBN-WP architecture is easy to implement and offers\ngeneralization as regards the change in location of the wind farm is concerned.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 06:54:28 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Khan", "Asifullah", ""], ["Zameer", "Aneela", ""], ["Jamal", "Tauseef", ""], ["Raza", "Ahmad", ""]]}, {"id": "1807.11694", "submitter": "Zenan Ling", "authors": "Zenan Ling, Xing He, Robert C. Qiu", "title": "Spectrum concentration in deep residual learning: a free probability\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the initialization of deep residual networks (ResNets) by\nintroducing a novel analytical tool in free probability to the community of\ndeep learning. This tool deals with non-Hermitian random matrices, rather than\ntheir conventional Hermitian counterparts in the literature. As a consequence,\nthis new tool enables us to evaluate the singular value spectrum of the\ninput-output Jacobian of a fully-connected deep ResNet for both linear and\nnonlinear cases. With the powerful tool of free probability, we conduct an\nasymptotic analysis of the spectrum on the single-layer case, and then extend\nthis analysis to the multi-layer case of an arbitrary number of layers. In\nparticular, we propose to rescale the classical random initialization by the\nnumber of residual units, so that the spectrum has the order of $O(1)$, when\ncompared with the large width and depth of the network. We empirically\ndemonstrate that the proposed initialization scheme learns at a speed of orders\nof magnitudes faster than the classical ones, and thus attests a strong\npractical relevance of this investigation.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 07:49:59 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 10:34:20 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 09:43:46 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ling", "Zenan", ""], ["He", "Xing", ""], ["Qiu", "Robert C.", ""]]}, {"id": "1807.11697", "submitter": "Silvia Bucci", "authors": "Silvia Bucci, Mohammad Reza Loghmani and Barbara Caputo", "title": "Multimodal Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically a classifier trained on a given dataset (source domain) does not\nperforms well if it is tested on data acquired in a different setting (target\ndomain). This is the problem that domain adaptation (DA) tries to overcome and,\nwhile it is a well explored topic in computer vision, it is largely ignored in\nrobotic vision where usually visual classification methods are trained and\ntested in the same domain. Robots should be able to deal with unknown\nenvironments, recognize objects and use them in the correct way, so it is\nimportant to explore the domain adaptation scenario also in this context. The\ngoal of the project is to define a benchmark and a protocol for multi-modal\ndomain adaptation that is valuable for the robot vision community. With this\npurpose some of the state-of-the-art DA methods are selected: Deep Adaptation\nNetwork (DAN), Domain Adversarial Training of Neural Network (DANN), Automatic\nDomain Alignment Layers (AutoDIAL) and Adversarial Discriminative Domain\nAdaptation (ADDA). Evaluations have been done using different data types: RGB\nonly, depth only and RGB-D over the following datasets, designed for the\nrobotic community: RGB-D Object Dataset (ROD), Web Object Dataset (WOD),\nAutonomous Robot Indoor Dataset (ARID), Big Berkeley Instance Recognition\nDataset (BigBIRD) and Active Vision Dataset. Although progresses have been made\non the formulation of effective adaptation algorithms and more realistic object\ndatasets are available, the results obtained show that, training a sufficiently\ngood object classifier, especially in the domain adaptation scenario, is still\nan unsolved problem. Also the best way to combine depth with RGB informations\nto improve the performance is a point that needs to be investigated more.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 08:08:40 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Bucci", "Silvia", ""], ["Loghmani", "Mohammad Reza", ""], ["Caputo", "Barbara", ""]]}, {"id": "1807.11698", "submitter": "Guy Hadash", "authors": "Guy Hadash, Oren Sar Shalom, Rita Osadchy", "title": "Rank and Rate: Multi-task Learning for Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3240323.3240406", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two main tasks in the Recommender Systems domain are the ranking and\nrating prediction tasks. The rating prediction task aims at predicting to what\nextent a user would like any given item, which would enable to recommend the\nitems with the highest predicted scores. The ranking task on the other hand\ndirectly aims at recommending the most valuable items for the user. Several\nprevious approaches proposed learning user and item representations to optimize\nboth tasks simultaneously in a multi-task framework. In this work we propose a\nnovel multi-task framework that exploits the fact that a user does a two-phase\ndecision process - first decides to interact with an item (ranking task) and\nonly afterward to rate it (rating prediction task). We evaluated our framework\non two benchmark datasets, on two different configurations and showed its\nsuperiority over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 08:16:08 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Hadash", "Guy", ""], ["Shalom", "Oren Sar", ""], ["Osadchy", "Rita", ""]]}, {"id": "1807.11718", "submitter": "Sergul Aydore", "authors": "Sergul Aydore, Bertrand Thirion, Gael Varoquaux", "title": "Feature Grouping as a Stochastic Regularizer for High-Dimensional\n  Structured Data", "comments": "12 pages, 14 figures", "journal-ref": "ICML2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications where collecting data is expensive, for example\nneuroscience or medical imaging, the sample size is typically small compared to\nthe feature dimension. It is challenging in this setting to train expressive,\nnon-linear models without overfitting. These datasets call for intelligent\nregularization that exploits known structure, such as correlations between the\nfeatures arising from the measurement device. However, existing structured\nregularizers need specially crafted solvers, which are difficult to apply to\ncomplex models. We propose a new regularizer specifically designed to leverage\nstructure in the data in a way that can be applied efficiently to complex\nmodels. Our approach relies on feature grouping, using a fast clustering\nalgorithm inside a stochastic gradient descent loop: given a family of feature\ngroupings that capture feature covariations, we randomly select these groups at\neach iteration. We show that this approach amounts to enforcing a denoising\nregularizer on the solution. The method is easy to implement in many model\narchitectures, such as fully connected neural networks, and has a linear\ncomputational cost. We apply this regularizer to a real-world fMRI dataset and\nthe Olivetti Faces datasets. Experiments on both datasets demonstrate that the\nproposed approach produces models that generalize better than those trained\nwith conventional regularizers, and also improves convergence speed.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 09:33:58 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 16:48:16 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Aydore", "Sergul", ""], ["Thirion", "Bertrand", ""], ["Varoquaux", "Gael", ""]]}, {"id": "1807.11722", "submitter": "Soumitro Chakrabarty", "authors": "Soumitro Chakrabarty and Emanu\\\"el A. P. Habets", "title": "Multi-Speaker DOA Estimation Using Deep Convolutional Networks Trained\n  with Noise Signals", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2019.2901664", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning based methods for source localization, being data driven,\ncan be adapted to different acoustic conditions via training and have been\nshown to be robust to adverse acoustic environments. In this paper, a\nconvolutional neural network (CNN) based supervised learning method for\nestimating the direction-of-arrival (DOA) of multiple speakers is proposed.\nMulti-speaker DOA estimation is formulated as a multi-class multi-label\nclassification problem, where the assignment of each DOA label to the input\nfeature is treated as a separate binary classification problem. The phase\ncomponent of the short-time Fourier transform (STFT) coefficients of the\nreceived microphone signals are directly fed into the CNN, and the features for\nDOA estimation are learnt during training. Utilizing the assumption of disjoint\nspeaker activity in the STFT domain, a novel method is proposed to train the\nCNN with synthesized noise signals. Through experimental evaluation with both\nsimulated and measured acoustic impulse responses, the ability of the proposed\nDOA estimation approach to adapt to unseen acoustic conditions and its\nrobustness to unseen noise type is demonstrated. Through additional empirical\ninvestigation, it is also shown that with an array of M microphones our\nproposed framework yields the best localization performance with M-1\nconvolution layers. The ability of the proposed method to accurately localize\nspeakers in a dynamic acoustic scenario with varying number of sources is also\nshown.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 09:40:39 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Chakrabarty", "Soumitro", ""], ["Habets", "Emanu\u00ebl A. P.", ""]]}, {"id": "1807.11790", "submitter": "Zhihui Xie", "authors": "Gang Bai, Zhihui Xie, Liang Wang", "title": "Practical Constrained Optimization of Auction Mechanisms in E-Commerce\n  Sponsored Search Advertising", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search in E-commerce platforms such as Amazon, Taobao and Tmall\nprovides sellers an effective way to reach potential buyers with most relevant\npurpose. In this paper, we study the auction mechanism optimization problem in\nsponsored search on Alibaba's mobile E-commerce platform. Besides generating\nrevenue, we are supposed to maintain an efficient marketplace with plenty of\nquality users, guarantee a reasonable return on investment (ROI) for\nadvertisers, and meanwhile, facilitate a pleasant shopping experience for the\nusers. These requirements essentially pose a constrained optimization problem.\nDirectly optimizing over auction parameters yields a discontinuous, non-convex\nproblem that denies effective solutions. One of our major contribution is a\npractical convex optimization formulation of the original problem. We devise a\nnovel re-parametrization of auction mechanism with discrete sets of\nrepresentative instances. To construct the optimization problem, we build an\nauction simulation system which estimates the resulted business indicators of\nthe selected parameters by replaying the auctions recorded from real online\nrequests. We summarized the experiments on real search traffics to analyze the\neffects of fidelity of auction simulation, the efficacy under various\nconstraint targets and the influence of regularization. The experiment results\nshow that with proper entropy regularization, we are able to maximize revenue\nwhile constraining other business indicators within given ranges.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 12:42:46 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Bai", "Gang", ""], ["Xie", "Zhihui", ""], ["Wang", "Liang", ""]]}, {"id": "1807.11805", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris and Francesc X. Prenafeta-Bold\\'u", "title": "Disaster Monitoring using Unmanned Aerial Vehicles and Deep Learning", "comments": "Disaster Management for Resilience and Public Safety Workshop, Proc.\n  of EnviroInfo 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring of disasters is crucial for mitigating their effects on the\nenvironment and human population, and can be facilitated by the use of unmanned\naerial vehicles (UAV), equipped with camera sensors that produce aerial photos\nof the areas of interest. A modern technique for recognition of events based on\naerial photos is deep learning. In this paper, we present the state of the art\nwork related to the use of deep learning techniques for disaster\nidentification. We demonstrate the potential of this technique in identifying\ndisasters with high accuracy, by means of a relatively simple deep learning\nmodel. Based on a dataset of 544 images (containing disaster images such as\nfires, earthquakes, collapsed buildings, tsunami and flooding, as well as\nnon-disaster scenes), our results show an accuracy of 91% achieved, indicating\nthat deep learning, combined with UAV equipped with camera sensors, have the\npotential to predict disasters with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 13:24:31 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 09:29:37 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Prenafeta-Bold\u00fa", "Francesc X.", ""]]}, {"id": "1807.11809", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris and Francesc X. Prenafeta-Boldu", "title": "Deep learning in agriculture: A survey", "comments": null, "journal-ref": "Computers and Electronics in Agriculture International Journal,\n  2018", "doi": "10.1016/j.compag.2018.02.016", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning constitutes a recent, modern technique for image processing and\ndata analysis, with promising results and large potential. As deep learning has\nbeen successfully applied in various domains, it has recently entered also the\ndomain of agriculture. In this paper, we perform a survey of 40 research\nefforts that employ deep learning techniques, applied to various agricultural\nand food production challenges. We examine the particular agricultural problems\nunder study, the specific models and frameworks employed, the sources, nature\nand pre-processing of data used, and the overall performance achieved according\nto the metrics used at each work under study. Moreover, we study comparisons of\ndeep learning with other existing popular techniques, in respect to differences\nin classification or regression performance. Our findings indicate that deep\nlearning provides high accuracy, outperforming existing commonly used image\nprocessing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 13:30:03 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Prenafeta-Boldu", "Francesc X.", ""]]}, {"id": "1807.11824", "submitter": "David Chan", "authors": "David M. Chan, Roshan Rao, Forrest Huang, John F. Canny", "title": "t-SNE-CUDA: GPU-Accelerated t-SNE and its Applications to Modern Data", "comments": "To appear in HPML 2018 High Performance Machine Learning Workshop\n  (Accepted, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern datasets and models are notoriously difficult to explore and analyze\ndue to their inherent high dimensionality and massive numbers of samples.\nExisting visualization methods which employ dimensionality reduction to two or\nthree dimensions are often inefficient and/or ineffective for these datasets.\nThis paper introduces t-SNE-CUDA, a GPU-accelerated implementation of\nt-distributed Symmetric Neighbor Embedding (t-SNE) for visualizing datasets and\nmodels. t-SNE-CUDA significantly outperforms current implementations with\n50-700x speedups on the CIFAR-10 and MNIST datasets. These speedups enable, for\nthe first time, visualization of the neural network activations on the entire\nImageNet dataset - a feat that was previously computationally intractable. We\nalso demonstrate visualization performance in the NLP domain by visualizing the\nGloVe embedding vectors. From these visualizations, we can draw interesting\nconclusions about using the L2 metric in these embedding spaces. t-SNE-CUDA is\npublicly available athttps://github.com/CannyLab/tsne-cuda\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 14:04:33 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Chan", "David M.", ""], ["Rao", "Roshan", ""], ["Huang", "Forrest", ""], ["Canny", "John F.", ""]]}, {"id": "1807.11836", "submitter": "Jean Pierre Char", "authors": "Jean Pierre Char", "title": "Inferring the ground truth through crowdsourcing", "comments": "6 pages, 1 figure, Intelligent Systems seminar SS18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universally valid ground truth is almost impossible to obtain or would come\nat a very high cost. For supervised learning without universally valid ground\ntruth, a recommended approach is applying crowdsourcing: Gathering a large data\nset annotated by multiple individuals of varying possibly expertise levels and\ninferring the ground truth data to be used as labels to train the classifier.\nNevertheless, due to the sensitivity of the problem at hand (e.g. mitosis\ndetection in breast cancer histology images), the obtained data needs\nverification and proper assessment before being used for classifier training.\nEven in the context of organic computing systems, an indisputable ground truth\nmight not always exist. Therefore, it should be inferred through the\naggregation and verification of the local knowledge of each autonomous agent.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 14:21:32 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Char", "Jean Pierre", ""]]}, {"id": "1807.11876", "submitter": "Emma Frejinger", "authors": "Eric Larsen, S\\'ebastien Lachapelle, Yoshua Bengio, Emma Frejinger,\n  Simon Lacoste-Julien, Andrea Lodi", "title": "Predicting Tactical Solutions to Operational Planning Problems under\n  Imperfect Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict expected tactical descriptions of operational solutions\n(TDOSs). The problem we address occurs in the context of two-stage stochastic\nprogramming where the second stage is demanding computationally. We aim to\npredict at a high speed the expected TDOS associated with the second stage\nproblem, conditionally on the first stage variables. This may be used in\nsupport of the solution to the overall two-stage problem by avoiding the online\ngeneration of multiple second stage scenarios and solutions. We formulate the\ntactical prediction problem as a stochastic optimal prediction program, whose\nsolution we approximate with supervised machine learning. The training dataset\nconsists of a large number of deterministic operational problems generated by\ncontrolled probabilistic sampling. The labels are computed based on solutions\nto these problems (solved independently and offline), employing appropriate\naggregation and subselection methods to address uncertainty. Results on our\nmotivating application on load planning for rail transportation show that deep\nlearning models produce accurate predictions in very short computing time\n(milliseconds or less). The predictive accuracy is close to the lower bounds\ncalculated based on sample average approximation of the stochastic prediction\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 15:39:37 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 10:32:07 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 00:55:53 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 14:19:29 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Larsen", "Eric", ""], ["Lachapelle", "S\u00e9bastien", ""], ["Bengio", "Yoshua", ""], ["Frejinger", "Emma", ""], ["Lacoste-Julien", "Simon", ""], ["Lodi", "Andrea", ""]]}, {"id": "1807.11880", "submitter": "Jie Chen", "authors": "Jie Chen, Ronny Luss", "title": "Stochastic Gradient Descent with Biased but Consistent Gradient\n  Estimators", "comments": "Companion codes are at\n  https://github.com/jiechenjiechen/FastGCN-matlab", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD), which dates back to the 1950s, is one of\nthe most popular and effective approaches for performing stochastic\noptimization. Research on SGD resurged recently in machine learning for\noptimizing convex loss functions and training nonconvex deep neural networks.\nThe theory assumes that one can easily compute an unbiased gradient estimator,\nwhich is usually the case due to the sample average nature of empirical risk\nminimization. There exist, however, many scenarios (e.g., graphs) where an\nunbiased estimator may be as expensive to compute as the full gradient because\ntraining examples are interconnected. Recently, Chen et al. (2018) proposed\nusing a consistent gradient estimator as an economic alternative. Encouraged by\nempirical success, we show, in a general setting, that consistent estimators\nresult in the same convergence behavior as do unbiased ones. Our analysis\ncovers strongly convex, convex, and nonconvex objectives. We verify the results\nwith illustrative experiments on synthetic and real-world data. This work opens\nseveral new research directions, including the development of more efficient\nSGD updates with consistent estimators and the design of efficient training\nalgorithms for large-scale graphs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 15:51:08 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 18:10:51 GMT"}, {"version": "v3", "created": "Sat, 19 Jan 2019 05:48:36 GMT"}, {"version": "v4", "created": "Mon, 23 Dec 2019 15:03:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chen", "Jie", ""], ["Luss", "Ronny", ""]]}, {"id": "1807.11916", "submitter": "Michael Andrews", "authors": "Michael Andrews, Manfred Paulini, Sergei Gleyzer, Barnabas Poczos", "title": "End-to-End Physics Event Classification with CMS Open Data: Applying\n  Image-Based Deep Learning to Detector Data for the Direct Classification of\n  Collision Events at the LHC", "comments": "14 pages, 5 figures; v3: published version", "journal-ref": "Comput Softw Big Sci 4, 6 (2020)", "doi": "10.1007/s41781-020-00038-8", "report-no": null, "categories": "physics.data-an cs.CV cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the construction of novel end-to-end image-based\nclassifiers that directly leverage low-level simulated detector data to\ndiscriminate signal and background processes in pp collision events at the\nLarge Hadron Collider at CERN. To better understand what end-to-end classifiers\nare capable of learning from the data and to address a number of associated\nchallenges, we distinguish the decay of the standard model Higgs boson into two\nphotons from its leading background sources using high-fidelity simulated CMS\nOpen Data. We demonstrate the ability of end-to-end classifiers to learn from\nthe angular distribution of the photons recorded as electromagnetic showers,\ntheir intrinsic shapes, and the energy of their constituent hits, even when the\nunderlying particles are not fully resolved, delivering a clear advantage in\nsuch cases over purely kinematics-based classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 16:52:07 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 21:17:04 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 23:14:06 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Andrews", "Michael", ""], ["Paulini", "Manfred", ""], ["Gleyzer", "Sergei", ""], ["Poczos", "Barnabas", ""]]}]