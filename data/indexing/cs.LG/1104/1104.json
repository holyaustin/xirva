[{"id": "1104.0111", "submitter": "Yi Gai", "authors": "Yi Gai and Bhaskar Krishnamachari", "title": "Decentralized Online Learning Algorithms for Opportunistic Spectrum\n  Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental problem of multiple secondary users contending for\nopportunistic spectrum access over multiple channels in cognitive radio\nnetworks has been formulated recently as a decentralized multi-armed bandit\n(D-MAB) problem. In a D-MAB problem there are $M$ users and $N$ arms (channels)\nthat each offer i.i.d. stochastic rewards with unknown means so long as they\nare accessed without collision. The goal is to design a decentralized online\nlearning policy that incurs minimal regret, defined as the difference between\nthe total expected rewards accumulated by a model-aware genie, and that\nobtained by all users applying the policy. We make two contributions in this\npaper. First, we consider the setting where the users have a prioritized\nranking, such that it is desired for the $K$-th-ranked user to learn to access\nthe arm offering the $K$-th highest mean reward. For this problem, we present\nthe first distributed policy that yields regret that is uniformly logarithmic\nover time without requiring any prior assumption about the mean rewards.\nSecond, we consider the case when a fair access policy is required, i.e., it is\ndesired for all users to experience the same mean reward. For this problem, we\npresent a distributed policy that yields order-optimal regret scaling with\nrespect to the number of users and arms, better than previously proposed\npolicies in the literature. Both of our distributed policies make use of an\ninnovative modification of the well known UCB1 policy for the classic\nmulti-armed bandit problem that allows a single user to learn how to play the\narm that yields the $K$-th largest mean reward.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2011 08:48:54 GMT"}], "update_date": "2011-04-04", "authors_parsed": [["Gai", "Yi", ""], ["Krishnamachari", "Bhaskar", ""]]}, {"id": "1104.0235", "submitter": "Ido Ginodi", "authors": "Ido Ginodi, Amir Globerson", "title": "Gaussian Robust Classification", "comments": "Master's dissertation of the first author, carried out under the\n  supervision of the second author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning is all about the ability to generalize knowledge.\nSpecifically, the goal of the learning is to train a classifier using training\ndata, in such a way that it will be capable of classifying new unseen data\ncorrectly. In order to acheive this goal, it is important to carefully design\nthe learner, so it will not overfit the training data. The later can is done\nusually by adding a regularization term. The statistical learning theory\nexplains the success of this method by claiming that it restricts the\ncomplexity of the learned model. This explanation, however, is rather abstract\nand does not have a geometric intuition. The generalization error of a\nclassifier may be thought of as correlated with its robustness to perturbations\nof the data: a classifier that copes with disturbance is expected to generalize\nwell. Indeed, Xu et al. [2009] have shown that the SVM formulation is\nequivalent to a robust optimization (RO) formulation, in which an adversary\ndisplaces the training and testing points within a ball of pre-determined\nradius. In this work we explore a different kind of robustness, namely changing\neach data point with a Gaussian cloud centered at the sample. Loss is evaluated\nas the expectation of an underlying loss function on the cloud. This setup fits\nthe fact that in many applications, the data is sampled along with noise. We\ndevelop an RO framework, in which the adversary chooses the covariance of the\nnoise. In our algorithm named GURU, the tuning parameter is a spectral bound on\nthe noise, thus it can be estimated using physical or applicative\nconsiderations. Our experiments show that this framework performs as well as\nSVM and even slightly better in some cases. Generalizations for Mercer kernels\nand for the multiclass case are presented as well. We also show that our\nframework may be further generalized, using the technique of convex perspective\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2011 19:33:05 GMT"}], "update_date": "2011-04-04", "authors_parsed": [["Ginodi", "Ido", ""], ["Globerson", "Amir", ""]]}, {"id": "1104.0651", "submitter": "Mariano Tepper", "authors": "Mariano Tepper, Pablo Mus\\'e, Andr\\'es Almansa", "title": "Meaningful Clustered Forest: an Automatic and Robust Clustering\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new clustering technique that can be regarded as a numerical\nmethod to compute the proximity gestalt. The method analyzes edge length\nstatistics in the MST of the dataset and provides an a contrario cluster\ndetection criterion. The approach is fully parametric on the chosen distance\nand can detect arbitrarily shaped clusters. The method is also automatic, in\nthe sense that only a single parameter is left to the user. This parameter has\nan intuitive interpretation as it controls the expected number of false\ndetections. We show that the iterative application of our method can (1)\nprovide robustness to noise and (2) solve a masking phenomenon in which a\nhighly populated and salient cluster dominates the scene and inhibits the\ndetection of less-populated, but still salient, clusters.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2011 19:04:25 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2011 22:30:03 GMT"}, {"version": "v3", "created": "Tue, 19 Jul 2011 14:39:35 GMT"}], "update_date": "2011-07-20", "authors_parsed": [["Tepper", "Mariano", ""], ["Mus\u00e9", "Pablo", ""], ["Almansa", "Andr\u00e9s", ""]]}, {"id": "1104.0729", "submitter": "Afshin Rostamizadeh", "authors": "Afshin Rostamizadeh, Alekh Agarwal, Peter Bartlett", "title": "Online and Batch Learning Algorithms for Data with Missing Features", "comments": null, "journal-ref": "27th Conference on Uncertainty in Artificial Intelligence (UAI\n  2011)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new online and batch algorithms that are robust to data with\nmissing features, a situation that arises in many practical applications. In\nthe online setup, we allow for the comparison hypothesis to change as a\nfunction of the subset of features that is observed on any given round,\nextending the standard setting where the comparison hypothesis is fixed\nthroughout. In the batch setup, we present a convex relation of a non-convex\nproblem to jointly estimate an imputation function, used to fill in the values\nof missing features, along with the classification hypothesis. We prove regret\nbounds in the online setting and Rademacher complexity bounds for the batch\ni.i.d. setting. The algorithms are tested on several UCI datasets, showing\nsuperior performance over baselines.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2011 04:28:51 GMT"}, {"version": "v2", "created": "Mon, 2 May 2011 05:24:55 GMT"}, {"version": "v3", "created": "Sat, 21 May 2011 18:17:23 GMT"}, {"version": "v4", "created": "Thu, 16 Jun 2011 15:40:28 GMT"}], "update_date": "2012-02-19", "authors_parsed": [["Rostamizadeh", "Afshin", ""], ["Agarwal", "Alekh", ""], ["Bartlett", "Peter", ""]]}, {"id": "1104.1436", "submitter": "Massimiliano Pontil", "authors": "Andreas Argyriou, Charles A. Micchelli, Massimiliano Pontil, Lixin\n  Shen, Yuesheng Xu", "title": "Efficient First Order Methods for Linear Composite Regularizers", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide class of regularization problems in machine learning and statistics\nemploy a regularization term which is obtained by composing a simple convex\nfunction \\omega with a linear transformation. This setting includes Group Lasso\nmethods, the Fused Lasso and other total variation methods, multi-task learning\nmethods and many more. In this paper, we present a general approach for\ncomputing the proximity operator of this class of regularizers, under the\nassumption that the proximity operator of the function \\omega is known in\nadvance. Our approach builds on a recent line of research on optimal first\norder optimization methods and uses fixed point iterations for numerically\ncomputing the proximity operator. It is more general than current approaches\nand, as we show with numerical simulations, computationally more efficient than\navailable first order methods which do not achieve the optimal rate. In\nparticular, our method outperforms state of the art O(1/T) methods for\noverlapping Group Lasso and matches optimal O(1/T^2) methods for the Fused\nLasso and tree structured Group Lasso.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2011 20:05:48 GMT"}], "update_date": "2011-04-11", "authors_parsed": [["Argyriou", "Andreas", ""], ["Micchelli", "Charles A.", ""], ["Pontil", "Massimiliano", ""], ["Shen", "Lixin", ""], ["Xu", "Yuesheng", ""]]}, {"id": "1104.1450", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker", "title": "Plug-in Approach to Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new active learning algorithm based on nonparametric estimators\nof the regression function. Our investigation provides probabilistic bounds for\nthe rates of convergence of the generalization error achievable by proposed\nmethod over a broad class of underlying distributions. We also prove minimax\nlower bounds which show that the obtained rates are almost tight.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2011 21:54:09 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2011 03:20:06 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Minsker", "Stanislav", ""]]}, {"id": "1104.1672", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Sham M. Kakade, Tong Zhang", "title": "Dimension-free tail inequalities for sums of random matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive exponential tail inequalities for sums of random matrices with no\ndependence on the explicit matrix dimensions. These are similar to the matrix\nversions of the Chernoff bound and Bernstein inequality except with the\nexplicit matrix dimensions replaced by a trace quantity that can be small even\nwhen the dimension is large or infinite. Some applications to principal\ncomponent analysis and approximate matrix multiplication are given to\nillustrate the utility of the new bounds.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2011 04:25:04 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2011 05:51:47 GMT"}, {"version": "v3", "created": "Sat, 16 Apr 2011 04:17:23 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Zhang", "Tong", ""]]}, {"id": "1104.1872", "submitter": "Julien Mairal", "authors": "Julien Mairal, Rodolphe Jenatton (LIENS, INRIA Paris - Rocquencourt),\n  Guillaume Obozinski (LIENS, INRIA Paris - Rocquencourt), Francis Bach (LIENS,\n  INRIA Paris - Rocquencourt)", "title": "Convex and Network Flow Optimization for Structured Sparsity", "comments": "to appear in the Journal of Machine Learning Research (JMLR)", "journal-ref": "Journal of Machine Learning Research 12 (2011) 2681?2720", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of learning problems regularized by a structured\nsparsity-inducing norm defined as the sum of l_2- or l_infinity-norms over\ngroups of variables. Whereas much effort has been put in developing fast\noptimization techniques when the groups are disjoint or embedded in a\nhierarchy, we address here the case of general overlapping groups. To this end,\nwe present two different strategies: On the one hand, we show that the proximal\noperator associated with a sum of l_infinity-norms can be computed exactly in\npolynomial time by solving a quadratic min-cost flow problem, allowing the use\nof accelerated proximal gradient methods. On the other hand, we use proximal\nsplitting techniques, and address an equivalent formulation with\nnon-overlapping groups, but in higher dimension and with additional\nconstraints. We propose efficient and scalable algorithms exploiting these two\nstrategies, which are significantly faster than alternative approaches. We\nillustrate these methods with several problems such as CUR matrix\nfactorization, multi-task learning of tree-structured dictionaries, background\nsubtraction in video sequences, image denoising with wavelets, and topographic\ndictionary learning of natural image patches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 08:04:59 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2011 05:29:41 GMT"}, {"version": "v3", "created": "Fri, 16 Sep 2011 05:26:00 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Mairal", "Julien", "", "LIENS, INRIA Paris - Rocquencourt"], ["Jenatton", "Rodolphe", "", "LIENS, INRIA Paris - Rocquencourt"], ["Obozinski", "Guillaume", "", "LIENS, INRIA Paris - Rocquencourt"], ["Bach", "Francis", "", "LIENS,\n  INRIA Paris - Rocquencourt"]]}, {"id": "1104.1990", "submitter": "Kevin Xu", "authors": "Kevin S. Xu, Mark Kliger, Alfred O. Hero III", "title": "Adaptive Evolutionary Clustering", "comments": "To appear in Data Mining and Knowledge Discovery, MATLAB toolbox\n  available at http://tbayes.eecs.umich.edu/xukevin/affect", "journal-ref": "Data Mining and Knowledge Discovery 28 (2014) 304-336", "doi": "10.1007/s10618-012-0302-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical applications of clustering, the objects to be clustered\nevolve over time, and a clustering result is desired at each time step. In such\napplications, evolutionary clustering typically outperforms traditional static\nclustering by producing clustering results that reflect long-term trends while\nbeing robust to short-term variations. Several evolutionary clustering\nalgorithms have recently been proposed, often by adding a temporal smoothness\npenalty to the cost function of a static clustering method. In this paper, we\nintroduce a different approach to evolutionary clustering by accurately\ntracking the time-varying proximities between objects followed by static\nclustering. We present an evolutionary clustering framework that adaptively\nestimates the optimal smoothing parameter using shrinkage estimation, a\nstatistical approach that improves a naive estimate using additional\ninformation. The proposed framework can be used to extend a variety of static\nclustering algorithms, including hierarchical, k-means, and spectral\nclustering, into evolutionary clustering algorithms. Experiments on synthetic\nand real data sets indicate that the proposed framework outperforms static\nclustering and existing evolutionary clustering algorithms in many scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 16:38:50 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2012 22:35:53 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 16:17:49 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Xu", "Kevin S.", ""], ["Kliger", "Mark", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1104.2018", "submitter": "Varun Kanade", "authors": "Sham Kakade and Adam Tauman Kalai and Varun Kanade and Ohad Shamir", "title": "Efficient Learning of Generalized Linear and Single Index Models with\n  Isotonic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Linear Models (GLMs) and Single Index Models (SIMs) provide\npowerful generalizations of linear regression, where the target variable is\nassumed to be a (possibly unknown) 1-dimensional function of a linear\npredictor. In general, these problems entail non-convex estimation procedures,\nand, in practice, iterative local search heuristics are often used. Kalai and\nSastry (2009) recently provided the first provably efficient method for\nlearning SIMs and GLMs, under the assumptions that the data are in fact\ngenerated under a GLM and under certain monotonicity and Lipschitz constraints.\nHowever, to obtain provable performance, the method requires a fresh sample\nevery iteration. In this paper, we provide algorithms for learning GLMs and\nSIMs, which are both computationally and statistically efficient. We also\nprovide an empirical study, demonstrating their feasibility in practice.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 18:24:01 GMT"}], "update_date": "2011-04-14", "authors_parsed": [["Kakade", "Sham", ""], ["Kalai", "Adam Tauman", ""], ["Kanade", "Varun", ""], ["Shamir", "Ohad", ""]]}, {"id": "1104.2097", "submitter": "Vladimir Pestov", "authors": "Vladimir Pestov", "title": "PAC learnability versus VC dimension: a footnote to a basic result of\n  statistical learning", "comments": "Revised submission to IJCNN'2011", "journal-ref": "Proc. 2011 International Joint Confernce on Neural Networks\n  (IJCNN'2011), San Jose, CA (July 30 - Aug. 5, 2011), pp. 1141 - 1145", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental result of statistical learnig theory states that a concept\nclass is PAC learnable if and only if it is a uniform Glivenko-Cantelli class\nif and only if the VC dimension of the class is finite. However, the theorem is\nonly valid under special assumptions of measurability of the class, in which\ncase the PAC learnability even becomes consistent. Otherwise, there is a\nclassical example, constructed under the Continuum Hypothesis by Dudley and\nDurst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a\nconcept class of VC dimension one which is neither uniform Glivenko-Cantelli\nnor consistently PAC learnable. We show that, rather surprisingly, under an\nadditional set-theoretic hypothesis which is much milder than the Continuum\nHypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC\ndimension for every concept class.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2011 01:15:03 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Pestov", "Vladimir", ""]]}, {"id": "1104.2580", "submitter": "Diego Rother", "authors": "Diego Rother, Simon Sch\\\"utz, Ren\\'e Vidal", "title": "Hypothesize and Bound: A Computational Focus of Attention Mechanism for\n  Simultaneous N-D Segmentation, Pose Estimation and Classification Using Shape\n  Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the ever increasing bandwidth of the visual information available to\nmany intelligent systems, it is becoming essential to endow them with a sense\nof what is worthwhile their attention and what can be safely disregarded. This\narticle presents a general mathematical framework to efficiently allocate the\navailable computational resources to process the parts of the input that are\nrelevant to solve a given perceptual problem. By this we mean to find the\nhypothesis H (i.e., the state of the world) that maximizes a function L(H),\nrepresenting how well each hypothesis \"explains\" the input. Given the large\nbandwidth of the sensory input, fully evaluating L(H) for each hypothesis H is\ncomputationally infeasible (e.g., because it would imply checking a large\nnumber of pixels). To address this problem we propose a mathematical framework\nwith two key ingredients. The first one is a Bounding Mechanism (BM) to compute\nlower and upper bounds of L(H), for a given computational budget. These bounds\nare much cheaper to compute than L(H) itself, can be refined at any time by\nincreasing the budget allocated to a hypothesis, and are frequently enough to\ndiscard a hypothesis. To compute these bounds, we develop a novel theory of\nshapes and shape priors. The second ingredient is a Focus of Attention\nMechanism (FoAM) to select which hypothesis' bounds should be refined next,\nwith the goal of discarding non-optimal hypotheses with the least amount of\ncomputation. The proposed framework: 1) is very efficient since most hypotheses\nare discarded with minimal computation; 2) is parallelizable; 3) is guaranteed\nto find the globally optimal hypothesis; and 4) its running time depends on the\nproblem at hand, not on the bandwidth of the input. We instantiate the proposed\nframework for the problem of simultaneously estimating the class, pose, and a\nnoiseless version of a 2D shape in a 2D image.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 18:59:52 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2011 19:31:24 GMT"}], "update_date": "2011-08-16", "authors_parsed": [["Rother", "Diego", ""], ["Sch\u00fctz", "Simon", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1104.2930", "submitter": "Donghui Yan", "authors": "Donghui Yan, Aiyou Chen, Michael I. Jordan", "title": "Cluster Forests", "comments": "23 pages, 6 figures", "journal-ref": "Computational Statistics and Data Analysis 2013, Vol. 66, 178-192", "doi": "10.1016/j.csda.2013.04.010", "report-no": "COMSTA5571", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With inspiration from Random Forests (RF) in the context of classification, a\nnew clustering ensemble method---Cluster Forests (CF) is proposed.\nGeometrically, CF randomly probes a high-dimensional data cloud to obtain \"good\nlocal clusterings\" and then aggregates via spectral clustering to obtain\ncluster assignments for the whole dataset. The search for good local\nclusterings is guided by a cluster quality measure kappa. CF progressively\nimproves each local clustering in a fashion that resembles the tree growth in\nRF. Empirical studies on several real-world datasets under two different\nperformance metrics show that CF compares favorably to its competitors.\nTheoretical analysis reveals that the kappa measure makes it possible to grow\nthe local clustering in a desirable way---it is \"noise-resistant\". A\nclosed-form expression is obtained for the mis-clustering rate of spectral\nclustering under a perturbation model, which yields new insights into some\naspects of spectral clustering.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 21:29:10 GMT"}, {"version": "v2", "created": "Mon, 18 Apr 2011 05:06:04 GMT"}, {"version": "v3", "created": "Thu, 23 May 2013 21:17:26 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Yan", "Donghui", ""], ["Chen", "Aiyou", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1104.3248", "submitter": "Max Neff", "authors": "M. Neff, G. Anton, A. Enzenh\\\"ofer, K. Graf, J. H\\\"o{\\ss}l, U. Katz,\n  R. Lahmann and C. Richardt", "title": "Signal Classification for Acoustic Neutrino Detection", "comments": "8 Pages, 6 Figures, ARENA 2010 Conference Proceedings", "journal-ref": null, "doi": "10.1016/j.nima.2010.11.016", "report-no": null, "categories": "astro-ph.IM cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses on signal classification for deep-sea acoustic neutrino\ndetection. In the deep sea, the background of transient signals is very\ndiverse. Approaches like matched filtering are not sufficient to distinguish\nbetween neutrino-like signals and other transient signals with similar\nsignature, which are forming the acoustic background for neutrino detection in\nthe deep-sea environment. A classification system based on machine learning\nalgorithms is analysed with the goal to find a robust and effective way to\nperform this task. For a well-trained model, a testing error on the level of\none percent is achieved for strong classifiers like Random Forest and Boosting\nTrees using the extracted features of the signal as input and utilising dense\nclusters of sensors instead of single sensors.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2011 17:35:20 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Neff", "M.", ""], ["Anton", "G.", ""], ["Enzenh\u00f6fer", "A.", ""], ["Graf", "K.", ""], ["H\u00f6\u00dfl", "J.", ""], ["Katz", "U.", ""], ["Lahmann", "R.", ""], ["Richardt", "C.", ""]]}, {"id": "1104.3792", "submitter": "Yu-Ping Wang", "authors": "J. Duan, Charles Soussen, David Brie, Jerome Idier and Y.-P. Wang", "title": "A sufficient condition on monotonic increase of the number of nonzero\n  entry in the optimizer of L1 norm penalized least-square problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\ell$-1 norm based optimization is widely used in signal processing,\nespecially in recent compressed sensing theory. This paper studies the solution\npath of the $\\ell$-1 norm penalized least-square problem, whose constrained\nform is known as Least Absolute Shrinkage and Selection Operator (LASSO). A\nsolution path is the set of all the optimizers with respect to the evolution of\nthe hyperparameter (Lagrange multiplier). The study of the solution path is of\ngreat significance in viewing and understanding the profile of the tradeoff\nbetween the approximation and regularization terms. If the solution path of a\ngiven problem is known, it can help us to find the optimal hyperparameter under\na given criterion such as the Akaike Information Criterion. In this paper we\npresent a sufficient condition on $\\ell$-1 norm penalized least-square problem.\nUnder this sufficient condition, the number of nonzero entries in the optimizer\nor solution vector increases monotonically when the hyperparameter decreases.\nWe also generalize the result to the often used total variation case, where the\n$\\ell$-1 norm is taken over the first order derivative of the solution vector.\nWe prove that the proposed condition has intrinsic connections with the\ncondition given by Donoho, et al \\cite{Donoho08} and the positive cone\ncondition by Efron {\\it el al} \\cite{Efron04}. However, the proposed condition\ndoes not need to assume the sparsity level of the signal as required by Donoho\net al's condition, and is easier to verify than Efron, et al's positive cone\ncondition when being used for practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 16:19:03 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Duan", "J.", ""], ["Soussen", "Charles", ""], ["Brie", "David", ""], ["Idier", "Jerome", ""], ["Wang", "Y. -P.", ""]]}, {"id": "1104.3929", "submitter": "Libin Shen", "authors": "Libin Shen", "title": "Understanding Exhaustive Pattern Learning", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern learning in an important problem in Natural Language Processing\n(NLP). Some exhaustive pattern learning (EPL) methods (Bod, 1992) were proved\nto be flawed (Johnson, 2002), while similar algorithms (Och and Ney, 2004)\nshowed great advantages on other tasks, such as machine translation. In this\narticle, we first formalize EPL, and then show that the probability given by an\nEPL model is constant-factor approximation of the probability given by an\nensemble method that integrates exponential number of models obtained with\nvarious segmentations of the training data. This work for the first time\nprovides theoretical justification for the widely used EPL algorithm in NLP,\nwhich was previously viewed as a flawed heuristic method. Better understanding\nof EPL may lead to improved pattern learning algorithms in future.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2011 02:49:59 GMT"}], "update_date": "2011-04-21", "authors_parsed": [["Shen", "Libin", ""]]}, {"id": "1104.4376", "submitter": "Vikram Krishnamurthy", "authors": "Alex Wang and Vikram Krishnamurthy and Bhashyam Balaji", "title": "Intent Inference and Syntactic Tracking with GMTI Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional target tracking systems, human operators use the estimated\ntarget tracks to make higher level inference of the target behaviour/intent.\nThis paper develops syntactic filtering algorithms that assist human operators\nby extracting spatial patterns from target tracks to identify\nsuspicious/anomalous spatial trajectories. The targets' spatial trajectories\nare modeled by a stochastic context free grammar (SCFG) and a switched mode\nstate space model. Bayesian filtering algorithms for stochastic context free\ngrammars are presented for extracting the syntactic structure and illustrated\nfor a ground moving target indicator (GMTI) radar example. The performance of\nthe algorithms is tested with the experimental data collected using DRDC\nOttawa's X-band Wideband Experimental Airborne Radar (XWEAR).\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2011 02:27:45 GMT"}], "update_date": "2011-04-25", "authors_parsed": [["Wang", "Alex", ""], ["Krishnamurthy", "Vikram", ""], ["Balaji", "Bhashyam", ""]]}, {"id": "1104.4512", "submitter": "Vassilis Kekatos", "authors": "Pedro A. Forero, Vassilis Kekatos, Georgios B. Giannakis", "title": "Robust Clustering Using Outlier-Sparsity Regularization", "comments": "Submitted to IEEE Trans. on PAMI", "journal-ref": null, "doi": "10.1109/TSP.2012.2196696", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Notwithstanding the popularity of conventional clustering algorithms such as\nK-means and probabilistic clustering, their clustering results are sensitive to\nthe presence of outliers in the data. Even a few outliers can compromise the\nability of these algorithms to identify meaningful hidden structures rendering\ntheir outcome unreliable. This paper develops robust clustering algorithms that\nnot only aim to cluster the data, but also to identify the outliers. The novel\napproaches rely on the infrequent presence of outliers in the data which\ntranslates to sparsity in a judiciously chosen domain. Capitalizing on the\nsparsity in the outlier domain, outlier-aware robust K-means and probabilistic\nclustering approaches are proposed. Their novelty lies on identifying outliers\nwhile effecting sparsity in the outlier domain through carefully chosen\nregularization. A block coordinate descent approach is developed to obtain\niterative algorithms with convergence guarantees and small excess computational\ncomplexity with respect to their non-robust counterparts. Kernelized versions\nof the robust clustering algorithms are also developed to efficiently handle\nhigh-dimensional data, identify nonlinearly separable clusters, or even cluster\nobjects that are not represented by vectors. Numerical tests on both synthetic\nand real datasets validate the performance and applicability of the novel\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2011 22:01:14 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Forero", "Pedro A.", ""], ["Kekatos", "Vassilis", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1104.4605", "submitter": "Xiaoye Jiang", "authors": "Xiaoye Jiang and Yuan Yao and Han Liu and Leonidas Guibas", "title": "Compressive Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DM cs.LG cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data acquisition routinely produces massive amounts of network data.\nThough many methods and models have been proposed to analyze such data, the\nresearch of network data is largely disconnected with the classical theory of\nstatistical learning and signal processing. In this paper, we present a new\nframework for modeling network data, which connects two seemingly different\nareas: network data analysis and compressed sensing. From a nonparametric\nperspective, we model an observed network using a large dictionary. In\nparticular, we consider the network clique detection problem and show\nconnections between our formulation with a new algebraic tool, namely Randon\nbasis pursuit in homogeneous spaces. Such a connection allows us to identify\nrigorous recovery conditions for clique detection problems. Though this paper\nis mainly conceptual, we also develop practical approximation algorithms for\nsolving empirical problems and demonstrate their usefulness on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2011 06:06:12 GMT"}], "update_date": "2011-04-26", "authors_parsed": [["Jiang", "Xiaoye", ""], ["Yao", "Yuan", ""], ["Liu", "Han", ""], ["Guibas", "Leonidas", ""]]}, {"id": "1104.4664", "submitter": "Mitchell Bloch", "authors": "Mitchell Keith Bloch", "title": "Temporal Second Difference Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning is a reliable but inefficient off-policy temporal-difference\nmethod, backing up reward only one step at a time. Replacing traces, using a\nrecency heuristic, are more efficient but less reliable. In this work, we\nintroduce model-free, off-policy temporal difference methods that make better\nuse of experience than Watkins' Q(\\lambda). We introduce both Optimistic\nQ(\\lambda) and the temporal second difference trace (TSDT). TSDT is\nparticularly powerful in deterministic domains. TSDT uses neither recency nor\nfrequency heuristics, storing (s,a,r,s',\\delta) so that off-policy updates can\nbe performed after apparently suboptimal actions have been taken. There are\nadditional advantages when using state abstraction, as in MAXQ. We demonstrate\nthat TSDT does significantly better than both Q-learning and Watkins'\nQ(\\lambda) in a deterministic cliff-walking domain. Results in a noisy\ncliff-walking domain are less advantageous for TSDT, but demonstrate the\nefficacy of Optimistic Q(\\lambda), a replacing trace with some of the\nadvantages of TSDT.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2011 22:59:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bloch", "Mitchell Keith", ""]]}, {"id": "1104.4803", "submitter": "Yudong Chen", "authors": "Yudong Chen, Ali Jalali, Sujay Sanghavi and Huan Xu", "title": "Clustering Partially Observed Graphs via Convex Optimization", "comments": "This is the final version published in Journal of Machine Learning\n  Research (JMLR). Partial results appeared in International Conference on\n  Machine Learning (ICML) 2011", "journal-ref": "Journal of Machine Learning Research, vol. 15, pp. 2213-2238, 2014", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of clustering a partially observed\nunweighted graph---i.e., one where for some node pairs we know there is an edge\nbetween them, for some others we know there is no edge, and for the remaining\nwe do not know whether or not there is an edge. We want to organize the nodes\ninto disjoint clusters so that there is relatively dense (observed)\nconnectivity within clusters, and sparse across clusters.\n  We take a novel yet natural approach to this problem, by focusing on finding\nthe clustering that minimizes the number of \"disagreements\"---i.e., the sum of\nthe number of (observed) missing edges within clusters, and (observed) present\nedges across clusters. Our algorithm uses convex optimization; its basis is a\nreduction of disagreement minimization to the problem of recovering an\n(unknown) low-rank matrix and an (unknown) sparse matrix from their partially\nobserved sum. We evaluate the performance of our algorithm on the classical\nPlanted Partition/Stochastic Block Model. Our main theorem provides sufficient\nconditions for the success of our algorithm as a function of the minimum\ncluster size, edge density and observation probability; in particular, the\nresults characterize the tradeoff between the observation probability and the\nedge density gap. When there are a constant number of clusters of equal size,\nour results are optimal up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2011 20:33:55 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2011 19:08:49 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2013 21:27:20 GMT"}, {"version": "v4", "created": "Thu, 24 Jul 2014 00:44:05 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Chen", "Yudong", ""], ["Jalali", "Ali", ""], ["Sanghavi", "Sujay", ""], ["Xu", "Huan", ""]]}, {"id": "1104.5059", "submitter": "Mitchell Bloch", "authors": "Mitchell Keith Bloch", "title": "Reducing Commitment to Tasks with Off-Policy Hierarchical Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In experimenting with off-policy temporal difference (TD) methods in\nhierarchical reinforcement learning (HRL) systems, we have observed unwanted\non-policy learning under reproducible conditions. Here we present modifications\nto several TD methods that prevent unintentional on-policy learning from\noccurring. These modifications create a tension between exploration and\nlearning. Traditional TD methods require commitment to finishing subtasks\nwithout exploration in order to update Q-values for early actions with high\nprobability. One-step intra-option learning and temporal second difference\ntraces (TSDT) do not suffer from this limitation. We demonstrate that our HRL\nsystem is efficient without commitment to completion of subtasks in a\ncliff-walking domain, contrary to a widespread claim in the literature that it\nis critical for efficiency of learning. Furthermore, decreasing commitment as\nexploration progresses is shown to improve both online performance and the\nresultant policy in the taxicab domain, opening a new avenue for research into\nwhen it is more beneficial to continue with the current subtask or to replan.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 00:58:52 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bloch", "Mitchell Keith", ""]]}, {"id": "1104.5061", "submitter": "Theja Tulabandhula", "authors": "Theja Tulabandhula, Cynthia Rudin", "title": "On Combining Machine Learning with Decision Making", "comments": "35 pages, 16 figures, longer version of a paper appearing in\n  Algorithmic Decision Theory 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new application and covering number bound for the framework of\n\"Machine Learning with Operational Costs (MLOC),\" which is an exploratory form\nof decision theory. The MLOC framework incorporates knowledge about how a\npredictive model will be used for a subsequent task, thus combining machine\nlearning with the decision that is made afterwards. In this work, we use the\nMLOC framework to study a problem that has implications for power grid\nreliability and maintenance, called the Machine Learning and Traveling\nRepairman Problem ML&TRP. The goal of the ML&TRP is to determine a route for a\n\"repair crew,\" which repairs nodes on a graph. The repair crew aims to minimize\nthe cost of failures at the nodes, but as in many real situations, the failure\nprobabilities are not known and must be estimated. The MLOC framework allows us\nto understand how this uncertainty influences the repair route. We also present\nnew covering number generalization bounds for the MLOC framework.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 01:21:05 GMT"}, {"version": "v2", "created": "Thu, 13 Mar 2014 01:07:49 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Tulabandhula", "Theja", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1104.5070", "submitter": "Alexander Rakhlin", "authors": "Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari", "title": "Online Learning: Stochastic and Constrained Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning theory has largely focused on two main learning scenarios. The first\nis the classical statistical setting where instances are drawn i.i.d. from a\nfixed distribution and the second scenario is the online learning, completely\nadversarial scenario where adversary at every time step picks the worst\ninstance to provide the learner with. It can be argued that in the real world\nneither of these assumptions are reasonable. It is therefore important to study\nproblems with a range of assumptions on data. Unfortunately, theoretical\nresults in this area are scarce, possibly due to absence of general tools for\nanalysis. Focusing on the regret formulation, we define the minimax value of a\ngame where the adversary is restricted in his moves. The framework captures\nstochastic and non-stochastic assumptions on data. Building on the sequential\nsymmetrization approach, we define a notion of distribution-dependent\nRademacher complexity for the spectrum of problems ranging from i.i.d. to\nworst-case. The bounds let us immediately deduce variation-type bounds. We then\nconsider the i.i.d. adversary and show equivalence of online and batch\nlearnability. In the supervised setting, we consider various hybrid assumptions\non the way that x and y variables are chosen. Finally, we consider smoothed\nlearning problems and show that half-spaces are online learnable in the\nsmoothed model. In fact, exponentially small noise added to adversary's\ndecisions turns this problem with infinite Littlestone's dimension into a\nlearnable problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 04:11:10 GMT"}], "update_date": "2011-04-28", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1104.5071", "submitter": "Valentino Crespi", "authors": "Valentino Crespi and George Cybenko and Annarita Giani", "title": "Attacking and Defending Covert Channels and Behavioral Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present methods for attacking and defending $k$-gram\nstatistical analysis techniques that are used, for example, in network traffic\nanalysis and covert channel detection. The main new result is our demonstration\nof how to use a behavior's or process' $k$-order statistics to build a\nstochastic process that has those same $k$-order stationary statistics but\npossesses different, deliberately designed, $(k+1)$-order statistics if\ndesired. Such a model realizes a \"complexification\" of the process or behavior\nwhich a defender can use to monitor whether an attacker is shaping the\nbehavior. By deliberately introducing designed $(k+1)$-order behaviors, the\ndefender can check to see if those behaviors are present in the data. We also\ndevelop constructs for source codes that respect the $k$-order statistics of a\nprocess while encoding covert information. One fundamental consequence of these\nresults is that certain types of behavior analyses techniques come down to an\n{\\em arms race} in the sense that the advantage goes to the party that has more\ncomputing resources applied to the problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 04:12:47 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Crespi", "Valentino", ""], ["Cybenko", "George", ""], ["Giani", "Annarita", ""]]}, {"id": "1104.5150", "submitter": "Johanne Cohen", "authors": "Mariem Krichen and Johanne Cohen and Dominique Barth", "title": "File Transfer Application For Sharing Femto Access", "comments": "15 pages, 9 figures; extended version from Conference ISCIS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In wireless access network optimization, today's main challenges reside in\ntraffic offload and in the improvement of both capacity and coverage networks.\nThe operators are interested in solving their localized coverage and capacity\nproblems in areas where the macro network signal is not able to serve the\ndemand for mobile data. Thus, the major issue for operators is to find the best\nsolution at reasonable expanses. The femto cell seems to be the answer to this\nproblematic. In this work (This work is supported by the COMET project AWARE.\nhttp://www.ftw.at/news/project-start-for-aware-ftw), we focus on the problem of\nsharing femto access between a same mobile operator's customers. This problem\ncan be modeled as a game where service requesters customers (SRCs) and service\nproviders customers (SPCs) are the players.\n  This work addresses the sharing femto access problem considering only one SPC\nusing game theory tools. We consider that SRCs are static and have some similar\nand regular connection behavior. We also note that the SPC and each SRC have a\nsoftware embedded respectively on its femto access, user equipment (UE).\n  After each connection requested by a SRC, its software will learn the\nstrategy increasing its gain knowing that no information about the other SRCs\nstrategies is given. The following article presents a distributed learning\nalgorithm with incomplete information running in SRCs software. We will then\nanswer the following questions for a game with $N$ SRCs and one SPC: how many\nconnections are necessary for each SRC in order to learn the strategy\nmaximizing its gain? Does this algorithm converge to a stable state? If yes,\ndoes this state a Nash Equilibrium and is there any way to optimize the\nlearning process duration time triggered by SRCs software?\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 14:04:27 GMT"}], "update_date": "2011-04-28", "authors_parsed": [["Krichen", "Mariem", ""], ["Cohen", "Johanne", ""], ["Barth", "Dominique", ""]]}, {"id": "1104.5256", "submitter": "Shilin Ding", "authors": "Shilin Ding", "title": "Learning Undirected Graphical Models with Structure Penalty", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In undirected graphical models, learning the graph structure and learning the\nfunctions that relate the predictive variables (features) to the responses\ngiven the structure are two topics that have been widely investigated in\nmachine learning and statistics. Learning graphical models in two stages will\nhave problems because graph structure may change after considering the\nfeatures. The main contribution of this paper is the proposed method that\nlearns the graph structure and functions on the graph at the same time. General\ngraphical models with binary outcomes conditioned on predictive variables are\nproved to be equivalent to multivariate Bernoulli model. The reparameterization\nof the potential functions in graphical model by conditional log odds ratios in\nmultivariate Bernoulli model offers advantage in the representation of the\nconditional independence structure in the model. Additionally, we impose a\nstructure penalty on groups of conditional log odds ratios to learn the graph\nstructure. These groups of functions are designed with overlaps to enforce\nhierarchical function selection. In this way, we are able to shrink higher\norder interactions to obtain a sparse graph structure. Simulation studies show\nthat the method is able to recover the graph structure. The analysis of county\ndata from Census Bureau gives interesting relations between unemployment rate,\ncrime and others discovered by the model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2011 21:40:09 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Ding", "Shilin", ""]]}, {"id": "1104.5391", "submitter": "Lin Chen", "authors": "Quan Liu, Kehao Wang, Lin Chen", "title": "On Optimality of Greedy Policy for a Class of Standard Reward Function\n  of Restless Multi-armed Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper,we consider the restless bandit problem, which is one of the\nmost well-studied generalizations of the celebrated stochastic multi-armed\nbandit problem in decision theory. However, it is known be PSPACE-Hard to\napproximate to any non-trivial factor. Thus the optimality is very difficult to\nobtain due to its high complexity. A natural method is to obtain the greedy\npolicy considering its stability and simplicity. However, the greedy policy\nwill result in the optimality loss for its intrinsic myopic behavior generally.\nIn this paper, by analyzing one class of so-called standard reward function, we\nestablish the closed-form condition about the discounted factor \\beta such that\nthe optimality of the greedy policy is guaranteed under the discounted expected\nreward criterion, especially, the condition \\beta = 1 indicating the optimality\nof the greedy policy under the average accumulative reward criterion. Thus, the\nstandard form of reward function can easily be used to judge the optimality of\nthe greedy policy without any complicated calculation. Some examples in\ncognitive radio networks are presented to verify the effectiveness of the\nmathematical result in judging the optimality of the greedy policy.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2011 13:55:27 GMT"}], "update_date": "2011-04-29", "authors_parsed": [["Liu", "Quan", ""], ["Wang", "Kehao", ""], ["Chen", "Lin", ""]]}, {"id": "1104.5466", "submitter": "Daniel Burfoot", "authors": "Daniel Burfoot", "title": "Notes on a New Philosophy of Empirical Science", "comments": "Draft Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book presents a methodology and philosophy of empirical science based on\nlarge scale lossless data compression. In this view a theory is scientific if\nit can be used to build a data compression program, and it is valuable if it\ncan compress a standard benchmark database to a small size, taking into account\nthe length of the compressor itself. This methodology therefore includes an\nOccam principle as well as a solution to the problem of demarcation. Because of\nthe fundamental difficulty of lossless compression, this type of research must\nbe empirical in nature: compression can only be achieved by discovering and\ncharacterizing empirical regularities in the data. Because of this, the\nphilosophy provides a way to reformulate fields such as computer vision and\ncomputational linguistics as empirical sciences: the former by attempting to\ncompress databases of natural images, the latter by attempting to compress\nlarge text databases. The book argues that the rigor and objectivity of the\ncompression principle should set the stage for systematic progress in these\nfields. The argument is especially strong in the context of computer vision,\nwhich is plagued by chronic problems of evaluation.\n  The book also considers the field of machine learning. Here the traditional\napproach requires that the models proposed to solve learning problems be\nextremely simple, in order to avoid overfitting. However, the world may contain\nintrinsically complex phenomena, which would require complex models to\nunderstand. The compression philosophy can justify complex models because of\nthe large quantity of data being modeled (if the target database is 100 Gb, it\nis easy to justify a 10 Mb model). The complex models and abstractions learned\non the basis of the raw data (images, language, etc) can then be reused to\nsolve any specific learning problem, such as face recognition or machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2011 18:46:06 GMT"}], "update_date": "2011-04-29", "authors_parsed": [["Burfoot", "Daniel", ""]]}, {"id": "1104.5601", "submitter": "Shie Mannor", "authors": "Shie Mannor and John Tsitsiklis", "title": "Mean-Variance Optimization in Markov Decision Processes", "comments": "A full version of an ICML 2011 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider finite horizon Markov decision processes under performance\nmeasures that involve both the mean and the variance of the cumulative reward.\nWe show that either randomized or history-based policies can improve\nperformance. We prove that the complexity of computing a policy that maximizes\nthe mean reward under a variance constraint is NP-hard for some cases, and\nstrongly NP-hard for others. We finally offer pseudopolynomial exact and\napproximation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 11:39:40 GMT"}], "update_date": "2011-05-02", "authors_parsed": [["Mannor", "Shie", ""], ["Tsitsiklis", "John", ""]]}, {"id": "1104.5617", "submitter": "Diego Colombo", "authors": "Diego Colombo, Marloes H. Maathuis, Markus Kalisch, Thomas S.\n  Richardson", "title": "Learning high-dimensional directed acyclic graphs with latent and\n  selection variables", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS940 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 1, 294-321", "doi": "10.1214/11-AOS940", "report-no": "IMS-AOS-AOS940", "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal information between random\nvariables in directed acyclic graphs (DAGs) when allowing arbitrarily many\nlatent and selection variables. The FCI (Fast Causal Inference) algorithm has\nbeen explicitly designed to infer conditional independence and causal\ninformation in such settings. However, FCI is computationally infeasible for\nlarge graphs. We therefore propose the new RFCI algorithm, which is much faster\nthan FCI. In some situations the output of RFCI is slightly less informative,\nin particular with respect to conditional independence information. However, we\nprove that any causal information in the output of RFCI is correct in the\nasymptotic limit. We also define a class of graphs on which the outputs of FCI\nand RFCI are identical. We prove consistency of FCI and RFCI in sparse\nhigh-dimensional settings, and demonstrate in simulations that the estimation\nperformances of the algorithms are very similar. All software is implemented in\nthe R-package pcalg.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 12:57:10 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2011 08:09:46 GMT"}, {"version": "v3", "created": "Tue, 29 May 2012 13:02:17 GMT"}], "update_date": "2012-05-30", "authors_parsed": [["Colombo", "Diego", ""], ["Maathuis", "Marloes H.", ""], ["Kalisch", "Markus", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1104.5687", "submitter": "Christos Dimitrakakis", "authors": "Constantin Rothkopf and Christos Dimitrakakis", "title": "Preference elicitation and inverse reinforcement learning", "comments": "13 pages, 4 figures; ECML 2011", "journal-ref": null, "doi": null, "report-no": "EPFL-REPORT-165975", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We state the problem of inverse reinforcement learning in terms of preference\nelicitation, resulting in a principled (Bayesian) statistical formulation. This\ngeneralises previous work on Bayesian inverse reinforcement learning and allows\nus to obtain a posterior distribution on the agent's preferences, policy and\noptionally, the obtained reward sequence, from observations. We examine the\nrelation of the resulting approach to other statistical methods for inverse\nreinforcement learning via analysis and experimental results. We show that\npreferences can be determined accurately, even if the observed agent's policy\nis sub-optimal with respect to its own preferences. In that case, significantly\nimproved policies with respect to the agent's preferences are obtained,\ncompared to both other methods and to the performance of the demonstrated\npolicy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 17:45:50 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2011 14:06:42 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Rothkopf", "Constantin", ""], ["Dimitrakakis", "Christos", ""]]}]