[{"id": "1205.0044", "submitter": "Ankur Moitra", "authors": "Ankur Moitra", "title": "A Singly-Exponential Time Algorithm for Computing Nonnegative Rank", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we give an algorithm for deciding if the nonnegative rank of a matrix\n$M$ of dimension $m \\times n$ is at most $r$ which runs in time\n$(nm)^{O(r^2)}$. This is the first exact algorithm that runs in time\nsingly-exponential in $r$. This algorithm (and earlier algorithms) are built on\nmethods for finding a solution to a system of polynomial inequalities (if one\nexists). Notably, the best algorithms for this task run in time exponential in\nthe number of variables but polynomial in all of the other parameters (the\nnumber of inequalities and the maximum degree).\n  Hence these algorithms motivate natural algebraic questions whose solution\nhave immediate {\\em algorithmic} implications: How many variables do we need to\nrepresent the decision problem, does $M$ have nonnegative rank at most $r$? A\nnaive formulation uses $nr + mr$ variables and yields an algorithm that is\nexponential in $n$ and $m$ even for constant $r$. (Arora, Ge, Kannan, Moitra,\nSTOC 2012) recently reduced the number of variables to $2r^2 2^r$, and here we\nexponentially reduce the number of variables to $2r^2$ and this yields our main\nalgorithm. In fact, the algorithm that we obtain is nearly-optimal (under the\nExponential Time Hypothesis) since an algorithm that runs in time $(nm)^{o(r)}$\nwould yield a subexponential algorithm for 3-SAT .\n  Our main result is based on establishing a normal form for nonnegative matrix\nfactorization - which in turn allows us to exploit algebraic dependence among a\nlarge collection of linear transformations with variable entries. Additionally,\nwe also demonstrate that nonnegative rank cannot be certified by even a very\nlarge submatrix of $M$, and this property also follows from the intuition\ngained from viewing nonnegative rank through the lens of systems of polynomial\ninequalities.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 22:26:51 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Moitra", "Ankur", ""]]}, {"id": "1205.0047", "submitter": "Soummya Kar", "authors": "Soummya Kar, Jose' M.F. Moura and H. Vincent Poor", "title": "$QD$-Learning: A Collaborative Distributed Strategy for Multi-Agent\n  Reinforcement Learning Through Consensus + Innovations", "comments": "Submitted to the IEEE Transactions on Signal Processing, 33 pages", "journal-ref": null, "doi": "10.1109/TSP.2013.2241057", "report-no": null, "categories": "stat.ML cs.LG cs.MA math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers a class of multi-agent Markov decision processes (MDPs),\nin which the network agents respond differently (as manifested by the\ninstantaneous one-stage random costs) to a global controlled state and the\ncontrol actions of a remote controller. The paper investigates a distributed\nreinforcement learning setup with no prior information on the global state\ntransition and local agent cost statistics. Specifically, with the agents'\nobjective consisting of minimizing a network-averaged infinite horizon\ndiscounted cost, the paper proposes a distributed version of $Q$-learning,\n$\\mathcal{QD}$-learning, in which the network agents collaborate by means of\nlocal processing and mutual information exchange over a sparse (possibly\nstochastic) communication network to achieve the network goal. Under the\nassumption that each agent is only aware of its local online cost data and the\ninter-agent communication network is \\emph{weakly} connected, the proposed\ndistributed scheme is almost surely (a.s.) shown to yield asymptotically the\ndesired value function and the optimal stationary control policy at each\nnetwork agent. The analytical techniques developed in the paper to address the\nmixed time-scale stochastic dynamics of the \\emph{consensus + innovations}\nform, which arise as a result of the proposed interactive distributed scheme,\nare of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 22:48:37 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 01:59:10 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Kar", "Soummya", ""], ["Moura", "Jose' M. F.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1205.0079", "submitter": "Julien Mairal", "authors": "Julien Mairal and Bin Yu", "title": "Complexity Analysis of the Lasso Regularization Path", "comments": "To appear in the proceedings of 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The regularization path of the Lasso can be shown to be piecewise linear,\nmaking it possible to \"follow\" and explicitly compute the entire path. We\nanalyze in this paper this popular strategy, and prove that its worst case\ncomplexity is exponential in the number of variables. We then oppose this\npessimistic result to an (optimistic) approximate analysis: We show that an\napproximate path with at most O(1/sqrt(epsilon)) linear segments can always be\nobtained, where every point on the path is guaranteed to be optimal up to a\nrelative epsilon-duality gap. We complete our theoretical analysis with a\npractical algorithm to compute these approximate paths.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 03:37:13 GMT"}, {"version": "v2", "created": "Sat, 19 May 2012 21:06:21 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Mairal", "Julien", ""], ["Yu", "Bin", ""]]}, {"id": "1205.0088", "submitter": "Ranch Y.Q. Lai", "authors": "Ranch Y.Q. Lai and Pong C. Yuen", "title": "ProPPA: A Fast Algorithm for $\\ell_1$ Minimization and Low-Rank Matrix\n  Completion", "comments": "update needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Projected Proximal Point Algorithm (ProPPA) for solving a class\nof optimization problems. The algorithm iteratively computes the proximal point\nof the last estimated solution projected into an affine space which itself is\nparallel and approaching to the feasible set. We provide convergence analysis\ntheoretically supporting the general algorithm, and then apply it for solving\n$\\ell_1$-minimization problems and the matrix completion problem. These\nproblems arise in many applications including machine learning, image and\nsignal processing. We compare our algorithm with the existing state-of-the-art\nalgorithms. Experimental results on solving these problems show that our\nalgorithm is very efficient and competitive.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 04:59:12 GMT"}, {"version": "v2", "created": "Sat, 19 May 2012 15:10:54 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Lai", "Ranch Y. Q.", ""], ["Yuen", "Pong C.", ""]]}, {"id": "1205.0288", "submitter": "Arash Afkanpour", "authors": "Arash Afkanpour, Andr\\'as Gy\\\"orgy, Csaba Szepesv\\'ari, Michael\n  Bowling", "title": "A Randomized Mirror Descent Algorithm for Large Scale Multiple Kernel\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneously learning to linearly combine a very\nlarge number of kernels and learn a good predictor based on the learnt kernel.\nWhen the number of kernels $d$ to be combined is very large, multiple kernel\nlearning methods whose computational cost scales linearly in $d$ are\nintractable. We propose a randomized version of the mirror descent algorithm to\novercome this issue, under the objective of minimizing the group $p$-norm\npenalized empirical risk. The key to achieve the required exponential speed-up\nis the computationally efficient construction of low-variance estimates of the\ngradient. We propose importance sampling based estimates, and find that the\nideal distribution samples a coordinate with a probability proportional to the\nmagnitude of the corresponding gradient. We show the surprising result that in\nthe case of learning the coefficients of a polynomial kernel, the combinatorial\nstructure of the base kernels to be combined allows the implementation of\nsampling from this distribution to run in $O(\\log(d))$ time, making the total\ncomputational cost of the method to achieve an $\\epsilon$-optimal solution to\nbe $O(\\log(d)/\\epsilon^2)$, thereby allowing our method to operate for very\nlarge values of $d$. Experiments with simulated and real data confirm that the\nnew algorithm is computationally more efficient than its state-of-the-art\nalternatives.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 23:42:57 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2013 17:42:46 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Afkanpour", "Arash", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Bowling", "Michael", ""]]}, {"id": "1205.0406", "submitter": "Rui Wang", "authors": "Rui Wang and Ke Tang", "title": "Minimax Classifier for Uncertain Costs", "comments": "6 pages, more materials will be added into the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies on the cost-sensitive learning assumed that a unique cost matrix\nis known for a problem. However, this assumption may not hold for many\nreal-world problems. For example, a classifier might need to be applied in\nseveral circumstances, each of which associates with a different cost matrix.\nOr, different human experts have different opinions about the costs for a given\nproblem. Motivated by these facts, this study aims to seek the minimax\nclassifier over multiple cost matrices. In summary, we theoretically proved\nthat, no matter how many cost matrices are involved, the minimax problem can be\ntackled by solving a number of standard cost-sensitive problems and\nsub-problems that involve only two cost matrices. As a result, a general\nframework for achieving minimax classifier over multiple cost matrices is\nsuggested and justified by preliminary empirical studies.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 12:38:11 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Wang", "Rui", ""], ["Tang", "Ke", ""]]}, {"id": "1205.0411", "submitter": "Dino Sejdinovic", "authors": "Dino Sejdinovic, Arthur Gretton, Bharath Sriperumbudur, Kenji Fukumizu", "title": "Hypothesis testing using pairwise distances and associated kernels (with\n  Appendix)", "comments": "Appearing in Proceedings of the 29th International Conference on\n  Machine Learning, Edinburgh, Scotland, UK, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a unifying framework linking two classes of statistics used in\ntwo-sample and independence testing: on the one hand, the energy distances and\ndistance covariances from the statistics literature; on the other, distances\nbetween embeddings of distributions to reproducing kernel Hilbert spaces\n(RKHS), as established in machine learning. The equivalence holds when energy\ndistances are computed with semimetrics of negative type, in which case a\nkernel may be defined such that the RKHS distance between distributions\ncorresponds exactly to the energy distance. We determine the class of\nprobability distributions for which kernels induced by semimetrics are\ncharacteristic (that is, for which embeddings of the distributions to an RKHS\nare injective). Finally, we investigate the performance of this family of\nkernels in two-sample and independence tests: we show in particular that the\nenergy distance most commonly employed in statistics is just one member of a\nparametric family of kernels, and that other choices from this family can yield\nmore powerful tests.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 12:49:19 GMT"}, {"version": "v2", "created": "Mon, 21 May 2012 23:29:06 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Sejdinovic", "Dino", ""], ["Gretton", "Arthur", ""], ["Sriperumbudur", "Bharath", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1205.0610", "submitter": "Gang Chen", "authors": "Gang Chen and Jason Corso", "title": "Greedy Multiple Instance Learning via Codebook Learning and Nearest\n  Neighbor Voting", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Multiple instance learning (MIL) has attracted great attention recently in\nmachine learning community. However, most MIL algorithms are very slow and\ncannot be applied to large datasets. In this paper, we propose a greedy\nstrategy to speed up the multiple instance learning process. Our contribution\nis two fold. First, we propose a density ratio model, and show that maximizing\na density ratio function is the low bound of the DD model under certain\nconditions. Secondly, we make use of a histogram ratio between positive bags\nand negative bags to represent the density ratio function and find codebooks\nseparately for positive bags and negative bags by a greedy strategy. For\ntesting, we make use of a nearest neighbor strategy to classify new bags. We\ntest our method on both small benchmark datasets and the large TRECVID MED11\ndataset. The experimental results show that our method yields comparable\naccuracy to the current state of the art, while being up to at least one order\nof magnitude faster.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 04:09:19 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["Chen", "Gang", ""], ["Corso", "Jason", ""]]}, {"id": "1205.0651", "submitter": "Gaurav Pandey", "authors": "Ambedkar Dukkipati, Gaurav Pandey, Debarghya Ghoshdastidar, Paramita\n  Koley, D. M. V. Satya Sriram", "title": "Generative Maximum Entropy Learning for Multiclass Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum entropy approach to classification is very well studied in applied\nstatistics and machine learning and almost all the methods that exists in\nliterature are discriminative in nature. In this paper, we introduce a maximum\nentropy classification method with feature selection for large dimensional data\nsuch as text datasets that is generative in nature. To tackle the curse of\ndimensionality of large data sets, we employ conditional independence\nassumption (Naive Bayes) and we perform feature selection simultaneously, by\nenforcing a `maximum discrimination' between estimated class conditional\ndensities. For two class problems, in the proposed method, we use Jeffreys\n($J$) divergence to discriminate the class conditional densities. To extend our\nmethod to the multi-class case, we propose a completely new approach by\nconsidering a multi-distribution divergence: we replace Jeffreys divergence by\nJensen-Shannon ($JS$) divergence to discriminate conditional densities of\nmultiple classes. In order to reduce computational complexity, we employ a\nmodified Jensen-Shannon divergence ($JS_{GM}$), based on AM-GM inequality. We\nshow that the resulting divergence is a natural generalization of Jeffreys\ndivergence to a multiple distributions case. As far as the theoretical\njustifications are concerned we show that when one intends to select the best\nfeatures in a generative maximum entropy approach, maximum discrimination using\n$J-$divergence emerges naturally in binary classification. Performance and\ncomparative study of the proposed algorithms have been demonstrated on large\ndimensional text and gene expression datasets that show our methods scale up\nvery well with large dimensional datasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 08:49:01 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2012 09:38:47 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2013 08:27:53 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Dukkipati", "Ambedkar", ""], ["Pandey", "Gaurav", ""], ["Ghoshdastidar", "Debarghya", ""], ["Koley", "Paramita", ""], ["Sriram", "D. M. V. Satya", ""]]}, {"id": "1205.0908", "submitter": "Leonid Litinskii", "authors": "Iakov Karandashev, Boris Kryzhanovsky and Leonid Litinskii", "title": "Weighted Patterns as a Tool for Improving the Hopfield Model", "comments": "19 pages, 17 figures", "journal-ref": "Physical Review E, 2012, Vol.85, No.4", "doi": "10.1103/PhysRevE.85.041925", "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the standard Hopfield model to the case when a weight is\nassigned to each input pattern. The weight can be interpreted as the frequency\nof the pattern occurrence at the input of the network. In the framework of the\nstatistical physics approach we obtain the saddle-point equation allowing us to\nexamine the memory of the network. In the case of unequal weights our model\ndoes not lead to the catastrophic destruction of the memory due to its\noverfilling (that is typical for the standard Hopfield model). The real memory\nconsists only of the patterns with weights exceeding a critical value that is\ndetermined by the weights distribution. We obtain the algorithm allowing us to\nfind this critical value for an arbitrary distribution of the weights, and\nanalyze in detail some particular weights distributions. It is shown that the\nmemory decreases as compared to the case of the standard Hopfield model.\nHowever, in our model the network can learn online without the catastrophic\ndestruction of the memory.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 10:33:22 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Karandashev", "Iakov", ""], ["Kryzhanovsky", "Boris", ""], ["Litinskii", "Leonid", ""]]}, {"id": "1205.1053", "submitter": "Dongwoo Kim", "authors": "Dongwoo Kim, Yeonseung Chung, Alice Oh", "title": "Variable Selection for Latent Dirichlet Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In latent Dirichlet allocation (LDA), topics are multinomial distributions\nover the entire vocabulary. However, the vocabulary usually contains many words\nthat are not relevant in forming the topics. We adopt a variable selection\nmethod widely used in statistical modeling as a dimension reduction tool and\ncombine it with LDA. In this variable selection model for LDA (vsLDA), topics\nare multinomial distributions over a subset of the vocabulary, and by excluding\nwords that are not informative for finding the latent topic structure of the\ncorpus, vsLDA finds topics that are more robust and discriminative. We compare\nthree models, vsLDA, LDA with symmetric priors, and LDA with asymmetric priors,\non heldout likelihood, MCMC chain consistency, and document classification. The\nperformance of vsLDA is better than symmetric LDA for likelihood and\nclassification, better than asymmetric LDA for consistency and classification,\nand about the same in the other comparisons.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 03:14:18 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Kim", "Dongwoo", ""], ["Chung", "Yeonseung", ""], ["Oh", "Alice", ""]]}, {"id": "1205.1183", "submitter": "Xiaohui Bei", "authors": "Xiaohui Bei, Ning Chen, Shengyu Zhang", "title": "On the Complexity of Trial and Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by certain applications from physics, biochemistry, economics, and\ncomputer science, in which the objects under investigation are not accessible\nbecause of various limitations, we propose a trial-and-error model to examine\nalgorithmic issues in such situations. Given a search problem with a hidden\ninput, we are asked to find a valid solution, to find which we can propose\ncandidate solutions (trials), and use observed violations (errors), to prepare\nfuture proposals. In accordance with our motivating applications, we consider\nthe fairly broad class of constraint satisfaction problems, and assume that\nerrors are signaled by a verification oracle in the format of the index of a\nviolated constraint (with the content of the constraint still hidden).\n  Our discoveries are summarized as follows. On one hand, despite the seemingly\nvery little information provided by the verification oracle, efficient\nalgorithms do exist for a number of important problems. For the Nash, Core,\nStable Matching, and SAT problems, the unknown-input versions are as hard as\nthe corresponding known-input versions, up to a factor of polynomial. We\nfurther give almost tight bounds on the latter two problems' trial\ncomplexities. On the other hand, there are problems whose complexities are\nsubstantially increased in the unknown-input model. In particular, no\ntime-efficient algorithms exist (under standard hardness assumptions) for Graph\nIsomorphism and Group Isomorphism problems. The tools used to achieve these\nresults include order theory, strong ellipsoid method, and some non-standard\nreductions.\n  Our model investigates the value of information, and our results demonstrate\nthat the lack of input information can introduce various levels of extra\ndifficulty. The model exhibits intimate connections with (and we hope can also\nserve as a useful supplement to) certain existing learning and complexity\ntheories.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 06:03:27 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 05:39:19 GMT"}], "update_date": "2013-04-19", "authors_parsed": [["Bei", "Xiaohui", ""], ["Chen", "Ning", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1205.1240", "submitter": "Guillaume Obozinski", "authors": "Guillaume Obozinski (INRIA Paris - Rocquencourt, LIENS), Francis Bach\n  (INRIA Paris - Rocquencourt, LIENS)", "title": "Convex Relaxation for Combinatorial Penalties", "comments": "35 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an unifying view of several recently proposed\nstructured sparsity-inducing norms. We consider the situation of a model\nsimultaneously (a) penalized by a set- function de ned on the support of the\nunknown parameter vector which represents prior knowledge on supports, and (b)\nregularized in Lp-norm. We show that the natural combinatorial optimization\nproblems obtained may be relaxed into convex optimization problems and\nintroduce a notion, the lower combinatorial envelope of a set-function, that\ncharacterizes the tightness of our relaxations. We moreover establish links\nwith norms based on latent representations including the latent group Lasso and\nblock-coding, and with norms obtained from submodular functions.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 19:54:33 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Obozinski", "Guillaume", "", "INRIA Paris - Rocquencourt, LIENS"], ["Bach", "Francis", "", "INRIA Paris - Rocquencourt, LIENS"]]}, {"id": "1205.1245", "submitter": "Martin Vincent", "authors": "Martin Vincent, Niels Richard Hansen", "title": "Sparse group lasso and high dimensional multinomial classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse group lasso optimization problem is solved using a coordinate\ngradient descent algorithm. The algorithm is applicable to a broad class of\nconvex loss functions. Convergence of the algorithm is established, and the\nalgorithm is used to investigate the performance of the multinomial sparse\ngroup lasso classifier. On three different real data examples the multinomial\ngroup lasso clearly outperforms multinomial lasso in terms of achieved\nclassification error rate and in terms of including fewer features for the\nclassification. The run-time of our sparse group lasso implementation is of the\nsame order of magnitude as the multinomial lasso algorithm implemented in the R\npackage glmnet. Our implementation scales well with the problem size. One of\nthe high dimensional examples considered is a 50 class classification problem\nwith 10k features, which amounts to estimating 500k parameters. The\nimplementation is available as the R package msgl.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 20:18:13 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2013 09:36:02 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Vincent", "Martin", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "1205.1287", "submitter": "Zhilin Zhang", "authors": "Zhilin Zhang, Tzyy-Ping Jung, Scott Makeig, Bhaskar D. Rao", "title": "Compressed Sensing for Energy-Efficient Wireless Telemonitoring of\n  Noninvasive Fetal ECG via Block Sparse Bayesian Learning", "comments": "The code and the data can be downloaded from the first author's\n  homepage: http://sites.google.com/site/researchbyzhang/bsbl, or\n  http://dsp.ucsd.edu/~zhilin/BSBL.html", "journal-ref": null, "doi": "10.1109/TBME.2012.2226175", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fetal ECG (FECG) telemonitoring is an important branch in telemedicine. The\ndesign of a telemonitoring system via a wireless body-area network with low\nenergy consumption for ambulatory use is highly desirable. As an emerging\ntechnique, compressed sensing (CS) shows great promise in\ncompressing/reconstructing data with low energy consumption. However, due to\nsome specific characteristics of raw FECG recordings such as non-sparsity and\nstrong noise contamination, current CS algorithms generally fail in this\napplication.\n  This work proposes to use the block sparse Bayesian learning (BSBL) framework\nto compress/reconstruct non-sparse raw FECG recordings. Experimental results\nshow that the framework can reconstruct the raw recordings with high quality.\nEspecially, the reconstruction does not destroy the interdependence relation\namong the multichannel recordings. This ensures that the independent component\nanalysis decomposition of the reconstructed recordings has high fidelity.\nFurthermore, the framework allows the use of a sparse binary sensing matrix\nwith much fewer nonzero entries to compress recordings. Particularly, each\ncolumn of the matrix can contain only two nonzero entries. This shows the\nframework, compared to other algorithms such as current CS algorithms and\nwavelet algorithms, can greatly reduce code execution in CPU in the data\ncompression stage.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 06:15:15 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2012 16:04:28 GMT"}, {"version": "v3", "created": "Sun, 29 Jul 2012 12:41:03 GMT"}, {"version": "v4", "created": "Wed, 19 Sep 2012 20:05:41 GMT"}, {"version": "v5", "created": "Sun, 23 Sep 2012 22:29:43 GMT"}, {"version": "v6", "created": "Fri, 19 Oct 2012 12:24:39 GMT"}, {"version": "v7", "created": "Sun, 2 Nov 2014 05:38:50 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Zhang", "Zhilin", ""], ["Jung", "Tzyy-Ping", ""], ["Makeig", "Scott", ""], ["Rao", "Bhaskar D.", ""]]}, {"id": "1205.1357", "submitter": "Eitan Menahem", "authors": "Eitan Menahem and Rami Puzis", "title": "Detecting Spammers via Aggregated Historical Data Set", "comments": "This is a conference version of the HDS research. 13 pages 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The battle between email service providers and senders of mass unsolicited\nemails (Spam) continues to gain traction. Vast numbers of Spam emails are sent\nmainly from automatic botnets distributed over the world. One method for\nmitigating Spam in a computationally efficient manner is fast and accurate\nblacklisting of the senders. In this work we propose a new sender reputation\nmechanism that is based on an aggregated historical data-set which encodes the\nbehavior of mail transfer agents over time. A historical data-set is created\nfrom labeled logs of received emails. We use machine learning algorithms to\nbuild a model that predicts the \\emph{spammingness} of mail transfer agents in\nthe near future. The proposed mechanism is targeted mainly at large enterprises\nand email service providers and can be used for updating both the black and the\nwhite lists. We evaluate the proposed mechanism using 9.5M anonymized log\nentries obtained from the biggest Internet service provider in Europe.\nExperiments show that proposed method detects more than 94% of the Spam emails\nthat escaped the blacklist (i.e., TPR), while having less than 0.5%\nfalse-alarms. Therefore, the effectiveness of the proposed method is much\nhigher than of previously reported reputation mechanisms, which rely on emails\nlogs. In addition, the proposed method, when used for updating both the black\nand white lists, eliminated the need in automatic content inspection of 4 out\nof 5 incoming emails, which resulted in dramatic reduction in the filtering\ncomputational load.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 12:16:27 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Menahem", "Eitan", ""], ["Puzis", "Rami", ""]]}, {"id": "1205.1456", "submitter": "Chiranjib Bhattacharyya", "authors": "Himabindu Lakkaraju, Indrajit Bhattacharya, Chiranjib Bhattacharyya", "title": "Dynamic Multi-Relational Chinese Restaurant Process for Analyzing\n  Influences on Users in Social Media", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of analyzing influence of various factors affecting\nindividual messages posted in social media. The problem is challenging because\nof various types of influences propagating through the social media network\nthat act simultaneously on any user. Additionally, the topic composition of the\ninfluencing factors and the susceptibility of users to these influences evolve\nover time. This problem has not studied before, and off-the-shelf models are\nunsuitable for this purpose. To capture the complex interplay of these various\nfactors, we propose a new non-parametric model called the Dynamic\nMulti-Relational Chinese Restaurant Process. This accounts for the user network\nfor data generation and also allows the parameters to evolve over time.\nDesigning inference algorithms for this model suited for large scale\nsocial-media data is another challenge. To this end, we propose a scalable and\nmulti-threaded inference algorithm based on online Gibbs Sampling. Extensive\nevaluations on large-scale Twitter and Facebook data show that the extracted\ntopics when applied to authorship and commenting prediction outperform\nstate-of-the-art baselines. More importantly, our model produces valuable\ninsights on topic trends and user personality trends, beyond the capability of\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 16:45:09 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Lakkaraju", "Himabindu", ""], ["Bhattacharya", "Indrajit", ""], ["Bhattacharyya", "Chiranjib", ""]]}, {"id": "1205.1482", "submitter": "Charles-Alban Deledalle", "authors": "Charles-Alban Deledalle (CEREMADE), Samuel Vaiter (CEREMADE), Gabriel\n  Peyr\\'e (CEREMADE), Jalal Fadili (GREYC), Charles Dossal (IMB)", "title": "Risk estimation for matrix recovery with spectral regularization", "comments": "This version is an update of our original paper presented at\n  ICML'2012 workshop on Sparsity, Dictionaries and Projections in Machine\n  Learning and Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an approach to recursively estimate the quadratic\nrisk for matrix recovery problems regularized with spectral functions. Toward\nthis end, in the spirit of the SURE theory, a key step is to compute the (weak)\nderivative and divergence of a solution with respect to the observations. As\nsuch a solution is not available in closed form, but rather through a proximal\nsplitting algorithm, we propose to recursively compute the divergence from the\nsequence of iterates. A second challenge that we unlocked is the computation of\nthe (weak) derivative of the proximity operator of a spectral function. To show\nthe potential applicability of our approach, we exemplify it on a matrix\ncompletion problem to objectively and automatically select the regularization\nparameter.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 18:55:04 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2012 10:44:04 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2012 20:28:03 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Deledalle", "Charles-Alban", "", "CEREMADE"], ["Vaiter", "Samuel", "", "CEREMADE"], ["Peyr\u00e9", "Gabriel", "", "CEREMADE"], ["Fadili", "Jalal", "", "GREYC"], ["Dossal", "Charles", "", "IMB"]]}, {"id": "1205.1496", "submitter": "Jing Qian", "authors": "Jing Qian, Venkatesh Saligrama, Manqi Zhao", "title": "Graph-based Learning with Unbalanced Clusters", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph construction is a crucial step in spectral clustering (SC) and\ngraph-based semi-supervised learning (SSL). Spectral methods applied on\nstandard graphs such as full-RBF, $\\epsilon$-graphs and $k$-NN graphs can lead\nto poor performance in the presence of proximal and unbalanced data. This is\nbecause spectral methods based on minimizing RatioCut or normalized cut on\nthese graphs tend to put more importance on balancing cluster sizes over\nreducing cut values. We propose a novel graph construction technique and show\nthat the RatioCut solution on this new graph is able to handle proximal and\nunbalanced data. Our method is based on adaptively modulating the neighborhood\ndegrees in a $k$-NN graph, which tends to sparsify neighborhoods in low density\nregions. Our method adapts to data with varying levels of unbalancedness and\ncan be naturally used for small cluster detection. We justify our ideas through\nlimit cut analysis. Unsupervised and semi-supervised experiments on synthetic\nand real data sets demonstrate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 19:55:31 GMT"}, {"version": "v2", "created": "Tue, 8 May 2012 18:27:52 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Qian", "Jing", ""], ["Saligrama", "Venkatesh", ""], ["Zhao", "Manqi", ""]]}, {"id": "1205.1782", "submitter": "Marek Petrik", "authors": "Marek Petrik", "title": "Approximate Dynamic Programming By Minimizing Distributionally Robust\n  Bounds", "comments": "In Proceedings of International Conference on Machine Learning, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate dynamic programming is a popular method for solving large Markov\ndecision processes. This paper describes a new class of approximate dynamic\nprogramming (ADP) methods- distributionally robust ADP-that address the curse\nof dimensionality by minimizing a pessimistic bound on the policy loss. This\napproach turns ADP into an optimization problem, for which we derive new\nmathematical program formulations and analyze its properties. DRADP improves on\nthe theoretical guarantees of existing ADP methods-it guarantees convergence\nand L1 norm based error bounds. The empirical evaluation of DRADP shows that\nthe theoretical guarantees translate well into good performance on benchmark\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 19:22:43 GMT"}, {"version": "v2", "created": "Mon, 21 May 2012 16:30:22 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Petrik", "Marek", ""]]}, {"id": "1205.1828", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein", "title": "The Natural Gradient by Analogy to Signal Whitening, and Recipes and\n  Tricks for its Use", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural gradient allows for more efficient gradient descent by removing\ndependencies and biases inherent in a function's parameterization. Several\npapers present the topic thoroughly and precisely. It remains a very difficult\nidea to get your head around however. The intent of this note is to provide\nsimple intuition for the natural gradient and its use. We review how an ill\nconditioned parameter space can undermine learning, introduce the natural\ngradient by analogy to the more widely understood concept of signal whitening,\nand present tricks and specific prescriptions for applying the natural gradient\nto learning problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 21:12:03 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1205.1925", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein and Benjamin J. Culpepper", "title": "Hamiltonian Annealed Importance Sampling for partition function\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension to annealed importance sampling that uses\nHamiltonian dynamics to rapidly estimate normalization constants. We\ndemonstrate this method by computing log likelihoods in directed and undirected\nprobabilistic image models. We compare the performance of linear generative\nmodels with both Gaussian and Laplace priors, product of experts models with\nLaplace and Student's t experts, the mc-RBM, and a bilinear generative model.\nWe provide code to compare additional models.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 09:49:37 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""], ["Culpepper", "Benjamin J.", ""]]}, {"id": "1205.1928", "submitter": "Francesco Dinuzzo", "authors": "Francesco Dinuzzo, Bernhard Sch\\\"olkopf", "title": "The representer theorem for Hilbert spaces: a necessary and sufficient\n  condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of regularization functionals is said to admit a linear representer\ntheorem if every member of the family admits minimizers that lie in a fixed\nfinite dimensional subspace. A recent characterization states that a general\nclass of regularization functionals with differentiable regularizer admits a\nlinear representer theorem if and only if the regularization term is a\nnon-decreasing function of the norm. In this report, we improve over such\nresult by replacing the differentiability assumption with lower semi-continuity\nand deriving a proof that is independent of the dimensionality of the space.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 10:01:09 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2012 13:54:08 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2012 10:36:07 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Dinuzzo", "Francesco", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1205.1939", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein", "title": "Hamiltonian Monte Carlo with Reduced Momentum Flips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (or hybrid Monte Carlo) with partial momentum\nrefreshment explores the state space more slowly than it otherwise would due to\nthe momentum reversals which occur on proposal rejection. These cause\ntrajectories to double back on themselves, leading to random walk behavior on\ntimescales longer than the typical rejection time, and leading to slower\nmixing. I present a technique by which the number of momentum reversals can be\nreduced. This is accomplished by maintaining the net exchange of probability\nbetween states with opposite momenta, but reducing the rate of exchange in both\ndirections such that it is 0 in one direction. An experiment illustrates these\nreduced momentum flips accelerating mixing for a particular distribution.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 11:14:00 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1205.2056", "submitter": "Ryan Rossi", "authors": "Ryan Rossi, Brian Gallagher, Jennifer Neville, Keith Henderson", "title": "Dynamic Behavioral Mixed-Membership Model for Large Evolving Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of real-world networks are dynamic and extremely large (e.g.,\nInternet Traffic, Twitter, Facebook, ...). To understand the structural\nbehavior of nodes in these large dynamic networks, it may be necessary to model\nthe dynamics of behavioral roles representing the main connectivity patterns\nover time. In this paper, we propose a dynamic behavioral mixed-membership\nmodel (DBMM) that captures the roles of nodes in the graph and how they evolve\nover time. Unlike other node-centric models, our model is scalable for\nanalyzing large dynamic networks. In addition, DBMM is flexible,\nparameter-free, has no functional form or parameterization, and is\ninterpretable (identifies explainable patterns). The performance results\nindicate our approach can be applied to very large networks while the\nexperimental results show that our model uncovers interesting patterns\nunderlying the dynamics of these networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:20:32 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Rossi", "Ryan", ""], ["Gallagher", "Brian", ""], ["Neville", "Jennifer", ""], ["Henderson", "Keith", ""]]}, {"id": "1205.2151", "submitter": "Andri Mirzal", "authors": "Andri Mirzal", "title": "A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix\n  Factorization with Automatic Regularization Parameters Determination", "comments": "Preliminary result without experimental result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a converged algorithm for Tikhonov regularized nonnegative matrix\nfactorization (NMF). We specially choose this regularization because it is\nknown that Tikhonov regularized least square (LS) is the more preferable form\nin solving linear inverse problems than the conventional LS. Because an NMF\nproblem can be decomposed into LS subproblems, it can be expected that Tikhonov\nregularized NMF will be the more appropriate approach in solving NMF problems.\nThe algorithm is derived using additive update rules which have been shown to\nhave convergence guarantee. We equip the algorithm with a mechanism to\nautomatically determine the regularization parameters based on the L-curve, a\nwell-known concept in the inverse problems community, but is rather unknown in\nthe NMF research. The introduction of this algorithm thus solves two inherent\nproblems in Tikhonov regularized NMF algorithm research, i.e., convergence\nguarantee and regularization parameters determination.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 03:31:39 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Mirzal", "Andri", ""]]}, {"id": "1205.2171", "submitter": "Hachem Kadri", "authors": "Hachem Kadri (INRIA Lille - Nord Europe), Mohammad Ghavamzadeh (INRIA\n  Lille - Nord Europe), Philippe Preux (INRIA Lille - Nord Europe)", "title": "A Generalized Kernel Approach to Structured Output Learning", "comments": "in International Conference on Machine Learning (ICML), Jun 2013,\n  Atlanta, United States. 2013", "journal-ref": null, "doi": null, "report-no": "RR-7956", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of structured output learning from a regression\nperspective. We first provide a general formulation of the kernel dependency\nestimation (KDE) problem using operator-valued kernels. We show that some of\nthe existing formulations of this problem are special cases of our framework.\nWe then propose a covariance-based operator-valued kernel that allows us to\ntake into account the structure of the kernel feature space. This kernel\noperates on the output space and encodes the interactions between the outputs\nwithout any reference to the input space. To address this issue, we introduce a\nvariant of our KDE method based on the conditional covariance operator that in\naddition to the correlation between the outputs takes into account the effects\nof the input variables. Finally, we evaluate the performance of our KDE\napproach using both covariance and conditional covariance kernels on two\nstructured output problems, and compare it to the state-of-the-art kernel-based\nstructured output regression methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 07:01:00 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2015 18:42:11 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Kadri", "Hachem", "", "INRIA Lille - Nord Europe"], ["Ghavamzadeh", "Mohammad", "", "INRIA\n  Lille - Nord Europe"], ["Preux", "Philippe", "", "INRIA Lille - Nord Europe"]]}, {"id": "1205.2172", "submitter": "Mohamed Khalil El Mahrsi", "authors": "Mohamed Khalil El Mahrsi (LTCI), Fabrice Rossi (SAMM)", "title": "Modularity-Based Clustering for Network-Constrained Trajectories", "comments": "20-th European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESANN 2012), Bruges : Belgium (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel clustering approach for moving object trajectories that\nare constrained by an underlying road network. The approach builds a similarity\ngraph based on these trajectories then uses modularity-optimization hiearchical\ngraph clustering to regroup trajectories with similar profiles. Our\nexperimental study shows the superiority of the proposed approach over classic\nhierarchical clustering and gives a brief insight to visualization of the\nclustering results.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 07:02:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2012 06:22:14 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Mahrsi", "Mohamed Khalil El", "", "LTCI"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1205.2265", "submitter": "Mehrdad Mahdavi", "authors": "Mehrdad Mahdavi, Tianbao Yang, Rong Jin", "title": "Efficient Constrained Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning constitutes a mathematical and compelling framework to\nanalyze sequential decision making problems in adversarial environments. The\nlearner repeatedly chooses an action, the environment responds with an outcome,\nand then the learner receives a reward for the played action. The goal of the\nlearner is to maximize his total reward. However, there are situations in\nwhich, in addition to maximizing the cumulative reward, there are some\nadditional constraints on the sequence of decisions that must be satisfied on\naverage by the learner. In this paper we study an extension to the online\nlearning where the learner aims to maximize the total reward given that some\nadditional constraints need to be satisfied. By leveraging on the theory of\nLagrangian method in constrained optimization, we propose Lagrangian\nexponentially weighted average (LEWA) algorithm, which is a primal-dual variant\nof the well known exponentially weighted average algorithm, to efficiently\nsolve constrained online decision making problems. Using novel theoretical\nanalysis, we establish the regret and the violation of the constraint bounds in\nfull information and bandit feedback models.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 23:06:06 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2012 06:49:29 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Mahdavi", "Mehrdad", ""], ["Yang", "Tianbao", ""], ["Jin", "Rong", ""]]}, {"id": "1205.2282", "submitter": "Fabrice Rossi", "authors": "Matthieu Durut (LTCI), Beno\\^it Patra (LSTA), Fabrice Rossi (SAMM)", "title": "A Discussion on Parallelization Schemes for Stochastic Vector\n  Quantization Algorithms", "comments": null, "journal-ref": "20-th European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning (ESANN 2012), Bruges :\n  Belgium (2012)", "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies parallelization schemes for stochastic Vector Quantization\nalgorithms in order to obtain time speed-ups using distributed resources. We\nshow that the most intuitive parallelization scheme does not lead to better\nperformances than the sequential algorithm. Another distributed scheme is\ntherefore introduced which obtains the expected speed-ups. Then, it is improved\nto fit implementation on distributed architectures where communications are\nslow and inter-machines synchronization too costly. The schemes are tested with\nsimulated distributed architectures and, for the last one, with Microsoft\nWindows Azure platform obtaining speed-ups up to 32 Virtual Machines.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 14:44:31 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Durut", "Matthieu", "", "LTCI"], ["Patra", "Beno\u00eet", "", "LSTA"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1205.2334", "submitter": "Yong Zhang", "authors": "Zhaosong Lu and Yong Zhang", "title": "Sparse Approximation via Penalty Decomposition Methods", "comments": "31 pages, 3 figures and 9 tables. arXiv admin note: substantial text\n  overlap with arXiv:1008.5372", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider sparse approximation problems, that is, general\n$l_0$ minimization problems with the $l_0$-\"norm\" of a vector being a part of\nconstraints or objective function. In particular, we first study the\nfirst-order optimality conditions for these problems. We then propose penalty\ndecomposition (PD) methods for solving them in which a sequence of penalty\nsubproblems are solved by a block coordinate descent (BCD) method. Under some\nsuitable assumptions, we establish that any accumulation point of the sequence\ngenerated by the PD methods satisfies the first-order optimality conditions of\nthe problems. Furthermore, for the problems in which the $l_0$ part is the only\nnonconvex part, we show that such an accumulation point is a local minimizer of\nthe problems. In addition, we show that any accumulation point of the sequence\ngenerated by the BCD method is a saddle point of the penalty subproblem.\nMoreover, for the problems in which the $l_0$ part is the only nonconvex part,\nwe establish that such an accumulation point is a local minimizer of the\npenalty subproblem. Finally, we test the performance of our PD methods by\napplying them to sparse logistic regression, sparse inverse covariance\nselection, and compressed sensing problems. The computational results\ndemonstrate that our methods generally outperform the existing methods in terms\nof solution quality and/or speed.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 18:25:06 GMT"}, {"version": "v2", "created": "Wed, 30 May 2012 00:49:30 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Lu", "Zhaosong", ""], ["Zhang", "Yong", ""]]}, {"id": "1205.2584", "submitter": "Anh Huy Phan", "authors": "Anh Huy Phan and Petr Tichavsk\\'y and Andrzej Cichocki", "title": "Low Complexity Damped Gauss-Newton Algorithms for CANDECOMP/PARAFAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The damped Gauss-Newton (dGN) algorithm for CANDECOMP/PARAFAC (CP)\ndecomposition can handle the challenges of collinearity of factors and\ndifferent magnitudes of factors; nevertheless, for factorization of an $N$-D\ntensor of size $I_1\\times I_N$ with rank $R$, the algorithm is computationally\ndemanding due to construction of large approximate Hessian of size $(RT \\times\nRT)$ and its inversion where $T = \\sum_n I_n$. In this paper, we propose a fast\nimplementation of the dGN algorithm which is based on novel expressions of the\ninverse approximate Hessian in block form. The new implementation has lower\ncomputational complexity, besides computation of the gradient (this part is\ncommon to both methods), requiring the inversion of a matrix of size\n$NR^2\\times NR^2$, which is much smaller than the whole approximate Hessian, if\n$T \\gg NR$. In addition, the implementation has lower memory requirements,\nbecause neither the Hessian nor its inverse never need to be stored in their\nentirety. A variant of the algorithm working with complex valued data is\nproposed as well. Complexity and performance of the proposed algorithm is\ncompared with those of dGN and ALS with line search on examples of difficult\nbenchmark tensors.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 17:26:21 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2012 03:14:12 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Phan", "Anh Huy", ""], ["Tichavsk\u00fd", "Petr", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1205.2599", "submitter": "Kun Zhang", "authors": "Kun Zhang, Aapo Hyvarinen", "title": "On the Identifiability of the Post-Nonlinear Causal Model", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-647-655", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By taking into account the nonlinear effect of the cause, the inner noise\neffect, and the measurement distortion effect in the observed variables, the\npost-nonlinear (PNL) causal model has demonstrated its excellent performance in\ndistinguishing the cause from effect. However, its identifiability has not been\nproperly addressed, and how to apply it in the case of more than two variables\nis also a problem. In this paper, we conduct a systematic investigation on its\nidentifiability in the two-variable case. We show that this model is\nidentifiable in most cases; by enumerating all possible situations in which the\nmodel is not identifiable, we provide sufficient conditions for its\nidentifiability. Simulations are given to support the theoretical results.\nMoreover, in the case of more than two variables, we show that the whole causal\nstructure can be found by applying the PNL causal model to each structure in\nthe Markov equivalent class and testing if the disturbance is independent of\nthe direct causes for each variable. In this way the exhaustive search over all\npossible causal structures is avoided.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:49:04 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Zhang", "Kun", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1205.2600", "submitter": "Reza Bosagh Zadeh", "authors": "Reza Bosagh Zadeh, Shai Ben-David", "title": "A Uniqueness Theorem for Clustering", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-639-646", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread use of Clustering, there is distressingly little\ngeneral theory of clustering available. Questions like \"What distinguishes a\nclustering of data from other data partitioning?\", \"Are there any principles\ngoverning all clustering paradigms?\", \"How should a user choose an appropriate\nclustering algorithm for a particular task?\", etc. are almost completely\nunanswered by the existing body of clustering literature. We consider an\naxiomatic approach to the theory of Clustering. We adopt the framework of\nKleinberg, [Kle03]. By relaxing one of Kleinberg's clustering axioms, we\nsidestep his impossibility result and arrive at a consistent set of axioms. We\nsuggest to extend these axioms, aiming to provide an axiomatic taxonomy of\nclustering paradigms. Such a taxonomy should provide users some guidance\nconcerning the choice of the appropriate clustering paradigm for a given task.\nThe main result of this paper is a set of abstract properties that characterize\nthe Single-Linkage clustering function. This characterization result provides\nnew insight into the properties of desired data groupings that make\nSingle-Linkage the appropriate choice. We conclude by considering a taxonomy of\nclustering functions based on abstract properties that each satisfies.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:48:23 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Zadeh", "Reza Bosagh", ""], ["Ben-David", "Shai", ""]]}, {"id": "1205.2602", "submitter": "Jin Yu", "authors": "Jin Yu, S. V.N. Vishwanatan, Jian Zhang", "title": "The Entire Quantile Path of a Risk-Agnostic SVM Classifier", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-623-630", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quantile binary classifier uses the rule: Classify x as +1 if P(Y = 1|X =\nx) >= t, and as -1 otherwise, for a fixed quantile parameter t {[0, 1]. It has\nbeen shown that Support Vector Machines (SVMs) in the limit are quantile\nclassifiers with t = 1/2 . In this paper, we show that by using asymmetric cost\nof misclassification SVMs can be appropriately extended to recover, in the\nlimit, the quantile binary classifier for any t. We then present a principled\nalgorithm to solve the extended SVM classifier for all values of t\nsimultaneously. This has two implications: First, one can recover the entire\nconditional distribution P(Y = 1|X = x) = t for t {[0, 1]. Second, we can build\na risk-agnostic SVM classifier where the cost of misclassification need not be\nknown apriori. Preliminary numerical experiments show the effectiveness of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:46:51 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Yu", "Jin", ""], ["Vishwanatan", "S. V. N.", ""], ["Zhang", "Jian", ""]]}, {"id": "1205.2604", "submitter": "David Wingate", "authors": "David Wingate, Noah Goodman, Daniel Roy, Joshua Tenenbaum", "title": "The Infinite Latent Events Model", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-607-614", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Infinite Latent Events Model, a nonparametric hierarchical\nBayesian distribution over infinite dimensional Dynamic Bayesian Networks with\nbinary state representations and noisy-OR-like transitions. The distribution\ncan be used to learn structure in discrete timeseries data by simultaneously\ninferring a set of latent events, which events fired at each timestep, and how\nthose events are causally linked. We illustrate the model on a sound\nfactorization task, a network topology identification task, and a video game\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:43:56 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Wingate", "David", ""], ["Goodman", "Noah", ""], ["Roy", "Daniel", ""], ["Tenenbaum", "Joshua", ""]]}, {"id": "1205.2605", "submitter": "Max Welling", "authors": "Max Welling", "title": "Herding Dynamic Weights for Partially Observed Random Field Models", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-599-606", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the parameters of a (potentially partially observable) random field\nmodel is intractable in general. Instead of focussing on a single optimal\nparameter value we propose to treat parameters as dynamical quantities. We\nintroduce an algorithm to generate complex dynamics for parameters and (both\nvisible and hidden) state vectors. We show that under certain conditions\naverages computed over trajectories of the proposed dynamical system converge\nto averages computed over the data. Our \"herding dynamics\" does not require\nexpensive operations such as exponentiation and is fully deterministic.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:42:06 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Welling", "Max", ""]]}, {"id": "1205.2606", "submitter": "Thomas J. Walsh", "authors": "Thomas J. Walsh, Istvan Szita, Carlos Diuk, Michael L. Littman", "title": "Exploring compact reinforcement-learning representations with linear\n  regression", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-591-598", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm for online linear regression whose\nefficiency guarantees satisfy the requirements of the KWIK (Knows What It\nKnows) framework. The algorithm improves on the complexity bounds of the\ncurrent state-of-the-art procedure in this setting. We explore several\napplications of this algorithm for learning compact reinforcement-learning\nrepresentations. We show that KWIK linear regression can be used to learn the\nreward function of a factored MDP and the probabilities of action outcomes in\nStochastic STRIPS and Object Oriented MDPs, none of which have been proven to\nbe efficiently learnable in the RL setting before. We also combine KWIK linear\nregression with other KWIK learners to learn larger portions of these models,\nincluding experiments on learning factored MDP transition and reward functions\ntogether.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:40:40 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Walsh", "Thomas J.", ""], ["Szita", "Istvan", ""], ["Diuk", "Carlos", ""], ["Littman", "Michael L.", ""]]}, {"id": "1205.2608", "submitter": "Christopher M. Vigorito", "authors": "Christopher M. Vigorito", "title": "Temporal-Difference Networks for Dynamical Systems with Continuous\n  Observations and Actions", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-575-582", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-difference (TD) networks are a class of predictive state\nrepresentations that use well-established TD methods to learn models of\npartially observable dynamical systems. Previous research with TD networks has\ndealt only with dynamical systems with finite sets of observations and actions.\nWe present an algorithm for learning TD network representations of dynamical\nsystems with continuous observations and actions. Our results show that the\nalgorithm is capable of learning accurate and robust models of several noisy\ncontinuous dynamical systems. The algorithm presented here is the first fully\nincremental method for learning a predictive representation of a continuous\ndynamical system.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:38:39 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Vigorito", "Christopher M.", ""]]}, {"id": "1205.2609", "submitter": "Nakul Verma", "authors": "Nakul Verma, Samory Kpotufe, Sanjoy Dasgupta", "title": "Which Spatial Partition Trees are Adaptive to Intrinsic Dimension?", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-565-574", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theory work has found that a special type of spatial partition tree -\ncalled a random projection tree - is adaptive to the intrinsic dimension of the\ndata from which it is built. Here we examine this same question, with a\ncombination of theory and experiments, for a broader class of trees that\nincludes k-d trees, dyadic trees, and PCA trees. Our motivation is to get a\nfeel for (i) the kind of intrinsic low dimensional structure that can be\nempirically verified, (ii) the extent to which a spatial partition can exploit\nsuch structure, and (iii) the implications for standard statistical tasks such\nas regression, vector quantization, and nearest neighbor search.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:37:50 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Verma", "Nakul", ""], ["Kpotufe", "Samory", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1205.2610", "submitter": "Shankar Vembu", "authors": "Shankar Vembu, Thomas Gartner, Mario Boley", "title": "Probabilistic Structured Predictors", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009). arXiv admin note: substantial text\n  overlap with arXiv:0912.4473", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-557-564", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider MAP estimators for structured prediction with exponential family\nmodels. In particular, we concentrate on the case that efficient algorithms for\nuniform sampling from the output space exist. We show that under this\nassumption (i) exact computation of the partition function remains a hard\nproblem, and (ii) the partition function and the gradient of the log partition\nfunction can be approximated efficiently. Our main result is an approximation\nscheme for the partition function based on Markov Chain Monte Carlo theory. We\nalso show that the efficient uniform sampling assumption holds in several\napplication settings that are of importance in machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:36:39 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Vembu", "Shankar", ""], ["Gartner", "Thomas", ""], ["Boley", "Mario", ""]]}, {"id": "1205.2611", "submitter": "Tran The Truyen", "authors": "Tran The Truyen, Dinh Q. Phung, Svetha Venkatesh", "title": "Ordinal Boltzmann Machines for Collaborative Filtering", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-548-556", "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering is an effective recommendation technique wherein the\npreference of an individual can potentially be predicted based on preferences\nof other members. Early algorithms often relied on the strong locality in the\npreference data, that is, it is enough to predict preference of a user on a\nparticular item based on a small subset of other users with similar tastes or\nof other items with similar properties. More recently, dimensionality reduction\ntechniques have proved to be equally competitive, and these are based on the\nco-occurrence patterns rather than locality. This paper explores and extends a\nprobabilistic model known as Boltzmann Machine for collaborative filtering\ntasks. It seamlessly integrates both the similarity and co-occurrence in a\nprincipled manner. In particular, we study parameterisation options to deal\nwith the ordinal nature of the preferences, and propose a joint modelling of\nboth the user-based and item-based processes. Experiments on moderate and\nlarge-scale movie recommendation show that our framework rivals existing\nwell-known methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:35:35 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Truyen", "Tran The", ""], ["Phung", "Dinh Q.", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1205.2612", "submitter": "Jin Tian", "authors": "Jin Tian, Ru He", "title": "Computing Posterior Probabilities of Structural Features in Bayesian\n  Networks", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-538-547", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Bayesian network structures from data.\nKoivisto and Sood (2004) and Koivisto (2006) presented algorithms that can\ncompute the exact marginal posterior probability of a subnetwork, e.g., a\nsingle edge, in O(n2n) time and the posterior probabilities for all n(n-1)\npotential edges in O(n2n) total time, assuming that the number of parents per\nnode or the indegree is bounded by a constant. One main drawback of their\nalgorithms is the requirement of a special structure prior that is non uniform\nand does not respect Markov equivalence. In this paper, we develop an algorithm\nthat can compute the exact posterior probability of a subnetwork in O(3n) time\nand the posterior probabilities for all n(n-1) potential edges in O(n3n) total\ntime. Our algorithm also assumes a bounded indegree but allows general\nstructure priors. We demonstrate the applicability of the algorithm on several\ndata sets with up to 20 variables.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:33:52 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Tian", "Jin", ""], ["He", "Ru", ""]]}, {"id": "1205.2614", "submitter": "Graham W Taylor", "authors": "Graham W Taylor, Geoffrey E. Hinton", "title": "Products of Hidden Markov Models: It Takes N>1 to Tango", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-522-529", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Products of Hidden Markov Models(PoHMMs) are an interesting class of\ngenerative models which have received little attention since their\nintroduction. This maybe in part due to their more computationally expensive\ngradient-based learning algorithm,and the intractability of computing the log\nlikelihood of sequences under the model. In this paper, we demonstrate how the\npartition function can be estimated reliably via Annealed Importance Sampling.\nWe perform experiments using contrastive divergence learning on rainfall data\nand data captured from pairs of people dancing. Our results suggest that\nadvances in learning and evaluation for undirected graphical models and recent\nincreases in available computing power make PoHMMs worth considering for\ncomplex time-series modeling tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:30:23 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Taylor", "Graham W", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1205.2617", "submitter": "Mark Schmidt", "authors": "Mark Schmidt, Kevin Murphy", "title": "Modeling Discrete Interventional Data using Directed Cyclic Graphical\n  Models", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-487-495", "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a representation for discrete multivariate distributions in terms\nof interventional potential functions that are globally normalized. This\nrepresentation can be used to model the effects of interventions, and the\nindependence properties encoded in this model can be represented as a directed\ngraph that allows cycles. In addition to discussing inference and sampling with\nthis representation, we give an exponential family parametrization that allows\nparameter estimation to be stated as a convex optimization problem; we also\ngive a convex relaxation of the task of simultaneous parameter and structure\nlearning using group l1-regularization. The model is evaluated on simulated\ndata and intracellular flow cytometry data.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:26:23 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Schmidt", "Mark", ""], ["Murphy", "Kevin", ""]]}, {"id": "1205.2618", "submitter": "Steffen Rendle", "authors": "Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars\n  Schmidt-Thieme", "title": "BPR: Bayesian Personalized Ranking from Implicit Feedback", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-452-461", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item recommendation is the task of predicting a personalized ranking on a set\nof items (e.g. websites, movies, products). In this paper, we investigate the\nmost common scenario with implicit feedback (e.g. clicks, purchases). There are\nmany methods for item recommendation from implicit feedback like matrix\nfactorization (MF) or adaptive knearest-neighbor (kNN). Even though these\nmethods are designed for the item prediction task of personalized ranking, none\nof them is directly optimized for ranking. In this paper we present a generic\noptimization criterion BPR-Opt for personalized ranking that is the maximum\nposterior estimator derived from a Bayesian analysis of the problem. We also\nprovide a generic learning algorithm for optimizing models with respect to\nBPR-Opt. The learning method is based on stochastic gradient descent with\nbootstrap sampling. We show how to apply our method to two state-of-the-art\nrecommender models: matrix factorization and adaptive kNN. Our experiments\nindicate that for the task of personalized ranking our optimization method\noutperforms the standard learning techniques for MF and kNN. The results show\nthe importance of optimizing models for the right criterion.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:25:09 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Rendle", "Steffen", ""], ["Freudenthaler", "Christoph", ""], ["Gantner", "Zeno", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1205.2622", "submitter": "Sara Mostafavi", "authors": "Sara Mostafavi, Quaid Morris", "title": "Using the Gene Ontology Hierarchy when Predicting Gene Function", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-419-427", "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multilabel classification when the labels are related through\na hierarchical categorization scheme occurs in many application domains such as\ncomputational biology. For example, this problem arises naturally when trying\nto automatically assign gene function using a controlled vocabularies like Gene\nOntology. However, most existing approaches for predicting gene functions solve\nindependent classification problems to predict genes that are involved in a\ngiven function category, independently of the rest. Here, we propose two simple\nmethods for incorporating information about the hierarchical nature of the\ncategorization scheme. In the first method, we use information about a gene's\nprevious annotation to set an initial prior on its label. In a second approach,\nwe extend a graph-based semi-supervised learning algorithm for predicting gene\nfunction in a hierarchy. We show that we can efficiently solve this problem by\nsolving a linear system of equations. We compare these approaches with a\nprevious label reconciliation-based approach. Results show that using the\nhierarchy information directly, compared to using reconciliation methods,\nimproves gene function prediction.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:26:42 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Mostafavi", "Sara", ""], ["Morris", "Quaid", ""]]}, {"id": "1205.2623", "submitter": "Thomas P. Minka", "authors": "Thomas P. Minka, Rongjing Xiang, Yuan (Alan) Qi", "title": "Virtual Vector Machine for Bayesian Online Classification", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-411-418", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a typical online learning scenario, a learner is required to process a\nlarge data stream using a small memory buffer. Such a requirement is usually in\nconflict with a learner's primary pursuit of prediction accuracy. To address\nthis dilemma, we introduce a novel Bayesian online classi cation algorithm,\ncalled the Virtual Vector Machine. The virtual vector machine allows you to\nsmoothly trade-off prediction accuracy with memory size. The virtual vector\nmachine summarizes the information contained in the preceding data stream by a\nGaussian distribution over the classi cation weights plus a constant number of\nvirtual data points. The virtual data points are designed to add extra\nnon-Gaussian information about the classi cation weights. To maintain the\nconstant number of virtual points, the virtual vector machine adds the current\nreal data point into the virtual point set, merges two most similar virtual\npoints into a new virtual point or deletes a virtual point that is far from the\ndecision boundary. The information lost in this process is absorbed into the\nGaussian distribution. The extra information provided by the virtual points\nleads to improved predictive accuracy over previous online classification\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:24:52 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Minka", "Thomas P.", "", "Alan"], ["Xiang", "Rongjing", "", "Alan"], ["Yuan", "", "", "Alan"], ["Qi", "", ""]]}, {"id": "1205.2624", "submitter": "Ofer Meshi", "authors": "Ofer Meshi, Ariel Jaimovich, Amir Globerson, Nir Friedman", "title": "Convexifying the Bethe Free Energy", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-402-410", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of loopy belief propagation (LBP) revitalized the\napplication of graphical models in many domains. Many recent works present\nimprovements on the basic LBP algorithm in an attempt to overcome convergence\nand local optima problems. Notable among these are convexified free energy\napproximations that lead to inference procedures with provable convergence and\nquality properties. However, empirically LBP still outperforms most of its\nconvex variants in a variety of settings, as we also demonstrate here.\nMotivated by this fact we seek convexified free energies that directly\napproximate the Bethe free energy. We show that the proposed approximations\ncompare favorably with state-of-the art convex free energy approximations.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:23:13 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Meshi", "Ofer", ""], ["Jaimovich", "Ariel", ""], ["Globerson", "Amir", ""], ["Friedman", "Nir", ""]]}, {"id": "1205.2625", "submitter": "Talya Meltzer", "authors": "Talya Meltzer, Amir Globerson, Yair Weiss", "title": "Convergent message passing algorithms - a unifying view", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-393-401", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message-passing algorithms have emerged as powerful techniques for\napproximate inference in graphical models. When these algorithms converge, they\ncan be shown to find local (or sometimes even global) optima of variational\nformulations to the inference problem. But many of the most popular algorithms\nare not guaranteed to converge. This has lead to recent interest in convergent\nmessage-passing algorithms. In this paper, we present a unified view of\nconvergent message-passing algorithms. We present a simple derivation of an\nabstract algorithm, tree-consistency bound optimization (TCBO) that is provably\nconvergent in both its sum and max product forms. We then show that many of the\nexisting convergent algorithms are instances of our TCBO algorithm, and obtain\nnovel convergent algorithms \"for free\" by exchanging maximizations and\nsummations in existing algorithms. In particular, we show that Wainwright's\nnon-convergent sum-product algorithm for tree based variational bounds, is\nactually convergent with the right update order for the case where trees are\nmonotonic chains.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:21:25 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Meltzer", "Talya", ""], ["Globerson", "Amir", ""], ["Weiss", "Yair", ""]]}, {"id": "1205.2626", "submitter": "Benjamin Marlin", "authors": "Benjamin Marlin, Mark Schmidt, Kevin Murphy", "title": "Group Sparse Priors for Covariance Estimation", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-383-392", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it has become popular to learn sparse Gaussian graphical models\n(GGMs) by imposing l1 or group l1,2 penalties on the elements of the precision\nmatrix. Thispenalized likelihood approach results in a tractable convex\noptimization problem. In this paper, we reinterpret these results as performing\nMAP estimation under a novel prior which we call the group l1 and l1,2\npositivedefinite matrix distributions. This enables us to build a hierarchical\nmodel in which the l1 regularization terms vary depending on which group the\nentries are assigned to, which in turn allows us to learn block structured\nsparse GGMs with unknown group assignments. Exact inference in this\nhierarchical model is intractable, due to the need to compute the normalization\nconstant of these matrix distributions. However, we derive upper bounds on the\npartition functions, which lets us use fast variational inference (optimizing a\nlower bound on the joint posterior). We show that on two real world data sets\n(motion capture and financial data), our method which infers the block\nstructure outperforms a method that uses a fixed block structure, which in turn\noutperforms baseline methods that ignore block structure.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:19:05 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Marlin", "Benjamin", ""], ["Schmidt", "Mark", ""], ["Murphy", "Kevin", ""]]}, {"id": "1205.2627", "submitter": "Yi Mao", "authors": "Yi Mao, Guy Lebanon", "title": "Domain Knowledge Uncertainty and Probabilistic Parameter Constraints", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-375-382", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating domain knowledge into the modeling process is an effective way\nto improve learning accuracy. However, as it is provided by humans, domain\nknowledge can only be specified with some degree of uncertainty. We propose to\nexplicitly model such uncertainty through probabilistic constraints over the\nparameter space. In contrast to hard parameter constraints, our approach is\neffective also when the domain knowledge is inaccurate and generally results in\nsuperior modeling accuracy. We focus on generative and conditional modeling\nwhere the parameters are assigned a Dirichlet or Gaussian prior and demonstrate\nthe framework with experiments on both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:17:33 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Mao", "Yi", ""], ["Lebanon", "Guy", ""]]}, {"id": "1205.2628", "submitter": "Yishay Mansour", "authors": "Yishay Mansour, Mehryar Mohri, Afshin Rostamizadeh", "title": "Multiple Source Adaptation and the Renyi Divergence", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-367-374", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel theoretical study of the general problem of\nmultiple source adaptation using the notion of Renyi divergence. Our results\nbuild on our previous work [12], but significantly broaden the scope of that\nwork in several directions. We extend previous multiple source loss guarantees\nbased on distribution weighted combinations to arbitrary target distributions\nP, not necessarily mixtures of the source distributions, analyze both known and\nunknown target distribution cases, and prove a lower bound. We further extend\nour bounds to deal with the case where the learner receives an approximate\ndistribution for each source instead of the exact one, and show that similar\nloss guarantees can be achieved depending on the divergence between the\napproximate and true distributions. We also analyze the case where the labeling\nfunctions of the source domains are somewhat different. Finally, we report the\nresults of experiments with both an artificial data set and a sentiment\nanalysis task, showing the performance benefits of the distribution weighted\ncombinations and the quality of our bounds based on the Renyi divergence.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:15:45 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "1205.2629", "submitter": "Siwei Lyu", "authors": "Siwei Lyu", "title": "Interpretation and Generalization of Score Matching", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-359-366", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score matching is a recently developed parameter learning method that is\nparticularly effective to complicated high dimensional density models with\nintractable partition functions. In this paper, we study two issues that have\nnot been completely resolved for score matching. First, we provide a formal\nlink between maximum likelihood and score matching. Our analysis shows that\nscore matching finds model parameters that are more robust with noisy training\ndata. Second, we develop a generalization of score matching. Based on this\ngeneralization, we further demonstrate an extension of score matching to models\nof discrete data.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:14:10 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Lyu", "Siwei", ""]]}, {"id": "1205.2631", "submitter": "Jun Liu", "authors": "Jun Liu, Shuiwang Ji, Jieping Ye", "title": "Multi-Task Feature Learning Via Efficient l2,1-Norm Minimization", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-339-348", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of joint feature selection across a group of related tasks has\napplications in many areas including biomedical informatics and computer\nvision. We consider the l2,1-norm regularized regression model for joint\nfeature selection from multiple tasks, which can be derived in the\nprobabilistic framework by assuming a suitable prior from the exponential\nfamily. One appealing feature of the l2,1-norm regularization is that it\nencourages multiple predictors to share similar sparsity patterns. However, the\nresulting optimization problem is challenging to solve due to the\nnon-smoothness of the l2,1-norm regularization. In this paper, we propose to\naccelerate the computation by reformulating it as two equivalent smooth convex\noptimization problems which are then solved via the Nesterov's method-an\noptimal first-order black-box method for smooth convex optimization. A key\nbuilding block in solving the reformulations is the Euclidean projection. We\nshow that the Euclidean projection for the first reformulation can be\nanalytically computed, while the Euclidean projection for the second one can be\ncomputed in linear time. Empirical evaluations on several data sets verify the\nefficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:09:42 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Liu", "Jun", ""], ["Ji", "Shuiwang", ""], ["Ye", "Jieping", ""]]}, {"id": "1205.2632", "submitter": "Ping Li", "authors": "Ping Li", "title": "Improving Compressed Counting", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-329-338", "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed Counting (CC) [22] was recently proposed for estimating the ath\nfrequency moments of data streams, where 0 < a <= 2. CC can be used for\nestimating Shannon entropy, which can be approximated by certain functions of\nthe ath frequency moments as a -> 1. Monitoring Shannon entropy for anomaly\ndetection (e.g., DDoS attacks) in large networks is an important task. This\npaper presents a new algorithm for improving CC. The improvement is most\nsubstantial when a -> 1--. For example, when a = 0:99, the new algorithm\nreduces the estimation variance roughly by 100-fold. This new algorithm would\nmake CC considerably more practical for estimating Shannon entropy.\nFurthermore, the new algorithm is statistically optimal when a = 0.5.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:49:12 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "1205.2640", "submitter": "Dominik Janzing", "authors": "Dominik Janzing, Jonas Peters, Joris Mooij, Bernhard Schoelkopf", "title": "Identifying confounders using additive noise models", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-249-257", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for inferring the existence of a latent common cause\n('confounder') of two observed random variables. The method assumes that the\ntwo effects of the confounder are (possibly nonlinear) functions of the\nconfounder plus independent, additive noise. We discuss under which conditions\nthe model is identifiable (up to an arbitrary reparameterization of the\nconfounder) from the joint distribution of the effects. We state and prove a\ntheoretical result that provides evidence for the conjecture that the model is\ngenerically identifiable under suitable technical conditions. In addition, we\npropose a practical method to estimate the confounder from a finite i.i.d.\nsample of the effects and illustrate that the method works well on both\nsimulated and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:31:59 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Janzing", "Dominik", ""], ["Peters", "Jonas", ""], ["Mooij", "Joris", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1205.2641", "submitter": "Patrik O. Hoyer", "authors": "Patrik O. Hoyer, Antti Hyttinen", "title": "Bayesian Discovery of Linear Acyclic Causal Models", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-240-248", "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for automated discovery of causal relationships from\nnon-interventional data have received much attention recently. A widely used\nand well understood model family is given by linear acyclic causal models\n(recursive structural equation models). For Gaussian data both constraint-based\nmethods (Spirtes et al., 1993; Pearl, 2000) (which output a single equivalence\nclass) and Bayesian score-based methods (Geiger and Heckerman, 1994) (which\nassign relative scores to the equivalence classes) are available. On the\ncontrary, all current methods able to utilize non-Gaussianity in the data\n(Shimizu et al., 2006; Hoyer et al., 2008) always return only a single graph or\na single equivalence class, and so are fundamentally unable to express the\ndegree of certainty attached to that output. In this paper we develop a\nBayesian score-based approach able to take advantage of non-Gaussianity when\nestimating linear acyclic causal models, and we empirically demonstrate that,\nat least on very modest size networks, its accuracy is as good as or better\nthan existing methods. We provide a complete code package (in R) which\nimplements all algorithms and performs all of the analysis provided in the\npaper, and hope that this will further the application of these methods to\nsolving causal inference problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:30:07 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Hoyer", "Patrik O.", ""], ["Hyttinen", "Antti", ""]]}, {"id": "1205.2643", "submitter": "Matthias Hoffman", "authors": "Matthias Hoffman, Hendrik Kueck, Nando de Freitas, Arnaud Doucet", "title": "New inference strategies for solving Markov Decision Processes using\n  reversible jump MCMC", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-223-231", "categories": "cs.LG cs.SY math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we build on previous work which uses inferences techniques, in\nparticular Markov Chain Monte Carlo (MCMC) methods, to solve parameterized\ncontrol problems. We propose a number of modifications in order to make this\napproach more practical in general, higher-dimensional spaces. We first\nintroduce a new target distribution which is able to incorporate more reward\ninformation from sampled trajectories. We also show how to break strong\ncorrelations between the policy parameters and sampled trajectories in order to\nsample more freely. Finally, we show how to incorporate these techniques in a\nprincipled manner to obtain estimates of the optimal policy.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:26:47 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Hoffman", "Matthias", ""], ["Kueck", "Hendrik", ""], ["de Freitas", "Nando", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1205.2646", "submitter": "Kuzman Ganchev", "authors": "Kuzman Ganchev, Michael Kearns, Yuriy Nevmyvaka, Jennifer Wortman\n  Vaughan", "title": "Censored Exploration and the Dark Pool Problem", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-185-194", "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze a natural algorithm for multi-venue exploration from\ncensored data, which is motivated by the Dark Pool Problem of modern\nquantitative finance. We prove that our algorithm converges in polynomial time\nto a near-optimal allocation policy; prior results for similar problems in\nstochastic inventory control guaranteed only asymptotic convergence and\nexamined variants in which each venue could be treated independently. Our\nanalysis bears a strong resemblance to that of efficient exploration/\nexploitation schemes in the reinforcement learning literature. We describe an\nextensive experimental evaluation of our algorithm on the Dark Pool Problem\nusing real trading data.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:16:31 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Ganchev", "Kuzman", ""], ["Kearns", "Michael", ""], ["Nevmyvaka", "Yuriy", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "1205.2648", "submitter": "Yu Fan", "authors": "Yu Fan, Christian R. Shelton", "title": "Learning Continuous-Time Social Network Dynamics", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-161-168", "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that a number of sociology models for social network dynamics\ncan be viewed as continuous time Bayesian networks (CTBNs). A sampling-based\napproximate inference method for CTBNs can be used as the basis of an\nexpectation-maximization procedure that achieves better accuracy in estimating\nthe parameters of the model than the standard method of moments\nalgorithmfromthe sociology literature. We extend the existing social network\nmodels to allow for indirect and asynchronous observations of the links. A\nMarkov chain Monte Carlo sampling algorithm for this new model permits\nestimation and inference. We provide results on both a synthetic network (for\nverification) and real social network data.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:13:59 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Fan", "Yu", ""], ["Shelton", "Christian R.", ""]]}, {"id": "1205.2650", "submitter": "Finale Doshi-Velez", "authors": "Finale Doshi-Velez, Zoubin Ghahramani", "title": "Correlated Non-Parametric Latent Feature Models", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-143-150", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are often interested in explaining data through a set of hidden factors or\nfeatures. When the number of hidden features is unknown, the Indian Buffet\nProcess (IBP) is a nonparametric latent feature model that does not bound the\nnumber of active features in dataset. However, the IBP assumes that all latent\nfeatures are uncorrelated, making it inadequate for many realworld problems. We\nintroduce a framework for correlated nonparametric feature models, generalising\nthe IBP. We use this framework to generate several specific models and\ndemonstrate applications on realworld datasets.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:09:51 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Doshi-Velez", "Finale", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1205.2653", "submitter": "Corinna Cortes", "authors": "Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh", "title": "L2 Regularization for Learning Kernels", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-109-116", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of the kernel is critical to the success of many learning\nalgorithms but it is typically left to the user. Instead, the training data can\nbe used to learn the kernel by selecting it out of a given family, such as that\nof non-negative linear combinations of p base kernels, constrained by a trace\nor L1 regularization. This paper studies the problem of learning kernels with\nthe same family of kernels but with an L2 regularization instead, and for\nregression problems. We analyze the problem of learning kernels with ridge\nregression. We derive the form of the solution of the optimization problem and\ngive an efficient iterative algorithm for computing that solution. We present a\nnovel theoretical analysis of the problem based on stability and give learning\nbounds for orthogonal kernels that contain only an additive term O(pp/m) when\ncompared to the standard kernel ridge regression stability bound. We also\nreport the results of experiments indicating that L1 regularization can lead to\nmodest improvements for a small number of kernels, but to performance\ndegradations in larger-scale cases. In contrast, L2 regularization never\ndegrades performance and in fact achieves significant improvements with a large\nnumber of kernels.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:01:22 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "1205.2656", "submitter": "David M. Bradley", "authors": "David M. Bradley, J Andrew Bagnell", "title": "Convex Coding", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-83-90", "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent work on convex formulations of clustering (Lashkari &\nGolland, 2008; Nowozin & Bakir, 2008) we investigate a new formulation of the\nSparse Coding Problem (Olshausen & Field, 1997). In sparse coding we attempt to\nsimultaneously represent a sequence of data-vectors sparsely (i.e. sparse\napproximation (Tropp et al., 2006)) in terms of a 'code' defined by a set of\nbasis elements, while also finding a code that enables such an approximation.\nAs existing alternating optimization procedures for sparse coding are\ntheoretically prone to severe local minima problems, we propose a convex\nrelaxation of the sparse coding problem and derive a boosting-style algorithm,\nthat (Nowozin & Bakir, 2008) serves as a convex 'master problem' which calls a\n(potentially non-convex) sub-problem to identify the next code element to add.\nFinally, we demonstrate the properties of our boosted coding algorithm on an\nimage denoising task.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:54:51 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Bradley", "David M.", ""], ["Bagnell", "J Andrew", ""]]}, {"id": "1205.2657", "submitter": "Jordan Boyd-Graber", "authors": "Jordan Boyd-Graber, David Blei", "title": "Multilingual Topic Models for Unaligned Text", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-75-82", "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the multilingual topic model for unaligned text (MuTo), a\nprobabilistic model of text that is designed to analyze corpora composed of\ndocuments in two languages. From these documents, MuTo uses stochastic EM to\nsimultaneously discover both a matching between the languages and multilingual\nlatent topics. We demonstrate that MuTo is able to find shared topics on\nreal-world multilingual corpora, successfully pairing related documents across\nlanguages. MuTo provides a new framework for creating multilingual topic models\nwithout needing carefully curated parallel corpora and allows applications\nbuilt using the topic model formalism to be applied to a much wider class of\ncorpora.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:53:11 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Boyd-Graber", "Jordan", ""], ["Blei", "David", ""]]}, {"id": "1205.2658", "submitter": "Alexandre Bouchard-Cote", "authors": "Alexandre Bouchard-Cote, Michael I. Jordan", "title": "Optimization of Structured Mean Field Objectives", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-67-74", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In intractable, undirected graphical models, an intuitive way of creating\nstructured mean field approximations is to select an acyclic tractable\nsubgraph. We show that the hardness of computing the objective function and\ngradient of the mean field objective qualitatively depends on a simple graph\nproperty. If the tractable subgraph has this property- we call such subgraphs\nv-acyclic-a very fast block coordinate ascent algorithm is possible. If not,\noptimization is harder, but we show a new algorithm based on the construction\nof an auxiliary exponential family that can be used to make inference possible\nin this case as well. We discuss the advantages and disadvantages of each\nregime and compare the algorithms empirically.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:51:42 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Bouchard-Cote", "Alexandre", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1205.2660", "submitter": "Kedar Bellare", "authors": "Kedar Bellare, Gregory Druck, Andrew McCallum", "title": "Alternating Projections for Learning with Expectation Constraints", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-43-50", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an objective function for learning with unlabeled data that\nutilizes auxiliary expectation constraints. We optimize this objective function\nusing a procedure that alternates between information and moment projections.\nOur method provides an alternate interpretation of the posterior regularization\nframework (Graca et al., 2008), maintains uncertainty during optimization\nunlike constraint-driven learning (Chang et al., 2007), and is more efficient\nthan generalized expectation criteria (Mann & McCallum, 2008). Applications of\nthis framework include minimally supervised learning, semisupervised learning,\nand learning with constraints that are more expressive than the underlying\nmodel. In experiments, we demonstrate comparable accuracy to generalized\nexpectation criteria for minimally supervised learning, and use expressive\nstructural constraints to guide semi-supervised learning, providing a 3%-6%\nimprovement over stateof-the-art constraint-driven learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:48:34 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Bellare", "Kedar", ""], ["Druck", "Gregory", ""], ["McCallum", "Andrew", ""]]}, {"id": "1205.2661", "submitter": "Peter L. Bartlett", "authors": "Peter L. Bartlett, Ambuj Tewari", "title": "REGAL: A Regularization based Algorithm for Reinforcement Learning in\n  Weakly Communicating MDPs", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-35-42", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an algorithm that achieves the optimal regret rate in an unknown\nweakly communicating Markov Decision Process (MDP). The algorithm proceeds in\nepisodes where, in each episode, it picks a policy using regularization based\non the span of the optimal bias vector. For an MDP with S states and A actions\nwhose optimal bias vector has span bounded by H, we show a regret bound of\n~O(HSpAT). We also relate the span to various diameter-like quantities\nassociated with the MDP, demonstrating how our results improve on previous\nregret bounds.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:47:06 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1205.2662", "submitter": "Arthur Asuncion", "authors": "Arthur Asuncion, Max Welling, Padhraic Smyth, Yee Whye Teh", "title": "On Smoothing and Inference for Topic Models", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-27-34", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet analysis, or topic modeling, is a flexible latent variable\nframework for modeling high-dimensional sparse count data. Various learning\nalgorithms have been developed in recent years, including collapsed Gibbs\nsampling, variational inference, and maximum a posteriori estimation, and this\nvariety motivates the need for careful empirical comparisons. In this paper, we\nhighlight the close connections between these approaches. We find that the main\ndifferences are attributable to the amount of smoothing applied to the counts.\nWhen the hyperparameters are optimized, the differences in performance among\nthe algorithms diminish significantly. The ability of these algorithms to\nachieve solutions of comparable accuracy gives us the freedom to select\ncomputationally efficient approaches. Using the insights gained from this\ncomparative study, we show how accurate topic models can be learned in several\nseconds on text corpora with thousands of documents.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:43:32 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Asuncion", "Arthur", ""], ["Welling", "Max", ""], ["Smyth", "Padhraic", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1205.2664", "submitter": "John Asmuth", "authors": "John Asmuth, Lihong Li, Michael L. Littman, Ali Nouri, David Wingate", "title": "A Bayesian Sampling Approach to Exploration in Reinforcement Learning", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-19-26", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular approach to reinforcement learning that uses a Bayesian\nrepresentation of the uncertainty over models. The approach, BOSS (Best of\nSampled Set), drives exploration by sampling multiple models from the posterior\nand selecting actions optimistically. It extends previous work by providing a\nrule for deciding when to resample and how to combine the models. We show that\nour algorithm achieves nearoptimal reward with high probability with a sample\ncomplexity that is low relative to the speed at which the posterior\ndistribution converges during learning. We demonstrate that BOSS performs quite\nfavorably compared to state-of-the-art reinforcement-learning approaches and\nillustrate its flexibility by pairing it with a non-parametric model that\ngeneralizes across states.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:42:20 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Asmuth", "John", ""], ["Li", "Lihong", ""], ["Littman", "Michael L.", ""], ["Nouri", "Ali", ""], ["Wingate", "David", ""]]}, {"id": "1205.2874", "submitter": "Ohad Shamir", "authors": "Orly Avner, Shie Mannor, Ohad Shamir", "title": "Decoupling Exploration and Exploitation in Multi-Armed Bandits", "comments": "Full version of the paper presented at ICML 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-armed bandit problem where the decision maker can explore\nand exploit different arms at every round. The exploited arm adds to the\ndecision maker's cumulative reward (without necessarily observing the reward)\nwhile the explored arm reveals its value. We devise algorithms for this setup\nand show that the dependence on the number of arms, k, can be much better than\nthe standard square root of k dependence, depending on the behavior of the\narms' reward sequences. For the important case of piecewise stationary\nstochastic bandits, we show a significant improvement over existing algorithms.\nOur algorithms are based on a non-uniform sampling policy, which we show is\nessential to the success of any algorithm in the adversarial setup. Finally, we\nshow some simulation results on an ultra-wide band channel selection inspired\nsetting indicating the applicability of our algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2012 15:11:00 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2012 21:56:07 GMT"}, {"version": "v3", "created": "Sat, 30 Jun 2012 08:17:09 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Avner", "Orly", ""], ["Mannor", "Shie", ""], ["Shamir", "Ohad", ""]]}, {"id": "1205.2930", "submitter": "Deng Cai", "authors": "Yue Lin and Deng Cai and Cheng Li", "title": "Density Sensitive Hashing", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbors search is a fundamental problem in various research fields\nlike machine learning, data mining and pattern recognition. Recently,\nhashing-based approaches, e.g., Locality Sensitive Hashing (LSH), are proved to\nbe effective for scalable high dimensional nearest neighbors search. Many\nhashing algorithms found their theoretic root in random projection. Since these\nalgorithms generate the hash tables (projections) randomly, a large number of\nhash tables (i.e., long codewords) are required in order to achieve both high\nprecision and recall. To address this limitation, we propose a novel hashing\nalgorithm called {\\em Density Sensitive Hashing} (DSH) in this paper. DSH can\nbe regarded as an extension of LSH. By exploring the geometric structure of the\ndata, DSH avoids the purely random projections selection and uses those\nprojective functions which best agree with the distribution of the data.\nExtensive experimental results on real-world data sets have shown that the\nproposed method achieves better performance compared to the state-of-the-art\nhashing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 02:27:52 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Lin", "Yue", ""], ["Cai", "Deng", ""], ["Li", "Cheng", ""]]}, {"id": "1205.2958", "submitter": "Ping Li", "authors": "Ping Li and Anshumali Shrivastava and Arnd Christian Konig", "title": "b-Bit Minwise Hashing in Practice: Large-Scale Batch and Online Learning\n  and Using GPUs for Fast Preprocessing with Simple Hash Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study several critical issues which must be tackled before\none can apply b-bit minwise hashing to the volumes of data often used\nindustrial applications, especially in the context of search.\n  1. (b-bit) Minwise hashing requires an expensive preprocessing step that\ncomputes k (e.g., 500) minimal values after applying the corresponding\npermutations for each data vector. We developed a parallelization scheme using\nGPUs and observed that the preprocessing time can be reduced by a factor of\n20-80 and becomes substantially smaller than the data loading time.\n  2. One major advantage of b-bit minwise hashing is that it can substantially\nreduce the amount of memory required for batch learning. However, as online\nalgorithms become increasingly popular for large-scale learning in the context\nof search, it is not clear if b-bit minwise yields significant improvements for\nthem. This paper demonstrates that $b$-bit minwise hashing provides an\neffective data size/dimension reduction scheme and hence it can dramatically\nreduce the data loading time for each epoch of the online training process.\nThis is significant because online learning often requires many (e.g., 10 to\n100) epochs to reach a sufficient accuracy.\n  3. Another critical issue is that for very large data sets it becomes\nimpossible to store a (fully) random permutation matrix, due to its space\nrequirements. Our paper is the first study to demonstrate that $b$-bit minwise\nhashing implemented using simple hash functions, e.g., the 2-universal (2U) and\n4-universal (4U) hash families, can produce very similar learning results as\nusing fully random permutations. Experiments on datasets of up to 200GB are\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 08:28:10 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Li", "Ping", ""], ["Shrivastava", "Anshumali", ""], ["Konig", "Arnd Christian", ""]]}, {"id": "1205.3062", "submitter": "Priyank Singhal", "authors": "Priyank Singhal, Nataasha Raul", "title": "Malware Detection Module using Machine Learning Algorithms to Assist in\n  Centralized Security in Enterprise Networks", "comments": "6 pages", "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA), Vol.4, No.1, January 2012", "doi": "10.5121/ijnsa.2012.4106", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious software is abundant in a world of innumerable computer users, who\nare constantly faced with these threats from various sources like the internet,\nlocal networks and portable drives. Malware is potentially low to high risk and\ncan cause systems to function incorrectly, steal data and even crash. Malware\nmay be executable or system library files in the form of viruses, worms,\nTrojans, all aimed at breaching the security of the system and compromising\nuser privacy. Typically, anti-virus software is based on a signature definition\nsystem which keeps updating from the internet and thus keeping track of known\nviruses. While this may be sufficient for home-users, a security risk from a\nnew virus could threaten an entire enterprise network. This paper proposes a\nnew and more sophisticated antivirus engine that can not only scan files, but\nalso build knowledge and detect files as potential viruses. This is done by\nextracting system API calls made by various normal and harmful executable, and\nusing machine learning algorithms to classify and hence, rank files on a scale\nof security risk. While such a system is processor heavy, it is very effective\nwhen used centrally to protect an enterprise network which maybe more prone to\nsuch threats.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 14:21:02 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Singhal", "Priyank", ""], ["Raul", "Nataasha", ""]]}, {"id": "1205.3109", "submitter": "Arthur Guez", "authors": "Arthur Guez and David Silver and Peter Dayan", "title": "Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based\n  Search", "comments": "14 pages, 7 figures, includes supplementary material. Advances in\n  Neural Information Processing Systems (NIPS) 2012", "journal-ref": "(2012) Advances in Neural Information Processing Systems 25, pages\n  1034-1042", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian model-based reinforcement learning is a formally elegant approach to\nlearning optimal behaviour under model uncertainty, trading off exploration and\nexploitation in an ideal way. Unfortunately, finding the resulting\nBayes-optimal policies is notoriously taxing, since the search space becomes\nenormous. In this paper we introduce a tractable, sample-based method for\napproximate Bayes-optimal planning which exploits Monte-Carlo tree search. Our\napproach outperformed prior Bayesian model-based RL algorithms by a significant\nmargin on several well-known benchmark problems -- because it avoids expensive\napplications of Bayes rule within the search tree by lazily sampling models\nfrom the current beliefs. We illustrate the advantages of our approach by\nshowing it working in an infinite state space domain which is qualitatively out\nof reach of almost all previous work in Bayesian exploration.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 17:20:29 GMT"}, {"version": "v2", "created": "Sat, 13 Oct 2012 15:19:09 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2013 14:44:59 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2013 11:45:49 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Guez", "Arthur", ""], ["Silver", "David", ""], ["Dayan", "Peter", ""]]}, {"id": "1205.3137", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Abhinav Gupta, Alexei A. Efros", "title": "Unsupervised Discovery of Mid-Level Discriminative Patches", "comments": null, "journal-ref": "European Conference on Computer Vision, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to discover a set of discriminative patches which\ncan serve as a fully unsupervised mid-level visual representation. The desired\npatches need to satisfy two requirements: 1) to be representative, they need to\noccur frequently enough in the visual world; 2) to be discriminative, they need\nto be different enough from the rest of the visual world. The patches could\ncorrespond to parts, objects, \"visual phrases\", etc. but are not restricted to\nbe any one of them. We pose this as an unsupervised discriminative clustering\nproblem on a huge dataset of image patches. We use an iterative procedure which\nalternates between clustering and training discriminative classifiers, while\napplying careful cross-validation at each step to prevent overfitting. The\npaper experimentally demonstrates the effectiveness of discriminative patches\nas an unsupervised mid-level visual representation, suggesting that it could be\nused in place of visual words for many tasks. Furthermore, discriminative\npatches can also be used in a supervised regime, such as scene classification,\nwhere they demonstrate state-of-the-art performance on the MIT Indoor-67\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 18:52:57 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2012 04:16:13 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Singh", "Saurabh", ""], ["Gupta", "Abhinav", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1205.3181", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck, Tengyao Wang, Nitin Viswanathan", "title": "Multiple Identifications in Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying the top $m$ arms in a multi-armed bandit\ngame. Our proposed solution relies on a new algorithm based on successive\nrejects of the seemingly bad arms, and successive accepts of the good ones.\nThis algorithmic contribution allows to tackle other multiple identifications\nsettings that were previously out of reach. In particular we show that this\nidea of successive accepts and rejects applies to the multi-bandit best arm\nidentification problem.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 20:10:04 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Wang", "Tengyao", ""], ["Viswanathan", "Nitin", ""]]}, {"id": "1205.3441", "submitter": "Romain Giot", "authors": "Romain Giot (GREYC), Christophe Rosenberger (GREYC)", "title": "Genetic Programming for Multibiometrics", "comments": null, "journal-ref": "Expert Systems with Applications 39, 2 1837-1847 (2012)", "doi": "10.1016/j.eswa.2011.08.066", "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric systems suffer from some drawbacks: a biometric system can provide\nin general good performances except with some individuals as its performance\ndepends highly on the quality of the capture. One solution to solve some of\nthese problems is to use multibiometrics where different biometric systems are\ncombined together (multiple captures of the same biometric modality, multiple\nfeature extraction algorithms, multiple biometric modalities...). In this\npaper, we are interested in score level fusion functions application (i.e., we\nuse a multibiometric authentication scheme which accept or deny the claimant\nfor using an application). In the state of the art, the weighted sum of scores\n(which is a linear classifier) and the use of an SVM (which is a non linear\nclassifier) provided by different biometric systems provide one of the best\nperformances. We present a new method based on the use of genetic programming\ngiving similar or better performances (depending on the complexity of the\ndatabase). We derive a score fusion function by assembling some classical\nprimitives functions (+, *, -, ...). We have validated the proposed method on\nthree significant biometric benchmark datasets from the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 10:25:16 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Giot", "Romain", "", "GREYC"], ["Rosenberger", "Christophe", "", "GREYC"]]}, {"id": "1205.3549", "submitter": "Kenji Yamanishi", "authors": "So Hirai and Kenji Yamanishi", "title": "Normalized Maximum Likelihood Coding for Exponential Family with Its\n  Applications to Optimal Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are concerned with the issue of how to calculate the normalized maximum\nlikelihood (NML) code-length. There is a problem that the normalization term of\nthe NML code-length may diverge when it is continuous and unbounded and a\nstraightforward computation of it is highly expensive when the data domain is\nfinite . In previous works it has been investigated how to calculate the NML\ncode-length for specific types of distributions. We first propose a general\nmethod for computing the NML code-length for the exponential family. Then we\nspecifically focus on Gaussian mixture model (GMM), and propose a new efficient\nmethod for computing the NML to them. We develop it by generalizing Rissanen's\nre-normalizing technique. Then we apply this method to the clustering issue, in\nwhich a clustering structure is modeled using a GMM, and the main task is to\nestimate the optimal number of clusters on the basis of the NML code-length. We\ndemonstrate using artificial data sets the superiority of the NML-based\nclustering over other criteria such as AIC, BIC in terms of the data size\nrequired for high accuracy rate to be achieved.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 03:54:30 GMT"}, {"version": "v2", "created": "Thu, 17 May 2012 01:03:19 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Hirai", "So", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1205.3767", "submitter": "Vladimir V'yugin", "authors": "Vladimir V'yugin and Vladimir Trunov", "title": "Universal Algorithm for Online Trading Based on the Method of\n  Calibration", "comments": "32 pages. arXiv admin note: substantial text overlap with\n  arXiv:1105.4272", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a universal algorithm for online trading in Stock Market which\nperforms asymptotically at least as good as any stationary trading strategy\nthat computes the investment at each step using a fixed function of the side\ninformation that belongs to a given RKHS (Reproducing Kernel Hilbert Space).\nUsing a universal kernel, we extend this result for any continuous stationary\nstrategy. In this learning process, a trader rationally chooses his gambles\nusing predictions made by a randomized well-calibrated algorithm. Our strategy\nis based on Dawid's notion of calibration with more general checking rules and\non some modification of Kakade and Foster's randomized rounding algorithm for\ncomputing the well-calibrated forecasts. We combine the method of randomized\ncalibration with Vovk's method of defensive forecasting in RKHS. Unlike the\nstatistical theory, no stochastic assumptions are made about the stock prices.\nOur empirical results on historical markets provide strong evidence that this\ntype of technical trading can \"beat the market\" if transaction costs are\nignored.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 19:17:03 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 09:00:25 GMT"}, {"version": "v3", "created": "Tue, 4 Nov 2014 00:36:57 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["V'yugin", "Vladimir", ""], ["Trunov", "Vladimir", ""]]}, {"id": "1205.3981", "submitter": "Paolo Frasconi", "authors": "Paolo Frasconi, Fabrizio Costa, Luc De Raedt, Kurt De Grave", "title": "kLog: A Language for Logical and Relational Learning with Kernels", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2014.08.003", "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce kLog, a novel approach to statistical relational learning.\nUnlike standard approaches, kLog does not represent a probability distribution\ndirectly. It is rather a language to perform kernel-based learning on\nexpressive logical and relational representations. kLog allows users to specify\nlearning problems declaratively. It builds on simple but powerful concepts:\nlearning from interpretations, entity/relationship data modeling, logic\nprogramming, and deductive databases. Access by the kernel to the rich\nrepresentation is mediated by a technique we call graphicalization: the\nrelational representation is first transformed into a graph --- in particular,\na grounded entity/relationship diagram. Subsequently, a choice of graph kernel\ndefines the feature space. kLog supports mixed numerical and symbolic data, as\nwell as background knowledge in the form of Prolog or Datalog programs as in\ninductive logic programming systems. The kLog framework can be applied to\ntackle the same range of tasks that has made statistical relational learning so\npopular, including classification, regression, multitask learning, and\ncollective classification. We also report about empirical comparisons, showing\nthat kLog can be either more accurate, or much faster at the same level of\naccuracy, than Tilde and Alchemy. kLog is GPLv3 licensed and is available at\nhttp://klog.dinfo.unifi.it along with tutorials.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 17:00:00 GMT"}, {"version": "v2", "created": "Fri, 18 May 2012 12:46:57 GMT"}, {"version": "v3", "created": "Fri, 22 Jun 2012 12:06:52 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2014 11:47:55 GMT"}, {"version": "v5", "created": "Mon, 28 Jul 2014 13:41:00 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Frasconi", "Paolo", ""], ["Costa", "Fabrizio", ""], ["De Raedt", "Luc", ""], ["De Grave", "Kurt", ""]]}, {"id": "1205.4133", "submitter": "Mehrdad Yaghoobi Vaighan", "authors": "Mehrdad Yaghoobi, Sangnam Nam, Remi Gribonval and Mike E. Davies", "title": "Constrained Overcomplete Analysis Operator Learning for Cosparse Signal\n  Modelling", "comments": "29 pages, 13 figures, accepted to be published in TSP", "journal-ref": null, "doi": "10.1109/TSP.2013.2250968", "report-no": null, "categories": "math.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a low-dimensional signal model from a\ncollection of training samples. The mainstream approach would be to learn an\novercomplete dictionary to provide good approximations of the training samples\nusing sparse synthesis coefficients. This famous sparse model has a less well\nknown counterpart, in analysis form, called the cosparse analysis model. In\nthis new model, signals are characterised by their parsimony in a transformed\ndomain using an overcomplete (linear) analysis operator. We propose to learn an\nanalysis operator from a training corpus using a constrained optimisation\nframework based on L1 optimisation. The reason for introducing a constraint in\nthe optimisation framework is to exclude trivial solutions. Although there is\nno final answer here for which constraint is the most relevant constraint, we\ninvestigate some conventional constraints in the model adaptation field and use\nthe uniformly normalised tight frame (UNTF) for this purpose. We then derive a\npractical learning algorithm, based on projected subgradients and\nDouglas-Rachford splitting technique, and demonstrate its ability to robustly\nrecover a ground truth analysis operator, when provided with a clean training\nset, of sufficient size. We also find an analysis operator for images, using\nsome noisy cosparse signals, which is indeed a more realistic experiment. As\nthe derived optimisation problem is not a convex program, we often find a local\nminimum using such variational methods. Some local optimality conditions are\nderived for two different settings, providing preliminary theoretical support\nfor the well-posedness of the learning problem under appropriate conditions.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 10:54:39 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2013 15:07:18 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Yaghoobi", "Mehrdad", ""], ["Nam", "Sangnam", ""], ["Gribonval", "Remi", ""], ["Davies", "Mike E.", ""]]}, {"id": "1205.4159", "submitter": "Wray Buntine", "authors": "Changyou Chen, Wray Buntine and Nan Ding", "title": "Theory of Dependent Hierarchical Normalized Random Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents theory for Normalized Random Measures (NRMs), Normalized\nGeneralized Gammas (NGGs), a particular kind of NRM, and Dependent Hierarchical\nNRMs which allow networks of dependent NRMs to be analysed. These have been\nused, for instance, for time-dependent topic modelling. In this paper, we first\nintroduce some mathematical background of completely random measures (CRMs) and\ntheir construction from Poisson processes, and then introduce NRMs and NGGs.\nSlice sampling is also introduced for posterior inference. The dependency\noperators in Poisson processes and for the corresponding CRMs and NRMs is then\nintroduced and Posterior inference for the NGG presented. Finally, we give\ndependency and composition results when applying these operators to NRMs so\nthey can be used in a network with hierarchical and dependent relations.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 13:56:17 GMT"}, {"version": "v2", "created": "Fri, 25 May 2012 05:32:57 GMT"}], "update_date": "2012-05-28", "authors_parsed": [["Chen", "Changyou", ""], ["Buntine", "Wray", ""], ["Ding", "Nan", ""]]}, {"id": "1205.4213", "submitter": "Pannagadatta Shivaswamy", "authors": "Pannaga Shivaswamy and Thorsten Joachims", "title": "Online Structured Prediction via Coactive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Coactive Learning as a model of interaction between a learning\nsystem and a human user, where both have the common goal of providing results\nof maximum utility to the user. At each step, the system (e.g. search engine)\nreceives a context (e.g. query) and predicts an object (e.g. ranking). The user\nresponds by correcting the system if necessary, providing a slightly improved\n-- but not necessarily optimal -- object as feedback. We argue that such\nfeedback can often be inferred from observable user behavior, for example, from\nclicks in web-search. Evaluating predictions by their cardinal utility to the\nuser, we propose efficient learning algorithms that have ${\\cal\nO}(\\frac{1}{\\sqrt{T}})$ average regret, even though the learning algorithm\nnever observes cardinal utility values as in conventional online learning. We\ndemonstrate the applicability of our model and learning algorithms on a movie\nrecommendation task, as well as ranking for web-search.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 18:19:13 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2012 16:25:02 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Shivaswamy", "Pannaga", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1205.4217", "submitter": "Nathaniel Korda", "authors": "Emilie Kaufmann, Nathaniel Korda and R\\'emi Munos", "title": "Thompson Sampling: An Asymptotically Optimal Finite Time Analysis", "comments": "15 pages, 2 figures, submitted to ALT (Algorithmic Learning Theory)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of the optimality of Thompson Sampling for solving the\nstochastic multi-armed bandit problem had been open since 1933. In this paper\nwe answer it positively for the case of Bernoulli rewards by providing the\nfirst finite-time analysis that matches the asymptotic rate given in the Lai\nand Robbins lower bound for the cumulative regret. The proof is accompanied by\na numerical comparison with other optimal policies, experiments that have been\nlacking in the literature until now for the Bernoulli case.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 19:00:51 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2012 13:59:13 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Kaufmann", "Emilie", ""], ["Korda", "Nathaniel", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1205.4220", "submitter": "Jianshu Chen", "authors": "Ali H. Sayed", "title": "Diffusion Adaptation over Networks", "comments": "114 pages, 16 figures, 9 tables, to appear in E-Reference Signal\n  Processing, R. Chellapa and S. Theodoridis, Eds., Elsevier, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive networks are well-suited to perform decentralized information\nprocessing and optimization tasks and to model various types of self-organized\nand complex behavior encountered in nature. Adaptive networks consist of a\ncollection of agents with processing and learning abilities. The agents are\nlinked together through a connection topology, and they cooperate with each\nother through local interactions to solve distributed optimization, estimation,\nand inference problems in real-time. The continuous diffusion of information\nacross the network enables agents to adapt their performance in relation to\nstreaming data and network conditions; it also results in improved adaptation\nand learning performance relative to non-cooperative agents. This article\nprovides an overview of diffusion strategies for adaptation and learning over\nnetworks. The article is divided into several sections: 1. Motivation; 2.\nMean-Square-Error Estimation; 3. Distributed Optimization via Diffusion\nStrategies; 4. Adaptive Diffusion Strategies; 5. Performance of\nSteepest-Descent Diffusion Strategies; 6. Performance of Adaptive Diffusion\nStrategies; 7. Comparing the Performance of Cooperative Strategies; 8.\nSelecting the Combination Weights; 9. Diffusion with Noisy Information\nExchanges; 10. Extensions and Further Considerations; Appendix A: Properties of\nKronecker Products; Appendix B: Graph Laplacian and Network Connectivity;\nAppendix C: Stochastic Matrices; Appendix D: Block Maximum Norm; Appendix E:\nComparison with Consensus Strategies; References.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 19:09:46 GMT"}, {"version": "v2", "created": "Sun, 5 May 2013 22:42:36 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Sayed", "Ali H.", ""]]}, {"id": "1205.4234", "submitter": "Dmitry Lande", "authors": "D. V. Lande", "title": "Visualization of features of a series of measurements with\n  one-dimensional cellular structure", "comments": "4 pages, russian language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the method of visualization of periodic constituents and\ninstability areas in series of measurements, being based on the algorithm of\nsmoothing out and concept of one-dimensional cellular automata. A method can be\nused at the analysis of temporal series, related to the volumes of thematic\npublications in web-space.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 08:16:21 GMT"}, {"version": "v2", "created": "Fri, 25 May 2012 10:24:35 GMT"}], "update_date": "2012-05-28", "authors_parsed": [["Lande", "D. V.", ""]]}, {"id": "1205.4295", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein", "title": "Efficient Methods for Unsupervised Learning of Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis I develop a variety of techniques to train, evaluate, and\nsample from intractable and high dimensional probabilistic models. Abstract\nexceeds arXiv space limitations -- see PDF.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 04:25:04 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1205.4343", "submitter": "Andres Munoz", "authors": "Mehryar Mohri and Andres Munoz Medina", "title": "New Analysis and Algorithm for Learning with Drifting Distributions", "comments": "15 pages, 2 figures to be published in volume 7568 of the Lecture\n  Notes in Computer Science series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new analysis of the problem of learning with drifting\ndistributions in the batch setting using the notion of discrepancy. We prove\nlearning bounds based on the Rademacher complexity of the hypothesis set and\nthe discrepancy of distributions both for a drifting PAC scenario and a\ntracking scenario. Our bounds are always tighter and in some cases\nsubstantially improve upon previous ones based on the $L_1$ distance. We also\npresent a generalization of the standard on-line to batch conversion to the\ndrifting scenario in terms of the discrepancy and arbitrary convex combinations\nof hypotheses. We introduce a new algorithm exploiting these learning\nguarantees, which we show can be formulated as a simple QP. Finally, we report\nthe results of preliminary experiments demonstrating the benefits of this\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 16:09:15 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2012 00:15:55 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Mohri", "Mehryar", ""], ["Medina", "Andres Munoz", ""]]}, {"id": "1205.4349", "submitter": "Sergiu Goschin", "authors": "Sergiu Goschin", "title": "From Exact Learning to Computing Boolean Functions and Back Again", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the paper is to relate complexity measures associated with the\nevaluation of Boolean functions (certificate complexity, decision tree\ncomplexity) and learning dimensions used to characterize exact learning\n(teaching dimension, extended teaching dimension). The high level motivation is\nto discover non-trivial relations between exact learning of an unknown concept\nand testing whether an unknown concept is part of a concept class or not.\nConcretely, the goal is to provide lower and upper bounds of complexity\nmeasures for one problem type in terms of the other.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 17:16:53 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Goschin", "Sergiu", ""]]}, {"id": "1205.4471", "submitter": "Zhilin Zhang", "authors": "Bhaskar D. Rao, Zhilin Zhang, Yuzhe Jin", "title": "Sparse Signal Recovery in the Presence of Intra-Vector and Inter-Vector\n  Correlation", "comments": "Invited review paper of 2012 International Conference on Signal\n  Processing and Communications (SPCOM 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work discusses the problem of sparse signal recovery when there is\ncorrelation among the values of non-zero entries. We examine intra-vector\ncorrelation in the context of the block sparse model and inter-vector\ncorrelation in the context of the multiple measurement vector model, as well as\ntheir combination. Algorithms based on the sparse Bayesian learning are\npresented and the benefits of incorporating correlation at the algorithm level\nare discussed. The impact of correlation on the limits of support recovery is\nalso discussed highlighting the different impact intra-vector and inter-vector\ncorrelations have on such limits.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 23:56:17 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Rao", "Bhaskar D.", ""], ["Zhang", "Zhilin", ""], ["Jin", "Yuzhe", ""]]}, {"id": "1205.4476", "submitter": "Deniz Akdemir", "authors": "Deniz Akdemir and Nicolas Heslot", "title": "Soft Rule Ensembles for Statistical Learning", "comments": "arXiv admin note: text overlap with arXiv:1112.3699", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article supervised learning problems are solved using soft rule\nensembles. We first review the importance sampling learning ensembles (ISLE)\napproach that is useful for generating hard rules. The soft rules are then\nobtained with logistic regression from the corresponding hard rules. In order\nto deal with the perfect separation problem related to the logistic regression,\nFirth's bias corrected likelihood is used. Various examples and simulation\nresults show that soft rule ensembles can improve predictive performance over\nhard rule ensembles.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 01:46:04 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2012 16:14:45 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2013 17:03:20 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Akdemir", "Deniz", ""], ["Heslot", "Nicolas", ""]]}, {"id": "1205.4477", "submitter": "Srivatsan Laxman", "authors": "Debprakash Patnaik and Naren Ramakrishnan and Srivatsan Laxman and\n  Badrish Chandramouli", "title": "Streaming Algorithms for Pattern Discovery over Dynamically Changing\n  Event Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering frequent episodes over event sequences is an important data\nmining task. In many applications, events constituting the data sequence arrive\nas a stream, at furious rates, and recent trends (or frequent episodes) can\nchange and drift due to the dynamical nature of the underlying event generation\nprocess. The ability to detect and track such the changing sets of frequent\nepisodes can be valuable in many application scenarios. Current methods for\nfrequent episode discovery are typically multipass algorithms, making them\nunsuitable in the streaming context. In this paper, we propose a new streaming\nalgorithm for discovering frequent episodes over a window of recent events in\nthe stream. Our algorithm processes events as they arrive, one batch at a time,\nwhile discovering the top frequent episodes over a window consisting of several\nbatches in the immediate past. We derive approximation guarantees for our\nalgorithm under the condition that frequent episodes are approximately\nwell-separated from infrequent ones in every batch of the window. We present\nextensive experimental evaluations of our algorithm on both real and synthetic\ndata. We also present comparisons with baselines and adaptations of streaming\nalgorithms from itemset mining literature.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 01:46:57 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Patnaik", "Debprakash", ""], ["Ramakrishnan", "Naren", ""], ["Laxman", "Srivatsan", ""], ["Chandramouli", "Badrish", ""]]}, {"id": "1205.4481", "submitter": "Hua Ouyang", "authors": "Hua Ouyang, Alexander Gray", "title": "Stochastic Smoothing for Nonsmooth Minimizations: Accelerating SGD by\n  Exploiting Structure", "comments": "Full length version of ICML'12 with all proofs. In this version, a\n  bug in proving Theorem 6 is fixed. We'd like to thank Dr. Francesco Orabona\n  for pointing it out", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the stochastic minimization of nonsmooth convex loss\nfunctions, a central problem in machine learning. We propose a novel algorithm\ncalled Accelerated Nonsmooth Stochastic Gradient Descent (ANSGD), which\nexploits the structure of common nonsmooth loss functions to achieve optimal\nconvergence rates for a class of problems including SVMs. It is the first\nstochastic algorithm that can achieve the optimal O(1/t) rate for minimizing\nnonsmooth loss functions (with strong convexity). The fast rates are confirmed\nby empirical comparisons, in which ANSGD significantly outperforms previous\nsubgradient descent algorithms including SGD.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 03:29:17 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2012 14:53:38 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2012 15:15:42 GMT"}, {"version": "v4", "created": "Mon, 1 Oct 2012 16:55:06 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Ouyang", "Hua", ""], ["Gray", "Alexander", ""]]}, {"id": "1205.4656", "submitter": "Steffen Gr\\\"unew\\\"alder", "authors": "Steffen Gr\\\"unew\\\"alder, Guy Lever, Luca Baldassarre, Sam Patterson,\n  Arthur Gretton, Massimilano Pontil", "title": "Conditional mean embeddings as regressors - supplementary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate an equivalence between reproducing kernel Hilbert space (RKHS)\nembeddings of conditional distributions and vector-valued regressors. This\nconnection introduces a natural regularized loss function which the RKHS\nembeddings minimise, providing an intuitive understanding of the embeddings and\na justification for their use. Furthermore, the equivalence allows the\napplication of vector-valued regression methods and results to the problem of\nlearning conditional distributions. Using this link we derive a sparse version\nof the embedding by considering alternative formulations. Further, by applying\nconvergence results for vector-valued regression to the embedding problem we\nderive minimax convergence rates which are O(\\log(n)/n) -- compared to current\nstate of the art rates of O(n^{-1/4}) -- and are valid under milder and more\nintuitive assumptions. These minimax upper rates coincide with lower rates up\nto a logarithmic factor, showing that the embedding method achieves nearly\noptimal rates. We study our sparse embedding algorithm in a reinforcement\nlearning task where the algorithm shows significant improvement in sparsity\nover an incomplete Cholesky decomposition.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 16:43:02 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2012 13:15:47 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Gr\u00fcnew\u00e4lder", "Steffen", ""], ["Lever", "Guy", ""], ["Baldassarre", "Luca", ""], ["Patterson", "Sam", ""], ["Gretton", "Arthur", ""], ["Pontil", "Massimilano", ""]]}, {"id": "1205.4698", "submitter": "Constantinos Panagiotakopoulos", "authors": "Constantinos Panagiotakopoulos and Petroula Tsampouka", "title": "The Role of Weight Shrinking in Large Margin Perceptron Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce into the classical perceptron algorithm with margin a mechanism\nthat shrinks the current weight vector as a first step of the update. If the\nshrinking factor is constant the resulting algorithm may be regarded as a\nmargin-error-driven version of NORMA with constant learning rate. In this case\nwe show that the allowed strength of shrinking depends on the value of the\nmaximum margin. We also consider variable shrinking factors for which there is\nno such dependence. In both cases we obtain new generalizations of the\nperceptron with margin able to provably attain in a finite number of steps any\ndesirable approximation of the maximal margin hyperplane. The new approximate\nmaximum margin classifiers appear experimentally to be very competitive in\n2-norm soft margin tasks involving linear kernels.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 19:19:49 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2013 19:10:14 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Panagiotakopoulos", "Constantinos", ""], ["Tsampouka", "Petroula", ""]]}, {"id": "1205.4776", "submitter": "Ilknur Icke", "authors": "Ilknur Icke and Andrew Rosenberg", "title": "Visual and semantic interpretability of projections of high dimensional\n  data for classification tasks", "comments": "Longer version of the VAST 2011 poster.\n  http://dx.doi.org/10.1109/VAST.2011.6102474", "journal-ref": null, "doi": "10.1109/VAST.2011.6102474", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of visual quality measures have been introduced in visual analytics\nliterature in order to automatically select the best views of high dimensional\ndata from a large number of candidate data projections. These methods generally\nconcentrate on the interpretability of the visualization and pay little\nattention to the interpretability of the projection axes. In this paper, we\nargue that interpretability of the visualizations and the feature\ntransformation functions are both crucial for visual exploration of high\ndimensional labeled data. We present a two-part user study to examine these two\nrelated but orthogonal aspects of interpretability. We first study how humans\njudge the quality of 2D scatterplots of various datasets with varying number of\nclasses and provide comparisons with ten automated measures, including a number\nof visual quality measures and related measures from various machine learning\nfields. We then investigate how the user perception on interpretability of\nmathematical expressions relate to various automated measures of complexity\nthat can be used to characterize data projection functions. We conclude with a\ndiscussion of how automated measures of visual and semantic interpretability of\ndata projections can be used together for exploratory analysis in\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 00:10:45 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Icke", "Ilknur", ""], ["Rosenberg", "Andrew", ""]]}, {"id": "1205.4810", "submitter": "Teodor Mihai Moldovan", "authors": "Teodor Mihai Moldovan, Pieter Abbeel", "title": "Safe Exploration in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In environments with uncertain dynamics exploration is necessary to learn how\nto perform well. Existing reinforcement learning algorithms provide strong\nexploration guarantees, but they tend to rely on an ergodicity assumption. The\nessence of ergodicity is that any state is eventually reachable from any other\nstate by following a suitable policy. This assumption allows for exploration\nalgorithms that operate by simply favoring states that have rarely been visited\nbefore. For most physical systems this assumption is impractical as the systems\nwould break before any reasonable exploration has taken place, i.e., most\nphysical systems don't satisfy the ergodicity assumption. In this paper we\naddress the need for safe exploration methods in Markov decision processes. We\nfirst propose a general formulation of safety through ergodicity. We show that\nimposing safety by restricting attention to the resulting set of guaranteed\nsafe policies is NP-hard. We then present an efficient algorithm for guaranteed\nsafe, but potentially suboptimal, exploration. At the core is an optimization\nformulation in which the constraints restrict attention to a subset of the\nguaranteed safe policies and the objective favors exploration policies. Our\nframework is compatible with the majority of previously proposed exploration\nmethods, which rely on an exploration bonus. Our experiments, which include a\nMartian terrain exploration problem, show that our method is able to explore\nbetter than classical exploration methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 06:02:09 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2012 09:17:38 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2012 20:56:23 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Moldovan", "Teodor Mihai", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1205.4839", "submitter": "Thomas Degris", "authors": "Thomas Degris, Martha White, Richard S. Sutton", "title": "Off-Policy Actor-Critic", "comments": "Full version of the paper, appendix and errata included; Proceedings\n  of the 2012 International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first actor-critic algorithm for off-policy\nreinforcement learning. Our algorithm is online and incremental, and its\nper-time-step complexity scales linearly with the number of learned weights.\nPrevious work on actor-critic algorithms is limited to the on-policy setting\nand does not take advantage of the recent advances in off-policy gradient\ntemporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable\na target policy to be learned while following and obtaining data from another\n(behavior) policy. For many problems, however, actor-critic methods are more\npractical than action value methods (like Greedy-GQ) because they explicitly\nrepresent the policy; consequently, the policy can be stochastic and utilize a\nlarge action space. In this paper, we illustrate how to practically combine the\ngenerality and learning potential of off-policy learning with the flexibility\nin action selection given by actor-critic methods. We derive an incremental,\nlinear time and space complexity algorithm that includes eligibility traces,\nprove convergence under assumptions similar to previous off-policy algorithms,\nand empirically show better or comparable performance to existing algorithms on\nstandard reinforcement-learning benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 08:36:41 GMT"}, {"version": "v2", "created": "Wed, 23 May 2012 14:36:42 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2012 20:40:47 GMT"}, {"version": "v4", "created": "Tue, 14 Aug 2012 07:08:17 GMT"}, {"version": "v5", "created": "Thu, 20 Jun 2013 10:53:42 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Degris", "Thomas", ""], ["White", "Martha", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1205.4891", "submitter": "Amit Daniely", "authors": "Amit Daniely and Nati Linial and Michael Saks", "title": "Clustering is difficult only when it does not matter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous papers ask how difficult it is to cluster data. We suggest that the\nmore relevant and interesting question is how difficult it is to cluster data\nsets {\\em that can be clustered well}. More generally, despite the ubiquity and\nthe great importance of clustering, we still do not have a satisfactory\nmathematical theory of clustering. In order to properly understand clustering,\nit is clearly necessary to develop a solid theoretical basis for the area. For\nexample, from the perspective of computational complexity theory the clustering\nproblem seems very hard. Numerous papers introduce various criteria and\nnumerical measures to quantify the quality of a given clustering. The resulting\nconclusions are pessimistic, since it is computationally difficult to find an\noptimal clustering of a given data set, if we go by any of these popular\ncriteria. In contrast, the practitioners' perspective is much more optimistic.\nOur explanation for this disparity of opinions is that complexity theory\nconcentrates on the worst case, whereas in reality we only care for data sets\nthat can be clustered well.\n  We introduce a theoretical framework of clustering in metric spaces that\nrevolves around a notion of \"good clustering\". We show that if a good\nclustering exists, then in many cases it can be efficiently found. Our\nconclusion is that contrary to popular belief, clustering should not be\nconsidered a hard task.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 12:25:01 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Daniely", "Amit", ""], ["Linial", "Nati", ""], ["Saks", "Michael", ""]]}, {"id": "1205.4893", "submitter": "Amit Daniely", "authors": "Yonatan Bilu and Amit Daniely and Nati Linial and Michael Saks", "title": "On the practically interesting instances of MAXCUT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of a computational problem is traditionally quantified based\non the hardness of its worst case. This approach has many advantages and has\nled to a deep and beautiful theory. However, from the practical perspective,\nthis leaves much to be desired. In application areas, practically interesting\ninstances very often occupy just a tiny part of an algorithm's space of\ninstances, and the vast majority of instances are simply irrelevant. Addressing\nthese issues is a major challenge for theoretical computer science which may\nmake theory more relevant to the practice of computer science.\n  Following Bilu and Linial, we apply this perspective to MAXCUT, viewed as a\nclustering problem. Using a variety of techniques, we investigate practically\ninteresting instances of this problem. Specifically, we show how to solve in\npolynomial time distinguished, metric, expanding and dense instances of MAXCUT\nunder mild stability assumptions. In particular, $(1+\\epsilon)$-stability\n(which is optimal) suffices for metric and dense MAXCUT. We also show how to\nsolve in polynomial time $\\Omega(\\sqrt{n})$-stable instances of MAXCUT,\nsubstantially improving the best previously known result.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 12:30:27 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Bilu", "Yonatan", ""], ["Daniely", "Amit", ""], ["Linial", "Nati", ""], ["Saks", "Michael", ""]]}, {"id": "1205.5012", "submitter": "Jason Lee", "authors": "Jason D. Lee and Trevor J. Hastie", "title": "Learning Mixed Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the structure of a pairwise graphical\nmodel over continuous and discrete variables. We present a new pairwise model\nfor graphical models with both continuous and discrete variables that is\namenable to structure learning. In previous work, authors have considered\nstructure learning of Gaussian graphical models and structure learning of\ndiscrete models. Our approach is a natural generalization of these two lines of\nwork to the mixed case. The penalization scheme involves a novel symmetric use\nof the group-lasso norm and follows naturally from a particular parametrization\nof the model.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 19:20:07 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2012 06:46:47 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2013 23:06:52 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Lee", "Jason D.", ""], ["Hastie", "Trevor J.", ""]]}, {"id": "1205.5075", "submitter": "Shuo Xiang", "authors": "Shuo Xiang, Xiaotong Shen, Jieping Ye", "title": "Efficient Sparse Group Feature Selection via Nonconvex Optimization", "comments": "Accepted by the 30th International Conference on Machine Learning\n  (ICML 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse feature selection has been demonstrated to be effective in handling\nhigh-dimensional data. While promising, most of the existing works use convex\nmethods, which may be suboptimal in terms of the accuracy of feature selection\nand parameter estimation. In this paper, we expand a nonconvex paradigm to\nsparse group feature selection, which is motivated by applications that require\nidentifying the underlying group structure and performing feature selection\nsimultaneously. The main contributions of this article are twofold: (1)\nstatistically, we introduce a nonconvex sparse group feature selection model\nwhich can reconstruct the oracle estimator. Therefore, consistent feature\nselection and parameter estimation can be achieved; (2) computationally, we\npropose an efficient algorithm that is applicable to large-scale problems.\nNumerical results suggest that the proposed nonconvex method compares favorably\nagainst its competitors on synthetic data and real-world applications, thus\nachieving desired goal of delivering high performance.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2012 00:02:01 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 21:06:49 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Xiang", "Shuo", ""], ["Shen", "Xiaotong", ""], ["Ye", "Jieping", ""]]}, {"id": "1205.5353", "submitter": "Ravindra Jain", "authors": "Ravindra Jain", "title": "A hybrid clustering algorithm for data mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data clustering is a process of arranging similar data into groups. A\nclustering algorithm partitions a data set into several groups such that the\nsimilarity within a group is better than among groups. In this paper a hybrid\nclustering algorithm based on K-mean and K-harmonic mean (KHM) is described.\nThe proposed algorithm is tested on five different datasets. The research is\nfocused on fast and accurate clustering. Its performance is compared with the\ntraditional K-means & KHM algorithm. The result obtained from proposed hybrid\nalgorithm is much better than the traditional K-mean & KHM algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 07:37:28 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Jain", "Ravindra", ""]]}, {"id": "1205.5367", "submitter": "Nicola Di Mauro", "authors": "Claudio Taranto, Nicola Di Mauro, Floriana Esposito", "title": "Language-Constraint Reachability Learning in Probabilistic Graphs", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probabilistic graphs framework models the uncertainty inherent in\nreal-world domains by means of probabilistic edges whose value quantifies the\nlikelihood of the edge existence or the strength of the link it represents. The\ngoal of this paper is to provide a learning method to compute the most likely\nrelationship between two nodes in a framework based on probabilistic graphs. In\nparticular, given a probabilistic graph we adopted the language-constraint\nreachability method to compute the probability of possible interconnections\nthat may exists between two nodes. Each of these connections may be viewed as\nfeature, or a factor, between the two nodes and the corresponding probability\nas its weight. Each observed link is considered as a positive instance for its\ncorresponding link label. Given the training set of observed links a\nL2-regularized Logistic Regression has been adopted to learn a model able to\npredict unobserved link labels. The experiments on a real world collaborative\nfiltering problem proved that the proposed approach achieves better results\nthan that obtained adopting classical methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 08:43:14 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Taranto", "Claudio", ""], ["Di Mauro", "Nicola", ""], ["Esposito", "Floriana", ""]]}, {"id": "1205.5819", "submitter": "Damjan Kalajdzievski", "authors": "Damjan Kalajdzievski", "title": "Measurability Aspects of the Compactness Theorem for Sample Compression\n  Schemes", "comments": "Latex 2e, 64 pages, 1 figure. This is an M.Sc. thesis defended on\n  July 4'th 2012 at the University of Ottawa, Canada, under the supervision of\n  Dr. V. Pestov, and with examiners Dr. J. Levy and Dr. S. Zilles", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was proved in 1998 by Ben-David and Litman that a concept space has a\nsample compression scheme of size d if and only if every finite subspace has a\nsample compression scheme of size d. In the compactness theorem, measurability\nof the hypotheses of the created sample compression scheme is not guaranteed;\nat the same time measurability of the hypotheses is a necessary condition for\nlearnability. In this thesis we discuss when a sample compression scheme,\ncreated from com- pression schemes on finite subspaces via the compactness\ntheorem, have measurable hypotheses. We show that if X is a standard Borel\nspace with a d-maximum and universally separable concept class C, then (X,C)\nhas a sample compression scheme of size d with universally Borel measurable\nhypotheses. Additionally we introduce a new variant of compression scheme\ncalled a copy sample compression scheme.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2012 20:38:55 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2012 04:35:11 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Kalajdzievski", "Damjan", ""]]}, {"id": "1205.6031", "submitter": "Xin Guo", "authors": "Wen-Jun Shen, Hau-San Wong, Quan-Wu Xiao, Xin Guo, Stephen Smale", "title": "Towards a Mathematical Foundation of Immunology and Amino Acid Chains", "comments": "updated on June 25, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We attempt to set a mathematical foundation of immunology and amino acid\nchains. To measure the similarities of these chains, a kernel on strings is\ndefined using only the sequence of the chains and a good amino acid\nsubstitution matrix (e.g. BLOSUM62). The kernel is used in learning machines to\npredict binding affinities of peptides to human leukocyte antigens DR (HLA-DR)\nmolecules. On both fixed allele (Nielsen and Lund 2009) and pan-allele (Nielsen\net.al. 2010) benchmark databases, our algorithm achieves the state-of-the-art\nperformance. The kernel is also used to define a distance on an HLA-DR allele\nset based on which a clustering analysis precisely recovers the serotype\nclassifications assigned by WHO (Nielsen and Lund 2009, and Marsh et.al. 2010).\nThese results suggest that our kernel relates well the chain structure of both\npeptides and HLA-DR molecules to their biological functions, and that it offers\na simple, powerful and promising methodology to immunology and amino acid chain\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2012 05:47:52 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2012 04:45:37 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Shen", "Wen-Jun", ""], ["Wong", "Hau-San", ""], ["Xiao", "Quan-Wu", ""], ["Guo", "Xin", ""], ["Smale", "Stephen", ""]]}, {"id": "1205.6210", "submitter": "Christian Sigg", "authors": "Christian D. Sigg and Tomas Dikk and Joachim M. Buhmann", "title": "Learning Dictionaries with Bounded Self-Coherence", "comments": "4 pages, 2 figures; IEEE Signal Processing Letters, vol. 19, no. 12,\n  2012", "journal-ref": null, "doi": "10.1109/LSP.2012.2223757", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding in learned dictionaries has been established as a successful\napproach for signal denoising, source separation and solving inverse problems\nin general. A dictionary learning method adapts an initial dictionary to a\nparticular signal class by iteratively computing an approximate factorization\nof a training data matrix into a dictionary and a sparse coding matrix. The\nlearned dictionary is characterized by two properties: the coherence of the\ndictionary to observations of the signal class, and the self-coherence of the\ndictionary atoms. A high coherence to the signal class enables the sparse\ncoding of signal observations with a small approximation error, while a low\nself-coherence of the atoms guarantees atom recovery and a more rapid residual\nerror decay rate for the sparse coding algorithm. The two goals of high signal\ncoherence and low self-coherence are typically in conflict, therefore one seeks\na trade-off between them, depending on the application. We present a dictionary\nlearning method with an effective control over the self-coherence of the\ntrained dictionary, enabling a trade-off between maximizing the sparsity of\ncodings and approximating an equiangular tight frame.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2012 20:06:45 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2012 09:20:15 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Sigg", "Christian D.", ""], ["Dikk", "Tomas", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1205.6326", "submitter": "Iain Murray", "authors": "Krzysztof Chalupka, Christopher K. I. Williams and Iain Murray", "title": "A Framework for Evaluating Approximation Methods for Gaussian Process\n  Regression", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) predictors are an important component of many Bayesian\napproaches to machine learning. However, even a straightforward implementation\nof Gaussian process regression (GPR) requires O(n^2) space and O(n^3) time for\na dataset of n examples. Several approximation methods have been proposed, but\nthere is a lack of understanding of the relative merits of the different\napproximations, and in what situations they are most useful. We recommend\nassessing the quality of the predictions obtained as a function of the compute\ntime taken, and comparing to standard baselines (e.g., Subset of Data and\nFITC). We empirically investigate four different approximation algorithms on\nfour different prediction problems, and make our code available to encourage\nfuture comparisons.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 10:59:30 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2012 17:39:32 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Williams", "Christopher K. I.", ""], ["Murray", "Iain", ""]]}, {"id": "1205.6432", "submitter": "Amit Daniely", "authors": "Amit Daniely and Sivan Sabato and Shai Shalev Shwartz", "title": "Multiclass Learning Approaches: A Theoretical Comparison with\n  Implications", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2012, pages\n  494-502", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically analyze and compare the following five popular multiclass\nclassification methods: One vs. All, All Pairs, Tree-based classifiers, Error\nCorrecting Output Codes (ECOC) with randomly generated code matrices, and\nMulticlass SVM. In the first four methods, the classification is based on a\nreduction to binary classification. We consider the case where the binary\nclassifier comes from a class of VC dimension $d$, and in particular from the\nclass of halfspaces over $\\reals^d$. We analyze both the estimation error and\nthe approximation error of these methods. Our analysis reveals interesting\nconclusions of practical relevance, regarding the success of the different\napproaches under various conditions. Our proof technique employs tools from VC\ntheory to analyze the \\emph{approximation error} of hypothesis classes. This is\nin sharp contrast to most, if not all, previous uses of VC theory, which only\ndeal with estimation error.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 17:40:04 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2012 14:12:58 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Daniely", "Amit", ""], ["Sabato", "Sivan", ""], ["Shwartz", "Shai Shalev", ""]]}, {"id": "1205.6523", "submitter": "Jana Gevertz", "authors": "Chamont Wang, Jana Gevertz, Chaur-Chin Chen, Leonardo Auslender", "title": "Finding Important Genes from High-Dimensional Data: An Appraisal of\n  Statistical Tests and Machine-Learning Approaches", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, statisticians and machine-learning researchers have\ndeveloped literally thousands of new tools for the reduction of\nhigh-dimensional data in order to identify the variables most responsible for a\nparticular trait. These tools have applications in a plethora of settings,\nincluding data analysis in the fields of business, education, forensics, and\nbiology (such as microarray, proteomics, brain imaging), to name a few.\n  In the present work, we focus our investigation on the limitations and\npotential misuses of certain tools in the analysis of the benchmark colon\ncancer data (2,000 variables; Alon et al., 1999) and the prostate cancer data\n(6,033 variables; Efron, 2010, 2008). Our analysis demonstrates that models\nthat produce 100% accuracy measures often select different sets of genes and\ncannot stand the scrutiny of parameter estimates and model stability.\n  Furthermore, we created a host of simulation datasets and \"artificial\ndiseases\" to evaluate the reliability of commonly used statistical and data\nmining tools. We found that certain widely used models can classify the data\nwith 100% accuracy without using any of the variables responsible for the\ndisease. With moderate sample size and suitable pre-screening, stochastic\ngradient boosting will be shown to be a superior model for gene selection and\nvariable screening from high-dimensional datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 01:23:01 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Wang", "Chamont", ""], ["Gevertz", "Jana", ""], ["Chen", "Chaur-Chin", ""], ["Auslender", "Leonardo", ""]]}, {"id": "1205.6544", "submitter": "Shu Kong", "authors": "Shu Kong, Donghui Wang", "title": "A Brief Summary of Dictionary Learning Based Approach for Classification\n  (revised)", "comments": "a note revised from a withdrawn one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 05:07:55 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Kong", "Shu", ""], ["Wang", "Donghui", ""]]}, {"id": "1205.6849", "submitter": "Hassan Mansour", "authors": "Hassan Mansour", "title": "Beyond $\\ell_1$-norm minimization for sparse signal recovery", "comments": "IEEE Workshop on Statistical Signal Processing (SSP), August 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse signal recovery has been dominated by the basis pursuit denoise (BPDN)\nproblem formulation for over a decade. In this paper, we propose an algorithm\nthat outperforms BPDN in finding sparse solutions to underdetermined linear\nsystems of equations at no additional computational cost. Our algorithm, called\nWSPGL1, is a modification of the spectral projected gradient for $\\ell_1$\nminimization (SPGL1) algorithm in which the sequence of LASSO subproblems are\nreplaced by a sequence of weighted LASSO subproblems with constant weights\napplied to a support estimate. The support estimate is derived from the data\nand is updated at every iteration. The algorithm also modifies the Pareto curve\nat every iteration to reflect the new weighted $\\ell_1$ minimization problem\nthat is being solved. We demonstrate through extensive simulations that the\nsparse recovery performance of our algorithm is superior to that of $\\ell_1$\nminimization and approaches the recovery performance of iterative re-weighted\n$\\ell_1$ (IRWL1) minimization of Cand{\\`e}s, Wakin, and Boyd, although it does\nnot match it in general. Moreover, our algorithm has the computational cost of\na single BPDN problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 22:24:50 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Mansour", "Hassan", ""]]}]